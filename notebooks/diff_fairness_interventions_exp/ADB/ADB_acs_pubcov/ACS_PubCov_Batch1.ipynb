{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c653a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5435209f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eccae41b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da2e6d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213268f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363b601f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba124d8e",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98443de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSPublicCoverageDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3405f6",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6186218a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_pubcov'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_CA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb833b",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a15cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9fb58e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c72361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bf843ff8-62e9-4aac-83bc-d805e3299fdc\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e7226",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7e353a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>ESR</th>\n",
       "      <th>ST</th>\n",
       "      <th>FER</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL MAR SEX DIS ESP CIT MIG MIL ANC NATIVITY DEAR DEYE DREM ESR ST FER  \\\n",
       "0   19   5   1   2   0   1   3   4   1        1    2    2    2   6  6   0   \n",
       "1   16   5   1   2   0   3   3   4   4        1    2    2    2   1  6   0   \n",
       "2   13   5   2   2   1   1   1   0   2        1    2    2    2   6  6   2   \n",
       "3   20   1   2   2   0   4   1   4   1        2    2    2    2   6  6   2   \n",
       "4   16   1   2   2   0   4   1   4   1        2    2    2    2   6  6   0   \n",
       "\n",
       "  RAC1P  AGEP   PINCP  \n",
       "0     1    21  3150.0  \n",
       "1     9    18  1600.0  \n",
       "2     1    16     0.0  \n",
       "3     8    43     0.0  \n",
       "4     6    54     0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSPublicCoverageDataset(state=['CA'], year=2018, with_nulls=False,\n",
    "                                       subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4cc570c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d883d",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720363c0",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb83741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b91aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:54:33 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7536ba522344ef8015e763ad877105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:54:33 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e1bce0204a4755a100b9aece82d43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4fb59cdd7e446e9a3359567ccd4454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.718741; batch adversarial loss: 0.594687\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615528; batch adversarial loss: 0.630470\n",
      "epoch 2; iter: 0; batch classifier loss: 0.633997; batch adversarial loss: 0.636515\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553427; batch adversarial loss: 0.645571\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566175; batch adversarial loss: 0.577790\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592362; batch adversarial loss: 0.568766\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543984; batch adversarial loss: 0.592243\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574178; batch adversarial loss: 0.592201\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549742; batch adversarial loss: 0.611262\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522920; batch adversarial loss: 0.527602\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466149; batch adversarial loss: 0.567428\n",
      "epoch 11; iter: 0; batch classifier loss: 0.452881; batch adversarial loss: 0.548498\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511138; batch adversarial loss: 0.562968\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542615; batch adversarial loss: 0.541802\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497020; batch adversarial loss: 0.473004\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508833; batch adversarial loss: 0.523507\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497249; batch adversarial loss: 0.584651\n",
      "epoch 17; iter: 0; batch classifier loss: 0.540207; batch adversarial loss: 0.593120\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497390; batch adversarial loss: 0.600323\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514440; batch adversarial loss: 0.537841\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511009; batch adversarial loss: 0.511370\n",
      "epoch 21; iter: 0; batch classifier loss: 0.442445; batch adversarial loss: 0.550735\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491062; batch adversarial loss: 0.567866\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452797; batch adversarial loss: 0.590702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505958; batch adversarial loss: 0.535488\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502314; batch adversarial loss: 0.637218\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444298; batch adversarial loss: 0.547617\n",
      "epoch 27; iter: 0; batch classifier loss: 0.456540; batch adversarial loss: 0.601846\n",
      "epoch 28; iter: 0; batch classifier loss: 0.540797; batch adversarial loss: 0.503888\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485113; batch adversarial loss: 0.526569\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449033; batch adversarial loss: 0.588274\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475269; batch adversarial loss: 0.596847\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461854; batch adversarial loss: 0.615484\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488432; batch adversarial loss: 0.501630\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441925; batch adversarial loss: 0.606769\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484316; batch adversarial loss: 0.527673\n",
      "epoch 36; iter: 0; batch classifier loss: 0.409945; batch adversarial loss: 0.526765\n",
      "epoch 37; iter: 0; batch classifier loss: 0.482146; batch adversarial loss: 0.544711\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443510; batch adversarial loss: 0.571389\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430581; batch adversarial loss: 0.598350\n",
      "epoch 40; iter: 0; batch classifier loss: 0.374390; batch adversarial loss: 0.536091\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414148; batch adversarial loss: 0.543842\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441518; batch adversarial loss: 0.544413\n",
      "epoch 43; iter: 0; batch classifier loss: 0.361413; batch adversarial loss: 0.517351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397493; batch adversarial loss: 0.507997\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450170; batch adversarial loss: 0.561848\n",
      "epoch 46; iter: 0; batch classifier loss: 0.379854; batch adversarial loss: 0.580742\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469007; batch adversarial loss: 0.517290\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416048; batch adversarial loss: 0.562961\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468985; batch adversarial loss: 0.535240\n",
      "epoch 50; iter: 0; batch classifier loss: 0.467049; batch adversarial loss: 0.582128\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441472; batch adversarial loss: 0.500385\n",
      "epoch 52; iter: 0; batch classifier loss: 0.514275; batch adversarial loss: 0.517420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450668; batch adversarial loss: 0.535949\n",
      "epoch 54; iter: 0; batch classifier loss: 0.472704; batch adversarial loss: 0.534527\n",
      "epoch 55; iter: 0; batch classifier loss: 0.477553; batch adversarial loss: 0.536251\n",
      "epoch 56; iter: 0; batch classifier loss: 0.494376; batch adversarial loss: 0.590121\n",
      "epoch 57; iter: 0; batch classifier loss: 0.337164; batch adversarial loss: 0.572819\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464180; batch adversarial loss: 0.589981\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406574; batch adversarial loss: 0.599155\n",
      "epoch 60; iter: 0; batch classifier loss: 0.461558; batch adversarial loss: 0.563464\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410046; batch adversarial loss: 0.508625\n",
      "epoch 62; iter: 0; batch classifier loss: 0.495489; batch adversarial loss: 0.580616\n",
      "epoch 63; iter: 0; batch classifier loss: 0.366019; batch adversarial loss: 0.471793\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393412; batch adversarial loss: 0.605887\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425295; batch adversarial loss: 0.588051\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435987; batch adversarial loss: 0.588521\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388988; batch adversarial loss: 0.548824\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393969; batch adversarial loss: 0.624535\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371921; batch adversarial loss: 0.579904\n",
      "epoch 70; iter: 0; batch classifier loss: 0.470212; batch adversarial loss: 0.582533\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394460; batch adversarial loss: 0.504607\n",
      "epoch 72; iter: 0; batch classifier loss: 0.462794; batch adversarial loss: 0.553589\n",
      "epoch 73; iter: 0; batch classifier loss: 0.454907; batch adversarial loss: 0.634256\n",
      "epoch 74; iter: 0; batch classifier loss: 0.342647; batch adversarial loss: 0.488800\n",
      "epoch 75; iter: 0; batch classifier loss: 0.469524; batch adversarial loss: 0.517465\n",
      "epoch 76; iter: 0; batch classifier loss: 0.453897; batch adversarial loss: 0.573081\n",
      "epoch 77; iter: 0; batch classifier loss: 0.444758; batch adversarial loss: 0.488310\n",
      "epoch 78; iter: 0; batch classifier loss: 0.479883; batch adversarial loss: 0.581607\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379565; batch adversarial loss: 0.544465\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416079; batch adversarial loss: 0.572058\n",
      "epoch 81; iter: 0; batch classifier loss: 0.355483; batch adversarial loss: 0.581183\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400536; batch adversarial loss: 0.562937\n",
      "epoch 83; iter: 0; batch classifier loss: 0.426870; batch adversarial loss: 0.571992\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443885; batch adversarial loss: 0.554076\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370923; batch adversarial loss: 0.644244\n",
      "epoch 86; iter: 0; batch classifier loss: 0.482817; batch adversarial loss: 0.526305\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423696; batch adversarial loss: 0.526779\n",
      "epoch 88; iter: 0; batch classifier loss: 0.343830; batch adversarial loss: 0.491438\n",
      "epoch 89; iter: 0; batch classifier loss: 0.301863; batch adversarial loss: 0.579891\n",
      "epoch 90; iter: 0; batch classifier loss: 0.356013; batch adversarial loss: 0.516224\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416571; batch adversarial loss: 0.445445\n",
      "epoch 92; iter: 0; batch classifier loss: 0.420800; batch adversarial loss: 0.565702\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386660; batch adversarial loss: 0.637660\n",
      "epoch 94; iter: 0; batch classifier loss: 0.467379; batch adversarial loss: 0.609762\n",
      "epoch 95; iter: 0; batch classifier loss: 0.335412; batch adversarial loss: 0.472746\n",
      "epoch 96; iter: 0; batch classifier loss: 0.484232; batch adversarial loss: 0.554598\n",
      "epoch 97; iter: 0; batch classifier loss: 0.472704; batch adversarial loss: 0.634268\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378949; batch adversarial loss: 0.536782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.420675; batch adversarial loss: 0.570276\n",
      "epoch 100; iter: 0; batch classifier loss: 0.424502; batch adversarial loss: 0.536201\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394856; batch adversarial loss: 0.598748\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393497; batch adversarial loss: 0.508910\n",
      "epoch 103; iter: 0; batch classifier loss: 0.450205; batch adversarial loss: 0.553830\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370058; batch adversarial loss: 0.434884\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416638; batch adversarial loss: 0.554274\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365648; batch adversarial loss: 0.526120\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371104; batch adversarial loss: 0.480703\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380969; batch adversarial loss: 0.598977\n",
      "epoch 109; iter: 0; batch classifier loss: 0.418813; batch adversarial loss: 0.508049\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396488; batch adversarial loss: 0.644756\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344431; batch adversarial loss: 0.573872\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356233; batch adversarial loss: 0.545472\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371556; batch adversarial loss: 0.508527\n",
      "epoch 114; iter: 0; batch classifier loss: 0.387182; batch adversarial loss: 0.543871\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332979; batch adversarial loss: 0.653533\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351863; batch adversarial loss: 0.517515\n",
      "epoch 117; iter: 0; batch classifier loss: 0.424360; batch adversarial loss: 0.534248\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404239; batch adversarial loss: 0.559917\n",
      "epoch 119; iter: 0; batch classifier loss: 0.358433; batch adversarial loss: 0.543015\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350919; batch adversarial loss: 0.492129\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398453; batch adversarial loss: 0.488790\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385950; batch adversarial loss: 0.472263\n",
      "epoch 123; iter: 0; batch classifier loss: 0.412269; batch adversarial loss: 0.582675\n",
      "epoch 124; iter: 0; batch classifier loss: 0.453798; batch adversarial loss: 0.525687\n",
      "epoch 125; iter: 0; batch classifier loss: 0.441893; batch adversarial loss: 0.508097\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391835; batch adversarial loss: 0.598702\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365836; batch adversarial loss: 0.552044\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343132; batch adversarial loss: 0.561788\n",
      "epoch 129; iter: 0; batch classifier loss: 0.437461; batch adversarial loss: 0.516889\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340115; batch adversarial loss: 0.615620\n",
      "epoch 131; iter: 0; batch classifier loss: 0.460733; batch adversarial loss: 0.562793\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431272; batch adversarial loss: 0.644337\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341827; batch adversarial loss: 0.545116\n",
      "epoch 134; iter: 0; batch classifier loss: 0.429979; batch adversarial loss: 0.627700\n",
      "epoch 135; iter: 0; batch classifier loss: 0.295680; batch adversarial loss: 0.507957\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377773; batch adversarial loss: 0.525891\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351782; batch adversarial loss: 0.553180\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380241; batch adversarial loss: 0.516687\n",
      "epoch 139; iter: 0; batch classifier loss: 0.420717; batch adversarial loss: 0.508958\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360329; batch adversarial loss: 0.526640\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359718; batch adversarial loss: 0.535635\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355111; batch adversarial loss: 0.535008\n",
      "epoch 143; iter: 0; batch classifier loss: 0.310074; batch adversarial loss: 0.552167\n",
      "epoch 144; iter: 0; batch classifier loss: 0.391813; batch adversarial loss: 0.516693\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365749; batch adversarial loss: 0.550926\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341160; batch adversarial loss: 0.554043\n",
      "epoch 147; iter: 0; batch classifier loss: 0.392422; batch adversarial loss: 0.553658\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303271; batch adversarial loss: 0.526141\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388473; batch adversarial loss: 0.579398\n",
      "epoch 150; iter: 0; batch classifier loss: 0.464016; batch adversarial loss: 0.599037\n",
      "epoch 151; iter: 0; batch classifier loss: 0.399707; batch adversarial loss: 0.525692\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323831; batch adversarial loss: 0.535190\n",
      "epoch 153; iter: 0; batch classifier loss: 0.387933; batch adversarial loss: 0.507108\n",
      "epoch 154; iter: 0; batch classifier loss: 0.417319; batch adversarial loss: 0.546610\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346492; batch adversarial loss: 0.579105\n",
      "epoch 156; iter: 0; batch classifier loss: 0.397640; batch adversarial loss: 0.537044\n",
      "epoch 157; iter: 0; batch classifier loss: 0.351840; batch adversarial loss: 0.499977\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345067; batch adversarial loss: 0.581705\n",
      "epoch 159; iter: 0; batch classifier loss: 0.324345; batch adversarial loss: 0.562936\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381469; batch adversarial loss: 0.508857\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376429; batch adversarial loss: 0.435768\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369241; batch adversarial loss: 0.517867\n",
      "epoch 163; iter: 0; batch classifier loss: 0.415708; batch adversarial loss: 0.525526\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345467; batch adversarial loss: 0.508513\n",
      "epoch 165; iter: 0; batch classifier loss: 0.316244; batch adversarial loss: 0.497261\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409999; batch adversarial loss: 0.569144\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341658; batch adversarial loss: 0.589884\n",
      "epoch 168; iter: 0; batch classifier loss: 0.303224; batch adversarial loss: 0.635085\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390016; batch adversarial loss: 0.555633\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379597; batch adversarial loss: 0.570457\n",
      "epoch 171; iter: 0; batch classifier loss: 0.425369; batch adversarial loss: 0.571328\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372901; batch adversarial loss: 0.591576\n",
      "epoch 173; iter: 0; batch classifier loss: 0.310577; batch adversarial loss: 0.517916\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350387; batch adversarial loss: 0.555148\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395882; batch adversarial loss: 0.526514\n",
      "epoch 176; iter: 0; batch classifier loss: 0.318210; batch adversarial loss: 0.498937\n",
      "epoch 177; iter: 0; batch classifier loss: 0.422083; batch adversarial loss: 0.563625\n",
      "epoch 178; iter: 0; batch classifier loss: 0.388170; batch adversarial loss: 0.541038\n",
      "epoch 179; iter: 0; batch classifier loss: 0.420165; batch adversarial loss: 0.560321\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353097; batch adversarial loss: 0.509237\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355829; batch adversarial loss: 0.562753\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402489; batch adversarial loss: 0.516105\n",
      "epoch 183; iter: 0; batch classifier loss: 0.398011; batch adversarial loss: 0.571091\n",
      "epoch 184; iter: 0; batch classifier loss: 0.403965; batch adversarial loss: 0.571440\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326189; batch adversarial loss: 0.535339\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368862; batch adversarial loss: 0.536216\n",
      "epoch 187; iter: 0; batch classifier loss: 0.415891; batch adversarial loss: 0.543567\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381465; batch adversarial loss: 0.489601\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414499; batch adversarial loss: 0.672146\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345876; batch adversarial loss: 0.518143\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323313; batch adversarial loss: 0.626519\n",
      "epoch 192; iter: 0; batch classifier loss: 0.407198; batch adversarial loss: 0.534491\n",
      "epoch 193; iter: 0; batch classifier loss: 0.310682; batch adversarial loss: 0.534757\n",
      "epoch 194; iter: 0; batch classifier loss: 0.475788; batch adversarial loss: 0.589045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.415711; batch adversarial loss: 0.526961\n",
      "epoch 196; iter: 0; batch classifier loss: 0.307925; batch adversarial loss: 0.562440\n",
      "epoch 197; iter: 0; batch classifier loss: 0.376950; batch adversarial loss: 0.508164\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328156; batch adversarial loss: 0.562678\n",
      "epoch 199; iter: 0; batch classifier loss: 0.310993; batch adversarial loss: 0.508931\n",
      "epoch 0; iter: 0; batch classifier loss: 0.646581; batch adversarial loss: 0.762764\n",
      "epoch 1; iter: 0; batch classifier loss: 0.645298; batch adversarial loss: 0.749807\n",
      "epoch 2; iter: 0; batch classifier loss: 0.544547; batch adversarial loss: 0.697864\n",
      "epoch 3; iter: 0; batch classifier loss: 0.489113; batch adversarial loss: 0.660580\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580470; batch adversarial loss: 0.645178\n",
      "epoch 5; iter: 0; batch classifier loss: 0.522701; batch adversarial loss: 0.622529\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508329; batch adversarial loss: 0.638078\n",
      "epoch 7; iter: 0; batch classifier loss: 0.506335; batch adversarial loss: 0.632524\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526883; batch adversarial loss: 0.595736\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479899; batch adversarial loss: 0.597181\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516806; batch adversarial loss: 0.565452\n",
      "epoch 11; iter: 0; batch classifier loss: 0.476022; batch adversarial loss: 0.568019\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537047; batch adversarial loss: 0.558079\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476871; batch adversarial loss: 0.532739\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515200; batch adversarial loss: 0.585052\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580026; batch adversarial loss: 0.608876\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511697; batch adversarial loss: 0.592345\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488351; batch adversarial loss: 0.578221\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496640; batch adversarial loss: 0.578714\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495647; batch adversarial loss: 0.538611\n",
      "epoch 20; iter: 0; batch classifier loss: 0.545266; batch adversarial loss: 0.587874\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498174; batch adversarial loss: 0.579033\n",
      "epoch 22; iter: 0; batch classifier loss: 0.511210; batch adversarial loss: 0.541670\n",
      "epoch 23; iter: 0; batch classifier loss: 0.556019; batch adversarial loss: 0.632381\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479654; batch adversarial loss: 0.669379\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457934; batch adversarial loss: 0.574011\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505231; batch adversarial loss: 0.643451\n",
      "epoch 27; iter: 0; batch classifier loss: 0.531380; batch adversarial loss: 0.583517\n",
      "epoch 28; iter: 0; batch classifier loss: 0.518923; batch adversarial loss: 0.488126\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483443; batch adversarial loss: 0.578503\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474371; batch adversarial loss: 0.581192\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456170; batch adversarial loss: 0.541562\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470781; batch adversarial loss: 0.620859\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455670; batch adversarial loss: 0.563281\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404704; batch adversarial loss: 0.556273\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464866; batch adversarial loss: 0.556632\n",
      "epoch 36; iter: 0; batch classifier loss: 0.380262; batch adversarial loss: 0.469027\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421167; batch adversarial loss: 0.570794\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415221; batch adversarial loss: 0.570777\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411726; batch adversarial loss: 0.544542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445748; batch adversarial loss: 0.535657\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415954; batch adversarial loss: 0.537921\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447013; batch adversarial loss: 0.579357\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433574; batch adversarial loss: 0.553332\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436040; batch adversarial loss: 0.563213\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451792; batch adversarial loss: 0.455620\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446681; batch adversarial loss: 0.579518\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423250; batch adversarial loss: 0.579826\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381417; batch adversarial loss: 0.543882\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408289; batch adversarial loss: 0.429436\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394105; batch adversarial loss: 0.563022\n",
      "epoch 51; iter: 0; batch classifier loss: 0.499541; batch adversarial loss: 0.605301\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418754; batch adversarial loss: 0.553290\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466929; batch adversarial loss: 0.570808\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447271; batch adversarial loss: 0.570046\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480630; batch adversarial loss: 0.579038\n",
      "epoch 56; iter: 0; batch classifier loss: 0.407356; batch adversarial loss: 0.571269\n",
      "epoch 57; iter: 0; batch classifier loss: 0.487701; batch adversarial loss: 0.564188\n",
      "epoch 58; iter: 0; batch classifier loss: 0.478960; batch adversarial loss: 0.552877\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398163; batch adversarial loss: 0.545410\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405182; batch adversarial loss: 0.524782\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463710; batch adversarial loss: 0.472875\n",
      "epoch 62; iter: 0; batch classifier loss: 0.355447; batch adversarial loss: 0.570326\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386476; batch adversarial loss: 0.614757\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454872; batch adversarial loss: 0.604615\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385711; batch adversarial loss: 0.483157\n",
      "epoch 66; iter: 0; batch classifier loss: 0.372266; batch adversarial loss: 0.445740\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430665; batch adversarial loss: 0.545157\n",
      "epoch 68; iter: 0; batch classifier loss: 0.451561; batch adversarial loss: 0.562734\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435186; batch adversarial loss: 0.490622\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421347; batch adversarial loss: 0.480101\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427701; batch adversarial loss: 0.597859\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383779; batch adversarial loss: 0.554348\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410686; batch adversarial loss: 0.543437\n",
      "epoch 74; iter: 0; batch classifier loss: 0.360237; batch adversarial loss: 0.509848\n",
      "epoch 75; iter: 0; batch classifier loss: 0.500541; batch adversarial loss: 0.551872\n",
      "epoch 76; iter: 0; batch classifier loss: 0.356267; batch adversarial loss: 0.571465\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418334; batch adversarial loss: 0.606837\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438535; batch adversarial loss: 0.563555\n",
      "epoch 79; iter: 0; batch classifier loss: 0.473366; batch adversarial loss: 0.489659\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426152; batch adversarial loss: 0.599201\n",
      "epoch 81; iter: 0; batch classifier loss: 0.411575; batch adversarial loss: 0.616060\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385183; batch adversarial loss: 0.501158\n",
      "epoch 83; iter: 0; batch classifier loss: 0.456092; batch adversarial loss: 0.544710\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398848; batch adversarial loss: 0.500002\n",
      "epoch 85; iter: 0; batch classifier loss: 0.304748; batch adversarial loss: 0.534447\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360001; batch adversarial loss: 0.526832\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416255; batch adversarial loss: 0.515884\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371545; batch adversarial loss: 0.579473\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399116; batch adversarial loss: 0.463537\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386089; batch adversarial loss: 0.605518\n",
      "epoch 91; iter: 0; batch classifier loss: 0.323764; batch adversarial loss: 0.514915\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377411; batch adversarial loss: 0.560767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.344707; batch adversarial loss: 0.521382\n",
      "epoch 94; iter: 0; batch classifier loss: 0.352975; batch adversarial loss: 0.528643\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344146; batch adversarial loss: 0.607813\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377183; batch adversarial loss: 0.487042\n",
      "epoch 97; iter: 0; batch classifier loss: 0.419527; batch adversarial loss: 0.645906\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402596; batch adversarial loss: 0.482429\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355334; batch adversarial loss: 0.500064\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348507; batch adversarial loss: 0.627207\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399436; batch adversarial loss: 0.572437\n",
      "epoch 102; iter: 0; batch classifier loss: 0.352141; batch adversarial loss: 0.617029\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390276; batch adversarial loss: 0.553427\n",
      "epoch 104; iter: 0; batch classifier loss: 0.435580; batch adversarial loss: 0.606153\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378276; batch adversarial loss: 0.447381\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370289; batch adversarial loss: 0.533625\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352429; batch adversarial loss: 0.504607\n",
      "epoch 108; iter: 0; batch classifier loss: 0.296068; batch adversarial loss: 0.508997\n",
      "epoch 109; iter: 0; batch classifier loss: 0.433922; batch adversarial loss: 0.470562\n",
      "epoch 110; iter: 0; batch classifier loss: 0.345032; batch adversarial loss: 0.498813\n",
      "epoch 111; iter: 0; batch classifier loss: 0.422521; batch adversarial loss: 0.474502\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384368; batch adversarial loss: 0.537374\n",
      "epoch 113; iter: 0; batch classifier loss: 0.288992; batch adversarial loss: 0.507751\n",
      "epoch 114; iter: 0; batch classifier loss: 0.315956; batch adversarial loss: 0.606809\n",
      "epoch 115; iter: 0; batch classifier loss: 0.486492; batch adversarial loss: 0.494339\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393824; batch adversarial loss: 0.471660\n",
      "epoch 117; iter: 0; batch classifier loss: 0.328608; batch adversarial loss: 0.498649\n",
      "epoch 118; iter: 0; batch classifier loss: 0.435386; batch adversarial loss: 0.497192\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363137; batch adversarial loss: 0.535531\n",
      "epoch 120; iter: 0; batch classifier loss: 0.301240; batch adversarial loss: 0.623639\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398971; batch adversarial loss: 0.556042\n",
      "epoch 122; iter: 0; batch classifier loss: 0.357473; batch adversarial loss: 0.544536\n",
      "epoch 123; iter: 0; batch classifier loss: 0.344220; batch adversarial loss: 0.489172\n",
      "epoch 124; iter: 0; batch classifier loss: 0.475057; batch adversarial loss: 0.628466\n",
      "epoch 125; iter: 0; batch classifier loss: 0.312240; batch adversarial loss: 0.571681\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395871; batch adversarial loss: 0.524378\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334824; batch adversarial loss: 0.499820\n",
      "epoch 128; iter: 0; batch classifier loss: 0.333305; batch adversarial loss: 0.559570\n",
      "epoch 129; iter: 0; batch classifier loss: 0.297478; batch adversarial loss: 0.543312\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322105; batch adversarial loss: 0.633435\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382956; batch adversarial loss: 0.577359\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352363; batch adversarial loss: 0.599639\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352090; batch adversarial loss: 0.637690\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371570; batch adversarial loss: 0.560846\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424417; batch adversarial loss: 0.513252\n",
      "epoch 136; iter: 0; batch classifier loss: 0.446690; batch adversarial loss: 0.630395\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329496; batch adversarial loss: 0.566545\n",
      "epoch 138; iter: 0; batch classifier loss: 0.451879; batch adversarial loss: 0.588259\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401514; batch adversarial loss: 0.571110\n",
      "epoch 140; iter: 0; batch classifier loss: 0.436900; batch adversarial loss: 0.584728\n",
      "epoch 141; iter: 0; batch classifier loss: 0.385269; batch adversarial loss: 0.519921\n",
      "epoch 142; iter: 0; batch classifier loss: 0.456897; batch adversarial loss: 0.583234\n",
      "epoch 143; iter: 0; batch classifier loss: 0.409447; batch adversarial loss: 0.622831\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342163; batch adversarial loss: 0.550223\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355288; batch adversarial loss: 0.601416\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332006; batch adversarial loss: 0.569631\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340413; batch adversarial loss: 0.550971\n",
      "epoch 148; iter: 0; batch classifier loss: 0.283960; batch adversarial loss: 0.522796\n",
      "epoch 149; iter: 0; batch classifier loss: 0.330296; batch adversarial loss: 0.546795\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382666; batch adversarial loss: 0.536075\n",
      "epoch 151; iter: 0; batch classifier loss: 0.309538; batch adversarial loss: 0.550468\n",
      "epoch 152; iter: 0; batch classifier loss: 0.327879; batch adversarial loss: 0.654121\n",
      "epoch 153; iter: 0; batch classifier loss: 0.326563; batch adversarial loss: 0.528551\n",
      "epoch 154; iter: 0; batch classifier loss: 0.331832; batch adversarial loss: 0.593904\n",
      "epoch 155; iter: 0; batch classifier loss: 0.439004; batch adversarial loss: 0.496348\n",
      "epoch 156; iter: 0; batch classifier loss: 0.304344; batch adversarial loss: 0.496258\n",
      "epoch 157; iter: 0; batch classifier loss: 0.355045; batch adversarial loss: 0.566790\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355480; batch adversarial loss: 0.533574\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354121; batch adversarial loss: 0.435528\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335164; batch adversarial loss: 0.555492\n",
      "epoch 161; iter: 0; batch classifier loss: 0.401123; batch adversarial loss: 0.485435\n",
      "epoch 162; iter: 0; batch classifier loss: 0.413356; batch adversarial loss: 0.534837\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328290; batch adversarial loss: 0.507985\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385588; batch adversarial loss: 0.616543\n",
      "epoch 165; iter: 0; batch classifier loss: 0.425994; batch adversarial loss: 0.564224\n",
      "epoch 166; iter: 0; batch classifier loss: 0.436420; batch adversarial loss: 0.528081\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302407; batch adversarial loss: 0.491769\n",
      "epoch 168; iter: 0; batch classifier loss: 0.429940; batch adversarial loss: 0.598163\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384369; batch adversarial loss: 0.582318\n",
      "epoch 170; iter: 0; batch classifier loss: 0.314939; batch adversarial loss: 0.618368\n",
      "epoch 171; iter: 0; batch classifier loss: 0.422477; batch adversarial loss: 0.562393\n",
      "epoch 172; iter: 0; batch classifier loss: 0.296402; batch adversarial loss: 0.531744\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345616; batch adversarial loss: 0.561724\n",
      "epoch 174; iter: 0; batch classifier loss: 0.303469; batch adversarial loss: 0.602236\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388396; batch adversarial loss: 0.624743\n",
      "epoch 176; iter: 0; batch classifier loss: 0.312918; batch adversarial loss: 0.571984\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391821; batch adversarial loss: 0.589570\n",
      "epoch 178; iter: 0; batch classifier loss: 0.270676; batch adversarial loss: 0.491145\n",
      "epoch 179; iter: 0; batch classifier loss: 0.424941; batch adversarial loss: 0.524344\n",
      "epoch 180; iter: 0; batch classifier loss: 0.306977; batch adversarial loss: 0.545554\n",
      "epoch 181; iter: 0; batch classifier loss: 0.348416; batch adversarial loss: 0.529323\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333394; batch adversarial loss: 0.563829\n",
      "epoch 183; iter: 0; batch classifier loss: 0.286611; batch adversarial loss: 0.536734\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342890; batch adversarial loss: 0.538014\n",
      "epoch 185; iter: 0; batch classifier loss: 0.399593; batch adversarial loss: 0.506620\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359977; batch adversarial loss: 0.578808\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371119; batch adversarial loss: 0.535266\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396173; batch adversarial loss: 0.653094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.363582; batch adversarial loss: 0.550837\n",
      "epoch 190; iter: 0; batch classifier loss: 0.310412; batch adversarial loss: 0.526640\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366438; batch adversarial loss: 0.532217\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376308; batch adversarial loss: 0.534507\n",
      "epoch 193; iter: 0; batch classifier loss: 0.355324; batch adversarial loss: 0.551497\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362630; batch adversarial loss: 0.515750\n",
      "epoch 195; iter: 0; batch classifier loss: 0.401200; batch adversarial loss: 0.542691\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338830; batch adversarial loss: 0.612948\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322953; batch adversarial loss: 0.516593\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333404; batch adversarial loss: 0.483417\n",
      "epoch 199; iter: 0; batch classifier loss: 0.376437; batch adversarial loss: 0.535118\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699001; batch adversarial loss: 0.599920\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556291; batch adversarial loss: 0.621590\n",
      "epoch 2; iter: 0; batch classifier loss: 0.584849; batch adversarial loss: 0.654006\n",
      "epoch 3; iter: 0; batch classifier loss: 0.632270; batch adversarial loss: 0.656033\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553489; batch adversarial loss: 0.625866\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564688; batch adversarial loss: 0.580302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590126; batch adversarial loss: 0.620163\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588139; batch adversarial loss: 0.607731\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546704; batch adversarial loss: 0.608202\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520780; batch adversarial loss: 0.581316\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542017; batch adversarial loss: 0.551828\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517275; batch adversarial loss: 0.578562\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509322; batch adversarial loss: 0.567223\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473641; batch adversarial loss: 0.561647\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489507; batch adversarial loss: 0.581309\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539202; batch adversarial loss: 0.556829\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550204; batch adversarial loss: 0.540998\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491705; batch adversarial loss: 0.580645\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515508; batch adversarial loss: 0.584811\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523038; batch adversarial loss: 0.506943\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525756; batch adversarial loss: 0.556136\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520041; batch adversarial loss: 0.583834\n",
      "epoch 22; iter: 0; batch classifier loss: 0.510400; batch adversarial loss: 0.583588\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457002; batch adversarial loss: 0.617412\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481323; batch adversarial loss: 0.539426\n",
      "epoch 25; iter: 0; batch classifier loss: 0.507259; batch adversarial loss: 0.555002\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520686; batch adversarial loss: 0.563282\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487309; batch adversarial loss: 0.492433\n",
      "epoch 28; iter: 0; batch classifier loss: 0.597883; batch adversarial loss: 0.502839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.518115; batch adversarial loss: 0.537683\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478992; batch adversarial loss: 0.580916\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438211; batch adversarial loss: 0.489334\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497898; batch adversarial loss: 0.454325\n",
      "epoch 33; iter: 0; batch classifier loss: 0.470370; batch adversarial loss: 0.552801\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447505; batch adversarial loss: 0.526253\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455365; batch adversarial loss: 0.598134\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470418; batch adversarial loss: 0.555970\n",
      "epoch 37; iter: 0; batch classifier loss: 0.411523; batch adversarial loss: 0.580338\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442922; batch adversarial loss: 0.562806\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433194; batch adversarial loss: 0.545329\n",
      "epoch 40; iter: 0; batch classifier loss: 0.555487; batch adversarial loss: 0.470024\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461870; batch adversarial loss: 0.572427\n",
      "epoch 42; iter: 0; batch classifier loss: 0.394118; batch adversarial loss: 0.573008\n",
      "epoch 43; iter: 0; batch classifier loss: 0.342244; batch adversarial loss: 0.582141\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447169; batch adversarial loss: 0.525647\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442502; batch adversarial loss: 0.544628\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445462; batch adversarial loss: 0.478994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435845; batch adversarial loss: 0.544123\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430069; batch adversarial loss: 0.535000\n",
      "epoch 49; iter: 0; batch classifier loss: 0.499211; batch adversarial loss: 0.580058\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415479; batch adversarial loss: 0.506439\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434252; batch adversarial loss: 0.479466\n",
      "epoch 52; iter: 0; batch classifier loss: 0.463621; batch adversarial loss: 0.609162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402282; batch adversarial loss: 0.563938\n",
      "epoch 54; iter: 0; batch classifier loss: 0.403854; batch adversarial loss: 0.631389\n",
      "epoch 55; iter: 0; batch classifier loss: 0.380456; batch adversarial loss: 0.535168\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447317; batch adversarial loss: 0.544948\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393820; batch adversarial loss: 0.516039\n",
      "epoch 58; iter: 0; batch classifier loss: 0.531643; batch adversarial loss: 0.524884\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420618; batch adversarial loss: 0.543976\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442473; batch adversarial loss: 0.505662\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467427; batch adversarial loss: 0.545312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382917; batch adversarial loss: 0.506660\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415156; batch adversarial loss: 0.485969\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438256; batch adversarial loss: 0.524738\n",
      "epoch 65; iter: 0; batch classifier loss: 0.373657; batch adversarial loss: 0.553187\n",
      "epoch 66; iter: 0; batch classifier loss: 0.383631; batch adversarial loss: 0.488507\n",
      "epoch 67; iter: 0; batch classifier loss: 0.321988; batch adversarial loss: 0.535687\n",
      "epoch 68; iter: 0; batch classifier loss: 0.353216; batch adversarial loss: 0.590584\n",
      "epoch 69; iter: 0; batch classifier loss: 0.460388; batch adversarial loss: 0.535402\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455419; batch adversarial loss: 0.544908\n",
      "epoch 71; iter: 0; batch classifier loss: 0.424721; batch adversarial loss: 0.628962\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414577; batch adversarial loss: 0.524807\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424724; batch adversarial loss: 0.619568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367119; batch adversarial loss: 0.582141\n",
      "epoch 75; iter: 0; batch classifier loss: 0.494139; batch adversarial loss: 0.496907\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408250; batch adversarial loss: 0.573606\n",
      "epoch 77; iter: 0; batch classifier loss: 0.353485; batch adversarial loss: 0.507062\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406385; batch adversarial loss: 0.621166\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368514; batch adversarial loss: 0.507125\n",
      "epoch 80; iter: 0; batch classifier loss: 0.484924; batch adversarial loss: 0.620594\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429260; batch adversarial loss: 0.524753\n",
      "epoch 82; iter: 0; batch classifier loss: 0.444645; batch adversarial loss: 0.592087\n",
      "epoch 83; iter: 0; batch classifier loss: 0.418616; batch adversarial loss: 0.562433\n",
      "epoch 84; iter: 0; batch classifier loss: 0.515202; batch adversarial loss: 0.497367\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350176; batch adversarial loss: 0.526257\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374003; batch adversarial loss: 0.458934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.435219; batch adversarial loss: 0.459052\n",
      "epoch 88; iter: 0; batch classifier loss: 0.407741; batch adversarial loss: 0.564467\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387362; batch adversarial loss: 0.545300\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463697; batch adversarial loss: 0.553775\n",
      "epoch 91; iter: 0; batch classifier loss: 0.508381; batch adversarial loss: 0.553624\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392060; batch adversarial loss: 0.515014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363237; batch adversarial loss: 0.496617\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336718; batch adversarial loss: 0.602227\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415946; batch adversarial loss: 0.486422\n",
      "epoch 96; iter: 0; batch classifier loss: 0.440421; batch adversarial loss: 0.534456\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378949; batch adversarial loss: 0.556114\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385486; batch adversarial loss: 0.515570\n",
      "epoch 99; iter: 0; batch classifier loss: 0.452093; batch adversarial loss: 0.637090\n",
      "epoch 100; iter: 0; batch classifier loss: 0.369432; batch adversarial loss: 0.533876\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411537; batch adversarial loss: 0.534422\n",
      "epoch 102; iter: 0; batch classifier loss: 0.435331; batch adversarial loss: 0.488044\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429124; batch adversarial loss: 0.515376\n",
      "epoch 104; iter: 0; batch classifier loss: 0.357156; batch adversarial loss: 0.572637\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413492; batch adversarial loss: 0.506240\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366464; batch adversarial loss: 0.584081\n",
      "epoch 107; iter: 0; batch classifier loss: 0.314487; batch adversarial loss: 0.561961\n",
      "epoch 108; iter: 0; batch classifier loss: 0.457073; batch adversarial loss: 0.525398\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358053; batch adversarial loss: 0.544079\n",
      "epoch 110; iter: 0; batch classifier loss: 0.374277; batch adversarial loss: 0.506952\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389340; batch adversarial loss: 0.591384\n",
      "epoch 112; iter: 0; batch classifier loss: 0.309884; batch adversarial loss: 0.571941\n",
      "epoch 113; iter: 0; batch classifier loss: 0.330587; batch adversarial loss: 0.506594\n",
      "epoch 114; iter: 0; batch classifier loss: 0.293939; batch adversarial loss: 0.591332\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394085; batch adversarial loss: 0.508400\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393798; batch adversarial loss: 0.498835\n",
      "epoch 117; iter: 0; batch classifier loss: 0.443245; batch adversarial loss: 0.536079\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366685; batch adversarial loss: 0.572615\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364800; batch adversarial loss: 0.515842\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354226; batch adversarial loss: 0.505537\n",
      "epoch 121; iter: 0; batch classifier loss: 0.359219; batch adversarial loss: 0.648588\n",
      "epoch 122; iter: 0; batch classifier loss: 0.317873; batch adversarial loss: 0.648814\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389565; batch adversarial loss: 0.460394\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346354; batch adversarial loss: 0.468439\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390560; batch adversarial loss: 0.545206\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351885; batch adversarial loss: 0.544270\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367851; batch adversarial loss: 0.469439\n",
      "epoch 128; iter: 0; batch classifier loss: 0.386622; batch adversarial loss: 0.525873\n",
      "epoch 129; iter: 0; batch classifier loss: 0.408826; batch adversarial loss: 0.593278\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413558; batch adversarial loss: 0.535594\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407568; batch adversarial loss: 0.535876\n",
      "epoch 132; iter: 0; batch classifier loss: 0.462785; batch adversarial loss: 0.440051\n",
      "epoch 133; iter: 0; batch classifier loss: 0.414371; batch adversarial loss: 0.534835\n",
      "epoch 134; iter: 0; batch classifier loss: 0.313205; batch adversarial loss: 0.478987\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363370; batch adversarial loss: 0.495178\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360455; batch adversarial loss: 0.506327\n",
      "epoch 137; iter: 0; batch classifier loss: 0.373582; batch adversarial loss: 0.601411\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376255; batch adversarial loss: 0.534361\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368697; batch adversarial loss: 0.468915\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413815; batch adversarial loss: 0.562333\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328331; batch adversarial loss: 0.599924\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326322; batch adversarial loss: 0.582531\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397788; batch adversarial loss: 0.610535\n",
      "epoch 144; iter: 0; batch classifier loss: 0.310768; batch adversarial loss: 0.536172\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346518; batch adversarial loss: 0.600874\n",
      "epoch 146; iter: 0; batch classifier loss: 0.335113; batch adversarial loss: 0.536363\n",
      "epoch 147; iter: 0; batch classifier loss: 0.370066; batch adversarial loss: 0.507318\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373245; batch adversarial loss: 0.534751\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315246; batch adversarial loss: 0.545203\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413300; batch adversarial loss: 0.506542\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341314; batch adversarial loss: 0.554143\n",
      "epoch 152; iter: 0; batch classifier loss: 0.467445; batch adversarial loss: 0.562969\n",
      "epoch 153; iter: 0; batch classifier loss: 0.410867; batch adversarial loss: 0.535264\n",
      "epoch 154; iter: 0; batch classifier loss: 0.383476; batch adversarial loss: 0.535478\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380139; batch adversarial loss: 0.430470\n",
      "epoch 156; iter: 0; batch classifier loss: 0.412790; batch adversarial loss: 0.573518\n",
      "epoch 157; iter: 0; batch classifier loss: 0.358986; batch adversarial loss: 0.571983\n",
      "epoch 158; iter: 0; batch classifier loss: 0.399013; batch adversarial loss: 0.573612\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370692; batch adversarial loss: 0.573581\n",
      "epoch 160; iter: 0; batch classifier loss: 0.415209; batch adversarial loss: 0.497362\n",
      "epoch 161; iter: 0; batch classifier loss: 0.398073; batch adversarial loss: 0.544060\n",
      "epoch 162; iter: 0; batch classifier loss: 0.279184; batch adversarial loss: 0.504760\n",
      "epoch 163; iter: 0; batch classifier loss: 0.398871; batch adversarial loss: 0.486870\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346897; batch adversarial loss: 0.516451\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339030; batch adversarial loss: 0.582316\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333517; batch adversarial loss: 0.486086\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302092; batch adversarial loss: 0.517274\n",
      "epoch 168; iter: 0; batch classifier loss: 0.350470; batch adversarial loss: 0.516360\n",
      "epoch 169; iter: 0; batch classifier loss: 0.348985; batch adversarial loss: 0.571886\n",
      "epoch 170; iter: 0; batch classifier loss: 0.303677; batch adversarial loss: 0.533785\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351942; batch adversarial loss: 0.544525\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359228; batch adversarial loss: 0.554561\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362569; batch adversarial loss: 0.507470\n",
      "epoch 174; iter: 0; batch classifier loss: 0.428448; batch adversarial loss: 0.486689\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392248; batch adversarial loss: 0.449612\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381955; batch adversarial loss: 0.525776\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318545; batch adversarial loss: 0.552655\n",
      "epoch 178; iter: 0; batch classifier loss: 0.310013; batch adversarial loss: 0.449844\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349334; batch adversarial loss: 0.507890\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359633; batch adversarial loss: 0.584110\n",
      "epoch 181; iter: 0; batch classifier loss: 0.348451; batch adversarial loss: 0.581431\n",
      "epoch 182; iter: 0; batch classifier loss: 0.304946; batch adversarial loss: 0.489619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.425137; batch adversarial loss: 0.514829\n",
      "epoch 184; iter: 0; batch classifier loss: 0.400690; batch adversarial loss: 0.507856\n",
      "epoch 185; iter: 0; batch classifier loss: 0.422148; batch adversarial loss: 0.525761\n",
      "epoch 186; iter: 0; batch classifier loss: 0.420864; batch adversarial loss: 0.553542\n",
      "epoch 187; iter: 0; batch classifier loss: 0.354119; batch adversarial loss: 0.440335\n",
      "epoch 188; iter: 0; batch classifier loss: 0.400071; batch adversarial loss: 0.582893\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378565; batch adversarial loss: 0.543808\n",
      "epoch 190; iter: 0; batch classifier loss: 0.381281; batch adversarial loss: 0.553141\n",
      "epoch 191; iter: 0; batch classifier loss: 0.410197; batch adversarial loss: 0.553095\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305759; batch adversarial loss: 0.524639\n",
      "epoch 193; iter: 0; batch classifier loss: 0.425228; batch adversarial loss: 0.555333\n",
      "epoch 194; iter: 0; batch classifier loss: 0.355730; batch adversarial loss: 0.554889\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332662; batch adversarial loss: 0.478122\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314343; batch adversarial loss: 0.496291\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345004; batch adversarial loss: 0.428986\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368905; batch adversarial loss: 0.458210\n",
      "epoch 199; iter: 0; batch classifier loss: 0.369454; batch adversarial loss: 0.486870\n",
      "epoch 0; iter: 0; batch classifier loss: 0.743230; batch adversarial loss: 0.645741\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583454; batch adversarial loss: 0.637945\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603315; batch adversarial loss: 0.624414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.647979; batch adversarial loss: 0.628730\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519475; batch adversarial loss: 0.624953\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511928; batch adversarial loss: 0.598210\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541135; batch adversarial loss: 0.598251\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532883; batch adversarial loss: 0.596417\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484139; batch adversarial loss: 0.609833\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610444; batch adversarial loss: 0.584948\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570890; batch adversarial loss: 0.567512\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503611; batch adversarial loss: 0.571121\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549426; batch adversarial loss: 0.554592\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448326; batch adversarial loss: 0.548271\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560471; batch adversarial loss: 0.515245\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488942; batch adversarial loss: 0.513466\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485816; batch adversarial loss: 0.610496\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504997; batch adversarial loss: 0.538854\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519283; batch adversarial loss: 0.568335\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504672; batch adversarial loss: 0.511335\n",
      "epoch 20; iter: 0; batch classifier loss: 0.455514; batch adversarial loss: 0.575379\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480246; batch adversarial loss: 0.572955\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458295; batch adversarial loss: 0.533903\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455186; batch adversarial loss: 0.540365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.472903; batch adversarial loss: 0.547014\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478031; batch adversarial loss: 0.538777\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451040; batch adversarial loss: 0.478164\n",
      "epoch 27; iter: 0; batch classifier loss: 0.497460; batch adversarial loss: 0.613717\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477854; batch adversarial loss: 0.536649\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405110; batch adversarial loss: 0.527663\n",
      "epoch 30; iter: 0; batch classifier loss: 0.494458; batch adversarial loss: 0.625288\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438325; batch adversarial loss: 0.490205\n",
      "epoch 32; iter: 0; batch classifier loss: 0.502429; batch adversarial loss: 0.544073\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421473; batch adversarial loss: 0.562961\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425007; batch adversarial loss: 0.572027\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424630; batch adversarial loss: 0.498346\n",
      "epoch 36; iter: 0; batch classifier loss: 0.399440; batch adversarial loss: 0.498055\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443115; batch adversarial loss: 0.535190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438705; batch adversarial loss: 0.497699\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435615; batch adversarial loss: 0.506745\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465454; batch adversarial loss: 0.488001\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429431; batch adversarial loss: 0.516242\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425974; batch adversarial loss: 0.629527\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440144; batch adversarial loss: 0.590405\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439784; batch adversarial loss: 0.554377\n",
      "epoch 45; iter: 0; batch classifier loss: 0.350145; batch adversarial loss: 0.610976\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406399; batch adversarial loss: 0.600907\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469354; batch adversarial loss: 0.515208\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426254; batch adversarial loss: 0.505565\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392579; batch adversarial loss: 0.517295\n",
      "epoch 50; iter: 0; batch classifier loss: 0.370780; batch adversarial loss: 0.563090\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421670; batch adversarial loss: 0.488268\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386488; batch adversarial loss: 0.525766\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445140; batch adversarial loss: 0.554423\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418642; batch adversarial loss: 0.564035\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384438; batch adversarial loss: 0.507128\n",
      "epoch 56; iter: 0; batch classifier loss: 0.382065; batch adversarial loss: 0.525222\n",
      "epoch 57; iter: 0; batch classifier loss: 0.460155; batch adversarial loss: 0.571666\n",
      "epoch 58; iter: 0; batch classifier loss: 0.379103; batch adversarial loss: 0.592045\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399850; batch adversarial loss: 0.535340\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456381; batch adversarial loss: 0.534508\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408811; batch adversarial loss: 0.507046\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394417; batch adversarial loss: 0.487975\n",
      "epoch 63; iter: 0; batch classifier loss: 0.362796; batch adversarial loss: 0.525949\n",
      "epoch 64; iter: 0; batch classifier loss: 0.340438; batch adversarial loss: 0.527248\n",
      "epoch 65; iter: 0; batch classifier loss: 0.474674; batch adversarial loss: 0.507975\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411683; batch adversarial loss: 0.517127\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403074; batch adversarial loss: 0.525470\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386003; batch adversarial loss: 0.496583\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402452; batch adversarial loss: 0.556029\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409371; batch adversarial loss: 0.507680\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471808; batch adversarial loss: 0.599584\n",
      "epoch 72; iter: 0; batch classifier loss: 0.406714; batch adversarial loss: 0.619325\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355455; batch adversarial loss: 0.580883\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396079; batch adversarial loss: 0.533580\n",
      "epoch 75; iter: 0; batch classifier loss: 0.445573; batch adversarial loss: 0.508315\n",
      "epoch 76; iter: 0; batch classifier loss: 0.338385; batch adversarial loss: 0.502921\n",
      "epoch 77; iter: 0; batch classifier loss: 0.456936; batch adversarial loss: 0.572744\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427575; batch adversarial loss: 0.506345\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389844; batch adversarial loss: 0.557125\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365028; batch adversarial loss: 0.563302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.404146; batch adversarial loss: 0.601794\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365668; batch adversarial loss: 0.498692\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385193; batch adversarial loss: 0.575289\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429328; batch adversarial loss: 0.573892\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387674; batch adversarial loss: 0.554653\n",
      "epoch 86; iter: 0; batch classifier loss: 0.375588; batch adversarial loss: 0.600640\n",
      "epoch 87; iter: 0; batch classifier loss: 0.341406; batch adversarial loss: 0.624448\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397960; batch adversarial loss: 0.574092\n",
      "epoch 89; iter: 0; batch classifier loss: 0.343471; batch adversarial loss: 0.543100\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370329; batch adversarial loss: 0.555822\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412367; batch adversarial loss: 0.515380\n",
      "epoch 92; iter: 0; batch classifier loss: 0.283696; batch adversarial loss: 0.524778\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410359; batch adversarial loss: 0.507339\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374522; batch adversarial loss: 0.591863\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422174; batch adversarial loss: 0.486704\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377075; batch adversarial loss: 0.611895\n",
      "epoch 97; iter: 0; batch classifier loss: 0.311605; batch adversarial loss: 0.485283\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358148; batch adversarial loss: 0.535059\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369964; batch adversarial loss: 0.561402\n",
      "epoch 100; iter: 0; batch classifier loss: 0.337346; batch adversarial loss: 0.545964\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362244; batch adversarial loss: 0.498187\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365994; batch adversarial loss: 0.572229\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382063; batch adversarial loss: 0.552590\n",
      "epoch 104; iter: 0; batch classifier loss: 0.436780; batch adversarial loss: 0.487117\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358854; batch adversarial loss: 0.544166\n",
      "epoch 106; iter: 0; batch classifier loss: 0.418105; batch adversarial loss: 0.507475\n",
      "epoch 107; iter: 0; batch classifier loss: 0.383275; batch adversarial loss: 0.554582\n",
      "epoch 108; iter: 0; batch classifier loss: 0.376821; batch adversarial loss: 0.585640\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401662; batch adversarial loss: 0.497063\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382581; batch adversarial loss: 0.536039\n",
      "epoch 111; iter: 0; batch classifier loss: 0.352699; batch adversarial loss: 0.563691\n",
      "epoch 112; iter: 0; batch classifier loss: 0.302083; batch adversarial loss: 0.569570\n",
      "epoch 113; iter: 0; batch classifier loss: 0.416289; batch adversarial loss: 0.507516\n",
      "epoch 114; iter: 0; batch classifier loss: 0.414827; batch adversarial loss: 0.521841\n",
      "epoch 115; iter: 0; batch classifier loss: 0.338338; batch adversarial loss: 0.497381\n",
      "epoch 116; iter: 0; batch classifier loss: 0.280845; batch adversarial loss: 0.546379\n",
      "epoch 117; iter: 0; batch classifier loss: 0.413794; batch adversarial loss: 0.495700\n",
      "epoch 118; iter: 0; batch classifier loss: 0.320538; batch adversarial loss: 0.494366\n",
      "epoch 119; iter: 0; batch classifier loss: 0.459265; batch adversarial loss: 0.550585\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369389; batch adversarial loss: 0.502550\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406451; batch adversarial loss: 0.505200\n",
      "epoch 122; iter: 0; batch classifier loss: 0.334289; batch adversarial loss: 0.484053\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369483; batch adversarial loss: 0.544481\n",
      "epoch 124; iter: 0; batch classifier loss: 0.364697; batch adversarial loss: 0.514058\n",
      "epoch 125; iter: 0; batch classifier loss: 0.430510; batch adversarial loss: 0.534131\n",
      "epoch 126; iter: 0; batch classifier loss: 0.309748; batch adversarial loss: 0.538359\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397793; batch adversarial loss: 0.497440\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402331; batch adversarial loss: 0.526872\n",
      "epoch 129; iter: 0; batch classifier loss: 0.431430; batch adversarial loss: 0.495839\n",
      "epoch 130; iter: 0; batch classifier loss: 0.315155; batch adversarial loss: 0.537238\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339027; batch adversarial loss: 0.660616\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347852; batch adversarial loss: 0.517014\n",
      "epoch 133; iter: 0; batch classifier loss: 0.418833; batch adversarial loss: 0.554498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350522; batch adversarial loss: 0.534959\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387796; batch adversarial loss: 0.612393\n",
      "epoch 136; iter: 0; batch classifier loss: 0.388295; batch adversarial loss: 0.563704\n",
      "epoch 137; iter: 0; batch classifier loss: 0.293896; batch adversarial loss: 0.562442\n",
      "epoch 138; iter: 0; batch classifier loss: 0.321252; batch adversarial loss: 0.562901\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338576; batch adversarial loss: 0.601556\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357187; batch adversarial loss: 0.459536\n",
      "epoch 141; iter: 0; batch classifier loss: 0.374832; batch adversarial loss: 0.579294\n",
      "epoch 142; iter: 0; batch classifier loss: 0.434509; batch adversarial loss: 0.505247\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413860; batch adversarial loss: 0.614215\n",
      "epoch 144; iter: 0; batch classifier loss: 0.420126; batch adversarial loss: 0.554831\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323346; batch adversarial loss: 0.507321\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331171; batch adversarial loss: 0.555541\n",
      "epoch 147; iter: 0; batch classifier loss: 0.301373; batch adversarial loss: 0.594960\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354424; batch adversarial loss: 0.584413\n",
      "epoch 149; iter: 0; batch classifier loss: 0.338403; batch adversarial loss: 0.543819\n",
      "epoch 150; iter: 0; batch classifier loss: 0.328860; batch adversarial loss: 0.535400\n",
      "epoch 151; iter: 0; batch classifier loss: 0.308259; batch adversarial loss: 0.562413\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346126; batch adversarial loss: 0.562456\n",
      "epoch 153; iter: 0; batch classifier loss: 0.301098; batch adversarial loss: 0.575823\n",
      "epoch 154; iter: 0; batch classifier loss: 0.309021; batch adversarial loss: 0.523646\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392953; batch adversarial loss: 0.535256\n",
      "epoch 156; iter: 0; batch classifier loss: 0.353725; batch adversarial loss: 0.534991\n",
      "epoch 157; iter: 0; batch classifier loss: 0.307018; batch adversarial loss: 0.516276\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373591; batch adversarial loss: 0.566261\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316415; batch adversarial loss: 0.582203\n",
      "epoch 160; iter: 0; batch classifier loss: 0.437448; batch adversarial loss: 0.524643\n",
      "epoch 161; iter: 0; batch classifier loss: 0.405074; batch adversarial loss: 0.592421\n",
      "epoch 162; iter: 0; batch classifier loss: 0.402670; batch adversarial loss: 0.506673\n",
      "epoch 163; iter: 0; batch classifier loss: 0.368510; batch adversarial loss: 0.535787\n",
      "epoch 164; iter: 0; batch classifier loss: 0.325970; batch adversarial loss: 0.485983\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326822; batch adversarial loss: 0.466641\n",
      "epoch 166; iter: 0; batch classifier loss: 0.423025; batch adversarial loss: 0.534645\n",
      "epoch 167; iter: 0; batch classifier loss: 0.375941; batch adversarial loss: 0.533172\n",
      "epoch 168; iter: 0; batch classifier loss: 0.309671; batch adversarial loss: 0.573217\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344980; batch adversarial loss: 0.565178\n",
      "epoch 170; iter: 0; batch classifier loss: 0.480743; batch adversarial loss: 0.515196\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327351; batch adversarial loss: 0.591289\n",
      "epoch 172; iter: 0; batch classifier loss: 0.425322; batch adversarial loss: 0.594610\n",
      "epoch 173; iter: 0; batch classifier loss: 0.379474; batch adversarial loss: 0.618555\n",
      "epoch 174; iter: 0; batch classifier loss: 0.450768; batch adversarial loss: 0.590029\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366469; batch adversarial loss: 0.506673\n",
      "epoch 176; iter: 0; batch classifier loss: 0.326203; batch adversarial loss: 0.532941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.427691; batch adversarial loss: 0.537010\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336222; batch adversarial loss: 0.601419\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367588; batch adversarial loss: 0.496736\n",
      "epoch 180; iter: 0; batch classifier loss: 0.361542; batch adversarial loss: 0.513965\n",
      "epoch 181; iter: 0; batch classifier loss: 0.324186; batch adversarial loss: 0.515362\n",
      "epoch 182; iter: 0; batch classifier loss: 0.407479; batch adversarial loss: 0.526133\n",
      "epoch 183; iter: 0; batch classifier loss: 0.280905; batch adversarial loss: 0.518939\n",
      "epoch 184; iter: 0; batch classifier loss: 0.245410; batch adversarial loss: 0.561338\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333672; batch adversarial loss: 0.526596\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323207; batch adversarial loss: 0.542066\n",
      "epoch 187; iter: 0; batch classifier loss: 0.308947; batch adversarial loss: 0.630514\n",
      "epoch 188; iter: 0; batch classifier loss: 0.437119; batch adversarial loss: 0.487676\n",
      "epoch 189; iter: 0; batch classifier loss: 0.410690; batch adversarial loss: 0.612916\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326138; batch adversarial loss: 0.485940\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357413; batch adversarial loss: 0.500162\n",
      "epoch 192; iter: 0; batch classifier loss: 0.369343; batch adversarial loss: 0.516438\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336847; batch adversarial loss: 0.486987\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335011; batch adversarial loss: 0.469395\n",
      "epoch 195; iter: 0; batch classifier loss: 0.419608; batch adversarial loss: 0.535024\n",
      "epoch 196; iter: 0; batch classifier loss: 0.405371; batch adversarial loss: 0.525639\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350233; batch adversarial loss: 0.572970\n",
      "epoch 198; iter: 0; batch classifier loss: 0.415632; batch adversarial loss: 0.545359\n",
      "epoch 199; iter: 0; batch classifier loss: 0.402181; batch adversarial loss: 0.476772\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713054; batch adversarial loss: 0.951802\n",
      "epoch 1; iter: 0; batch classifier loss: 0.988614; batch adversarial loss: 1.573949\n",
      "epoch 2; iter: 0; batch classifier loss: 1.089161; batch adversarial loss: 1.432657\n",
      "epoch 3; iter: 0; batch classifier loss: 1.180676; batch adversarial loss: 1.338783\n",
      "epoch 4; iter: 0; batch classifier loss: 1.155429; batch adversarial loss: 1.246529\n",
      "epoch 5; iter: 0; batch classifier loss: 1.267057; batch adversarial loss: 1.153687\n",
      "epoch 6; iter: 0; batch classifier loss: 1.290977; batch adversarial loss: 1.074449\n",
      "epoch 7; iter: 0; batch classifier loss: 1.111413; batch adversarial loss: 0.979191\n",
      "epoch 8; iter: 0; batch classifier loss: 1.175293; batch adversarial loss: 0.911536\n",
      "epoch 9; iter: 0; batch classifier loss: 1.142948; batch adversarial loss: 0.857187\n",
      "epoch 10; iter: 0; batch classifier loss: 1.288320; batch adversarial loss: 0.808526\n",
      "epoch 11; iter: 0; batch classifier loss: 1.075207; batch adversarial loss: 0.751054\n",
      "epoch 12; iter: 0; batch classifier loss: 1.164613; batch adversarial loss: 0.725927\n",
      "epoch 13; iter: 0; batch classifier loss: 1.030978; batch adversarial loss: 0.694229\n",
      "epoch 14; iter: 0; batch classifier loss: 1.213431; batch adversarial loss: 0.645726\n",
      "epoch 15; iter: 0; batch classifier loss: 0.953104; batch adversarial loss: 0.605927\n",
      "epoch 16; iter: 0; batch classifier loss: 0.788710; batch adversarial loss: 0.586087\n",
      "epoch 17; iter: 0; batch classifier loss: 0.583607; batch adversarial loss: 0.602690\n",
      "epoch 18; iter: 0; batch classifier loss: 0.581415; batch adversarial loss: 0.583407\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518697; batch adversarial loss: 0.541391\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513888; batch adversarial loss: 0.548476\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501887; batch adversarial loss: 0.529605\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506286; batch adversarial loss: 0.532155\n",
      "epoch 23; iter: 0; batch classifier loss: 0.565549; batch adversarial loss: 0.576603\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501949; batch adversarial loss: 0.586032\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515689; batch adversarial loss: 0.495597\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471294; batch adversarial loss: 0.550614\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513964; batch adversarial loss: 0.547749\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523642; batch adversarial loss: 0.569583\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464594; batch adversarial loss: 0.566518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466164; batch adversarial loss: 0.614917\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458730; batch adversarial loss: 0.532039\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472989; batch adversarial loss: 0.534061\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457385; batch adversarial loss: 0.600004\n",
      "epoch 34; iter: 0; batch classifier loss: 0.444698; batch adversarial loss: 0.536223\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465646; batch adversarial loss: 0.551673\n",
      "epoch 36; iter: 0; batch classifier loss: 0.521040; batch adversarial loss: 0.520682\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461539; batch adversarial loss: 0.545482\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412462; batch adversarial loss: 0.575028\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478127; batch adversarial loss: 0.551902\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383440; batch adversarial loss: 0.546398\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458375; batch adversarial loss: 0.552661\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418032; batch adversarial loss: 0.546000\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478087; batch adversarial loss: 0.586186\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457901; batch adversarial loss: 0.472211\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408567; batch adversarial loss: 0.537643\n",
      "epoch 46; iter: 0; batch classifier loss: 0.399584; batch adversarial loss: 0.524134\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439909; batch adversarial loss: 0.510697\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450157; batch adversarial loss: 0.550716\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440007; batch adversarial loss: 0.491137\n",
      "epoch 50; iter: 0; batch classifier loss: 0.375811; batch adversarial loss: 0.553016\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409999; batch adversarial loss: 0.527130\n",
      "epoch 52; iter: 0; batch classifier loss: 0.491211; batch adversarial loss: 0.533792\n",
      "epoch 53; iter: 0; batch classifier loss: 0.349427; batch adversarial loss: 0.538558\n",
      "epoch 54; iter: 0; batch classifier loss: 0.458461; batch adversarial loss: 0.509339\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404028; batch adversarial loss: 0.472402\n",
      "epoch 56; iter: 0; batch classifier loss: 0.370232; batch adversarial loss: 0.566016\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412659; batch adversarial loss: 0.499584\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414273; batch adversarial loss: 0.505278\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425467; batch adversarial loss: 0.583679\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390559; batch adversarial loss: 0.703885\n",
      "epoch 61; iter: 0; batch classifier loss: 0.324021; batch adversarial loss: 0.525133\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421048; batch adversarial loss: 0.515319\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429368; batch adversarial loss: 0.440403\n",
      "epoch 64; iter: 0; batch classifier loss: 0.416289; batch adversarial loss: 0.555468\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426343; batch adversarial loss: 0.525084\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422910; batch adversarial loss: 0.553377\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360896; batch adversarial loss: 0.572678\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389173; batch adversarial loss: 0.543892\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403208; batch adversarial loss: 0.506131\n",
      "epoch 70; iter: 0; batch classifier loss: 0.357987; batch adversarial loss: 0.553526\n",
      "epoch 71; iter: 0; batch classifier loss: 0.356235; batch adversarial loss: 0.535951\n",
      "epoch 72; iter: 0; batch classifier loss: 0.395747; batch adversarial loss: 0.478329\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403366; batch adversarial loss: 0.555696\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378963; batch adversarial loss: 0.534906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.385103; batch adversarial loss: 0.581013\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416559; batch adversarial loss: 0.485282\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387076; batch adversarial loss: 0.534600\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389435; batch adversarial loss: 0.543164\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379675; batch adversarial loss: 0.503118\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371871; batch adversarial loss: 0.554188\n",
      "epoch 81; iter: 0; batch classifier loss: 0.330476; batch adversarial loss: 0.524702\n",
      "epoch 82; iter: 0; batch classifier loss: 0.450683; batch adversarial loss: 0.519225\n",
      "epoch 83; iter: 0; batch classifier loss: 0.456680; batch adversarial loss: 0.623318\n",
      "epoch 84; iter: 0; batch classifier loss: 0.351646; batch adversarial loss: 0.639386\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391293; batch adversarial loss: 0.559178\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368902; batch adversarial loss: 0.595533\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345357; batch adversarial loss: 0.552145\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396837; batch adversarial loss: 0.597602\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353173; batch adversarial loss: 0.525892\n",
      "epoch 90; iter: 0; batch classifier loss: 0.335868; batch adversarial loss: 0.490586\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410091; batch adversarial loss: 0.536878\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406015; batch adversarial loss: 0.577645\n",
      "epoch 93; iter: 0; batch classifier loss: 0.309222; batch adversarial loss: 0.592388\n",
      "epoch 94; iter: 0; batch classifier loss: 0.299661; batch adversarial loss: 0.516127\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364762; batch adversarial loss: 0.562955\n",
      "epoch 96; iter: 0; batch classifier loss: 0.312758; batch adversarial loss: 0.497798\n",
      "epoch 97; iter: 0; batch classifier loss: 0.438148; batch adversarial loss: 0.555041\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339174; batch adversarial loss: 0.526496\n",
      "epoch 99; iter: 0; batch classifier loss: 0.459807; batch adversarial loss: 0.478109\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398297; batch adversarial loss: 0.527159\n",
      "epoch 101; iter: 0; batch classifier loss: 0.340989; batch adversarial loss: 0.525919\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407228; batch adversarial loss: 0.459805\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360954; batch adversarial loss: 0.581913\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369607; batch adversarial loss: 0.516005\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355850; batch adversarial loss: 0.552805\n",
      "epoch 106; iter: 0; batch classifier loss: 0.311799; batch adversarial loss: 0.468818\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371299; batch adversarial loss: 0.467860\n",
      "epoch 108; iter: 0; batch classifier loss: 0.341271; batch adversarial loss: 0.574425\n",
      "epoch 109; iter: 0; batch classifier loss: 0.311885; batch adversarial loss: 0.497150\n",
      "epoch 110; iter: 0; batch classifier loss: 0.448856; batch adversarial loss: 0.430382\n",
      "epoch 111; iter: 0; batch classifier loss: 0.364593; batch adversarial loss: 0.603258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.324172; batch adversarial loss: 0.496974\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381115; batch adversarial loss: 0.535262\n",
      "epoch 114; iter: 0; batch classifier loss: 0.313707; batch adversarial loss: 0.526258\n",
      "epoch 115; iter: 0; batch classifier loss: 0.351011; batch adversarial loss: 0.602767\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392828; batch adversarial loss: 0.447548\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393392; batch adversarial loss: 0.602007\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340830; batch adversarial loss: 0.534850\n",
      "epoch 119; iter: 0; batch classifier loss: 0.412431; batch adversarial loss: 0.505061\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346433; batch adversarial loss: 0.600838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351502; batch adversarial loss: 0.515547\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404599; batch adversarial loss: 0.611286\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359740; batch adversarial loss: 0.630743\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353631; batch adversarial loss: 0.554484\n",
      "epoch 125; iter: 0; batch classifier loss: 0.307943; batch adversarial loss: 0.505050\n",
      "epoch 126; iter: 0; batch classifier loss: 0.294401; batch adversarial loss: 0.563506\n",
      "epoch 127; iter: 0; batch classifier loss: 0.359728; batch adversarial loss: 0.507478\n",
      "epoch 128; iter: 0; batch classifier loss: 0.293146; batch adversarial loss: 0.488934\n",
      "epoch 129; iter: 0; batch classifier loss: 0.285688; batch adversarial loss: 0.537710\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358905; batch adversarial loss: 0.601074\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347320; batch adversarial loss: 0.581330\n",
      "epoch 132; iter: 0; batch classifier loss: 0.337766; batch adversarial loss: 0.564561\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336410; batch adversarial loss: 0.584806\n",
      "epoch 134; iter: 0; batch classifier loss: 0.345831; batch adversarial loss: 0.486056\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336852; batch adversarial loss: 0.534296\n",
      "epoch 136; iter: 0; batch classifier loss: 0.347648; batch adversarial loss: 0.495906\n",
      "epoch 137; iter: 0; batch classifier loss: 0.291059; batch adversarial loss: 0.440272\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318274; batch adversarial loss: 0.486948\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371631; batch adversarial loss: 0.479995\n",
      "epoch 140; iter: 0; batch classifier loss: 0.275970; batch adversarial loss: 0.466164\n",
      "epoch 141; iter: 0; batch classifier loss: 0.417773; batch adversarial loss: 0.600554\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331282; batch adversarial loss: 0.592850\n",
      "epoch 143; iter: 0; batch classifier loss: 0.263455; batch adversarial loss: 0.538023\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348608; batch adversarial loss: 0.564193\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347869; batch adversarial loss: 0.573812\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332366; batch adversarial loss: 0.544393\n",
      "epoch 147; iter: 0; batch classifier loss: 0.408242; batch adversarial loss: 0.572782\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337837; batch adversarial loss: 0.555995\n",
      "epoch 149; iter: 0; batch classifier loss: 0.358922; batch adversarial loss: 0.582640\n",
      "epoch 150; iter: 0; batch classifier loss: 0.357000; batch adversarial loss: 0.525135\n",
      "epoch 151; iter: 0; batch classifier loss: 0.288345; batch adversarial loss: 0.562867\n",
      "epoch 152; iter: 0; batch classifier loss: 0.282177; batch adversarial loss: 0.516031\n",
      "epoch 153; iter: 0; batch classifier loss: 0.290161; batch adversarial loss: 0.553231\n",
      "epoch 154; iter: 0; batch classifier loss: 0.327002; batch adversarial loss: 0.526700\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364873; batch adversarial loss: 0.524669\n",
      "epoch 156; iter: 0; batch classifier loss: 0.294170; batch adversarial loss: 0.564667\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313132; batch adversarial loss: 0.506317\n",
      "epoch 158; iter: 0; batch classifier loss: 0.281476; batch adversarial loss: 0.543414\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337576; batch adversarial loss: 0.609275\n",
      "epoch 160; iter: 0; batch classifier loss: 0.312628; batch adversarial loss: 0.506454\n",
      "epoch 161; iter: 0; batch classifier loss: 0.313855; batch adversarial loss: 0.497856\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325626; batch adversarial loss: 0.562528\n",
      "epoch 163; iter: 0; batch classifier loss: 0.312284; batch adversarial loss: 0.628776\n",
      "epoch 164; iter: 0; batch classifier loss: 0.260711; batch adversarial loss: 0.573429\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342445; batch adversarial loss: 0.459201\n",
      "epoch 166; iter: 0; batch classifier loss: 0.277247; batch adversarial loss: 0.591972\n",
      "epoch 167; iter: 0; batch classifier loss: 0.288474; batch adversarial loss: 0.581349\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318600; batch adversarial loss: 0.514737\n",
      "epoch 169; iter: 0; batch classifier loss: 0.295189; batch adversarial loss: 0.535158\n",
      "epoch 170; iter: 0; batch classifier loss: 0.284981; batch adversarial loss: 0.564108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.438559; batch adversarial loss: 0.555081\n",
      "epoch 172; iter: 0; batch classifier loss: 0.286316; batch adversarial loss: 0.504554\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339130; batch adversarial loss: 0.477425\n",
      "epoch 174; iter: 0; batch classifier loss: 0.301929; batch adversarial loss: 0.506638\n",
      "epoch 175; iter: 0; batch classifier loss: 0.285995; batch adversarial loss: 0.535740\n",
      "epoch 176; iter: 0; batch classifier loss: 0.261092; batch adversarial loss: 0.391096\n",
      "epoch 177; iter: 0; batch classifier loss: 0.353551; batch adversarial loss: 0.659039\n",
      "epoch 178; iter: 0; batch classifier loss: 0.403807; batch adversarial loss: 0.534679\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366904; batch adversarial loss: 0.524844\n",
      "epoch 180; iter: 0; batch classifier loss: 0.310252; batch adversarial loss: 0.611870\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311811; batch adversarial loss: 0.602741\n",
      "epoch 182; iter: 0; batch classifier loss: 0.315723; batch adversarial loss: 0.565012\n",
      "epoch 183; iter: 0; batch classifier loss: 0.302273; batch adversarial loss: 0.552935\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309665; batch adversarial loss: 0.629033\n",
      "epoch 185; iter: 0; batch classifier loss: 0.302353; batch adversarial loss: 0.460082\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348842; batch adversarial loss: 0.505140\n",
      "epoch 187; iter: 0; batch classifier loss: 0.323314; batch adversarial loss: 0.450039\n",
      "epoch 188; iter: 0; batch classifier loss: 0.253369; batch adversarial loss: 0.487000\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297209; batch adversarial loss: 0.467991\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360848; batch adversarial loss: 0.477961\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381448; batch adversarial loss: 0.593559\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315924; batch adversarial loss: 0.525591\n",
      "epoch 193; iter: 0; batch classifier loss: 0.265799; batch adversarial loss: 0.498673\n",
      "epoch 194; iter: 0; batch classifier loss: 0.334752; batch adversarial loss: 0.516665\n",
      "epoch 195; iter: 0; batch classifier loss: 0.295400; batch adversarial loss: 0.575076\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316027; batch adversarial loss: 0.594248\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364032; batch adversarial loss: 0.496801\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329462; batch adversarial loss: 0.537269\n",
      "epoch 199; iter: 0; batch classifier loss: 0.257343; batch adversarial loss: 0.534536\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689696; batch adversarial loss: 0.645670\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584570; batch adversarial loss: 0.638709\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547924; batch adversarial loss: 0.654180\n",
      "epoch 3; iter: 0; batch classifier loss: 0.500354; batch adversarial loss: 0.616635\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548107; batch adversarial loss: 0.623917\n",
      "epoch 5; iter: 0; batch classifier loss: 0.632254; batch adversarial loss: 0.607532\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592669; batch adversarial loss: 0.615122\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512398; batch adversarial loss: 0.624540\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579658; batch adversarial loss: 0.576176\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540559; batch adversarial loss: 0.585864\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556503; batch adversarial loss: 0.560729\n",
      "epoch 11; iter: 0; batch classifier loss: 0.513388; batch adversarial loss: 0.530255\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562934; batch adversarial loss: 0.550391\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544181; batch adversarial loss: 0.603165\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438497; batch adversarial loss: 0.509547\n",
      "epoch 15; iter: 0; batch classifier loss: 0.653834; batch adversarial loss: 0.544784\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497059; batch adversarial loss: 0.550310\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535063; batch adversarial loss: 0.546943\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539024; batch adversarial loss: 0.603579\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545949; batch adversarial loss: 0.529068\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538593; batch adversarial loss: 0.585698\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503906; batch adversarial loss: 0.541296\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483530; batch adversarial loss: 0.573942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.469333; batch adversarial loss: 0.513564\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477546; batch adversarial loss: 0.494683\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504172; batch adversarial loss: 0.571738\n",
      "epoch 26; iter: 0; batch classifier loss: 0.404066; batch adversarial loss: 0.580273\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483075; batch adversarial loss: 0.589166\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512196; batch adversarial loss: 0.578826\n",
      "epoch 29; iter: 0; batch classifier loss: 0.533278; batch adversarial loss: 0.528285\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455066; batch adversarial loss: 0.527337\n",
      "epoch 31; iter: 0; batch classifier loss: 0.580172; batch adversarial loss: 0.640797\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506986; batch adversarial loss: 0.580004\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458380; batch adversarial loss: 0.544921\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494672; batch adversarial loss: 0.509296\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397443; batch adversarial loss: 0.536058\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405835; batch adversarial loss: 0.526742\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477669; batch adversarial loss: 0.518278\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446743; batch adversarial loss: 0.490626\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455931; batch adversarial loss: 0.552569\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492454; batch adversarial loss: 0.554975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.365729; batch adversarial loss: 0.561618\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423639; batch adversarial loss: 0.552985\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484022; batch adversarial loss: 0.534426\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408474; batch adversarial loss: 0.481715\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516633; batch adversarial loss: 0.589816\n",
      "epoch 46; iter: 0; batch classifier loss: 0.517025; batch adversarial loss: 0.525925\n",
      "epoch 47; iter: 0; batch classifier loss: 0.387832; batch adversarial loss: 0.611122\n",
      "epoch 48; iter: 0; batch classifier loss: 0.304877; batch adversarial loss: 0.522107\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432553; batch adversarial loss: 0.528549\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434581; batch adversarial loss: 0.467176\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384292; batch adversarial loss: 0.495247\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449478; batch adversarial loss: 0.501278\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439754; batch adversarial loss: 0.557999\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445012; batch adversarial loss: 0.435533\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440327; batch adversarial loss: 0.527023\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448151; batch adversarial loss: 0.515264\n",
      "epoch 57; iter: 0; batch classifier loss: 0.327412; batch adversarial loss: 0.572458\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435494; batch adversarial loss: 0.591978\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440298; batch adversarial loss: 0.514873\n",
      "epoch 60; iter: 0; batch classifier loss: 0.399336; batch adversarial loss: 0.516290\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432850; batch adversarial loss: 0.536571\n",
      "epoch 62; iter: 0; batch classifier loss: 0.420381; batch adversarial loss: 0.581841\n",
      "epoch 63; iter: 0; batch classifier loss: 0.407323; batch adversarial loss: 0.519060\n",
      "epoch 64; iter: 0; batch classifier loss: 0.416071; batch adversarial loss: 0.518864\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409512; batch adversarial loss: 0.506920\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381860; batch adversarial loss: 0.582160\n",
      "epoch 67; iter: 0; batch classifier loss: 0.376978; batch adversarial loss: 0.543621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.457238; batch adversarial loss: 0.591248\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428560; batch adversarial loss: 0.572834\n",
      "epoch 70; iter: 0; batch classifier loss: 0.371875; batch adversarial loss: 0.524349\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395776; batch adversarial loss: 0.480869\n",
      "epoch 72; iter: 0; batch classifier loss: 0.421132; batch adversarial loss: 0.526363\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378754; batch adversarial loss: 0.591104\n",
      "epoch 74; iter: 0; batch classifier loss: 0.360521; batch adversarial loss: 0.535319\n",
      "epoch 75; iter: 0; batch classifier loss: 0.512105; batch adversarial loss: 0.554092\n",
      "epoch 76; iter: 0; batch classifier loss: 0.354549; batch adversarial loss: 0.581215\n",
      "epoch 77; iter: 0; batch classifier loss: 0.366980; batch adversarial loss: 0.542918\n",
      "epoch 78; iter: 0; batch classifier loss: 0.361465; batch adversarial loss: 0.561148\n",
      "epoch 79; iter: 0; batch classifier loss: 0.458427; batch adversarial loss: 0.517715\n",
      "epoch 80; iter: 0; batch classifier loss: 0.327322; batch adversarial loss: 0.553807\n",
      "epoch 81; iter: 0; batch classifier loss: 0.364759; batch adversarial loss: 0.572605\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376933; batch adversarial loss: 0.554440\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376037; batch adversarial loss: 0.552958\n",
      "epoch 84; iter: 0; batch classifier loss: 0.379048; batch adversarial loss: 0.571309\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404896; batch adversarial loss: 0.599610\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371432; batch adversarial loss: 0.526205\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401544; batch adversarial loss: 0.524140\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391694; batch adversarial loss: 0.599349\n",
      "epoch 89; iter: 0; batch classifier loss: 0.474682; batch adversarial loss: 0.570989\n",
      "epoch 90; iter: 0; batch classifier loss: 0.360714; batch adversarial loss: 0.568545\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367715; batch adversarial loss: 0.620734\n",
      "epoch 92; iter: 0; batch classifier loss: 0.445212; batch adversarial loss: 0.640439\n",
      "epoch 93; iter: 0; batch classifier loss: 0.478655; batch adversarial loss: 0.562762\n",
      "epoch 94; iter: 0; batch classifier loss: 0.399224; batch adversarial loss: 0.567606\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379883; batch adversarial loss: 0.488554\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402658; batch adversarial loss: 0.488978\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401093; batch adversarial loss: 0.479587\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375519; batch adversarial loss: 0.488497\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375092; batch adversarial loss: 0.516647\n",
      "epoch 100; iter: 0; batch classifier loss: 0.480856; batch adversarial loss: 0.600094\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426676; batch adversarial loss: 0.571837\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386960; batch adversarial loss: 0.499767\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377151; batch adversarial loss: 0.609339\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358724; batch adversarial loss: 0.516575\n",
      "epoch 105; iter: 0; batch classifier loss: 0.434230; batch adversarial loss: 0.526069\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374922; batch adversarial loss: 0.517558\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405603; batch adversarial loss: 0.516354\n",
      "epoch 108; iter: 0; batch classifier loss: 0.414069; batch adversarial loss: 0.524650\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363782; batch adversarial loss: 0.487474\n",
      "epoch 110; iter: 0; batch classifier loss: 0.400452; batch adversarial loss: 0.534678\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376880; batch adversarial loss: 0.600674\n",
      "epoch 112; iter: 0; batch classifier loss: 0.466780; batch adversarial loss: 0.535634\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394314; batch adversarial loss: 0.561953\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428324; batch adversarial loss: 0.582027\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419840; batch adversarial loss: 0.571893\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375170; batch adversarial loss: 0.618377\n",
      "epoch 117; iter: 0; batch classifier loss: 0.430734; batch adversarial loss: 0.470881\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340235; batch adversarial loss: 0.572401\n",
      "epoch 119; iter: 0; batch classifier loss: 0.441256; batch adversarial loss: 0.479733\n",
      "epoch 120; iter: 0; batch classifier loss: 0.397407; batch adversarial loss: 0.517339\n",
      "epoch 121; iter: 0; batch classifier loss: 0.405259; batch adversarial loss: 0.573137\n",
      "epoch 122; iter: 0; batch classifier loss: 0.427356; batch adversarial loss: 0.542584\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352308; batch adversarial loss: 0.588030\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386840; batch adversarial loss: 0.581380\n",
      "epoch 125; iter: 0; batch classifier loss: 0.420856; batch adversarial loss: 0.599189\n",
      "epoch 126; iter: 0; batch classifier loss: 0.438907; batch adversarial loss: 0.562807\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377023; batch adversarial loss: 0.653966\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418314; batch adversarial loss: 0.498944\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389482; batch adversarial loss: 0.553084\n",
      "epoch 130; iter: 0; batch classifier loss: 0.432838; batch adversarial loss: 0.591251\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336027; batch adversarial loss: 0.462055\n",
      "epoch 132; iter: 0; batch classifier loss: 0.393385; batch adversarial loss: 0.526926\n",
      "epoch 133; iter: 0; batch classifier loss: 0.298257; batch adversarial loss: 0.574145\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401877; batch adversarial loss: 0.534383\n",
      "epoch 135; iter: 0; batch classifier loss: 0.419173; batch adversarial loss: 0.597637\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360214; batch adversarial loss: 0.579488\n",
      "epoch 137; iter: 0; batch classifier loss: 0.395170; batch adversarial loss: 0.541451\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368948; batch adversarial loss: 0.569053\n",
      "epoch 139; iter: 0; batch classifier loss: 0.391335; batch adversarial loss: 0.514273\n",
      "epoch 140; iter: 0; batch classifier loss: 0.372100; batch adversarial loss: 0.590520\n",
      "epoch 141; iter: 0; batch classifier loss: 0.410339; batch adversarial loss: 0.518792\n",
      "epoch 142; iter: 0; batch classifier loss: 0.307397; batch adversarial loss: 0.559068\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350329; batch adversarial loss: 0.486129\n",
      "epoch 144; iter: 0; batch classifier loss: 0.432577; batch adversarial loss: 0.628764\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363530; batch adversarial loss: 0.451593\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349251; batch adversarial loss: 0.547961\n",
      "epoch 147; iter: 0; batch classifier loss: 0.408738; batch adversarial loss: 0.517423\n",
      "epoch 148; iter: 0; batch classifier loss: 0.380776; batch adversarial loss: 0.552920\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375376; batch adversarial loss: 0.460584\n",
      "epoch 150; iter: 0; batch classifier loss: 0.454332; batch adversarial loss: 0.553965\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337161; batch adversarial loss: 0.534696\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360937; batch adversarial loss: 0.469862\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385903; batch adversarial loss: 0.534969\n",
      "epoch 154; iter: 0; batch classifier loss: 0.406155; batch adversarial loss: 0.571750\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419228; batch adversarial loss: 0.516065\n",
      "epoch 156; iter: 0; batch classifier loss: 0.386607; batch adversarial loss: 0.580848\n",
      "epoch 157; iter: 0; batch classifier loss: 0.481901; batch adversarial loss: 0.517054\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367510; batch adversarial loss: 0.571338\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344376; batch adversarial loss: 0.570541\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382904; batch adversarial loss: 0.497532\n",
      "epoch 161; iter: 0; batch classifier loss: 0.418537; batch adversarial loss: 0.607761\n",
      "epoch 162; iter: 0; batch classifier loss: 0.439494; batch adversarial loss: 0.595198\n",
      "epoch 163; iter: 0; batch classifier loss: 0.390047; batch adversarial loss: 0.533666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.380960; batch adversarial loss: 0.615658\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321226; batch adversarial loss: 0.561285\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353499; batch adversarial loss: 0.533767\n",
      "epoch 167; iter: 0; batch classifier loss: 0.469392; batch adversarial loss: 0.500368\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375991; batch adversarial loss: 0.499015\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380086; batch adversarial loss: 0.589602\n",
      "epoch 170; iter: 0; batch classifier loss: 0.454038; batch adversarial loss: 0.619200\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344774; batch adversarial loss: 0.610397\n",
      "epoch 172; iter: 0; batch classifier loss: 0.451087; batch adversarial loss: 0.572995\n",
      "epoch 173; iter: 0; batch classifier loss: 0.458808; batch adversarial loss: 0.563707\n",
      "epoch 174; iter: 0; batch classifier loss: 0.402863; batch adversarial loss: 0.610532\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313483; batch adversarial loss: 0.507028\n",
      "epoch 176; iter: 0; batch classifier loss: 0.312974; batch adversarial loss: 0.490384\n",
      "epoch 177; iter: 0; batch classifier loss: 0.323968; batch adversarial loss: 0.479851\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417578; batch adversarial loss: 0.536951\n",
      "epoch 179; iter: 0; batch classifier loss: 0.361293; batch adversarial loss: 0.599273\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360934; batch adversarial loss: 0.580763\n",
      "epoch 181; iter: 0; batch classifier loss: 0.396803; batch adversarial loss: 0.608516\n",
      "epoch 182; iter: 0; batch classifier loss: 0.328409; batch adversarial loss: 0.498401\n",
      "epoch 183; iter: 0; batch classifier loss: 0.428702; batch adversarial loss: 0.551657\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337398; batch adversarial loss: 0.535013\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366923; batch adversarial loss: 0.553313\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358305; batch adversarial loss: 0.610839\n",
      "epoch 187; iter: 0; batch classifier loss: 0.331278; batch adversarial loss: 0.608551\n",
      "epoch 188; iter: 0; batch classifier loss: 0.364796; batch adversarial loss: 0.542516\n",
      "epoch 189; iter: 0; batch classifier loss: 0.388722; batch adversarial loss: 0.535999\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331266; batch adversarial loss: 0.561306\n",
      "epoch 191; iter: 0; batch classifier loss: 0.317863; batch adversarial loss: 0.622928\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349194; batch adversarial loss: 0.526720\n",
      "epoch 193; iter: 0; batch classifier loss: 0.400606; batch adversarial loss: 0.645126\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304284; batch adversarial loss: 0.607370\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359672; batch adversarial loss: 0.617478\n",
      "epoch 196; iter: 0; batch classifier loss: 0.429037; batch adversarial loss: 0.517409\n",
      "epoch 197; iter: 0; batch classifier loss: 0.432825; batch adversarial loss: 0.518962\n",
      "epoch 198; iter: 0; batch classifier loss: 0.414055; batch adversarial loss: 0.545012\n",
      "epoch 199; iter: 0; batch classifier loss: 0.410813; batch adversarial loss: 0.596959\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706840; batch adversarial loss: 0.782565\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600443; batch adversarial loss: 0.718571\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600070; batch adversarial loss: 0.694163\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555718; batch adversarial loss: 0.644888\n",
      "epoch 4; iter: 0; batch classifier loss: 0.612651; batch adversarial loss: 0.651005\n",
      "epoch 5; iter: 0; batch classifier loss: 0.494516; batch adversarial loss: 0.634889\n",
      "epoch 6; iter: 0; batch classifier loss: 0.484835; batch adversarial loss: 0.648055\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543214; batch adversarial loss: 0.598238\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523245; batch adversarial loss: 0.601731\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493798; batch adversarial loss: 0.581876\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557114; batch adversarial loss: 0.605187\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531685; batch adversarial loss: 0.585029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.625062; batch adversarial loss: 0.563467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501102; batch adversarial loss: 0.617602\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531923; batch adversarial loss: 0.595179\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525174; batch adversarial loss: 0.539178\n",
      "epoch 16; iter: 0; batch classifier loss: 0.566025; batch adversarial loss: 0.616244\n",
      "epoch 17; iter: 0; batch classifier loss: 0.597184; batch adversarial loss: 0.631014\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523819; batch adversarial loss: 0.555304\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470088; batch adversarial loss: 0.577821\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509519; batch adversarial loss: 0.599715\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491579; batch adversarial loss: 0.536426\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466176; batch adversarial loss: 0.545507\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506246; batch adversarial loss: 0.615278\n",
      "epoch 24; iter: 0; batch classifier loss: 0.544237; batch adversarial loss: 0.577754\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478838; batch adversarial loss: 0.583115\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462463; batch adversarial loss: 0.537841\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493983; batch adversarial loss: 0.590534\n",
      "epoch 28; iter: 0; batch classifier loss: 0.385634; batch adversarial loss: 0.590595\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447717; batch adversarial loss: 0.572797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475475; batch adversarial loss: 0.549027\n",
      "epoch 31; iter: 0; batch classifier loss: 0.509280; batch adversarial loss: 0.580992\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478988; batch adversarial loss: 0.579782\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480266; batch adversarial loss: 0.580352\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494826; batch adversarial loss: 0.520727\n",
      "epoch 35; iter: 0; batch classifier loss: 0.495473; batch adversarial loss: 0.495135\n",
      "epoch 36; iter: 0; batch classifier loss: 0.509101; batch adversarial loss: 0.545726\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452408; batch adversarial loss: 0.587633\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418860; batch adversarial loss: 0.570071\n",
      "epoch 39; iter: 0; batch classifier loss: 0.519356; batch adversarial loss: 0.588835\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460745; batch adversarial loss: 0.598732\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460252; batch adversarial loss: 0.543529\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480335; batch adversarial loss: 0.607079\n",
      "epoch 43; iter: 0; batch classifier loss: 0.416021; batch adversarial loss: 0.581272\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483541; batch adversarial loss: 0.598552\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466571; batch adversarial loss: 0.616015\n",
      "epoch 46; iter: 0; batch classifier loss: 0.493545; batch adversarial loss: 0.572413\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417778; batch adversarial loss: 0.519991\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464117; batch adversarial loss: 0.527790\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466203; batch adversarial loss: 0.526880\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411605; batch adversarial loss: 0.527300\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464769; batch adversarial loss: 0.562785\n",
      "epoch 52; iter: 0; batch classifier loss: 0.355644; batch adversarial loss: 0.570932\n",
      "epoch 53; iter: 0; batch classifier loss: 0.453993; batch adversarial loss: 0.553717\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411320; batch adversarial loss: 0.518729\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396014; batch adversarial loss: 0.586068\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429102; batch adversarial loss: 0.452700\n",
      "epoch 57; iter: 0; batch classifier loss: 0.475203; batch adversarial loss: 0.601507\n",
      "epoch 58; iter: 0; batch classifier loss: 0.433016; batch adversarial loss: 0.491570\n",
      "epoch 59; iter: 0; batch classifier loss: 0.479363; batch adversarial loss: 0.561127\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391536; batch adversarial loss: 0.511476\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424028; batch adversarial loss: 0.439627\n",
      "epoch 62; iter: 0; batch classifier loss: 0.528821; batch adversarial loss: 0.556869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.393702; batch adversarial loss: 0.561312\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421029; batch adversarial loss: 0.571238\n",
      "epoch 65; iter: 0; batch classifier loss: 0.486810; batch adversarial loss: 0.641770\n",
      "epoch 66; iter: 0; batch classifier loss: 0.556545; batch adversarial loss: 0.484232\n",
      "epoch 67; iter: 0; batch classifier loss: 0.484715; batch adversarial loss: 0.553264\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418071; batch adversarial loss: 0.579992\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430988; batch adversarial loss: 0.581452\n",
      "epoch 70; iter: 0; batch classifier loss: 0.458914; batch adversarial loss: 0.527401\n",
      "epoch 71; iter: 0; batch classifier loss: 0.474669; batch adversarial loss: 0.581472\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412643; batch adversarial loss: 0.481941\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421234; batch adversarial loss: 0.515990\n",
      "epoch 74; iter: 0; batch classifier loss: 0.470183; batch adversarial loss: 0.589449\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426314; batch adversarial loss: 0.625433\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413659; batch adversarial loss: 0.572296\n",
      "epoch 77; iter: 0; batch classifier loss: 0.459329; batch adversarial loss: 0.552417\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409362; batch adversarial loss: 0.516235\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429023; batch adversarial loss: 0.562935\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432006; batch adversarial loss: 0.519374\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369272; batch adversarial loss: 0.564335\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447256; batch adversarial loss: 0.587397\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396751; batch adversarial loss: 0.700264\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380514; batch adversarial loss: 0.565174\n",
      "epoch 85; iter: 0; batch classifier loss: 0.463096; batch adversarial loss: 0.498320\n",
      "epoch 86; iter: 0; batch classifier loss: 0.449337; batch adversarial loss: 0.537313\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395900; batch adversarial loss: 0.579569\n",
      "epoch 88; iter: 0; batch classifier loss: 0.458820; batch adversarial loss: 0.597661\n",
      "epoch 89; iter: 0; batch classifier loss: 0.495415; batch adversarial loss: 0.553014\n",
      "epoch 90; iter: 0; batch classifier loss: 0.472331; batch adversarial loss: 0.518968\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402374; batch adversarial loss: 0.527119\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397161; batch adversarial loss: 0.500476\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363524; batch adversarial loss: 0.501048\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392374; batch adversarial loss: 0.523816\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422785; batch adversarial loss: 0.580313\n",
      "epoch 96; iter: 0; batch classifier loss: 0.424467; batch adversarial loss: 0.508221\n",
      "epoch 97; iter: 0; batch classifier loss: 0.389229; batch adversarial loss: 0.572300\n",
      "epoch 98; iter: 0; batch classifier loss: 0.420825; batch adversarial loss: 0.528072\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417067; batch adversarial loss: 0.606977\n",
      "epoch 100; iter: 0; batch classifier loss: 0.427690; batch adversarial loss: 0.527676\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415772; batch adversarial loss: 0.536379\n",
      "epoch 102; iter: 0; batch classifier loss: 0.425059; batch adversarial loss: 0.596788\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346650; batch adversarial loss: 0.616218\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389751; batch adversarial loss: 0.518036\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347292; batch adversarial loss: 0.552880\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366600; batch adversarial loss: 0.571770\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407392; batch adversarial loss: 0.581364\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369356; batch adversarial loss: 0.588442\n",
      "epoch 109; iter: 0; batch classifier loss: 0.399227; batch adversarial loss: 0.524999\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408145; batch adversarial loss: 0.535482\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416056; batch adversarial loss: 0.533658\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382009; batch adversarial loss: 0.580297\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401146; batch adversarial loss: 0.589559\n",
      "epoch 114; iter: 0; batch classifier loss: 0.348650; batch adversarial loss: 0.579741\n",
      "epoch 115; iter: 0; batch classifier loss: 0.369871; batch adversarial loss: 0.527000\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377089; batch adversarial loss: 0.570996\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392689; batch adversarial loss: 0.518220\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398701; batch adversarial loss: 0.562378\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353493; batch adversarial loss: 0.482581\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330216; batch adversarial loss: 0.562757\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369515; batch adversarial loss: 0.534970\n",
      "epoch 122; iter: 0; batch classifier loss: 0.439256; batch adversarial loss: 0.552704\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356650; batch adversarial loss: 0.553204\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404289; batch adversarial loss: 0.544721\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367107; batch adversarial loss: 0.553381\n",
      "epoch 126; iter: 0; batch classifier loss: 0.543296; batch adversarial loss: 0.581441\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408003; batch adversarial loss: 0.588717\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361024; batch adversarial loss: 0.552442\n",
      "epoch 129; iter: 0; batch classifier loss: 0.302988; batch adversarial loss: 0.506700\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395251; batch adversarial loss: 0.499315\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382531; batch adversarial loss: 0.544151\n",
      "epoch 132; iter: 0; batch classifier loss: 0.439534; batch adversarial loss: 0.588675\n",
      "epoch 133; iter: 0; batch classifier loss: 0.427040; batch adversarial loss: 0.569932\n",
      "epoch 134; iter: 0; batch classifier loss: 0.452715; batch adversarial loss: 0.527507\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413523; batch adversarial loss: 0.553469\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425244; batch adversarial loss: 0.545047\n",
      "epoch 137; iter: 0; batch classifier loss: 0.338084; batch adversarial loss: 0.509744\n",
      "epoch 138; iter: 0; batch classifier loss: 0.316026; batch adversarial loss: 0.509471\n",
      "epoch 139; iter: 0; batch classifier loss: 0.423451; batch adversarial loss: 0.491720\n",
      "epoch 140; iter: 0; batch classifier loss: 0.345185; batch adversarial loss: 0.553777\n",
      "epoch 141; iter: 0; batch classifier loss: 0.394759; batch adversarial loss: 0.519915\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400154; batch adversarial loss: 0.510170\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401657; batch adversarial loss: 0.562602\n",
      "epoch 144; iter: 0; batch classifier loss: 0.397010; batch adversarial loss: 0.465871\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387314; batch adversarial loss: 0.545174\n",
      "epoch 146; iter: 0; batch classifier loss: 0.412049; batch adversarial loss: 0.527351\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329145; batch adversarial loss: 0.553878\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395354; batch adversarial loss: 0.570861\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367723; batch adversarial loss: 0.482538\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385990; batch adversarial loss: 0.535370\n",
      "epoch 151; iter: 0; batch classifier loss: 0.444061; batch adversarial loss: 0.544849\n",
      "epoch 152; iter: 0; batch classifier loss: 0.429225; batch adversarial loss: 0.589087\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362643; batch adversarial loss: 0.508288\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384725; batch adversarial loss: 0.642531\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398352; batch adversarial loss: 0.581047\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396304; batch adversarial loss: 0.607675\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359172; batch adversarial loss: 0.517170\n",
      "epoch 158; iter: 0; batch classifier loss: 0.412797; batch adversarial loss: 0.561833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.402323; batch adversarial loss: 0.544570\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374171; batch adversarial loss: 0.499438\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410252; batch adversarial loss: 0.462673\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347659; batch adversarial loss: 0.598353\n",
      "epoch 163; iter: 0; batch classifier loss: 0.419064; batch adversarial loss: 0.579687\n",
      "epoch 164; iter: 0; batch classifier loss: 0.453085; batch adversarial loss: 0.659479\n",
      "epoch 165; iter: 0; batch classifier loss: 0.444631; batch adversarial loss: 0.577182\n",
      "epoch 166; iter: 0; batch classifier loss: 0.450293; batch adversarial loss: 0.501963\n",
      "epoch 167; iter: 0; batch classifier loss: 0.309582; batch adversarial loss: 0.544408\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401572; batch adversarial loss: 0.455185\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312121; batch adversarial loss: 0.614829\n",
      "epoch 170; iter: 0; batch classifier loss: 0.338999; batch adversarial loss: 0.509437\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369045; batch adversarial loss: 0.591072\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397026; batch adversarial loss: 0.445260\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292981; batch adversarial loss: 0.598226\n",
      "epoch 174; iter: 0; batch classifier loss: 0.409390; batch adversarial loss: 0.538219\n",
      "epoch 175; iter: 0; batch classifier loss: 0.266342; batch adversarial loss: 0.563366\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339195; batch adversarial loss: 0.572017\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372074; batch adversarial loss: 0.509185\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376801; batch adversarial loss: 0.600398\n",
      "epoch 179; iter: 0; batch classifier loss: 0.324245; batch adversarial loss: 0.535779\n",
      "epoch 180; iter: 0; batch classifier loss: 0.364635; batch adversarial loss: 0.572253\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355732; batch adversarial loss: 0.580277\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354068; batch adversarial loss: 0.625173\n",
      "epoch 183; iter: 0; batch classifier loss: 0.437210; batch adversarial loss: 0.535440\n",
      "epoch 184; iter: 0; batch classifier loss: 0.453334; batch adversarial loss: 0.482427\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355819; batch adversarial loss: 0.490478\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330375; batch adversarial loss: 0.473931\n",
      "epoch 187; iter: 0; batch classifier loss: 0.445089; batch adversarial loss: 0.562143\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368544; batch adversarial loss: 0.589286\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348490; batch adversarial loss: 0.697982\n",
      "epoch 190; iter: 0; batch classifier loss: 0.370058; batch adversarial loss: 0.534773\n",
      "epoch 191; iter: 0; batch classifier loss: 0.458087; batch adversarial loss: 0.534161\n",
      "epoch 192; iter: 0; batch classifier loss: 0.397098; batch adversarial loss: 0.562002\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333875; batch adversarial loss: 0.535976\n",
      "epoch 194; iter: 0; batch classifier loss: 0.305554; batch adversarial loss: 0.554743\n",
      "epoch 195; iter: 0; batch classifier loss: 0.436414; batch adversarial loss: 0.563373\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301396; batch adversarial loss: 0.572429\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390971; batch adversarial loss: 0.581664\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355506; batch adversarial loss: 0.508097\n",
      "epoch 199; iter: 0; batch classifier loss: 0.361690; batch adversarial loss: 0.552397\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682167; batch adversarial loss: 0.938286\n",
      "epoch 1; iter: 0; batch classifier loss: 0.870851; batch adversarial loss: 1.381328\n",
      "epoch 2; iter: 0; batch classifier loss: 1.104762; batch adversarial loss: 1.309921\n",
      "epoch 3; iter: 0; batch classifier loss: 1.156835; batch adversarial loss: 1.217059\n",
      "epoch 4; iter: 0; batch classifier loss: 1.014681; batch adversarial loss: 1.134373\n",
      "epoch 5; iter: 0; batch classifier loss: 1.117012; batch adversarial loss: 1.038373\n",
      "epoch 6; iter: 0; batch classifier loss: 1.121379; batch adversarial loss: 0.956595\n",
      "epoch 7; iter: 0; batch classifier loss: 1.035906; batch adversarial loss: 0.890788\n",
      "epoch 8; iter: 0; batch classifier loss: 0.951055; batch adversarial loss: 0.817100\n",
      "epoch 9; iter: 0; batch classifier loss: 0.915884; batch adversarial loss: 0.766133\n",
      "epoch 10; iter: 0; batch classifier loss: 0.830612; batch adversarial loss: 0.704598\n",
      "epoch 11; iter: 0; batch classifier loss: 0.775546; batch adversarial loss: 0.659867\n",
      "epoch 12; iter: 0; batch classifier loss: 0.603307; batch adversarial loss: 0.621637\n",
      "epoch 13; iter: 0; batch classifier loss: 0.572831; batch adversarial loss: 0.604716\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527151; batch adversarial loss: 0.601900\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544640; batch adversarial loss: 0.573442\n",
      "epoch 16; iter: 0; batch classifier loss: 0.570608; batch adversarial loss: 0.595514\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486793; batch adversarial loss: 0.562775\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507466; batch adversarial loss: 0.559288\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474316; batch adversarial loss: 0.569371\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494613; batch adversarial loss: 0.548100\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454640; batch adversarial loss: 0.583306\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515976; batch adversarial loss: 0.555022\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489670; batch adversarial loss: 0.583676\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485792; batch adversarial loss: 0.541995\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502680; batch adversarial loss: 0.504969\n",
      "epoch 26; iter: 0; batch classifier loss: 0.430920; batch adversarial loss: 0.523855\n",
      "epoch 27; iter: 0; batch classifier loss: 0.535373; batch adversarial loss: 0.532342\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450513; batch adversarial loss: 0.579365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497194; batch adversarial loss: 0.565464\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484646; batch adversarial loss: 0.560602\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470541; batch adversarial loss: 0.507675\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426218; batch adversarial loss: 0.589375\n",
      "epoch 33; iter: 0; batch classifier loss: 0.512975; batch adversarial loss: 0.505455\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421174; batch adversarial loss: 0.502247\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425196; batch adversarial loss: 0.579033\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473629; batch adversarial loss: 0.526628\n",
      "epoch 37; iter: 0; batch classifier loss: 0.533350; batch adversarial loss: 0.485283\n",
      "epoch 38; iter: 0; batch classifier loss: 0.548341; batch adversarial loss: 0.475643\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407696; batch adversarial loss: 0.509376\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429786; batch adversarial loss: 0.588504\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452039; batch adversarial loss: 0.481224\n",
      "epoch 42; iter: 0; batch classifier loss: 0.518824; batch adversarial loss: 0.517505\n",
      "epoch 43; iter: 0; batch classifier loss: 0.505357; batch adversarial loss: 0.554219\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458744; batch adversarial loss: 0.579223\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430017; batch adversarial loss: 0.601321\n",
      "epoch 46; iter: 0; batch classifier loss: 0.489520; batch adversarial loss: 0.535821\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478265; batch adversarial loss: 0.563772\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411865; batch adversarial loss: 0.599949\n",
      "epoch 49; iter: 0; batch classifier loss: 0.425931; batch adversarial loss: 0.496808\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410129; batch adversarial loss: 0.552377\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392378; batch adversarial loss: 0.544307\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404036; batch adversarial loss: 0.610318\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406198; batch adversarial loss: 0.590987\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439763; batch adversarial loss: 0.574423\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414889; batch adversarial loss: 0.554998\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440127; batch adversarial loss: 0.537107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.363853; batch adversarial loss: 0.563527\n",
      "epoch 58; iter: 0; batch classifier loss: 0.373423; batch adversarial loss: 0.552945\n",
      "epoch 59; iter: 0; batch classifier loss: 0.343217; batch adversarial loss: 0.572896\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456078; batch adversarial loss: 0.543429\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468930; batch adversarial loss: 0.514677\n",
      "epoch 62; iter: 0; batch classifier loss: 0.488502; batch adversarial loss: 0.543988\n",
      "epoch 63; iter: 0; batch classifier loss: 0.325435; batch adversarial loss: 0.506902\n",
      "epoch 64; iter: 0; batch classifier loss: 0.329072; batch adversarial loss: 0.609750\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416106; batch adversarial loss: 0.609998\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395090; batch adversarial loss: 0.516051\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426213; batch adversarial loss: 0.440521\n",
      "epoch 68; iter: 0; batch classifier loss: 0.365570; batch adversarial loss: 0.565079\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361830; batch adversarial loss: 0.544316\n",
      "epoch 70; iter: 0; batch classifier loss: 0.371394; batch adversarial loss: 0.524746\n",
      "epoch 71; iter: 0; batch classifier loss: 0.433243; batch adversarial loss: 0.621631\n",
      "epoch 72; iter: 0; batch classifier loss: 0.486913; batch adversarial loss: 0.574325\n",
      "epoch 73; iter: 0; batch classifier loss: 0.482234; batch adversarial loss: 0.524642\n",
      "epoch 74; iter: 0; batch classifier loss: 0.334336; batch adversarial loss: 0.585454\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416213; batch adversarial loss: 0.592099\n",
      "epoch 76; iter: 0; batch classifier loss: 0.425875; batch adversarial loss: 0.554950\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392039; batch adversarial loss: 0.497176\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415872; batch adversarial loss: 0.506458\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376811; batch adversarial loss: 0.458737\n",
      "epoch 80; iter: 0; batch classifier loss: 0.343435; batch adversarial loss: 0.518740\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371139; batch adversarial loss: 0.556283\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359863; batch adversarial loss: 0.508054\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356590; batch adversarial loss: 0.554982\n",
      "epoch 84; iter: 0; batch classifier loss: 0.317595; batch adversarial loss: 0.487780\n",
      "epoch 85; iter: 0; batch classifier loss: 0.352991; batch adversarial loss: 0.572173\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353194; batch adversarial loss: 0.516262\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364550; batch adversarial loss: 0.599787\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384347; batch adversarial loss: 0.515807\n",
      "epoch 89; iter: 0; batch classifier loss: 0.317184; batch adversarial loss: 0.600581\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463432; batch adversarial loss: 0.566054\n",
      "epoch 91; iter: 0; batch classifier loss: 0.302697; batch adversarial loss: 0.486476\n",
      "epoch 92; iter: 0; batch classifier loss: 0.369256; batch adversarial loss: 0.592989\n",
      "epoch 93; iter: 0; batch classifier loss: 0.343326; batch adversarial loss: 0.572648\n",
      "epoch 94; iter: 0; batch classifier loss: 0.366030; batch adversarial loss: 0.590724\n",
      "epoch 95; iter: 0; batch classifier loss: 0.313314; batch adversarial loss: 0.486995\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388879; batch adversarial loss: 0.526130\n",
      "epoch 97; iter: 0; batch classifier loss: 0.345046; batch adversarial loss: 0.488370\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395207; batch adversarial loss: 0.543191\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360242; batch adversarial loss: 0.611656\n",
      "epoch 100; iter: 0; batch classifier loss: 0.391109; batch adversarial loss: 0.505711\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413486; batch adversarial loss: 0.496139\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371143; batch adversarial loss: 0.519786\n",
      "epoch 103; iter: 0; batch classifier loss: 0.410828; batch adversarial loss: 0.526183\n",
      "epoch 104; iter: 0; batch classifier loss: 0.429905; batch adversarial loss: 0.545624\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382539; batch adversarial loss: 0.666549\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404631; batch adversarial loss: 0.534388\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393847; batch adversarial loss: 0.592335\n",
      "epoch 108; iter: 0; batch classifier loss: 0.338781; batch adversarial loss: 0.610384\n",
      "epoch 109; iter: 0; batch classifier loss: 0.333858; batch adversarial loss: 0.525829\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343088; batch adversarial loss: 0.517064\n",
      "epoch 111; iter: 0; batch classifier loss: 0.316948; batch adversarial loss: 0.504684\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381962; batch adversarial loss: 0.402480\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386854; batch adversarial loss: 0.526965\n",
      "epoch 114; iter: 0; batch classifier loss: 0.423687; batch adversarial loss: 0.571019\n",
      "epoch 115; iter: 0; batch classifier loss: 0.281039; batch adversarial loss: 0.506777\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319863; batch adversarial loss: 0.526028\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406907; batch adversarial loss: 0.516332\n",
      "epoch 118; iter: 0; batch classifier loss: 0.337417; batch adversarial loss: 0.619838\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349088; batch adversarial loss: 0.563427\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361966; batch adversarial loss: 0.535676\n",
      "epoch 121; iter: 0; batch classifier loss: 0.333631; batch adversarial loss: 0.487910\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326416; batch adversarial loss: 0.486932\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334349; batch adversarial loss: 0.441214\n",
      "epoch 124; iter: 0; batch classifier loss: 0.341267; batch adversarial loss: 0.517411\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370124; batch adversarial loss: 0.534532\n",
      "epoch 126; iter: 0; batch classifier loss: 0.411618; batch adversarial loss: 0.582983\n",
      "epoch 127; iter: 0; batch classifier loss: 0.336804; batch adversarial loss: 0.533815\n",
      "epoch 128; iter: 0; batch classifier loss: 0.306030; batch adversarial loss: 0.486777\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377518; batch adversarial loss: 0.459679\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386299; batch adversarial loss: 0.638619\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386324; batch adversarial loss: 0.525069\n",
      "epoch 132; iter: 0; batch classifier loss: 0.322003; batch adversarial loss: 0.516292\n",
      "epoch 133; iter: 0; batch classifier loss: 0.287003; batch adversarial loss: 0.591494\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386352; batch adversarial loss: 0.600835\n",
      "epoch 135; iter: 0; batch classifier loss: 0.367444; batch adversarial loss: 0.487787\n",
      "epoch 136; iter: 0; batch classifier loss: 0.379679; batch adversarial loss: 0.562361\n",
      "epoch 137; iter: 0; batch classifier loss: 0.291865; batch adversarial loss: 0.543421\n",
      "epoch 138; iter: 0; batch classifier loss: 0.294702; batch adversarial loss: 0.580530\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392323; batch adversarial loss: 0.593216\n",
      "epoch 140; iter: 0; batch classifier loss: 0.293077; batch adversarial loss: 0.610595\n",
      "epoch 141; iter: 0; batch classifier loss: 0.355363; batch adversarial loss: 0.582862\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330995; batch adversarial loss: 0.477387\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388767; batch adversarial loss: 0.496081\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340782; batch adversarial loss: 0.619530\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367675; batch adversarial loss: 0.459360\n",
      "epoch 146; iter: 0; batch classifier loss: 0.276679; batch adversarial loss: 0.504934\n",
      "epoch 147; iter: 0; batch classifier loss: 0.256173; batch adversarial loss: 0.525199\n",
      "epoch 148; iter: 0; batch classifier loss: 0.441817; batch adversarial loss: 0.465748\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323261; batch adversarial loss: 0.534729\n",
      "epoch 150; iter: 0; batch classifier loss: 0.249782; batch adversarial loss: 0.618844\n",
      "epoch 151; iter: 0; batch classifier loss: 0.293503; batch adversarial loss: 0.507453\n",
      "epoch 152; iter: 0; batch classifier loss: 0.312832; batch adversarial loss: 0.506615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.346748; batch adversarial loss: 0.534413\n",
      "epoch 154; iter: 0; batch classifier loss: 0.259179; batch adversarial loss: 0.506393\n",
      "epoch 155; iter: 0; batch classifier loss: 0.313509; batch adversarial loss: 0.515277\n",
      "epoch 156; iter: 0; batch classifier loss: 0.298128; batch adversarial loss: 0.440263\n",
      "epoch 157; iter: 0; batch classifier loss: 0.259958; batch adversarial loss: 0.479227\n",
      "epoch 158; iter: 0; batch classifier loss: 0.272140; batch adversarial loss: 0.498151\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332671; batch adversarial loss: 0.608823\n",
      "epoch 160; iter: 0; batch classifier loss: 0.331028; batch adversarial loss: 0.449128\n",
      "epoch 161; iter: 0; batch classifier loss: 0.314805; batch adversarial loss: 0.534428\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327417; batch adversarial loss: 0.535699\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349511; batch adversarial loss: 0.506453\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348479; batch adversarial loss: 0.477167\n",
      "epoch 165; iter: 0; batch classifier loss: 0.323012; batch adversarial loss: 0.471678\n",
      "epoch 166; iter: 0; batch classifier loss: 0.293469; batch adversarial loss: 0.516980\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353409; batch adversarial loss: 0.490313\n",
      "epoch 168; iter: 0; batch classifier loss: 0.382560; batch adversarial loss: 0.543939\n",
      "epoch 169; iter: 0; batch classifier loss: 0.336545; batch adversarial loss: 0.580446\n",
      "epoch 170; iter: 0; batch classifier loss: 0.331183; batch adversarial loss: 0.536214\n",
      "epoch 171; iter: 0; batch classifier loss: 0.324467; batch adversarial loss: 0.484784\n",
      "epoch 172; iter: 0; batch classifier loss: 0.306270; batch adversarial loss: 0.468199\n",
      "epoch 173; iter: 0; batch classifier loss: 0.389701; batch adversarial loss: 0.581941\n",
      "epoch 174; iter: 0; batch classifier loss: 0.298461; batch adversarial loss: 0.678979\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328625; batch adversarial loss: 0.590085\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310041; batch adversarial loss: 0.585024\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363534; batch adversarial loss: 0.526030\n",
      "epoch 178; iter: 0; batch classifier loss: 0.285571; batch adversarial loss: 0.536630\n",
      "epoch 179; iter: 0; batch classifier loss: 0.273034; batch adversarial loss: 0.515783\n",
      "epoch 180; iter: 0; batch classifier loss: 0.349418; batch adversarial loss: 0.508665\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331457; batch adversarial loss: 0.522502\n",
      "epoch 182; iter: 0; batch classifier loss: 0.248430; batch adversarial loss: 0.527668\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327134; batch adversarial loss: 0.599897\n",
      "epoch 184; iter: 0; batch classifier loss: 0.399963; batch adversarial loss: 0.553000\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369027; batch adversarial loss: 0.601553\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347843; batch adversarial loss: 0.489356\n",
      "epoch 187; iter: 0; batch classifier loss: 0.328061; batch adversarial loss: 0.598281\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313641; batch adversarial loss: 0.536313\n",
      "epoch 189; iter: 0; batch classifier loss: 0.360840; batch adversarial loss: 0.534016\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339167; batch adversarial loss: 0.571376\n",
      "epoch 191; iter: 0; batch classifier loss: 0.278758; batch adversarial loss: 0.514840\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297973; batch adversarial loss: 0.562883\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332562; batch adversarial loss: 0.442320\n",
      "epoch 194; iter: 0; batch classifier loss: 0.283149; batch adversarial loss: 0.533927\n",
      "epoch 195; iter: 0; batch classifier loss: 0.394565; batch adversarial loss: 0.535874\n",
      "epoch 196; iter: 0; batch classifier loss: 0.299948; batch adversarial loss: 0.535198\n",
      "epoch 197; iter: 0; batch classifier loss: 0.311824; batch adversarial loss: 0.505229\n",
      "epoch 198; iter: 0; batch classifier loss: 0.273732; batch adversarial loss: 0.555237\n",
      "epoch 199; iter: 0; batch classifier loss: 0.266199; batch adversarial loss: 0.554131\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736223; batch adversarial loss: 0.695584\n",
      "epoch 1; iter: 0; batch classifier loss: 0.620268; batch adversarial loss: 0.683672\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599706; batch adversarial loss: 0.644490\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609873; batch adversarial loss: 0.638531\n",
      "epoch 4; iter: 0; batch classifier loss: 0.561381; batch adversarial loss: 0.618811\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575234; batch adversarial loss: 0.593610\n",
      "epoch 6; iter: 0; batch classifier loss: 0.498133; batch adversarial loss: 0.606277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514610; batch adversarial loss: 0.600110\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486129; batch adversarial loss: 0.583882\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503701; batch adversarial loss: 0.636402\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567034; batch adversarial loss: 0.551234\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515498; batch adversarial loss: 0.571634\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519298; batch adversarial loss: 0.540294\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493245; batch adversarial loss: 0.563097\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485451; batch adversarial loss: 0.557708\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469290; batch adversarial loss: 0.611312\n",
      "epoch 16; iter: 0; batch classifier loss: 0.570186; batch adversarial loss: 0.539669\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510198; batch adversarial loss: 0.622991\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507971; batch adversarial loss: 0.588813\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506020; batch adversarial loss: 0.552193\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539029; batch adversarial loss: 0.590622\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479639; batch adversarial loss: 0.585434\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509694; batch adversarial loss: 0.547750\n",
      "epoch 23; iter: 0; batch classifier loss: 0.447219; batch adversarial loss: 0.606978\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495040; batch adversarial loss: 0.593909\n",
      "epoch 25; iter: 0; batch classifier loss: 0.444307; batch adversarial loss: 0.485424\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501822; batch adversarial loss: 0.569788\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494395; batch adversarial loss: 0.548027\n",
      "epoch 28; iter: 0; batch classifier loss: 0.556205; batch adversarial loss: 0.541241\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451411; batch adversarial loss: 0.596745\n",
      "epoch 30; iter: 0; batch classifier loss: 0.523768; batch adversarial loss: 0.473574\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497827; batch adversarial loss: 0.570931\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490517; batch adversarial loss: 0.554583\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457929; batch adversarial loss: 0.519663\n",
      "epoch 34; iter: 0; batch classifier loss: 0.479196; batch adversarial loss: 0.493857\n",
      "epoch 35; iter: 0; batch classifier loss: 0.531922; batch adversarial loss: 0.544960\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439087; batch adversarial loss: 0.492265\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479599; batch adversarial loss: 0.588965\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439022; batch adversarial loss: 0.606296\n",
      "epoch 39; iter: 0; batch classifier loss: 0.469270; batch adversarial loss: 0.580340\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497320; batch adversarial loss: 0.500353\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462008; batch adversarial loss: 0.526680\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446151; batch adversarial loss: 0.544784\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433816; batch adversarial loss: 0.445672\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455517; batch adversarial loss: 0.561824\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407345; batch adversarial loss: 0.463406\n",
      "epoch 46; iter: 0; batch classifier loss: 0.514725; batch adversarial loss: 0.553120\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477770; batch adversarial loss: 0.489792\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396843; batch adversarial loss: 0.616625\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393664; batch adversarial loss: 0.598364\n",
      "epoch 50; iter: 0; batch classifier loss: 0.510090; batch adversarial loss: 0.552291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.391773; batch adversarial loss: 0.473504\n",
      "epoch 52; iter: 0; batch classifier loss: 0.465951; batch adversarial loss: 0.499142\n",
      "epoch 53; iter: 0; batch classifier loss: 0.507722; batch adversarial loss: 0.545572\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437639; batch adversarial loss: 0.527361\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423675; batch adversarial loss: 0.544209\n",
      "epoch 56; iter: 0; batch classifier loss: 0.422131; batch adversarial loss: 0.582398\n",
      "epoch 57; iter: 0; batch classifier loss: 0.383483; batch adversarial loss: 0.554446\n",
      "epoch 58; iter: 0; batch classifier loss: 0.433606; batch adversarial loss: 0.553319\n",
      "epoch 59; iter: 0; batch classifier loss: 0.459598; batch adversarial loss: 0.543350\n",
      "epoch 60; iter: 0; batch classifier loss: 0.495426; batch adversarial loss: 0.598931\n",
      "epoch 61; iter: 0; batch classifier loss: 0.473444; batch adversarial loss: 0.516700\n",
      "epoch 62; iter: 0; batch classifier loss: 0.466799; batch adversarial loss: 0.554085\n",
      "epoch 63; iter: 0; batch classifier loss: 0.487422; batch adversarial loss: 0.507033\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406323; batch adversarial loss: 0.444162\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421361; batch adversarial loss: 0.588736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.321705; batch adversarial loss: 0.526318\n",
      "epoch 67; iter: 0; batch classifier loss: 0.479516; batch adversarial loss: 0.545036\n",
      "epoch 68; iter: 0; batch classifier loss: 0.452193; batch adversarial loss: 0.508193\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439112; batch adversarial loss: 0.489407\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393091; batch adversarial loss: 0.571789\n",
      "epoch 71; iter: 0; batch classifier loss: 0.444458; batch adversarial loss: 0.544783\n",
      "epoch 72; iter: 0; batch classifier loss: 0.447450; batch adversarial loss: 0.580705\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390898; batch adversarial loss: 0.572143\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410550; batch adversarial loss: 0.580850\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440443; batch adversarial loss: 0.526156\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419233; batch adversarial loss: 0.580594\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435728; batch adversarial loss: 0.580996\n",
      "epoch 78; iter: 0; batch classifier loss: 0.403881; batch adversarial loss: 0.608668\n",
      "epoch 79; iter: 0; batch classifier loss: 0.443083; batch adversarial loss: 0.563272\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385302; batch adversarial loss: 0.536126\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423590; batch adversarial loss: 0.571882\n",
      "epoch 82; iter: 0; batch classifier loss: 0.347300; batch adversarial loss: 0.553608\n",
      "epoch 83; iter: 0; batch classifier loss: 0.454553; batch adversarial loss: 0.544451\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365445; batch adversarial loss: 0.535672\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393496; batch adversarial loss: 0.599549\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401044; batch adversarial loss: 0.544560\n",
      "epoch 87; iter: 0; batch classifier loss: 0.435399; batch adversarial loss: 0.498297\n",
      "epoch 88; iter: 0; batch classifier loss: 0.491727; batch adversarial loss: 0.516083\n",
      "epoch 89; iter: 0; batch classifier loss: 0.359613; batch adversarial loss: 0.543674\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430793; batch adversarial loss: 0.600902\n",
      "epoch 91; iter: 0; batch classifier loss: 0.426777; batch adversarial loss: 0.580096\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396016; batch adversarial loss: 0.580806\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347255; batch adversarial loss: 0.517579\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383045; batch adversarial loss: 0.598353\n",
      "epoch 95; iter: 0; batch classifier loss: 0.458312; batch adversarial loss: 0.553679\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387796; batch adversarial loss: 0.499858\n",
      "epoch 97; iter: 0; batch classifier loss: 0.455251; batch adversarial loss: 0.525665\n",
      "epoch 98; iter: 0; batch classifier loss: 0.514483; batch adversarial loss: 0.498914\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425947; batch adversarial loss: 0.581530\n",
      "epoch 100; iter: 0; batch classifier loss: 0.424103; batch adversarial loss: 0.545939\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396737; batch adversarial loss: 0.562700\n",
      "epoch 102; iter: 0; batch classifier loss: 0.366634; batch adversarial loss: 0.563112\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440724; batch adversarial loss: 0.547061\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341701; batch adversarial loss: 0.552724\n",
      "epoch 105; iter: 0; batch classifier loss: 0.390173; batch adversarial loss: 0.487706\n",
      "epoch 106; iter: 0; batch classifier loss: 0.401909; batch adversarial loss: 0.506802\n",
      "epoch 107; iter: 0; batch classifier loss: 0.419324; batch adversarial loss: 0.543829\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367159; batch adversarial loss: 0.635942\n",
      "epoch 109; iter: 0; batch classifier loss: 0.449892; batch adversarial loss: 0.517047\n",
      "epoch 110; iter: 0; batch classifier loss: 0.431752; batch adversarial loss: 0.516621\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376662; batch adversarial loss: 0.544497\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375498; batch adversarial loss: 0.488647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386142; batch adversarial loss: 0.525817\n",
      "epoch 114; iter: 0; batch classifier loss: 0.448513; batch adversarial loss: 0.526632\n",
      "epoch 115; iter: 0; batch classifier loss: 0.359794; batch adversarial loss: 0.608656\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394815; batch adversarial loss: 0.544543\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385972; batch adversarial loss: 0.553186\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404342; batch adversarial loss: 0.489642\n",
      "epoch 119; iter: 0; batch classifier loss: 0.360073; batch adversarial loss: 0.589335\n",
      "epoch 120; iter: 0; batch classifier loss: 0.355032; batch adversarial loss: 0.616287\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420442; batch adversarial loss: 0.535452\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377989; batch adversarial loss: 0.526925\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342976; batch adversarial loss: 0.591118\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346135; batch adversarial loss: 0.452152\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399867; batch adversarial loss: 0.489218\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365594; batch adversarial loss: 0.544632\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391759; batch adversarial loss: 0.553555\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415141; batch adversarial loss: 0.562580\n",
      "epoch 129; iter: 0; batch classifier loss: 0.326697; batch adversarial loss: 0.526104\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341998; batch adversarial loss: 0.544361\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381212; batch adversarial loss: 0.544570\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360063; batch adversarial loss: 0.535389\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374210; batch adversarial loss: 0.581278\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340755; batch adversarial loss: 0.517837\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373121; batch adversarial loss: 0.580692\n",
      "epoch 136; iter: 0; batch classifier loss: 0.433771; batch adversarial loss: 0.635709\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369185; batch adversarial loss: 0.562076\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342753; batch adversarial loss: 0.581675\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384848; batch adversarial loss: 0.408090\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397082; batch adversarial loss: 0.525957\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350976; batch adversarial loss: 0.563681\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400443; batch adversarial loss: 0.554704\n",
      "epoch 143; iter: 0; batch classifier loss: 0.447713; batch adversarial loss: 0.607247\n",
      "epoch 144; iter: 0; batch classifier loss: 0.427341; batch adversarial loss: 0.543438\n",
      "epoch 145; iter: 0; batch classifier loss: 0.434451; batch adversarial loss: 0.534475\n",
      "epoch 146; iter: 0; batch classifier loss: 0.427321; batch adversarial loss: 0.608018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.355928; batch adversarial loss: 0.562713\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365656; batch adversarial loss: 0.563048\n",
      "epoch 149; iter: 0; batch classifier loss: 0.358522; batch adversarial loss: 0.537793\n",
      "epoch 150; iter: 0; batch classifier loss: 0.322818; batch adversarial loss: 0.544532\n",
      "epoch 151; iter: 0; batch classifier loss: 0.412005; batch adversarial loss: 0.535624\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342683; batch adversarial loss: 0.581018\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360780; batch adversarial loss: 0.553668\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317853; batch adversarial loss: 0.617589\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357600; batch adversarial loss: 0.563406\n",
      "epoch 156; iter: 0; batch classifier loss: 0.388879; batch adversarial loss: 0.536432\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403913; batch adversarial loss: 0.536219\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334164; batch adversarial loss: 0.582237\n",
      "epoch 159; iter: 0; batch classifier loss: 0.335263; batch adversarial loss: 0.571700\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372798; batch adversarial loss: 0.481342\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412235; batch adversarial loss: 0.537273\n",
      "epoch 162; iter: 0; batch classifier loss: 0.404255; batch adversarial loss: 0.517829\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326335; batch adversarial loss: 0.553667\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385167; batch adversarial loss: 0.554375\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333522; batch adversarial loss: 0.536210\n",
      "epoch 166; iter: 0; batch classifier loss: 0.435584; batch adversarial loss: 0.645442\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399914; batch adversarial loss: 0.471454\n",
      "epoch 168; iter: 0; batch classifier loss: 0.413574; batch adversarial loss: 0.535153\n",
      "epoch 169; iter: 0; batch classifier loss: 0.398581; batch adversarial loss: 0.526262\n",
      "epoch 170; iter: 0; batch classifier loss: 0.442108; batch adversarial loss: 0.526278\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353126; batch adversarial loss: 0.554743\n",
      "epoch 172; iter: 0; batch classifier loss: 0.348923; batch adversarial loss: 0.635971\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383516; batch adversarial loss: 0.582012\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385871; batch adversarial loss: 0.552921\n",
      "epoch 175; iter: 0; batch classifier loss: 0.429621; batch adversarial loss: 0.600062\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353012; batch adversarial loss: 0.600010\n",
      "epoch 177; iter: 0; batch classifier loss: 0.451466; batch adversarial loss: 0.508166\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370879; batch adversarial loss: 0.599239\n",
      "epoch 179; iter: 0; batch classifier loss: 0.381996; batch adversarial loss: 0.544643\n",
      "epoch 180; iter: 0; batch classifier loss: 0.438913; batch adversarial loss: 0.553550\n",
      "epoch 181; iter: 0; batch classifier loss: 0.372547; batch adversarial loss: 0.553512\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348969; batch adversarial loss: 0.462245\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333012; batch adversarial loss: 0.562711\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397091; batch adversarial loss: 0.517009\n",
      "epoch 185; iter: 0; batch classifier loss: 0.350983; batch adversarial loss: 0.509256\n",
      "epoch 186; iter: 0; batch classifier loss: 0.452895; batch adversarial loss: 0.571999\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374069; batch adversarial loss: 0.535676\n",
      "epoch 188; iter: 0; batch classifier loss: 0.326082; batch adversarial loss: 0.500185\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361460; batch adversarial loss: 0.535148\n",
      "epoch 190; iter: 0; batch classifier loss: 0.355006; batch adversarial loss: 0.526009\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382891; batch adversarial loss: 0.553159\n",
      "epoch 192; iter: 0; batch classifier loss: 0.331067; batch adversarial loss: 0.543779\n",
      "epoch 193; iter: 0; batch classifier loss: 0.365978; batch adversarial loss: 0.526002\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397709; batch adversarial loss: 0.553651\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376553; batch adversarial loss: 0.562467\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400238; batch adversarial loss: 0.581584\n",
      "epoch 197; iter: 0; batch classifier loss: 0.442392; batch adversarial loss: 0.580713\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349068; batch adversarial loss: 0.545008\n",
      "epoch 199; iter: 0; batch classifier loss: 0.452206; batch adversarial loss: 0.515990\n",
      "epoch 0; iter: 0; batch classifier loss: 0.758442; batch adversarial loss: 0.572058\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601791; batch adversarial loss: 0.678263\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616589; batch adversarial loss: 0.627393\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588511; batch adversarial loss: 0.588262\n",
      "epoch 4; iter: 0; batch classifier loss: 0.480320; batch adversarial loss: 0.633568\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511334; batch adversarial loss: 0.662662\n",
      "epoch 6; iter: 0; batch classifier loss: 0.507517; batch adversarial loss: 0.626598\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518287; batch adversarial loss: 0.607422\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464262; batch adversarial loss: 0.558891\n",
      "epoch 9; iter: 0; batch classifier loss: 0.498278; batch adversarial loss: 0.613562\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550576; batch adversarial loss: 0.600210\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517629; batch adversarial loss: 0.544816\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470649; batch adversarial loss: 0.612249\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554028; batch adversarial loss: 0.560161\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463030; batch adversarial loss: 0.542956\n",
      "epoch 15; iter: 0; batch classifier loss: 0.596933; batch adversarial loss: 0.535193\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505746; batch adversarial loss: 0.572867\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532740; batch adversarial loss: 0.523254\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502810; batch adversarial loss: 0.611683\n",
      "epoch 19; iter: 0; batch classifier loss: 0.429366; batch adversarial loss: 0.559151\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437902; batch adversarial loss: 0.486792\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513286; batch adversarial loss: 0.580584\n",
      "epoch 22; iter: 0; batch classifier loss: 0.532503; batch adversarial loss: 0.559214\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487768; batch adversarial loss: 0.565460\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478695; batch adversarial loss: 0.440366\n",
      "epoch 25; iter: 0; batch classifier loss: 0.388223; batch adversarial loss: 0.571223\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444848; batch adversarial loss: 0.565828\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489971; batch adversarial loss: 0.499749\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463264; batch adversarial loss: 0.524846\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447017; batch adversarial loss: 0.639705\n",
      "epoch 30; iter: 0; batch classifier loss: 0.401379; batch adversarial loss: 0.493381\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506345; batch adversarial loss: 0.512016\n",
      "epoch 32; iter: 0; batch classifier loss: 0.456977; batch adversarial loss: 0.526629\n",
      "epoch 33; iter: 0; batch classifier loss: 0.490069; batch adversarial loss: 0.484755\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398201; batch adversarial loss: 0.606462\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450360; batch adversarial loss: 0.509566\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505577; batch adversarial loss: 0.493328\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472118; batch adversarial loss: 0.558145\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439983; batch adversarial loss: 0.517942\n",
      "epoch 39; iter: 0; batch classifier loss: 0.409091; batch adversarial loss: 0.536800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.377444; batch adversarial loss: 0.490364\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447408; batch adversarial loss: 0.481312\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460694; batch adversarial loss: 0.525425\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445849; batch adversarial loss: 0.554226\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411212; batch adversarial loss: 0.507208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.441205; batch adversarial loss: 0.525992\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455433; batch adversarial loss: 0.450088\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413285; batch adversarial loss: 0.507090\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457213; batch adversarial loss: 0.478707\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472566; batch adversarial loss: 0.506847\n",
      "epoch 50; iter: 0; batch classifier loss: 0.501241; batch adversarial loss: 0.554027\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471941; batch adversarial loss: 0.553992\n",
      "epoch 52; iter: 0; batch classifier loss: 0.463645; batch adversarial loss: 0.554319\n",
      "epoch 53; iter: 0; batch classifier loss: 0.382533; batch adversarial loss: 0.506777\n",
      "epoch 54; iter: 0; batch classifier loss: 0.387158; batch adversarial loss: 0.526127\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419976; batch adversarial loss: 0.611607\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447040; batch adversarial loss: 0.573482\n",
      "epoch 57; iter: 0; batch classifier loss: 0.373134; batch adversarial loss: 0.486737\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402799; batch adversarial loss: 0.544851\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427149; batch adversarial loss: 0.611625\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407121; batch adversarial loss: 0.554579\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382305; batch adversarial loss: 0.487956\n",
      "epoch 62; iter: 0; batch classifier loss: 0.347770; batch adversarial loss: 0.497592\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449677; batch adversarial loss: 0.478279\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426310; batch adversarial loss: 0.525645\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447995; batch adversarial loss: 0.592376\n",
      "epoch 66; iter: 0; batch classifier loss: 0.391989; batch adversarial loss: 0.553454\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409061; batch adversarial loss: 0.572663\n",
      "epoch 68; iter: 0; batch classifier loss: 0.367272; batch adversarial loss: 0.601065\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420459; batch adversarial loss: 0.524260\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444790; batch adversarial loss: 0.563276\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410527; batch adversarial loss: 0.544477\n",
      "epoch 72; iter: 0; batch classifier loss: 0.469632; batch adversarial loss: 0.611304\n",
      "epoch 73; iter: 0; batch classifier loss: 0.489907; batch adversarial loss: 0.525348\n",
      "epoch 74; iter: 0; batch classifier loss: 0.345655; batch adversarial loss: 0.515914\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425252; batch adversarial loss: 0.545184\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375428; batch adversarial loss: 0.497124\n",
      "epoch 77; iter: 0; batch classifier loss: 0.456036; batch adversarial loss: 0.497126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405362; batch adversarial loss: 0.507360\n",
      "epoch 79; iter: 0; batch classifier loss: 0.446274; batch adversarial loss: 0.515954\n",
      "epoch 80; iter: 0; batch classifier loss: 0.445301; batch adversarial loss: 0.535191\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384515; batch adversarial loss: 0.582958\n",
      "epoch 82; iter: 0; batch classifier loss: 0.439191; batch adversarial loss: 0.496962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405514; batch adversarial loss: 0.562608\n",
      "epoch 84; iter: 0; batch classifier loss: 0.321257; batch adversarial loss: 0.553768\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361277; batch adversarial loss: 0.524857\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382545; batch adversarial loss: 0.611560\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395721; batch adversarial loss: 0.545260\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396067; batch adversarial loss: 0.516645\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401054; batch adversarial loss: 0.478248\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432324; batch adversarial loss: 0.620856\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358422; batch adversarial loss: 0.526002\n",
      "epoch 92; iter: 0; batch classifier loss: 0.484854; batch adversarial loss: 0.593219\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356684; batch adversarial loss: 0.552909\n",
      "epoch 94; iter: 0; batch classifier loss: 0.500093; batch adversarial loss: 0.505767\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375466; batch adversarial loss: 0.565724\n",
      "epoch 96; iter: 0; batch classifier loss: 0.346646; batch adversarial loss: 0.507191\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375190; batch adversarial loss: 0.543319\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373978; batch adversarial loss: 0.534578\n",
      "epoch 99; iter: 0; batch classifier loss: 0.337378; batch adversarial loss: 0.562962\n",
      "epoch 100; iter: 0; batch classifier loss: 0.317288; batch adversarial loss: 0.579402\n",
      "epoch 101; iter: 0; batch classifier loss: 0.435317; batch adversarial loss: 0.525531\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350971; batch adversarial loss: 0.555693\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398426; batch adversarial loss: 0.535460\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367778; batch adversarial loss: 0.534945\n",
      "epoch 105; iter: 0; batch classifier loss: 0.412268; batch adversarial loss: 0.524996\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404369; batch adversarial loss: 0.514904\n",
      "epoch 107; iter: 0; batch classifier loss: 0.502947; batch adversarial loss: 0.466788\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381126; batch adversarial loss: 0.564919\n",
      "epoch 109; iter: 0; batch classifier loss: 0.446228; batch adversarial loss: 0.563658\n",
      "epoch 110; iter: 0; batch classifier loss: 0.354847; batch adversarial loss: 0.592330\n",
      "epoch 111; iter: 0; batch classifier loss: 0.333985; batch adversarial loss: 0.584515\n",
      "epoch 112; iter: 0; batch classifier loss: 0.352301; batch adversarial loss: 0.585368\n",
      "epoch 113; iter: 0; batch classifier loss: 0.322502; batch adversarial loss: 0.583047\n",
      "epoch 114; iter: 0; batch classifier loss: 0.342859; batch adversarial loss: 0.588921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.271245; batch adversarial loss: 0.525728\n",
      "epoch 116; iter: 0; batch classifier loss: 0.332707; batch adversarial loss: 0.478088\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415939; batch adversarial loss: 0.468222\n",
      "epoch 118; iter: 0; batch classifier loss: 0.445011; batch adversarial loss: 0.535687\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373196; batch adversarial loss: 0.554390\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362273; batch adversarial loss: 0.554413\n",
      "epoch 121; iter: 0; batch classifier loss: 0.425377; batch adversarial loss: 0.477240\n",
      "epoch 122; iter: 0; batch classifier loss: 0.342053; batch adversarial loss: 0.573288\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366556; batch adversarial loss: 0.572428\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345416; batch adversarial loss: 0.449232\n",
      "epoch 125; iter: 0; batch classifier loss: 0.333325; batch adversarial loss: 0.496173\n",
      "epoch 126; iter: 0; batch classifier loss: 0.326248; batch adversarial loss: 0.544431\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367275; batch adversarial loss: 0.534569\n",
      "epoch 128; iter: 0; batch classifier loss: 0.341605; batch adversarial loss: 0.581665\n",
      "epoch 129; iter: 0; batch classifier loss: 0.313679; batch adversarial loss: 0.543239\n",
      "epoch 130; iter: 0; batch classifier loss: 0.459220; batch adversarial loss: 0.593054\n",
      "epoch 131; iter: 0; batch classifier loss: 0.434427; batch adversarial loss: 0.543735\n",
      "epoch 132; iter: 0; batch classifier loss: 0.328778; batch adversarial loss: 0.562896\n",
      "epoch 133; iter: 0; batch classifier loss: 0.338090; batch adversarial loss: 0.553274\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402591; batch adversarial loss: 0.563029\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395326; batch adversarial loss: 0.532782\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340452; batch adversarial loss: 0.590806\n",
      "epoch 137; iter: 0; batch classifier loss: 0.388891; batch adversarial loss: 0.555380\n",
      "epoch 138; iter: 0; batch classifier loss: 0.354745; batch adversarial loss: 0.489293\n",
      "epoch 139; iter: 0; batch classifier loss: 0.310196; batch adversarial loss: 0.508743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328081; batch adversarial loss: 0.524727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.402130; batch adversarial loss: 0.564411\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400869; batch adversarial loss: 0.497898\n",
      "epoch 143; iter: 0; batch classifier loss: 0.422110; batch adversarial loss: 0.594237\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357038; batch adversarial loss: 0.534380\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351208; batch adversarial loss: 0.525345\n",
      "epoch 146; iter: 0; batch classifier loss: 0.302534; batch adversarial loss: 0.515434\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355976; batch adversarial loss: 0.544165\n",
      "epoch 148; iter: 0; batch classifier loss: 0.377434; batch adversarial loss: 0.554426\n",
      "epoch 149; iter: 0; batch classifier loss: 0.298083; batch adversarial loss: 0.575356\n",
      "epoch 150; iter: 0; batch classifier loss: 0.405810; batch adversarial loss: 0.524407\n",
      "epoch 151; iter: 0; batch classifier loss: 0.449920; batch adversarial loss: 0.527079\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330940; batch adversarial loss: 0.497356\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367985; batch adversarial loss: 0.411332\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349286; batch adversarial loss: 0.544298\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349152; batch adversarial loss: 0.498482\n",
      "epoch 156; iter: 0; batch classifier loss: 0.345807; batch adversarial loss: 0.440414\n",
      "epoch 157; iter: 0; batch classifier loss: 0.387964; batch adversarial loss: 0.553944\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364780; batch adversarial loss: 0.592698\n",
      "epoch 159; iter: 0; batch classifier loss: 0.295832; batch adversarial loss: 0.450239\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347088; batch adversarial loss: 0.582572\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392691; batch adversarial loss: 0.525844\n",
      "epoch 162; iter: 0; batch classifier loss: 0.345695; batch adversarial loss: 0.544670\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338777; batch adversarial loss: 0.497523\n",
      "epoch 164; iter: 0; batch classifier loss: 0.459515; batch adversarial loss: 0.506687\n",
      "epoch 165; iter: 0; batch classifier loss: 0.447791; batch adversarial loss: 0.553082\n",
      "epoch 166; iter: 0; batch classifier loss: 0.406478; batch adversarial loss: 0.564792\n",
      "epoch 167; iter: 0; batch classifier loss: 0.435926; batch adversarial loss: 0.620602\n",
      "epoch 168; iter: 0; batch classifier loss: 0.303295; batch adversarial loss: 0.515515\n",
      "epoch 169; iter: 0; batch classifier loss: 0.435486; batch adversarial loss: 0.467205\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374601; batch adversarial loss: 0.591685\n",
      "epoch 171; iter: 0; batch classifier loss: 0.280813; batch adversarial loss: 0.574448\n",
      "epoch 172; iter: 0; batch classifier loss: 0.329614; batch adversarial loss: 0.658871\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341771; batch adversarial loss: 0.526141\n",
      "epoch 174; iter: 0; batch classifier loss: 0.273161; batch adversarial loss: 0.495430\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338324; batch adversarial loss: 0.535865\n",
      "epoch 176; iter: 0; batch classifier loss: 0.415329; batch adversarial loss: 0.572247\n",
      "epoch 177; iter: 0; batch classifier loss: 0.411283; batch adversarial loss: 0.489018\n",
      "epoch 178; iter: 0; batch classifier loss: 0.373407; batch adversarial loss: 0.448389\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330373; batch adversarial loss: 0.535975\n",
      "epoch 180; iter: 0; batch classifier loss: 0.305504; batch adversarial loss: 0.488293\n",
      "epoch 181; iter: 0; batch classifier loss: 0.295669; batch adversarial loss: 0.535116\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389679; batch adversarial loss: 0.495226\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376613; batch adversarial loss: 0.554823\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381223; batch adversarial loss: 0.575484\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319635; batch adversarial loss: 0.534969\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338693; batch adversarial loss: 0.486073\n",
      "epoch 187; iter: 0; batch classifier loss: 0.302200; batch adversarial loss: 0.544778\n",
      "epoch 188; iter: 0; batch classifier loss: 0.305754; batch adversarial loss: 0.447533\n",
      "epoch 189; iter: 0; batch classifier loss: 0.314201; batch adversarial loss: 0.573368\n",
      "epoch 190; iter: 0; batch classifier loss: 0.285253; batch adversarial loss: 0.582806\n",
      "epoch 191; iter: 0; batch classifier loss: 0.404883; batch adversarial loss: 0.574067\n",
      "epoch 192; iter: 0; batch classifier loss: 0.429996; batch adversarial loss: 0.573349\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318625; batch adversarial loss: 0.611415\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399279; batch adversarial loss: 0.582735\n",
      "epoch 195; iter: 0; batch classifier loss: 0.313542; batch adversarial loss: 0.535300\n",
      "epoch 196; iter: 0; batch classifier loss: 0.447626; batch adversarial loss: 0.496758\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320503; batch adversarial loss: 0.526794\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328234; batch adversarial loss: 0.497842\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335863; batch adversarial loss: 0.554098\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717047; batch adversarial loss: 0.598148\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605365; batch adversarial loss: 0.659767\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561149; batch adversarial loss: 0.652347\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556977; batch adversarial loss: 0.629645\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549667; batch adversarial loss: 0.581175\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597625; batch adversarial loss: 0.636491\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558563; batch adversarial loss: 0.641545\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594785; batch adversarial loss: 0.648289\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545850; batch adversarial loss: 0.593695\n",
      "epoch 9; iter: 0; batch classifier loss: 0.615778; batch adversarial loss: 0.630284\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564826; batch adversarial loss: 0.586228\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570544; batch adversarial loss: 0.551384\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527982; batch adversarial loss: 0.590324\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486394; batch adversarial loss: 0.552629\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480622; batch adversarial loss: 0.582147\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494399; batch adversarial loss: 0.548258\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514133; batch adversarial loss: 0.558744\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536129; batch adversarial loss: 0.539302\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519643; batch adversarial loss: 0.503096\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487071; batch adversarial loss: 0.520856\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499559; batch adversarial loss: 0.485268\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499792; batch adversarial loss: 0.539455\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512855; batch adversarial loss: 0.506051\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471636; batch adversarial loss: 0.513079\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481660; batch adversarial loss: 0.588499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446682; batch adversarial loss: 0.564587\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469158; batch adversarial loss: 0.647841\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468851; batch adversarial loss: 0.580117\n",
      "epoch 28; iter: 0; batch classifier loss: 0.466842; batch adversarial loss: 0.527870\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511589; batch adversarial loss: 0.563123\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457256; batch adversarial loss: 0.580243\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444415; batch adversarial loss: 0.608662\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405236; batch adversarial loss: 0.553816\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514820; batch adversarial loss: 0.508345\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436041; batch adversarial loss: 0.571930\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485010; batch adversarial loss: 0.553755\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487683; batch adversarial loss: 0.544370\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465550; batch adversarial loss: 0.516620\n",
      "epoch 38; iter: 0; batch classifier loss: 0.401464; batch adversarial loss: 0.506935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.456680; batch adversarial loss: 0.507604\n",
      "epoch 40; iter: 0; batch classifier loss: 0.344777; batch adversarial loss: 0.534577\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464689; batch adversarial loss: 0.553281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.476259; batch adversarial loss: 0.545987\n",
      "epoch 43; iter: 0; batch classifier loss: 0.448671; batch adversarial loss: 0.534154\n",
      "epoch 44; iter: 0; batch classifier loss: 0.467272; batch adversarial loss: 0.523448\n",
      "epoch 45; iter: 0; batch classifier loss: 0.531184; batch adversarial loss: 0.552872\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483820; batch adversarial loss: 0.498670\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405122; batch adversarial loss: 0.581515\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427425; batch adversarial loss: 0.479435\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388852; batch adversarial loss: 0.592265\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431233; batch adversarial loss: 0.565781\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465957; batch adversarial loss: 0.553722\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443524; batch adversarial loss: 0.572438\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431613; batch adversarial loss: 0.582262\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406513; batch adversarial loss: 0.591724\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460146; batch adversarial loss: 0.556162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408003; batch adversarial loss: 0.534823\n",
      "epoch 57; iter: 0; batch classifier loss: 0.534489; batch adversarial loss: 0.506377\n",
      "epoch 58; iter: 0; batch classifier loss: 0.477344; batch adversarial loss: 0.508643\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412038; batch adversarial loss: 0.557909\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390202; batch adversarial loss: 0.533005\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422283; batch adversarial loss: 0.552705\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421441; batch adversarial loss: 0.535206\n",
      "epoch 63; iter: 0; batch classifier loss: 0.511328; batch adversarial loss: 0.572104\n",
      "epoch 64; iter: 0; batch classifier loss: 0.346042; batch adversarial loss: 0.545000\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397924; batch adversarial loss: 0.486661\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452677; batch adversarial loss: 0.450662\n",
      "epoch 67; iter: 0; batch classifier loss: 0.503090; batch adversarial loss: 0.449009\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421973; batch adversarial loss: 0.581737\n",
      "epoch 69; iter: 0; batch classifier loss: 0.368132; batch adversarial loss: 0.572675\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416089; batch adversarial loss: 0.543838\n",
      "epoch 71; iter: 0; batch classifier loss: 0.371966; batch adversarial loss: 0.583487\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387649; batch adversarial loss: 0.643403\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385388; batch adversarial loss: 0.507906\n",
      "epoch 74; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.501554\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409837; batch adversarial loss: 0.574142\n",
      "epoch 76; iter: 0; batch classifier loss: 0.361531; batch adversarial loss: 0.512677\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392917; batch adversarial loss: 0.522422\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427311; batch adversarial loss: 0.462786\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397955; batch adversarial loss: 0.525414\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367003; batch adversarial loss: 0.478623\n",
      "epoch 81; iter: 0; batch classifier loss: 0.364829; batch adversarial loss: 0.556373\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383370; batch adversarial loss: 0.572657\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434092; batch adversarial loss: 0.497876\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408361; batch adversarial loss: 0.640910\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378727; batch adversarial loss: 0.583203\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418141; batch adversarial loss: 0.553494\n",
      "epoch 87; iter: 0; batch classifier loss: 0.441002; batch adversarial loss: 0.512850\n",
      "epoch 88; iter: 0; batch classifier loss: 0.359213; batch adversarial loss: 0.545421\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401755; batch adversarial loss: 0.610146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388479; batch adversarial loss: 0.523383\n",
      "epoch 91; iter: 0; batch classifier loss: 0.371699; batch adversarial loss: 0.503952\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376186; batch adversarial loss: 0.533906\n",
      "epoch 93; iter: 0; batch classifier loss: 0.290198; batch adversarial loss: 0.585174\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354997; batch adversarial loss: 0.525182\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424203; batch adversarial loss: 0.494635\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408782; batch adversarial loss: 0.506198\n",
      "epoch 97; iter: 0; batch classifier loss: 0.456048; batch adversarial loss: 0.497397\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365034; batch adversarial loss: 0.505510\n",
      "epoch 99; iter: 0; batch classifier loss: 0.306025; batch adversarial loss: 0.543160\n",
      "epoch 100; iter: 0; batch classifier loss: 0.440191; batch adversarial loss: 0.544015\n",
      "epoch 101; iter: 0; batch classifier loss: 0.432640; batch adversarial loss: 0.533037\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380034; batch adversarial loss: 0.495236\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384749; batch adversarial loss: 0.609017\n",
      "epoch 104; iter: 0; batch classifier loss: 0.464832; batch adversarial loss: 0.481676\n",
      "epoch 105; iter: 0; batch classifier loss: 0.367740; batch adversarial loss: 0.480223\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379541; batch adversarial loss: 0.551673\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436635; batch adversarial loss: 0.580891\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366698; batch adversarial loss: 0.609760\n",
      "epoch 109; iter: 0; batch classifier loss: 0.445450; batch adversarial loss: 0.545222\n",
      "epoch 110; iter: 0; batch classifier loss: 0.345494; batch adversarial loss: 0.436981\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362142; batch adversarial loss: 0.500909\n",
      "epoch 112; iter: 0; batch classifier loss: 0.287228; batch adversarial loss: 0.548093\n",
      "epoch 113; iter: 0; batch classifier loss: 0.288634; batch adversarial loss: 0.590407\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360144; batch adversarial loss: 0.522494\n",
      "epoch 115; iter: 0; batch classifier loss: 0.392875; batch adversarial loss: 0.544733\n",
      "epoch 116; iter: 0; batch classifier loss: 0.378745; batch adversarial loss: 0.513884\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411399; batch adversarial loss: 0.583645\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361240; batch adversarial loss: 0.591404\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381339; batch adversarial loss: 0.489009\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388443; batch adversarial loss: 0.525614\n",
      "epoch 121; iter: 0; batch classifier loss: 0.331754; batch adversarial loss: 0.561074\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383289; batch adversarial loss: 0.503775\n",
      "epoch 123; iter: 0; batch classifier loss: 0.420394; batch adversarial loss: 0.522805\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354341; batch adversarial loss: 0.546113\n",
      "epoch 125; iter: 0; batch classifier loss: 0.449117; batch adversarial loss: 0.489193\n",
      "epoch 126; iter: 0; batch classifier loss: 0.416442; batch adversarial loss: 0.563529\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397468; batch adversarial loss: 0.504334\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403124; batch adversarial loss: 0.522993\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359979; batch adversarial loss: 0.545708\n",
      "epoch 130; iter: 0; batch classifier loss: 0.350504; batch adversarial loss: 0.546945\n",
      "epoch 131; iter: 0; batch classifier loss: 0.425095; batch adversarial loss: 0.504688\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350213; batch adversarial loss: 0.551573\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410885; batch adversarial loss: 0.561250\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376326; batch adversarial loss: 0.543977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.460677; batch adversarial loss: 0.520438\n",
      "epoch 136; iter: 0; batch classifier loss: 0.394701; batch adversarial loss: 0.621291\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403915; batch adversarial loss: 0.563816\n",
      "epoch 138; iter: 0; batch classifier loss: 0.333825; batch adversarial loss: 0.503946\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349396; batch adversarial loss: 0.543942\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399166; batch adversarial loss: 0.576678\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386721; batch adversarial loss: 0.561763\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355726; batch adversarial loss: 0.542290\n",
      "epoch 143; iter: 0; batch classifier loss: 0.313558; batch adversarial loss: 0.496926\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406437; batch adversarial loss: 0.582831\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381948; batch adversarial loss: 0.552322\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341569; batch adversarial loss: 0.599833\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374003; batch adversarial loss: 0.576559\n",
      "epoch 148; iter: 0; batch classifier loss: 0.329317; batch adversarial loss: 0.606869\n",
      "epoch 149; iter: 0; batch classifier loss: 0.337098; batch adversarial loss: 0.515903\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320940; batch adversarial loss: 0.509704\n",
      "epoch 151; iter: 0; batch classifier loss: 0.259861; batch adversarial loss: 0.572159\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383683; batch adversarial loss: 0.481893\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368640; batch adversarial loss: 0.465902\n",
      "epoch 154; iter: 0; batch classifier loss: 0.409649; batch adversarial loss: 0.547731\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337966; batch adversarial loss: 0.515703\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350277; batch adversarial loss: 0.534249\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313958; batch adversarial loss: 0.536609\n",
      "epoch 158; iter: 0; batch classifier loss: 0.358004; batch adversarial loss: 0.555285\n",
      "epoch 159; iter: 0; batch classifier loss: 0.379358; batch adversarial loss: 0.558844\n",
      "epoch 160; iter: 0; batch classifier loss: 0.263618; batch adversarial loss: 0.537685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.364830; batch adversarial loss: 0.569930\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353939; batch adversarial loss: 0.518476\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335182; batch adversarial loss: 0.489498\n",
      "epoch 164; iter: 0; batch classifier loss: 0.408154; batch adversarial loss: 0.541119\n",
      "epoch 165; iter: 0; batch classifier loss: 0.335499; batch adversarial loss: 0.546773\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365642; batch adversarial loss: 0.528299\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380963; batch adversarial loss: 0.492148\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331094; batch adversarial loss: 0.544728\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354168; batch adversarial loss: 0.534614\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346785; batch adversarial loss: 0.545723\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323704; batch adversarial loss: 0.484722\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379547; batch adversarial loss: 0.486941\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315700; batch adversarial loss: 0.430889\n",
      "epoch 174; iter: 0; batch classifier loss: 0.445156; batch adversarial loss: 0.527812\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338770; batch adversarial loss: 0.573434\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382999; batch adversarial loss: 0.581091\n",
      "epoch 177; iter: 0; batch classifier loss: 0.395690; batch adversarial loss: 0.551601\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369068; batch adversarial loss: 0.625201\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379352; batch adversarial loss: 0.643226\n",
      "epoch 180; iter: 0; batch classifier loss: 0.435852; batch adversarial loss: 0.595184\n",
      "epoch 181; iter: 0; batch classifier loss: 0.408247; batch adversarial loss: 0.605356\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334781; batch adversarial loss: 0.553908\n",
      "epoch 183; iter: 0; batch classifier loss: 0.268973; batch adversarial loss: 0.520081\n",
      "epoch 184; iter: 0; batch classifier loss: 0.274921; batch adversarial loss: 0.460873\n",
      "epoch 185; iter: 0; batch classifier loss: 0.505213; batch adversarial loss: 0.591033\n",
      "epoch 186; iter: 0; batch classifier loss: 0.304451; batch adversarial loss: 0.635115\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325964; batch adversarial loss: 0.573472\n",
      "epoch 188; iter: 0; batch classifier loss: 0.357021; batch adversarial loss: 0.559197\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369123; batch adversarial loss: 0.580853\n",
      "epoch 190; iter: 0; batch classifier loss: 0.284291; batch adversarial loss: 0.622858\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354132; batch adversarial loss: 0.478930\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381398; batch adversarial loss: 0.524816\n",
      "epoch 193; iter: 0; batch classifier loss: 0.392396; batch adversarial loss: 0.515167\n",
      "epoch 194; iter: 0; batch classifier loss: 0.294673; batch adversarial loss: 0.512882\n",
      "epoch 195; iter: 0; batch classifier loss: 0.396656; batch adversarial loss: 0.611760\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370545; batch adversarial loss: 0.533937\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388882; batch adversarial loss: 0.590506\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390726; batch adversarial loss: 0.601030\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319389; batch adversarial loss: 0.470349\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712730; batch adversarial loss: 0.613873\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556668; batch adversarial loss: 0.657848\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573971; batch adversarial loss: 0.640086\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573887; batch adversarial loss: 0.641767\n",
      "epoch 4; iter: 0; batch classifier loss: 0.630199; batch adversarial loss: 0.633656\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571362; batch adversarial loss: 0.609168\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554014; batch adversarial loss: 0.593095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548839; batch adversarial loss: 0.616351\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586162; batch adversarial loss: 0.629530\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561147; batch adversarial loss: 0.617316\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582530; batch adversarial loss: 0.615781\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563852; batch adversarial loss: 0.664435\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562869; batch adversarial loss: 0.578751\n",
      "epoch 13; iter: 0; batch classifier loss: 0.475353; batch adversarial loss: 0.532090\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501324; batch adversarial loss: 0.577145\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538426; batch adversarial loss: 0.515990\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554968; batch adversarial loss: 0.552478\n",
      "epoch 17; iter: 0; batch classifier loss: 0.475458; batch adversarial loss: 0.582800\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518597; batch adversarial loss: 0.537797\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469762; batch adversarial loss: 0.489849\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465206; batch adversarial loss: 0.553316\n",
      "epoch 21; iter: 0; batch classifier loss: 0.518525; batch adversarial loss: 0.536106\n",
      "epoch 22; iter: 0; batch classifier loss: 0.559223; batch adversarial loss: 0.549341\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487469; batch adversarial loss: 0.575812\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498123; batch adversarial loss: 0.524880\n",
      "epoch 25; iter: 0; batch classifier loss: 0.486613; batch adversarial loss: 0.645834\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501183; batch adversarial loss: 0.544818\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480405; batch adversarial loss: 0.579592\n",
      "epoch 28; iter: 0; batch classifier loss: 0.409592; batch adversarial loss: 0.553853\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432270; batch adversarial loss: 0.537746\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443397; batch adversarial loss: 0.562936\n",
      "epoch 31; iter: 0; batch classifier loss: 0.391071; batch adversarial loss: 0.462249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.486156; batch adversarial loss: 0.512999\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456713; batch adversarial loss: 0.590910\n",
      "epoch 34; iter: 0; batch classifier loss: 0.531981; batch adversarial loss: 0.490829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458966; batch adversarial loss: 0.519775\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426488; batch adversarial loss: 0.502988\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455250; batch adversarial loss: 0.592214\n",
      "epoch 38; iter: 0; batch classifier loss: 0.410659; batch adversarial loss: 0.544097\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468216; batch adversarial loss: 0.571173\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468289; batch adversarial loss: 0.492719\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420047; batch adversarial loss: 0.518858\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463730; batch adversarial loss: 0.568344\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480474; batch adversarial loss: 0.551217\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468912; batch adversarial loss: 0.554885\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477507; batch adversarial loss: 0.500650\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424706; batch adversarial loss: 0.599662\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410619; batch adversarial loss: 0.577122\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457721; batch adversarial loss: 0.498936\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435373; batch adversarial loss: 0.553948\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414178; batch adversarial loss: 0.534745\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453160; batch adversarial loss: 0.632640\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470951; batch adversarial loss: 0.484178\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424318; batch adversarial loss: 0.537129\n",
      "epoch 54; iter: 0; batch classifier loss: 0.495679; batch adversarial loss: 0.617720\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409582; batch adversarial loss: 0.582806\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434762; batch adversarial loss: 0.527144\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401103; batch adversarial loss: 0.627368\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426118; batch adversarial loss: 0.592690\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431670; batch adversarial loss: 0.565633\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405706; batch adversarial loss: 0.579028\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467629; batch adversarial loss: 0.490152\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405191; batch adversarial loss: 0.524796\n",
      "epoch 63; iter: 0; batch classifier loss: 0.484099; batch adversarial loss: 0.571154\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422724; batch adversarial loss: 0.562955\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433409; batch adversarial loss: 0.489550\n",
      "epoch 66; iter: 0; batch classifier loss: 0.470571; batch adversarial loss: 0.616734\n",
      "epoch 67; iter: 0; batch classifier loss: 0.458913; batch adversarial loss: 0.618905\n",
      "epoch 68; iter: 0; batch classifier loss: 0.452314; batch adversarial loss: 0.601690\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422256; batch adversarial loss: 0.618688\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413700; batch adversarial loss: 0.577987\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393304; batch adversarial loss: 0.505210\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434927; batch adversarial loss: 0.462574\n",
      "epoch 73; iter: 0; batch classifier loss: 0.453069; batch adversarial loss: 0.572724\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464607; batch adversarial loss: 0.534839\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352098; batch adversarial loss: 0.537611\n",
      "epoch 76; iter: 0; batch classifier loss: 0.470662; batch adversarial loss: 0.445184\n",
      "epoch 77; iter: 0; batch classifier loss: 0.364611; batch adversarial loss: 0.535205\n",
      "epoch 78; iter: 0; batch classifier loss: 0.462298; batch adversarial loss: 0.525643\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374069; batch adversarial loss: 0.523572\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417337; batch adversarial loss: 0.454202\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395323; batch adversarial loss: 0.653961\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396142; batch adversarial loss: 0.552793\n",
      "epoch 83; iter: 0; batch classifier loss: 0.442588; batch adversarial loss: 0.581147\n",
      "epoch 84; iter: 0; batch classifier loss: 0.465837; batch adversarial loss: 0.559693\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434977; batch adversarial loss: 0.655866\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414094; batch adversarial loss: 0.517912\n",
      "epoch 87; iter: 0; batch classifier loss: 0.400692; batch adversarial loss: 0.573737\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413604; batch adversarial loss: 0.500485\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384863; batch adversarial loss: 0.532973\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411021; batch adversarial loss: 0.517435\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398464; batch adversarial loss: 0.608373\n",
      "epoch 92; iter: 0; batch classifier loss: 0.446662; batch adversarial loss: 0.515494\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374869; batch adversarial loss: 0.471342\n",
      "epoch 94; iter: 0; batch classifier loss: 0.476415; batch adversarial loss: 0.562540\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361612; batch adversarial loss: 0.481510\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391224; batch adversarial loss: 0.617655\n",
      "epoch 97; iter: 0; batch classifier loss: 0.461291; batch adversarial loss: 0.627048\n",
      "epoch 98; iter: 0; batch classifier loss: 0.446678; batch adversarial loss: 0.526479\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356868; batch adversarial loss: 0.564151\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389342; batch adversarial loss: 0.564285\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374113; batch adversarial loss: 0.488853\n",
      "epoch 102; iter: 0; batch classifier loss: 0.496579; batch adversarial loss: 0.554522\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345744; batch adversarial loss: 0.517250\n",
      "epoch 104; iter: 0; batch classifier loss: 0.446947; batch adversarial loss: 0.544883\n",
      "epoch 105; iter: 0; batch classifier loss: 0.379528; batch adversarial loss: 0.544428\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398182; batch adversarial loss: 0.525966\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386819; batch adversarial loss: 0.500583\n",
      "epoch 108; iter: 0; batch classifier loss: 0.305012; batch adversarial loss: 0.541657\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410856; batch adversarial loss: 0.471070\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375377; batch adversarial loss: 0.535444\n",
      "epoch 111; iter: 0; batch classifier loss: 0.422635; batch adversarial loss: 0.554554\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391923; batch adversarial loss: 0.517634\n",
      "epoch 113; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.452151\n",
      "epoch 114; iter: 0; batch classifier loss: 0.390382; batch adversarial loss: 0.535481\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348119; batch adversarial loss: 0.589770\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420986; batch adversarial loss: 0.608880\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371741; batch adversarial loss: 0.553940\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394248; batch adversarial loss: 0.499401\n",
      "epoch 119; iter: 0; batch classifier loss: 0.405497; batch adversarial loss: 0.517651\n",
      "epoch 120; iter: 0; batch classifier loss: 0.411226; batch adversarial loss: 0.598644\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373914; batch adversarial loss: 0.590649\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362857; batch adversarial loss: 0.542300\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341234; batch adversarial loss: 0.562844\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378388; batch adversarial loss: 0.617723\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418668; batch adversarial loss: 0.544329\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404624; batch adversarial loss: 0.489146\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369334; batch adversarial loss: 0.589340\n",
      "epoch 128; iter: 0; batch classifier loss: 0.330358; batch adversarial loss: 0.489592\n",
      "epoch 129; iter: 0; batch classifier loss: 0.330323; batch adversarial loss: 0.535243\n",
      "epoch 130; iter: 0; batch classifier loss: 0.456228; batch adversarial loss: 0.473484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.428701; batch adversarial loss: 0.608003\n",
      "epoch 132; iter: 0; batch classifier loss: 0.416569; batch adversarial loss: 0.555354\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374164; batch adversarial loss: 0.553941\n",
      "epoch 134; iter: 0; batch classifier loss: 0.336858; batch adversarial loss: 0.636310\n",
      "epoch 135; iter: 0; batch classifier loss: 0.409930; batch adversarial loss: 0.570351\n",
      "epoch 136; iter: 0; batch classifier loss: 0.452779; batch adversarial loss: 0.535126\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407308; batch adversarial loss: 0.572408\n",
      "epoch 138; iter: 0; batch classifier loss: 0.427918; batch adversarial loss: 0.591084\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342456; batch adversarial loss: 0.416391\n",
      "epoch 140; iter: 0; batch classifier loss: 0.425153; batch adversarial loss: 0.552618\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390637; batch adversarial loss: 0.516657\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376946; batch adversarial loss: 0.544303\n",
      "epoch 143; iter: 0; batch classifier loss: 0.454746; batch adversarial loss: 0.599124\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363456; batch adversarial loss: 0.588931\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338852; batch adversarial loss: 0.543361\n",
      "epoch 146; iter: 0; batch classifier loss: 0.467939; batch adversarial loss: 0.663326\n",
      "epoch 147; iter: 0; batch classifier loss: 0.325726; batch adversarial loss: 0.626643\n",
      "epoch 148; iter: 0; batch classifier loss: 0.398959; batch adversarial loss: 0.534988\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375757; batch adversarial loss: 0.580271\n",
      "epoch 150; iter: 0; batch classifier loss: 0.430970; batch adversarial loss: 0.526108\n",
      "epoch 151; iter: 0; batch classifier loss: 0.332217; batch adversarial loss: 0.590285\n",
      "epoch 152; iter: 0; batch classifier loss: 0.439715; batch adversarial loss: 0.572884\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346575; batch adversarial loss: 0.497705\n",
      "epoch 154; iter: 0; batch classifier loss: 0.263789; batch adversarial loss: 0.607562\n",
      "epoch 155; iter: 0; batch classifier loss: 0.435587; batch adversarial loss: 0.516813\n",
      "epoch 156; iter: 0; batch classifier loss: 0.318036; batch adversarial loss: 0.516936\n",
      "epoch 157; iter: 0; batch classifier loss: 0.458472; batch adversarial loss: 0.508644\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392858; batch adversarial loss: 0.517097\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370514; batch adversarial loss: 0.462442\n",
      "epoch 160; iter: 0; batch classifier loss: 0.436887; batch adversarial loss: 0.599786\n",
      "epoch 161; iter: 0; batch classifier loss: 0.402083; batch adversarial loss: 0.590527\n",
      "epoch 162; iter: 0; batch classifier loss: 0.479394; batch adversarial loss: 0.453838\n",
      "epoch 163; iter: 0; batch classifier loss: 0.324638; batch adversarial loss: 0.554691\n",
      "epoch 164; iter: 0; batch classifier loss: 0.412559; batch adversarial loss: 0.527269\n",
      "epoch 165; iter: 0; batch classifier loss: 0.357082; batch adversarial loss: 0.589774\n",
      "epoch 166; iter: 0; batch classifier loss: 0.299139; batch adversarial loss: 0.516691\n",
      "epoch 167; iter: 0; batch classifier loss: 0.373184; batch adversarial loss: 0.498439\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362647; batch adversarial loss: 0.599033\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372923; batch adversarial loss: 0.534543\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353203; batch adversarial loss: 0.525566\n",
      "epoch 171; iter: 0; batch classifier loss: 0.423804; batch adversarial loss: 0.526706\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363023; batch adversarial loss: 0.544413\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375641; batch adversarial loss: 0.525660\n",
      "epoch 174; iter: 0; batch classifier loss: 0.419335; batch adversarial loss: 0.544362\n",
      "epoch 175; iter: 0; batch classifier loss: 0.341005; batch adversarial loss: 0.535289\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369521; batch adversarial loss: 0.580860\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339510; batch adversarial loss: 0.637062\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344907; batch adversarial loss: 0.563063\n",
      "epoch 179; iter: 0; batch classifier loss: 0.405499; batch adversarial loss: 0.536093\n",
      "epoch 180; iter: 0; batch classifier loss: 0.445528; batch adversarial loss: 0.481605\n",
      "epoch 181; iter: 0; batch classifier loss: 0.277109; batch adversarial loss: 0.571337\n",
      "epoch 182; iter: 0; batch classifier loss: 0.410393; batch adversarial loss: 0.571108\n",
      "epoch 183; iter: 0; batch classifier loss: 0.362224; batch adversarial loss: 0.643654\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371630; batch adversarial loss: 0.535424\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333725; batch adversarial loss: 0.525271\n",
      "epoch 186; iter: 0; batch classifier loss: 0.374492; batch adversarial loss: 0.571423\n",
      "epoch 187; iter: 0; batch classifier loss: 0.466916; batch adversarial loss: 0.571611\n",
      "epoch 188; iter: 0; batch classifier loss: 0.432633; batch adversarial loss: 0.590337\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345786; batch adversarial loss: 0.571822\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365324; batch adversarial loss: 0.499937\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336627; batch adversarial loss: 0.471449\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327322; batch adversarial loss: 0.479821\n",
      "epoch 193; iter: 0; batch classifier loss: 0.423586; batch adversarial loss: 0.517302\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353959; batch adversarial loss: 0.480138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359697; batch adversarial loss: 0.635502\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359247; batch adversarial loss: 0.543882\n",
      "epoch 197; iter: 0; batch classifier loss: 0.330895; batch adversarial loss: 0.526196\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384085; batch adversarial loss: 0.499319\n",
      "epoch 199; iter: 0; batch classifier loss: 0.372964; batch adversarial loss: 0.553924\n",
      "epoch 0; iter: 0; batch classifier loss: 1.007661; batch adversarial loss: 0.598570\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595123; batch adversarial loss: 0.682682\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605258; batch adversarial loss: 0.581775\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590580; batch adversarial loss: 0.604650\n",
      "epoch 4; iter: 0; batch classifier loss: 0.528667; batch adversarial loss: 0.623610\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527348; batch adversarial loss: 0.627909\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565236; batch adversarial loss: 0.563186\n",
      "epoch 7; iter: 0; batch classifier loss: 0.610462; batch adversarial loss: 0.581095\n",
      "epoch 8; iter: 0; batch classifier loss: 0.565558; batch adversarial loss: 0.590670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537881; batch adversarial loss: 0.627086\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547519; batch adversarial loss: 0.643391\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508467; batch adversarial loss: 0.551925\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469070; batch adversarial loss: 0.557862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575458; batch adversarial loss: 0.619482\n",
      "epoch 14; iter: 0; batch classifier loss: 0.604974; batch adversarial loss: 0.595400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.443535; batch adversarial loss: 0.561547\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533056; batch adversarial loss: 0.577454\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492348; batch adversarial loss: 0.626290\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483925; batch adversarial loss: 0.563161\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508514; batch adversarial loss: 0.572538\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525677; batch adversarial loss: 0.541518\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514949; batch adversarial loss: 0.538649\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509353; batch adversarial loss: 0.579437\n",
      "epoch 23; iter: 0; batch classifier loss: 0.587527; batch adversarial loss: 0.563251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448685; batch adversarial loss: 0.539973\n",
      "epoch 25; iter: 0; batch classifier loss: 0.559945; batch adversarial loss: 0.487090\n",
      "epoch 26; iter: 0; batch classifier loss: 0.553233; batch adversarial loss: 0.570163\n",
      "epoch 27; iter: 0; batch classifier loss: 0.527717; batch adversarial loss: 0.505373\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441056; batch adversarial loss: 0.532700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.465445; batch adversarial loss: 0.621925\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470086; batch adversarial loss: 0.622368\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476707; batch adversarial loss: 0.542796\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513005; batch adversarial loss: 0.501926\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469733; batch adversarial loss: 0.579083\n",
      "epoch 34; iter: 0; batch classifier loss: 0.550274; batch adversarial loss: 0.561972\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499900; batch adversarial loss: 0.615955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465459; batch adversarial loss: 0.670583\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414338; batch adversarial loss: 0.545290\n",
      "epoch 38; iter: 0; batch classifier loss: 0.507441; batch adversarial loss: 0.598588\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419920; batch adversarial loss: 0.490349\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412644; batch adversarial loss: 0.535560\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449922; batch adversarial loss: 0.562802\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416194; batch adversarial loss: 0.562787\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396576; batch adversarial loss: 0.599225\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406649; batch adversarial loss: 0.507283\n",
      "epoch 45; iter: 0; batch classifier loss: 0.510114; batch adversarial loss: 0.617987\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377716; batch adversarial loss: 0.607870\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451546; batch adversarial loss: 0.554011\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409915; batch adversarial loss: 0.562298\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385820; batch adversarial loss: 0.636590\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442033; batch adversarial loss: 0.636017\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425844; batch adversarial loss: 0.525366\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432260; batch adversarial loss: 0.590283\n",
      "epoch 53; iter: 0; batch classifier loss: 0.489194; batch adversarial loss: 0.599501\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399733; batch adversarial loss: 0.590317\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417522; batch adversarial loss: 0.553530\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457149; batch adversarial loss: 0.571776\n",
      "epoch 57; iter: 0; batch classifier loss: 0.491579; batch adversarial loss: 0.460828\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447262; batch adversarial loss: 0.507582\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378716; batch adversarial loss: 0.553902\n",
      "epoch 60; iter: 0; batch classifier loss: 0.494775; batch adversarial loss: 0.571206\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416831; batch adversarial loss: 0.507775\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436960; batch adversarial loss: 0.572281\n",
      "epoch 63; iter: 0; batch classifier loss: 0.480646; batch adversarial loss: 0.534201\n",
      "epoch 64; iter: 0; batch classifier loss: 0.455821; batch adversarial loss: 0.507031\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367576; batch adversarial loss: 0.564019\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382894; batch adversarial loss: 0.562824\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387860; batch adversarial loss: 0.655196\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428165; batch adversarial loss: 0.489303\n",
      "epoch 69; iter: 0; batch classifier loss: 0.391804; batch adversarial loss: 0.551976\n",
      "epoch 70; iter: 0; batch classifier loss: 0.360554; batch adversarial loss: 0.517273\n",
      "epoch 71; iter: 0; batch classifier loss: 0.433354; batch adversarial loss: 0.533995\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403708; batch adversarial loss: 0.544976\n",
      "epoch 73; iter: 0; batch classifier loss: 0.406096; batch adversarial loss: 0.524200\n",
      "epoch 74; iter: 0; batch classifier loss: 0.345423; batch adversarial loss: 0.553368\n",
      "epoch 75; iter: 0; batch classifier loss: 0.581858; batch adversarial loss: 0.562744\n",
      "epoch 76; iter: 0; batch classifier loss: 0.365158; batch adversarial loss: 0.479729\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424389; batch adversarial loss: 0.525495\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390903; batch adversarial loss: 0.655556\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377353; batch adversarial loss: 0.572608\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381717; batch adversarial loss: 0.561769\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370105; batch adversarial loss: 0.543631\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419534; batch adversarial loss: 0.616468\n",
      "epoch 83; iter: 0; batch classifier loss: 0.432733; batch adversarial loss: 0.588735\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429014; batch adversarial loss: 0.517966\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405101; batch adversarial loss: 0.545382\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424472; batch adversarial loss: 0.553442\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401273; batch adversarial loss: 0.555288\n",
      "epoch 88; iter: 0; batch classifier loss: 0.332312; batch adversarial loss: 0.573187\n",
      "epoch 89; iter: 0; batch classifier loss: 0.442339; batch adversarial loss: 0.508381\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434410; batch adversarial loss: 0.443214\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406952; batch adversarial loss: 0.471141\n",
      "epoch 92; iter: 0; batch classifier loss: 0.311445; batch adversarial loss: 0.507586\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438678; batch adversarial loss: 0.545544\n",
      "epoch 94; iter: 0; batch classifier loss: 0.444682; batch adversarial loss: 0.555089\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399630; batch adversarial loss: 0.535030\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336183; batch adversarial loss: 0.563295\n",
      "epoch 97; iter: 0; batch classifier loss: 0.470576; batch adversarial loss: 0.580440\n",
      "epoch 98; iter: 0; batch classifier loss: 0.314146; batch adversarial loss: 0.554340\n",
      "epoch 99; iter: 0; batch classifier loss: 0.446285; batch adversarial loss: 0.499923\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394334; batch adversarial loss: 0.554123\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386321; batch adversarial loss: 0.481038\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385300; batch adversarial loss: 0.588721\n",
      "epoch 103; iter: 0; batch classifier loss: 0.434123; batch adversarial loss: 0.524841\n",
      "epoch 104; iter: 0; batch classifier loss: 0.406683; batch adversarial loss: 0.535318\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359810; batch adversarial loss: 0.516998\n",
      "epoch 106; iter: 0; batch classifier loss: 0.493238; batch adversarial loss: 0.461487\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431979; batch adversarial loss: 0.544961\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370460; batch adversarial loss: 0.489258\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364887; batch adversarial loss: 0.525302\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363085; batch adversarial loss: 0.616342\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415997; batch adversarial loss: 0.543165\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362234; batch adversarial loss: 0.543527\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343360; batch adversarial loss: 0.543830\n",
      "epoch 114; iter: 0; batch classifier loss: 0.502142; batch adversarial loss: 0.527394\n",
      "epoch 115; iter: 0; batch classifier loss: 0.454937; batch adversarial loss: 0.525990\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348217; batch adversarial loss: 0.507580\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390553; batch adversarial loss: 0.506864\n",
      "epoch 118; iter: 0; batch classifier loss: 0.313644; batch adversarial loss: 0.533695\n",
      "epoch 119; iter: 0; batch classifier loss: 0.445870; batch adversarial loss: 0.517794\n",
      "epoch 120; iter: 0; batch classifier loss: 0.315262; batch adversarial loss: 0.574523\n",
      "epoch 121; iter: 0; batch classifier loss: 0.416074; batch adversarial loss: 0.525953\n",
      "epoch 122; iter: 0; batch classifier loss: 0.396877; batch adversarial loss: 0.544768\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403032; batch adversarial loss: 0.600726\n",
      "epoch 124; iter: 0; batch classifier loss: 0.433000; batch adversarial loss: 0.517279\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374149; batch adversarial loss: 0.525369\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399768; batch adversarial loss: 0.563437\n",
      "epoch 127; iter: 0; batch classifier loss: 0.315613; batch adversarial loss: 0.552988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.339526; batch adversarial loss: 0.515966\n",
      "epoch 129; iter: 0; batch classifier loss: 0.407291; batch adversarial loss: 0.562022\n",
      "epoch 130; iter: 0; batch classifier loss: 0.403395; batch adversarial loss: 0.498620\n",
      "epoch 131; iter: 0; batch classifier loss: 0.408387; batch adversarial loss: 0.516580\n",
      "epoch 132; iter: 0; batch classifier loss: 0.398406; batch adversarial loss: 0.572490\n",
      "epoch 133; iter: 0; batch classifier loss: 0.431353; batch adversarial loss: 0.544520\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371740; batch adversarial loss: 0.590615\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369103; batch adversarial loss: 0.480566\n",
      "epoch 136; iter: 0; batch classifier loss: 0.398732; batch adversarial loss: 0.515008\n",
      "epoch 137; iter: 0; batch classifier loss: 0.432079; batch adversarial loss: 0.580851\n",
      "epoch 138; iter: 0; batch classifier loss: 0.413871; batch adversarial loss: 0.498857\n",
      "epoch 139; iter: 0; batch classifier loss: 0.447687; batch adversarial loss: 0.509206\n",
      "epoch 140; iter: 0; batch classifier loss: 0.441900; batch adversarial loss: 0.517915\n",
      "epoch 141; iter: 0; batch classifier loss: 0.267182; batch adversarial loss: 0.544462\n",
      "epoch 142; iter: 0; batch classifier loss: 0.317472; batch adversarial loss: 0.506895\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350763; batch adversarial loss: 0.488823\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342341; batch adversarial loss: 0.535660\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381681; batch adversarial loss: 0.562728\n",
      "epoch 146; iter: 0; batch classifier loss: 0.413744; batch adversarial loss: 0.596676\n",
      "epoch 147; iter: 0; batch classifier loss: 0.432075; batch adversarial loss: 0.589510\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344243; batch adversarial loss: 0.534873\n",
      "epoch 149; iter: 0; batch classifier loss: 0.338681; batch adversarial loss: 0.601390\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355132; batch adversarial loss: 0.526539\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354412; batch adversarial loss: 0.480561\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403225; batch adversarial loss: 0.515796\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321567; batch adversarial loss: 0.525402\n",
      "epoch 154; iter: 0; batch classifier loss: 0.426869; batch adversarial loss: 0.534740\n",
      "epoch 155; iter: 0; batch classifier loss: 0.439363; batch adversarial loss: 0.517622\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334429; batch adversarial loss: 0.451486\n",
      "epoch 157; iter: 0; batch classifier loss: 0.430345; batch adversarial loss: 0.554249\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382568; batch adversarial loss: 0.551545\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400859; batch adversarial loss: 0.589748\n",
      "epoch 160; iter: 0; batch classifier loss: 0.354498; batch adversarial loss: 0.543647\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337744; batch adversarial loss: 0.526965\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327802; batch adversarial loss: 0.543788\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386800; batch adversarial loss: 0.526712\n",
      "epoch 164; iter: 0; batch classifier loss: 0.403040; batch adversarial loss: 0.598709\n",
      "epoch 165; iter: 0; batch classifier loss: 0.370960; batch adversarial loss: 0.561572\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331984; batch adversarial loss: 0.590889\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349195; batch adversarial loss: 0.526675\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344923; batch adversarial loss: 0.508067\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408415; batch adversarial loss: 0.508226\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335578; batch adversarial loss: 0.525017\n",
      "epoch 171; iter: 0; batch classifier loss: 0.311636; batch adversarial loss: 0.498896\n",
      "epoch 172; iter: 0; batch classifier loss: 0.284936; batch adversarial loss: 0.535361\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357476; batch adversarial loss: 0.487526\n",
      "epoch 174; iter: 0; batch classifier loss: 0.316373; batch adversarial loss: 0.527938\n",
      "epoch 175; iter: 0; batch classifier loss: 0.414677; batch adversarial loss: 0.552803\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329210; batch adversarial loss: 0.498777\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360788; batch adversarial loss: 0.580525\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361167; batch adversarial loss: 0.561706\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334727; batch adversarial loss: 0.526708\n",
      "epoch 180; iter: 0; batch classifier loss: 0.370850; batch adversarial loss: 0.647762\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376503; batch adversarial loss: 0.516099\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348389; batch adversarial loss: 0.527291\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330606; batch adversarial loss: 0.489877\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371397; batch adversarial loss: 0.562263\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369164; batch adversarial loss: 0.572197\n",
      "epoch 186; iter: 0; batch classifier loss: 0.428119; batch adversarial loss: 0.506867\n",
      "epoch 187; iter: 0; batch classifier loss: 0.314707; batch adversarial loss: 0.526062\n",
      "epoch 188; iter: 0; batch classifier loss: 0.388522; batch adversarial loss: 0.525976\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341852; batch adversarial loss: 0.564121\n",
      "epoch 190; iter: 0; batch classifier loss: 0.381384; batch adversarial loss: 0.518080\n",
      "epoch 191; iter: 0; batch classifier loss: 0.412526; batch adversarial loss: 0.553047\n",
      "epoch 192; iter: 0; batch classifier loss: 0.430160; batch adversarial loss: 0.554233\n",
      "epoch 193; iter: 0; batch classifier loss: 0.413882; batch adversarial loss: 0.588414\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390465; batch adversarial loss: 0.629506\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342542; batch adversarial loss: 0.507095\n",
      "epoch 196; iter: 0; batch classifier loss: 0.402757; batch adversarial loss: 0.479068\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358737; batch adversarial loss: 0.580691\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352951; batch adversarial loss: 0.616742\n",
      "epoch 199; iter: 0; batch classifier loss: 0.321786; batch adversarial loss: 0.489804\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701083; batch adversarial loss: 0.659611\n",
      "epoch 1; iter: 0; batch classifier loss: 0.636247; batch adversarial loss: 0.663603\n",
      "epoch 2; iter: 0; batch classifier loss: 0.549920; batch adversarial loss: 0.658651\n",
      "epoch 3; iter: 0; batch classifier loss: 0.490498; batch adversarial loss: 0.609139\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640473; batch adversarial loss: 0.623316\n",
      "epoch 5; iter: 0; batch classifier loss: 0.631527; batch adversarial loss: 0.606730\n",
      "epoch 6; iter: 0; batch classifier loss: 0.624982; batch adversarial loss: 0.594360\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601145; batch adversarial loss: 0.610792\n",
      "epoch 8; iter: 0; batch classifier loss: 0.663668; batch adversarial loss: 0.598787\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556756; batch adversarial loss: 0.580814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555115; batch adversarial loss: 0.528323\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576572; batch adversarial loss: 0.654838\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461260; batch adversarial loss: 0.588097\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528701; batch adversarial loss: 0.558844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564854; batch adversarial loss: 0.586030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505896; batch adversarial loss: 0.551944\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480167; batch adversarial loss: 0.590624\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517799; batch adversarial loss: 0.556073\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482493; batch adversarial loss: 0.588999\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506911; batch adversarial loss: 0.580630\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551758; batch adversarial loss: 0.633677\n",
      "epoch 21; iter: 0; batch classifier loss: 0.415239; batch adversarial loss: 0.524652\n",
      "epoch 22; iter: 0; batch classifier loss: 0.542511; batch adversarial loss: 0.552032\n",
      "epoch 23; iter: 0; batch classifier loss: 0.500648; batch adversarial loss: 0.637928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.461545; batch adversarial loss: 0.523087\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451746; batch adversarial loss: 0.571328\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517950; batch adversarial loss: 0.573265\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451055; batch adversarial loss: 0.579141\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481860; batch adversarial loss: 0.538325\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466208; batch adversarial loss: 0.545592\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439584; batch adversarial loss: 0.615441\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447015; batch adversarial loss: 0.553218\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453492; batch adversarial loss: 0.545633\n",
      "epoch 33; iter: 0; batch classifier loss: 0.367000; batch adversarial loss: 0.536579\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466277; batch adversarial loss: 0.624436\n",
      "epoch 35; iter: 0; batch classifier loss: 0.561743; batch adversarial loss: 0.562316\n",
      "epoch 36; iter: 0; batch classifier loss: 0.475838; batch adversarial loss: 0.544667\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480025; batch adversarial loss: 0.571467\n",
      "epoch 38; iter: 0; batch classifier loss: 0.493226; batch adversarial loss: 0.562757\n",
      "epoch 39; iter: 0; batch classifier loss: 0.518774; batch adversarial loss: 0.535861\n",
      "epoch 40; iter: 0; batch classifier loss: 0.368375; batch adversarial loss: 0.570959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.521615; batch adversarial loss: 0.553550\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429141; batch adversarial loss: 0.553833\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447262; batch adversarial loss: 0.589462\n",
      "epoch 44; iter: 0; batch classifier loss: 0.432372; batch adversarial loss: 0.489139\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448915; batch adversarial loss: 0.552651\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464830; batch adversarial loss: 0.552165\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487360; batch adversarial loss: 0.534139\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456152; batch adversarial loss: 0.487029\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464250; batch adversarial loss: 0.526938\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441740; batch adversarial loss: 0.543251\n",
      "epoch 51; iter: 0; batch classifier loss: 0.496589; batch adversarial loss: 0.516671\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461569; batch adversarial loss: 0.546516\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418568; batch adversarial loss: 0.573311\n",
      "epoch 54; iter: 0; batch classifier loss: 0.541941; batch adversarial loss: 0.479823\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394532; batch adversarial loss: 0.554774\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392351; batch adversarial loss: 0.554106\n",
      "epoch 57; iter: 0; batch classifier loss: 0.358185; batch adversarial loss: 0.572365\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394291; batch adversarial loss: 0.572055\n",
      "epoch 59; iter: 0; batch classifier loss: 0.396137; batch adversarial loss: 0.608265\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377338; batch adversarial loss: 0.591414\n",
      "epoch 61; iter: 0; batch classifier loss: 0.342674; batch adversarial loss: 0.588669\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399649; batch adversarial loss: 0.507907\n",
      "epoch 63; iter: 0; batch classifier loss: 0.382511; batch adversarial loss: 0.544357\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400970; batch adversarial loss: 0.607992\n",
      "epoch 65; iter: 0; batch classifier loss: 0.504720; batch adversarial loss: 0.545857\n",
      "epoch 66; iter: 0; batch classifier loss: 0.480516; batch adversarial loss: 0.454093\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444503; batch adversarial loss: 0.533785\n",
      "epoch 68; iter: 0; batch classifier loss: 0.480241; batch adversarial loss: 0.479450\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410797; batch adversarial loss: 0.479561\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447322; batch adversarial loss: 0.508803\n",
      "epoch 71; iter: 0; batch classifier loss: 0.443325; batch adversarial loss: 0.548461\n",
      "epoch 72; iter: 0; batch classifier loss: 0.470909; batch adversarial loss: 0.507867\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412849; batch adversarial loss: 0.549676\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415950; batch adversarial loss: 0.444637\n",
      "epoch 75; iter: 0; batch classifier loss: 0.350396; batch adversarial loss: 0.575302\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424899; batch adversarial loss: 0.545726\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388511; batch adversarial loss: 0.564169\n",
      "epoch 78; iter: 0; batch classifier loss: 0.499650; batch adversarial loss: 0.564448\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422875; batch adversarial loss: 0.515753\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414925; batch adversarial loss: 0.527042\n",
      "epoch 81; iter: 0; batch classifier loss: 0.372998; batch adversarial loss: 0.516939\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385570; batch adversarial loss: 0.544058\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398754; batch adversarial loss: 0.543796\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370544; batch adversarial loss: 0.625361\n",
      "epoch 85; iter: 0; batch classifier loss: 0.357664; batch adversarial loss: 0.601787\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440063; batch adversarial loss: 0.564315\n",
      "epoch 87; iter: 0; batch classifier loss: 0.362632; batch adversarial loss: 0.582682\n",
      "epoch 88; iter: 0; batch classifier loss: 0.508402; batch adversarial loss: 0.554102\n",
      "epoch 89; iter: 0; batch classifier loss: 0.372024; batch adversarial loss: 0.580356\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417503; batch adversarial loss: 0.543322\n",
      "epoch 91; iter: 0; batch classifier loss: 0.445816; batch adversarial loss: 0.571823\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395668; batch adversarial loss: 0.608773\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412841; batch adversarial loss: 0.610136\n",
      "epoch 94; iter: 0; batch classifier loss: 0.463540; batch adversarial loss: 0.599266\n",
      "epoch 95; iter: 0; batch classifier loss: 0.454594; batch adversarial loss: 0.572719\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395030; batch adversarial loss: 0.554673\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363011; batch adversarial loss: 0.617374\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382562; batch adversarial loss: 0.487793\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386545; batch adversarial loss: 0.655333\n",
      "epoch 100; iter: 0; batch classifier loss: 0.451091; batch adversarial loss: 0.526500\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362623; batch adversarial loss: 0.544392\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401604; batch adversarial loss: 0.544352\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369784; batch adversarial loss: 0.545847\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399150; batch adversarial loss: 0.598787\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372806; batch adversarial loss: 0.543565\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391509; batch adversarial loss: 0.531960\n",
      "epoch 107; iter: 0; batch classifier loss: 0.322504; batch adversarial loss: 0.544785\n",
      "epoch 108; iter: 0; batch classifier loss: 0.462653; batch adversarial loss: 0.599467\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388063; batch adversarial loss: 0.554878\n",
      "epoch 110; iter: 0; batch classifier loss: 0.312910; batch adversarial loss: 0.562460\n",
      "epoch 111; iter: 0; batch classifier loss: 0.464265; batch adversarial loss: 0.572235\n",
      "epoch 112; iter: 0; batch classifier loss: 0.439982; batch adversarial loss: 0.564198\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399326; batch adversarial loss: 0.545661\n",
      "epoch 114; iter: 0; batch classifier loss: 0.433076; batch adversarial loss: 0.480841\n",
      "epoch 115; iter: 0; batch classifier loss: 0.375796; batch adversarial loss: 0.461269\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413923; batch adversarial loss: 0.508668\n",
      "epoch 117; iter: 0; batch classifier loss: 0.355194; batch adversarial loss: 0.560779\n",
      "epoch 118; iter: 0; batch classifier loss: 0.408240; batch adversarial loss: 0.517504\n",
      "epoch 119; iter: 0; batch classifier loss: 0.444298; batch adversarial loss: 0.562967\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374034; batch adversarial loss: 0.507980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403427; batch adversarial loss: 0.542566\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365008; batch adversarial loss: 0.471456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.431943; batch adversarial loss: 0.481563\n",
      "epoch 124; iter: 0; batch classifier loss: 0.419849; batch adversarial loss: 0.481184\n",
      "epoch 125; iter: 0; batch classifier loss: 0.426882; batch adversarial loss: 0.546012\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387220; batch adversarial loss: 0.501005\n",
      "epoch 127; iter: 0; batch classifier loss: 0.328385; batch adversarial loss: 0.481530\n",
      "epoch 128; iter: 0; batch classifier loss: 0.333336; batch adversarial loss: 0.506849\n",
      "epoch 129; iter: 0; batch classifier loss: 0.499314; batch adversarial loss: 0.507564\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373713; batch adversarial loss: 0.491171\n",
      "epoch 131; iter: 0; batch classifier loss: 0.370927; batch adversarial loss: 0.516343\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349488; batch adversarial loss: 0.534911\n",
      "epoch 133; iter: 0; batch classifier loss: 0.419450; batch adversarial loss: 0.597887\n",
      "epoch 134; iter: 0; batch classifier loss: 0.448971; batch adversarial loss: 0.509444\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370492; batch adversarial loss: 0.508284\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375403; batch adversarial loss: 0.497888\n",
      "epoch 137; iter: 0; batch classifier loss: 0.436451; batch adversarial loss: 0.553072\n",
      "epoch 138; iter: 0; batch classifier loss: 0.420511; batch adversarial loss: 0.637941\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359486; batch adversarial loss: 0.553516\n",
      "epoch 140; iter: 0; batch classifier loss: 0.411139; batch adversarial loss: 0.579483\n",
      "epoch 141; iter: 0; batch classifier loss: 0.423692; batch adversarial loss: 0.508551\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408506; batch adversarial loss: 0.554729\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397418; batch adversarial loss: 0.590615\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395198; batch adversarial loss: 0.564465\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376851; batch adversarial loss: 0.590891\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410489; batch adversarial loss: 0.626956\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353299; batch adversarial loss: 0.498434\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337662; batch adversarial loss: 0.533764\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382247; batch adversarial loss: 0.461664\n",
      "epoch 150; iter: 0; batch classifier loss: 0.435016; batch adversarial loss: 0.535457\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361802; batch adversarial loss: 0.526926\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369819; batch adversarial loss: 0.599672\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333547; batch adversarial loss: 0.506105\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385238; batch adversarial loss: 0.563088\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401442; batch adversarial loss: 0.561346\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370906; batch adversarial loss: 0.643995\n",
      "epoch 157; iter: 0; batch classifier loss: 0.389018; batch adversarial loss: 0.542342\n",
      "epoch 158; iter: 0; batch classifier loss: 0.423769; batch adversarial loss: 0.543702\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373957; batch adversarial loss: 0.539013\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358573; batch adversarial loss: 0.562268\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362919; batch adversarial loss: 0.579652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355884; batch adversarial loss: 0.542967\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345102; batch adversarial loss: 0.535376\n",
      "epoch 164; iter: 0; batch classifier loss: 0.318184; batch adversarial loss: 0.517609\n",
      "epoch 165; iter: 0; batch classifier loss: 0.363272; batch adversarial loss: 0.573476\n",
      "epoch 166; iter: 0; batch classifier loss: 0.348042; batch adversarial loss: 0.535449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358029; batch adversarial loss: 0.490181\n",
      "epoch 168; iter: 0; batch classifier loss: 0.429038; batch adversarial loss: 0.525310\n",
      "epoch 169; iter: 0; batch classifier loss: 0.444034; batch adversarial loss: 0.608420\n",
      "epoch 170; iter: 0; batch classifier loss: 0.278693; batch adversarial loss: 0.580919\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374430; batch adversarial loss: 0.490884\n",
      "epoch 172; iter: 0; batch classifier loss: 0.412951; batch adversarial loss: 0.571674\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355812; batch adversarial loss: 0.516282\n",
      "epoch 174; iter: 0; batch classifier loss: 0.468739; batch adversarial loss: 0.554294\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325808; batch adversarial loss: 0.616411\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380051; batch adversarial loss: 0.601215\n",
      "epoch 177; iter: 0; batch classifier loss: 0.432153; batch adversarial loss: 0.572303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.295708; batch adversarial loss: 0.600433\n",
      "epoch 179; iter: 0; batch classifier loss: 0.432498; batch adversarial loss: 0.570991\n",
      "epoch 180; iter: 0; batch classifier loss: 0.469337; batch adversarial loss: 0.610316\n",
      "epoch 181; iter: 0; batch classifier loss: 0.426449; batch adversarial loss: 0.479434\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374086; batch adversarial loss: 0.487868\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393351; batch adversarial loss: 0.489110\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401108; batch adversarial loss: 0.506440\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333095; batch adversarial loss: 0.618965\n",
      "epoch 186; iter: 0; batch classifier loss: 0.369951; batch adversarial loss: 0.592481\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332076; batch adversarial loss: 0.524728\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365371; batch adversarial loss: 0.527588\n",
      "epoch 189; iter: 0; batch classifier loss: 0.373066; batch adversarial loss: 0.618512\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351914; batch adversarial loss: 0.527558\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389240; batch adversarial loss: 0.635939\n",
      "epoch 192; iter: 0; batch classifier loss: 0.374212; batch adversarial loss: 0.546005\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336335; batch adversarial loss: 0.571272\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340692; batch adversarial loss: 0.544284\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309417; batch adversarial loss: 0.526485\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312379; batch adversarial loss: 0.534403\n",
      "epoch 197; iter: 0; batch classifier loss: 0.313305; batch adversarial loss: 0.579667\n",
      "epoch 198; iter: 0; batch classifier loss: 0.318179; batch adversarial loss: 0.535672\n",
      "epoch 199; iter: 0; batch classifier loss: 0.394741; batch adversarial loss: 0.478514\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667212; batch adversarial loss: 0.793085\n",
      "epoch 1; iter: 0; batch classifier loss: 0.871040; batch adversarial loss: 1.065304\n",
      "epoch 2; iter: 0; batch classifier loss: 1.005864; batch adversarial loss: 0.974013\n",
      "epoch 3; iter: 0; batch classifier loss: 1.076109; batch adversarial loss: 0.928396\n",
      "epoch 4; iter: 0; batch classifier loss: 1.014052; batch adversarial loss: 0.851795\n",
      "epoch 5; iter: 0; batch classifier loss: 0.789862; batch adversarial loss: 0.751282\n",
      "epoch 6; iter: 0; batch classifier loss: 0.890021; batch adversarial loss: 0.735657\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626883; batch adversarial loss: 0.651554\n",
      "epoch 8; iter: 0; batch classifier loss: 0.600209; batch adversarial loss: 0.611645\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557379; batch adversarial loss: 0.634674\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518605; batch adversarial loss: 0.612317\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523501; batch adversarial loss: 0.557471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567820; batch adversarial loss: 0.594683\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522445; batch adversarial loss: 0.607450\n",
      "epoch 14; iter: 0; batch classifier loss: 0.581895; batch adversarial loss: 0.567697\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504946; batch adversarial loss: 0.541981\n",
      "epoch 16; iter: 0; batch classifier loss: 0.582300; batch adversarial loss: 0.604861\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526108; batch adversarial loss: 0.575699\n",
      "epoch 18; iter: 0; batch classifier loss: 0.510578; batch adversarial loss: 0.583995\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430450; batch adversarial loss: 0.525760\n",
      "epoch 20; iter: 0; batch classifier loss: 0.571795; batch adversarial loss: 0.643577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.496895; batch adversarial loss: 0.564473\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490874; batch adversarial loss: 0.631499\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519307; batch adversarial loss: 0.582565\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514365; batch adversarial loss: 0.563683\n",
      "epoch 25; iter: 0; batch classifier loss: 0.586942; batch adversarial loss: 0.570143\n",
      "epoch 26; iter: 0; batch classifier loss: 0.533507; batch adversarial loss: 0.502013\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501544; batch adversarial loss: 0.524007\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421074; batch adversarial loss: 0.489194\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477043; batch adversarial loss: 0.585642\n",
      "epoch 30; iter: 0; batch classifier loss: 0.539420; batch adversarial loss: 0.617181\n",
      "epoch 31; iter: 0; batch classifier loss: 0.434096; batch adversarial loss: 0.557546\n",
      "epoch 32; iter: 0; batch classifier loss: 0.416108; batch adversarial loss: 0.596950\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474523; batch adversarial loss: 0.499403\n",
      "epoch 34; iter: 0; batch classifier loss: 0.562167; batch adversarial loss: 0.488934\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443912; batch adversarial loss: 0.640855\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503645; batch adversarial loss: 0.556607\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447259; batch adversarial loss: 0.583220\n",
      "epoch 38; iter: 0; batch classifier loss: 0.355798; batch adversarial loss: 0.533897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436983; batch adversarial loss: 0.551646\n",
      "epoch 40; iter: 0; batch classifier loss: 0.415419; batch adversarial loss: 0.550125\n",
      "epoch 41; iter: 0; batch classifier loss: 0.510568; batch adversarial loss: 0.557379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.531716; batch adversarial loss: 0.607462\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447086; batch adversarial loss: 0.558794\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424560; batch adversarial loss: 0.500535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.508819; batch adversarial loss: 0.567466\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388312; batch adversarial loss: 0.456694\n",
      "epoch 47; iter: 0; batch classifier loss: 0.372041; batch adversarial loss: 0.545548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.514469; batch adversarial loss: 0.567771\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430333; batch adversarial loss: 0.542360\n",
      "epoch 50; iter: 0; batch classifier loss: 0.484892; batch adversarial loss: 0.555881\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425623; batch adversarial loss: 0.611236\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458521; batch adversarial loss: 0.484109\n",
      "epoch 53; iter: 0; batch classifier loss: 0.471566; batch adversarial loss: 0.580343\n",
      "epoch 54; iter: 0; batch classifier loss: 0.470367; batch adversarial loss: 0.602706\n",
      "epoch 55; iter: 0; batch classifier loss: 0.418630; batch adversarial loss: 0.508001\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428320; batch adversarial loss: 0.603404\n",
      "epoch 57; iter: 0; batch classifier loss: 0.364492; batch adversarial loss: 0.581699\n",
      "epoch 58; iter: 0; batch classifier loss: 0.475064; batch adversarial loss: 0.561194\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388049; batch adversarial loss: 0.533862\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373903; batch adversarial loss: 0.590294\n",
      "epoch 61; iter: 0; batch classifier loss: 0.487321; batch adversarial loss: 0.617672\n",
      "epoch 62; iter: 0; batch classifier loss: 0.356261; batch adversarial loss: 0.525199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423192; batch adversarial loss: 0.608347\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406634; batch adversarial loss: 0.554088\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425709; batch adversarial loss: 0.517503\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416884; batch adversarial loss: 0.563582\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399941; batch adversarial loss: 0.516366\n",
      "epoch 68; iter: 0; batch classifier loss: 0.464029; batch adversarial loss: 0.498574\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442050; batch adversarial loss: 0.499272\n",
      "epoch 70; iter: 0; batch classifier loss: 0.351636; batch adversarial loss: 0.535623\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384702; batch adversarial loss: 0.507207\n",
      "epoch 72; iter: 0; batch classifier loss: 0.495041; batch adversarial loss: 0.581870\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423726; batch adversarial loss: 0.515051\n",
      "epoch 74; iter: 0; batch classifier loss: 0.377039; batch adversarial loss: 0.618105\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407948; batch adversarial loss: 0.516587\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402740; batch adversarial loss: 0.581940\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416182; batch adversarial loss: 0.591206\n",
      "epoch 78; iter: 0; batch classifier loss: 0.432187; batch adversarial loss: 0.489407\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424903; batch adversarial loss: 0.563370\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430433; batch adversarial loss: 0.581863\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390711; batch adversarial loss: 0.498322\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419159; batch adversarial loss: 0.609762\n",
      "epoch 83; iter: 0; batch classifier loss: 0.424500; batch adversarial loss: 0.544295\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354461; batch adversarial loss: 0.525556\n",
      "epoch 85; iter: 0; batch classifier loss: 0.450822; batch adversarial loss: 0.553485\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428185; batch adversarial loss: 0.553988\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396318; batch adversarial loss: 0.571505\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418287; batch adversarial loss: 0.526525\n",
      "epoch 89; iter: 0; batch classifier loss: 0.461529; batch adversarial loss: 0.534901\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415092; batch adversarial loss: 0.554115\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370221; batch adversarial loss: 0.554500\n",
      "epoch 92; iter: 0; batch classifier loss: 0.343361; batch adversarial loss: 0.581017\n",
      "epoch 93; iter: 0; batch classifier loss: 0.461176; batch adversarial loss: 0.525840\n",
      "epoch 94; iter: 0; batch classifier loss: 0.353336; batch adversarial loss: 0.526396\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381272; batch adversarial loss: 0.452035\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361874; batch adversarial loss: 0.554862\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396177; batch adversarial loss: 0.536015\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382666; batch adversarial loss: 0.498970\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409360; batch adversarial loss: 0.516688\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403489; batch adversarial loss: 0.488540\n",
      "epoch 101; iter: 0; batch classifier loss: 0.492985; batch adversarial loss: 0.499854\n",
      "epoch 102; iter: 0; batch classifier loss: 0.328118; batch adversarial loss: 0.498854\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438207; batch adversarial loss: 0.582549\n",
      "epoch 104; iter: 0; batch classifier loss: 0.330471; batch adversarial loss: 0.515767\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337896; batch adversarial loss: 0.561882\n",
      "epoch 106; iter: 0; batch classifier loss: 0.477244; batch adversarial loss: 0.507184\n",
      "epoch 107; iter: 0; batch classifier loss: 0.333588; batch adversarial loss: 0.460837\n",
      "epoch 108; iter: 0; batch classifier loss: 0.425726; batch adversarial loss: 0.515956\n",
      "epoch 109; iter: 0; batch classifier loss: 0.336509; batch adversarial loss: 0.535446\n",
      "epoch 110; iter: 0; batch classifier loss: 0.493757; batch adversarial loss: 0.443233\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344006; batch adversarial loss: 0.489228\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411262; batch adversarial loss: 0.553141\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395929; batch adversarial loss: 0.562262\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372614; batch adversarial loss: 0.544249\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380420; batch adversarial loss: 0.535970\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319591; batch adversarial loss: 0.571959\n",
      "epoch 117; iter: 0; batch classifier loss: 0.418780; batch adversarial loss: 0.637352\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356404; batch adversarial loss: 0.563482\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370815; batch adversarial loss: 0.563093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.391021; batch adversarial loss: 0.488651\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319414; batch adversarial loss: 0.478994\n",
      "epoch 122; iter: 0; batch classifier loss: 0.411010; batch adversarial loss: 0.563555\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357821; batch adversarial loss: 0.480675\n",
      "epoch 124; iter: 0; batch classifier loss: 0.323604; batch adversarial loss: 0.507916\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346440; batch adversarial loss: 0.479099\n",
      "epoch 126; iter: 0; batch classifier loss: 0.333859; batch adversarial loss: 0.534780\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355119; batch adversarial loss: 0.479803\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343473; batch adversarial loss: 0.562869\n",
      "epoch 129; iter: 0; batch classifier loss: 0.427623; batch adversarial loss: 0.534296\n",
      "epoch 130; iter: 0; batch classifier loss: 0.443440; batch adversarial loss: 0.516078\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348688; batch adversarial loss: 0.498090\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373630; batch adversarial loss: 0.553604\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361572; batch adversarial loss: 0.645827\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350930; batch adversarial loss: 0.581288\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347222; batch adversarial loss: 0.582160\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373540; batch adversarial loss: 0.544817\n",
      "epoch 137; iter: 0; batch classifier loss: 0.437734; batch adversarial loss: 0.581013\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373000; batch adversarial loss: 0.581231\n",
      "epoch 139; iter: 0; batch classifier loss: 0.447784; batch adversarial loss: 0.554705\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358893; batch adversarial loss: 0.617254\n",
      "epoch 141; iter: 0; batch classifier loss: 0.362530; batch adversarial loss: 0.526932\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367003; batch adversarial loss: 0.591125\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360156; batch adversarial loss: 0.507128\n",
      "epoch 144; iter: 0; batch classifier loss: 0.394437; batch adversarial loss: 0.618697\n",
      "epoch 145; iter: 0; batch classifier loss: 0.322340; batch adversarial loss: 0.544231\n",
      "epoch 146; iter: 0; batch classifier loss: 0.333911; batch adversarial loss: 0.562210\n",
      "epoch 147; iter: 0; batch classifier loss: 0.398751; batch adversarial loss: 0.497820\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410215; batch adversarial loss: 0.562616\n",
      "epoch 149; iter: 0; batch classifier loss: 0.305273; batch adversarial loss: 0.580789\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326526; batch adversarial loss: 0.544703\n",
      "epoch 151; iter: 0; batch classifier loss: 0.394040; batch adversarial loss: 0.637272\n",
      "epoch 152; iter: 0; batch classifier loss: 0.393921; batch adversarial loss: 0.516997\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336820; batch adversarial loss: 0.581391\n",
      "epoch 154; iter: 0; batch classifier loss: 0.272973; batch adversarial loss: 0.544911\n",
      "epoch 155; iter: 0; batch classifier loss: 0.333297; batch adversarial loss: 0.600963\n",
      "epoch 156; iter: 0; batch classifier loss: 0.320432; batch adversarial loss: 0.488454\n",
      "epoch 157; iter: 0; batch classifier loss: 0.382590; batch adversarial loss: 0.581877\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319782; batch adversarial loss: 0.488206\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398497; batch adversarial loss: 0.526390\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345272; batch adversarial loss: 0.590678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.371919; batch adversarial loss: 0.526219\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313677; batch adversarial loss: 0.488134\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334027; batch adversarial loss: 0.553291\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348972; batch adversarial loss: 0.526134\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326569; batch adversarial loss: 0.526436\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354966; batch adversarial loss: 0.600189\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409979; batch adversarial loss: 0.498321\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398453; batch adversarial loss: 0.525710\n",
      "epoch 169; iter: 0; batch classifier loss: 0.303639; batch adversarial loss: 0.534246\n",
      "epoch 170; iter: 0; batch classifier loss: 0.432624; batch adversarial loss: 0.442886\n",
      "epoch 171; iter: 0; batch classifier loss: 0.412800; batch adversarial loss: 0.497931\n",
      "epoch 172; iter: 0; batch classifier loss: 0.316743; batch adversarial loss: 0.553948\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322688; batch adversarial loss: 0.562214\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363199; batch adversarial loss: 0.544888\n",
      "epoch 175; iter: 0; batch classifier loss: 0.282840; batch adversarial loss: 0.571746\n",
      "epoch 176; iter: 0; batch classifier loss: 0.401506; batch adversarial loss: 0.517591\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347273; batch adversarial loss: 0.516139\n",
      "epoch 178; iter: 0; batch classifier loss: 0.373599; batch adversarial loss: 0.471057\n",
      "epoch 179; iter: 0; batch classifier loss: 0.267397; batch adversarial loss: 0.582690\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414715; batch adversarial loss: 0.572180\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374292; batch adversarial loss: 0.524973\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380966; batch adversarial loss: 0.544807\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338837; batch adversarial loss: 0.609268\n",
      "epoch 184; iter: 0; batch classifier loss: 0.417165; batch adversarial loss: 0.534878\n",
      "epoch 185; iter: 0; batch classifier loss: 0.374284; batch adversarial loss: 0.609965\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399306; batch adversarial loss: 0.627035\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361517; batch adversarial loss: 0.553880\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328651; batch adversarial loss: 0.571624\n",
      "epoch 189; iter: 0; batch classifier loss: 0.329481; batch adversarial loss: 0.600004\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343892; batch adversarial loss: 0.535328\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359837; batch adversarial loss: 0.562729\n",
      "epoch 192; iter: 0; batch classifier loss: 0.392821; batch adversarial loss: 0.563119\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329509; batch adversarial loss: 0.619020\n",
      "epoch 194; iter: 0; batch classifier loss: 0.291652; batch adversarial loss: 0.562107\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361477; batch adversarial loss: 0.580932\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335506; batch adversarial loss: 0.554130\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357996; batch adversarial loss: 0.442800\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372308; batch adversarial loss: 0.479995\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396890; batch adversarial loss: 0.591107\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677831; batch adversarial loss: 0.639266\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613940; batch adversarial loss: 0.648567\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585670; batch adversarial loss: 0.679405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530462; batch adversarial loss: 0.642524\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572094; batch adversarial loss: 0.660083\n",
      "epoch 5; iter: 0; batch classifier loss: 0.542404; batch adversarial loss: 0.631665\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561226; batch adversarial loss: 0.629955\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454170; batch adversarial loss: 0.592263\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514058; batch adversarial loss: 0.591974\n",
      "epoch 9; iter: 0; batch classifier loss: 0.483587; batch adversarial loss: 0.560366\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553791; batch adversarial loss: 0.616418\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545831; batch adversarial loss: 0.607609\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519169; batch adversarial loss: 0.571375\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555165; batch adversarial loss: 0.580799\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511935; batch adversarial loss: 0.551006\n",
      "epoch 15; iter: 0; batch classifier loss: 0.446459; batch adversarial loss: 0.564229\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500381; batch adversarial loss: 0.542477\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496324; batch adversarial loss: 0.622892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.537857; batch adversarial loss: 0.576700\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509446; batch adversarial loss: 0.563326\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387645; batch adversarial loss: 0.498745\n",
      "epoch 21; iter: 0; batch classifier loss: 0.433563; batch adversarial loss: 0.531578\n",
      "epoch 22; iter: 0; batch classifier loss: 0.511390; batch adversarial loss: 0.555246\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468465; batch adversarial loss: 0.609673\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434627; batch adversarial loss: 0.550888\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525295; batch adversarial loss: 0.489409\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497307; batch adversarial loss: 0.538163\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477526; batch adversarial loss: 0.520308\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446220; batch adversarial loss: 0.553197\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430891; batch adversarial loss: 0.606222\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438668; batch adversarial loss: 0.545707\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506110; batch adversarial loss: 0.563248\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431260; batch adversarial loss: 0.518675\n",
      "epoch 33; iter: 0; batch classifier loss: 0.479875; batch adversarial loss: 0.571468\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421972; batch adversarial loss: 0.544714\n",
      "epoch 35; iter: 0; batch classifier loss: 0.495420; batch adversarial loss: 0.517845\n",
      "epoch 36; iter: 0; batch classifier loss: 0.475589; batch adversarial loss: 0.562857\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441994; batch adversarial loss: 0.553681\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442904; batch adversarial loss: 0.588843\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455394; batch adversarial loss: 0.560910\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476177; batch adversarial loss: 0.543823\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454448; batch adversarial loss: 0.484589\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465301; batch adversarial loss: 0.448068\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439183; batch adversarial loss: 0.592953\n",
      "epoch 44; iter: 0; batch classifier loss: 0.520262; batch adversarial loss: 0.566921\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392545; batch adversarial loss: 0.476634\n",
      "epoch 46; iter: 0; batch classifier loss: 0.456006; batch adversarial loss: 0.577290\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435353; batch adversarial loss: 0.593221\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452485; batch adversarial loss: 0.547123\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376901; batch adversarial loss: 0.563629\n",
      "epoch 50; iter: 0; batch classifier loss: 0.347887; batch adversarial loss: 0.554257\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397105; batch adversarial loss: 0.571728\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415965; batch adversarial loss: 0.633591\n",
      "epoch 53; iter: 0; batch classifier loss: 0.501015; batch adversarial loss: 0.510436\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405891; batch adversarial loss: 0.521136\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398030; batch adversarial loss: 0.539559\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412257; batch adversarial loss: 0.546531\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424352; batch adversarial loss: 0.546096\n",
      "epoch 58; iter: 0; batch classifier loss: 0.373211; batch adversarial loss: 0.535448\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445182; batch adversarial loss: 0.516154\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388763; batch adversarial loss: 0.497544\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416665; batch adversarial loss: 0.516919\n",
      "epoch 62; iter: 0; batch classifier loss: 0.313816; batch adversarial loss: 0.554067\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381393; batch adversarial loss: 0.642699\n",
      "epoch 64; iter: 0; batch classifier loss: 0.433382; batch adversarial loss: 0.552541\n",
      "epoch 65; iter: 0; batch classifier loss: 0.472364; batch adversarial loss: 0.515937\n",
      "epoch 66; iter: 0; batch classifier loss: 0.372941; batch adversarial loss: 0.523687\n",
      "epoch 67; iter: 0; batch classifier loss: 0.370131; batch adversarial loss: 0.569463\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423842; batch adversarial loss: 0.524885\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433624; batch adversarial loss: 0.554730\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417736; batch adversarial loss: 0.549069\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376728; batch adversarial loss: 0.620367\n",
      "epoch 72; iter: 0; batch classifier loss: 0.491334; batch adversarial loss: 0.548389\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446422; batch adversarial loss: 0.580458\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384168; batch adversarial loss: 0.536807\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438527; batch adversarial loss: 0.553980\n",
      "epoch 76; iter: 0; batch classifier loss: 0.361236; batch adversarial loss: 0.494426\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429065; batch adversarial loss: 0.453667\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397197; batch adversarial loss: 0.527827\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419527; batch adversarial loss: 0.663954\n",
      "epoch 80; iter: 0; batch classifier loss: 0.337599; batch adversarial loss: 0.482492\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397315; batch adversarial loss: 0.580612\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408660; batch adversarial loss: 0.589993\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423079; batch adversarial loss: 0.536501\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360836; batch adversarial loss: 0.580087\n",
      "epoch 85; iter: 0; batch classifier loss: 0.417859; batch adversarial loss: 0.652465\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418765; batch adversarial loss: 0.582295\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368293; batch adversarial loss: 0.540611\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420963; batch adversarial loss: 0.500684\n",
      "epoch 89; iter: 0; batch classifier loss: 0.344386; batch adversarial loss: 0.552828\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367758; batch adversarial loss: 0.577863\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410757; batch adversarial loss: 0.536177\n",
      "epoch 92; iter: 0; batch classifier loss: 0.426102; batch adversarial loss: 0.522901\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357947; batch adversarial loss: 0.516874\n",
      "epoch 94; iter: 0; batch classifier loss: 0.321047; batch adversarial loss: 0.520868\n",
      "epoch 95; iter: 0; batch classifier loss: 0.367440; batch adversarial loss: 0.542183\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376752; batch adversarial loss: 0.478706\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410643; batch adversarial loss: 0.589208\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378863; batch adversarial loss: 0.531491\n",
      "epoch 99; iter: 0; batch classifier loss: 0.374774; batch adversarial loss: 0.544967\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410514; batch adversarial loss: 0.533916\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393477; batch adversarial loss: 0.608961\n",
      "epoch 102; iter: 0; batch classifier loss: 0.497901; batch adversarial loss: 0.519967\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350749; batch adversarial loss: 0.582156\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351918; batch adversarial loss: 0.535907\n",
      "epoch 105; iter: 0; batch classifier loss: 0.467158; batch adversarial loss: 0.459572\n",
      "epoch 106; iter: 0; batch classifier loss: 0.332790; batch adversarial loss: 0.572235\n",
      "epoch 107; iter: 0; batch classifier loss: 0.426670; batch adversarial loss: 0.508389\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371408; batch adversarial loss: 0.498019\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400163; batch adversarial loss: 0.582032\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370229; batch adversarial loss: 0.608806\n",
      "epoch 111; iter: 0; batch classifier loss: 0.399846; batch adversarial loss: 0.508288\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403329; batch adversarial loss: 0.472875\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386946; batch adversarial loss: 0.571864\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392032; batch adversarial loss: 0.571291\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343267; batch adversarial loss: 0.544587\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394073; batch adversarial loss: 0.553775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.380815; batch adversarial loss: 0.534422\n",
      "epoch 118; iter: 0; batch classifier loss: 0.312658; batch adversarial loss: 0.532965\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369365; batch adversarial loss: 0.530232\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422329; batch adversarial loss: 0.527737\n",
      "epoch 121; iter: 0; batch classifier loss: 0.417626; batch adversarial loss: 0.545873\n",
      "epoch 122; iter: 0; batch classifier loss: 0.349884; batch adversarial loss: 0.553588\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379255; batch adversarial loss: 0.598261\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366036; batch adversarial loss: 0.454979\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329827; batch adversarial loss: 0.499598\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338915; batch adversarial loss: 0.565254\n",
      "epoch 127; iter: 0; batch classifier loss: 0.442203; batch adversarial loss: 0.534380\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344905; batch adversarial loss: 0.536670\n",
      "epoch 129; iter: 0; batch classifier loss: 0.410873; batch adversarial loss: 0.591138\n",
      "epoch 130; iter: 0; batch classifier loss: 0.319820; batch adversarial loss: 0.528777\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364501; batch adversarial loss: 0.609074\n",
      "epoch 132; iter: 0; batch classifier loss: 0.399950; batch adversarial loss: 0.610680\n",
      "epoch 133; iter: 0; batch classifier loss: 0.342877; batch adversarial loss: 0.564724\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365229; batch adversarial loss: 0.581335\n",
      "epoch 135; iter: 0; batch classifier loss: 0.329166; batch adversarial loss: 0.598177\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406548; batch adversarial loss: 0.599554\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334172; batch adversarial loss: 0.498889\n",
      "epoch 138; iter: 0; batch classifier loss: 0.374034; batch adversarial loss: 0.489757\n",
      "epoch 139; iter: 0; batch classifier loss: 0.504883; batch adversarial loss: 0.560417\n",
      "epoch 140; iter: 0; batch classifier loss: 0.439869; batch adversarial loss: 0.471870\n",
      "epoch 141; iter: 0; batch classifier loss: 0.374801; batch adversarial loss: 0.526171\n",
      "epoch 142; iter: 0; batch classifier loss: 0.394022; batch adversarial loss: 0.500462\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328165; batch adversarial loss: 0.532589\n",
      "epoch 144; iter: 0; batch classifier loss: 0.321590; batch adversarial loss: 0.513820\n",
      "epoch 145; iter: 0; batch classifier loss: 0.410390; batch adversarial loss: 0.587596\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373419; batch adversarial loss: 0.562407\n",
      "epoch 147; iter: 0; batch classifier loss: 0.331968; batch adversarial loss: 0.574787\n",
      "epoch 148; iter: 0; batch classifier loss: 0.326113; batch adversarial loss: 0.582486\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359676; batch adversarial loss: 0.590084\n",
      "epoch 150; iter: 0; batch classifier loss: 0.284557; batch adversarial loss: 0.536613\n",
      "epoch 151; iter: 0; batch classifier loss: 0.389210; batch adversarial loss: 0.442457\n",
      "epoch 152; iter: 0; batch classifier loss: 0.418736; batch adversarial loss: 0.444605\n",
      "epoch 153; iter: 0; batch classifier loss: 0.390889; batch adversarial loss: 0.508896\n",
      "epoch 154; iter: 0; batch classifier loss: 0.387608; batch adversarial loss: 0.597132\n",
      "epoch 155; iter: 0; batch classifier loss: 0.332667; batch adversarial loss: 0.558489\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355276; batch adversarial loss: 0.569188\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326259; batch adversarial loss: 0.526727\n",
      "epoch 158; iter: 0; batch classifier loss: 0.308211; batch adversarial loss: 0.536634\n",
      "epoch 159; iter: 0; batch classifier loss: 0.310342; batch adversarial loss: 0.500633\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349445; batch adversarial loss: 0.552743\n",
      "epoch 161; iter: 0; batch classifier loss: 0.420384; batch adversarial loss: 0.601544\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331538; batch adversarial loss: 0.627228\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391605; batch adversarial loss: 0.609539\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333882; batch adversarial loss: 0.555682\n",
      "epoch 165; iter: 0; batch classifier loss: 0.381099; batch adversarial loss: 0.478991\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312060; batch adversarial loss: 0.525618\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370628; batch adversarial loss: 0.531135\n",
      "epoch 168; iter: 0; batch classifier loss: 0.421110; batch adversarial loss: 0.528644\n",
      "epoch 169; iter: 0; batch classifier loss: 0.338727; batch adversarial loss: 0.496712\n",
      "epoch 170; iter: 0; batch classifier loss: 0.412970; batch adversarial loss: 0.537641\n",
      "epoch 171; iter: 0; batch classifier loss: 0.432524; batch adversarial loss: 0.499460\n",
      "epoch 172; iter: 0; batch classifier loss: 0.438170; batch adversarial loss: 0.598906\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357904; batch adversarial loss: 0.639073\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370571; batch adversarial loss: 0.576627\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323515; batch adversarial loss: 0.565015\n",
      "epoch 176; iter: 0; batch classifier loss: 0.357760; batch adversarial loss: 0.507169\n",
      "epoch 177; iter: 0; batch classifier loss: 0.415166; batch adversarial loss: 0.554433\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364542; batch adversarial loss: 0.506479\n",
      "epoch 179; iter: 0; batch classifier loss: 0.316229; batch adversarial loss: 0.529221\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334322; batch adversarial loss: 0.606840\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370483; batch adversarial loss: 0.601071\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351076; batch adversarial loss: 0.606940\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353341; batch adversarial loss: 0.573651\n",
      "epoch 184; iter: 0; batch classifier loss: 0.422649; batch adversarial loss: 0.618721\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332353; batch adversarial loss: 0.534544\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368765; batch adversarial loss: 0.638204\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339386; batch adversarial loss: 0.553753\n",
      "epoch 188; iter: 0; batch classifier loss: 0.405048; batch adversarial loss: 0.451403\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365802; batch adversarial loss: 0.525049\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367004; batch adversarial loss: 0.480557\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363851; batch adversarial loss: 0.571407\n",
      "epoch 192; iter: 0; batch classifier loss: 0.369335; batch adversarial loss: 0.599180\n",
      "epoch 193; iter: 0; batch classifier loss: 0.424286; batch adversarial loss: 0.573204\n",
      "epoch 194; iter: 0; batch classifier loss: 0.266841; batch adversarial loss: 0.563518\n",
      "epoch 195; iter: 0; batch classifier loss: 0.314084; batch adversarial loss: 0.630296\n",
      "epoch 196; iter: 0; batch classifier loss: 0.350113; batch adversarial loss: 0.582824\n",
      "epoch 197; iter: 0; batch classifier loss: 0.316774; batch adversarial loss: 0.526272\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362589; batch adversarial loss: 0.497162\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367676; batch adversarial loss: 0.553254\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681521; batch adversarial loss: 0.860708\n",
      "epoch 1; iter: 0; batch classifier loss: 0.893522; batch adversarial loss: 1.231849\n",
      "epoch 2; iter: 0; batch classifier loss: 1.053700; batch adversarial loss: 1.241055\n",
      "epoch 3; iter: 0; batch classifier loss: 0.982479; batch adversarial loss: 1.083644\n",
      "epoch 4; iter: 0; batch classifier loss: 1.162436; batch adversarial loss: 1.065341\n",
      "epoch 5; iter: 0; batch classifier loss: 1.072008; batch adversarial loss: 0.926303\n",
      "epoch 6; iter: 0; batch classifier loss: 0.915916; batch adversarial loss: 0.839338\n",
      "epoch 7; iter: 0; batch classifier loss: 0.896279; batch adversarial loss: 0.794719\n",
      "epoch 8; iter: 0; batch classifier loss: 0.806147; batch adversarial loss: 0.756287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.784870; batch adversarial loss: 0.701273\n",
      "epoch 10; iter: 0; batch classifier loss: 0.710816; batch adversarial loss: 0.647708\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586526; batch adversarial loss: 0.585221\n",
      "epoch 12; iter: 0; batch classifier loss: 0.597646; batch adversarial loss: 0.622542\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559359; batch adversarial loss: 0.635707\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547516; batch adversarial loss: 0.627458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.586526; batch adversarial loss: 0.558214\n",
      "epoch 16; iter: 0; batch classifier loss: 0.564203; batch adversarial loss: 0.579498\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489747; batch adversarial loss: 0.511204\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492411; batch adversarial loss: 0.549172\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461935; batch adversarial loss: 0.574693\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548197; batch adversarial loss: 0.545344\n",
      "epoch 21; iter: 0; batch classifier loss: 0.575488; batch adversarial loss: 0.498979\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481182; batch adversarial loss: 0.591390\n",
      "epoch 23; iter: 0; batch classifier loss: 0.532022; batch adversarial loss: 0.661869\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490857; batch adversarial loss: 0.567561\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499452; batch adversarial loss: 0.621833\n",
      "epoch 26; iter: 0; batch classifier loss: 0.523612; batch adversarial loss: 0.495382\n",
      "epoch 27; iter: 0; batch classifier loss: 0.566389; batch adversarial loss: 0.586050\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459819; batch adversarial loss: 0.553468\n",
      "epoch 29; iter: 0; batch classifier loss: 0.493355; batch adversarial loss: 0.597113\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479586; batch adversarial loss: 0.604085\n",
      "epoch 31; iter: 0; batch classifier loss: 0.565228; batch adversarial loss: 0.559424\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464879; batch adversarial loss: 0.621605\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503999; batch adversarial loss: 0.538590\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454462; batch adversarial loss: 0.557900\n",
      "epoch 35; iter: 0; batch classifier loss: 0.480371; batch adversarial loss: 0.556519\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456603; batch adversarial loss: 0.566306\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445722; batch adversarial loss: 0.498937\n",
      "epoch 38; iter: 0; batch classifier loss: 0.525672; batch adversarial loss: 0.528280\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477416; batch adversarial loss: 0.539905\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462407; batch adversarial loss: 0.553526\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483696; batch adversarial loss: 0.549275\n",
      "epoch 42; iter: 0; batch classifier loss: 0.479571; batch adversarial loss: 0.555827\n",
      "epoch 43; iter: 0; batch classifier loss: 0.522331; batch adversarial loss: 0.584064\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455554; batch adversarial loss: 0.498144\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457953; batch adversarial loss: 0.535876\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451590; batch adversarial loss: 0.566799\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417656; batch adversarial loss: 0.562889\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459824; batch adversarial loss: 0.501085\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392966; batch adversarial loss: 0.549550\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413515; batch adversarial loss: 0.528391\n",
      "epoch 51; iter: 0; batch classifier loss: 0.388048; batch adversarial loss: 0.612949\n",
      "epoch 52; iter: 0; batch classifier loss: 0.484272; batch adversarial loss: 0.508435\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431717; batch adversarial loss: 0.482939\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438166; batch adversarial loss: 0.530712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.489477; batch adversarial loss: 0.509581\n",
      "epoch 56; iter: 0; batch classifier loss: 0.402771; batch adversarial loss: 0.506001\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422962; batch adversarial loss: 0.538178\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464975; batch adversarial loss: 0.527299\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422356; batch adversarial loss: 0.527575\n",
      "epoch 60; iter: 0; batch classifier loss: 0.480149; batch adversarial loss: 0.513738\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381223; batch adversarial loss: 0.591761\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408166; batch adversarial loss: 0.592956\n",
      "epoch 63; iter: 0; batch classifier loss: 0.362241; batch adversarial loss: 0.549664\n",
      "epoch 64; iter: 0; batch classifier loss: 0.370710; batch adversarial loss: 0.457833\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381360; batch adversarial loss: 0.539326\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411463; batch adversarial loss: 0.586271\n",
      "epoch 67; iter: 0; batch classifier loss: 0.398686; batch adversarial loss: 0.555698\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376859; batch adversarial loss: 0.535170\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419563; batch adversarial loss: 0.497647\n",
      "epoch 70; iter: 0; batch classifier loss: 0.378041; batch adversarial loss: 0.553811\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437078; batch adversarial loss: 0.536451\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393988; batch adversarial loss: 0.480794\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448627; batch adversarial loss: 0.552355\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471876; batch adversarial loss: 0.524813\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391439; batch adversarial loss: 0.554279\n",
      "epoch 76; iter: 0; batch classifier loss: 0.439992; batch adversarial loss: 0.560267\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424374; batch adversarial loss: 0.561672\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376607; batch adversarial loss: 0.527081\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372908; batch adversarial loss: 0.572244\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395706; batch adversarial loss: 0.534500\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405843; batch adversarial loss: 0.542516\n",
      "epoch 82; iter: 0; batch classifier loss: 0.339626; batch adversarial loss: 0.532825\n",
      "epoch 83; iter: 0; batch classifier loss: 0.427468; batch adversarial loss: 0.458785\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431674; batch adversarial loss: 0.515674\n",
      "epoch 85; iter: 0; batch classifier loss: 0.394079; batch adversarial loss: 0.592829\n",
      "epoch 86; iter: 0; batch classifier loss: 0.320328; batch adversarial loss: 0.564531\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380692; batch adversarial loss: 0.547108\n",
      "epoch 88; iter: 0; batch classifier loss: 0.445237; batch adversarial loss: 0.583699\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366826; batch adversarial loss: 0.544052\n",
      "epoch 90; iter: 0; batch classifier loss: 0.516823; batch adversarial loss: 0.534640\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366719; batch adversarial loss: 0.534738\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351198; batch adversarial loss: 0.469208\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352725; batch adversarial loss: 0.535221\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390893; batch adversarial loss: 0.534530\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442634; batch adversarial loss: 0.517289\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371695; batch adversarial loss: 0.518937\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381706; batch adversarial loss: 0.526841\n",
      "epoch 98; iter: 0; batch classifier loss: 0.429756; batch adversarial loss: 0.535831\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413171; batch adversarial loss: 0.560366\n",
      "epoch 100; iter: 0; batch classifier loss: 0.509302; batch adversarial loss: 0.554002\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385583; batch adversarial loss: 0.504172\n",
      "epoch 102; iter: 0; batch classifier loss: 0.433180; batch adversarial loss: 0.535384\n",
      "epoch 103; iter: 0; batch classifier loss: 0.477469; batch adversarial loss: 0.495972\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351224; batch adversarial loss: 0.656011\n",
      "epoch 105; iter: 0; batch classifier loss: 0.431921; batch adversarial loss: 0.631033\n",
      "epoch 106; iter: 0; batch classifier loss: 0.451003; batch adversarial loss: 0.550673\n",
      "epoch 107; iter: 0; batch classifier loss: 0.433699; batch adversarial loss: 0.619202\n",
      "epoch 108; iter: 0; batch classifier loss: 0.433408; batch adversarial loss: 0.563953\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376479; batch adversarial loss: 0.554771\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411649; batch adversarial loss: 0.656151\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381208; batch adversarial loss: 0.543834\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391752; batch adversarial loss: 0.536216\n",
      "epoch 113; iter: 0; batch classifier loss: 0.409955; batch adversarial loss: 0.572927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.357177; batch adversarial loss: 0.508007\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411253; batch adversarial loss: 0.562844\n",
      "epoch 116; iter: 0; batch classifier loss: 0.314415; batch adversarial loss: 0.516466\n",
      "epoch 117; iter: 0; batch classifier loss: 0.453475; batch adversarial loss: 0.515988\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389958; batch adversarial loss: 0.516193\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415687; batch adversarial loss: 0.506877\n",
      "epoch 120; iter: 0; batch classifier loss: 0.410858; batch adversarial loss: 0.563101\n",
      "epoch 121; iter: 0; batch classifier loss: 0.282337; batch adversarial loss: 0.581754\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424554; batch adversarial loss: 0.600530\n",
      "epoch 123; iter: 0; batch classifier loss: 0.322146; batch adversarial loss: 0.498035\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398033; batch adversarial loss: 0.553994\n",
      "epoch 125; iter: 0; batch classifier loss: 0.417678; batch adversarial loss: 0.535564\n",
      "epoch 126; iter: 0; batch classifier loss: 0.332430; batch adversarial loss: 0.611152\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370386; batch adversarial loss: 0.489000\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355812; batch adversarial loss: 0.526409\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379877; batch adversarial loss: 0.497677\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357989; batch adversarial loss: 0.563894\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336014; batch adversarial loss: 0.525282\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360167; batch adversarial loss: 0.544258\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388844; batch adversarial loss: 0.590706\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365576; batch adversarial loss: 0.497334\n",
      "epoch 135; iter: 0; batch classifier loss: 0.450559; batch adversarial loss: 0.488049\n",
      "epoch 136; iter: 0; batch classifier loss: 0.296948; batch adversarial loss: 0.572786\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400062; batch adversarial loss: 0.487683\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389693; batch adversarial loss: 0.628466\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343525; batch adversarial loss: 0.544559\n",
      "epoch 140; iter: 0; batch classifier loss: 0.429098; batch adversarial loss: 0.553449\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357209; batch adversarial loss: 0.507343\n",
      "epoch 142; iter: 0; batch classifier loss: 0.357782; batch adversarial loss: 0.544650\n",
      "epoch 143; iter: 0; batch classifier loss: 0.272385; batch adversarial loss: 0.524720\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348181; batch adversarial loss: 0.600439\n",
      "epoch 145; iter: 0; batch classifier loss: 0.354912; batch adversarial loss: 0.543479\n",
      "epoch 146; iter: 0; batch classifier loss: 0.304598; batch adversarial loss: 0.553899\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397747; batch adversarial loss: 0.563481\n",
      "epoch 148; iter: 0; batch classifier loss: 0.383223; batch adversarial loss: 0.543518\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329327; batch adversarial loss: 0.564095\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359460; batch adversarial loss: 0.470351\n",
      "epoch 151; iter: 0; batch classifier loss: 0.319396; batch adversarial loss: 0.516354\n",
      "epoch 152; iter: 0; batch classifier loss: 0.285947; batch adversarial loss: 0.535088\n",
      "epoch 153; iter: 0; batch classifier loss: 0.304646; batch adversarial loss: 0.526441\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389712; batch adversarial loss: 0.628479\n",
      "epoch 155; iter: 0; batch classifier loss: 0.372370; batch adversarial loss: 0.544698\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373025; batch adversarial loss: 0.609522\n",
      "epoch 157; iter: 0; batch classifier loss: 0.389851; batch adversarial loss: 0.534960\n",
      "epoch 158; iter: 0; batch classifier loss: 0.301154; batch adversarial loss: 0.507155\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389982; batch adversarial loss: 0.544816\n",
      "epoch 160; iter: 0; batch classifier loss: 0.331233; batch adversarial loss: 0.506862\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330329; batch adversarial loss: 0.516564\n",
      "epoch 162; iter: 0; batch classifier loss: 0.292743; batch adversarial loss: 0.478421\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402050; batch adversarial loss: 0.516987\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352319; batch adversarial loss: 0.525656\n",
      "epoch 165; iter: 0; batch classifier loss: 0.354445; batch adversarial loss: 0.535050\n",
      "epoch 166; iter: 0; batch classifier loss: 0.297712; batch adversarial loss: 0.572356\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341493; batch adversarial loss: 0.450878\n",
      "epoch 168; iter: 0; batch classifier loss: 0.301102; batch adversarial loss: 0.609386\n",
      "epoch 169; iter: 0; batch classifier loss: 0.395350; batch adversarial loss: 0.516800\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354759; batch adversarial loss: 0.544299\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366187; batch adversarial loss: 0.553746\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354510; batch adversarial loss: 0.488902\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346724; batch adversarial loss: 0.497893\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376229; batch adversarial loss: 0.543566\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343020; batch adversarial loss: 0.478769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.315658; batch adversarial loss: 0.554552\n",
      "epoch 177; iter: 0; batch classifier loss: 0.415101; batch adversarial loss: 0.572445\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384774; batch adversarial loss: 0.582107\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392957; batch adversarial loss: 0.563600\n",
      "epoch 180; iter: 0; batch classifier loss: 0.370482; batch adversarial loss: 0.544818\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373180; batch adversarial loss: 0.525739\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405679; batch adversarial loss: 0.506739\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345238; batch adversarial loss: 0.498292\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366190; batch adversarial loss: 0.573107\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342437; batch adversarial loss: 0.628479\n",
      "epoch 186; iter: 0; batch classifier loss: 0.415704; batch adversarial loss: 0.496617\n",
      "epoch 187; iter: 0; batch classifier loss: 0.386261; batch adversarial loss: 0.526524\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347644; batch adversarial loss: 0.479474\n",
      "epoch 189; iter: 0; batch classifier loss: 0.407385; batch adversarial loss: 0.572737\n",
      "epoch 190; iter: 0; batch classifier loss: 0.281052; batch adversarial loss: 0.610370\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341694; batch adversarial loss: 0.488452\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335097; batch adversarial loss: 0.535940\n",
      "epoch 193; iter: 0; batch classifier loss: 0.352152; batch adversarial loss: 0.469490\n",
      "epoch 194; iter: 0; batch classifier loss: 0.323382; batch adversarial loss: 0.563335\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375576; batch adversarial loss: 0.533927\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312038; batch adversarial loss: 0.534941\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365251; batch adversarial loss: 0.545153\n",
      "epoch 198; iter: 0; batch classifier loss: 0.421929; batch adversarial loss: 0.601131\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335001; batch adversarial loss: 0.516361\n",
      "epoch 0; iter: 0; batch classifier loss: 0.743517; batch adversarial loss: 0.630822\n",
      "epoch 1; iter: 0; batch classifier loss: 0.579244; batch adversarial loss: 0.628899\n",
      "epoch 2; iter: 0; batch classifier loss: 0.596031; batch adversarial loss: 0.659096\n",
      "epoch 3; iter: 0; batch classifier loss: 0.511719; batch adversarial loss: 0.638668\n",
      "epoch 4; iter: 0; batch classifier loss: 0.611687; batch adversarial loss: 0.636534\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568076; batch adversarial loss: 0.642184\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581969; batch adversarial loss: 0.599054\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547156; batch adversarial loss: 0.585290\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541363; batch adversarial loss: 0.596314\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559582; batch adversarial loss: 0.609712\n",
      "epoch 10; iter: 0; batch classifier loss: 0.587632; batch adversarial loss: 0.556870\n",
      "epoch 11; iter: 0; batch classifier loss: 0.625217; batch adversarial loss: 0.585276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.552594; batch adversarial loss: 0.644009\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494612; batch adversarial loss: 0.518110\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552483; batch adversarial loss: 0.531564\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478639; batch adversarial loss: 0.558332\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552955; batch adversarial loss: 0.631438\n",
      "epoch 17; iter: 0; batch classifier loss: 0.461631; batch adversarial loss: 0.561709\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535236; batch adversarial loss: 0.593727\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482223; batch adversarial loss: 0.628886\n",
      "epoch 20; iter: 0; batch classifier loss: 0.587019; batch adversarial loss: 0.513752\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545183; batch adversarial loss: 0.511286\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529602; batch adversarial loss: 0.562484\n",
      "epoch 23; iter: 0; batch classifier loss: 0.429590; batch adversarial loss: 0.541423\n",
      "epoch 24; iter: 0; batch classifier loss: 0.430511; batch adversarial loss: 0.539021\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502099; batch adversarial loss: 0.596283\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536368; batch adversarial loss: 0.497936\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479541; batch adversarial loss: 0.594549\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510805; batch adversarial loss: 0.571324\n",
      "epoch 29; iter: 0; batch classifier loss: 0.498349; batch adversarial loss: 0.546856\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502650; batch adversarial loss: 0.563442\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490897; batch adversarial loss: 0.479164\n",
      "epoch 32; iter: 0; batch classifier loss: 0.509807; batch adversarial loss: 0.589948\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457113; batch adversarial loss: 0.562463\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482405; batch adversarial loss: 0.569549\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429368; batch adversarial loss: 0.579036\n",
      "epoch 36; iter: 0; batch classifier loss: 0.498842; batch adversarial loss: 0.545171\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467248; batch adversarial loss: 0.536965\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459053; batch adversarial loss: 0.579487\n",
      "epoch 39; iter: 0; batch classifier loss: 0.506167; batch adversarial loss: 0.562783\n",
      "epoch 40; iter: 0; batch classifier loss: 0.473347; batch adversarial loss: 0.466657\n",
      "epoch 41; iter: 0; batch classifier loss: 0.373901; batch adversarial loss: 0.510000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.394389; batch adversarial loss: 0.562173\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413511; batch adversarial loss: 0.562283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403822; batch adversarial loss: 0.562650\n",
      "epoch 45; iter: 0; batch classifier loss: 0.488249; batch adversarial loss: 0.562290\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437023; batch adversarial loss: 0.562576\n",
      "epoch 47; iter: 0; batch classifier loss: 0.501345; batch adversarial loss: 0.571091\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370257; batch adversarial loss: 0.553646\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388623; batch adversarial loss: 0.553586\n",
      "epoch 50; iter: 0; batch classifier loss: 0.446197; batch adversarial loss: 0.481882\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471935; batch adversarial loss: 0.482737\n",
      "epoch 52; iter: 0; batch classifier loss: 0.394270; batch adversarial loss: 0.537375\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464778; batch adversarial loss: 0.545566\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455847; batch adversarial loss: 0.554137\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447160; batch adversarial loss: 0.561943\n",
      "epoch 56; iter: 0; batch classifier loss: 0.492893; batch adversarial loss: 0.517612\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414742; batch adversarial loss: 0.563279\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398633; batch adversarial loss: 0.536375\n",
      "epoch 59; iter: 0; batch classifier loss: 0.373012; batch adversarial loss: 0.596843\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434167; batch adversarial loss: 0.492106\n",
      "epoch 61; iter: 0; batch classifier loss: 0.486472; batch adversarial loss: 0.518796\n",
      "epoch 62; iter: 0; batch classifier loss: 0.474605; batch adversarial loss: 0.605974\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449048; batch adversarial loss: 0.484982\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398753; batch adversarial loss: 0.553448\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410981; batch adversarial loss: 0.526940\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428032; batch adversarial loss: 0.544855\n",
      "epoch 67; iter: 0; batch classifier loss: 0.479364; batch adversarial loss: 0.535814\n",
      "epoch 68; iter: 0; batch classifier loss: 0.446804; batch adversarial loss: 0.605792\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401825; batch adversarial loss: 0.553549\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410844; batch adversarial loss: 0.562001\n",
      "epoch 71; iter: 0; batch classifier loss: 0.442648; batch adversarial loss: 0.553577\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355787; batch adversarial loss: 0.448234\n",
      "epoch 73; iter: 0; batch classifier loss: 0.354305; batch adversarial loss: 0.482732\n",
      "epoch 74; iter: 0; batch classifier loss: 0.474618; batch adversarial loss: 0.569762\n",
      "epoch 75; iter: 0; batch classifier loss: 0.521802; batch adversarial loss: 0.526306\n",
      "epoch 76; iter: 0; batch classifier loss: 0.403433; batch adversarial loss: 0.463600\n",
      "epoch 77; iter: 0; batch classifier loss: 0.545270; batch adversarial loss: 0.614010\n",
      "epoch 78; iter: 0; batch classifier loss: 0.539400; batch adversarial loss: 0.606983\n",
      "epoch 79; iter: 0; batch classifier loss: 0.307831; batch adversarial loss: 0.562609\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360750; batch adversarial loss: 0.537303\n",
      "epoch 81; iter: 0; batch classifier loss: 0.458145; batch adversarial loss: 0.527284\n",
      "epoch 82; iter: 0; batch classifier loss: 0.448274; batch adversarial loss: 0.509322\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407573; batch adversarial loss: 0.493340\n",
      "epoch 84; iter: 0; batch classifier loss: 0.464198; batch adversarial loss: 0.509570\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411730; batch adversarial loss: 0.605387\n",
      "epoch 86; iter: 0; batch classifier loss: 0.441098; batch adversarial loss: 0.510151\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387879; batch adversarial loss: 0.588303\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375591; batch adversarial loss: 0.554092\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427998; batch adversarial loss: 0.597261\n",
      "epoch 90; iter: 0; batch classifier loss: 0.471524; batch adversarial loss: 0.518134\n",
      "epoch 91; iter: 0; batch classifier loss: 0.338530; batch adversarial loss: 0.605784\n",
      "epoch 92; iter: 0; batch classifier loss: 0.436575; batch adversarial loss: 0.509744\n",
      "epoch 93; iter: 0; batch classifier loss: 0.442410; batch adversarial loss: 0.553060\n",
      "epoch 94; iter: 0; batch classifier loss: 0.324261; batch adversarial loss: 0.535889\n",
      "epoch 95; iter: 0; batch classifier loss: 0.367034; batch adversarial loss: 0.579316\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380102; batch adversarial loss: 0.641112\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393089; batch adversarial loss: 0.606960\n",
      "epoch 98; iter: 0; batch classifier loss: 0.366372; batch adversarial loss: 0.501077\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408955; batch adversarial loss: 0.562472\n",
      "epoch 100; iter: 0; batch classifier loss: 0.443910; batch adversarial loss: 0.580639\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376298; batch adversarial loss: 0.528156\n",
      "epoch 102; iter: 0; batch classifier loss: 0.354766; batch adversarial loss: 0.597559\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398887; batch adversarial loss: 0.527773\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375420; batch adversarial loss: 0.535326\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389176; batch adversarial loss: 0.553677\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350572; batch adversarial loss: 0.491892\n",
      "epoch 107; iter: 0; batch classifier loss: 0.389018; batch adversarial loss: 0.544597\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403571; batch adversarial loss: 0.562194\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387875; batch adversarial loss: 0.579507\n",
      "epoch 110; iter: 0; batch classifier loss: 0.418049; batch adversarial loss: 0.552726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.361278; batch adversarial loss: 0.535531\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362165; batch adversarial loss: 0.473749\n",
      "epoch 113; iter: 0; batch classifier loss: 0.414068; batch adversarial loss: 0.518148\n",
      "epoch 114; iter: 0; batch classifier loss: 0.446800; batch adversarial loss: 0.633244\n",
      "epoch 115; iter: 0; batch classifier loss: 0.325959; batch adversarial loss: 0.518451\n",
      "epoch 116; iter: 0; batch classifier loss: 0.448828; batch adversarial loss: 0.527270\n",
      "epoch 117; iter: 0; batch classifier loss: 0.400092; batch adversarial loss: 0.579226\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345614; batch adversarial loss: 0.492862\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375352; batch adversarial loss: 0.553733\n",
      "epoch 120; iter: 0; batch classifier loss: 0.355017; batch adversarial loss: 0.570891\n",
      "epoch 121; iter: 0; batch classifier loss: 0.438952; batch adversarial loss: 0.624165\n",
      "epoch 122; iter: 0; batch classifier loss: 0.329742; batch adversarial loss: 0.613175\n",
      "epoch 123; iter: 0; batch classifier loss: 0.447523; batch adversarial loss: 0.517844\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352140; batch adversarial loss: 0.641783\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356289; batch adversarial loss: 0.616197\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412559; batch adversarial loss: 0.563289\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354658; batch adversarial loss: 0.519375\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375338; batch adversarial loss: 0.554334\n",
      "epoch 129; iter: 0; batch classifier loss: 0.436330; batch adversarial loss: 0.588739\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396620; batch adversarial loss: 0.599032\n",
      "epoch 131; iter: 0; batch classifier loss: 0.376243; batch adversarial loss: 0.623866\n",
      "epoch 132; iter: 0; batch classifier loss: 0.337926; batch adversarial loss: 0.536715\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329446; batch adversarial loss: 0.562510\n",
      "epoch 134; iter: 0; batch classifier loss: 0.494919; batch adversarial loss: 0.553759\n",
      "epoch 135; iter: 0; batch classifier loss: 0.310745; batch adversarial loss: 0.598469\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406457; batch adversarial loss: 0.536385\n",
      "epoch 137; iter: 0; batch classifier loss: 0.284803; batch adversarial loss: 0.553429\n",
      "epoch 138; iter: 0; batch classifier loss: 0.333253; batch adversarial loss: 0.578931\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374354; batch adversarial loss: 0.500618\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341712; batch adversarial loss: 0.588313\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349349; batch adversarial loss: 0.580665\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371091; batch adversarial loss: 0.641936\n",
      "epoch 143; iter: 0; batch classifier loss: 0.345342; batch adversarial loss: 0.571623\n",
      "epoch 144; iter: 0; batch classifier loss: 0.317076; batch adversarial loss: 0.474945\n",
      "epoch 145; iter: 0; batch classifier loss: 0.430189; batch adversarial loss: 0.615955\n",
      "epoch 146; iter: 0; batch classifier loss: 0.420505; batch adversarial loss: 0.465923\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329329; batch adversarial loss: 0.518706\n",
      "epoch 148; iter: 0; batch classifier loss: 0.352920; batch adversarial loss: 0.545074\n",
      "epoch 149; iter: 0; batch classifier loss: 0.442826; batch adversarial loss: 0.429051\n",
      "epoch 150; iter: 0; batch classifier loss: 0.453450; batch adversarial loss: 0.527754\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363045; batch adversarial loss: 0.482476\n",
      "epoch 152; iter: 0; batch classifier loss: 0.417864; batch adversarial loss: 0.507636\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371264; batch adversarial loss: 0.614965\n",
      "epoch 154; iter: 0; batch classifier loss: 0.473052; batch adversarial loss: 0.563374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.420523; batch adversarial loss: 0.509237\n",
      "epoch 156; iter: 0; batch classifier loss: 0.300088; batch adversarial loss: 0.615712\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341624; batch adversarial loss: 0.580641\n",
      "epoch 158; iter: 0; batch classifier loss: 0.411064; batch adversarial loss: 0.554546\n",
      "epoch 159; iter: 0; batch classifier loss: 0.310172; batch adversarial loss: 0.553946\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372821; batch adversarial loss: 0.560822\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414005; batch adversarial loss: 0.516948\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381109; batch adversarial loss: 0.508678\n",
      "epoch 163; iter: 0; batch classifier loss: 0.383481; batch adversarial loss: 0.571496\n",
      "epoch 164; iter: 0; batch classifier loss: 0.364361; batch adversarial loss: 0.587341\n",
      "epoch 165; iter: 0; batch classifier loss: 0.383697; batch adversarial loss: 0.536340\n",
      "epoch 166; iter: 0; batch classifier loss: 0.338368; batch adversarial loss: 0.589569\n",
      "epoch 167; iter: 0; batch classifier loss: 0.436557; batch adversarial loss: 0.633132\n",
      "epoch 168; iter: 0; batch classifier loss: 0.339055; batch adversarial loss: 0.606174\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337411; batch adversarial loss: 0.579105\n",
      "epoch 170; iter: 0; batch classifier loss: 0.400258; batch adversarial loss: 0.535193\n",
      "epoch 171; iter: 0; batch classifier loss: 0.416447; batch adversarial loss: 0.623540\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381986; batch adversarial loss: 0.553607\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324397; batch adversarial loss: 0.552962\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365961; batch adversarial loss: 0.492385\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323400; batch adversarial loss: 0.649012\n",
      "epoch 176; iter: 0; batch classifier loss: 0.325971; batch adversarial loss: 0.579431\n",
      "epoch 177; iter: 0; batch classifier loss: 0.364125; batch adversarial loss: 0.649522\n",
      "epoch 178; iter: 0; batch classifier loss: 0.428879; batch adversarial loss: 0.508929\n",
      "epoch 179; iter: 0; batch classifier loss: 0.319567; batch adversarial loss: 0.492284\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367850; batch adversarial loss: 0.561686\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314530; batch adversarial loss: 0.553640\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375310; batch adversarial loss: 0.509093\n",
      "epoch 183; iter: 0; batch classifier loss: 0.455178; batch adversarial loss: 0.580838\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339488; batch adversarial loss: 0.474539\n",
      "epoch 185; iter: 0; batch classifier loss: 0.341276; batch adversarial loss: 0.465751\n",
      "epoch 186; iter: 0; batch classifier loss: 0.446180; batch adversarial loss: 0.562272\n",
      "epoch 187; iter: 0; batch classifier loss: 0.323142; batch adversarial loss: 0.553223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328371; batch adversarial loss: 0.517563\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322962; batch adversarial loss: 0.527454\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347057; batch adversarial loss: 0.553484\n",
      "epoch 191; iter: 0; batch classifier loss: 0.317354; batch adversarial loss: 0.562283\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297150; batch adversarial loss: 0.509375\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338146; batch adversarial loss: 0.545432\n",
      "epoch 194; iter: 0; batch classifier loss: 0.375729; batch adversarial loss: 0.614359\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332893; batch adversarial loss: 0.553938\n",
      "epoch 196; iter: 0; batch classifier loss: 0.350771; batch adversarial loss: 0.571640\n",
      "epoch 197; iter: 0; batch classifier loss: 0.398081; batch adversarial loss: 0.537256\n",
      "epoch 198; iter: 0; batch classifier loss: 0.296222; batch adversarial loss: 0.544787\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379179; batch adversarial loss: 0.572116\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698254; batch adversarial loss: 1.013237\n",
      "epoch 1; iter: 0; batch classifier loss: 0.889973; batch adversarial loss: 1.372179\n",
      "epoch 2; iter: 0; batch classifier loss: 1.028765; batch adversarial loss: 1.324924\n",
      "epoch 3; iter: 0; batch classifier loss: 1.041500; batch adversarial loss: 1.321577\n",
      "epoch 4; iter: 0; batch classifier loss: 1.045885; batch adversarial loss: 1.184161\n",
      "epoch 5; iter: 0; batch classifier loss: 1.119726; batch adversarial loss: 1.078312\n",
      "epoch 6; iter: 0; batch classifier loss: 1.078287; batch adversarial loss: 0.987080\n",
      "epoch 7; iter: 0; batch classifier loss: 1.072144; batch adversarial loss: 0.922722\n",
      "epoch 8; iter: 0; batch classifier loss: 0.961625; batch adversarial loss: 0.856769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.942611; batch adversarial loss: 0.787925\n",
      "epoch 10; iter: 0; batch classifier loss: 0.809246; batch adversarial loss: 0.741814\n",
      "epoch 11; iter: 0; batch classifier loss: 0.735751; batch adversarial loss: 0.702302\n",
      "epoch 12; iter: 0; batch classifier loss: 0.679157; batch adversarial loss: 0.668984\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524930; batch adversarial loss: 0.640801\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566400; batch adversarial loss: 0.587863\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513720; batch adversarial loss: 0.618445\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497177; batch adversarial loss: 0.607306\n",
      "epoch 17; iter: 0; batch classifier loss: 0.554173; batch adversarial loss: 0.553144\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453073; batch adversarial loss: 0.540406\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497387; batch adversarial loss: 0.547775\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548593; batch adversarial loss: 0.531927\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510783; batch adversarial loss: 0.606243\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468226; batch adversarial loss: 0.503239\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491735; batch adversarial loss: 0.544005\n",
      "epoch 24; iter: 0; batch classifier loss: 0.429446; batch adversarial loss: 0.556006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500904; batch adversarial loss: 0.569089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467801; batch adversarial loss: 0.542118\n",
      "epoch 27; iter: 0; batch classifier loss: 0.396766; batch adversarial loss: 0.600860\n",
      "epoch 28; iter: 0; batch classifier loss: 0.544246; batch adversarial loss: 0.514484\n",
      "epoch 29; iter: 0; batch classifier loss: 0.408137; batch adversarial loss: 0.545627\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478768; batch adversarial loss: 0.593423\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468765; batch adversarial loss: 0.511420\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499995; batch adversarial loss: 0.543233\n",
      "epoch 33; iter: 0; batch classifier loss: 0.525401; batch adversarial loss: 0.534168\n",
      "epoch 34; iter: 0; batch classifier loss: 0.413836; batch adversarial loss: 0.567446\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450172; batch adversarial loss: 0.540258\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476366; batch adversarial loss: 0.481022\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476665; batch adversarial loss: 0.559152\n",
      "epoch 38; iter: 0; batch classifier loss: 0.433800; batch adversarial loss: 0.622775\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465183; batch adversarial loss: 0.517848\n",
      "epoch 40; iter: 0; batch classifier loss: 0.510899; batch adversarial loss: 0.492681\n",
      "epoch 41; iter: 0; batch classifier loss: 0.423666; batch adversarial loss: 0.501014\n",
      "epoch 42; iter: 0; batch classifier loss: 0.494201; batch adversarial loss: 0.595310\n",
      "epoch 43; iter: 0; batch classifier loss: 0.548290; batch adversarial loss: 0.517639\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464106; batch adversarial loss: 0.454366\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465653; batch adversarial loss: 0.481945\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372450; batch adversarial loss: 0.561481\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413193; batch adversarial loss: 0.587595\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450865; batch adversarial loss: 0.563825\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468870; batch adversarial loss: 0.571521\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461502; batch adversarial loss: 0.629773\n",
      "epoch 51; iter: 0; batch classifier loss: 0.366524; batch adversarial loss: 0.553335\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390285; batch adversarial loss: 0.593969\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470333; batch adversarial loss: 0.534396\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440029; batch adversarial loss: 0.546079\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442259; batch adversarial loss: 0.647219\n",
      "epoch 56; iter: 0; batch classifier loss: 0.386144; batch adversarial loss: 0.533516\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472401; batch adversarial loss: 0.581021\n",
      "epoch 58; iter: 0; batch classifier loss: 0.454272; batch adversarial loss: 0.505726\n",
      "epoch 59; iter: 0; batch classifier loss: 0.324732; batch adversarial loss: 0.497516\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418175; batch adversarial loss: 0.534107\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444308; batch adversarial loss: 0.571849\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417638; batch adversarial loss: 0.581384\n",
      "epoch 63; iter: 0; batch classifier loss: 0.353559; batch adversarial loss: 0.515545\n",
      "epoch 64; iter: 0; batch classifier loss: 0.344273; batch adversarial loss: 0.547659\n",
      "epoch 65; iter: 0; batch classifier loss: 0.331439; batch adversarial loss: 0.545434\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397127; batch adversarial loss: 0.525933\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406552; batch adversarial loss: 0.543847\n",
      "epoch 68; iter: 0; batch classifier loss: 0.352291; batch adversarial loss: 0.573090\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417506; batch adversarial loss: 0.601711\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374222; batch adversarial loss: 0.516082\n",
      "epoch 71; iter: 0; batch classifier loss: 0.325564; batch adversarial loss: 0.554084\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444081; batch adversarial loss: 0.573126\n",
      "epoch 73; iter: 0; batch classifier loss: 0.363908; batch adversarial loss: 0.515713\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452479; batch adversarial loss: 0.486870\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443796; batch adversarial loss: 0.542669\n",
      "epoch 76; iter: 0; batch classifier loss: 0.325978; batch adversarial loss: 0.583898\n",
      "epoch 77; iter: 0; batch classifier loss: 0.329132; batch adversarial loss: 0.525538\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394827; batch adversarial loss: 0.591498\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413399; batch adversarial loss: 0.594918\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423150; batch adversarial loss: 0.472143\n",
      "epoch 81; iter: 0; batch classifier loss: 0.420814; batch adversarial loss: 0.612206\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363236; batch adversarial loss: 0.509545\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441438; batch adversarial loss: 0.581116\n",
      "epoch 84; iter: 0; batch classifier loss: 0.357507; batch adversarial loss: 0.610142\n",
      "epoch 85; iter: 0; batch classifier loss: 0.314153; batch adversarial loss: 0.518545\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358759; batch adversarial loss: 0.578811\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390697; batch adversarial loss: 0.534024\n",
      "epoch 88; iter: 0; batch classifier loss: 0.313640; batch adversarial loss: 0.561612\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400460; batch adversarial loss: 0.512600\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381914; batch adversarial loss: 0.547216\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376830; batch adversarial loss: 0.525989\n",
      "epoch 92; iter: 0; batch classifier loss: 0.311105; batch adversarial loss: 0.612737\n",
      "epoch 93; iter: 0; batch classifier loss: 0.332084; batch adversarial loss: 0.523915\n",
      "epoch 94; iter: 0; batch classifier loss: 0.389141; batch adversarial loss: 0.630125\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426883; batch adversarial loss: 0.618990\n",
      "epoch 96; iter: 0; batch classifier loss: 0.296525; batch adversarial loss: 0.523765\n",
      "epoch 97; iter: 0; batch classifier loss: 0.419284; batch adversarial loss: 0.506685\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381380; batch adversarial loss: 0.524548\n",
      "epoch 99; iter: 0; batch classifier loss: 0.372059; batch adversarial loss: 0.572695\n",
      "epoch 100; iter: 0; batch classifier loss: 0.437349; batch adversarial loss: 0.545695\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359343; batch adversarial loss: 0.593733\n",
      "epoch 102; iter: 0; batch classifier loss: 0.352116; batch adversarial loss: 0.590798\n",
      "epoch 103; iter: 0; batch classifier loss: 0.370898; batch adversarial loss: 0.553114\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400153; batch adversarial loss: 0.505318\n",
      "epoch 105; iter: 0; batch classifier loss: 0.318839; batch adversarial loss: 0.460876\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381335; batch adversarial loss: 0.507292\n",
      "epoch 107; iter: 0; batch classifier loss: 0.302622; batch adversarial loss: 0.473029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.286075; batch adversarial loss: 0.598917\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361471; batch adversarial loss: 0.583757\n",
      "epoch 110; iter: 0; batch classifier loss: 0.317731; batch adversarial loss: 0.544628\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418285; batch adversarial loss: 0.451370\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381968; batch adversarial loss: 0.487714\n",
      "epoch 113; iter: 0; batch classifier loss: 0.364470; batch adversarial loss: 0.525817\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426846; batch adversarial loss: 0.515967\n",
      "epoch 115; iter: 0; batch classifier loss: 0.471465; batch adversarial loss: 0.442287\n",
      "epoch 116; iter: 0; batch classifier loss: 0.310717; batch adversarial loss: 0.496459\n",
      "epoch 117; iter: 0; batch classifier loss: 0.442760; batch adversarial loss: 0.572388\n",
      "epoch 118; iter: 0; batch classifier loss: 0.308044; batch adversarial loss: 0.516301\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381120; batch adversarial loss: 0.524467\n",
      "epoch 120; iter: 0; batch classifier loss: 0.297082; batch adversarial loss: 0.542537\n",
      "epoch 121; iter: 0; batch classifier loss: 0.340629; batch adversarial loss: 0.526147\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372328; batch adversarial loss: 0.635450\n",
      "epoch 123; iter: 0; batch classifier loss: 0.321760; batch adversarial loss: 0.591708\n",
      "epoch 124; iter: 0; batch classifier loss: 0.323893; batch adversarial loss: 0.600601\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344664; batch adversarial loss: 0.598738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360568; batch adversarial loss: 0.533210\n",
      "epoch 127; iter: 0; batch classifier loss: 0.435967; batch adversarial loss: 0.522874\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369237; batch adversarial loss: 0.551582\n",
      "epoch 129; iter: 0; batch classifier loss: 0.475484; batch adversarial loss: 0.558890\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363610; batch adversarial loss: 0.439316\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361420; batch adversarial loss: 0.467020\n",
      "epoch 132; iter: 0; batch classifier loss: 0.361568; batch adversarial loss: 0.557153\n",
      "epoch 133; iter: 0; batch classifier loss: 0.379129; batch adversarial loss: 0.477180\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337167; batch adversarial loss: 0.490037\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340800; batch adversarial loss: 0.596974\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395624; batch adversarial loss: 0.470319\n",
      "epoch 137; iter: 0; batch classifier loss: 0.318270; batch adversarial loss: 0.614995\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382680; batch adversarial loss: 0.641568\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356364; batch adversarial loss: 0.553792\n",
      "epoch 140; iter: 0; batch classifier loss: 0.270488; batch adversarial loss: 0.572652\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387462; batch adversarial loss: 0.525172\n",
      "epoch 142; iter: 0; batch classifier loss: 0.279060; batch adversarial loss: 0.552431\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352930; batch adversarial loss: 0.527608\n",
      "epoch 144; iter: 0; batch classifier loss: 0.344737; batch adversarial loss: 0.480245\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332301; batch adversarial loss: 0.600941\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369815; batch adversarial loss: 0.479353\n",
      "epoch 147; iter: 0; batch classifier loss: 0.251101; batch adversarial loss: 0.518460\n",
      "epoch 148; iter: 0; batch classifier loss: 0.284759; batch adversarial loss: 0.600686\n",
      "epoch 149; iter: 0; batch classifier loss: 0.431171; batch adversarial loss: 0.563570\n",
      "epoch 150; iter: 0; batch classifier loss: 0.306286; batch adversarial loss: 0.572096\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395866; batch adversarial loss: 0.536462\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332075; batch adversarial loss: 0.580600\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324116; batch adversarial loss: 0.611516\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320518; batch adversarial loss: 0.522143\n",
      "epoch 155; iter: 0; batch classifier loss: 0.277203; batch adversarial loss: 0.498348\n",
      "epoch 156; iter: 0; batch classifier loss: 0.329666; batch adversarial loss: 0.461933\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326015; batch adversarial loss: 0.526647\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346639; batch adversarial loss: 0.467226\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354244; batch adversarial loss: 0.527821\n",
      "epoch 160; iter: 0; batch classifier loss: 0.435715; batch adversarial loss: 0.555545\n",
      "epoch 161; iter: 0; batch classifier loss: 0.308373; batch adversarial loss: 0.546109\n",
      "epoch 162; iter: 0; batch classifier loss: 0.333083; batch adversarial loss: 0.514559\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319822; batch adversarial loss: 0.560677\n",
      "epoch 164; iter: 0; batch classifier loss: 0.303974; batch adversarial loss: 0.574433\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329647; batch adversarial loss: 0.556116\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318228; batch adversarial loss: 0.580525\n",
      "epoch 167; iter: 0; batch classifier loss: 0.355826; batch adversarial loss: 0.537075\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333535; batch adversarial loss: 0.551921\n",
      "epoch 169; iter: 0; batch classifier loss: 0.268699; batch adversarial loss: 0.639313\n",
      "epoch 170; iter: 0; batch classifier loss: 0.239697; batch adversarial loss: 0.562004\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373288; batch adversarial loss: 0.498222\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342312; batch adversarial loss: 0.469794\n",
      "epoch 173; iter: 0; batch classifier loss: 0.348765; batch adversarial loss: 0.542151\n",
      "epoch 174; iter: 0; batch classifier loss: 0.397838; batch adversarial loss: 0.619136\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376630; batch adversarial loss: 0.590662\n",
      "epoch 176; iter: 0; batch classifier loss: 0.309495; batch adversarial loss: 0.543363\n",
      "epoch 177; iter: 0; batch classifier loss: 0.286028; batch adversarial loss: 0.498774\n",
      "epoch 178; iter: 0; batch classifier loss: 0.271437; batch adversarial loss: 0.528578\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333149; batch adversarial loss: 0.528257\n",
      "epoch 180; iter: 0; batch classifier loss: 0.399846; batch adversarial loss: 0.518900\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361042; batch adversarial loss: 0.571387\n",
      "epoch 182; iter: 0; batch classifier loss: 0.287258; batch adversarial loss: 0.571442\n",
      "epoch 183; iter: 0; batch classifier loss: 0.279315; batch adversarial loss: 0.514982\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376019; batch adversarial loss: 0.583427\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358908; batch adversarial loss: 0.478182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347211; batch adversarial loss: 0.627830\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360392; batch adversarial loss: 0.525867\n",
      "epoch 188; iter: 0; batch classifier loss: 0.291420; batch adversarial loss: 0.533562\n",
      "epoch 189; iter: 0; batch classifier loss: 0.302158; batch adversarial loss: 0.592847\n",
      "epoch 190; iter: 0; batch classifier loss: 0.249286; batch adversarial loss: 0.517318\n",
      "epoch 191; iter: 0; batch classifier loss: 0.247039; batch adversarial loss: 0.487423\n",
      "epoch 192; iter: 0; batch classifier loss: 0.302506; batch adversarial loss: 0.495183\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383858; batch adversarial loss: 0.468047\n",
      "epoch 194; iter: 0; batch classifier loss: 0.293783; batch adversarial loss: 0.526278\n",
      "epoch 195; iter: 0; batch classifier loss: 0.358465; batch adversarial loss: 0.485285\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349732; batch adversarial loss: 0.498237\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354581; batch adversarial loss: 0.603762\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354965; batch adversarial loss: 0.580014\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309865; batch adversarial loss: 0.580675\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683252; batch adversarial loss: 0.646430\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583003; batch adversarial loss: 0.644137\n",
      "epoch 2; iter: 0; batch classifier loss: 0.513044; batch adversarial loss: 0.625852\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543116; batch adversarial loss: 0.624196\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573066; batch adversarial loss: 0.630726\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588160; batch adversarial loss: 0.622538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.637520; batch adversarial loss: 0.605690\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626954; batch adversarial loss: 0.608867\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618740; batch adversarial loss: 0.621051\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557348; batch adversarial loss: 0.593972\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578194; batch adversarial loss: 0.635580\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591015; batch adversarial loss: 0.580695\n",
      "epoch 12; iter: 0; batch classifier loss: 0.508379; batch adversarial loss: 0.601972\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543506; batch adversarial loss: 0.552364\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523744; batch adversarial loss: 0.643098\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570998; batch adversarial loss: 0.569366\n",
      "epoch 16; iter: 0; batch classifier loss: 0.585667; batch adversarial loss: 0.556673\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443167; batch adversarial loss: 0.511906\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517579; batch adversarial loss: 0.575125\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536913; batch adversarial loss: 0.625187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496224; batch adversarial loss: 0.498891\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492001; batch adversarial loss: 0.572520\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486131; batch adversarial loss: 0.534504\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472811; batch adversarial loss: 0.524048\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491007; batch adversarial loss: 0.570449\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472423; batch adversarial loss: 0.480410\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517372; batch adversarial loss: 0.586220\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457730; batch adversarial loss: 0.547364\n",
      "epoch 28; iter: 0; batch classifier loss: 0.552216; batch adversarial loss: 0.467495\n",
      "epoch 29; iter: 0; batch classifier loss: 0.566814; batch adversarial loss: 0.511162\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495310; batch adversarial loss: 0.493417\n",
      "epoch 31; iter: 0; batch classifier loss: 0.424495; batch adversarial loss: 0.518971\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459040; batch adversarial loss: 0.597256\n",
      "epoch 33; iter: 0; batch classifier loss: 0.495306; batch adversarial loss: 0.474025\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477676; batch adversarial loss: 0.562311\n",
      "epoch 35; iter: 0; batch classifier loss: 0.439054; batch adversarial loss: 0.465353\n",
      "epoch 36; iter: 0; batch classifier loss: 0.417209; batch adversarial loss: 0.490893\n",
      "epoch 37; iter: 0; batch classifier loss: 0.390424; batch adversarial loss: 0.499832\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417617; batch adversarial loss: 0.526745\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425384; batch adversarial loss: 0.535776\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445908; batch adversarial loss: 0.481519\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440762; batch adversarial loss: 0.553700\n",
      "epoch 42; iter: 0; batch classifier loss: 0.497611; batch adversarial loss: 0.562663\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393582; batch adversarial loss: 0.508581\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397869; batch adversarial loss: 0.553698\n",
      "epoch 45; iter: 0; batch classifier loss: 0.347141; batch adversarial loss: 0.508545\n",
      "epoch 46; iter: 0; batch classifier loss: 0.499370; batch adversarial loss: 0.553501\n",
      "epoch 47; iter: 0; batch classifier loss: 0.390216; batch adversarial loss: 0.571728\n",
      "epoch 48; iter: 0; batch classifier loss: 0.441732; batch adversarial loss: 0.617277\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402920; batch adversarial loss: 0.599410\n",
      "epoch 50; iter: 0; batch classifier loss: 0.488070; batch adversarial loss: 0.598189\n",
      "epoch 51; iter: 0; batch classifier loss: 0.460108; batch adversarial loss: 0.517776\n",
      "epoch 52; iter: 0; batch classifier loss: 0.369213; batch adversarial loss: 0.508237\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408071; batch adversarial loss: 0.590043\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443064; batch adversarial loss: 0.571696\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397167; batch adversarial loss: 0.554165\n",
      "epoch 56; iter: 0; batch classifier loss: 0.401363; batch adversarial loss: 0.525912\n",
      "epoch 57; iter: 0; batch classifier loss: 0.497572; batch adversarial loss: 0.490818\n",
      "epoch 58; iter: 0; batch classifier loss: 0.483133; batch adversarial loss: 0.482255\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456991; batch adversarial loss: 0.527225\n",
      "epoch 60; iter: 0; batch classifier loss: 0.399716; batch adversarial loss: 0.607191\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410795; batch adversarial loss: 0.544619\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378092; batch adversarial loss: 0.616734\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431653; batch adversarial loss: 0.561876\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387194; batch adversarial loss: 0.642806\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390176; batch adversarial loss: 0.546194\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421085; batch adversarial loss: 0.564403\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435337; batch adversarial loss: 0.480038\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380551; batch adversarial loss: 0.554222\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457420; batch adversarial loss: 0.460962\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393649; batch adversarial loss: 0.535246\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410343; batch adversarial loss: 0.489123\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379315; batch adversarial loss: 0.562664\n",
      "epoch 73; iter: 0; batch classifier loss: 0.464789; batch adversarial loss: 0.507480\n",
      "epoch 74; iter: 0; batch classifier loss: 0.309229; batch adversarial loss: 0.479625\n",
      "epoch 75; iter: 0; batch classifier loss: 0.465971; batch adversarial loss: 0.572308\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372918; batch adversarial loss: 0.553232\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433853; batch adversarial loss: 0.544095\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365027; batch adversarial loss: 0.535337\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430966; batch adversarial loss: 0.424752\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370258; batch adversarial loss: 0.534634\n",
      "epoch 81; iter: 0; batch classifier loss: 0.342750; batch adversarial loss: 0.554274\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421192; batch adversarial loss: 0.598969\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383221; batch adversarial loss: 0.535317\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421780; batch adversarial loss: 0.554008\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389489; batch adversarial loss: 0.535960\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418765; batch adversarial loss: 0.516766\n",
      "epoch 87; iter: 0; batch classifier loss: 0.463142; batch adversarial loss: 0.516597\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379154; batch adversarial loss: 0.562335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438937; batch adversarial loss: 0.590725\n",
      "epoch 90; iter: 0; batch classifier loss: 0.431877; batch adversarial loss: 0.589832\n",
      "epoch 91; iter: 0; batch classifier loss: 0.340363; batch adversarial loss: 0.591567\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378999; batch adversarial loss: 0.517381\n",
      "epoch 93; iter: 0; batch classifier loss: 0.436271; batch adversarial loss: 0.499294\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392031; batch adversarial loss: 0.508554\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387311; batch adversarial loss: 0.580840\n",
      "epoch 96; iter: 0; batch classifier loss: 0.473146; batch adversarial loss: 0.498936\n",
      "epoch 97; iter: 0; batch classifier loss: 0.373200; batch adversarial loss: 0.599033\n",
      "epoch 98; iter: 0; batch classifier loss: 0.399921; batch adversarial loss: 0.572192\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363730; batch adversarial loss: 0.589235\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367780; batch adversarial loss: 0.497985\n",
      "epoch 101; iter: 0; batch classifier loss: 0.378437; batch adversarial loss: 0.553140\n",
      "epoch 102; iter: 0; batch classifier loss: 0.478517; batch adversarial loss: 0.645959\n",
      "epoch 103; iter: 0; batch classifier loss: 0.449239; batch adversarial loss: 0.553152\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372234; batch adversarial loss: 0.609453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.394520; batch adversarial loss: 0.580859\n",
      "epoch 106; iter: 0; batch classifier loss: 0.356128; batch adversarial loss: 0.581099\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339338; batch adversarial loss: 0.572782\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364178; batch adversarial loss: 0.498709\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421502; batch adversarial loss: 0.480103\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391530; batch adversarial loss: 0.563300\n",
      "epoch 111; iter: 0; batch classifier loss: 0.462144; batch adversarial loss: 0.498411\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430321; batch adversarial loss: 0.553711\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377596; batch adversarial loss: 0.480121\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366872; batch adversarial loss: 0.545728\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388456; batch adversarial loss: 0.580652\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394327; batch adversarial loss: 0.570971\n",
      "epoch 117; iter: 0; batch classifier loss: 0.442939; batch adversarial loss: 0.571069\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367326; batch adversarial loss: 0.536528\n",
      "epoch 119; iter: 0; batch classifier loss: 0.322664; batch adversarial loss: 0.553342\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407216; batch adversarial loss: 0.589056\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351186; batch adversarial loss: 0.606987\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409485; batch adversarial loss: 0.525465\n",
      "epoch 123; iter: 0; batch classifier loss: 0.323900; batch adversarial loss: 0.499383\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347812; batch adversarial loss: 0.580611\n",
      "epoch 125; iter: 0; batch classifier loss: 0.424043; batch adversarial loss: 0.553180\n",
      "epoch 126; iter: 0; batch classifier loss: 0.459261; batch adversarial loss: 0.581482\n",
      "epoch 127; iter: 0; batch classifier loss: 0.364576; batch adversarial loss: 0.581220\n",
      "epoch 128; iter: 0; batch classifier loss: 0.371038; batch adversarial loss: 0.589827\n",
      "epoch 129; iter: 0; batch classifier loss: 0.404262; batch adversarial loss: 0.599052\n",
      "epoch 130; iter: 0; batch classifier loss: 0.428309; batch adversarial loss: 0.535754\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399100; batch adversarial loss: 0.644135\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364178; batch adversarial loss: 0.561745\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326427; batch adversarial loss: 0.544484\n",
      "epoch 134; iter: 0; batch classifier loss: 0.342479; batch adversarial loss: 0.683572\n",
      "epoch 135; iter: 0; batch classifier loss: 0.307115; batch adversarial loss: 0.526450\n",
      "epoch 136; iter: 0; batch classifier loss: 0.325451; batch adversarial loss: 0.563101\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396093; batch adversarial loss: 0.534898\n",
      "epoch 138; iter: 0; batch classifier loss: 0.330449; batch adversarial loss: 0.562731\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377296; batch adversarial loss: 0.545067\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401103; batch adversarial loss: 0.581412\n",
      "epoch 141; iter: 0; batch classifier loss: 0.313884; batch adversarial loss: 0.580428\n",
      "epoch 142; iter: 0; batch classifier loss: 0.301909; batch adversarial loss: 0.507985\n",
      "epoch 143; iter: 0; batch classifier loss: 0.316154; batch adversarial loss: 0.461688\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388503; batch adversarial loss: 0.560852\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399291; batch adversarial loss: 0.618584\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379198; batch adversarial loss: 0.572053\n",
      "epoch 147; iter: 0; batch classifier loss: 0.440770; batch adversarial loss: 0.526825\n",
      "epoch 148; iter: 0; batch classifier loss: 0.429145; batch adversarial loss: 0.553457\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367489; batch adversarial loss: 0.507643\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354938; batch adversarial loss: 0.518041\n",
      "epoch 151; iter: 0; batch classifier loss: 0.302806; batch adversarial loss: 0.562603\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362055; batch adversarial loss: 0.544746\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402401; batch adversarial loss: 0.609452\n",
      "epoch 154; iter: 0; batch classifier loss: 0.386768; batch adversarial loss: 0.498901\n",
      "epoch 155; iter: 0; batch classifier loss: 0.352718; batch adversarial loss: 0.471054\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387219; batch adversarial loss: 0.581832\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315876; batch adversarial loss: 0.572061\n",
      "epoch 158; iter: 0; batch classifier loss: 0.313350; batch adversarial loss: 0.534406\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380511; batch adversarial loss: 0.526673\n",
      "epoch 160; iter: 0; batch classifier loss: 0.313176; batch adversarial loss: 0.590711\n",
      "epoch 161; iter: 0; batch classifier loss: 0.406460; batch adversarial loss: 0.545000\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371314; batch adversarial loss: 0.479920\n",
      "epoch 163; iter: 0; batch classifier loss: 0.376733; batch adversarial loss: 0.534626\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409399; batch adversarial loss: 0.562181\n",
      "epoch 165; iter: 0; batch classifier loss: 0.489674; batch adversarial loss: 0.554090\n",
      "epoch 166; iter: 0; batch classifier loss: 0.321085; batch adversarial loss: 0.517690\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353315; batch adversarial loss: 0.463628\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340501; batch adversarial loss: 0.572659\n",
      "epoch 169; iter: 0; batch classifier loss: 0.307971; batch adversarial loss: 0.508729\n",
      "epoch 170; iter: 0; batch classifier loss: 0.272232; batch adversarial loss: 0.516518\n",
      "epoch 171; iter: 0; batch classifier loss: 0.422425; batch adversarial loss: 0.526296\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336496; batch adversarial loss: 0.507920\n",
      "epoch 173; iter: 0; batch classifier loss: 0.306422; batch adversarial loss: 0.534470\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361259; batch adversarial loss: 0.471240\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372976; batch adversarial loss: 0.480232\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388923; batch adversarial loss: 0.536449\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360627; batch adversarial loss: 0.580813\n",
      "epoch 178; iter: 0; batch classifier loss: 0.306020; batch adversarial loss: 0.563824\n",
      "epoch 179; iter: 0; batch classifier loss: 0.336984; batch adversarial loss: 0.525998\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307100; batch adversarial loss: 0.616866\n",
      "epoch 181; iter: 0; batch classifier loss: 0.430480; batch adversarial loss: 0.515984\n",
      "epoch 182; iter: 0; batch classifier loss: 0.356150; batch adversarial loss: 0.562751\n",
      "epoch 183; iter: 0; batch classifier loss: 0.468154; batch adversarial loss: 0.506973\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373702; batch adversarial loss: 0.536609\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319826; batch adversarial loss: 0.488978\n",
      "epoch 186; iter: 0; batch classifier loss: 0.420738; batch adversarial loss: 0.527660\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334262; batch adversarial loss: 0.534841\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353171; batch adversarial loss: 0.552508\n",
      "epoch 189; iter: 0; batch classifier loss: 0.316159; batch adversarial loss: 0.534611\n",
      "epoch 190; iter: 0; batch classifier loss: 0.445838; batch adversarial loss: 0.535308\n",
      "epoch 191; iter: 0; batch classifier loss: 0.435178; batch adversarial loss: 0.525300\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389195; batch adversarial loss: 0.544806\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356433; batch adversarial loss: 0.525762\n",
      "epoch 194; iter: 0; batch classifier loss: 0.386369; batch adversarial loss: 0.471969\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327199; batch adversarial loss: 0.580306\n",
      "epoch 196; iter: 0; batch classifier loss: 0.502649; batch adversarial loss: 0.571375\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361072; batch adversarial loss: 0.591115\n",
      "epoch 198; iter: 0; batch classifier loss: 0.388713; batch adversarial loss: 0.681141\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339597; batch adversarial loss: 0.536357\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708091; batch adversarial loss: 0.695457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574934; batch adversarial loss: 0.660921\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578393; batch adversarial loss: 0.651591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.632395; batch adversarial loss: 0.636840\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542459; batch adversarial loss: 0.638505\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552853; batch adversarial loss: 0.624376\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552861; batch adversarial loss: 0.611914\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509594; batch adversarial loss: 0.577806\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532244; batch adversarial loss: 0.605707\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488205; batch adversarial loss: 0.568779\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559346; batch adversarial loss: 0.557875\n",
      "epoch 11; iter: 0; batch classifier loss: 0.466414; batch adversarial loss: 0.578163\n",
      "epoch 12; iter: 0; batch classifier loss: 0.473693; batch adversarial loss: 0.544707\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518404; batch adversarial loss: 0.541884\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462748; batch adversarial loss: 0.631092\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548643; batch adversarial loss: 0.570719\n",
      "epoch 16; iter: 0; batch classifier loss: 0.597204; batch adversarial loss: 0.544298\n",
      "epoch 17; iter: 0; batch classifier loss: 0.441413; batch adversarial loss: 0.589242\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548389; batch adversarial loss: 0.515571\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535527; batch adversarial loss: 0.551354\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524568; batch adversarial loss: 0.544706\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473249; batch adversarial loss: 0.592431\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479065; batch adversarial loss: 0.595604\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472051; batch adversarial loss: 0.591531\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485846; batch adversarial loss: 0.576454\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487537; batch adversarial loss: 0.547161\n",
      "epoch 26; iter: 0; batch classifier loss: 0.540960; batch adversarial loss: 0.540309\n",
      "epoch 27; iter: 0; batch classifier loss: 0.405624; batch adversarial loss: 0.594485\n",
      "epoch 28; iter: 0; batch classifier loss: 0.535007; batch adversarial loss: 0.554921\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455414; batch adversarial loss: 0.620671\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533431; batch adversarial loss: 0.605626\n",
      "epoch 31; iter: 0; batch classifier loss: 0.519149; batch adversarial loss: 0.468122\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433691; batch adversarial loss: 0.561930\n",
      "epoch 33; iter: 0; batch classifier loss: 0.393400; batch adversarial loss: 0.550656\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488136; batch adversarial loss: 0.536032\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465567; batch adversarial loss: 0.566177\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469588; batch adversarial loss: 0.543301\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417184; batch adversarial loss: 0.579844\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418521; batch adversarial loss: 0.536040\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449934; batch adversarial loss: 0.529273\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507354; batch adversarial loss: 0.535923\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415627; batch adversarial loss: 0.541379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469577; batch adversarial loss: 0.449690\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429081; batch adversarial loss: 0.592411\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457871; batch adversarial loss: 0.564646\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477004; batch adversarial loss: 0.464582\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485965; batch adversarial loss: 0.519141\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428130; batch adversarial loss: 0.536596\n",
      "epoch 48; iter: 0; batch classifier loss: 0.493428; batch adversarial loss: 0.553090\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440914; batch adversarial loss: 0.552611\n",
      "epoch 50; iter: 0; batch classifier loss: 0.376596; batch adversarial loss: 0.500856\n",
      "epoch 51; iter: 0; batch classifier loss: 0.348997; batch adversarial loss: 0.482730\n",
      "epoch 52; iter: 0; batch classifier loss: 0.482485; batch adversarial loss: 0.580061\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429754; batch adversarial loss: 0.535633\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469884; batch adversarial loss: 0.580374\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431110; batch adversarial loss: 0.499544\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439966; batch adversarial loss: 0.499287\n",
      "epoch 57; iter: 0; batch classifier loss: 0.366961; batch adversarial loss: 0.544202\n",
      "epoch 58; iter: 0; batch classifier loss: 0.501788; batch adversarial loss: 0.489164\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414319; batch adversarial loss: 0.579316\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437020; batch adversarial loss: 0.562423\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373779; batch adversarial loss: 0.520399\n",
      "epoch 62; iter: 0; batch classifier loss: 0.381423; batch adversarial loss: 0.536101\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412684; batch adversarial loss: 0.562975\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414890; batch adversarial loss: 0.500336\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442945; batch adversarial loss: 0.535076\n",
      "epoch 66; iter: 0; batch classifier loss: 0.444086; batch adversarial loss: 0.571917\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392501; batch adversarial loss: 0.597989\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430051; batch adversarial loss: 0.544729\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429840; batch adversarial loss: 0.491962\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387330; batch adversarial loss: 0.614433\n",
      "epoch 71; iter: 0; batch classifier loss: 0.442418; batch adversarial loss: 0.472647\n",
      "epoch 72; iter: 0; batch classifier loss: 0.451283; batch adversarial loss: 0.651121\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418157; batch adversarial loss: 0.641595\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408904; batch adversarial loss: 0.498987\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415880; batch adversarial loss: 0.535474\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440788; batch adversarial loss: 0.545525\n",
      "epoch 77; iter: 0; batch classifier loss: 0.428862; batch adversarial loss: 0.535653\n",
      "epoch 78; iter: 0; batch classifier loss: 0.309527; batch adversarial loss: 0.517659\n",
      "epoch 79; iter: 0; batch classifier loss: 0.463734; batch adversarial loss: 0.553877\n",
      "epoch 80; iter: 0; batch classifier loss: 0.466050; batch adversarial loss: 0.599744\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351455; batch adversarial loss: 0.580487\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386323; batch adversarial loss: 0.553650\n",
      "epoch 83; iter: 0; batch classifier loss: 0.329600; batch adversarial loss: 0.553641\n",
      "epoch 84; iter: 0; batch classifier loss: 0.494113; batch adversarial loss: 0.517657\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393652; batch adversarial loss: 0.690394\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416385; batch adversarial loss: 0.500312\n",
      "epoch 87; iter: 0; batch classifier loss: 0.354192; batch adversarial loss: 0.553389\n",
      "epoch 88; iter: 0; batch classifier loss: 0.326697; batch adversarial loss: 0.517809\n",
      "epoch 89; iter: 0; batch classifier loss: 0.461429; batch adversarial loss: 0.507478\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404440; batch adversarial loss: 0.599990\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365810; batch adversarial loss: 0.517214\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366628; batch adversarial loss: 0.535112\n",
      "epoch 93; iter: 0; batch classifier loss: 0.330040; batch adversarial loss: 0.589874\n",
      "epoch 94; iter: 0; batch classifier loss: 0.412551; batch adversarial loss: 0.498587\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396711; batch adversarial loss: 0.516746\n",
      "epoch 96; iter: 0; batch classifier loss: 0.353297; batch adversarial loss: 0.543631\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410828; batch adversarial loss: 0.489957\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390767; batch adversarial loss: 0.562882\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460276; batch adversarial loss: 0.636189\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416271; batch adversarial loss: 0.526151\n",
      "epoch 101; iter: 0; batch classifier loss: 0.438920; batch adversarial loss: 0.572260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.372858; batch adversarial loss: 0.471449\n",
      "epoch 103; iter: 0; batch classifier loss: 0.303879; batch adversarial loss: 0.498767\n",
      "epoch 104; iter: 0; batch classifier loss: 0.401846; batch adversarial loss: 0.480608\n",
      "epoch 105; iter: 0; batch classifier loss: 0.367437; batch adversarial loss: 0.526446\n",
      "epoch 106; iter: 0; batch classifier loss: 0.349834; batch adversarial loss: 0.590289\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373763; batch adversarial loss: 0.525754\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395317; batch adversarial loss: 0.499338\n",
      "epoch 109; iter: 0; batch classifier loss: 0.404801; batch adversarial loss: 0.572089\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377131; batch adversarial loss: 0.580700\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387621; batch adversarial loss: 0.562581\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370353; batch adversarial loss: 0.617085\n",
      "epoch 113; iter: 0; batch classifier loss: 0.304933; batch adversarial loss: 0.544620\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358100; batch adversarial loss: 0.581574\n",
      "epoch 115; iter: 0; batch classifier loss: 0.375371; batch adversarial loss: 0.508236\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368240; batch adversarial loss: 0.517273\n",
      "epoch 117; iter: 0; batch classifier loss: 0.319873; batch adversarial loss: 0.563010\n",
      "epoch 118; iter: 0; batch classifier loss: 0.433036; batch adversarial loss: 0.535385\n",
      "epoch 119; iter: 0; batch classifier loss: 0.337108; batch adversarial loss: 0.526462\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394893; batch adversarial loss: 0.490433\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406967; batch adversarial loss: 0.508262\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410315; batch adversarial loss: 0.644476\n",
      "epoch 123; iter: 0; batch classifier loss: 0.347946; batch adversarial loss: 0.617458\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334676; batch adversarial loss: 0.499579\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375725; batch adversarial loss: 0.544355\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372489; batch adversarial loss: 0.590112\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348843; batch adversarial loss: 0.507276\n",
      "epoch 128; iter: 0; batch classifier loss: 0.302844; batch adversarial loss: 0.553412\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348019; batch adversarial loss: 0.572228\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405937; batch adversarial loss: 0.553559\n",
      "epoch 131; iter: 0; batch classifier loss: 0.269002; batch adversarial loss: 0.580588\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403365; batch adversarial loss: 0.517555\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412174; batch adversarial loss: 0.616919\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406686; batch adversarial loss: 0.544704\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371596; batch adversarial loss: 0.607746\n",
      "epoch 136; iter: 0; batch classifier loss: 0.456013; batch adversarial loss: 0.581122\n",
      "epoch 137; iter: 0; batch classifier loss: 0.395386; batch adversarial loss: 0.580940\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335136; batch adversarial loss: 0.481315\n",
      "epoch 139; iter: 0; batch classifier loss: 0.426914; batch adversarial loss: 0.590016\n",
      "epoch 140; iter: 0; batch classifier loss: 0.424031; batch adversarial loss: 0.571361\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390149; batch adversarial loss: 0.535473\n",
      "epoch 142; iter: 0; batch classifier loss: 0.423993; batch adversarial loss: 0.589836\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412592; batch adversarial loss: 0.499219\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337404; batch adversarial loss: 0.517398\n",
      "epoch 145; iter: 0; batch classifier loss: 0.430020; batch adversarial loss: 0.581617\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377135; batch adversarial loss: 0.554278\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388752; batch adversarial loss: 0.572034\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336868; batch adversarial loss: 0.571926\n",
      "epoch 149; iter: 0; batch classifier loss: 0.371572; batch adversarial loss: 0.535186\n",
      "epoch 150; iter: 0; batch classifier loss: 0.468409; batch adversarial loss: 0.462658\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387820; batch adversarial loss: 0.471815\n",
      "epoch 152; iter: 0; batch classifier loss: 0.409756; batch adversarial loss: 0.635590\n",
      "epoch 153; iter: 0; batch classifier loss: 0.408255; batch adversarial loss: 0.535207\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374587; batch adversarial loss: 0.572540\n",
      "epoch 155; iter: 0; batch classifier loss: 0.305821; batch adversarial loss: 0.452751\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396667; batch adversarial loss: 0.654580\n",
      "epoch 157; iter: 0; batch classifier loss: 0.432241; batch adversarial loss: 0.580627\n",
      "epoch 158; iter: 0; batch classifier loss: 0.393646; batch adversarial loss: 0.489939\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338925; batch adversarial loss: 0.526295\n",
      "epoch 160; iter: 0; batch classifier loss: 0.288458; batch adversarial loss: 0.561475\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410419; batch adversarial loss: 0.572674\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401863; batch adversarial loss: 0.489485\n",
      "epoch 163; iter: 0; batch classifier loss: 0.372783; batch adversarial loss: 0.563287\n",
      "epoch 164; iter: 0; batch classifier loss: 0.272442; batch adversarial loss: 0.535144\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345503; batch adversarial loss: 0.608034\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361728; batch adversarial loss: 0.643481\n",
      "epoch 167; iter: 0; batch classifier loss: 0.330058; batch adversarial loss: 0.482117\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359498; batch adversarial loss: 0.562747\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353584; batch adversarial loss: 0.508945\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333119; batch adversarial loss: 0.517506\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321505; batch adversarial loss: 0.517505\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404880; batch adversarial loss: 0.544501\n",
      "epoch 173; iter: 0; batch classifier loss: 0.347797; batch adversarial loss: 0.526384\n",
      "epoch 174; iter: 0; batch classifier loss: 0.451061; batch adversarial loss: 0.535493\n",
      "epoch 175; iter: 0; batch classifier loss: 0.377756; batch adversarial loss: 0.545234\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393339; batch adversarial loss: 0.553390\n",
      "epoch 177; iter: 0; batch classifier loss: 0.350258; batch adversarial loss: 0.497874\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343317; batch adversarial loss: 0.507615\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362459; batch adversarial loss: 0.507548\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366754; batch adversarial loss: 0.607895\n",
      "epoch 181; iter: 0; batch classifier loss: 0.315002; batch adversarial loss: 0.589676\n",
      "epoch 182; iter: 0; batch classifier loss: 0.345458; batch adversarial loss: 0.562622\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315602; batch adversarial loss: 0.617271\n",
      "epoch 184; iter: 0; batch classifier loss: 0.284688; batch adversarial loss: 0.589728\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358283; batch adversarial loss: 0.526255\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323522; batch adversarial loss: 0.562719\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371974; batch adversarial loss: 0.535337\n",
      "epoch 188; iter: 0; batch classifier loss: 0.323941; batch adversarial loss: 0.508361\n",
      "epoch 189; iter: 0; batch classifier loss: 0.428725; batch adversarial loss: 0.580630\n",
      "epoch 190; iter: 0; batch classifier loss: 0.304710; batch adversarial loss: 0.499234\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372737; batch adversarial loss: 0.598632\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342148; batch adversarial loss: 0.508463\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347586; batch adversarial loss: 0.499465\n",
      "epoch 194; iter: 0; batch classifier loss: 0.417651; batch adversarial loss: 0.535634\n",
      "epoch 195; iter: 0; batch classifier loss: 0.469160; batch adversarial loss: 0.553108\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378590; batch adversarial loss: 0.590343\n",
      "epoch 197; iter: 0; batch classifier loss: 0.346324; batch adversarial loss: 0.590519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.360329; batch adversarial loss: 0.571917\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363377; batch adversarial loss: 0.562512\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678868; batch adversarial loss: 0.693940\n",
      "epoch 1; iter: 0; batch classifier loss: 0.553259; batch adversarial loss: 0.665226\n",
      "epoch 2; iter: 0; batch classifier loss: 0.555190; batch adversarial loss: 0.643280\n",
      "epoch 3; iter: 0; batch classifier loss: 0.561409; batch adversarial loss: 0.628290\n",
      "epoch 4; iter: 0; batch classifier loss: 0.501334; batch adversarial loss: 0.604489\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568753; batch adversarial loss: 0.667769\n",
      "epoch 6; iter: 0; batch classifier loss: 0.456098; batch adversarial loss: 0.637875\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533678; batch adversarial loss: 0.586666\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537559; batch adversarial loss: 0.609812\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571316; batch adversarial loss: 0.592269\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537243; batch adversarial loss: 0.561574\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518209; batch adversarial loss: 0.638999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.584082; batch adversarial loss: 0.521722\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553838; batch adversarial loss: 0.552134\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514730; batch adversarial loss: 0.623026\n",
      "epoch 15; iter: 0; batch classifier loss: 0.495444; batch adversarial loss: 0.575622\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464799; batch adversarial loss: 0.513383\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484233; batch adversarial loss: 0.608252\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547784; batch adversarial loss: 0.522867\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538810; batch adversarial loss: 0.605720\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475201; batch adversarial loss: 0.565754\n",
      "epoch 21; iter: 0; batch classifier loss: 0.568200; batch adversarial loss: 0.529609\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526557; batch adversarial loss: 0.516283\n",
      "epoch 23; iter: 0; batch classifier loss: 0.446672; batch adversarial loss: 0.541896\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471787; batch adversarial loss: 0.519980\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482275; batch adversarial loss: 0.532189\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453206; batch adversarial loss: 0.570315\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440644; batch adversarial loss: 0.604629\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486601; batch adversarial loss: 0.538169\n",
      "epoch 29; iter: 0; batch classifier loss: 0.457770; batch adversarial loss: 0.614342\n",
      "epoch 30; iter: 0; batch classifier loss: 0.530095; batch adversarial loss: 0.571838\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501488; batch adversarial loss: 0.510010\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499256; batch adversarial loss: 0.561331\n",
      "epoch 33; iter: 0; batch classifier loss: 0.508807; batch adversarial loss: 0.606809\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393106; batch adversarial loss: 0.500331\n",
      "epoch 35; iter: 0; batch classifier loss: 0.431997; batch adversarial loss: 0.463684\n",
      "epoch 36; iter: 0; batch classifier loss: 0.412519; batch adversarial loss: 0.516939\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476711; batch adversarial loss: 0.624004\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455769; batch adversarial loss: 0.525889\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417386; batch adversarial loss: 0.626082\n",
      "epoch 40; iter: 0; batch classifier loss: 0.386202; batch adversarial loss: 0.565511\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449319; batch adversarial loss: 0.533227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459380; batch adversarial loss: 0.555463\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420354; batch adversarial loss: 0.479326\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398004; batch adversarial loss: 0.497930\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416570; batch adversarial loss: 0.497154\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440515; batch adversarial loss: 0.487039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.414488; batch adversarial loss: 0.514744\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478599; batch adversarial loss: 0.486041\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422380; batch adversarial loss: 0.546436\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424039; batch adversarial loss: 0.472261\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437326; batch adversarial loss: 0.592853\n",
      "epoch 52; iter: 0; batch classifier loss: 0.384469; batch adversarial loss: 0.536383\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381584; batch adversarial loss: 0.599292\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414822; batch adversarial loss: 0.570589\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442750; batch adversarial loss: 0.543510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.506243; batch adversarial loss: 0.468173\n",
      "epoch 57; iter: 0; batch classifier loss: 0.449113; batch adversarial loss: 0.528494\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455625; batch adversarial loss: 0.526580\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449040; batch adversarial loss: 0.443957\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437157; batch adversarial loss: 0.534119\n",
      "epoch 61; iter: 0; batch classifier loss: 0.507329; batch adversarial loss: 0.480111\n",
      "epoch 62; iter: 0; batch classifier loss: 0.548471; batch adversarial loss: 0.472684\n",
      "epoch 63; iter: 0; batch classifier loss: 0.444059; batch adversarial loss: 0.532388\n",
      "epoch 64; iter: 0; batch classifier loss: 0.490273; batch adversarial loss: 0.475669\n",
      "epoch 65; iter: 0; batch classifier loss: 0.393893; batch adversarial loss: 0.517918\n",
      "epoch 66; iter: 0; batch classifier loss: 0.355839; batch adversarial loss: 0.484441\n",
      "epoch 67; iter: 0; batch classifier loss: 0.393633; batch adversarial loss: 0.514533\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395447; batch adversarial loss: 0.517241\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438530; batch adversarial loss: 0.475665\n",
      "epoch 70; iter: 0; batch classifier loss: 0.386253; batch adversarial loss: 0.524923\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372404; batch adversarial loss: 0.527297\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390290; batch adversarial loss: 0.510202\n",
      "epoch 73; iter: 0; batch classifier loss: 0.482728; batch adversarial loss: 0.540996\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457997; batch adversarial loss: 0.552194\n",
      "epoch 75; iter: 0; batch classifier loss: 0.365810; batch adversarial loss: 0.561067\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371032; batch adversarial loss: 0.530283\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386491; batch adversarial loss: 0.497903\n",
      "epoch 78; iter: 0; batch classifier loss: 0.436372; batch adversarial loss: 0.547938\n",
      "epoch 79; iter: 0; batch classifier loss: 0.300231; batch adversarial loss: 0.606919\n",
      "epoch 80; iter: 0; batch classifier loss: 0.379449; batch adversarial loss: 0.589158\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407082; batch adversarial loss: 0.590947\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406091; batch adversarial loss: 0.482687\n",
      "epoch 83; iter: 0; batch classifier loss: 0.433053; batch adversarial loss: 0.572021\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372058; batch adversarial loss: 0.516208\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414570; batch adversarial loss: 0.569846\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379581; batch adversarial loss: 0.596219\n",
      "epoch 87; iter: 0; batch classifier loss: 0.444219; batch adversarial loss: 0.515577\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357399; batch adversarial loss: 0.472279\n",
      "epoch 89; iter: 0; batch classifier loss: 0.460857; batch adversarial loss: 0.589582\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407846; batch adversarial loss: 0.553560\n",
      "epoch 91; iter: 0; batch classifier loss: 0.371930; batch adversarial loss: 0.521683\n",
      "epoch 92; iter: 0; batch classifier loss: 0.361097; batch adversarial loss: 0.583496\n",
      "epoch 93; iter: 0; batch classifier loss: 0.348328; batch adversarial loss: 0.411348\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375090; batch adversarial loss: 0.525357\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407458; batch adversarial loss: 0.549784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.455341; batch adversarial loss: 0.488145\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397383; batch adversarial loss: 0.628458\n",
      "epoch 98; iter: 0; batch classifier loss: 0.485328; batch adversarial loss: 0.518951\n",
      "epoch 99; iter: 0; batch classifier loss: 0.370643; batch adversarial loss: 0.564386\n",
      "epoch 100; iter: 0; batch classifier loss: 0.409795; batch adversarial loss: 0.488238\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390150; batch adversarial loss: 0.572936\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412632; batch adversarial loss: 0.580392\n",
      "epoch 103; iter: 0; batch classifier loss: 0.338702; batch adversarial loss: 0.532043\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369092; batch adversarial loss: 0.527768\n",
      "epoch 105; iter: 0; batch classifier loss: 0.475048; batch adversarial loss: 0.469779\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328279; batch adversarial loss: 0.583788\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353811; batch adversarial loss: 0.590716\n",
      "epoch 108; iter: 0; batch classifier loss: 0.337309; batch adversarial loss: 0.579304\n",
      "epoch 109; iter: 0; batch classifier loss: 0.480263; batch adversarial loss: 0.546131\n",
      "epoch 110; iter: 0; batch classifier loss: 0.454607; batch adversarial loss: 0.505781\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344987; batch adversarial loss: 0.473197\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385353; batch adversarial loss: 0.549897\n",
      "epoch 113; iter: 0; batch classifier loss: 0.465448; batch adversarial loss: 0.563556\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418503; batch adversarial loss: 0.520709\n",
      "epoch 115; iter: 0; batch classifier loss: 0.462911; batch adversarial loss: 0.658366\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373990; batch adversarial loss: 0.493004\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338859; batch adversarial loss: 0.583062\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368138; batch adversarial loss: 0.575152\n",
      "epoch 119; iter: 0; batch classifier loss: 0.298496; batch adversarial loss: 0.534493\n",
      "epoch 120; iter: 0; batch classifier loss: 0.469955; batch adversarial loss: 0.620451\n",
      "epoch 121; iter: 0; batch classifier loss: 0.377996; batch adversarial loss: 0.525092\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350530; batch adversarial loss: 0.536091\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376028; batch adversarial loss: 0.588957\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366150; batch adversarial loss: 0.526729\n",
      "epoch 125; iter: 0; batch classifier loss: 0.321215; batch adversarial loss: 0.616390\n",
      "epoch 126; iter: 0; batch classifier loss: 0.397583; batch adversarial loss: 0.618429\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367393; batch adversarial loss: 0.561607\n",
      "epoch 128; iter: 0; batch classifier loss: 0.435335; batch adversarial loss: 0.561173\n",
      "epoch 129; iter: 0; batch classifier loss: 0.341780; batch adversarial loss: 0.556380\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366879; batch adversarial loss: 0.587130\n",
      "epoch 131; iter: 0; batch classifier loss: 0.486993; batch adversarial loss: 0.518971\n",
      "epoch 132; iter: 0; batch classifier loss: 0.466595; batch adversarial loss: 0.608556\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394198; batch adversarial loss: 0.555267\n",
      "epoch 134; iter: 0; batch classifier loss: 0.524519; batch adversarial loss: 0.590566\n",
      "epoch 135; iter: 0; batch classifier loss: 0.454120; batch adversarial loss: 0.543454\n",
      "epoch 136; iter: 0; batch classifier loss: 0.407387; batch adversarial loss: 0.549371\n",
      "epoch 137; iter: 0; batch classifier loss: 0.477359; batch adversarial loss: 0.498979\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356709; batch adversarial loss: 0.572639\n",
      "epoch 139; iter: 0; batch classifier loss: 0.469617; batch adversarial loss: 0.491024\n",
      "epoch 140; iter: 0; batch classifier loss: 0.491279; batch adversarial loss: 0.580837\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380055; batch adversarial loss: 0.588765\n",
      "epoch 142; iter: 0; batch classifier loss: 0.458767; batch adversarial loss: 0.560771\n",
      "epoch 143; iter: 0; batch classifier loss: 0.280809; batch adversarial loss: 0.516372\n",
      "epoch 144; iter: 0; batch classifier loss: 0.328436; batch adversarial loss: 0.453404\n",
      "epoch 145; iter: 0; batch classifier loss: 0.391576; batch adversarial loss: 0.588704\n",
      "epoch 146; iter: 0; batch classifier loss: 0.433599; batch adversarial loss: 0.551698\n",
      "epoch 147; iter: 0; batch classifier loss: 0.321039; batch adversarial loss: 0.524295\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353072; batch adversarial loss: 0.489335\n",
      "epoch 149; iter: 0; batch classifier loss: 0.431724; batch adversarial loss: 0.563780\n",
      "epoch 150; iter: 0; batch classifier loss: 0.416964; batch adversarial loss: 0.569648\n",
      "epoch 151; iter: 0; batch classifier loss: 0.385399; batch adversarial loss: 0.561881\n",
      "epoch 152; iter: 0; batch classifier loss: 0.271382; batch adversarial loss: 0.475488\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328653; batch adversarial loss: 0.526549\n",
      "epoch 154; iter: 0; batch classifier loss: 0.285730; batch adversarial loss: 0.500329\n",
      "epoch 155; iter: 0; batch classifier loss: 0.339641; batch adversarial loss: 0.549836\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370011; batch adversarial loss: 0.554916\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364327; batch adversarial loss: 0.549228\n",
      "epoch 158; iter: 0; batch classifier loss: 0.418030; batch adversarial loss: 0.555148\n",
      "epoch 159; iter: 0; batch classifier loss: 0.421049; batch adversarial loss: 0.553362\n",
      "epoch 160; iter: 0; batch classifier loss: 0.397690; batch adversarial loss: 0.522975\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362736; batch adversarial loss: 0.529396\n",
      "epoch 162; iter: 0; batch classifier loss: 0.462334; batch adversarial loss: 0.502129\n",
      "epoch 163; iter: 0; batch classifier loss: 0.371848; batch adversarial loss: 0.570996\n",
      "epoch 164; iter: 0; batch classifier loss: 0.388561; batch adversarial loss: 0.587177\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360141; batch adversarial loss: 0.510572\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364073; batch adversarial loss: 0.576098\n",
      "epoch 167; iter: 0; batch classifier loss: 0.427175; batch adversarial loss: 0.545814\n",
      "epoch 168; iter: 0; batch classifier loss: 0.297634; batch adversarial loss: 0.481818\n",
      "epoch 169; iter: 0; batch classifier loss: 0.411047; batch adversarial loss: 0.448484\n",
      "epoch 170; iter: 0; batch classifier loss: 0.389040; batch adversarial loss: 0.571712\n",
      "epoch 171; iter: 0; batch classifier loss: 0.418612; batch adversarial loss: 0.412769\n",
      "epoch 172; iter: 0; batch classifier loss: 0.340167; batch adversarial loss: 0.474881\n",
      "epoch 173; iter: 0; batch classifier loss: 0.421447; batch adversarial loss: 0.590867\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376235; batch adversarial loss: 0.563360\n",
      "epoch 175; iter: 0; batch classifier loss: 0.449548; batch adversarial loss: 0.537202\n",
      "epoch 176; iter: 0; batch classifier loss: 0.345666; batch adversarial loss: 0.542922\n",
      "epoch 177; iter: 0; batch classifier loss: 0.402858; batch adversarial loss: 0.554374\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330628; batch adversarial loss: 0.553015\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334728; batch adversarial loss: 0.535901\n",
      "epoch 180; iter: 0; batch classifier loss: 0.397923; batch adversarial loss: 0.539400\n",
      "epoch 181; iter: 0; batch classifier loss: 0.315528; batch adversarial loss: 0.565278\n",
      "epoch 182; iter: 0; batch classifier loss: 0.429955; batch adversarial loss: 0.519750\n",
      "epoch 183; iter: 0; batch classifier loss: 0.404698; batch adversarial loss: 0.574631\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383001; batch adversarial loss: 0.618565\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326625; batch adversarial loss: 0.491853\n",
      "epoch 186; iter: 0; batch classifier loss: 0.364022; batch adversarial loss: 0.490011\n",
      "epoch 187; iter: 0; batch classifier loss: 0.415518; batch adversarial loss: 0.459176\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330992; batch adversarial loss: 0.516828\n",
      "epoch 189; iter: 0; batch classifier loss: 0.438852; batch adversarial loss: 0.497759\n",
      "epoch 190; iter: 0; batch classifier loss: 0.399171; batch adversarial loss: 0.520324\n",
      "epoch 191; iter: 0; batch classifier loss: 0.328270; batch adversarial loss: 0.552128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.351799; batch adversarial loss: 0.441878\n",
      "epoch 193; iter: 0; batch classifier loss: 0.382974; batch adversarial loss: 0.544678\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312160; batch adversarial loss: 0.542346\n",
      "epoch 195; iter: 0; batch classifier loss: 0.401308; batch adversarial loss: 0.586935\n",
      "epoch 196; iter: 0; batch classifier loss: 0.363745; batch adversarial loss: 0.536833\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342547; batch adversarial loss: 0.576493\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365128; batch adversarial loss: 0.537400\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309731; batch adversarial loss: 0.556796\n",
      "epoch 0; iter: 0; batch classifier loss: 0.648437; batch adversarial loss: 0.704051\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591985; batch adversarial loss: 0.668634\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561007; batch adversarial loss: 0.668798\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607249; batch adversarial loss: 0.621716\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518254; batch adversarial loss: 0.635297\n",
      "epoch 5; iter: 0; batch classifier loss: 0.547534; batch adversarial loss: 0.602947\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535838; batch adversarial loss: 0.565471\n",
      "epoch 7; iter: 0; batch classifier loss: 0.445189; batch adversarial loss: 0.620922\n",
      "epoch 8; iter: 0; batch classifier loss: 0.473949; batch adversarial loss: 0.571860\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505426; batch adversarial loss: 0.550601\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578142; batch adversarial loss: 0.546519\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480066; batch adversarial loss: 0.624413\n",
      "epoch 12; iter: 0; batch classifier loss: 0.424959; batch adversarial loss: 0.531960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552380; batch adversarial loss: 0.490294\n",
      "epoch 14; iter: 0; batch classifier loss: 0.551735; batch adversarial loss: 0.619795\n",
      "epoch 15; iter: 0; batch classifier loss: 0.461247; batch adversarial loss: 0.578031\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477652; batch adversarial loss: 0.655906\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523428; batch adversarial loss: 0.564055\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500497; batch adversarial loss: 0.543363\n",
      "epoch 19; iter: 0; batch classifier loss: 0.464703; batch adversarial loss: 0.514298\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454530; batch adversarial loss: 0.435256\n",
      "epoch 21; iter: 0; batch classifier loss: 0.572420; batch adversarial loss: 0.587322\n",
      "epoch 22; iter: 0; batch classifier loss: 0.455935; batch adversarial loss: 0.535504\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506580; batch adversarial loss: 0.529725\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483007; batch adversarial loss: 0.531311\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439914; batch adversarial loss: 0.492648\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491348; batch adversarial loss: 0.535223\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484188; batch adversarial loss: 0.585924\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515138; batch adversarial loss: 0.512436\n",
      "epoch 29; iter: 0; batch classifier loss: 0.402109; batch adversarial loss: 0.509029\n",
      "epoch 30; iter: 0; batch classifier loss: 0.532267; batch adversarial loss: 0.526099\n",
      "epoch 31; iter: 0; batch classifier loss: 0.546542; batch adversarial loss: 0.492791\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470083; batch adversarial loss: 0.486889\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471744; batch adversarial loss: 0.575533\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430185; batch adversarial loss: 0.574011\n",
      "epoch 35; iter: 0; batch classifier loss: 0.391573; batch adversarial loss: 0.641250\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366338; batch adversarial loss: 0.531147\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417305; batch adversarial loss: 0.574564\n",
      "epoch 38; iter: 0; batch classifier loss: 0.479122; batch adversarial loss: 0.498168\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442940; batch adversarial loss: 0.558353\n",
      "epoch 40; iter: 0; batch classifier loss: 0.482758; batch adversarial loss: 0.532658\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382734; batch adversarial loss: 0.607993\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449897; batch adversarial loss: 0.527619\n",
      "epoch 43; iter: 0; batch classifier loss: 0.385075; batch adversarial loss: 0.554219\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393099; batch adversarial loss: 0.580452\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416242; batch adversarial loss: 0.481154\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437180; batch adversarial loss: 0.563035\n",
      "epoch 47; iter: 0; batch classifier loss: 0.373606; batch adversarial loss: 0.553533\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377241; batch adversarial loss: 0.554182\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429480; batch adversarial loss: 0.479146\n",
      "epoch 50; iter: 0; batch classifier loss: 0.377430; batch adversarial loss: 0.620005\n",
      "epoch 51; iter: 0; batch classifier loss: 0.306844; batch adversarial loss: 0.544589\n",
      "epoch 52; iter: 0; batch classifier loss: 0.362571; batch adversarial loss: 0.497138\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386341; batch adversarial loss: 0.497084\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443748; batch adversarial loss: 0.526044\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376054; batch adversarial loss: 0.591486\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445298; batch adversarial loss: 0.516026\n",
      "epoch 57; iter: 0; batch classifier loss: 0.434115; batch adversarial loss: 0.535426\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422854; batch adversarial loss: 0.467965\n",
      "epoch 59; iter: 0; batch classifier loss: 0.488484; batch adversarial loss: 0.515261\n",
      "epoch 60; iter: 0; batch classifier loss: 0.469518; batch adversarial loss: 0.525626\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403803; batch adversarial loss: 0.554238\n",
      "epoch 62; iter: 0; batch classifier loss: 0.372147; batch adversarial loss: 0.525244\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404232; batch adversarial loss: 0.555712\n",
      "epoch 64; iter: 0; batch classifier loss: 0.471911; batch adversarial loss: 0.505862\n",
      "epoch 65; iter: 0; batch classifier loss: 0.337011; batch adversarial loss: 0.525371\n",
      "epoch 66; iter: 0; batch classifier loss: 0.402018; batch adversarial loss: 0.544769\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402695; batch adversarial loss: 0.554384\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426219; batch adversarial loss: 0.477184\n",
      "epoch 69; iter: 0; batch classifier loss: 0.385092; batch adversarial loss: 0.583252\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392692; batch adversarial loss: 0.554778\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366226; batch adversarial loss: 0.534532\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412843; batch adversarial loss: 0.553859\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369495; batch adversarial loss: 0.573960\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364881; batch adversarial loss: 0.409358\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400072; batch adversarial loss: 0.496597\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387971; batch adversarial loss: 0.505825\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412630; batch adversarial loss: 0.535836\n",
      "epoch 78; iter: 0; batch classifier loss: 0.331020; batch adversarial loss: 0.524907\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389619; batch adversarial loss: 0.601194\n",
      "epoch 80; iter: 0; batch classifier loss: 0.434468; batch adversarial loss: 0.545151\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388004; batch adversarial loss: 0.515524\n",
      "epoch 82; iter: 0; batch classifier loss: 0.357441; batch adversarial loss: 0.448184\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405326; batch adversarial loss: 0.457920\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354905; batch adversarial loss: 0.495812\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427995; batch adversarial loss: 0.573941\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358468; batch adversarial loss: 0.554911\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405935; batch adversarial loss: 0.525591\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381083; batch adversarial loss: 0.602614\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409189; batch adversarial loss: 0.515986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.500146; batch adversarial loss: 0.505978\n",
      "epoch 91; iter: 0; batch classifier loss: 0.445069; batch adversarial loss: 0.544896\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383406; batch adversarial loss: 0.536101\n",
      "epoch 93; iter: 0; batch classifier loss: 0.314968; batch adversarial loss: 0.574068\n",
      "epoch 94; iter: 0; batch classifier loss: 0.441157; batch adversarial loss: 0.506508\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427032; batch adversarial loss: 0.515574\n",
      "epoch 96; iter: 0; batch classifier loss: 0.356555; batch adversarial loss: 0.467746\n",
      "epoch 97; iter: 0; batch classifier loss: 0.325808; batch adversarial loss: 0.506266\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409505; batch adversarial loss: 0.516171\n",
      "epoch 99; iter: 0; batch classifier loss: 0.483699; batch adversarial loss: 0.554662\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420762; batch adversarial loss: 0.544267\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405747; batch adversarial loss: 0.544263\n",
      "epoch 102; iter: 0; batch classifier loss: 0.501526; batch adversarial loss: 0.545030\n",
      "epoch 103; iter: 0; batch classifier loss: 0.338135; batch adversarial loss: 0.612246\n",
      "epoch 104; iter: 0; batch classifier loss: 0.429488; batch adversarial loss: 0.593344\n",
      "epoch 105; iter: 0; batch classifier loss: 0.455429; batch adversarial loss: 0.514565\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359825; batch adversarial loss: 0.573716\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378009; batch adversarial loss: 0.555166\n",
      "epoch 108; iter: 0; batch classifier loss: 0.410233; batch adversarial loss: 0.505131\n",
      "epoch 109; iter: 0; batch classifier loss: 0.463541; batch adversarial loss: 0.544430\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362308; batch adversarial loss: 0.573103\n",
      "epoch 111; iter: 0; batch classifier loss: 0.427397; batch adversarial loss: 0.544586\n",
      "epoch 112; iter: 0; batch classifier loss: 0.484245; batch adversarial loss: 0.554517\n",
      "epoch 113; iter: 0; batch classifier loss: 0.424644; batch adversarial loss: 0.563989\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400672; batch adversarial loss: 0.524786\n",
      "epoch 115; iter: 0; batch classifier loss: 0.386765; batch adversarial loss: 0.524796\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401237; batch adversarial loss: 0.496715\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384763; batch adversarial loss: 0.487859\n",
      "epoch 118; iter: 0; batch classifier loss: 0.316604; batch adversarial loss: 0.545129\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408397; batch adversarial loss: 0.525200\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383659; batch adversarial loss: 0.573982\n",
      "epoch 121; iter: 0; batch classifier loss: 0.343833; batch adversarial loss: 0.487292\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399617; batch adversarial loss: 0.525319\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380018; batch adversarial loss: 0.584166\n",
      "epoch 124; iter: 0; batch classifier loss: 0.383849; batch adversarial loss: 0.525799\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349450; batch adversarial loss: 0.534885\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359239; batch adversarial loss: 0.515958\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378515; batch adversarial loss: 0.574213\n",
      "epoch 128; iter: 0; batch classifier loss: 0.359409; batch adversarial loss: 0.496212\n",
      "epoch 129; iter: 0; batch classifier loss: 0.349902; batch adversarial loss: 0.477400\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384259; batch adversarial loss: 0.515670\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392324; batch adversarial loss: 0.573389\n",
      "epoch 132; iter: 0; batch classifier loss: 0.336667; batch adversarial loss: 0.496634\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375079; batch adversarial loss: 0.582926\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382386; batch adversarial loss: 0.573165\n",
      "epoch 135; iter: 0; batch classifier loss: 0.328192; batch adversarial loss: 0.467461\n",
      "epoch 136; iter: 0; batch classifier loss: 0.380982; batch adversarial loss: 0.544607\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334885; batch adversarial loss: 0.535612\n",
      "epoch 138; iter: 0; batch classifier loss: 0.309164; batch adversarial loss: 0.544485\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373008; batch adversarial loss: 0.583599\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373453; batch adversarial loss: 0.554516\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377210; batch adversarial loss: 0.660636\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375141; batch adversarial loss: 0.467511\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382332; batch adversarial loss: 0.515810\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376990; batch adversarial loss: 0.591996\n",
      "epoch 145; iter: 0; batch classifier loss: 0.310863; batch adversarial loss: 0.535501\n",
      "epoch 146; iter: 0; batch classifier loss: 0.390275; batch adversarial loss: 0.554525\n",
      "epoch 147; iter: 0; batch classifier loss: 0.293602; batch adversarial loss: 0.573034\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371369; batch adversarial loss: 0.438494\n",
      "epoch 149; iter: 0; batch classifier loss: 0.313496; batch adversarial loss: 0.506321\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363770; batch adversarial loss: 0.457402\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361972; batch adversarial loss: 0.515750\n",
      "epoch 152; iter: 0; batch classifier loss: 0.430072; batch adversarial loss: 0.448232\n",
      "epoch 153; iter: 0; batch classifier loss: 0.395895; batch adversarial loss: 0.583842\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329429; batch adversarial loss: 0.476755\n",
      "epoch 155; iter: 0; batch classifier loss: 0.309010; batch adversarial loss: 0.583435\n",
      "epoch 156; iter: 0; batch classifier loss: 0.416020; batch adversarial loss: 0.622354\n",
      "epoch 157; iter: 0; batch classifier loss: 0.444817; batch adversarial loss: 0.486950\n",
      "epoch 158; iter: 0; batch classifier loss: 0.358040; batch adversarial loss: 0.487664\n",
      "epoch 159; iter: 0; batch classifier loss: 0.395156; batch adversarial loss: 0.486327\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368844; batch adversarial loss: 0.506066\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347499; batch adversarial loss: 0.419235\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373287; batch adversarial loss: 0.497078\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331345; batch adversarial loss: 0.487278\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375162; batch adversarial loss: 0.487181\n",
      "epoch 165; iter: 0; batch classifier loss: 0.354458; batch adversarial loss: 0.583658\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364416; batch adversarial loss: 0.535161\n",
      "epoch 167; iter: 0; batch classifier loss: 0.386204; batch adversarial loss: 0.525467\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318954; batch adversarial loss: 0.544599\n",
      "epoch 169; iter: 0; batch classifier loss: 0.331788; batch adversarial loss: 0.495936\n",
      "epoch 170; iter: 0; batch classifier loss: 0.313700; batch adversarial loss: 0.534191\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373311; batch adversarial loss: 0.525941\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367448; batch adversarial loss: 0.544689\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345148; batch adversarial loss: 0.526255\n",
      "epoch 174; iter: 0; batch classifier loss: 0.382193; batch adversarial loss: 0.573272\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306069; batch adversarial loss: 0.467544\n",
      "epoch 176; iter: 0; batch classifier loss: 0.315991; batch adversarial loss: 0.525106\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343371; batch adversarial loss: 0.525648\n",
      "epoch 178; iter: 0; batch classifier loss: 0.456745; batch adversarial loss: 0.535254\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378608; batch adversarial loss: 0.515921\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328059; batch adversarial loss: 0.573675\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330948; batch adversarial loss: 0.564649\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318854; batch adversarial loss: 0.535750\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351253; batch adversarial loss: 0.535112\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359464; batch adversarial loss: 0.544763\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367534; batch adversarial loss: 0.535394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.372534; batch adversarial loss: 0.506386\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372301; batch adversarial loss: 0.573957\n",
      "epoch 188; iter: 0; batch classifier loss: 0.370159; batch adversarial loss: 0.534583\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305764; batch adversarial loss: 0.525366\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338161; batch adversarial loss: 0.476695\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378401; batch adversarial loss: 0.564019\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313880; batch adversarial loss: 0.544468\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351979; batch adversarial loss: 0.477323\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384942; batch adversarial loss: 0.574643\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381031; batch adversarial loss: 0.477562\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356731; batch adversarial loss: 0.583034\n",
      "epoch 197; iter: 0; batch classifier loss: 0.301996; batch adversarial loss: 0.574096\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377547; batch adversarial loss: 0.400092\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345272; batch adversarial loss: 0.485971\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706064; batch adversarial loss: 0.694989\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603208; batch adversarial loss: 0.679280\n",
      "epoch 2; iter: 0; batch classifier loss: 0.568463; batch adversarial loss: 0.653005\n",
      "epoch 3; iter: 0; batch classifier loss: 0.509812; batch adversarial loss: 0.616320\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539102; batch adversarial loss: 0.586925\n",
      "epoch 5; iter: 0; batch classifier loss: 0.501588; batch adversarial loss: 0.590478\n",
      "epoch 6; iter: 0; batch classifier loss: 0.487336; batch adversarial loss: 0.580097\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546353; batch adversarial loss: 0.583129\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465687; batch adversarial loss: 0.564944\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601066; batch adversarial loss: 0.575675\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545967; batch adversarial loss: 0.606839\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481801; batch adversarial loss: 0.569389\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509980; batch adversarial loss: 0.528930\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498583; batch adversarial loss: 0.571125\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503507; batch adversarial loss: 0.571040\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546832; batch adversarial loss: 0.570001\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472825; batch adversarial loss: 0.528134\n",
      "epoch 17; iter: 0; batch classifier loss: 0.542920; batch adversarial loss: 0.555064\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529033; batch adversarial loss: 0.534688\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518364; batch adversarial loss: 0.622238\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488171; batch adversarial loss: 0.604040\n",
      "epoch 21; iter: 0; batch classifier loss: 0.551880; batch adversarial loss: 0.601783\n",
      "epoch 22; iter: 0; batch classifier loss: 0.594805; batch adversarial loss: 0.545468\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501689; batch adversarial loss: 0.517960\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508601; batch adversarial loss: 0.650375\n",
      "epoch 25; iter: 0; batch classifier loss: 0.544323; batch adversarial loss: 0.529740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491744; batch adversarial loss: 0.503333\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448830; batch adversarial loss: 0.509544\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489336; batch adversarial loss: 0.507283\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450832; batch adversarial loss: 0.562520\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424523; batch adversarial loss: 0.570876\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452549; batch adversarial loss: 0.605201\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479180; batch adversarial loss: 0.492189\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494239; batch adversarial loss: 0.563558\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420306; batch adversarial loss: 0.507081\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390589; batch adversarial loss: 0.551415\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480069; batch adversarial loss: 0.574046\n",
      "epoch 37; iter: 0; batch classifier loss: 0.453255; batch adversarial loss: 0.515321\n",
      "epoch 38; iter: 0; batch classifier loss: 0.426529; batch adversarial loss: 0.542217\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433318; batch adversarial loss: 0.532441\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435594; batch adversarial loss: 0.601006\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396034; batch adversarial loss: 0.519587\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465932; batch adversarial loss: 0.486790\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426583; batch adversarial loss: 0.612940\n",
      "epoch 44; iter: 0; batch classifier loss: 0.342484; batch adversarial loss: 0.480829\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418563; batch adversarial loss: 0.536819\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370570; batch adversarial loss: 0.584390\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395013; batch adversarial loss: 0.513772\n",
      "epoch 48; iter: 0; batch classifier loss: 0.359785; batch adversarial loss: 0.523690\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418859; batch adversarial loss: 0.588871\n",
      "epoch 50; iter: 0; batch classifier loss: 0.333862; batch adversarial loss: 0.544530\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426550; batch adversarial loss: 0.581173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.381246; batch adversarial loss: 0.617322\n",
      "epoch 53; iter: 0; batch classifier loss: 0.366880; batch adversarial loss: 0.505626\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445709; batch adversarial loss: 0.418374\n",
      "epoch 55; iter: 0; batch classifier loss: 0.399360; batch adversarial loss: 0.533878\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388311; batch adversarial loss: 0.486970\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390396; batch adversarial loss: 0.536041\n",
      "epoch 58; iter: 0; batch classifier loss: 0.340688; batch adversarial loss: 0.613019\n",
      "epoch 59; iter: 0; batch classifier loss: 0.376008; batch adversarial loss: 0.523942\n",
      "epoch 60; iter: 0; batch classifier loss: 0.460086; batch adversarial loss: 0.545225\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409034; batch adversarial loss: 0.578534\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443706; batch adversarial loss: 0.505616\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391425; batch adversarial loss: 0.477503\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423738; batch adversarial loss: 0.512228\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417053; batch adversarial loss: 0.479681\n",
      "epoch 66; iter: 0; batch classifier loss: 0.470079; batch adversarial loss: 0.516552\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388633; batch adversarial loss: 0.594061\n",
      "epoch 68; iter: 0; batch classifier loss: 0.310688; batch adversarial loss: 0.646038\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413006; batch adversarial loss: 0.532993\n",
      "epoch 70; iter: 0; batch classifier loss: 0.485816; batch adversarial loss: 0.509043\n",
      "epoch 71; iter: 0; batch classifier loss: 0.319066; batch adversarial loss: 0.554820\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427313; batch adversarial loss: 0.534395\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376239; batch adversarial loss: 0.578325\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372906; batch adversarial loss: 0.526548\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413447; batch adversarial loss: 0.607690\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414780; batch adversarial loss: 0.527969\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394612; batch adversarial loss: 0.542627\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347456; batch adversarial loss: 0.533929\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354974; batch adversarial loss: 0.540742\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374673; batch adversarial loss: 0.532444\n",
      "epoch 81; iter: 0; batch classifier loss: 0.496488; batch adversarial loss: 0.524132\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388216; batch adversarial loss: 0.527263\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402605; batch adversarial loss: 0.591182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.431624; batch adversarial loss: 0.496819\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349991; batch adversarial loss: 0.572451\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373940; batch adversarial loss: 0.401420\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372619; batch adversarial loss: 0.562154\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362509; batch adversarial loss: 0.477677\n",
      "epoch 89; iter: 0; batch classifier loss: 0.337397; batch adversarial loss: 0.507295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348699; batch adversarial loss: 0.580627\n",
      "epoch 91; iter: 0; batch classifier loss: 0.448397; batch adversarial loss: 0.552989\n",
      "epoch 92; iter: 0; batch classifier loss: 0.350125; batch adversarial loss: 0.540707\n",
      "epoch 93; iter: 0; batch classifier loss: 0.295948; batch adversarial loss: 0.637990\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397012; batch adversarial loss: 0.612779\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375730; batch adversarial loss: 0.478034\n",
      "epoch 96; iter: 0; batch classifier loss: 0.406139; batch adversarial loss: 0.516977\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368203; batch adversarial loss: 0.527300\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386344; batch adversarial loss: 0.516851\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401906; batch adversarial loss: 0.513985\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361210; batch adversarial loss: 0.564325\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342292; batch adversarial loss: 0.545280\n",
      "epoch 102; iter: 0; batch classifier loss: 0.384605; batch adversarial loss: 0.554873\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362872; batch adversarial loss: 0.544528\n",
      "epoch 104; iter: 0; batch classifier loss: 0.378494; batch adversarial loss: 0.505876\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358577; batch adversarial loss: 0.448768\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390705; batch adversarial loss: 0.601707\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372221; batch adversarial loss: 0.477619\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353020; batch adversarial loss: 0.478234\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352385; batch adversarial loss: 0.584840\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357583; batch adversarial loss: 0.576092\n",
      "epoch 111; iter: 0; batch classifier loss: 0.314757; batch adversarial loss: 0.459538\n",
      "epoch 112; iter: 0; batch classifier loss: 0.322884; batch adversarial loss: 0.543197\n",
      "epoch 113; iter: 0; batch classifier loss: 0.446447; batch adversarial loss: 0.438219\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391044; batch adversarial loss: 0.544815\n",
      "epoch 115; iter: 0; batch classifier loss: 0.360865; batch adversarial loss: 0.536209\n",
      "epoch 116; iter: 0; batch classifier loss: 0.395449; batch adversarial loss: 0.513609\n",
      "epoch 117; iter: 0; batch classifier loss: 0.328700; batch adversarial loss: 0.531145\n",
      "epoch 118; iter: 0; batch classifier loss: 0.320389; batch adversarial loss: 0.490002\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350487; batch adversarial loss: 0.518100\n",
      "epoch 120; iter: 0; batch classifier loss: 0.298056; batch adversarial loss: 0.565671\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316933; batch adversarial loss: 0.534937\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366113; batch adversarial loss: 0.546970\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416224; batch adversarial loss: 0.555304\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378843; batch adversarial loss: 0.506925\n",
      "epoch 125; iter: 0; batch classifier loss: 0.348930; batch adversarial loss: 0.489278\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406595; batch adversarial loss: 0.524535\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355088; batch adversarial loss: 0.507495\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360041; batch adversarial loss: 0.498536\n",
      "epoch 129; iter: 0; batch classifier loss: 0.314894; batch adversarial loss: 0.637012\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348176; batch adversarial loss: 0.582626\n",
      "epoch 131; iter: 0; batch classifier loss: 0.425617; batch adversarial loss: 0.465624\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380377; batch adversarial loss: 0.531230\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376486; batch adversarial loss: 0.539193\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373970; batch adversarial loss: 0.475010\n",
      "epoch 135; iter: 0; batch classifier loss: 0.357763; batch adversarial loss: 0.583707\n",
      "epoch 136; iter: 0; batch classifier loss: 0.459028; batch adversarial loss: 0.552005\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340303; batch adversarial loss: 0.581132\n",
      "epoch 138; iter: 0; batch classifier loss: 0.395881; batch adversarial loss: 0.571818\n",
      "epoch 139; iter: 0; batch classifier loss: 0.274410; batch adversarial loss: 0.546058\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379433; batch adversarial loss: 0.564163\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371261; batch adversarial loss: 0.545310\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340336; batch adversarial loss: 0.432961\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367037; batch adversarial loss: 0.553648\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338868; batch adversarial loss: 0.489122\n",
      "epoch 145; iter: 0; batch classifier loss: 0.320057; batch adversarial loss: 0.564062\n",
      "epoch 146; iter: 0; batch classifier loss: 0.448486; batch adversarial loss: 0.564907\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379553; batch adversarial loss: 0.555083\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376808; batch adversarial loss: 0.620451\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373733; batch adversarial loss: 0.544366\n",
      "epoch 150; iter: 0; batch classifier loss: 0.328887; batch adversarial loss: 0.490173\n",
      "epoch 151; iter: 0; batch classifier loss: 0.402689; batch adversarial loss: 0.560145\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388436; batch adversarial loss: 0.503294\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389085; batch adversarial loss: 0.560352\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298202; batch adversarial loss: 0.500578\n",
      "epoch 155; iter: 0; batch classifier loss: 0.433282; batch adversarial loss: 0.467594\n",
      "epoch 156; iter: 0; batch classifier loss: 0.382962; batch adversarial loss: 0.535099\n",
      "epoch 157; iter: 0; batch classifier loss: 0.473242; batch adversarial loss: 0.498834\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362905; batch adversarial loss: 0.515725\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345826; batch adversarial loss: 0.504923\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376806; batch adversarial loss: 0.496850\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316965; batch adversarial loss: 0.477456\n",
      "epoch 162; iter: 0; batch classifier loss: 0.310655; batch adversarial loss: 0.513988\n",
      "epoch 163; iter: 0; batch classifier loss: 0.417359; batch adversarial loss: 0.552680\n",
      "epoch 164; iter: 0; batch classifier loss: 0.321451; batch adversarial loss: 0.599758\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315004; batch adversarial loss: 0.538320\n",
      "epoch 166; iter: 0; batch classifier loss: 0.416187; batch adversarial loss: 0.498182\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399294; batch adversarial loss: 0.516525\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376633; batch adversarial loss: 0.562830\n",
      "epoch 169; iter: 0; batch classifier loss: 0.358023; batch adversarial loss: 0.542950\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337752; batch adversarial loss: 0.583314\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327208; batch adversarial loss: 0.523997\n",
      "epoch 172; iter: 0; batch classifier loss: 0.277791; batch adversarial loss: 0.646489\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387931; batch adversarial loss: 0.449381\n",
      "epoch 174; iter: 0; batch classifier loss: 0.235437; batch adversarial loss: 0.535129\n",
      "epoch 175; iter: 0; batch classifier loss: 0.295691; batch adversarial loss: 0.562673\n",
      "epoch 176; iter: 0; batch classifier loss: 0.279268; batch adversarial loss: 0.496596\n",
      "epoch 177; iter: 0; batch classifier loss: 0.349507; batch adversarial loss: 0.552333\n",
      "epoch 178; iter: 0; batch classifier loss: 0.395396; batch adversarial loss: 0.497143\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345094; batch adversarial loss: 0.545479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.346918; batch adversarial loss: 0.528161\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354503; batch adversarial loss: 0.562674\n",
      "epoch 182; iter: 0; batch classifier loss: 0.331146; batch adversarial loss: 0.591947\n",
      "epoch 183; iter: 0; batch classifier loss: 0.442285; batch adversarial loss: 0.506313\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329463; batch adversarial loss: 0.431311\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349993; batch adversarial loss: 0.553249\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358701; batch adversarial loss: 0.516880\n",
      "epoch 187; iter: 0; batch classifier loss: 0.262821; batch adversarial loss: 0.486939\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348218; batch adversarial loss: 0.552130\n",
      "epoch 189; iter: 0; batch classifier loss: 0.413714; batch adversarial loss: 0.542521\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329254; batch adversarial loss: 0.580007\n",
      "epoch 191; iter: 0; batch classifier loss: 0.349438; batch adversarial loss: 0.552852\n",
      "epoch 192; iter: 0; batch classifier loss: 0.383603; batch adversarial loss: 0.467246\n",
      "epoch 193; iter: 0; batch classifier loss: 0.380246; batch adversarial loss: 0.600111\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379313; batch adversarial loss: 0.498064\n",
      "epoch 195; iter: 0; batch classifier loss: 0.306721; batch adversarial loss: 0.616480\n",
      "epoch 196; iter: 0; batch classifier loss: 0.297187; batch adversarial loss: 0.553154\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315249; batch adversarial loss: 0.534607\n",
      "epoch 198; iter: 0; batch classifier loss: 0.274863; batch adversarial loss: 0.503426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.382145; batch adversarial loss: 0.487610\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728850; batch adversarial loss: 0.849000\n",
      "epoch 1; iter: 0; batch classifier loss: 0.828706; batch adversarial loss: 0.931828\n",
      "epoch 2; iter: 0; batch classifier loss: 0.984167; batch adversarial loss: 0.929753\n",
      "epoch 3; iter: 0; batch classifier loss: 1.001671; batch adversarial loss: 0.849845\n",
      "epoch 4; iter: 0; batch classifier loss: 0.864112; batch adversarial loss: 0.762845\n",
      "epoch 5; iter: 0; batch classifier loss: 0.842229; batch adversarial loss: 0.727231\n",
      "epoch 6; iter: 0; batch classifier loss: 0.707029; batch adversarial loss: 0.678405\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607843; batch adversarial loss: 0.646036\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551182; batch adversarial loss: 0.637386\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522709; batch adversarial loss: 0.617364\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542650; batch adversarial loss: 0.575732\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532700; batch adversarial loss: 0.584743\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527233; batch adversarial loss: 0.541164\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567697; batch adversarial loss: 0.557371\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488332; batch adversarial loss: 0.575573\n",
      "epoch 15; iter: 0; batch classifier loss: 0.547813; batch adversarial loss: 0.573717\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484909; batch adversarial loss: 0.571816\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498408; batch adversarial loss: 0.620739\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496064; batch adversarial loss: 0.597750\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473462; batch adversarial loss: 0.613025\n",
      "epoch 20; iter: 0; batch classifier loss: 0.400897; batch adversarial loss: 0.574094\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488568; batch adversarial loss: 0.559889\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507775; batch adversarial loss: 0.502716\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516375; batch adversarial loss: 0.579370\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434316; batch adversarial loss: 0.510977\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487545; batch adversarial loss: 0.490470\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479269; batch adversarial loss: 0.537220\n",
      "epoch 27; iter: 0; batch classifier loss: 0.525034; batch adversarial loss: 0.580247\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418576; batch adversarial loss: 0.594951\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495152; batch adversarial loss: 0.528742\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456181; batch adversarial loss: 0.555319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.528113; batch adversarial loss: 0.498480\n",
      "epoch 32; iter: 0; batch classifier loss: 0.563980; batch adversarial loss: 0.507909\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462035; batch adversarial loss: 0.542268\n",
      "epoch 34; iter: 0; batch classifier loss: 0.530310; batch adversarial loss: 0.544454\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424326; batch adversarial loss: 0.540802\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474739; batch adversarial loss: 0.540084\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425169; batch adversarial loss: 0.568942\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482023; batch adversarial loss: 0.543350\n",
      "epoch 39; iter: 0; batch classifier loss: 0.395010; batch adversarial loss: 0.585816\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459269; batch adversarial loss: 0.547599\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472066; batch adversarial loss: 0.627199\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427405; batch adversarial loss: 0.543876\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439200; batch adversarial loss: 0.440951\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428733; batch adversarial loss: 0.548478\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436429; batch adversarial loss: 0.504974\n",
      "epoch 46; iter: 0; batch classifier loss: 0.391536; batch adversarial loss: 0.533725\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415859; batch adversarial loss: 0.543877\n",
      "epoch 48; iter: 0; batch classifier loss: 0.384040; batch adversarial loss: 0.515450\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436163; batch adversarial loss: 0.571264\n",
      "epoch 50; iter: 0; batch classifier loss: 0.384020; batch adversarial loss: 0.521115\n",
      "epoch 51; iter: 0; batch classifier loss: 0.327729; batch adversarial loss: 0.547136\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387756; batch adversarial loss: 0.561854\n",
      "epoch 53; iter: 0; batch classifier loss: 0.485546; batch adversarial loss: 0.619128\n",
      "epoch 54; iter: 0; batch classifier loss: 0.378420; batch adversarial loss: 0.564639\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425642; batch adversarial loss: 0.470363\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431555; batch adversarial loss: 0.518800\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387500; batch adversarial loss: 0.591409\n",
      "epoch 58; iter: 0; batch classifier loss: 0.405466; batch adversarial loss: 0.506709\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442841; batch adversarial loss: 0.489275\n",
      "epoch 60; iter: 0; batch classifier loss: 0.338071; batch adversarial loss: 0.609383\n",
      "epoch 61; iter: 0; batch classifier loss: 0.398241; batch adversarial loss: 0.470008\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450689; batch adversarial loss: 0.609290\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379187; batch adversarial loss: 0.591113\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419560; batch adversarial loss: 0.516780\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370021; batch adversarial loss: 0.516116\n",
      "epoch 66; iter: 0; batch classifier loss: 0.368252; batch adversarial loss: 0.478829\n",
      "epoch 67; iter: 0; batch classifier loss: 0.337655; batch adversarial loss: 0.582165\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419091; batch adversarial loss: 0.516341\n",
      "epoch 69; iter: 0; batch classifier loss: 0.337174; batch adversarial loss: 0.515391\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412738; batch adversarial loss: 0.600667\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370584; batch adversarial loss: 0.572928\n",
      "epoch 72; iter: 0; batch classifier loss: 0.493655; batch adversarial loss: 0.592210\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382116; batch adversarial loss: 0.525673\n",
      "epoch 74; iter: 0; batch classifier loss: 0.484833; batch adversarial loss: 0.516098\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358644; batch adversarial loss: 0.441725\n",
      "epoch 76; iter: 0; batch classifier loss: 0.506921; batch adversarial loss: 0.544105\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376348; batch adversarial loss: 0.565105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.375060; batch adversarial loss: 0.552592\n",
      "epoch 79; iter: 0; batch classifier loss: 0.339571; batch adversarial loss: 0.517052\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403037; batch adversarial loss: 0.535405\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403543; batch adversarial loss: 0.486610\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390500; batch adversarial loss: 0.583886\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367741; batch adversarial loss: 0.611080\n",
      "epoch 84; iter: 0; batch classifier loss: 0.332415; batch adversarial loss: 0.490206\n",
      "epoch 85; iter: 0; batch classifier loss: 0.299561; batch adversarial loss: 0.609389\n",
      "epoch 86; iter: 0; batch classifier loss: 0.376817; batch adversarial loss: 0.536238\n",
      "epoch 87; iter: 0; batch classifier loss: 0.408629; batch adversarial loss: 0.553618\n",
      "epoch 88; iter: 0; batch classifier loss: 0.353507; batch adversarial loss: 0.602744\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357859; batch adversarial loss: 0.535889\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355107; batch adversarial loss: 0.572494\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460162; batch adversarial loss: 0.527324\n",
      "epoch 92; iter: 0; batch classifier loss: 0.507383; batch adversarial loss: 0.553359\n",
      "epoch 93; iter: 0; batch classifier loss: 0.346739; batch adversarial loss: 0.543453\n",
      "epoch 94; iter: 0; batch classifier loss: 0.369335; batch adversarial loss: 0.554221\n",
      "epoch 95; iter: 0; batch classifier loss: 0.292923; batch adversarial loss: 0.486651\n",
      "epoch 96; iter: 0; batch classifier loss: 0.379378; batch adversarial loss: 0.488347\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367262; batch adversarial loss: 0.514863\n",
      "epoch 98; iter: 0; batch classifier loss: 0.332940; batch adversarial loss: 0.534980\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351844; batch adversarial loss: 0.571235\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403536; batch adversarial loss: 0.516501\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379483; batch adversarial loss: 0.544160\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379592; batch adversarial loss: 0.554844\n",
      "epoch 103; iter: 0; batch classifier loss: 0.435535; batch adversarial loss: 0.450666\n",
      "epoch 104; iter: 0; batch classifier loss: 0.469293; batch adversarial loss: 0.563038\n",
      "epoch 105; iter: 0; batch classifier loss: 0.375705; batch adversarial loss: 0.534041\n",
      "epoch 106; iter: 0; batch classifier loss: 0.453942; batch adversarial loss: 0.685137\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347584; batch adversarial loss: 0.549633\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393320; batch adversarial loss: 0.514733\n",
      "epoch 109; iter: 0; batch classifier loss: 0.404431; batch adversarial loss: 0.601767\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343878; batch adversarial loss: 0.591566\n",
      "epoch 111; iter: 0; batch classifier loss: 0.341483; batch adversarial loss: 0.522413\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384249; batch adversarial loss: 0.556472\n",
      "epoch 113; iter: 0; batch classifier loss: 0.423102; batch adversarial loss: 0.578936\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389927; batch adversarial loss: 0.647376\n",
      "epoch 115; iter: 0; batch classifier loss: 0.391132; batch adversarial loss: 0.561607\n",
      "epoch 116; iter: 0; batch classifier loss: 0.341282; batch adversarial loss: 0.508041\n",
      "epoch 117; iter: 0; batch classifier loss: 0.420911; batch adversarial loss: 0.601936\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387921; batch adversarial loss: 0.618139\n",
      "epoch 119; iter: 0; batch classifier loss: 0.336914; batch adversarial loss: 0.581663\n",
      "epoch 120; iter: 0; batch classifier loss: 0.340428; batch adversarial loss: 0.573378\n",
      "epoch 121; iter: 0; batch classifier loss: 0.424823; batch adversarial loss: 0.522516\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361200; batch adversarial loss: 0.589885\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346536; batch adversarial loss: 0.478508\n",
      "epoch 124; iter: 0; batch classifier loss: 0.327595; batch adversarial loss: 0.533627\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359836; batch adversarial loss: 0.429636\n",
      "epoch 126; iter: 0; batch classifier loss: 0.401618; batch adversarial loss: 0.630592\n",
      "epoch 127; iter: 0; batch classifier loss: 0.323239; batch adversarial loss: 0.597252\n",
      "epoch 128; iter: 0; batch classifier loss: 0.405037; batch adversarial loss: 0.515601\n",
      "epoch 129; iter: 0; batch classifier loss: 0.411314; batch adversarial loss: 0.542180\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363315; batch adversarial loss: 0.543546\n",
      "epoch 131; iter: 0; batch classifier loss: 0.308509; batch adversarial loss: 0.567326\n",
      "epoch 132; iter: 0; batch classifier loss: 0.387840; batch adversarial loss: 0.571115\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353636; batch adversarial loss: 0.488835\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340570; batch adversarial loss: 0.522977\n",
      "epoch 135; iter: 0; batch classifier loss: 0.359117; batch adversarial loss: 0.611230\n",
      "epoch 136; iter: 0; batch classifier loss: 0.274359; batch adversarial loss: 0.563603\n",
      "epoch 137; iter: 0; batch classifier loss: 0.345167; batch adversarial loss: 0.514828\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364079; batch adversarial loss: 0.557318\n",
      "epoch 139; iter: 0; batch classifier loss: 0.315158; batch adversarial loss: 0.508502\n",
      "epoch 140; iter: 0; batch classifier loss: 0.415972; batch adversarial loss: 0.562694\n",
      "epoch 141; iter: 0; batch classifier loss: 0.341280; batch adversarial loss: 0.526161\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336122; batch adversarial loss: 0.517336\n",
      "epoch 143; iter: 0; batch classifier loss: 0.441512; batch adversarial loss: 0.476896\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327256; batch adversarial loss: 0.537236\n",
      "epoch 145; iter: 0; batch classifier loss: 0.360208; batch adversarial loss: 0.507409\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327955; batch adversarial loss: 0.533530\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362182; batch adversarial loss: 0.516174\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381002; batch adversarial loss: 0.629084\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339364; batch adversarial loss: 0.545321\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413008; batch adversarial loss: 0.615600\n",
      "epoch 151; iter: 0; batch classifier loss: 0.299657; batch adversarial loss: 0.551926\n",
      "epoch 152; iter: 0; batch classifier loss: 0.266444; batch adversarial loss: 0.545703\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361678; batch adversarial loss: 0.581753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.471311; batch adversarial loss: 0.545200\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347738; batch adversarial loss: 0.591828\n",
      "epoch 156; iter: 0; batch classifier loss: 0.308856; batch adversarial loss: 0.508002\n",
      "epoch 157; iter: 0; batch classifier loss: 0.311623; batch adversarial loss: 0.566812\n",
      "epoch 158; iter: 0; batch classifier loss: 0.351546; batch adversarial loss: 0.517282\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316204; batch adversarial loss: 0.571979\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368485; batch adversarial loss: 0.590520\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345638; batch adversarial loss: 0.562548\n",
      "epoch 162; iter: 0; batch classifier loss: 0.341745; batch adversarial loss: 0.459626\n",
      "epoch 163; iter: 0; batch classifier loss: 0.323414; batch adversarial loss: 0.495459\n",
      "epoch 164; iter: 0; batch classifier loss: 0.323005; batch adversarial loss: 0.496644\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418400; batch adversarial loss: 0.571478\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339485; batch adversarial loss: 0.581927\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401020; batch adversarial loss: 0.478932\n",
      "epoch 168; iter: 0; batch classifier loss: 0.277812; batch adversarial loss: 0.546144\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379478; batch adversarial loss: 0.536571\n",
      "epoch 170; iter: 0; batch classifier loss: 0.293396; batch adversarial loss: 0.619416\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355836; batch adversarial loss: 0.552260\n",
      "epoch 172; iter: 0; batch classifier loss: 0.313577; batch adversarial loss: 0.583700\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367071; batch adversarial loss: 0.553394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.363371; batch adversarial loss: 0.553828\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328452; batch adversarial loss: 0.451876\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374470; batch adversarial loss: 0.496149\n",
      "epoch 177; iter: 0; batch classifier loss: 0.394743; batch adversarial loss: 0.544530\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333732; batch adversarial loss: 0.590688\n",
      "epoch 179; iter: 0; batch classifier loss: 0.309309; batch adversarial loss: 0.592323\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315710; batch adversarial loss: 0.554465\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355194; batch adversarial loss: 0.507789\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320290; batch adversarial loss: 0.459804\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347858; batch adversarial loss: 0.498110\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319503; batch adversarial loss: 0.556273\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328242; batch adversarial loss: 0.544973\n",
      "epoch 186; iter: 0; batch classifier loss: 0.297682; batch adversarial loss: 0.488028\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365183; batch adversarial loss: 0.626997\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355397; batch adversarial loss: 0.538389\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382283; batch adversarial loss: 0.476849\n",
      "epoch 190; iter: 0; batch classifier loss: 0.416249; batch adversarial loss: 0.533755\n",
      "epoch 191; iter: 0; batch classifier loss: 0.409356; batch adversarial loss: 0.496935\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297459; batch adversarial loss: 0.439639\n",
      "epoch 193; iter: 0; batch classifier loss: 0.276458; batch adversarial loss: 0.555115\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315379; batch adversarial loss: 0.527664\n",
      "epoch 195; iter: 0; batch classifier loss: 0.244684; batch adversarial loss: 0.543972\n",
      "epoch 196; iter: 0; batch classifier loss: 0.426459; batch adversarial loss: 0.553345\n",
      "epoch 197; iter: 0; batch classifier loss: 0.282868; batch adversarial loss: 0.543443\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332500; batch adversarial loss: 0.507016\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318501; batch adversarial loss: 0.440562\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678565; batch adversarial loss: 0.619715\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575984; batch adversarial loss: 0.648347\n",
      "epoch 2; iter: 0; batch classifier loss: 0.566171; batch adversarial loss: 0.651798\n",
      "epoch 3; iter: 0; batch classifier loss: 0.501325; batch adversarial loss: 0.618972\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598874; batch adversarial loss: 0.653773\n",
      "epoch 5; iter: 0; batch classifier loss: 0.651104; batch adversarial loss: 0.621796\n",
      "epoch 6; iter: 0; batch classifier loss: 0.679368; batch adversarial loss: 0.665025\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601148; batch adversarial loss: 0.642140\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530738; batch adversarial loss: 0.584188\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503994; batch adversarial loss: 0.589110\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575962; batch adversarial loss: 0.604580\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528039; batch adversarial loss: 0.577003\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567794; batch adversarial loss: 0.555395\n",
      "epoch 13; iter: 0; batch classifier loss: 0.629297; batch adversarial loss: 0.604414\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576329; batch adversarial loss: 0.547411\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432491; batch adversarial loss: 0.545185\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513193; batch adversarial loss: 0.564050\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409842; batch adversarial loss: 0.559440\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487273; batch adversarial loss: 0.542844\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465198; batch adversarial loss: 0.572350\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572842; batch adversarial loss: 0.515362\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455266; batch adversarial loss: 0.490998\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427282; batch adversarial loss: 0.489035\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481243; batch adversarial loss: 0.554228\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527117; batch adversarial loss: 0.484649\n",
      "epoch 25; iter: 0; batch classifier loss: 0.388890; batch adversarial loss: 0.513401\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499535; batch adversarial loss: 0.491797\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425175; batch adversarial loss: 0.527399\n",
      "epoch 28; iter: 0; batch classifier loss: 0.443296; batch adversarial loss: 0.482626\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441674; batch adversarial loss: 0.553831\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459672; batch adversarial loss: 0.518037\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469410; batch adversarial loss: 0.580722\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461763; batch adversarial loss: 0.544706\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466547; batch adversarial loss: 0.627800\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473911; batch adversarial loss: 0.572098\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485229; batch adversarial loss: 0.562913\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453821; batch adversarial loss: 0.590340\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489044; batch adversarial loss: 0.479782\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424888; batch adversarial loss: 0.558758\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450654; batch adversarial loss: 0.550324\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418981; batch adversarial loss: 0.489213\n",
      "epoch 41; iter: 0; batch classifier loss: 0.501006; batch adversarial loss: 0.506555\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465210; batch adversarial loss: 0.551699\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489965; batch adversarial loss: 0.545312\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459973; batch adversarial loss: 0.630473\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457728; batch adversarial loss: 0.554411\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409664; batch adversarial loss: 0.648908\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504567; batch adversarial loss: 0.570332\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399921; batch adversarial loss: 0.536084\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465213; batch adversarial loss: 0.526362\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389956; batch adversarial loss: 0.523802\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418398; batch adversarial loss: 0.506436\n",
      "epoch 52; iter: 0; batch classifier loss: 0.359770; batch adversarial loss: 0.523291\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450756; batch adversarial loss: 0.639327\n",
      "epoch 54; iter: 0; batch classifier loss: 0.444253; batch adversarial loss: 0.556497\n",
      "epoch 55; iter: 0; batch classifier loss: 0.354948; batch adversarial loss: 0.607843\n",
      "epoch 56; iter: 0; batch classifier loss: 0.472227; batch adversarial loss: 0.561378\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426847; batch adversarial loss: 0.459822\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435740; batch adversarial loss: 0.570722\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418974; batch adversarial loss: 0.552104\n",
      "epoch 60; iter: 0; batch classifier loss: 0.462382; batch adversarial loss: 0.560455\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416088; batch adversarial loss: 0.580477\n",
      "epoch 62; iter: 0; batch classifier loss: 0.343572; batch adversarial loss: 0.544428\n",
      "epoch 63; iter: 0; batch classifier loss: 0.491430; batch adversarial loss: 0.558430\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434647; batch adversarial loss: 0.536460\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403174; batch adversarial loss: 0.529694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.388475; batch adversarial loss: 0.536601\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412409; batch adversarial loss: 0.541306\n",
      "epoch 68; iter: 0; batch classifier loss: 0.379773; batch adversarial loss: 0.507066\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430609; batch adversarial loss: 0.551971\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433580; batch adversarial loss: 0.585195\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463423; batch adversarial loss: 0.585049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.408571; batch adversarial loss: 0.524164\n",
      "epoch 73; iter: 0; batch classifier loss: 0.459999; batch adversarial loss: 0.523784\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405611; batch adversarial loss: 0.583669\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433939; batch adversarial loss: 0.514621\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459884; batch adversarial loss: 0.544855\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376877; batch adversarial loss: 0.572099\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376017; batch adversarial loss: 0.516549\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392910; batch adversarial loss: 0.554065\n",
      "epoch 80; iter: 0; batch classifier loss: 0.396487; batch adversarial loss: 0.497203\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376765; batch adversarial loss: 0.544548\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390253; batch adversarial loss: 0.448888\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356905; batch adversarial loss: 0.553453\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431733; batch adversarial loss: 0.496610\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390754; batch adversarial loss: 0.534949\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426535; batch adversarial loss: 0.554013\n",
      "epoch 87; iter: 0; batch classifier loss: 0.419340; batch adversarial loss: 0.620861\n",
      "epoch 88; iter: 0; batch classifier loss: 0.366190; batch adversarial loss: 0.572811\n",
      "epoch 89; iter: 0; batch classifier loss: 0.354503; batch adversarial loss: 0.534043\n",
      "epoch 90; iter: 0; batch classifier loss: 0.433212; batch adversarial loss: 0.458405\n",
      "epoch 91; iter: 0; batch classifier loss: 0.359662; batch adversarial loss: 0.487206\n",
      "epoch 92; iter: 0; batch classifier loss: 0.333464; batch adversarial loss: 0.573211\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347444; batch adversarial loss: 0.532854\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383422; batch adversarial loss: 0.544252\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364785; batch adversarial loss: 0.597691\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389740; batch adversarial loss: 0.580336\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366609; batch adversarial loss: 0.554443\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401027; batch adversarial loss: 0.600189\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351618; batch adversarial loss: 0.567274\n",
      "epoch 100; iter: 0; batch classifier loss: 0.319756; batch adversarial loss: 0.551264\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371445; batch adversarial loss: 0.538640\n",
      "epoch 102; iter: 0; batch classifier loss: 0.341813; batch adversarial loss: 0.501271\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345333; batch adversarial loss: 0.554754\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413687; batch adversarial loss: 0.458539\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342812; batch adversarial loss: 0.493832\n",
      "epoch 106; iter: 0; batch classifier loss: 0.375155; batch adversarial loss: 0.580603\n",
      "epoch 107; iter: 0; batch classifier loss: 0.367204; batch adversarial loss: 0.463863\n",
      "epoch 108; iter: 0; batch classifier loss: 0.337583; batch adversarial loss: 0.505820\n",
      "epoch 109; iter: 0; batch classifier loss: 0.454503; batch adversarial loss: 0.528129\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351346; batch adversarial loss: 0.541013\n",
      "epoch 111; iter: 0; batch classifier loss: 0.366650; batch adversarial loss: 0.495907\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389129; batch adversarial loss: 0.505209\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377099; batch adversarial loss: 0.513944\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397982; batch adversarial loss: 0.457734\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407405; batch adversarial loss: 0.573430\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373821; batch adversarial loss: 0.609809\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406310; batch adversarial loss: 0.558192\n",
      "epoch 118; iter: 0; batch classifier loss: 0.426457; batch adversarial loss: 0.479256\n",
      "epoch 119; iter: 0; batch classifier loss: 0.319848; batch adversarial loss: 0.495887\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343841; batch adversarial loss: 0.435104\n",
      "epoch 121; iter: 0; batch classifier loss: 0.396185; batch adversarial loss: 0.564593\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402180; batch adversarial loss: 0.514543\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342283; batch adversarial loss: 0.521195\n",
      "epoch 124; iter: 0; batch classifier loss: 0.475133; batch adversarial loss: 0.562952\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351874; batch adversarial loss: 0.486617\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369339; batch adversarial loss: 0.525824\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330135; batch adversarial loss: 0.532813\n",
      "epoch 128; iter: 0; batch classifier loss: 0.323542; batch adversarial loss: 0.584691\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344311; batch adversarial loss: 0.610176\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421549; batch adversarial loss: 0.455743\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339588; batch adversarial loss: 0.470222\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359781; batch adversarial loss: 0.547176\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362222; batch adversarial loss: 0.554756\n",
      "epoch 134; iter: 0; batch classifier loss: 0.428950; batch adversarial loss: 0.554590\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408211; batch adversarial loss: 0.476509\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333629; batch adversarial loss: 0.626145\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344553; batch adversarial loss: 0.561219\n",
      "epoch 138; iter: 0; batch classifier loss: 0.322107; batch adversarial loss: 0.431718\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360953; batch adversarial loss: 0.560771\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376663; batch adversarial loss: 0.531850\n",
      "epoch 141; iter: 0; batch classifier loss: 0.414762; batch adversarial loss: 0.581871\n",
      "epoch 142; iter: 0; batch classifier loss: 0.392114; batch adversarial loss: 0.521117\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395648; batch adversarial loss: 0.505283\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437037; batch adversarial loss: 0.488298\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375893; batch adversarial loss: 0.534577\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363917; batch adversarial loss: 0.479768\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383607; batch adversarial loss: 0.514638\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279985; batch adversarial loss: 0.554345\n",
      "epoch 149; iter: 0; batch classifier loss: 0.408016; batch adversarial loss: 0.536437\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413087; batch adversarial loss: 0.521855\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351283; batch adversarial loss: 0.582626\n",
      "epoch 152; iter: 0; batch classifier loss: 0.284772; batch adversarial loss: 0.516951\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367578; batch adversarial loss: 0.513629\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354915; batch adversarial loss: 0.574707\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388144; batch adversarial loss: 0.557388\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317755; batch adversarial loss: 0.535634\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312575; batch adversarial loss: 0.616228\n",
      "epoch 158; iter: 0; batch classifier loss: 0.460664; batch adversarial loss: 0.561145\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366630; batch adversarial loss: 0.447256\n",
      "epoch 160; iter: 0; batch classifier loss: 0.402197; batch adversarial loss: 0.494905\n",
      "epoch 161; iter: 0; batch classifier loss: 0.449064; batch adversarial loss: 0.545483\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369940; batch adversarial loss: 0.528983\n",
      "epoch 163; iter: 0; batch classifier loss: 0.377494; batch adversarial loss: 0.568556\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395594; batch adversarial loss: 0.538060\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371178; batch adversarial loss: 0.570682\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356007; batch adversarial loss: 0.486673\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344328; batch adversarial loss: 0.553918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.361142; batch adversarial loss: 0.479719\n",
      "epoch 169; iter: 0; batch classifier loss: 0.292046; batch adversarial loss: 0.579673\n",
      "epoch 170; iter: 0; batch classifier loss: 0.351163; batch adversarial loss: 0.524583\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381984; batch adversarial loss: 0.475549\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353434; batch adversarial loss: 0.553166\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339211; batch adversarial loss: 0.475033\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351278; batch adversarial loss: 0.554104\n",
      "epoch 175; iter: 0; batch classifier loss: 0.446189; batch adversarial loss: 0.450676\n",
      "epoch 176; iter: 0; batch classifier loss: 0.392262; batch adversarial loss: 0.507085\n",
      "epoch 177; iter: 0; batch classifier loss: 0.414789; batch adversarial loss: 0.489846\n",
      "epoch 178; iter: 0; batch classifier loss: 0.407660; batch adversarial loss: 0.592757\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357235; batch adversarial loss: 0.477459\n",
      "epoch 180; iter: 0; batch classifier loss: 0.416487; batch adversarial loss: 0.510382\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358843; batch adversarial loss: 0.559596\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364062; batch adversarial loss: 0.604590\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352668; batch adversarial loss: 0.544302\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336603; batch adversarial loss: 0.466663\n",
      "epoch 185; iter: 0; batch classifier loss: 0.373652; batch adversarial loss: 0.581188\n",
      "epoch 186; iter: 0; batch classifier loss: 0.336990; batch adversarial loss: 0.535475\n",
      "epoch 187; iter: 0; batch classifier loss: 0.447096; batch adversarial loss: 0.593491\n",
      "epoch 188; iter: 0; batch classifier loss: 0.278381; batch adversarial loss: 0.524135\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315334; batch adversarial loss: 0.563866\n",
      "epoch 190; iter: 0; batch classifier loss: 0.330947; batch adversarial loss: 0.505574\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377145; batch adversarial loss: 0.497879\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375615; batch adversarial loss: 0.555440\n",
      "epoch 193; iter: 0; batch classifier loss: 0.382301; batch adversarial loss: 0.535718\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390830; batch adversarial loss: 0.517677\n",
      "epoch 195; iter: 0; batch classifier loss: 0.344298; batch adversarial loss: 0.570211\n",
      "epoch 196; iter: 0; batch classifier loss: 0.398020; batch adversarial loss: 0.561191\n",
      "epoch 197; iter: 0; batch classifier loss: 0.410600; batch adversarial loss: 0.542176\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360538; batch adversarial loss: 0.520913\n",
      "epoch 199; iter: 0; batch classifier loss: 0.443208; batch adversarial loss: 0.590999\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714361; batch adversarial loss: 0.693114\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609333; batch adversarial loss: 0.654897\n",
      "epoch 2; iter: 0; batch classifier loss: 0.634447; batch adversarial loss: 0.647657\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531995; batch adversarial loss: 0.668337\n",
      "epoch 4; iter: 0; batch classifier loss: 0.662545; batch adversarial loss: 0.666341\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572422; batch adversarial loss: 0.603957\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558353; batch adversarial loss: 0.648537\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584134; batch adversarial loss: 0.601064\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532222; batch adversarial loss: 0.588870\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552770; batch adversarial loss: 0.572109\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512512; batch adversarial loss: 0.563280\n",
      "epoch 11; iter: 0; batch classifier loss: 0.572170; batch adversarial loss: 0.655224\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556207; batch adversarial loss: 0.581148\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544046; batch adversarial loss: 0.569441\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544737; batch adversarial loss: 0.603839\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498518; batch adversarial loss: 0.575275\n",
      "epoch 16; iter: 0; batch classifier loss: 0.598984; batch adversarial loss: 0.553666\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487960; batch adversarial loss: 0.570797\n",
      "epoch 18; iter: 0; batch classifier loss: 0.495334; batch adversarial loss: 0.502269\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521385; batch adversarial loss: 0.580024\n",
      "epoch 20; iter: 0; batch classifier loss: 0.453607; batch adversarial loss: 0.538811\n",
      "epoch 21; iter: 0; batch classifier loss: 0.466548; batch adversarial loss: 0.503249\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483709; batch adversarial loss: 0.574790\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506038; batch adversarial loss: 0.534685\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524952; batch adversarial loss: 0.546785\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470302; batch adversarial loss: 0.548654\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493648; batch adversarial loss: 0.557987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.397375; batch adversarial loss: 0.562061\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473330; batch adversarial loss: 0.611543\n",
      "epoch 29; iter: 0; batch classifier loss: 0.353240; batch adversarial loss: 0.558577\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480762; batch adversarial loss: 0.586674\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435203; batch adversarial loss: 0.502374\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445475; batch adversarial loss: 0.510923\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434989; batch adversarial loss: 0.547500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.566599\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481071; batch adversarial loss: 0.547521\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425485; batch adversarial loss: 0.537760\n",
      "epoch 37; iter: 0; batch classifier loss: 0.382242; batch adversarial loss: 0.575181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430346; batch adversarial loss: 0.545741\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457121; batch adversarial loss: 0.517992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.368768; batch adversarial loss: 0.541049\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441759; batch adversarial loss: 0.591009\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416360; batch adversarial loss: 0.567447\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410559; batch adversarial loss: 0.581063\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419995; batch adversarial loss: 0.563459\n",
      "epoch 45; iter: 0; batch classifier loss: 0.499317; batch adversarial loss: 0.534944\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491814; batch adversarial loss: 0.554511\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433115; batch adversarial loss: 0.581587\n",
      "epoch 48; iter: 0; batch classifier loss: 0.518403; batch adversarial loss: 0.504345\n",
      "epoch 49; iter: 0; batch classifier loss: 0.454565; batch adversarial loss: 0.525062\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408867; batch adversarial loss: 0.591151\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383658; batch adversarial loss: 0.598008\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464028; batch adversarial loss: 0.506558\n",
      "epoch 53; iter: 0; batch classifier loss: 0.519944; batch adversarial loss: 0.445092\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417298; batch adversarial loss: 0.595790\n",
      "epoch 55; iter: 0; batch classifier loss: 0.379621; batch adversarial loss: 0.530149\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394299; batch adversarial loss: 0.572868\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397004; batch adversarial loss: 0.596933\n",
      "epoch 58; iter: 0; batch classifier loss: 0.476022; batch adversarial loss: 0.527646\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441104; batch adversarial loss: 0.476308\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420756; batch adversarial loss: 0.527557\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423040; batch adversarial loss: 0.587660\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398907; batch adversarial loss: 0.588455\n",
      "epoch 63; iter: 0; batch classifier loss: 0.380658; batch adversarial loss: 0.509712\n",
      "epoch 64; iter: 0; batch classifier loss: 0.354709; batch adversarial loss: 0.508546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.433190; batch adversarial loss: 0.589441\n",
      "epoch 66; iter: 0; batch classifier loss: 0.393922; batch adversarial loss: 0.589696\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405480; batch adversarial loss: 0.571689\n",
      "epoch 68; iter: 0; batch classifier loss: 0.387570; batch adversarial loss: 0.544187\n",
      "epoch 69; iter: 0; batch classifier loss: 0.456803; batch adversarial loss: 0.553444\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387753; batch adversarial loss: 0.590072\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398692; batch adversarial loss: 0.544261\n",
      "epoch 72; iter: 0; batch classifier loss: 0.470248; batch adversarial loss: 0.582166\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428335; batch adversarial loss: 0.570967\n",
      "epoch 74; iter: 0; batch classifier loss: 0.431163; batch adversarial loss: 0.589232\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387843; batch adversarial loss: 0.571118\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383478; batch adversarial loss: 0.572047\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416997; batch adversarial loss: 0.516204\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377738; batch adversarial loss: 0.508615\n",
      "epoch 79; iter: 0; batch classifier loss: 0.434333; batch adversarial loss: 0.526061\n",
      "epoch 80; iter: 0; batch classifier loss: 0.425273; batch adversarial loss: 0.562908\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361777; batch adversarial loss: 0.561979\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356954; batch adversarial loss: 0.554208\n",
      "epoch 83; iter: 0; batch classifier loss: 0.348613; batch adversarial loss: 0.518633\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366784; batch adversarial loss: 0.580371\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434717; batch adversarial loss: 0.496725\n",
      "epoch 86; iter: 0; batch classifier loss: 0.445583; batch adversarial loss: 0.524832\n",
      "epoch 87; iter: 0; batch classifier loss: 0.461982; batch adversarial loss: 0.532995\n",
      "epoch 88; iter: 0; batch classifier loss: 0.484160; batch adversarial loss: 0.588396\n",
      "epoch 89; iter: 0; batch classifier loss: 0.335974; batch adversarial loss: 0.534443\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344733; batch adversarial loss: 0.551177\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432113; batch adversarial loss: 0.484260\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388600; batch adversarial loss: 0.544113\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374063; batch adversarial loss: 0.542886\n",
      "epoch 94; iter: 0; batch classifier loss: 0.353869; batch adversarial loss: 0.615259\n",
      "epoch 95; iter: 0; batch classifier loss: 0.475649; batch adversarial loss: 0.633044\n",
      "epoch 96; iter: 0; batch classifier loss: 0.316164; batch adversarial loss: 0.607281\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338016; batch adversarial loss: 0.545499\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389485; batch adversarial loss: 0.560364\n",
      "epoch 99; iter: 0; batch classifier loss: 0.468374; batch adversarial loss: 0.616006\n",
      "epoch 100; iter: 0; batch classifier loss: 0.511655; batch adversarial loss: 0.581063\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394412; batch adversarial loss: 0.536366\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415099; batch adversarial loss: 0.633012\n",
      "epoch 103; iter: 0; batch classifier loss: 0.283842; batch adversarial loss: 0.553367\n",
      "epoch 104; iter: 0; batch classifier loss: 0.446067; batch adversarial loss: 0.509050\n",
      "epoch 105; iter: 0; batch classifier loss: 0.425745; batch adversarial loss: 0.536260\n",
      "epoch 106; iter: 0; batch classifier loss: 0.325869; batch adversarial loss: 0.509873\n",
      "epoch 107; iter: 0; batch classifier loss: 0.469692; batch adversarial loss: 0.518295\n",
      "epoch 108; iter: 0; batch classifier loss: 0.394341; batch adversarial loss: 0.641734\n",
      "epoch 109; iter: 0; batch classifier loss: 0.321083; batch adversarial loss: 0.562645\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388151; batch adversarial loss: 0.526907\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382740; batch adversarial loss: 0.543666\n",
      "epoch 112; iter: 0; batch classifier loss: 0.352520; batch adversarial loss: 0.617504\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356671; batch adversarial loss: 0.553508\n",
      "epoch 114; iter: 0; batch classifier loss: 0.407922; batch adversarial loss: 0.615786\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394486; batch adversarial loss: 0.480078\n",
      "epoch 116; iter: 0; batch classifier loss: 0.447866; batch adversarial loss: 0.535427\n",
      "epoch 117; iter: 0; batch classifier loss: 0.303779; batch adversarial loss: 0.455260\n",
      "epoch 118; iter: 0; batch classifier loss: 0.380096; batch adversarial loss: 0.533001\n",
      "epoch 119; iter: 0; batch classifier loss: 0.343372; batch adversarial loss: 0.498248\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366442; batch adversarial loss: 0.570736\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371226; batch adversarial loss: 0.639298\n",
      "epoch 122; iter: 0; batch classifier loss: 0.327929; batch adversarial loss: 0.552032\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342002; batch adversarial loss: 0.544481\n",
      "epoch 124; iter: 0; batch classifier loss: 0.421711; batch adversarial loss: 0.499220\n",
      "epoch 125; iter: 0; batch classifier loss: 0.453518; batch adversarial loss: 0.498502\n",
      "epoch 126; iter: 0; batch classifier loss: 0.341688; batch adversarial loss: 0.569033\n",
      "epoch 127; iter: 0; batch classifier loss: 0.421859; batch adversarial loss: 0.505679\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403053; batch adversarial loss: 0.462515\n",
      "epoch 129; iter: 0; batch classifier loss: 0.316171; batch adversarial loss: 0.680283\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363738; batch adversarial loss: 0.561804\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337111; batch adversarial loss: 0.554095\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431986; batch adversarial loss: 0.562778\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397386; batch adversarial loss: 0.572245\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387098; batch adversarial loss: 0.573122\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397236; batch adversarial loss: 0.572192\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393001; batch adversarial loss: 0.553857\n",
      "epoch 137; iter: 0; batch classifier loss: 0.345234; batch adversarial loss: 0.554153\n",
      "epoch 138; iter: 0; batch classifier loss: 0.402624; batch adversarial loss: 0.431811\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390049; batch adversarial loss: 0.543579\n",
      "epoch 140; iter: 0; batch classifier loss: 0.416263; batch adversarial loss: 0.554079\n",
      "epoch 141; iter: 0; batch classifier loss: 0.426238; batch adversarial loss: 0.571345\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386446; batch adversarial loss: 0.543748\n",
      "epoch 143; iter: 0; batch classifier loss: 0.419188; batch adversarial loss: 0.501013\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395214; batch adversarial loss: 0.437353\n",
      "epoch 145; iter: 0; batch classifier loss: 0.271795; batch adversarial loss: 0.581201\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377044; batch adversarial loss: 0.571282\n",
      "epoch 147; iter: 0; batch classifier loss: 0.311643; batch adversarial loss: 0.553208\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357647; batch adversarial loss: 0.543265\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377522; batch adversarial loss: 0.562888\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362885; batch adversarial loss: 0.536577\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371698; batch adversarial loss: 0.481898\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387672; batch adversarial loss: 0.616194\n",
      "epoch 153; iter: 0; batch classifier loss: 0.375458; batch adversarial loss: 0.588497\n",
      "epoch 154; iter: 0; batch classifier loss: 0.378761; batch adversarial loss: 0.482276\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336350; batch adversarial loss: 0.578741\n",
      "epoch 156; iter: 0; batch classifier loss: 0.310899; batch adversarial loss: 0.570846\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359708; batch adversarial loss: 0.562216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403995; batch adversarial loss: 0.545795\n",
      "epoch 159; iter: 0; batch classifier loss: 0.382655; batch adversarial loss: 0.580258\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323476; batch adversarial loss: 0.624818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.464685; batch adversarial loss: 0.534213\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379308; batch adversarial loss: 0.544752\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386148; batch adversarial loss: 0.562624\n",
      "epoch 164; iter: 0; batch classifier loss: 0.405603; batch adversarial loss: 0.535668\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410848; batch adversarial loss: 0.580809\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366816; batch adversarial loss: 0.553440\n",
      "epoch 167; iter: 0; batch classifier loss: 0.417215; batch adversarial loss: 0.660332\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375410; batch adversarial loss: 0.516694\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366183; batch adversarial loss: 0.535632\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322643; batch adversarial loss: 0.490788\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353359; batch adversarial loss: 0.455804\n",
      "epoch 172; iter: 0; batch classifier loss: 0.270061; batch adversarial loss: 0.526665\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316089; batch adversarial loss: 0.571479\n",
      "epoch 174; iter: 0; batch classifier loss: 0.443480; batch adversarial loss: 0.580924\n",
      "epoch 175; iter: 0; batch classifier loss: 0.462972; batch adversarial loss: 0.580713\n",
      "epoch 176; iter: 0; batch classifier loss: 0.350428; batch adversarial loss: 0.481539\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315589; batch adversarial loss: 0.607084\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314181; batch adversarial loss: 0.543514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347956; batch adversarial loss: 0.554500\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389646; batch adversarial loss: 0.499780\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320246; batch adversarial loss: 0.516820\n",
      "epoch 182; iter: 0; batch classifier loss: 0.410518; batch adversarial loss: 0.518244\n",
      "epoch 183; iter: 0; batch classifier loss: 0.363175; batch adversarial loss: 0.526478\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336298; batch adversarial loss: 0.571488\n",
      "epoch 185; iter: 0; batch classifier loss: 0.287771; batch adversarial loss: 0.471868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368233; batch adversarial loss: 0.552884\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333369; batch adversarial loss: 0.508455\n",
      "epoch 188; iter: 0; batch classifier loss: 0.326889; batch adversarial loss: 0.588801\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354608; batch adversarial loss: 0.562272\n",
      "epoch 190; iter: 0; batch classifier loss: 0.396562; batch adversarial loss: 0.491001\n",
      "epoch 191; iter: 0; batch classifier loss: 0.349189; batch adversarial loss: 0.517773\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339978; batch adversarial loss: 0.553623\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342231; batch adversarial loss: 0.553466\n",
      "epoch 194; iter: 0; batch classifier loss: 0.299018; batch adversarial loss: 0.571142\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328050; batch adversarial loss: 0.581028\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310703; batch adversarial loss: 0.571300\n",
      "epoch 197; iter: 0; batch classifier loss: 0.458627; batch adversarial loss: 0.527697\n",
      "epoch 198; iter: 0; batch classifier loss: 0.282993; batch adversarial loss: 0.590158\n",
      "epoch 199; iter: 0; batch classifier loss: 0.395006; batch adversarial loss: 0.563165\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701125; batch adversarial loss: 0.643234\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560703; batch adversarial loss: 0.651226\n",
      "epoch 2; iter: 0; batch classifier loss: 0.608896; batch adversarial loss: 0.644083\n",
      "epoch 3; iter: 0; batch classifier loss: 0.560257; batch adversarial loss: 0.611591\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565353; batch adversarial loss: 0.609238\n",
      "epoch 5; iter: 0; batch classifier loss: 0.622680; batch adversarial loss: 0.603776\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605702; batch adversarial loss: 0.617046\n",
      "epoch 7; iter: 0; batch classifier loss: 0.577796; batch adversarial loss: 0.611098\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566867; batch adversarial loss: 0.586356\n",
      "epoch 9; iter: 0; batch classifier loss: 0.599261; batch adversarial loss: 0.611758\n",
      "epoch 10; iter: 0; batch classifier loss: 0.587909; batch adversarial loss: 0.596273\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529093; batch adversarial loss: 0.572019\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534878; batch adversarial loss: 0.569372\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502184; batch adversarial loss: 0.561155\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540833; batch adversarial loss: 0.575106\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536855; batch adversarial loss: 0.545902\n",
      "epoch 16; iter: 0; batch classifier loss: 0.458765; batch adversarial loss: 0.578017\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467601; batch adversarial loss: 0.502135\n",
      "epoch 18; iter: 0; batch classifier loss: 0.451732; batch adversarial loss: 0.545881\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535699; batch adversarial loss: 0.548193\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482790; batch adversarial loss: 0.545359\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502815; batch adversarial loss: 0.534579\n",
      "epoch 22; iter: 0; batch classifier loss: 0.445038; batch adversarial loss: 0.523509\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459235; batch adversarial loss: 0.515010\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464531; batch adversarial loss: 0.556599\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566976; batch adversarial loss: 0.565177\n",
      "epoch 26; iter: 0; batch classifier loss: 0.559359; batch adversarial loss: 0.590367\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482554; batch adversarial loss: 0.527898\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488769; batch adversarial loss: 0.581388\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432701; batch adversarial loss: 0.590162\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434120; batch adversarial loss: 0.474806\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468532; batch adversarial loss: 0.438334\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477973; batch adversarial loss: 0.562574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489824; batch adversarial loss: 0.571678\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471107; batch adversarial loss: 0.562577\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422586; batch adversarial loss: 0.516615\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487704; batch adversarial loss: 0.525560\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471395; batch adversarial loss: 0.516735\n",
      "epoch 38; iter: 0; batch classifier loss: 0.477308; batch adversarial loss: 0.535677\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501043; batch adversarial loss: 0.574049\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459678; batch adversarial loss: 0.525779\n",
      "epoch 41; iter: 0; batch classifier loss: 0.457202; batch adversarial loss: 0.450202\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410957; batch adversarial loss: 0.609584\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470674; batch adversarial loss: 0.524604\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493923; batch adversarial loss: 0.515029\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433543; batch adversarial loss: 0.536477\n",
      "epoch 46; iter: 0; batch classifier loss: 0.484484; batch adversarial loss: 0.461240\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449096; batch adversarial loss: 0.536653\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478730; batch adversarial loss: 0.479013\n",
      "epoch 49; iter: 0; batch classifier loss: 0.494706; batch adversarial loss: 0.554595\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479154; batch adversarial loss: 0.533034\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442706; batch adversarial loss: 0.513469\n",
      "epoch 52; iter: 0; batch classifier loss: 0.491658; batch adversarial loss: 0.545393\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427704; batch adversarial loss: 0.610314\n",
      "epoch 54; iter: 0; batch classifier loss: 0.476887; batch adversarial loss: 0.526251\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414221; batch adversarial loss: 0.516393\n",
      "epoch 56; iter: 0; batch classifier loss: 0.491765; batch adversarial loss: 0.590804\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439374; batch adversarial loss: 0.504548\n",
      "epoch 58; iter: 0; batch classifier loss: 0.415127; batch adversarial loss: 0.573803\n",
      "epoch 59; iter: 0; batch classifier loss: 0.397741; batch adversarial loss: 0.566029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.423402; batch adversarial loss: 0.574340\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442216; batch adversarial loss: 0.523840\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391368; batch adversarial loss: 0.582665\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433108; batch adversarial loss: 0.531671\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411161; batch adversarial loss: 0.561552\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376629; batch adversarial loss: 0.494562\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409258; batch adversarial loss: 0.497150\n",
      "epoch 67; iter: 0; batch classifier loss: 0.470398; batch adversarial loss: 0.479187\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411538; batch adversarial loss: 0.572522\n",
      "epoch 69; iter: 0; batch classifier loss: 0.421531; batch adversarial loss: 0.467964\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407373; batch adversarial loss: 0.563073\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438964; batch adversarial loss: 0.619394\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416091; batch adversarial loss: 0.476739\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440112; batch adversarial loss: 0.573704\n",
      "epoch 74; iter: 0; batch classifier loss: 0.371283; batch adversarial loss: 0.572687\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358575; batch adversarial loss: 0.479475\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383043; batch adversarial loss: 0.486033\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345261; batch adversarial loss: 0.546398\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407079; batch adversarial loss: 0.485348\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354495; batch adversarial loss: 0.553160\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403323; batch adversarial loss: 0.573062\n",
      "epoch 81; iter: 0; batch classifier loss: 0.329469; batch adversarial loss: 0.544555\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376554; batch adversarial loss: 0.629343\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377163; batch adversarial loss: 0.534355\n",
      "epoch 84; iter: 0; batch classifier loss: 0.463532; batch adversarial loss: 0.527967\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401259; batch adversarial loss: 0.516065\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381157; batch adversarial loss: 0.565214\n",
      "epoch 87; iter: 0; batch classifier loss: 0.446798; batch adversarial loss: 0.603109\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391575; batch adversarial loss: 0.477678\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428535; batch adversarial loss: 0.459284\n",
      "epoch 90; iter: 0; batch classifier loss: 0.439763; batch adversarial loss: 0.486794\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421034; batch adversarial loss: 0.593015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.442826; batch adversarial loss: 0.525439\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420501; batch adversarial loss: 0.551521\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452949; batch adversarial loss: 0.525332\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343972; batch adversarial loss: 0.525881\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414909; batch adversarial loss: 0.623643\n",
      "epoch 97; iter: 0; batch classifier loss: 0.448385; batch adversarial loss: 0.431128\n",
      "epoch 98; iter: 0; batch classifier loss: 0.461258; batch adversarial loss: 0.546909\n",
      "epoch 99; iter: 0; batch classifier loss: 0.345021; batch adversarial loss: 0.557289\n",
      "epoch 100; iter: 0; batch classifier loss: 0.460404; batch adversarial loss: 0.494622\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358317; batch adversarial loss: 0.505295\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400416; batch adversarial loss: 0.603614\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402951; batch adversarial loss: 0.556026\n",
      "epoch 104; iter: 0; batch classifier loss: 0.379466; batch adversarial loss: 0.602474\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404136; batch adversarial loss: 0.544904\n",
      "epoch 106; iter: 0; batch classifier loss: 0.447904; batch adversarial loss: 0.585851\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366251; batch adversarial loss: 0.506669\n",
      "epoch 108; iter: 0; batch classifier loss: 0.361611; batch adversarial loss: 0.497488\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368066; batch adversarial loss: 0.554241\n",
      "epoch 110; iter: 0; batch classifier loss: 0.430858; batch adversarial loss: 0.536133\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393522; batch adversarial loss: 0.598299\n",
      "epoch 112; iter: 0; batch classifier loss: 0.331383; batch adversarial loss: 0.503223\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417092; batch adversarial loss: 0.402881\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412029; batch adversarial loss: 0.487509\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366369; batch adversarial loss: 0.555303\n",
      "epoch 116; iter: 0; batch classifier loss: 0.468160; batch adversarial loss: 0.594211\n",
      "epoch 117; iter: 0; batch classifier loss: 0.440961; batch adversarial loss: 0.571350\n",
      "epoch 118; iter: 0; batch classifier loss: 0.445796; batch adversarial loss: 0.582320\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423561; batch adversarial loss: 0.623350\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341824; batch adversarial loss: 0.506498\n",
      "epoch 121; iter: 0; batch classifier loss: 0.477913; batch adversarial loss: 0.610229\n",
      "epoch 122; iter: 0; batch classifier loss: 0.318110; batch adversarial loss: 0.448846\n",
      "epoch 123; iter: 0; batch classifier loss: 0.402445; batch adversarial loss: 0.517595\n",
      "epoch 124; iter: 0; batch classifier loss: 0.333349; batch adversarial loss: 0.582504\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361540; batch adversarial loss: 0.544630\n",
      "epoch 126; iter: 0; batch classifier loss: 0.341966; batch adversarial loss: 0.543451\n",
      "epoch 127; iter: 0; batch classifier loss: 0.386284; batch adversarial loss: 0.573934\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402820; batch adversarial loss: 0.595226\n",
      "epoch 129; iter: 0; batch classifier loss: 0.484560; batch adversarial loss: 0.488498\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405597; batch adversarial loss: 0.623152\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405805; batch adversarial loss: 0.592690\n",
      "epoch 132; iter: 0; batch classifier loss: 0.343176; batch adversarial loss: 0.526361\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383533; batch adversarial loss: 0.587640\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383250; batch adversarial loss: 0.542694\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370387; batch adversarial loss: 0.508297\n",
      "epoch 136; iter: 0; batch classifier loss: 0.250981; batch adversarial loss: 0.624280\n",
      "epoch 137; iter: 0; batch classifier loss: 0.445703; batch adversarial loss: 0.528620\n",
      "epoch 138; iter: 0; batch classifier loss: 0.447319; batch adversarial loss: 0.506129\n",
      "epoch 139; iter: 0; batch classifier loss: 0.420707; batch adversarial loss: 0.544919\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377438; batch adversarial loss: 0.532374\n",
      "epoch 141; iter: 0; batch classifier loss: 0.347265; batch adversarial loss: 0.573065\n",
      "epoch 142; iter: 0; batch classifier loss: 0.419942; batch adversarial loss: 0.514507\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406834; batch adversarial loss: 0.516012\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340409; batch adversarial loss: 0.496257\n",
      "epoch 145; iter: 0; batch classifier loss: 0.413197; batch adversarial loss: 0.534483\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383829; batch adversarial loss: 0.571823\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393575; batch adversarial loss: 0.498507\n",
      "epoch 148; iter: 0; batch classifier loss: 0.322127; batch adversarial loss: 0.581939\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418576; batch adversarial loss: 0.564241\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367629; batch adversarial loss: 0.524354\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341169; batch adversarial loss: 0.544463\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351554; batch adversarial loss: 0.525354\n",
      "epoch 153; iter: 0; batch classifier loss: 0.466947; batch adversarial loss: 0.622480\n",
      "epoch 154; iter: 0; batch classifier loss: 0.387273; batch adversarial loss: 0.565123\n",
      "epoch 155; iter: 0; batch classifier loss: 0.478928; batch adversarial loss: 0.496428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.362121; batch adversarial loss: 0.535206\n",
      "epoch 157; iter: 0; batch classifier loss: 0.484884; batch adversarial loss: 0.592222\n",
      "epoch 158; iter: 0; batch classifier loss: 0.487349; batch adversarial loss: 0.524055\n",
      "epoch 159; iter: 0; batch classifier loss: 0.436786; batch adversarial loss: 0.567685\n",
      "epoch 160; iter: 0; batch classifier loss: 0.490880; batch adversarial loss: 0.543052\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383264; batch adversarial loss: 0.525117\n",
      "epoch 162; iter: 0; batch classifier loss: 0.362076; batch adversarial loss: 0.514963\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386883; batch adversarial loss: 0.487103\n",
      "epoch 164; iter: 0; batch classifier loss: 0.349672; batch adversarial loss: 0.544515\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361347; batch adversarial loss: 0.517184\n",
      "epoch 166; iter: 0; batch classifier loss: 0.484163; batch adversarial loss: 0.582729\n",
      "epoch 167; iter: 0; batch classifier loss: 0.414289; batch adversarial loss: 0.517408\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392540; batch adversarial loss: 0.518989\n",
      "epoch 169; iter: 0; batch classifier loss: 0.419440; batch adversarial loss: 0.496225\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353420; batch adversarial loss: 0.582326\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366657; batch adversarial loss: 0.516740\n",
      "epoch 172; iter: 0; batch classifier loss: 0.416067; batch adversarial loss: 0.514921\n",
      "epoch 173; iter: 0; batch classifier loss: 0.406010; batch adversarial loss: 0.565592\n",
      "epoch 174; iter: 0; batch classifier loss: 0.389213; batch adversarial loss: 0.508384\n",
      "epoch 175; iter: 0; batch classifier loss: 0.429370; batch adversarial loss: 0.546273\n",
      "epoch 176; iter: 0; batch classifier loss: 0.414509; batch adversarial loss: 0.571261\n",
      "epoch 177; iter: 0; batch classifier loss: 0.429780; batch adversarial loss: 0.448856\n",
      "epoch 178; iter: 0; batch classifier loss: 0.425602; batch adversarial loss: 0.525213\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355657; batch adversarial loss: 0.603148\n",
      "epoch 180; iter: 0; batch classifier loss: 0.393057; batch adversarial loss: 0.506307\n",
      "epoch 181; iter: 0; batch classifier loss: 0.437217; batch adversarial loss: 0.505734\n",
      "epoch 182; iter: 0; batch classifier loss: 0.388464; batch adversarial loss: 0.506917\n",
      "epoch 183; iter: 0; batch classifier loss: 0.361978; batch adversarial loss: 0.496320\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360904; batch adversarial loss: 0.382257\n",
      "epoch 185; iter: 0; batch classifier loss: 0.359111; batch adversarial loss: 0.647652\n",
      "epoch 186; iter: 0; batch classifier loss: 0.420125; batch adversarial loss: 0.527150\n",
      "epoch 187; iter: 0; batch classifier loss: 0.404231; batch adversarial loss: 0.534453\n",
      "epoch 188; iter: 0; batch classifier loss: 0.410538; batch adversarial loss: 0.553020\n",
      "epoch 189; iter: 0; batch classifier loss: 0.390304; batch adversarial loss: 0.621328\n",
      "epoch 190; iter: 0; batch classifier loss: 0.404388; batch adversarial loss: 0.554333\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360303; batch adversarial loss: 0.526128\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298724; batch adversarial loss: 0.506402\n",
      "epoch 193; iter: 0; batch classifier loss: 0.382177; batch adversarial loss: 0.622751\n",
      "epoch 194; iter: 0; batch classifier loss: 0.408750; batch adversarial loss: 0.516567\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336672; batch adversarial loss: 0.547995\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383781; batch adversarial loss: 0.524891\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396240; batch adversarial loss: 0.478082\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368992; batch adversarial loss: 0.543324\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386111; batch adversarial loss: 0.534613\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691775; batch adversarial loss: 0.614617\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594876; batch adversarial loss: 0.648733\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594449; batch adversarial loss: 0.693380\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629978; batch adversarial loss: 0.653189\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517156; batch adversarial loss: 0.654416\n",
      "epoch 5; iter: 0; batch classifier loss: 0.604046; batch adversarial loss: 0.620665\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589325; batch adversarial loss: 0.622296\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518783; batch adversarial loss: 0.630202\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560527; batch adversarial loss: 0.581108\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546758; batch adversarial loss: 0.606849\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550373; batch adversarial loss: 0.572595\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531652; batch adversarial loss: 0.595387\n",
      "epoch 12; iter: 0; batch classifier loss: 0.580363; batch adversarial loss: 0.573273\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497361; batch adversarial loss: 0.544700\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500071; batch adversarial loss: 0.559016\n",
      "epoch 15; iter: 0; batch classifier loss: 0.594350; batch adversarial loss: 0.575611\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476990; batch adversarial loss: 0.539059\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519569; batch adversarial loss: 0.529414\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519666; batch adversarial loss: 0.568977\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436245; batch adversarial loss: 0.525805\n",
      "epoch 20; iter: 0; batch classifier loss: 0.445468; batch adversarial loss: 0.571945\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508141; batch adversarial loss: 0.587999\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452337; batch adversarial loss: 0.522923\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499397; batch adversarial loss: 0.625820\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477147; batch adversarial loss: 0.579650\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449245; batch adversarial loss: 0.612786\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536227; batch adversarial loss: 0.588652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511857; batch adversarial loss: 0.553224\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478046; batch adversarial loss: 0.521905\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471698; batch adversarial loss: 0.535869\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482522; batch adversarial loss: 0.552475\n",
      "epoch 31; iter: 0; batch classifier loss: 0.503080; batch adversarial loss: 0.639950\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445782; batch adversarial loss: 0.561095\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498632; batch adversarial loss: 0.545597\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496820; batch adversarial loss: 0.491664\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521848; batch adversarial loss: 0.552540\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494179; batch adversarial loss: 0.537939\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406979; batch adversarial loss: 0.534900\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465395; batch adversarial loss: 0.544050\n",
      "epoch 39; iter: 0; batch classifier loss: 0.360417; batch adversarial loss: 0.508528\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449575; batch adversarial loss: 0.526660\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438848; batch adversarial loss: 0.535684\n",
      "epoch 42; iter: 0; batch classifier loss: 0.542017; batch adversarial loss: 0.571679\n",
      "epoch 43; iter: 0; batch classifier loss: 0.501119; batch adversarial loss: 0.562460\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470646; batch adversarial loss: 0.633696\n",
      "epoch 45; iter: 0; batch classifier loss: 0.339890; batch adversarial loss: 0.526656\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392468; batch adversarial loss: 0.517855\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463542; batch adversarial loss: 0.644425\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434582; batch adversarial loss: 0.580688\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383726; batch adversarial loss: 0.562231\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424980; batch adversarial loss: 0.473160\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434382; batch adversarial loss: 0.553501\n",
      "epoch 52; iter: 0; batch classifier loss: 0.378852; batch adversarial loss: 0.553641\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396652; batch adversarial loss: 0.562585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.428699; batch adversarial loss: 0.617198\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420723; batch adversarial loss: 0.553414\n",
      "epoch 56; iter: 0; batch classifier loss: 0.380653; batch adversarial loss: 0.489937\n",
      "epoch 57; iter: 0; batch classifier loss: 0.430421; batch adversarial loss: 0.562422\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391482; batch adversarial loss: 0.562453\n",
      "epoch 59; iter: 0; batch classifier loss: 0.502996; batch adversarial loss: 0.571641\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407220; batch adversarial loss: 0.580967\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429071; batch adversarial loss: 0.634909\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395223; batch adversarial loss: 0.580614\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391513; batch adversarial loss: 0.535099\n",
      "epoch 64; iter: 0; batch classifier loss: 0.391887; batch adversarial loss: 0.562491\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406435; batch adversarial loss: 0.553510\n",
      "epoch 66; iter: 0; batch classifier loss: 0.375012; batch adversarial loss: 0.526198\n",
      "epoch 67; iter: 0; batch classifier loss: 0.499549; batch adversarial loss: 0.535560\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428842; batch adversarial loss: 0.562290\n",
      "epoch 69; iter: 0; batch classifier loss: 0.445849; batch adversarial loss: 0.488943\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411640; batch adversarial loss: 0.543049\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384230; batch adversarial loss: 0.525643\n",
      "epoch 72; iter: 0; batch classifier loss: 0.338633; batch adversarial loss: 0.480613\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396049; batch adversarial loss: 0.600362\n",
      "epoch 74; iter: 0; batch classifier loss: 0.485109; batch adversarial loss: 0.572638\n",
      "epoch 75; iter: 0; batch classifier loss: 0.439369; batch adversarial loss: 0.653169\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373359; batch adversarial loss: 0.562138\n",
      "epoch 77; iter: 0; batch classifier loss: 0.318262; batch adversarial loss: 0.553207\n",
      "epoch 78; iter: 0; batch classifier loss: 0.487686; batch adversarial loss: 0.545385\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409310; batch adversarial loss: 0.608408\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423148; batch adversarial loss: 0.508631\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419016; batch adversarial loss: 0.464028\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400851; batch adversarial loss: 0.562780\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370402; batch adversarial loss: 0.536371\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381260; batch adversarial loss: 0.490626\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425215; batch adversarial loss: 0.590392\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424527; batch adversarial loss: 0.544342\n",
      "epoch 87; iter: 0; batch classifier loss: 0.343670; batch adversarial loss: 0.589802\n",
      "epoch 88; iter: 0; batch classifier loss: 0.437614; batch adversarial loss: 0.571933\n",
      "epoch 89; iter: 0; batch classifier loss: 0.451758; batch adversarial loss: 0.481751\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432042; batch adversarial loss: 0.580129\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421451; batch adversarial loss: 0.579982\n",
      "epoch 92; iter: 0; batch classifier loss: 0.481051; batch adversarial loss: 0.553192\n",
      "epoch 93; iter: 0; batch classifier loss: 0.292475; batch adversarial loss: 0.535711\n",
      "epoch 94; iter: 0; batch classifier loss: 0.322343; batch adversarial loss: 0.481397\n",
      "epoch 95; iter: 0; batch classifier loss: 0.367395; batch adversarial loss: 0.526447\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394438; batch adversarial loss: 0.481592\n",
      "epoch 97; iter: 0; batch classifier loss: 0.479391; batch adversarial loss: 0.590419\n",
      "epoch 98; iter: 0; batch classifier loss: 0.328106; batch adversarial loss: 0.517708\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419112; batch adversarial loss: 0.562382\n",
      "epoch 100; iter: 0; batch classifier loss: 0.463586; batch adversarial loss: 0.571654\n",
      "epoch 101; iter: 0; batch classifier loss: 0.427129; batch adversarial loss: 0.608356\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330283; batch adversarial loss: 0.581060\n",
      "epoch 103; iter: 0; batch classifier loss: 0.422664; batch adversarial loss: 0.535634\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402204; batch adversarial loss: 0.581037\n",
      "epoch 105; iter: 0; batch classifier loss: 0.335783; batch adversarial loss: 0.571529\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402172; batch adversarial loss: 0.499160\n",
      "epoch 107; iter: 0; batch classifier loss: 0.422712; batch adversarial loss: 0.571617\n",
      "epoch 108; iter: 0; batch classifier loss: 0.416195; batch adversarial loss: 0.508372\n",
      "epoch 109; iter: 0; batch classifier loss: 0.366397; batch adversarial loss: 0.626043\n",
      "epoch 110; iter: 0; batch classifier loss: 0.418353; batch adversarial loss: 0.607015\n",
      "epoch 111; iter: 0; batch classifier loss: 0.306748; batch adversarial loss: 0.580699\n",
      "epoch 112; iter: 0; batch classifier loss: 0.395622; batch adversarial loss: 0.507730\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419572; batch adversarial loss: 0.554167\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397147; batch adversarial loss: 0.600019\n",
      "epoch 115; iter: 0; batch classifier loss: 0.463729; batch adversarial loss: 0.490138\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358613; batch adversarial loss: 0.516972\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365549; batch adversarial loss: 0.544311\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376983; batch adversarial loss: 0.571471\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423731; batch adversarial loss: 0.498820\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408652; batch adversarial loss: 0.480586\n",
      "epoch 121; iter: 0; batch classifier loss: 0.337243; batch adversarial loss: 0.562331\n",
      "epoch 122; iter: 0; batch classifier loss: 0.458941; batch adversarial loss: 0.635048\n",
      "epoch 123; iter: 0; batch classifier loss: 0.433711; batch adversarial loss: 0.607638\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373318; batch adversarial loss: 0.581367\n",
      "epoch 125; iter: 0; batch classifier loss: 0.457494; batch adversarial loss: 0.507716\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374205; batch adversarial loss: 0.544480\n",
      "epoch 127; iter: 0; batch classifier loss: 0.327991; batch adversarial loss: 0.517579\n",
      "epoch 128; iter: 0; batch classifier loss: 0.314828; batch adversarial loss: 0.545328\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388309; batch adversarial loss: 0.589974\n",
      "epoch 130; iter: 0; batch classifier loss: 0.316548; batch adversarial loss: 0.516917\n",
      "epoch 131; iter: 0; batch classifier loss: 0.254938; batch adversarial loss: 0.517780\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342960; batch adversarial loss: 0.472038\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394381; batch adversarial loss: 0.480771\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381095; batch adversarial loss: 0.536438\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385058; batch adversarial loss: 0.562836\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343604; batch adversarial loss: 0.498135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.439216; batch adversarial loss: 0.508652\n",
      "epoch 138; iter: 0; batch classifier loss: 0.343158; batch adversarial loss: 0.562413\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376652; batch adversarial loss: 0.454571\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377211; batch adversarial loss: 0.526646\n",
      "epoch 141; iter: 0; batch classifier loss: 0.382780; batch adversarial loss: 0.553084\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338717; batch adversarial loss: 0.590255\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391989; batch adversarial loss: 0.544594\n",
      "epoch 144; iter: 0; batch classifier loss: 0.286716; batch adversarial loss: 0.607825\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359210; batch adversarial loss: 0.607943\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327064; batch adversarial loss: 0.580289\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329945; batch adversarial loss: 0.544334\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335671; batch adversarial loss: 0.554294\n",
      "epoch 149; iter: 0; batch classifier loss: 0.294569; batch adversarial loss: 0.500426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150; iter: 0; batch classifier loss: 0.371627; batch adversarial loss: 0.571749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.401448; batch adversarial loss: 0.517302\n",
      "epoch 152; iter: 0; batch classifier loss: 0.373472; batch adversarial loss: 0.562551\n",
      "epoch 153; iter: 0; batch classifier loss: 0.474468; batch adversarial loss: 0.571862\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361249; batch adversarial loss: 0.581393\n",
      "epoch 155; iter: 0; batch classifier loss: 0.431399; batch adversarial loss: 0.579944\n",
      "epoch 156; iter: 0; batch classifier loss: 0.265282; batch adversarial loss: 0.508548\n",
      "epoch 157; iter: 0; batch classifier loss: 0.316726; batch adversarial loss: 0.563872\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375164; batch adversarial loss: 0.500011\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353902; batch adversarial loss: 0.553283\n",
      "epoch 160; iter: 0; batch classifier loss: 0.354147; batch adversarial loss: 0.589403\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325499; batch adversarial loss: 0.517275\n",
      "epoch 162; iter: 0; batch classifier loss: 0.310275; batch adversarial loss: 0.553070\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369923; batch adversarial loss: 0.498788\n",
      "epoch 164; iter: 0; batch classifier loss: 0.370317; batch adversarial loss: 0.580723\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371131; batch adversarial loss: 0.525689\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347618; batch adversarial loss: 0.498557\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345352; batch adversarial loss: 0.517612\n",
      "epoch 168; iter: 0; batch classifier loss: 0.300191; batch adversarial loss: 0.472096\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337218; batch adversarial loss: 0.571708\n",
      "epoch 170; iter: 0; batch classifier loss: 0.411555; batch adversarial loss: 0.526432\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401958; batch adversarial loss: 0.599195\n",
      "epoch 172; iter: 0; batch classifier loss: 0.431251; batch adversarial loss: 0.535628\n",
      "epoch 173; iter: 0; batch classifier loss: 0.508159; batch adversarial loss: 0.488849\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378870; batch adversarial loss: 0.490917\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364368; batch adversarial loss: 0.543447\n",
      "epoch 176; iter: 0; batch classifier loss: 0.385634; batch adversarial loss: 0.563621\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314491; batch adversarial loss: 0.562470\n",
      "epoch 178; iter: 0; batch classifier loss: 0.304229; batch adversarial loss: 0.554246\n",
      "epoch 179; iter: 0; batch classifier loss: 0.290914; batch adversarial loss: 0.517176\n",
      "epoch 180; iter: 0; batch classifier loss: 0.395537; batch adversarial loss: 0.626820\n",
      "epoch 181; iter: 0; batch classifier loss: 0.286375; batch adversarial loss: 0.580733\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404307; batch adversarial loss: 0.552555\n",
      "epoch 183; iter: 0; batch classifier loss: 0.340245; batch adversarial loss: 0.552687\n",
      "epoch 184; iter: 0; batch classifier loss: 0.415021; batch adversarial loss: 0.572271\n",
      "epoch 185; iter: 0; batch classifier loss: 0.411305; batch adversarial loss: 0.617150\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356132; batch adversarial loss: 0.516773\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395848; batch adversarial loss: 0.490437\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362895; batch adversarial loss: 0.526412\n",
      "epoch 189; iter: 0; batch classifier loss: 0.463549; batch adversarial loss: 0.653252\n",
      "epoch 190; iter: 0; batch classifier loss: 0.396430; batch adversarial loss: 0.562611\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363629; batch adversarial loss: 0.525427\n",
      "epoch 192; iter: 0; batch classifier loss: 0.388344; batch adversarial loss: 0.499099\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329077; batch adversarial loss: 0.480769\n",
      "epoch 194; iter: 0; batch classifier loss: 0.328349; batch adversarial loss: 0.589281\n",
      "epoch 195; iter: 0; batch classifier loss: 0.331604; batch adversarial loss: 0.553164\n",
      "epoch 196; iter: 0; batch classifier loss: 0.410014; batch adversarial loss: 0.544384\n",
      "epoch 197; iter: 0; batch classifier loss: 0.395712; batch adversarial loss: 0.480740\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328778; batch adversarial loss: 0.652995\n",
      "epoch 199; iter: 0; batch classifier loss: 0.368751; batch adversarial loss: 0.608338\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709818; batch adversarial loss: 0.732650\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573305; batch adversarial loss: 0.692572\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582382; batch adversarial loss: 0.681292\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605091; batch adversarial loss: 0.644927\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586287; batch adversarial loss: 0.642843\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580521; batch adversarial loss: 0.596697\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579388; batch adversarial loss: 0.599186\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578945; batch adversarial loss: 0.577881\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534973; batch adversarial loss: 0.612498\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534604; batch adversarial loss: 0.586425\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520470; batch adversarial loss: 0.581737\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533665; batch adversarial loss: 0.579071\n",
      "epoch 12; iter: 0; batch classifier loss: 0.574583; batch adversarial loss: 0.589550\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510805; batch adversarial loss: 0.558413\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474622; batch adversarial loss: 0.551900\n",
      "epoch 15; iter: 0; batch classifier loss: 0.433668; batch adversarial loss: 0.521215\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478780; batch adversarial loss: 0.578653\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494982; batch adversarial loss: 0.549696\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536604; batch adversarial loss: 0.634939\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515109; batch adversarial loss: 0.545837\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496201; batch adversarial loss: 0.563062\n",
      "epoch 21; iter: 0; batch classifier loss: 0.558678; batch adversarial loss: 0.546279\n",
      "epoch 22; iter: 0; batch classifier loss: 0.523841; batch adversarial loss: 0.542623\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483540; batch adversarial loss: 0.540020\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481683; batch adversarial loss: 0.617045\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526095; batch adversarial loss: 0.512387\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451720; batch adversarial loss: 0.556401\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507863; batch adversarial loss: 0.484619\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435610; batch adversarial loss: 0.482126\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450270; batch adversarial loss: 0.562967\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475701; batch adversarial loss: 0.555327\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474706; batch adversarial loss: 0.470342\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477522; batch adversarial loss: 0.519817\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438267; batch adversarial loss: 0.492301\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476388; batch adversarial loss: 0.551934\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471432; batch adversarial loss: 0.440259\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452772; batch adversarial loss: 0.508094\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477396; batch adversarial loss: 0.482551\n",
      "epoch 38; iter: 0; batch classifier loss: 0.401739; batch adversarial loss: 0.553533\n",
      "epoch 39; iter: 0; batch classifier loss: 0.377700; batch adversarial loss: 0.472864\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423260; batch adversarial loss: 0.534767\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418480; batch adversarial loss: 0.536301\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457952; batch adversarial loss: 0.608763\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477693; batch adversarial loss: 0.527109\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434138; batch adversarial loss: 0.462878\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457483; batch adversarial loss: 0.599519\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398333; batch adversarial loss: 0.472887\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399219; batch adversarial loss: 0.552100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.502613; batch adversarial loss: 0.660999\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424941; batch adversarial loss: 0.526569\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400828; batch adversarial loss: 0.536094\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398119; batch adversarial loss: 0.481629\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456738; batch adversarial loss: 0.598001\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449913; batch adversarial loss: 0.535695\n",
      "epoch 54; iter: 0; batch classifier loss: 0.377454; batch adversarial loss: 0.535716\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441978; batch adversarial loss: 0.609414\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416131; batch adversarial loss: 0.572443\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437426; batch adversarial loss: 0.517346\n",
      "epoch 58; iter: 0; batch classifier loss: 0.385814; batch adversarial loss: 0.543312\n",
      "epoch 59; iter: 0; batch classifier loss: 0.448787; batch adversarial loss: 0.544655\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411071; batch adversarial loss: 0.599637\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383440; batch adversarial loss: 0.497538\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416330; batch adversarial loss: 0.489871\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463968; batch adversarial loss: 0.516598\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362958; batch adversarial loss: 0.553475\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451019; batch adversarial loss: 0.534986\n",
      "epoch 66; iter: 0; batch classifier loss: 0.424363; batch adversarial loss: 0.506950\n",
      "epoch 67; iter: 0; batch classifier loss: 0.461761; batch adversarial loss: 0.553339\n",
      "epoch 68; iter: 0; batch classifier loss: 0.353155; batch adversarial loss: 0.534175\n",
      "epoch 69; iter: 0; batch classifier loss: 0.434901; batch adversarial loss: 0.490080\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368588; batch adversarial loss: 0.544553\n",
      "epoch 71; iter: 0; batch classifier loss: 0.415737; batch adversarial loss: 0.489801\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434091; batch adversarial loss: 0.590700\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383579; batch adversarial loss: 0.535920\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417242; batch adversarial loss: 0.489760\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386865; batch adversarial loss: 0.516748\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440202; batch adversarial loss: 0.563639\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392076; batch adversarial loss: 0.572133\n",
      "epoch 78; iter: 0; batch classifier loss: 0.315699; batch adversarial loss: 0.572687\n",
      "epoch 79; iter: 0; batch classifier loss: 0.458912; batch adversarial loss: 0.498362\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414569; batch adversarial loss: 0.507688\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374151; batch adversarial loss: 0.489299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406359; batch adversarial loss: 0.553636\n",
      "epoch 83; iter: 0; batch classifier loss: 0.297777; batch adversarial loss: 0.516518\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416020; batch adversarial loss: 0.553588\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344806; batch adversarial loss: 0.488749\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360495; batch adversarial loss: 0.553714\n",
      "epoch 87; iter: 0; batch classifier loss: 0.311271; batch adversarial loss: 0.470369\n",
      "epoch 88; iter: 0; batch classifier loss: 0.434097; batch adversarial loss: 0.525703\n",
      "epoch 89; iter: 0; batch classifier loss: 0.454178; batch adversarial loss: 0.470895\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401054; batch adversarial loss: 0.572199\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413689; batch adversarial loss: 0.544638\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393159; batch adversarial loss: 0.581429\n",
      "epoch 93; iter: 0; batch classifier loss: 0.370292; batch adversarial loss: 0.507414\n",
      "epoch 94; iter: 0; batch classifier loss: 0.341701; batch adversarial loss: 0.553917\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419462; batch adversarial loss: 0.544480\n",
      "epoch 96; iter: 0; batch classifier loss: 0.320002; batch adversarial loss: 0.562767\n",
      "epoch 97; iter: 0; batch classifier loss: 0.347477; batch adversarial loss: 0.516975\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400677; batch adversarial loss: 0.462172\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386513; batch adversarial loss: 0.553719\n",
      "epoch 100; iter: 0; batch classifier loss: 0.430449; batch adversarial loss: 0.553980\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400539; batch adversarial loss: 0.544533\n",
      "epoch 102; iter: 0; batch classifier loss: 0.427314; batch adversarial loss: 0.562889\n",
      "epoch 103; iter: 0; batch classifier loss: 0.472596; batch adversarial loss: 0.544616\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402572; batch adversarial loss: 0.443768\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396540; batch adversarial loss: 0.553682\n",
      "epoch 106; iter: 0; batch classifier loss: 0.442389; batch adversarial loss: 0.526033\n",
      "epoch 107; iter: 0; batch classifier loss: 0.333706; batch adversarial loss: 0.553233\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366791; batch adversarial loss: 0.579968\n",
      "epoch 109; iter: 0; batch classifier loss: 0.441209; batch adversarial loss: 0.544791\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405468; batch adversarial loss: 0.498293\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362226; batch adversarial loss: 0.551468\n",
      "epoch 112; iter: 0; batch classifier loss: 0.354330; batch adversarial loss: 0.587873\n",
      "epoch 113; iter: 0; batch classifier loss: 0.334784; batch adversarial loss: 0.537375\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367856; batch adversarial loss: 0.498049\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379379; batch adversarial loss: 0.544288\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389576; batch adversarial loss: 0.591252\n",
      "epoch 117; iter: 0; batch classifier loss: 0.300569; batch adversarial loss: 0.462555\n",
      "epoch 118; iter: 0; batch classifier loss: 0.305016; batch adversarial loss: 0.600709\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353034; batch adversarial loss: 0.526130\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343821; batch adversarial loss: 0.582146\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385003; batch adversarial loss: 0.506564\n",
      "epoch 122; iter: 0; batch classifier loss: 0.370021; batch adversarial loss: 0.516774\n",
      "epoch 123; iter: 0; batch classifier loss: 0.506885; batch adversarial loss: 0.620093\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334178; batch adversarial loss: 0.525909\n",
      "epoch 125; iter: 0; batch classifier loss: 0.406143; batch adversarial loss: 0.562452\n",
      "epoch 126; iter: 0; batch classifier loss: 0.346284; batch adversarial loss: 0.536344\n",
      "epoch 127; iter: 0; batch classifier loss: 0.322938; batch adversarial loss: 0.554379\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404153; batch adversarial loss: 0.488635\n",
      "epoch 129; iter: 0; batch classifier loss: 0.384962; batch adversarial loss: 0.508519\n",
      "epoch 130; iter: 0; batch classifier loss: 0.344152; batch adversarial loss: 0.572230\n",
      "epoch 131; iter: 0; batch classifier loss: 0.354561; batch adversarial loss: 0.553999\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380051; batch adversarial loss: 0.562848\n",
      "epoch 133; iter: 0; batch classifier loss: 0.320733; batch adversarial loss: 0.525934\n",
      "epoch 134; iter: 0; batch classifier loss: 0.413873; batch adversarial loss: 0.572125\n",
      "epoch 135; iter: 0; batch classifier loss: 0.423051; batch adversarial loss: 0.562937\n",
      "epoch 136; iter: 0; batch classifier loss: 0.319846; batch adversarial loss: 0.443597\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344464; batch adversarial loss: 0.599715\n",
      "epoch 138; iter: 0; batch classifier loss: 0.408506; batch adversarial loss: 0.636688\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347360; batch adversarial loss: 0.572146\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342745; batch adversarial loss: 0.581638\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377265; batch adversarial loss: 0.489312\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346826; batch adversarial loss: 0.544558\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363773; batch adversarial loss: 0.562551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.402151; batch adversarial loss: 0.552904\n",
      "epoch 145; iter: 0; batch classifier loss: 0.436082; batch adversarial loss: 0.572263\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411824; batch adversarial loss: 0.607530\n",
      "epoch 147; iter: 0; batch classifier loss: 0.443167; batch adversarial loss: 0.525851\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360362; batch adversarial loss: 0.580567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.406397; batch adversarial loss: 0.544428\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400463; batch adversarial loss: 0.535531\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382156; batch adversarial loss: 0.563170\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357565; batch adversarial loss: 0.507368\n",
      "epoch 153; iter: 0; batch classifier loss: 0.404418; batch adversarial loss: 0.572243\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343650; batch adversarial loss: 0.451711\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323613; batch adversarial loss: 0.536486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371819; batch adversarial loss: 0.563041\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370956; batch adversarial loss: 0.534574\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382063; batch adversarial loss: 0.526608\n",
      "epoch 159; iter: 0; batch classifier loss: 0.434132; batch adversarial loss: 0.508325\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375512; batch adversarial loss: 0.472205\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343275; batch adversarial loss: 0.535674\n",
      "epoch 162; iter: 0; batch classifier loss: 0.332162; batch adversarial loss: 0.544662\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359481; batch adversarial loss: 0.498119\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336199; batch adversarial loss: 0.489047\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374807; batch adversarial loss: 0.553753\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360250; batch adversarial loss: 0.535126\n",
      "epoch 167; iter: 0; batch classifier loss: 0.424327; batch adversarial loss: 0.544133\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331576; batch adversarial loss: 0.535152\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351835; batch adversarial loss: 0.590610\n",
      "epoch 170; iter: 0; batch classifier loss: 0.470753; batch adversarial loss: 0.562666\n",
      "epoch 171; iter: 0; batch classifier loss: 0.352833; batch adversarial loss: 0.472011\n",
      "epoch 172; iter: 0; batch classifier loss: 0.312460; batch adversarial loss: 0.526417\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410239; batch adversarial loss: 0.608953\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392172; batch adversarial loss: 0.535228\n",
      "epoch 175; iter: 0; batch classifier loss: 0.324057; batch adversarial loss: 0.571709\n",
      "epoch 176; iter: 0; batch classifier loss: 0.430529; batch adversarial loss: 0.535394\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374113; batch adversarial loss: 0.571895\n",
      "epoch 178; iter: 0; batch classifier loss: 0.265648; batch adversarial loss: 0.562789\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372923; batch adversarial loss: 0.535413\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322213; batch adversarial loss: 0.608421\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358631; batch adversarial loss: 0.600046\n",
      "epoch 182; iter: 0; batch classifier loss: 0.325568; batch adversarial loss: 0.499411\n",
      "epoch 183; iter: 0; batch classifier loss: 0.438713; batch adversarial loss: 0.489851\n",
      "epoch 184; iter: 0; batch classifier loss: 0.239533; batch adversarial loss: 0.462241\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348553; batch adversarial loss: 0.605284\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365113; batch adversarial loss: 0.607666\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373220; batch adversarial loss: 0.479978\n",
      "epoch 188; iter: 0; batch classifier loss: 0.446479; batch adversarial loss: 0.479117\n",
      "epoch 189; iter: 0; batch classifier loss: 0.373562; batch adversarial loss: 0.537079\n",
      "epoch 190; iter: 0; batch classifier loss: 0.310394; batch adversarial loss: 0.506973\n",
      "epoch 191; iter: 0; batch classifier loss: 0.453841; batch adversarial loss: 0.525800\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342947; batch adversarial loss: 0.451897\n",
      "epoch 193; iter: 0; batch classifier loss: 0.416844; batch adversarial loss: 0.600369\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395453; batch adversarial loss: 0.525896\n",
      "epoch 195; iter: 0; batch classifier loss: 0.329725; batch adversarial loss: 0.479587\n",
      "epoch 196; iter: 0; batch classifier loss: 0.416440; batch adversarial loss: 0.553973\n",
      "epoch 197; iter: 0; batch classifier loss: 0.272974; batch adversarial loss: 0.636843\n",
      "epoch 198; iter: 0; batch classifier loss: 0.351345; batch adversarial loss: 0.571792\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330939; batch adversarial loss: 0.544518\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693962; batch adversarial loss: 0.680365\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581104; batch adversarial loss: 0.682005\n",
      "epoch 2; iter: 0; batch classifier loss: 0.666791; batch adversarial loss: 0.619025\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550962; batch adversarial loss: 0.637114\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600576; batch adversarial loss: 0.627441\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556831; batch adversarial loss: 0.629127\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539784; batch adversarial loss: 0.613280\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561623; batch adversarial loss: 0.562691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559884; batch adversarial loss: 0.586840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486227; batch adversarial loss: 0.533613\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512163; batch adversarial loss: 0.600147\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516369; batch adversarial loss: 0.593011\n",
      "epoch 12; iter: 0; batch classifier loss: 0.483829; batch adversarial loss: 0.626383\n",
      "epoch 13; iter: 0; batch classifier loss: 0.461377; batch adversarial loss: 0.590772\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522012; batch adversarial loss: 0.623411\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473142; batch adversarial loss: 0.554429\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488981; batch adversarial loss: 0.560811\n",
      "epoch 17; iter: 0; batch classifier loss: 0.493011; batch adversarial loss: 0.575764\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491957; batch adversarial loss: 0.594633\n",
      "epoch 19; iter: 0; batch classifier loss: 0.585067; batch adversarial loss: 0.613610\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530882; batch adversarial loss: 0.542376\n",
      "epoch 21; iter: 0; batch classifier loss: 0.604258; batch adversarial loss: 0.625712\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473578; batch adversarial loss: 0.574034\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515669; batch adversarial loss: 0.570877\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482387; batch adversarial loss: 0.634556\n",
      "epoch 25; iter: 0; batch classifier loss: 0.435094; batch adversarial loss: 0.451460\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453680; batch adversarial loss: 0.539183\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457433; batch adversarial loss: 0.591468\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421885; batch adversarial loss: 0.519773\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495471; batch adversarial loss: 0.536354\n",
      "epoch 30; iter: 0; batch classifier loss: 0.522953; batch adversarial loss: 0.574117\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457314; batch adversarial loss: 0.507178\n",
      "epoch 32; iter: 0; batch classifier loss: 0.572091; batch adversarial loss: 0.486091\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489904; batch adversarial loss: 0.597579\n",
      "epoch 34; iter: 0; batch classifier loss: 0.505280; batch adversarial loss: 0.532043\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453048; batch adversarial loss: 0.468274\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435027; batch adversarial loss: 0.473488\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438634; batch adversarial loss: 0.573869\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466714; batch adversarial loss: 0.474264\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458641; batch adversarial loss: 0.559131\n",
      "epoch 40; iter: 0; batch classifier loss: 0.494723; batch adversarial loss: 0.521225\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461519; batch adversarial loss: 0.584908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.425109; batch adversarial loss: 0.608491\n",
      "epoch 43; iter: 0; batch classifier loss: 0.505664; batch adversarial loss: 0.535251\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444688; batch adversarial loss: 0.541519\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444483; batch adversarial loss: 0.562441\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469751; batch adversarial loss: 0.543047\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487919; batch adversarial loss: 0.525373\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420371; batch adversarial loss: 0.553097\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456484; batch adversarial loss: 0.587279\n",
      "epoch 50; iter: 0; batch classifier loss: 0.427742; batch adversarial loss: 0.483950\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470737; batch adversarial loss: 0.582264\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413275; batch adversarial loss: 0.563011\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417689; batch adversarial loss: 0.550067\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423800; batch adversarial loss: 0.472138\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446701; batch adversarial loss: 0.546504\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423975; batch adversarial loss: 0.599811\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454757; batch adversarial loss: 0.544928\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419016; batch adversarial loss: 0.498220\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378937; batch adversarial loss: 0.509282\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412615; batch adversarial loss: 0.544348\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449069; batch adversarial loss: 0.579801\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379174; batch adversarial loss: 0.527467\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449365; batch adversarial loss: 0.514443\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395313; batch adversarial loss: 0.570823\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415537; batch adversarial loss: 0.528213\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420848; batch adversarial loss: 0.526764\n",
      "epoch 67; iter: 0; batch classifier loss: 0.337913; batch adversarial loss: 0.525901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410524; batch adversarial loss: 0.589807\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410753; batch adversarial loss: 0.498881\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422547; batch adversarial loss: 0.564332\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412447; batch adversarial loss: 0.591217\n",
      "epoch 72; iter: 0; batch classifier loss: 0.472447; batch adversarial loss: 0.655691\n",
      "epoch 73; iter: 0; batch classifier loss: 0.497184; batch adversarial loss: 0.571997\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444424; batch adversarial loss: 0.524633\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423766; batch adversarial loss: 0.537767\n",
      "epoch 76; iter: 0; batch classifier loss: 0.518871; batch adversarial loss: 0.578419\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400404; batch adversarial loss: 0.569678\n",
      "epoch 78; iter: 0; batch classifier loss: 0.429060; batch adversarial loss: 0.562249\n",
      "epoch 79; iter: 0; batch classifier loss: 0.316490; batch adversarial loss: 0.507918\n",
      "epoch 80; iter: 0; batch classifier loss: 0.475041; batch adversarial loss: 0.601643\n",
      "epoch 81; iter: 0; batch classifier loss: 0.437030; batch adversarial loss: 0.546076\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403428; batch adversarial loss: 0.490916\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407142; batch adversarial loss: 0.560396\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429935; batch adversarial loss: 0.600425\n",
      "epoch 85; iter: 0; batch classifier loss: 0.449217; batch adversarial loss: 0.489237\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384990; batch adversarial loss: 0.580629\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406976; batch adversarial loss: 0.532653\n",
      "epoch 88; iter: 0; batch classifier loss: 0.445475; batch adversarial loss: 0.553990\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367990; batch adversarial loss: 0.581264\n",
      "epoch 90; iter: 0; batch classifier loss: 0.451890; batch adversarial loss: 0.506884\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349779; batch adversarial loss: 0.510283\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421096; batch adversarial loss: 0.492467\n",
      "epoch 93; iter: 0; batch classifier loss: 0.396072; batch adversarial loss: 0.608841\n",
      "epoch 94; iter: 0; batch classifier loss: 0.503421; batch adversarial loss: 0.541241\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352403; batch adversarial loss: 0.496781\n",
      "epoch 96; iter: 0; batch classifier loss: 0.329796; batch adversarial loss: 0.545177\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411194; batch adversarial loss: 0.497338\n",
      "epoch 98; iter: 0; batch classifier loss: 0.352711; batch adversarial loss: 0.572356\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404979; batch adversarial loss: 0.599528\n",
      "epoch 100; iter: 0; batch classifier loss: 0.362858; batch adversarial loss: 0.537704\n",
      "epoch 101; iter: 0; batch classifier loss: 0.433746; batch adversarial loss: 0.569746\n",
      "epoch 102; iter: 0; batch classifier loss: 0.470343; batch adversarial loss: 0.526197\n",
      "epoch 103; iter: 0; batch classifier loss: 0.427265; batch adversarial loss: 0.480442\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422762; batch adversarial loss: 0.534330\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423082; batch adversarial loss: 0.499883\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408961; batch adversarial loss: 0.506795\n",
      "epoch 107; iter: 0; batch classifier loss: 0.519403; batch adversarial loss: 0.581214\n",
      "epoch 108; iter: 0; batch classifier loss: 0.342060; batch adversarial loss: 0.626218\n",
      "epoch 109; iter: 0; batch classifier loss: 0.426777; batch adversarial loss: 0.524267\n",
      "epoch 110; iter: 0; batch classifier loss: 0.409147; batch adversarial loss: 0.515873\n",
      "epoch 111; iter: 0; batch classifier loss: 0.452544; batch adversarial loss: 0.544449\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414864; batch adversarial loss: 0.590390\n",
      "epoch 113; iter: 0; batch classifier loss: 0.468741; batch adversarial loss: 0.508435\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363479; batch adversarial loss: 0.579193\n",
      "epoch 115; iter: 0; batch classifier loss: 0.434990; batch adversarial loss: 0.534936\n",
      "epoch 116; iter: 0; batch classifier loss: 0.441113; batch adversarial loss: 0.599175\n",
      "epoch 117; iter: 0; batch classifier loss: 0.446857; batch adversarial loss: 0.552585\n",
      "epoch 118; iter: 0; batch classifier loss: 0.466469; batch adversarial loss: 0.599202\n",
      "epoch 119; iter: 0; batch classifier loss: 0.467343; batch adversarial loss: 0.627588\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413323; batch adversarial loss: 0.528146\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371468; batch adversarial loss: 0.518218\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376841; batch adversarial loss: 0.588960\n",
      "epoch 123; iter: 0; batch classifier loss: 0.300589; batch adversarial loss: 0.573011\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399238; batch adversarial loss: 0.473823\n",
      "epoch 125; iter: 0; batch classifier loss: 0.358914; batch adversarial loss: 0.553727\n",
      "epoch 126; iter: 0; batch classifier loss: 0.355699; batch adversarial loss: 0.508787\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369755; batch adversarial loss: 0.552750\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410114; batch adversarial loss: 0.553082\n",
      "epoch 129; iter: 0; batch classifier loss: 0.283064; batch adversarial loss: 0.534461\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372355; batch adversarial loss: 0.490623\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321808; batch adversarial loss: 0.543753\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382195; batch adversarial loss: 0.619459\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387496; batch adversarial loss: 0.533909\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337586; batch adversarial loss: 0.454484\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314781; batch adversarial loss: 0.573096\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378702; batch adversarial loss: 0.607756\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372402; batch adversarial loss: 0.516167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.428871; batch adversarial loss: 0.544196\n",
      "epoch 139; iter: 0; batch classifier loss: 0.459380; batch adversarial loss: 0.588560\n",
      "epoch 140; iter: 0; batch classifier loss: 0.436788; batch adversarial loss: 0.498602\n",
      "epoch 141; iter: 0; batch classifier loss: 0.376474; batch adversarial loss: 0.507775\n",
      "epoch 142; iter: 0; batch classifier loss: 0.392378; batch adversarial loss: 0.655890\n",
      "epoch 143; iter: 0; batch classifier loss: 0.411591; batch adversarial loss: 0.507015\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388241; batch adversarial loss: 0.598204\n",
      "epoch 145; iter: 0; batch classifier loss: 0.457196; batch adversarial loss: 0.537103\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367974; batch adversarial loss: 0.526892\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336297; batch adversarial loss: 0.625117\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344605; batch adversarial loss: 0.679869\n",
      "epoch 149; iter: 0; batch classifier loss: 0.409743; batch adversarial loss: 0.500481\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371454; batch adversarial loss: 0.561451\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355026; batch adversarial loss: 0.507792\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363145; batch adversarial loss: 0.535186\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356786; batch adversarial loss: 0.564430\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321569; batch adversarial loss: 0.545099\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412672; batch adversarial loss: 0.626822\n",
      "epoch 156; iter: 0; batch classifier loss: 0.420203; batch adversarial loss: 0.519201\n",
      "epoch 157; iter: 0; batch classifier loss: 0.343692; batch adversarial loss: 0.617737\n",
      "epoch 158; iter: 0; batch classifier loss: 0.416057; batch adversarial loss: 0.645658\n",
      "epoch 159; iter: 0; batch classifier loss: 0.368698; batch adversarial loss: 0.590238\n",
      "epoch 160; iter: 0; batch classifier loss: 0.512270; batch adversarial loss: 0.615764\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374465; batch adversarial loss: 0.516370\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372745; batch adversarial loss: 0.626960\n",
      "epoch 163; iter: 0; batch classifier loss: 0.396693; batch adversarial loss: 0.582644\n",
      "epoch 164; iter: 0; batch classifier loss: 0.303344; batch adversarial loss: 0.526200\n",
      "epoch 165; iter: 0; batch classifier loss: 0.367625; batch adversarial loss: 0.564472\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382259; batch adversarial loss: 0.543601\n",
      "epoch 167; iter: 0; batch classifier loss: 0.451990; batch adversarial loss: 0.488727\n",
      "epoch 168; iter: 0; batch classifier loss: 0.469359; batch adversarial loss: 0.561471\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324121; batch adversarial loss: 0.497645\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378162; batch adversarial loss: 0.499486\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343169; batch adversarial loss: 0.536206\n",
      "epoch 172; iter: 0; batch classifier loss: 0.399087; batch adversarial loss: 0.563320\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340153; batch adversarial loss: 0.543119\n",
      "epoch 174; iter: 0; batch classifier loss: 0.278655; batch adversarial loss: 0.533784\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331195; batch adversarial loss: 0.500137\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358467; batch adversarial loss: 0.547795\n",
      "epoch 177; iter: 0; batch classifier loss: 0.454543; batch adversarial loss: 0.516546\n",
      "epoch 178; iter: 0; batch classifier loss: 0.396530; batch adversarial loss: 0.491258\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362314; batch adversarial loss: 0.524792\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328042; batch adversarial loss: 0.516574\n",
      "epoch 181; iter: 0; batch classifier loss: 0.393124; batch adversarial loss: 0.480367\n",
      "epoch 182; iter: 0; batch classifier loss: 0.438804; batch adversarial loss: 0.536569\n",
      "epoch 183; iter: 0; batch classifier loss: 0.392348; batch adversarial loss: 0.552771\n",
      "epoch 184; iter: 0; batch classifier loss: 0.430866; batch adversarial loss: 0.546507\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328452; batch adversarial loss: 0.506100\n",
      "epoch 186; iter: 0; batch classifier loss: 0.446244; batch adversarial loss: 0.601014\n",
      "epoch 187; iter: 0; batch classifier loss: 0.451927; batch adversarial loss: 0.481429\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395839; batch adversarial loss: 0.609176\n",
      "epoch 189; iter: 0; batch classifier loss: 0.288671; batch adversarial loss: 0.591328\n",
      "epoch 190; iter: 0; batch classifier loss: 0.412510; batch adversarial loss: 0.563250\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344889; batch adversarial loss: 0.517279\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401100; batch adversarial loss: 0.553357\n",
      "epoch 193; iter: 0; batch classifier loss: 0.441076; batch adversarial loss: 0.535084\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366291; batch adversarial loss: 0.489563\n",
      "epoch 195; iter: 0; batch classifier loss: 0.316333; batch adversarial loss: 0.543492\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339685; batch adversarial loss: 0.497840\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324615; batch adversarial loss: 0.588911\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343190; batch adversarial loss: 0.516478\n",
      "epoch 199; iter: 0; batch classifier loss: 0.376306; batch adversarial loss: 0.472080\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699418; batch adversarial loss: 0.629203\n",
      "epoch 1; iter: 0; batch classifier loss: 0.658117; batch adversarial loss: 0.656244\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573349; batch adversarial loss: 0.646532\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586678; batch adversarial loss: 0.629212\n",
      "epoch 4; iter: 0; batch classifier loss: 0.645250; batch adversarial loss: 0.621498\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593320; batch adversarial loss: 0.630167\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542211; batch adversarial loss: 0.649434\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548895; batch adversarial loss: 0.609260\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569549; batch adversarial loss: 0.586844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558857; batch adversarial loss: 0.558181\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512060; batch adversarial loss: 0.518170\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514867; batch adversarial loss: 0.555179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494935; batch adversarial loss: 0.613407\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495645; batch adversarial loss: 0.502472\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554641; batch adversarial loss: 0.506433\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498127; batch adversarial loss: 0.589642\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541969; batch adversarial loss: 0.583742\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487615; batch adversarial loss: 0.547034\n",
      "epoch 18; iter: 0; batch classifier loss: 0.576488; batch adversarial loss: 0.530478\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554162; batch adversarial loss: 0.492827\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428193; batch adversarial loss: 0.556561\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482742; batch adversarial loss: 0.582248\n",
      "epoch 22; iter: 0; batch classifier loss: 0.455502; batch adversarial loss: 0.475049\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501953; batch adversarial loss: 0.608663\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519025; batch adversarial loss: 0.516872\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467964; batch adversarial loss: 0.599040\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500063; batch adversarial loss: 0.482048\n",
      "epoch 27; iter: 0; batch classifier loss: 0.541190; batch adversarial loss: 0.472717\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489164; batch adversarial loss: 0.581013\n",
      "epoch 29; iter: 0; batch classifier loss: 0.470798; batch adversarial loss: 0.597465\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468982; batch adversarial loss: 0.597415\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484407; batch adversarial loss: 0.597337\n",
      "epoch 32; iter: 0; batch classifier loss: 0.385990; batch adversarial loss: 0.519270\n",
      "epoch 33; iter: 0; batch classifier loss: 0.419179; batch adversarial loss: 0.546531\n",
      "epoch 34; iter: 0; batch classifier loss: 0.507289; batch adversarial loss: 0.591736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.442936; batch adversarial loss: 0.585053\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485329; batch adversarial loss: 0.506813\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438447; batch adversarial loss: 0.524729\n",
      "epoch 38; iter: 0; batch classifier loss: 0.426395; batch adversarial loss: 0.506694\n",
      "epoch 39; iter: 0; batch classifier loss: 0.395287; batch adversarial loss: 0.582568\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425055; batch adversarial loss: 0.572402\n",
      "epoch 41; iter: 0; batch classifier loss: 0.457917; batch adversarial loss: 0.556043\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450570; batch adversarial loss: 0.507531\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435995; batch adversarial loss: 0.477920\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474018; batch adversarial loss: 0.544479\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463928; batch adversarial loss: 0.591521\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426866; batch adversarial loss: 0.591206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450467; batch adversarial loss: 0.422823\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448210; batch adversarial loss: 0.497399\n",
      "epoch 49; iter: 0; batch classifier loss: 0.504950; batch adversarial loss: 0.525669\n",
      "epoch 50; iter: 0; batch classifier loss: 0.483948; batch adversarial loss: 0.515368\n",
      "epoch 51; iter: 0; batch classifier loss: 0.517118; batch adversarial loss: 0.524339\n",
      "epoch 52; iter: 0; batch classifier loss: 0.518908; batch adversarial loss: 0.620648\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464373; batch adversarial loss: 0.525959\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451769; batch adversarial loss: 0.553270\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396901; batch adversarial loss: 0.555336\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446946; batch adversarial loss: 0.525823\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413995; batch adversarial loss: 0.469457\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460222; batch adversarial loss: 0.543956\n",
      "epoch 59; iter: 0; batch classifier loss: 0.535861; batch adversarial loss: 0.554885\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381568; batch adversarial loss: 0.516803\n",
      "epoch 61; iter: 0; batch classifier loss: 0.521082; batch adversarial loss: 0.581505\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434391; batch adversarial loss: 0.535256\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417005; batch adversarial loss: 0.478197\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404404; batch adversarial loss: 0.592508\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439885; batch adversarial loss: 0.583263\n",
      "epoch 66; iter: 0; batch classifier loss: 0.499389; batch adversarial loss: 0.488273\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413683; batch adversarial loss: 0.498008\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430252; batch adversarial loss: 0.545122\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389109; batch adversarial loss: 0.583193\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410887; batch adversarial loss: 0.515651\n",
      "epoch 71; iter: 0; batch classifier loss: 0.382248; batch adversarial loss: 0.611560\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410403; batch adversarial loss: 0.535335\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405799; batch adversarial loss: 0.515296\n",
      "epoch 74; iter: 0; batch classifier loss: 0.479740; batch adversarial loss: 0.544516\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387094; batch adversarial loss: 0.554318\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397321; batch adversarial loss: 0.525616\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435145; batch adversarial loss: 0.582754\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428159; batch adversarial loss: 0.591667\n",
      "epoch 79; iter: 0; batch classifier loss: 0.431157; batch adversarial loss: 0.544223\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378046; batch adversarial loss: 0.525178\n",
      "epoch 81; iter: 0; batch classifier loss: 0.490886; batch adversarial loss: 0.599702\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446856; batch adversarial loss: 0.581952\n",
      "epoch 83; iter: 0; batch classifier loss: 0.418607; batch adversarial loss: 0.516696\n",
      "epoch 84; iter: 0; batch classifier loss: 0.477780; batch adversarial loss: 0.450227\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402360; batch adversarial loss: 0.583253\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389272; batch adversarial loss: 0.544238\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430234; batch adversarial loss: 0.589878\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400284; batch adversarial loss: 0.667002\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375107; batch adversarial loss: 0.574132\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434556; batch adversarial loss: 0.545336\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432841; batch adversarial loss: 0.534338\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383904; batch adversarial loss: 0.554738\n",
      "epoch 93; iter: 0; batch classifier loss: 0.491814; batch adversarial loss: 0.526894\n",
      "epoch 94; iter: 0; batch classifier loss: 0.493521; batch adversarial loss: 0.506061\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420224; batch adversarial loss: 0.488209\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410235; batch adversarial loss: 0.572085\n",
      "epoch 97; iter: 0; batch classifier loss: 0.427633; batch adversarial loss: 0.553923\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400635; batch adversarial loss: 0.544762\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413355; batch adversarial loss: 0.591591\n",
      "epoch 100; iter: 0; batch classifier loss: 0.395686; batch adversarial loss: 0.592361\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382923; batch adversarial loss: 0.535293\n",
      "epoch 102; iter: 0; batch classifier loss: 0.437021; batch adversarial loss: 0.554494\n",
      "epoch 103; iter: 0; batch classifier loss: 0.353866; batch adversarial loss: 0.525980\n",
      "epoch 104; iter: 0; batch classifier loss: 0.408844; batch adversarial loss: 0.525448\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416608; batch adversarial loss: 0.487822\n",
      "epoch 106; iter: 0; batch classifier loss: 0.457951; batch adversarial loss: 0.525829\n",
      "epoch 107; iter: 0; batch classifier loss: 0.417144; batch adversarial loss: 0.506269\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393723; batch adversarial loss: 0.600956\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388912; batch adversarial loss: 0.516465\n",
      "epoch 110; iter: 0; batch classifier loss: 0.450422; batch adversarial loss: 0.535038\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380577; batch adversarial loss: 0.553649\n",
      "epoch 112; iter: 0; batch classifier loss: 0.471641; batch adversarial loss: 0.535274\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405846; batch adversarial loss: 0.515968\n",
      "epoch 114; iter: 0; batch classifier loss: 0.460048; batch adversarial loss: 0.563252\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346971; batch adversarial loss: 0.506753\n",
      "epoch 116; iter: 0; batch classifier loss: 0.367797; batch adversarial loss: 0.658321\n",
      "epoch 117; iter: 0; batch classifier loss: 0.409503; batch adversarial loss: 0.554541\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397700; batch adversarial loss: 0.610202\n",
      "epoch 119; iter: 0; batch classifier loss: 0.469510; batch adversarial loss: 0.552394\n",
      "epoch 120; iter: 0; batch classifier loss: 0.436746; batch adversarial loss: 0.608756\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335102; batch adversarial loss: 0.496952\n",
      "epoch 122; iter: 0; batch classifier loss: 0.332445; batch adversarial loss: 0.543172\n",
      "epoch 123; iter: 0; batch classifier loss: 0.397352; batch adversarial loss: 0.543484\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386381; batch adversarial loss: 0.478686\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369179; batch adversarial loss: 0.535512\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363912; batch adversarial loss: 0.487601\n",
      "epoch 127; iter: 0; batch classifier loss: 0.431806; batch adversarial loss: 0.459708\n",
      "epoch 128; iter: 0; batch classifier loss: 0.310933; batch adversarial loss: 0.555409\n",
      "epoch 129; iter: 0; batch classifier loss: 0.435074; batch adversarial loss: 0.515742\n",
      "epoch 130; iter: 0; batch classifier loss: 0.507562; batch adversarial loss: 0.553320\n",
      "epoch 131; iter: 0; batch classifier loss: 0.435412; batch adversarial loss: 0.515924\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381799; batch adversarial loss: 0.545799\n",
      "epoch 133; iter: 0; batch classifier loss: 0.428085; batch adversarial loss: 0.536177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.386244; batch adversarial loss: 0.449178\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366330; batch adversarial loss: 0.487369\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369262; batch adversarial loss: 0.536371\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353855; batch adversarial loss: 0.506707\n",
      "epoch 138; iter: 0; batch classifier loss: 0.452072; batch adversarial loss: 0.591657\n",
      "epoch 139; iter: 0; batch classifier loss: 0.310301; batch adversarial loss: 0.449697\n",
      "epoch 140; iter: 0; batch classifier loss: 0.372096; batch adversarial loss: 0.564354\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365368; batch adversarial loss: 0.574320\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374509; batch adversarial loss: 0.496469\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413468; batch adversarial loss: 0.507608\n",
      "epoch 144; iter: 0; batch classifier loss: 0.484471; batch adversarial loss: 0.554812\n",
      "epoch 145; iter: 0; batch classifier loss: 0.424657; batch adversarial loss: 0.544917\n",
      "epoch 146; iter: 0; batch classifier loss: 0.338265; batch adversarial loss: 0.545305\n",
      "epoch 147; iter: 0; batch classifier loss: 0.403575; batch adversarial loss: 0.611012\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376497; batch adversarial loss: 0.516607\n",
      "epoch 149; iter: 0; batch classifier loss: 0.387094; batch adversarial loss: 0.601124\n",
      "epoch 150; iter: 0; batch classifier loss: 0.424022; batch adversarial loss: 0.506208\n",
      "epoch 151; iter: 0; batch classifier loss: 0.335036; batch adversarial loss: 0.488099\n",
      "epoch 152; iter: 0; batch classifier loss: 0.411714; batch adversarial loss: 0.618809\n",
      "epoch 153; iter: 0; batch classifier loss: 0.307208; batch adversarial loss: 0.534857\n",
      "epoch 154; iter: 0; batch classifier loss: 0.482978; batch adversarial loss: 0.535119\n",
      "epoch 155; iter: 0; batch classifier loss: 0.274872; batch adversarial loss: 0.525651\n",
      "epoch 156; iter: 0; batch classifier loss: 0.497371; batch adversarial loss: 0.543877\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367128; batch adversarial loss: 0.591920\n",
      "epoch 158; iter: 0; batch classifier loss: 0.497557; batch adversarial loss: 0.544146\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373633; batch adversarial loss: 0.572173\n",
      "epoch 160; iter: 0; batch classifier loss: 0.285549; batch adversarial loss: 0.562349\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412643; batch adversarial loss: 0.515783\n",
      "epoch 162; iter: 0; batch classifier loss: 0.498978; batch adversarial loss: 0.517305\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374183; batch adversarial loss: 0.524870\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346795; batch adversarial loss: 0.598616\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327870; batch adversarial loss: 0.551571\n",
      "epoch 166; iter: 0; batch classifier loss: 0.454173; batch adversarial loss: 0.452175\n",
      "epoch 167; iter: 0; batch classifier loss: 0.429114; batch adversarial loss: 0.525311\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352759; batch adversarial loss: 0.625394\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403101; batch adversarial loss: 0.525712\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342863; batch adversarial loss: 0.545650\n",
      "epoch 171; iter: 0; batch classifier loss: 0.434351; batch adversarial loss: 0.506426\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379120; batch adversarial loss: 0.555006\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404015; batch adversarial loss: 0.592623\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348588; batch adversarial loss: 0.563309\n",
      "epoch 175; iter: 0; batch classifier loss: 0.459093; batch adversarial loss: 0.554843\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381018; batch adversarial loss: 0.535428\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346510; batch adversarial loss: 0.564080\n",
      "epoch 178; iter: 0; batch classifier loss: 0.373457; batch adversarial loss: 0.524643\n",
      "epoch 179; iter: 0; batch classifier loss: 0.418070; batch adversarial loss: 0.582451\n",
      "epoch 180; iter: 0; batch classifier loss: 0.406955; batch adversarial loss: 0.574838\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320958; batch adversarial loss: 0.487882\n",
      "epoch 182; iter: 0; batch classifier loss: 0.298649; batch adversarial loss: 0.496412\n",
      "epoch 183; iter: 0; batch classifier loss: 0.477415; batch adversarial loss: 0.508346\n",
      "epoch 184; iter: 0; batch classifier loss: 0.310494; batch adversarial loss: 0.516858\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383800; batch adversarial loss: 0.506156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.374768; batch adversarial loss: 0.497315\n",
      "epoch 187; iter: 0; batch classifier loss: 0.296182; batch adversarial loss: 0.524961\n",
      "epoch 188; iter: 0; batch classifier loss: 0.357614; batch adversarial loss: 0.572466\n",
      "epoch 189; iter: 0; batch classifier loss: 0.474724; batch adversarial loss: 0.555896\n",
      "epoch 190; iter: 0; batch classifier loss: 0.303243; batch adversarial loss: 0.488226\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322312; batch adversarial loss: 0.552988\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318330; batch adversarial loss: 0.553859\n",
      "epoch 193; iter: 0; batch classifier loss: 0.431381; batch adversarial loss: 0.467244\n",
      "epoch 194; iter: 0; batch classifier loss: 0.391335; batch adversarial loss: 0.574269\n",
      "epoch 195; iter: 0; batch classifier loss: 0.411652; batch adversarial loss: 0.564151\n",
      "epoch 196; iter: 0; batch classifier loss: 0.409865; batch adversarial loss: 0.525373\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322003; batch adversarial loss: 0.498000\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363110; batch adversarial loss: 0.554194\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342548; batch adversarial loss: 0.552433\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708232; batch adversarial loss: 0.693222\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600690; batch adversarial loss: 0.665185\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593690; batch adversarial loss: 0.613200\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531316; batch adversarial loss: 0.637515\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584639; batch adversarial loss: 0.652126\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495694; batch adversarial loss: 0.623412\n",
      "epoch 6; iter: 0; batch classifier loss: 0.499288; batch adversarial loss: 0.596570\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539518; batch adversarial loss: 0.605827\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552414; batch adversarial loss: 0.544717\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558982; batch adversarial loss: 0.569750\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511125; batch adversarial loss: 0.599086\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496344; batch adversarial loss: 0.626174\n",
      "epoch 12; iter: 0; batch classifier loss: 0.563186; batch adversarial loss: 0.567147\n",
      "epoch 13; iter: 0; batch classifier loss: 0.465449; batch adversarial loss: 0.544201\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521334; batch adversarial loss: 0.562763\n",
      "epoch 15; iter: 0; batch classifier loss: 0.567467; batch adversarial loss: 0.535400\n",
      "epoch 16; iter: 0; batch classifier loss: 0.564978; batch adversarial loss: 0.577868\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537967; batch adversarial loss: 0.600149\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493221; batch adversarial loss: 0.636537\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541712; batch adversarial loss: 0.585933\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478754; batch adversarial loss: 0.542547\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497233; batch adversarial loss: 0.543999\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503651; batch adversarial loss: 0.556070\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506453; batch adversarial loss: 0.614102\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487658; batch adversarial loss: 0.532785\n",
      "epoch 25; iter: 0; batch classifier loss: 0.459529; batch adversarial loss: 0.556516\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506889; batch adversarial loss: 0.537417\n",
      "epoch 27; iter: 0; batch classifier loss: 0.492494; batch adversarial loss: 0.597918\n",
      "epoch 28; iter: 0; batch classifier loss: 0.509569; batch adversarial loss: 0.560372\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424776; batch adversarial loss: 0.552278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.517374; batch adversarial loss: 0.541300\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473542; batch adversarial loss: 0.569654\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496221; batch adversarial loss: 0.512925\n",
      "epoch 33; iter: 0; batch classifier loss: 0.499920; batch adversarial loss: 0.580863\n",
      "epoch 34; iter: 0; batch classifier loss: 0.479724; batch adversarial loss: 0.495999\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456488; batch adversarial loss: 0.545414\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434672; batch adversarial loss: 0.536875\n",
      "epoch 37; iter: 0; batch classifier loss: 0.397511; batch adversarial loss: 0.527829\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442838; batch adversarial loss: 0.527296\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470308; batch adversarial loss: 0.562097\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490833; batch adversarial loss: 0.483435\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434087; batch adversarial loss: 0.545031\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448309; batch adversarial loss: 0.597731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.373401; batch adversarial loss: 0.553805\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427285; batch adversarial loss: 0.571361\n",
      "epoch 45; iter: 0; batch classifier loss: 0.547604; batch adversarial loss: 0.562248\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422545; batch adversarial loss: 0.562925\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443287; batch adversarial loss: 0.562922\n",
      "epoch 48; iter: 0; batch classifier loss: 0.436465; batch adversarial loss: 0.536131\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382389; batch adversarial loss: 0.526434\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463699; batch adversarial loss: 0.526555\n",
      "epoch 51; iter: 0; batch classifier loss: 0.457753; batch adversarial loss: 0.517721\n",
      "epoch 52; iter: 0; batch classifier loss: 0.478251; batch adversarial loss: 0.562270\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442472; batch adversarial loss: 0.572590\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423218; batch adversarial loss: 0.507804\n",
      "epoch 55; iter: 0; batch classifier loss: 0.391813; batch adversarial loss: 0.543894\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414518; batch adversarial loss: 0.625829\n",
      "epoch 57; iter: 0; batch classifier loss: 0.488115; batch adversarial loss: 0.571339\n",
      "epoch 58; iter: 0; batch classifier loss: 0.563374; batch adversarial loss: 0.490851\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410815; batch adversarial loss: 0.527125\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428155; batch adversarial loss: 0.571754\n",
      "epoch 61; iter: 0; batch classifier loss: 0.431293; batch adversarial loss: 0.626809\n",
      "epoch 62; iter: 0; batch classifier loss: 0.486634; batch adversarial loss: 0.507888\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378718; batch adversarial loss: 0.535424\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384261; batch adversarial loss: 0.534887\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367843; batch adversarial loss: 0.499085\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433005; batch adversarial loss: 0.499412\n",
      "epoch 67; iter: 0; batch classifier loss: 0.440839; batch adversarial loss: 0.533997\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393659; batch adversarial loss: 0.574390\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371360; batch adversarial loss: 0.526201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.346978; batch adversarial loss: 0.545590\n",
      "epoch 71; iter: 0; batch classifier loss: 0.348354; batch adversarial loss: 0.562481\n",
      "epoch 72; iter: 0; batch classifier loss: 0.476526; batch adversarial loss: 0.444502\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446063; batch adversarial loss: 0.563070\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385200; batch adversarial loss: 0.554392\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362683; batch adversarial loss: 0.525423\n",
      "epoch 76; iter: 0; batch classifier loss: 0.478683; batch adversarial loss: 0.517753\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413821; batch adversarial loss: 0.535912\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401154; batch adversarial loss: 0.534633\n",
      "epoch 79; iter: 0; batch classifier loss: 0.431556; batch adversarial loss: 0.490449\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442720; batch adversarial loss: 0.518140\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389373; batch adversarial loss: 0.532820\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350597; batch adversarial loss: 0.553615\n",
      "epoch 83; iter: 0; batch classifier loss: 0.451797; batch adversarial loss: 0.598945\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411824; batch adversarial loss: 0.489997\n",
      "epoch 85; iter: 0; batch classifier loss: 0.429267; batch adversarial loss: 0.581449\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365581; batch adversarial loss: 0.590542\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420987; batch adversarial loss: 0.536357\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418869; batch adversarial loss: 0.591220\n",
      "epoch 89; iter: 0; batch classifier loss: 0.364770; batch adversarial loss: 0.499959\n",
      "epoch 90; iter: 0; batch classifier loss: 0.503786; batch adversarial loss: 0.573077\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410251; batch adversarial loss: 0.528118\n",
      "epoch 92; iter: 0; batch classifier loss: 0.340541; batch adversarial loss: 0.607287\n",
      "epoch 93; iter: 0; batch classifier loss: 0.331932; batch adversarial loss: 0.560158\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415113; batch adversarial loss: 0.490333\n",
      "epoch 95; iter: 0; batch classifier loss: 0.376218; batch adversarial loss: 0.582024\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416740; batch adversarial loss: 0.554465\n",
      "epoch 97; iter: 0; batch classifier loss: 0.432836; batch adversarial loss: 0.518284\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349160; batch adversarial loss: 0.534720\n",
      "epoch 99; iter: 0; batch classifier loss: 0.306723; batch adversarial loss: 0.662780\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439308; batch adversarial loss: 0.545037\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382350; batch adversarial loss: 0.534699\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415768; batch adversarial loss: 0.578616\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406435; batch adversarial loss: 0.518242\n",
      "epoch 104; iter: 0; batch classifier loss: 0.424325; batch adversarial loss: 0.633521\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424238; batch adversarial loss: 0.553409\n",
      "epoch 106; iter: 0; batch classifier loss: 0.340141; batch adversarial loss: 0.544349\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380492; batch adversarial loss: 0.553044\n",
      "epoch 108; iter: 0; batch classifier loss: 0.441973; batch adversarial loss: 0.588346\n",
      "epoch 109; iter: 0; batch classifier loss: 0.414548; batch adversarial loss: 0.480316\n",
      "epoch 110; iter: 0; batch classifier loss: 0.427416; batch adversarial loss: 0.444870\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408150; batch adversarial loss: 0.534453\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405143; batch adversarial loss: 0.582174\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354336; batch adversarial loss: 0.518081\n",
      "epoch 114; iter: 0; batch classifier loss: 0.415343; batch adversarial loss: 0.545691\n",
      "epoch 115; iter: 0; batch classifier loss: 0.338896; batch adversarial loss: 0.626240\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357527; batch adversarial loss: 0.527256\n",
      "epoch 117; iter: 0; batch classifier loss: 0.410216; batch adversarial loss: 0.517116\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427681; batch adversarial loss: 0.571442\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352366; batch adversarial loss: 0.546297\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383164; batch adversarial loss: 0.606459\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341210; batch adversarial loss: 0.551611\n",
      "epoch 122; iter: 0; batch classifier loss: 0.341576; batch adversarial loss: 0.569954\n",
      "epoch 123; iter: 0; batch classifier loss: 0.386363; batch adversarial loss: 0.571534\n",
      "epoch 124; iter: 0; batch classifier loss: 0.315474; batch adversarial loss: 0.526327\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349640; batch adversarial loss: 0.545745\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338935; batch adversarial loss: 0.554925\n",
      "epoch 127; iter: 0; batch classifier loss: 0.425446; batch adversarial loss: 0.506937\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404331; batch adversarial loss: 0.579421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.356524; batch adversarial loss: 0.588627\n",
      "epoch 130; iter: 0; batch classifier loss: 0.416122; batch adversarial loss: 0.509017\n",
      "epoch 131; iter: 0; batch classifier loss: 0.470032; batch adversarial loss: 0.634686\n",
      "epoch 132; iter: 0; batch classifier loss: 0.368307; batch adversarial loss: 0.501247\n",
      "epoch 133; iter: 0; batch classifier loss: 0.447773; batch adversarial loss: 0.535673\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372761; batch adversarial loss: 0.590954\n",
      "epoch 135; iter: 0; batch classifier loss: 0.409067; batch adversarial loss: 0.570628\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378818; batch adversarial loss: 0.573454\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354142; batch adversarial loss: 0.578861\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383061; batch adversarial loss: 0.562859\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383383; batch adversarial loss: 0.571430\n",
      "epoch 140; iter: 0; batch classifier loss: 0.406291; batch adversarial loss: 0.561657\n",
      "epoch 141; iter: 0; batch classifier loss: 0.301059; batch adversarial loss: 0.517175\n",
      "epoch 142; iter: 0; batch classifier loss: 0.277568; batch adversarial loss: 0.591005\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378986; batch adversarial loss: 0.552464\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358591; batch adversarial loss: 0.517995\n",
      "epoch 145; iter: 0; batch classifier loss: 0.449901; batch adversarial loss: 0.509582\n",
      "epoch 146; iter: 0; batch classifier loss: 0.356930; batch adversarial loss: 0.572249\n",
      "epoch 147; iter: 0; batch classifier loss: 0.419172; batch adversarial loss: 0.591020\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367138; batch adversarial loss: 0.681251\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353519; batch adversarial loss: 0.535657\n",
      "epoch 150; iter: 0; batch classifier loss: 0.274203; batch adversarial loss: 0.572023\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310686; batch adversarial loss: 0.481738\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356760; batch adversarial loss: 0.627305\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339615; batch adversarial loss: 0.536475\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375106; batch adversarial loss: 0.545567\n",
      "epoch 155; iter: 0; batch classifier loss: 0.431319; batch adversarial loss: 0.526700\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357115; batch adversarial loss: 0.561870\n",
      "epoch 157; iter: 0; batch classifier loss: 0.419052; batch adversarial loss: 0.597164\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336356; batch adversarial loss: 0.535826\n",
      "epoch 159; iter: 0; batch classifier loss: 0.426142; batch adversarial loss: 0.516499\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360275; batch adversarial loss: 0.507783\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380734; batch adversarial loss: 0.579754\n",
      "epoch 162; iter: 0; batch classifier loss: 0.294042; batch adversarial loss: 0.588214\n",
      "epoch 163; iter: 0; batch classifier loss: 0.459247; batch adversarial loss: 0.606588\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385433; batch adversarial loss: 0.516868\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343534; batch adversarial loss: 0.599251\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364227; batch adversarial loss: 0.463397\n",
      "epoch 167; iter: 0; batch classifier loss: 0.436111; batch adversarial loss: 0.518952\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330643; batch adversarial loss: 0.489510\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371210; batch adversarial loss: 0.479667\n",
      "epoch 170; iter: 0; batch classifier loss: 0.305932; batch adversarial loss: 0.605511\n",
      "epoch 171; iter: 0; batch classifier loss: 0.301400; batch adversarial loss: 0.526346\n",
      "epoch 172; iter: 0; batch classifier loss: 0.319288; batch adversarial loss: 0.625636\n",
      "epoch 173; iter: 0; batch classifier loss: 0.347708; batch adversarial loss: 0.489546\n",
      "epoch 174; iter: 0; batch classifier loss: 0.488484; batch adversarial loss: 0.444933\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349465; batch adversarial loss: 0.599860\n",
      "epoch 176; iter: 0; batch classifier loss: 0.429504; batch adversarial loss: 0.534829\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391714; batch adversarial loss: 0.580734\n",
      "epoch 178; iter: 0; batch classifier loss: 0.398706; batch adversarial loss: 0.553642\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366376; batch adversarial loss: 0.515933\n",
      "epoch 180; iter: 0; batch classifier loss: 0.280902; batch adversarial loss: 0.526144\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354784; batch adversarial loss: 0.555484\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370334; batch adversarial loss: 0.525632\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348961; batch adversarial loss: 0.551509\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357116; batch adversarial loss: 0.589016\n",
      "epoch 185; iter: 0; batch classifier loss: 0.412687; batch adversarial loss: 0.490721\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350323; batch adversarial loss: 0.570980\n",
      "epoch 187; iter: 0; batch classifier loss: 0.381103; batch adversarial loss: 0.544459\n",
      "epoch 188; iter: 0; batch classifier loss: 0.326708; batch adversarial loss: 0.500540\n",
      "epoch 189; iter: 0; batch classifier loss: 0.324271; batch adversarial loss: 0.516189\n",
      "epoch 190; iter: 0; batch classifier loss: 0.413186; batch adversarial loss: 0.508167\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390675; batch adversarial loss: 0.562835\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355023; batch adversarial loss: 0.588746\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331773; batch adversarial loss: 0.516886\n",
      "epoch 194; iter: 0; batch classifier loss: 0.420819; batch adversarial loss: 0.590503\n",
      "epoch 195; iter: 0; batch classifier loss: 0.442882; batch adversarial loss: 0.535443\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345992; batch adversarial loss: 0.562361\n",
      "epoch 197; iter: 0; batch classifier loss: 0.338029; batch adversarial loss: 0.545097\n",
      "epoch 198; iter: 0; batch classifier loss: 0.318388; batch adversarial loss: 0.541776\n",
      "epoch 199; iter: 0; batch classifier loss: 0.294553; batch adversarial loss: 0.581539\n",
      "epoch 0; iter: 0; batch classifier loss: 0.639551; batch adversarial loss: 0.651796\n",
      "epoch 1; iter: 0; batch classifier loss: 0.552129; batch adversarial loss: 0.655529\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595808; batch adversarial loss: 0.619222\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652611; batch adversarial loss: 0.687242\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521611; batch adversarial loss: 0.642164\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517473; batch adversarial loss: 0.622713\n",
      "epoch 6; iter: 0; batch classifier loss: 0.530339; batch adversarial loss: 0.636250\n",
      "epoch 7; iter: 0; batch classifier loss: 0.629647; batch adversarial loss: 0.669334\n",
      "epoch 8; iter: 0; batch classifier loss: 0.603733; batch adversarial loss: 0.561777\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526957; batch adversarial loss: 0.560763\n",
      "epoch 10; iter: 0; batch classifier loss: 0.488216; batch adversarial loss: 0.568140\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525108; batch adversarial loss: 0.644182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.466931; batch adversarial loss: 0.560399\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536962; batch adversarial loss: 0.566655\n",
      "epoch 14; iter: 0; batch classifier loss: 0.519974; batch adversarial loss: 0.574351\n",
      "epoch 15; iter: 0; batch classifier loss: 0.461287; batch adversarial loss: 0.540101\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465176; batch adversarial loss: 0.555117\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501299; batch adversarial loss: 0.574092\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503788; batch adversarial loss: 0.531924\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463730; batch adversarial loss: 0.525615\n",
      "epoch 20; iter: 0; batch classifier loss: 0.486916; batch adversarial loss: 0.611686\n",
      "epoch 21; iter: 0; batch classifier loss: 0.457013; batch adversarial loss: 0.533368\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486766; batch adversarial loss: 0.562597\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451007; batch adversarial loss: 0.521640\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509474; batch adversarial loss: 0.522513\n",
      "epoch 25; iter: 0; batch classifier loss: 0.402087; batch adversarial loss: 0.521414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.480417; batch adversarial loss: 0.569805\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437230; batch adversarial loss: 0.570251\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473415; batch adversarial loss: 0.554815\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475310; batch adversarial loss: 0.590686\n",
      "epoch 30; iter: 0; batch classifier loss: 0.379289; batch adversarial loss: 0.589424\n",
      "epoch 31; iter: 0; batch classifier loss: 0.405397; batch adversarial loss: 0.544834\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438919; batch adversarial loss: 0.499526\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429901; batch adversarial loss: 0.553100\n",
      "epoch 34; iter: 0; batch classifier loss: 0.413496; batch adversarial loss: 0.581040\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438187; batch adversarial loss: 0.525596\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473333; batch adversarial loss: 0.635768\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500352; batch adversarial loss: 0.608192\n",
      "epoch 38; iter: 0; batch classifier loss: 0.421591; batch adversarial loss: 0.590949\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428789; batch adversarial loss: 0.590556\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420080; batch adversarial loss: 0.581844\n",
      "epoch 41; iter: 0; batch classifier loss: 0.506629; batch adversarial loss: 0.563061\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398401; batch adversarial loss: 0.526118\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433432; batch adversarial loss: 0.534876\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446544; batch adversarial loss: 0.489235\n",
      "epoch 45; iter: 0; batch classifier loss: 0.493754; batch adversarial loss: 0.591250\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458303; batch adversarial loss: 0.469106\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413745; batch adversarial loss: 0.581500\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464053; batch adversarial loss: 0.524417\n",
      "epoch 49; iter: 0; batch classifier loss: 0.363847; batch adversarial loss: 0.507112\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423538; batch adversarial loss: 0.524545\n",
      "epoch 51; iter: 0; batch classifier loss: 0.396574; batch adversarial loss: 0.506093\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399146; batch adversarial loss: 0.507555\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437871; batch adversarial loss: 0.577972\n",
      "epoch 54; iter: 0; batch classifier loss: 0.398943; batch adversarial loss: 0.526844\n",
      "epoch 55; iter: 0; batch classifier loss: 0.399658; batch adversarial loss: 0.552744\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445206; batch adversarial loss: 0.580606\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425605; batch adversarial loss: 0.549038\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430008; batch adversarial loss: 0.515920\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384100; batch adversarial loss: 0.554143\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407323; batch adversarial loss: 0.553023\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418095; batch adversarial loss: 0.576967\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397819; batch adversarial loss: 0.470998\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473599; batch adversarial loss: 0.564225\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407378; batch adversarial loss: 0.468517\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438362; batch adversarial loss: 0.629812\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408356; batch adversarial loss: 0.536226\n",
      "epoch 67; iter: 0; batch classifier loss: 0.358178; batch adversarial loss: 0.594361\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401762; batch adversarial loss: 0.498440\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416870; batch adversarial loss: 0.496671\n",
      "epoch 70; iter: 0; batch classifier loss: 0.379929; batch adversarial loss: 0.497057\n",
      "epoch 71; iter: 0; batch classifier loss: 0.385282; batch adversarial loss: 0.581103\n",
      "epoch 72; iter: 0; batch classifier loss: 0.384029; batch adversarial loss: 0.488265\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355972; batch adversarial loss: 0.548176\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391037; batch adversarial loss: 0.547062\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398682; batch adversarial loss: 0.442765\n",
      "epoch 76; iter: 0; batch classifier loss: 0.451264; batch adversarial loss: 0.444158\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411388; batch adversarial loss: 0.523836\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377927; batch adversarial loss: 0.507666\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384408; batch adversarial loss: 0.537021\n",
      "epoch 80; iter: 0; batch classifier loss: 0.468171; batch adversarial loss: 0.514507\n",
      "epoch 81; iter: 0; batch classifier loss: 0.320184; batch adversarial loss: 0.583903\n",
      "epoch 82; iter: 0; batch classifier loss: 0.347670; batch adversarial loss: 0.477097\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425409; batch adversarial loss: 0.579574\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377433; batch adversarial loss: 0.614396\n",
      "epoch 85; iter: 0; batch classifier loss: 0.341061; batch adversarial loss: 0.560302\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412600; batch adversarial loss: 0.559023\n",
      "epoch 87; iter: 0; batch classifier loss: 0.453689; batch adversarial loss: 0.506851\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428061; batch adversarial loss: 0.487529\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395561; batch adversarial loss: 0.517465\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420121; batch adversarial loss: 0.505014\n",
      "epoch 91; iter: 0; batch classifier loss: 0.357848; batch adversarial loss: 0.552215\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402250; batch adversarial loss: 0.564843\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.544484\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365973; batch adversarial loss: 0.529475\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392147; batch adversarial loss: 0.442276\n",
      "epoch 96; iter: 0; batch classifier loss: 0.435232; batch adversarial loss: 0.556355\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370782; batch adversarial loss: 0.552402\n",
      "epoch 98; iter: 0; batch classifier loss: 0.340294; batch adversarial loss: 0.484910\n",
      "epoch 99; iter: 0; batch classifier loss: 0.451165; batch adversarial loss: 0.542913\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370709; batch adversarial loss: 0.517780\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399081; batch adversarial loss: 0.551894\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385047; batch adversarial loss: 0.497102\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396160; batch adversarial loss: 0.573936\n",
      "epoch 104; iter: 0; batch classifier loss: 0.485985; batch adversarial loss: 0.545481\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363174; batch adversarial loss: 0.487292\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376727; batch adversarial loss: 0.517020\n",
      "epoch 107; iter: 0; batch classifier loss: 0.428532; batch adversarial loss: 0.609014\n",
      "epoch 108; iter: 0; batch classifier loss: 0.445940; batch adversarial loss: 0.543355\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421405; batch adversarial loss: 0.603689\n",
      "epoch 110; iter: 0; batch classifier loss: 0.334086; batch adversarial loss: 0.579914\n",
      "epoch 111; iter: 0; batch classifier loss: 0.366342; batch adversarial loss: 0.582227\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375966; batch adversarial loss: 0.534661\n",
      "epoch 113; iter: 0; batch classifier loss: 0.336268; batch adversarial loss: 0.572261\n",
      "epoch 114; iter: 0; batch classifier loss: 0.431450; batch adversarial loss: 0.526780\n",
      "epoch 115; iter: 0; batch classifier loss: 0.327488; batch adversarial loss: 0.545525\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402921; batch adversarial loss: 0.522336\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415434; batch adversarial loss: 0.499489\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395039; batch adversarial loss: 0.597972\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433282; batch adversarial loss: 0.508030\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372440; batch adversarial loss: 0.527316\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365062; batch adversarial loss: 0.518096\n",
      "epoch 122; iter: 0; batch classifier loss: 0.257276; batch adversarial loss: 0.534583\n",
      "epoch 123; iter: 0; batch classifier loss: 0.448720; batch adversarial loss: 0.617641\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408738; batch adversarial loss: 0.554821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.386963; batch adversarial loss: 0.547953\n",
      "epoch 126; iter: 0; batch classifier loss: 0.437391; batch adversarial loss: 0.509871\n",
      "epoch 127; iter: 0; batch classifier loss: 0.410232; batch adversarial loss: 0.456815\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338020; batch adversarial loss: 0.507472\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385749; batch adversarial loss: 0.516198\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361912; batch adversarial loss: 0.630236\n",
      "epoch 131; iter: 0; batch classifier loss: 0.352607; batch adversarial loss: 0.523558\n",
      "epoch 132; iter: 0; batch classifier loss: 0.296454; batch adversarial loss: 0.498854\n",
      "epoch 133; iter: 0; batch classifier loss: 0.401432; batch adversarial loss: 0.599021\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364744; batch adversarial loss: 0.512631\n",
      "epoch 135; iter: 0; batch classifier loss: 0.411670; batch adversarial loss: 0.602156\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370823; batch adversarial loss: 0.558013\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372409; batch adversarial loss: 0.579163\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388331; batch adversarial loss: 0.461129\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334923; batch adversarial loss: 0.537844\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360867; batch adversarial loss: 0.582407\n",
      "epoch 141; iter: 0; batch classifier loss: 0.453928; batch adversarial loss: 0.423247\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398345; batch adversarial loss: 0.565702\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356326; batch adversarial loss: 0.518691\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354390; batch adversarial loss: 0.490310\n",
      "epoch 145; iter: 0; batch classifier loss: 0.297549; batch adversarial loss: 0.524419\n",
      "epoch 146; iter: 0; batch classifier loss: 0.333557; batch adversarial loss: 0.583094\n",
      "epoch 147; iter: 0; batch classifier loss: 0.428556; batch adversarial loss: 0.513945\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386465; batch adversarial loss: 0.525736\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319422; batch adversarial loss: 0.536423\n",
      "epoch 150; iter: 0; batch classifier loss: 0.420150; batch adversarial loss: 0.513740\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367701; batch adversarial loss: 0.524004\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362927; batch adversarial loss: 0.606329\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329369; batch adversarial loss: 0.657238\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332139; batch adversarial loss: 0.514336\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394282; batch adversarial loss: 0.504644\n",
      "epoch 156; iter: 0; batch classifier loss: 0.422443; batch adversarial loss: 0.547071\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374071; batch adversarial loss: 0.596615\n",
      "epoch 158; iter: 0; batch classifier loss: 0.451364; batch adversarial loss: 0.584181\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351563; batch adversarial loss: 0.592253\n",
      "epoch 160; iter: 0; batch classifier loss: 0.359057; batch adversarial loss: 0.552540\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412091; batch adversarial loss: 0.529419\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382978; batch adversarial loss: 0.518762\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386804; batch adversarial loss: 0.524547\n",
      "epoch 164; iter: 0; batch classifier loss: 0.451945; batch adversarial loss: 0.612391\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344084; batch adversarial loss: 0.488882\n",
      "epoch 166; iter: 0; batch classifier loss: 0.355908; batch adversarial loss: 0.535859\n",
      "epoch 167; iter: 0; batch classifier loss: 0.314819; batch adversarial loss: 0.561935\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366977; batch adversarial loss: 0.535505\n",
      "epoch 169; iter: 0; batch classifier loss: 0.396419; batch adversarial loss: 0.487406\n",
      "epoch 170; iter: 0; batch classifier loss: 0.358360; batch adversarial loss: 0.554472\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369846; batch adversarial loss: 0.449069\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377294; batch adversarial loss: 0.536514\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321851; batch adversarial loss: 0.486261\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338468; batch adversarial loss: 0.561548\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328771; batch adversarial loss: 0.573834\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369980; batch adversarial loss: 0.566677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.357439; batch adversarial loss: 0.559283\n",
      "epoch 178; iter: 0; batch classifier loss: 0.262307; batch adversarial loss: 0.517376\n",
      "epoch 179; iter: 0; batch classifier loss: 0.278295; batch adversarial loss: 0.490264\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369713; batch adversarial loss: 0.517920\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383427; batch adversarial loss: 0.523476\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357181; batch adversarial loss: 0.572533\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353357; batch adversarial loss: 0.554244\n",
      "epoch 184; iter: 0; batch classifier loss: 0.409167; batch adversarial loss: 0.550126\n",
      "epoch 185; iter: 0; batch classifier loss: 0.314553; batch adversarial loss: 0.505940\n",
      "epoch 186; iter: 0; batch classifier loss: 0.332540; batch adversarial loss: 0.527449\n",
      "epoch 187; iter: 0; batch classifier loss: 0.305529; batch adversarial loss: 0.497660\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387709; batch adversarial loss: 0.524375\n",
      "epoch 189; iter: 0; batch classifier loss: 0.398581; batch adversarial loss: 0.478586\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336811; batch adversarial loss: 0.597445\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337850; batch adversarial loss: 0.574281\n",
      "epoch 192; iter: 0; batch classifier loss: 0.425723; batch adversarial loss: 0.659833\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403545; batch adversarial loss: 0.494943\n",
      "epoch 194; iter: 0; batch classifier loss: 0.291595; batch adversarial loss: 0.548274\n",
      "epoch 195; iter: 0; batch classifier loss: 0.264405; batch adversarial loss: 0.549583\n",
      "epoch 196; iter: 0; batch classifier loss: 0.324619; batch adversarial loss: 0.509149\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317529; batch adversarial loss: 0.500734\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356870; batch adversarial loss: 0.470324\n",
      "epoch 199; iter: 0; batch classifier loss: 0.305416; batch adversarial loss: 0.601356\n",
      "epoch 0; iter: 0; batch classifier loss: 0.646852; batch adversarial loss: 0.799730\n",
      "epoch 1; iter: 0; batch classifier loss: 0.782825; batch adversarial loss: 0.918761\n",
      "epoch 2; iter: 0; batch classifier loss: 0.944045; batch adversarial loss: 0.846952\n",
      "epoch 3; iter: 0; batch classifier loss: 0.944277; batch adversarial loss: 0.787120\n",
      "epoch 4; iter: 0; batch classifier loss: 0.847494; batch adversarial loss: 0.722932\n",
      "epoch 5; iter: 0; batch classifier loss: 0.799768; batch adversarial loss: 0.668843\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596874; batch adversarial loss: 0.620183\n",
      "epoch 7; iter: 0; batch classifier loss: 0.649059; batch adversarial loss: 0.602772\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601646; batch adversarial loss: 0.566037\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527709; batch adversarial loss: 0.602388\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543555; batch adversarial loss: 0.625458\n",
      "epoch 11; iter: 0; batch classifier loss: 0.472590; batch adversarial loss: 0.588209\n",
      "epoch 12; iter: 0; batch classifier loss: 0.613784; batch adversarial loss: 0.579571\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515425; batch adversarial loss: 0.549746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491888; batch adversarial loss: 0.551148\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519930; batch adversarial loss: 0.597391\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476103; batch adversarial loss: 0.554834\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471726; batch adversarial loss: 0.561537\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497476; batch adversarial loss: 0.583290\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468796; batch adversarial loss: 0.561115\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529952; batch adversarial loss: 0.552777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.499107; batch adversarial loss: 0.617730\n",
      "epoch 22; iter: 0; batch classifier loss: 0.561201; batch adversarial loss: 0.606396\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463277; batch adversarial loss: 0.568277\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475388; batch adversarial loss: 0.542516\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461970; batch adversarial loss: 0.526321\n",
      "epoch 26; iter: 0; batch classifier loss: 0.406923; batch adversarial loss: 0.562108\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442870; batch adversarial loss: 0.574644\n",
      "epoch 28; iter: 0; batch classifier loss: 0.543544; batch adversarial loss: 0.535478\n",
      "epoch 29; iter: 0; batch classifier loss: 0.552114; batch adversarial loss: 0.539513\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432482; batch adversarial loss: 0.466220\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494983; batch adversarial loss: 0.555000\n",
      "epoch 32; iter: 0; batch classifier loss: 0.532207; batch adversarial loss: 0.552049\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460343; batch adversarial loss: 0.604093\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426595; batch adversarial loss: 0.539720\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411165; batch adversarial loss: 0.509961\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469735; batch adversarial loss: 0.503309\n",
      "epoch 37; iter: 0; batch classifier loss: 0.517744; batch adversarial loss: 0.621845\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480868; batch adversarial loss: 0.524916\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479342; batch adversarial loss: 0.576532\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399629; batch adversarial loss: 0.526878\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464525; batch adversarial loss: 0.472723\n",
      "epoch 42; iter: 0; batch classifier loss: 0.516323; batch adversarial loss: 0.533984\n",
      "epoch 43; iter: 0; batch classifier loss: 0.496389; batch adversarial loss: 0.554475\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459928; batch adversarial loss: 0.485270\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466305; batch adversarial loss: 0.532382\n",
      "epoch 46; iter: 0; batch classifier loss: 0.515424; batch adversarial loss: 0.534680\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440549; batch adversarial loss: 0.542631\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442095; batch adversarial loss: 0.528736\n",
      "epoch 49; iter: 0; batch classifier loss: 0.379108; batch adversarial loss: 0.529044\n",
      "epoch 50; iter: 0; batch classifier loss: 0.381078; batch adversarial loss: 0.508012\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445185; batch adversarial loss: 0.498682\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442460; batch adversarial loss: 0.534758\n",
      "epoch 53; iter: 0; batch classifier loss: 0.394473; batch adversarial loss: 0.586671\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451975; batch adversarial loss: 0.609449\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397966; batch adversarial loss: 0.524791\n",
      "epoch 56; iter: 0; batch classifier loss: 0.366639; batch adversarial loss: 0.615434\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456329; batch adversarial loss: 0.525843\n",
      "epoch 58; iter: 0; batch classifier loss: 0.370746; batch adversarial loss: 0.581280\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456450; batch adversarial loss: 0.581001\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416796; batch adversarial loss: 0.517879\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403699; batch adversarial loss: 0.590815\n",
      "epoch 62; iter: 0; batch classifier loss: 0.456357; batch adversarial loss: 0.572671\n",
      "epoch 63; iter: 0; batch classifier loss: 0.357644; batch adversarial loss: 0.543975\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440213; batch adversarial loss: 0.513490\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398760; batch adversarial loss: 0.552632\n",
      "epoch 66; iter: 0; batch classifier loss: 0.390896; batch adversarial loss: 0.490047\n",
      "epoch 67; iter: 0; batch classifier loss: 0.449011; batch adversarial loss: 0.587439\n",
      "epoch 68; iter: 0; batch classifier loss: 0.361823; batch adversarial loss: 0.588219\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435636; batch adversarial loss: 0.517582\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391941; batch adversarial loss: 0.559060\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373136; batch adversarial loss: 0.542424\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376816; batch adversarial loss: 0.490940\n",
      "epoch 73; iter: 0; batch classifier loss: 0.434190; batch adversarial loss: 0.555678\n",
      "epoch 74; iter: 0; batch classifier loss: 0.407452; batch adversarial loss: 0.519402\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402725; batch adversarial loss: 0.489303\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372897; batch adversarial loss: 0.624823\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391225; batch adversarial loss: 0.563568\n",
      "epoch 78; iter: 0; batch classifier loss: 0.488339; batch adversarial loss: 0.534941\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398397; batch adversarial loss: 0.483305\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419253; batch adversarial loss: 0.518995\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361038; batch adversarial loss: 0.526640\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418874; batch adversarial loss: 0.528389\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410667; batch adversarial loss: 0.581162\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370516; batch adversarial loss: 0.499073\n",
      "epoch 85; iter: 0; batch classifier loss: 0.388143; batch adversarial loss: 0.588847\n",
      "epoch 86; iter: 0; batch classifier loss: 0.349110; batch adversarial loss: 0.480485\n",
      "epoch 87; iter: 0; batch classifier loss: 0.421252; batch adversarial loss: 0.507131\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441870; batch adversarial loss: 0.508200\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385754; batch adversarial loss: 0.608679\n",
      "epoch 90; iter: 0; batch classifier loss: 0.342021; batch adversarial loss: 0.607537\n",
      "epoch 91; iter: 0; batch classifier loss: 0.368514; batch adversarial loss: 0.544204\n",
      "epoch 92; iter: 0; batch classifier loss: 0.293723; batch adversarial loss: 0.481028\n",
      "epoch 93; iter: 0; batch classifier loss: 0.426302; batch adversarial loss: 0.618416\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397189; batch adversarial loss: 0.508647\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413610; batch adversarial loss: 0.555737\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386077; batch adversarial loss: 0.490673\n",
      "epoch 97; iter: 0; batch classifier loss: 0.407108; batch adversarial loss: 0.545492\n",
      "epoch 98; iter: 0; batch classifier loss: 0.345507; batch adversarial loss: 0.581987\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365172; batch adversarial loss: 0.591051\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372836; batch adversarial loss: 0.544304\n",
      "epoch 101; iter: 0; batch classifier loss: 0.361008; batch adversarial loss: 0.517174\n",
      "epoch 102; iter: 0; batch classifier loss: 0.408682; batch adversarial loss: 0.545114\n",
      "epoch 103; iter: 0; batch classifier loss: 0.330085; batch adversarial loss: 0.564032\n",
      "epoch 104; iter: 0; batch classifier loss: 0.326567; batch adversarial loss: 0.508285\n",
      "epoch 105; iter: 0; batch classifier loss: 0.357212; batch adversarial loss: 0.515847\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389675; batch adversarial loss: 0.627328\n",
      "epoch 107; iter: 0; batch classifier loss: 0.401881; batch adversarial loss: 0.552224\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393399; batch adversarial loss: 0.536318\n",
      "epoch 109; iter: 0; batch classifier loss: 0.444670; batch adversarial loss: 0.543996\n",
      "epoch 110; iter: 0; batch classifier loss: 0.360793; batch adversarial loss: 0.607848\n",
      "epoch 111; iter: 0; batch classifier loss: 0.308465; batch adversarial loss: 0.525551\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386024; batch adversarial loss: 0.516381\n",
      "epoch 113; iter: 0; batch classifier loss: 0.282974; batch adversarial loss: 0.637185\n",
      "epoch 114; iter: 0; batch classifier loss: 0.316577; batch adversarial loss: 0.617035\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352145; batch adversarial loss: 0.526081\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347813; batch adversarial loss: 0.626721\n",
      "epoch 117; iter: 0; batch classifier loss: 0.323630; batch adversarial loss: 0.545489\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360622; batch adversarial loss: 0.590520\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385420; batch adversarial loss: 0.646863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.403884; batch adversarial loss: 0.453156\n",
      "epoch 121; iter: 0; batch classifier loss: 0.258150; batch adversarial loss: 0.591989\n",
      "epoch 122; iter: 0; batch classifier loss: 0.284615; batch adversarial loss: 0.481431\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378889; batch adversarial loss: 0.544588\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372582; batch adversarial loss: 0.500397\n",
      "epoch 125; iter: 0; batch classifier loss: 0.327308; batch adversarial loss: 0.498795\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402140; batch adversarial loss: 0.571566\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344592; batch adversarial loss: 0.489336\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377663; batch adversarial loss: 0.480648\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385706; batch adversarial loss: 0.582457\n",
      "epoch 130; iter: 0; batch classifier loss: 0.336729; batch adversarial loss: 0.544770\n",
      "epoch 131; iter: 0; batch classifier loss: 0.370551; batch adversarial loss: 0.571014\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381282; batch adversarial loss: 0.570267\n",
      "epoch 133; iter: 0; batch classifier loss: 0.292551; batch adversarial loss: 0.463191\n",
      "epoch 134; iter: 0; batch classifier loss: 0.359550; batch adversarial loss: 0.525456\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420597; batch adversarial loss: 0.571800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.314675; batch adversarial loss: 0.535655\n",
      "epoch 137; iter: 0; batch classifier loss: 0.421244; batch adversarial loss: 0.525959\n",
      "epoch 138; iter: 0; batch classifier loss: 0.314320; batch adversarial loss: 0.554232\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357418; batch adversarial loss: 0.543299\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365972; batch adversarial loss: 0.562287\n",
      "epoch 141; iter: 0; batch classifier loss: 0.302997; batch adversarial loss: 0.527111\n",
      "epoch 142; iter: 0; batch classifier loss: 0.312942; batch adversarial loss: 0.542923\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350420; batch adversarial loss: 0.573343\n",
      "epoch 144; iter: 0; batch classifier loss: 0.325992; batch adversarial loss: 0.518053\n",
      "epoch 145; iter: 0; batch classifier loss: 0.237272; batch adversarial loss: 0.488750\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329070; batch adversarial loss: 0.581267\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303696; batch adversarial loss: 0.562665\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360266; batch adversarial loss: 0.535896\n",
      "epoch 149; iter: 0; batch classifier loss: 0.299349; batch adversarial loss: 0.599494\n",
      "epoch 150; iter: 0; batch classifier loss: 0.416551; batch adversarial loss: 0.653311\n",
      "epoch 151; iter: 0; batch classifier loss: 0.311084; batch adversarial loss: 0.526880\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376458; batch adversarial loss: 0.561165\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385153; batch adversarial loss: 0.508544\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350837; batch adversarial loss: 0.535385\n",
      "epoch 155; iter: 0; batch classifier loss: 0.408918; batch adversarial loss: 0.516825\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377971; batch adversarial loss: 0.580847\n",
      "epoch 157; iter: 0; batch classifier loss: 0.415734; batch adversarial loss: 0.489723\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337191; batch adversarial loss: 0.534518\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342104; batch adversarial loss: 0.681905\n",
      "epoch 160; iter: 0; batch classifier loss: 0.259373; batch adversarial loss: 0.536005\n",
      "epoch 161; iter: 0; batch classifier loss: 0.322564; batch adversarial loss: 0.588104\n",
      "epoch 162; iter: 0; batch classifier loss: 0.337891; batch adversarial loss: 0.543923\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344968; batch adversarial loss: 0.535012\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336375; batch adversarial loss: 0.616993\n",
      "epoch 165; iter: 0; batch classifier loss: 0.305120; batch adversarial loss: 0.544172\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318177; batch adversarial loss: 0.545102\n",
      "epoch 167; iter: 0; batch classifier loss: 0.260242; batch adversarial loss: 0.543431\n",
      "epoch 168; iter: 0; batch classifier loss: 0.410116; batch adversarial loss: 0.572170\n",
      "epoch 169; iter: 0; batch classifier loss: 0.275516; batch adversarial loss: 0.543815\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319760; batch adversarial loss: 0.589514\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363236; batch adversarial loss: 0.463509\n",
      "epoch 172; iter: 0; batch classifier loss: 0.347726; batch adversarial loss: 0.582454\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330569; batch adversarial loss: 0.490520\n",
      "epoch 174; iter: 0; batch classifier loss: 0.313349; batch adversarial loss: 0.591950\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335337; batch adversarial loss: 0.598022\n",
      "epoch 176; iter: 0; batch classifier loss: 0.314978; batch adversarial loss: 0.499502\n",
      "epoch 177; iter: 0; batch classifier loss: 0.386030; batch adversarial loss: 0.590063\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363109; batch adversarial loss: 0.525868\n",
      "epoch 179; iter: 0; batch classifier loss: 0.444270; batch adversarial loss: 0.472644\n",
      "epoch 180; iter: 0; batch classifier loss: 0.274872; batch adversarial loss: 0.534918\n",
      "epoch 181; iter: 0; batch classifier loss: 0.348503; batch adversarial loss: 0.545404\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359430; batch adversarial loss: 0.571209\n",
      "epoch 183; iter: 0; batch classifier loss: 0.410647; batch adversarial loss: 0.509843\n",
      "epoch 184; iter: 0; batch classifier loss: 0.283247; batch adversarial loss: 0.571554\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321640; batch adversarial loss: 0.562487\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353643; batch adversarial loss: 0.652712\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365114; batch adversarial loss: 0.533977\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371698; batch adversarial loss: 0.536947\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377394; batch adversarial loss: 0.608964\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338466; batch adversarial loss: 0.535598\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336913; batch adversarial loss: 0.506110\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298480; batch adversarial loss: 0.589488\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364191; batch adversarial loss: 0.615913\n",
      "epoch 194; iter: 0; batch classifier loss: 0.329792; batch adversarial loss: 0.535067\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366743; batch adversarial loss: 0.507737\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373193; batch adversarial loss: 0.452860\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339460; batch adversarial loss: 0.534560\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340243; batch adversarial loss: 0.518124\n",
      "epoch 199; iter: 0; batch classifier loss: 0.287659; batch adversarial loss: 0.562233\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722907; batch adversarial loss: 0.612938\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604325; batch adversarial loss: 0.649334\n",
      "epoch 2; iter: 0; batch classifier loss: 0.550954; batch adversarial loss: 0.624992\n",
      "epoch 3; iter: 0; batch classifier loss: 0.545691; batch adversarial loss: 0.615498\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576932; batch adversarial loss: 0.645861\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521828; batch adversarial loss: 0.615820\n",
      "epoch 6; iter: 0; batch classifier loss: 0.604380; batch adversarial loss: 0.610003\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535323; batch adversarial loss: 0.617025\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531776; batch adversarial loss: 0.604265\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580259; batch adversarial loss: 0.560762\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521615; batch adversarial loss: 0.622477\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543805; batch adversarial loss: 0.504695\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548566; batch adversarial loss: 0.578362\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492090; batch adversarial loss: 0.551468\n",
      "epoch 14; iter: 0; batch classifier loss: 0.549276; batch adversarial loss: 0.551925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531213; batch adversarial loss: 0.523622\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490566; batch adversarial loss: 0.465079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.478046; batch adversarial loss: 0.513478\n",
      "epoch 18; iter: 0; batch classifier loss: 0.552780; batch adversarial loss: 0.608502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.539886; batch adversarial loss: 0.570858\n",
      "epoch 20; iter: 0; batch classifier loss: 0.600427; batch adversarial loss: 0.540661\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508557; batch adversarial loss: 0.523912\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489754; batch adversarial loss: 0.618874\n",
      "epoch 23; iter: 0; batch classifier loss: 0.510206; batch adversarial loss: 0.609726\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463010; batch adversarial loss: 0.552803\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483681; batch adversarial loss: 0.510073\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480669; batch adversarial loss: 0.459883\n",
      "epoch 27; iter: 0; batch classifier loss: 0.527394; batch adversarial loss: 0.558241\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434919; batch adversarial loss: 0.545305\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487953; batch adversarial loss: 0.602241\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504091; batch adversarial loss: 0.513650\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464146; batch adversarial loss: 0.546101\n",
      "epoch 32; iter: 0; batch classifier loss: 0.524965; batch adversarial loss: 0.511201\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460230; batch adversarial loss: 0.544734\n",
      "epoch 34; iter: 0; batch classifier loss: 0.510485; batch adversarial loss: 0.505412\n",
      "epoch 35; iter: 0; batch classifier loss: 0.415011; batch adversarial loss: 0.571546\n",
      "epoch 36; iter: 0; batch classifier loss: 0.542687; batch adversarial loss: 0.545965\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449961; batch adversarial loss: 0.557102\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434745; batch adversarial loss: 0.506211\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431212; batch adversarial loss: 0.563560\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418833; batch adversarial loss: 0.508233\n",
      "epoch 41; iter: 0; batch classifier loss: 0.500748; batch adversarial loss: 0.589367\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449699; batch adversarial loss: 0.597469\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412773; batch adversarial loss: 0.499133\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447484; batch adversarial loss: 0.489428\n",
      "epoch 45; iter: 0; batch classifier loss: 0.495320; batch adversarial loss: 0.600267\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460202; batch adversarial loss: 0.465766\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444273; batch adversarial loss: 0.474011\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417825; batch adversarial loss: 0.531009\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470764; batch adversarial loss: 0.561263\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443216; batch adversarial loss: 0.541936\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447017; batch adversarial loss: 0.526363\n",
      "epoch 52; iter: 0; batch classifier loss: 0.395461; batch adversarial loss: 0.526363\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418664; batch adversarial loss: 0.499470\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473487; batch adversarial loss: 0.546987\n",
      "epoch 55; iter: 0; batch classifier loss: 0.535624; batch adversarial loss: 0.536178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396430; batch adversarial loss: 0.489678\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396791; batch adversarial loss: 0.526905\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434081; batch adversarial loss: 0.544520\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415034; batch adversarial loss: 0.589833\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425804; batch adversarial loss: 0.580738\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422969; batch adversarial loss: 0.489449\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439020; batch adversarial loss: 0.626557\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386004; batch adversarial loss: 0.516742\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439589; batch adversarial loss: 0.562564\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383807; batch adversarial loss: 0.525321\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366288; batch adversarial loss: 0.507124\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414104; batch adversarial loss: 0.516016\n",
      "epoch 68; iter: 0; batch classifier loss: 0.480515; batch adversarial loss: 0.535196\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444836; batch adversarial loss: 0.571820\n",
      "epoch 70; iter: 0; batch classifier loss: 0.395997; batch adversarial loss: 0.600031\n",
      "epoch 71; iter: 0; batch classifier loss: 0.469023; batch adversarial loss: 0.517982\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397722; batch adversarial loss: 0.497439\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400376; batch adversarial loss: 0.516760\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364033; batch adversarial loss: 0.581118\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385773; batch adversarial loss: 0.562755\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411379; batch adversarial loss: 0.488612\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415355; batch adversarial loss: 0.602272\n",
      "epoch 78; iter: 0; batch classifier loss: 0.374479; batch adversarial loss: 0.591155\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362207; batch adversarial loss: 0.506484\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455160; batch adversarial loss: 0.551786\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429550; batch adversarial loss: 0.516917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414875; batch adversarial loss: 0.620413\n",
      "epoch 83; iter: 0; batch classifier loss: 0.474756; batch adversarial loss: 0.570186\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373061; batch adversarial loss: 0.563417\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381569; batch adversarial loss: 0.573049\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389387; batch adversarial loss: 0.506966\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404899; batch adversarial loss: 0.592988\n",
      "epoch 88; iter: 0; batch classifier loss: 0.485532; batch adversarial loss: 0.601466\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383960; batch adversarial loss: 0.495843\n",
      "epoch 90; iter: 0; batch classifier loss: 0.400140; batch adversarial loss: 0.516479\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363626; batch adversarial loss: 0.526471\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390768; batch adversarial loss: 0.543700\n",
      "epoch 93; iter: 0; batch classifier loss: 0.348065; batch adversarial loss: 0.544203\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383589; batch adversarial loss: 0.536852\n",
      "epoch 95; iter: 0; batch classifier loss: 0.488438; batch adversarial loss: 0.584652\n",
      "epoch 96; iter: 0; batch classifier loss: 0.442133; batch adversarial loss: 0.497979\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370910; batch adversarial loss: 0.537209\n",
      "epoch 98; iter: 0; batch classifier loss: 0.352314; batch adversarial loss: 0.536648\n",
      "epoch 99; iter: 0; batch classifier loss: 0.418770; batch adversarial loss: 0.459453\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423910; batch adversarial loss: 0.507691\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426912; batch adversarial loss: 0.470386\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409686; batch adversarial loss: 0.592308\n",
      "epoch 103; iter: 0; batch classifier loss: 0.363050; batch adversarial loss: 0.487810\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349013; batch adversarial loss: 0.544410\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411260; batch adversarial loss: 0.468939\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355315; batch adversarial loss: 0.572809\n",
      "epoch 107; iter: 0; batch classifier loss: 0.461775; batch adversarial loss: 0.620748\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380616; batch adversarial loss: 0.572994\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400116; batch adversarial loss: 0.525619\n",
      "epoch 110; iter: 0; batch classifier loss: 0.456144; batch adversarial loss: 0.506831\n",
      "epoch 111; iter: 0; batch classifier loss: 0.455590; batch adversarial loss: 0.525759\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409524; batch adversarial loss: 0.573307\n",
      "epoch 113; iter: 0; batch classifier loss: 0.312547; batch adversarial loss: 0.591140\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400721; batch adversarial loss: 0.441501\n",
      "epoch 115; iter: 0; batch classifier loss: 0.402080; batch adversarial loss: 0.637160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.344913; batch adversarial loss: 0.563315\n",
      "epoch 117; iter: 0; batch classifier loss: 0.344688; batch adversarial loss: 0.579665\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389052; batch adversarial loss: 0.497885\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366815; batch adversarial loss: 0.544735\n",
      "epoch 120; iter: 0; batch classifier loss: 0.489178; batch adversarial loss: 0.571834\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346318; batch adversarial loss: 0.600740\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399342; batch adversarial loss: 0.459856\n",
      "epoch 123; iter: 0; batch classifier loss: 0.330314; batch adversarial loss: 0.592014\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374975; batch adversarial loss: 0.544274\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395600; batch adversarial loss: 0.535328\n",
      "epoch 126; iter: 0; batch classifier loss: 0.348642; batch adversarial loss: 0.479527\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381811; batch adversarial loss: 0.544155\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403556; batch adversarial loss: 0.543420\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434252; batch adversarial loss: 0.532377\n",
      "epoch 130; iter: 0; batch classifier loss: 0.332100; batch adversarial loss: 0.488488\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384477; batch adversarial loss: 0.593663\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415905; batch adversarial loss: 0.506632\n",
      "epoch 133; iter: 0; batch classifier loss: 0.327723; batch adversarial loss: 0.497613\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387628; batch adversarial loss: 0.487645\n",
      "epoch 135; iter: 0; batch classifier loss: 0.409568; batch adversarial loss: 0.544355\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383613; batch adversarial loss: 0.544106\n",
      "epoch 137; iter: 0; batch classifier loss: 0.427310; batch adversarial loss: 0.468979\n",
      "epoch 138; iter: 0; batch classifier loss: 0.323980; batch adversarial loss: 0.563449\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388489; batch adversarial loss: 0.573413\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381910; batch adversarial loss: 0.563034\n",
      "epoch 141; iter: 0; batch classifier loss: 0.314233; batch adversarial loss: 0.460635\n",
      "epoch 142; iter: 0; batch classifier loss: 0.382680; batch adversarial loss: 0.591329\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396823; batch adversarial loss: 0.553339\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371019; batch adversarial loss: 0.535981\n",
      "epoch 145; iter: 0; batch classifier loss: 0.315016; batch adversarial loss: 0.525879\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373773; batch adversarial loss: 0.431366\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360958; batch adversarial loss: 0.479074\n",
      "epoch 148; iter: 0; batch classifier loss: 0.393661; batch adversarial loss: 0.554230\n",
      "epoch 149; iter: 0; batch classifier loss: 0.417097; batch adversarial loss: 0.497525\n",
      "epoch 150; iter: 0; batch classifier loss: 0.402857; batch adversarial loss: 0.572011\n",
      "epoch 151; iter: 0; batch classifier loss: 0.404277; batch adversarial loss: 0.553311\n",
      "epoch 152; iter: 0; batch classifier loss: 0.301263; batch adversarial loss: 0.545360\n",
      "epoch 153; iter: 0; batch classifier loss: 0.413504; batch adversarial loss: 0.544687\n",
      "epoch 154; iter: 0; batch classifier loss: 0.441741; batch adversarial loss: 0.544272\n",
      "epoch 155; iter: 0; batch classifier loss: 0.306799; batch adversarial loss: 0.478232\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337641; batch adversarial loss: 0.516529\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373093; batch adversarial loss: 0.535079\n",
      "epoch 158; iter: 0; batch classifier loss: 0.242901; batch adversarial loss: 0.517257\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347306; batch adversarial loss: 0.515088\n",
      "epoch 160; iter: 0; batch classifier loss: 0.504380; batch adversarial loss: 0.535007\n",
      "epoch 161; iter: 0; batch classifier loss: 0.421625; batch adversarial loss: 0.534674\n",
      "epoch 162; iter: 0; batch classifier loss: 0.296374; batch adversarial loss: 0.499434\n",
      "epoch 163; iter: 0; batch classifier loss: 0.378143; batch adversarial loss: 0.470722\n",
      "epoch 164; iter: 0; batch classifier loss: 0.443108; batch adversarial loss: 0.517062\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315230; batch adversarial loss: 0.582602\n",
      "epoch 166; iter: 0; batch classifier loss: 0.363444; batch adversarial loss: 0.515696\n",
      "epoch 167; iter: 0; batch classifier loss: 0.327125; batch adversarial loss: 0.524940\n",
      "epoch 168; iter: 0; batch classifier loss: 0.467154; batch adversarial loss: 0.440658\n",
      "epoch 169; iter: 0; batch classifier loss: 0.333019; batch adversarial loss: 0.543892\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352354; batch adversarial loss: 0.535662\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317538; batch adversarial loss: 0.516644\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351435; batch adversarial loss: 0.554514\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351694; batch adversarial loss: 0.553397\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336937; batch adversarial loss: 0.535488\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337578; batch adversarial loss: 0.572444\n",
      "epoch 176; iter: 0; batch classifier loss: 0.295608; batch adversarial loss: 0.534962\n",
      "epoch 177; iter: 0; batch classifier loss: 0.424436; batch adversarial loss: 0.553925\n",
      "epoch 178; iter: 0; batch classifier loss: 0.377023; batch adversarial loss: 0.507616\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323720; batch adversarial loss: 0.516438\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329628; batch adversarial loss: 0.563025\n",
      "epoch 181; iter: 0; batch classifier loss: 0.443200; batch adversarial loss: 0.564016\n",
      "epoch 182; iter: 0; batch classifier loss: 0.488174; batch adversarial loss: 0.498426\n",
      "epoch 183; iter: 0; batch classifier loss: 0.319974; batch adversarial loss: 0.609559\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380073; batch adversarial loss: 0.515662\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381592; batch adversarial loss: 0.460655\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371026; batch adversarial loss: 0.516318\n",
      "epoch 187; iter: 0; batch classifier loss: 0.288312; batch adversarial loss: 0.553871\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366929; batch adversarial loss: 0.479164\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368892; batch adversarial loss: 0.610500\n",
      "epoch 190; iter: 0; batch classifier loss: 0.421361; batch adversarial loss: 0.610623\n",
      "epoch 191; iter: 0; batch classifier loss: 0.329846; batch adversarial loss: 0.591759\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364087; batch adversarial loss: 0.600895\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370853; batch adversarial loss: 0.459757\n",
      "epoch 194; iter: 0; batch classifier loss: 0.425864; batch adversarial loss: 0.563343\n",
      "epoch 195; iter: 0; batch classifier loss: 0.372742; batch adversarial loss: 0.591888\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327867; batch adversarial loss: 0.497724\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321060; batch adversarial loss: 0.516404\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366942; batch adversarial loss: 0.487755\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365794; batch adversarial loss: 0.609456\n",
      "epoch 0; iter: 0; batch classifier loss: 0.745507; batch adversarial loss: 0.834410\n",
      "epoch 1; iter: 0; batch classifier loss: 0.761313; batch adversarial loss: 0.851471\n",
      "epoch 2; iter: 0; batch classifier loss: 0.924552; batch adversarial loss: 0.805050\n",
      "epoch 3; iter: 0; batch classifier loss: 0.951578; batch adversarial loss: 0.739169\n",
      "epoch 4; iter: 0; batch classifier loss: 0.834460; batch adversarial loss: 0.685423\n",
      "epoch 5; iter: 0; batch classifier loss: 0.807299; batch adversarial loss: 0.626178\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568050; batch adversarial loss: 0.597002\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542122; batch adversarial loss: 0.612484\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571085; batch adversarial loss: 0.573589\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616428; batch adversarial loss: 0.582500\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584599; batch adversarial loss: 0.549941\n",
      "epoch 11; iter: 0; batch classifier loss: 0.478365; batch adversarial loss: 0.612265\n",
      "epoch 12; iter: 0; batch classifier loss: 0.541134; batch adversarial loss: 0.595529\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491760; batch adversarial loss: 0.615112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.552907; batch adversarial loss: 0.547565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544587; batch adversarial loss: 0.522680\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523277; batch adversarial loss: 0.568771\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550062; batch adversarial loss: 0.555216\n",
      "epoch 18; iter: 0; batch classifier loss: 0.448017; batch adversarial loss: 0.596219\n",
      "epoch 19; iter: 0; batch classifier loss: 0.445333; batch adversarial loss: 0.544877\n",
      "epoch 20; iter: 0; batch classifier loss: 0.419539; batch adversarial loss: 0.540799\n",
      "epoch 21; iter: 0; batch classifier loss: 0.588147; batch adversarial loss: 0.611120\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489919; batch adversarial loss: 0.548718\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465570; batch adversarial loss: 0.510594\n",
      "epoch 24; iter: 0; batch classifier loss: 0.447783; batch adversarial loss: 0.534725\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501858; batch adversarial loss: 0.518003\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466573; batch adversarial loss: 0.571462\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453246; batch adversarial loss: 0.518644\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451671; batch adversarial loss: 0.538988\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496500; batch adversarial loss: 0.468848\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456258; batch adversarial loss: 0.579073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422417; batch adversarial loss: 0.582701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.509735; batch adversarial loss: 0.558785\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486135; batch adversarial loss: 0.493069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457379; batch adversarial loss: 0.547880\n",
      "epoch 35; iter: 0; batch classifier loss: 0.418982; batch adversarial loss: 0.575028\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438656; batch adversarial loss: 0.663630\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383754; batch adversarial loss: 0.578506\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432999; batch adversarial loss: 0.635854\n",
      "epoch 39; iter: 0; batch classifier loss: 0.362398; batch adversarial loss: 0.573998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.388839; batch adversarial loss: 0.507666\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426949; batch adversarial loss: 0.492344\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408531; batch adversarial loss: 0.601108\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424515; batch adversarial loss: 0.508044\n",
      "epoch 44; iter: 0; batch classifier loss: 0.432502; batch adversarial loss: 0.489426\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422047; batch adversarial loss: 0.562720\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438699; batch adversarial loss: 0.537655\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409091; batch adversarial loss: 0.470501\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443105; batch adversarial loss: 0.481961\n",
      "epoch 49; iter: 0; batch classifier loss: 0.469433; batch adversarial loss: 0.499487\n",
      "epoch 50; iter: 0; batch classifier loss: 0.454764; batch adversarial loss: 0.506267\n",
      "epoch 51; iter: 0; batch classifier loss: 0.368099; batch adversarial loss: 0.581072\n",
      "epoch 52; iter: 0; batch classifier loss: 0.377310; batch adversarial loss: 0.507421\n",
      "epoch 53; iter: 0; batch classifier loss: 0.337534; batch adversarial loss: 0.599876\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392724; batch adversarial loss: 0.581855\n",
      "epoch 55; iter: 0; batch classifier loss: 0.356035; batch adversarial loss: 0.572393\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456467; batch adversarial loss: 0.563070\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390136; batch adversarial loss: 0.498385\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413661; batch adversarial loss: 0.572142\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447268; batch adversarial loss: 0.498672\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398575; batch adversarial loss: 0.517120\n",
      "epoch 61; iter: 0; batch classifier loss: 0.343371; batch adversarial loss: 0.553473\n",
      "epoch 62; iter: 0; batch classifier loss: 0.352442; batch adversarial loss: 0.488480\n",
      "epoch 63; iter: 0; batch classifier loss: 0.375819; batch adversarial loss: 0.620052\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435949; batch adversarial loss: 0.553497\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415118; batch adversarial loss: 0.552599\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412764; batch adversarial loss: 0.469146\n",
      "epoch 67; iter: 0; batch classifier loss: 0.433731; batch adversarial loss: 0.581679\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399551; batch adversarial loss: 0.506435\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416938; batch adversarial loss: 0.581179\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368640; batch adversarial loss: 0.488444\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451890; batch adversarial loss: 0.507031\n",
      "epoch 72; iter: 0; batch classifier loss: 0.436891; batch adversarial loss: 0.516439\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383322; batch adversarial loss: 0.544687\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397580; batch adversarial loss: 0.525789\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397465; batch adversarial loss: 0.497765\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393296; batch adversarial loss: 0.516542\n",
      "epoch 77; iter: 0; batch classifier loss: 0.380657; batch adversarial loss: 0.544221\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439034; batch adversarial loss: 0.460296\n",
      "epoch 79; iter: 0; batch classifier loss: 0.336850; batch adversarial loss: 0.478256\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455560; batch adversarial loss: 0.450480\n",
      "epoch 81; iter: 0; batch classifier loss: 0.307102; batch adversarial loss: 0.459772\n",
      "epoch 82; iter: 0; batch classifier loss: 0.331801; batch adversarial loss: 0.497917\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364918; batch adversarial loss: 0.507315\n",
      "epoch 84; iter: 0; batch classifier loss: 0.352566; batch adversarial loss: 0.591343\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382824; batch adversarial loss: 0.498036\n",
      "epoch 86; iter: 0; batch classifier loss: 0.422691; batch adversarial loss: 0.488840\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393779; batch adversarial loss: 0.601307\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378204; batch adversarial loss: 0.524648\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396326; batch adversarial loss: 0.534874\n",
      "epoch 90; iter: 0; batch classifier loss: 0.346968; batch adversarial loss: 0.620312\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402385; batch adversarial loss: 0.516144\n",
      "epoch 92; iter: 0; batch classifier loss: 0.332748; batch adversarial loss: 0.572603\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377417; batch adversarial loss: 0.552983\n",
      "epoch 94; iter: 0; batch classifier loss: 0.343256; batch adversarial loss: 0.506227\n",
      "epoch 95; iter: 0; batch classifier loss: 0.301902; batch adversarial loss: 0.488575\n",
      "epoch 96; iter: 0; batch classifier loss: 0.359058; batch adversarial loss: 0.545121\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315424; batch adversarial loss: 0.544717\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384113; batch adversarial loss: 0.562193\n",
      "epoch 99; iter: 0; batch classifier loss: 0.307580; batch adversarial loss: 0.618814\n",
      "epoch 100; iter: 0; batch classifier loss: 0.466055; batch adversarial loss: 0.535725\n",
      "epoch 101; iter: 0; batch classifier loss: 0.312016; batch adversarial loss: 0.544884\n",
      "epoch 102; iter: 0; batch classifier loss: 0.296414; batch adversarial loss: 0.488976\n",
      "epoch 103; iter: 0; batch classifier loss: 0.342996; batch adversarial loss: 0.532195\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371457; batch adversarial loss: 0.564144\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415149; batch adversarial loss: 0.536318\n",
      "epoch 106; iter: 0; batch classifier loss: 0.351278; batch adversarial loss: 0.516001\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403506; batch adversarial loss: 0.551698\n",
      "epoch 108; iter: 0; batch classifier loss: 0.309347; batch adversarial loss: 0.564105\n",
      "epoch 109; iter: 0; batch classifier loss: 0.353222; batch adversarial loss: 0.554023\n",
      "epoch 110; iter: 0; batch classifier loss: 0.342884; batch adversarial loss: 0.544800\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374770; batch adversarial loss: 0.450443\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411356; batch adversarial loss: 0.583351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.292383; batch adversarial loss: 0.535442\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347658; batch adversarial loss: 0.545433\n",
      "epoch 115; iter: 0; batch classifier loss: 0.347730; batch adversarial loss: 0.543439\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366663; batch adversarial loss: 0.507499\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342630; batch adversarial loss: 0.544529\n",
      "epoch 118; iter: 0; batch classifier loss: 0.331605; batch adversarial loss: 0.524831\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387821; batch adversarial loss: 0.591797\n",
      "epoch 120; iter: 0; batch classifier loss: 0.342734; batch adversarial loss: 0.487348\n",
      "epoch 121; iter: 0; batch classifier loss: 0.363864; batch adversarial loss: 0.535392\n",
      "epoch 122; iter: 0; batch classifier loss: 0.283001; batch adversarial loss: 0.517450\n",
      "epoch 123; iter: 0; batch classifier loss: 0.401206; batch adversarial loss: 0.515711\n",
      "epoch 124; iter: 0; batch classifier loss: 0.285540; batch adversarial loss: 0.600202\n",
      "epoch 125; iter: 0; batch classifier loss: 0.285974; batch adversarial loss: 0.507614\n",
      "epoch 126; iter: 0; batch classifier loss: 0.313648; batch adversarial loss: 0.535110\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387310; batch adversarial loss: 0.478333\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385357; batch adversarial loss: 0.553949\n",
      "epoch 129; iter: 0; batch classifier loss: 0.287934; batch adversarial loss: 0.527427\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385880; batch adversarial loss: 0.565902\n",
      "epoch 131; iter: 0; batch classifier loss: 0.301592; batch adversarial loss: 0.600438\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317831; batch adversarial loss: 0.518223\n",
      "epoch 133; iter: 0; batch classifier loss: 0.275062; batch adversarial loss: 0.532653\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350281; batch adversarial loss: 0.573889\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385518; batch adversarial loss: 0.610285\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334128; batch adversarial loss: 0.544304\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379173; batch adversarial loss: 0.535737\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389225; batch adversarial loss: 0.583224\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344492; batch adversarial loss: 0.507014\n",
      "epoch 140; iter: 0; batch classifier loss: 0.336434; batch adversarial loss: 0.582192\n",
      "epoch 141; iter: 0; batch classifier loss: 0.394406; batch adversarial loss: 0.516749\n",
      "epoch 142; iter: 0; batch classifier loss: 0.306263; batch adversarial loss: 0.563232\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322926; batch adversarial loss: 0.581309\n",
      "epoch 144; iter: 0; batch classifier loss: 0.296351; batch adversarial loss: 0.506705\n",
      "epoch 145; iter: 0; batch classifier loss: 0.280628; batch adversarial loss: 0.535189\n",
      "epoch 146; iter: 0; batch classifier loss: 0.301056; batch adversarial loss: 0.601011\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326062; batch adversarial loss: 0.524324\n",
      "epoch 148; iter: 0; batch classifier loss: 0.290585; batch adversarial loss: 0.525822\n",
      "epoch 149; iter: 0; batch classifier loss: 0.308400; batch adversarial loss: 0.517041\n",
      "epoch 150; iter: 0; batch classifier loss: 0.319525; batch adversarial loss: 0.507471\n",
      "epoch 151; iter: 0; batch classifier loss: 0.442667; batch adversarial loss: 0.487813\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347521; batch adversarial loss: 0.563145\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355458; batch adversarial loss: 0.600861\n",
      "epoch 154; iter: 0; batch classifier loss: 0.391049; batch adversarial loss: 0.591856\n",
      "epoch 155; iter: 0; batch classifier loss: 0.443604; batch adversarial loss: 0.553473\n",
      "epoch 156; iter: 0; batch classifier loss: 0.311313; batch adversarial loss: 0.507149\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335181; batch adversarial loss: 0.479734\n",
      "epoch 158; iter: 0; batch classifier loss: 0.359743; batch adversarial loss: 0.488079\n",
      "epoch 159; iter: 0; batch classifier loss: 0.279270; batch adversarial loss: 0.544474\n",
      "epoch 160; iter: 0; batch classifier loss: 0.287738; batch adversarial loss: 0.545680\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350595; batch adversarial loss: 0.581441\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364036; batch adversarial loss: 0.505814\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345983; batch adversarial loss: 0.609578\n",
      "epoch 164; iter: 0; batch classifier loss: 0.332994; batch adversarial loss: 0.591724\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375563; batch adversarial loss: 0.543689\n",
      "epoch 166; iter: 0; batch classifier loss: 0.402925; batch adversarial loss: 0.525770\n",
      "epoch 167; iter: 0; batch classifier loss: 0.297959; batch adversarial loss: 0.582044\n",
      "epoch 168; iter: 0; batch classifier loss: 0.402331; batch adversarial loss: 0.536090\n",
      "epoch 169; iter: 0; batch classifier loss: 0.301409; batch adversarial loss: 0.468695\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342102; batch adversarial loss: 0.544366\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326372; batch adversarial loss: 0.593321\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377421; batch adversarial loss: 0.544996\n",
      "epoch 173; iter: 0; batch classifier loss: 0.299320; batch adversarial loss: 0.497905\n",
      "epoch 174; iter: 0; batch classifier loss: 0.312355; batch adversarial loss: 0.515925\n",
      "epoch 175; iter: 0; batch classifier loss: 0.259204; batch adversarial loss: 0.536156\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367552; batch adversarial loss: 0.506589\n",
      "epoch 177; iter: 0; batch classifier loss: 0.307113; batch adversarial loss: 0.573640\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331313; batch adversarial loss: 0.563394\n",
      "epoch 179; iter: 0; batch classifier loss: 0.288881; batch adversarial loss: 0.497211\n",
      "epoch 180; iter: 0; batch classifier loss: 0.364021; batch adversarial loss: 0.545939\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333963; batch adversarial loss: 0.629041\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329158; batch adversarial loss: 0.544253\n",
      "epoch 183; iter: 0; batch classifier loss: 0.368847; batch adversarial loss: 0.515997\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360310; batch adversarial loss: 0.554364\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389147; batch adversarial loss: 0.581080\n",
      "epoch 186; iter: 0; batch classifier loss: 0.259738; batch adversarial loss: 0.554429\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363118; batch adversarial loss: 0.486464\n",
      "epoch 188; iter: 0; batch classifier loss: 0.286013; batch adversarial loss: 0.591039\n",
      "epoch 189; iter: 0; batch classifier loss: 0.342528; batch adversarial loss: 0.535231\n",
      "epoch 190; iter: 0; batch classifier loss: 0.284534; batch adversarial loss: 0.535792\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323659; batch adversarial loss: 0.544667\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326765; batch adversarial loss: 0.590052\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343403; batch adversarial loss: 0.535119\n",
      "epoch 194; iter: 0; batch classifier loss: 0.283767; batch adversarial loss: 0.590718\n",
      "epoch 195; iter: 0; batch classifier loss: 0.429841; batch adversarial loss: 0.552552\n",
      "epoch 196; iter: 0; batch classifier loss: 0.290283; batch adversarial loss: 0.600121\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322613; batch adversarial loss: 0.620542\n",
      "epoch 198; iter: 0; batch classifier loss: 0.289089; batch adversarial loss: 0.600621\n",
      "epoch 199; iter: 0; batch classifier loss: 0.368387; batch adversarial loss: 0.479319\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738757; batch adversarial loss: 0.606678\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602403; batch adversarial loss: 0.637122\n",
      "epoch 2; iter: 0; batch classifier loss: 0.557858; batch adversarial loss: 0.625664\n",
      "epoch 3; iter: 0; batch classifier loss: 0.554832; batch adversarial loss: 0.599863\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547321; batch adversarial loss: 0.609616\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532823; batch adversarial loss: 0.628112\n",
      "epoch 6; iter: 0; batch classifier loss: 0.506704; batch adversarial loss: 0.588202\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527822; batch adversarial loss: 0.622682\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524888; batch adversarial loss: 0.619153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.590612; batch adversarial loss: 0.594206\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536181; batch adversarial loss: 0.636900\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582584; batch adversarial loss: 0.531478\n",
      "epoch 12; iter: 0; batch classifier loss: 0.583757; batch adversarial loss: 0.593828\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540441; batch adversarial loss: 0.520030\n",
      "epoch 14; iter: 0; batch classifier loss: 0.607020; batch adversarial loss: 0.601691\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519459; batch adversarial loss: 0.538316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442016; batch adversarial loss: 0.577268\n",
      "epoch 17; iter: 0; batch classifier loss: 0.563769; batch adversarial loss: 0.595987\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472716; batch adversarial loss: 0.559392\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482997; batch adversarial loss: 0.555730\n",
      "epoch 20; iter: 0; batch classifier loss: 0.541227; batch adversarial loss: 0.562949\n",
      "epoch 21; iter: 0; batch classifier loss: 0.582900; batch adversarial loss: 0.522004\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514391; batch adversarial loss: 0.642877\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463570; batch adversarial loss: 0.589073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465671; batch adversarial loss: 0.501340\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472358; batch adversarial loss: 0.545302\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464989; batch adversarial loss: 0.604234\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482653; batch adversarial loss: 0.599848\n",
      "epoch 28; iter: 0; batch classifier loss: 0.519012; batch adversarial loss: 0.544864\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428822; batch adversarial loss: 0.558288\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459231; batch adversarial loss: 0.469988\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499714; batch adversarial loss: 0.542558\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468009; batch adversarial loss: 0.559243\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432821; batch adversarial loss: 0.487708\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453736; batch adversarial loss: 0.591517\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429410; batch adversarial loss: 0.584486\n",
      "epoch 36; iter: 0; batch classifier loss: 0.491396; batch adversarial loss: 0.465820\n",
      "epoch 37; iter: 0; batch classifier loss: 0.419826; batch adversarial loss: 0.511926\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484314; batch adversarial loss: 0.573361\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479383; batch adversarial loss: 0.552806\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442431; batch adversarial loss: 0.481416\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382824; batch adversarial loss: 0.563653\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448748; batch adversarial loss: 0.617501\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460159; batch adversarial loss: 0.554369\n",
      "epoch 44; iter: 0; batch classifier loss: 0.452408; batch adversarial loss: 0.570784\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421520; batch adversarial loss: 0.525492\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432740; batch adversarial loss: 0.526775\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471656; batch adversarial loss: 0.569888\n",
      "epoch 48; iter: 0; batch classifier loss: 0.367212; batch adversarial loss: 0.499163\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438520; batch adversarial loss: 0.490002\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422808; batch adversarial loss: 0.553382\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444088; batch adversarial loss: 0.570850\n",
      "epoch 52; iter: 0; batch classifier loss: 0.364940; batch adversarial loss: 0.490057\n",
      "epoch 53; iter: 0; batch classifier loss: 0.482909; batch adversarial loss: 0.544051\n",
      "epoch 54; iter: 0; batch classifier loss: 0.370911; batch adversarial loss: 0.626624\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432647; batch adversarial loss: 0.528040\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416611; batch adversarial loss: 0.534996\n",
      "epoch 57; iter: 0; batch classifier loss: 0.444150; batch adversarial loss: 0.607217\n",
      "epoch 58; iter: 0; batch classifier loss: 0.480630; batch adversarial loss: 0.507921\n",
      "epoch 59; iter: 0; batch classifier loss: 0.448328; batch adversarial loss: 0.545928\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416621; batch adversarial loss: 0.490136\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454884; batch adversarial loss: 0.662330\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378450; batch adversarial loss: 0.489120\n",
      "epoch 63; iter: 0; batch classifier loss: 0.469906; batch adversarial loss: 0.552852\n",
      "epoch 64; iter: 0; batch classifier loss: 0.465657; batch adversarial loss: 0.534950\n",
      "epoch 65; iter: 0; batch classifier loss: 0.504877; batch adversarial loss: 0.564760\n",
      "epoch 66; iter: 0; batch classifier loss: 0.351302; batch adversarial loss: 0.598877\n",
      "epoch 67; iter: 0; batch classifier loss: 0.422641; batch adversarial loss: 0.580672\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408597; batch adversarial loss: 0.481113\n",
      "epoch 69; iter: 0; batch classifier loss: 0.322661; batch adversarial loss: 0.526446\n",
      "epoch 70; iter: 0; batch classifier loss: 0.365143; batch adversarial loss: 0.452910\n",
      "epoch 71; iter: 0; batch classifier loss: 0.360343; batch adversarial loss: 0.516931\n",
      "epoch 72; iter: 0; batch classifier loss: 0.347826; batch adversarial loss: 0.571611\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405718; batch adversarial loss: 0.579614\n",
      "epoch 74; iter: 0; batch classifier loss: 0.446394; batch adversarial loss: 0.544420\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438091; batch adversarial loss: 0.525071\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407118; batch adversarial loss: 0.507887\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378073; batch adversarial loss: 0.516947\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400444; batch adversarial loss: 0.571175\n",
      "epoch 79; iter: 0; batch classifier loss: 0.331974; batch adversarial loss: 0.515245\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395543; batch adversarial loss: 0.583394\n",
      "epoch 81; iter: 0; batch classifier loss: 0.379426; batch adversarial loss: 0.571777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.460291; batch adversarial loss: 0.517727\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391438; batch adversarial loss: 0.553796\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383620; batch adversarial loss: 0.599543\n",
      "epoch 85; iter: 0; batch classifier loss: 0.386026; batch adversarial loss: 0.561718\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446420; batch adversarial loss: 0.498148\n",
      "epoch 87; iter: 0; batch classifier loss: 0.389908; batch adversarial loss: 0.580732\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427464; batch adversarial loss: 0.480265\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369754; batch adversarial loss: 0.583482\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378702; batch adversarial loss: 0.590822\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402351; batch adversarial loss: 0.498243\n",
      "epoch 92; iter: 0; batch classifier loss: 0.331354; batch adversarial loss: 0.598714\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367527; batch adversarial loss: 0.480092\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370316; batch adversarial loss: 0.517179\n",
      "epoch 95; iter: 0; batch classifier loss: 0.373222; batch adversarial loss: 0.600465\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391731; batch adversarial loss: 0.526534\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436054; batch adversarial loss: 0.515995\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418789; batch adversarial loss: 0.589997\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410075; batch adversarial loss: 0.562409\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381011; batch adversarial loss: 0.552753\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397405; batch adversarial loss: 0.608022\n",
      "epoch 102; iter: 0; batch classifier loss: 0.430082; batch adversarial loss: 0.571964\n",
      "epoch 103; iter: 0; batch classifier loss: 0.370298; batch adversarial loss: 0.525753\n",
      "epoch 104; iter: 0; batch classifier loss: 0.300191; batch adversarial loss: 0.581850\n",
      "epoch 105; iter: 0; batch classifier loss: 0.433111; batch adversarial loss: 0.526071\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378135; batch adversarial loss: 0.535473\n",
      "epoch 107; iter: 0; batch classifier loss: 0.328154; batch adversarial loss: 0.588403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.370706; batch adversarial loss: 0.563426\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401560; batch adversarial loss: 0.609345\n",
      "epoch 110; iter: 0; batch classifier loss: 0.449091; batch adversarial loss: 0.471740\n",
      "epoch 111; iter: 0; batch classifier loss: 0.450608; batch adversarial loss: 0.554024\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372394; batch adversarial loss: 0.552615\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405511; batch adversarial loss: 0.516861\n",
      "epoch 114; iter: 0; batch classifier loss: 0.356409; batch adversarial loss: 0.580996\n",
      "epoch 115; iter: 0; batch classifier loss: 0.369296; batch adversarial loss: 0.417001\n",
      "epoch 116; iter: 0; batch classifier loss: 0.416174; batch adversarial loss: 0.517021\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367592; batch adversarial loss: 0.607619\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361392; batch adversarial loss: 0.616478\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371931; batch adversarial loss: 0.571851\n",
      "epoch 120; iter: 0; batch classifier loss: 0.405557; batch adversarial loss: 0.517023\n",
      "epoch 121; iter: 0; batch classifier loss: 0.409127; batch adversarial loss: 0.506658\n",
      "epoch 122; iter: 0; batch classifier loss: 0.411640; batch adversarial loss: 0.525397\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415619; batch adversarial loss: 0.508094\n",
      "epoch 124; iter: 0; batch classifier loss: 0.406212; batch adversarial loss: 0.562868\n",
      "epoch 125; iter: 0; batch classifier loss: 0.319811; batch adversarial loss: 0.553577\n",
      "epoch 126; iter: 0; batch classifier loss: 0.432203; batch adversarial loss: 0.561235\n",
      "epoch 127; iter: 0; batch classifier loss: 0.440761; batch adversarial loss: 0.572115\n",
      "epoch 128; iter: 0; batch classifier loss: 0.487986; batch adversarial loss: 0.589956\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365871; batch adversarial loss: 0.599659\n",
      "epoch 130; iter: 0; batch classifier loss: 0.369789; batch adversarial loss: 0.525746\n",
      "epoch 131; iter: 0; batch classifier loss: 0.319509; batch adversarial loss: 0.555467\n",
      "epoch 132; iter: 0; batch classifier loss: 0.387764; batch adversarial loss: 0.480508\n",
      "epoch 133; iter: 0; batch classifier loss: 0.381001; batch adversarial loss: 0.581644\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374418; batch adversarial loss: 0.590785\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424463; batch adversarial loss: 0.516873\n",
      "epoch 136; iter: 0; batch classifier loss: 0.297537; batch adversarial loss: 0.572714\n",
      "epoch 137; iter: 0; batch classifier loss: 0.414242; batch adversarial loss: 0.526162\n",
      "epoch 138; iter: 0; batch classifier loss: 0.269155; batch adversarial loss: 0.590936\n",
      "epoch 139; iter: 0; batch classifier loss: 0.430967; batch adversarial loss: 0.535731\n",
      "epoch 140; iter: 0; batch classifier loss: 0.313502; batch adversarial loss: 0.589921\n",
      "epoch 141; iter: 0; batch classifier loss: 0.373425; batch adversarial loss: 0.517138\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393996; batch adversarial loss: 0.517153\n",
      "epoch 143; iter: 0; batch classifier loss: 0.317992; batch adversarial loss: 0.535440\n",
      "epoch 144; iter: 0; batch classifier loss: 0.375762; batch adversarial loss: 0.589440\n",
      "epoch 145; iter: 0; batch classifier loss: 0.446761; batch adversarial loss: 0.597944\n",
      "epoch 146; iter: 0; batch classifier loss: 0.403752; batch adversarial loss: 0.489401\n",
      "epoch 147; iter: 0; batch classifier loss: 0.314702; batch adversarial loss: 0.597635\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360063; batch adversarial loss: 0.481110\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376491; batch adversarial loss: 0.537232\n",
      "epoch 150; iter: 0; batch classifier loss: 0.432526; batch adversarial loss: 0.517021\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357840; batch adversarial loss: 0.545380\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405202; batch adversarial loss: 0.525734\n",
      "epoch 153; iter: 0; batch classifier loss: 0.310929; batch adversarial loss: 0.543309\n",
      "epoch 154; iter: 0; batch classifier loss: 0.336727; batch adversarial loss: 0.582564\n",
      "epoch 155; iter: 0; batch classifier loss: 0.296741; batch adversarial loss: 0.562917\n",
      "epoch 156; iter: 0; batch classifier loss: 0.309653; batch adversarial loss: 0.635727\n",
      "epoch 157; iter: 0; batch classifier loss: 0.300199; batch adversarial loss: 0.544187\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356302; batch adversarial loss: 0.472174\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325917; batch adversarial loss: 0.553361\n",
      "epoch 160; iter: 0; batch classifier loss: 0.395093; batch adversarial loss: 0.544356\n",
      "epoch 161; iter: 0; batch classifier loss: 0.455429; batch adversarial loss: 0.663611\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334114; batch adversarial loss: 0.581725\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374711; batch adversarial loss: 0.590515\n",
      "epoch 164; iter: 0; batch classifier loss: 0.323171; batch adversarial loss: 0.536190\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388942; batch adversarial loss: 0.545274\n",
      "epoch 166; iter: 0; batch classifier loss: 0.410803; batch adversarial loss: 0.518229\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366622; batch adversarial loss: 0.508978\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370589; batch adversarial loss: 0.516596\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312841; batch adversarial loss: 0.526401\n",
      "epoch 170; iter: 0; batch classifier loss: 0.399840; batch adversarial loss: 0.497832\n",
      "epoch 171; iter: 0; batch classifier loss: 0.432994; batch adversarial loss: 0.491032\n",
      "epoch 172; iter: 0; batch classifier loss: 0.315900; batch adversarial loss: 0.582017\n",
      "epoch 173; iter: 0; batch classifier loss: 0.298885; batch adversarial loss: 0.581103\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356639; batch adversarial loss: 0.525668\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390188; batch adversarial loss: 0.553413\n",
      "epoch 176; iter: 0; batch classifier loss: 0.321848; batch adversarial loss: 0.563172\n",
      "epoch 177; iter: 0; batch classifier loss: 0.390675; batch adversarial loss: 0.607979\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362132; batch adversarial loss: 0.562788\n",
      "epoch 179; iter: 0; batch classifier loss: 0.382266; batch adversarial loss: 0.527044\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354064; batch adversarial loss: 0.462123\n",
      "epoch 181; iter: 0; batch classifier loss: 0.399055; batch adversarial loss: 0.499493\n",
      "epoch 182; iter: 0; batch classifier loss: 0.409538; batch adversarial loss: 0.535100\n",
      "epoch 183; iter: 0; batch classifier loss: 0.430583; batch adversarial loss: 0.608854\n",
      "epoch 184; iter: 0; batch classifier loss: 0.402937; batch adversarial loss: 0.609951\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355781; batch adversarial loss: 0.590210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383974; batch adversarial loss: 0.516212\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310834; batch adversarial loss: 0.572144\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336404; batch adversarial loss: 0.507791\n",
      "epoch 189; iter: 0; batch classifier loss: 0.294832; batch adversarial loss: 0.553844\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365510; batch adversarial loss: 0.571856\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347208; batch adversarial loss: 0.553939\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381303; batch adversarial loss: 0.590717\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336473; batch adversarial loss: 0.462109\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360704; batch adversarial loss: 0.617893\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393374; batch adversarial loss: 0.553319\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323450; batch adversarial loss: 0.581224\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375979; batch adversarial loss: 0.535612\n",
      "epoch 198; iter: 0; batch classifier loss: 0.429863; batch adversarial loss: 0.507757\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385114; batch adversarial loss: 0.544928\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709653; batch adversarial loss: 0.844646\n",
      "epoch 1; iter: 0; batch classifier loss: 0.711586; batch adversarial loss: 0.999228\n",
      "epoch 2; iter: 0; batch classifier loss: 0.811701; batch adversarial loss: 0.917080\n",
      "epoch 3; iter: 0; batch classifier loss: 0.699094; batch adversarial loss: 0.857115\n",
      "epoch 4; iter: 0; batch classifier loss: 0.690296; batch adversarial loss: 0.778408\n",
      "epoch 5; iter: 0; batch classifier loss: 0.684101; batch adversarial loss: 0.693551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.547127; batch adversarial loss: 0.649633\n",
      "epoch 7; iter: 0; batch classifier loss: 0.619041; batch adversarial loss: 0.634371\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490557; batch adversarial loss: 0.611173\n",
      "epoch 9; iter: 0; batch classifier loss: 0.617924; batch adversarial loss: 0.576101\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537379; batch adversarial loss: 0.614113\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562140; batch adversarial loss: 0.562642\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539562; batch adversarial loss: 0.545811\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535931; batch adversarial loss: 0.613559\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479090; batch adversarial loss: 0.589588\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524682; batch adversarial loss: 0.575970\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499405; batch adversarial loss: 0.587948\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530981; batch adversarial loss: 0.581346\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520521; batch adversarial loss: 0.582259\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502248; batch adversarial loss: 0.568198\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487654; batch adversarial loss: 0.619137\n",
      "epoch 21; iter: 0; batch classifier loss: 0.432511; batch adversarial loss: 0.515177\n",
      "epoch 22; iter: 0; batch classifier loss: 0.536142; batch adversarial loss: 0.573161\n",
      "epoch 23; iter: 0; batch classifier loss: 0.442131; batch adversarial loss: 0.585273\n",
      "epoch 24; iter: 0; batch classifier loss: 0.380484; batch adversarial loss: 0.541485\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484239; batch adversarial loss: 0.562103\n",
      "epoch 26; iter: 0; batch classifier loss: 0.602009; batch adversarial loss: 0.535687\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490382; batch adversarial loss: 0.566791\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407257; batch adversarial loss: 0.556699\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425426; batch adversarial loss: 0.542529\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421109; batch adversarial loss: 0.520455\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471516; batch adversarial loss: 0.491030\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403507; batch adversarial loss: 0.503608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.511189; batch adversarial loss: 0.607520\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478444; batch adversarial loss: 0.497939\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420978; batch adversarial loss: 0.590759\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474449; batch adversarial loss: 0.528111\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439147; batch adversarial loss: 0.582506\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432773; batch adversarial loss: 0.512146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447262; batch adversarial loss: 0.552730\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493637; batch adversarial loss: 0.482551\n",
      "epoch 41; iter: 0; batch classifier loss: 0.352800; batch adversarial loss: 0.508942\n",
      "epoch 42; iter: 0; batch classifier loss: 0.373139; batch adversarial loss: 0.491041\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464204; batch adversarial loss: 0.518449\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395778; batch adversarial loss: 0.581854\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403396; batch adversarial loss: 0.501169\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436107; batch adversarial loss: 0.552492\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449989; batch adversarial loss: 0.556995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451274; batch adversarial loss: 0.489521\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417620; batch adversarial loss: 0.505609\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430346; batch adversarial loss: 0.563054\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379682; batch adversarial loss: 0.496987\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383957; batch adversarial loss: 0.573332\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427762; batch adversarial loss: 0.507143\n",
      "epoch 54; iter: 0; batch classifier loss: 0.388838; batch adversarial loss: 0.543865\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389778; batch adversarial loss: 0.516377\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414474; batch adversarial loss: 0.516370\n",
      "epoch 57; iter: 0; batch classifier loss: 0.388995; batch adversarial loss: 0.545152\n",
      "epoch 58; iter: 0; batch classifier loss: 0.517313; batch adversarial loss: 0.488744\n",
      "epoch 59; iter: 0; batch classifier loss: 0.313249; batch adversarial loss: 0.554784\n",
      "epoch 60; iter: 0; batch classifier loss: 0.454582; batch adversarial loss: 0.639021\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439369; batch adversarial loss: 0.515887\n",
      "epoch 62; iter: 0; batch classifier loss: 0.466268; batch adversarial loss: 0.478554\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397278; batch adversarial loss: 0.526551\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380941; batch adversarial loss: 0.638693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421909; batch adversarial loss: 0.572500\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366741; batch adversarial loss: 0.554226\n",
      "epoch 67; iter: 0; batch classifier loss: 0.315547; batch adversarial loss: 0.601339\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382283; batch adversarial loss: 0.639437\n",
      "epoch 69; iter: 0; batch classifier loss: 0.494614; batch adversarial loss: 0.535141\n",
      "epoch 70; iter: 0; batch classifier loss: 0.527235; batch adversarial loss: 0.601718\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349782; batch adversarial loss: 0.553705\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414416; batch adversarial loss: 0.582761\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415155; batch adversarial loss: 0.572568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.403506; batch adversarial loss: 0.535275\n",
      "epoch 75; iter: 0; batch classifier loss: 0.406284; batch adversarial loss: 0.497442\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424858; batch adversarial loss: 0.601576\n",
      "epoch 77; iter: 0; batch classifier loss: 0.368054; batch adversarial loss: 0.610929\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424577; batch adversarial loss: 0.611561\n",
      "epoch 79; iter: 0; batch classifier loss: 0.335108; batch adversarial loss: 0.544445\n",
      "epoch 80; iter: 0; batch classifier loss: 0.344070; batch adversarial loss: 0.477783\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395510; batch adversarial loss: 0.554311\n",
      "epoch 82; iter: 0; batch classifier loss: 0.440277; batch adversarial loss: 0.573589\n",
      "epoch 83; iter: 0; batch classifier loss: 0.389811; batch adversarial loss: 0.553838\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415107; batch adversarial loss: 0.488195\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370891; batch adversarial loss: 0.553906\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353762; batch adversarial loss: 0.554566\n",
      "epoch 87; iter: 0; batch classifier loss: 0.332400; batch adversarial loss: 0.573295\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416370; batch adversarial loss: 0.497088\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407768; batch adversarial loss: 0.516052\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399955; batch adversarial loss: 0.468724\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386309; batch adversarial loss: 0.478948\n",
      "epoch 92; iter: 0; batch classifier loss: 0.505492; batch adversarial loss: 0.469219\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383895; batch adversarial loss: 0.525692\n",
      "epoch 94; iter: 0; batch classifier loss: 0.409517; batch adversarial loss: 0.629482\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399934; batch adversarial loss: 0.516376\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372092; batch adversarial loss: 0.629808\n",
      "epoch 97; iter: 0; batch classifier loss: 0.421695; batch adversarial loss: 0.516063\n",
      "epoch 98; iter: 0; batch classifier loss: 0.290881; batch adversarial loss: 0.621051\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364297; batch adversarial loss: 0.582926\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368894; batch adversarial loss: 0.534973\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382414; batch adversarial loss: 0.535207\n",
      "epoch 102; iter: 0; batch classifier loss: 0.447444; batch adversarial loss: 0.525523\n",
      "epoch 103; iter: 0; batch classifier loss: 0.466460; batch adversarial loss: 0.525485\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369027; batch adversarial loss: 0.591926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.329152; batch adversarial loss: 0.497042\n",
      "epoch 106; iter: 0; batch classifier loss: 0.360885; batch adversarial loss: 0.544474\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374311; batch adversarial loss: 0.497104\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364002; batch adversarial loss: 0.620896\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413625; batch adversarial loss: 0.515925\n",
      "epoch 110; iter: 0; batch classifier loss: 0.399721; batch adversarial loss: 0.535308\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403374; batch adversarial loss: 0.592020\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378190; batch adversarial loss: 0.544672\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340815; batch adversarial loss: 0.459571\n",
      "epoch 114; iter: 0; batch classifier loss: 0.417779; batch adversarial loss: 0.487566\n",
      "epoch 115; iter: 0; batch classifier loss: 0.403265; batch adversarial loss: 0.535378\n",
      "epoch 116; iter: 0; batch classifier loss: 0.279645; batch adversarial loss: 0.582684\n",
      "epoch 117; iter: 0; batch classifier loss: 0.321390; batch adversarial loss: 0.478380\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382523; batch adversarial loss: 0.629856\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369650; batch adversarial loss: 0.563497\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371774; batch adversarial loss: 0.525616\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347465; batch adversarial loss: 0.534944\n",
      "epoch 122; iter: 0; batch classifier loss: 0.338090; batch adversarial loss: 0.563613\n",
      "epoch 123; iter: 0; batch classifier loss: 0.439366; batch adversarial loss: 0.544548\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361685; batch adversarial loss: 0.544651\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353661; batch adversarial loss: 0.592133\n",
      "epoch 126; iter: 0; batch classifier loss: 0.327888; batch adversarial loss: 0.630078\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372708; batch adversarial loss: 0.525638\n",
      "epoch 128; iter: 0; batch classifier loss: 0.278109; batch adversarial loss: 0.516292\n",
      "epoch 129; iter: 0; batch classifier loss: 0.321786; batch adversarial loss: 0.449726\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339358; batch adversarial loss: 0.648916\n",
      "epoch 131; iter: 0; batch classifier loss: 0.446718; batch adversarial loss: 0.544638\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371432; batch adversarial loss: 0.544755\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398554; batch adversarial loss: 0.620171\n",
      "epoch 134; iter: 0; batch classifier loss: 0.346679; batch adversarial loss: 0.544809\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334386; batch adversarial loss: 0.554009\n",
      "epoch 136; iter: 0; batch classifier loss: 0.319246; batch adversarial loss: 0.573159\n",
      "epoch 137; iter: 0; batch classifier loss: 0.438707; batch adversarial loss: 0.487393\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404499; batch adversarial loss: 0.468401\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369744; batch adversarial loss: 0.545046\n",
      "epoch 140; iter: 0; batch classifier loss: 0.286291; batch adversarial loss: 0.592508\n",
      "epoch 141; iter: 0; batch classifier loss: 0.330781; batch adversarial loss: 0.439692\n",
      "epoch 142; iter: 0; batch classifier loss: 0.438451; batch adversarial loss: 0.430931\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337846; batch adversarial loss: 0.573733\n",
      "epoch 144; iter: 0; batch classifier loss: 0.313508; batch adversarial loss: 0.506685\n",
      "epoch 145; iter: 0; batch classifier loss: 0.368926; batch adversarial loss: 0.535022\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329876; batch adversarial loss: 0.525132\n",
      "epoch 147; iter: 0; batch classifier loss: 0.304514; batch adversarial loss: 0.468746\n",
      "epoch 148; iter: 0; batch classifier loss: 0.311442; batch adversarial loss: 0.535234\n",
      "epoch 149; iter: 0; batch classifier loss: 0.389513; batch adversarial loss: 0.553752\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349885; batch adversarial loss: 0.516270\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325975; batch adversarial loss: 0.488273\n",
      "epoch 152; iter: 0; batch classifier loss: 0.408311; batch adversarial loss: 0.497340\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329279; batch adversarial loss: 0.469139\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345741; batch adversarial loss: 0.506681\n",
      "epoch 155; iter: 0; batch classifier loss: 0.300116; batch adversarial loss: 0.525228\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370983; batch adversarial loss: 0.638907\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366920; batch adversarial loss: 0.516031\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367253; batch adversarial loss: 0.477981\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348536; batch adversarial loss: 0.525605\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300118; batch adversarial loss: 0.554175\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376483; batch adversarial loss: 0.554253\n",
      "epoch 162; iter: 0; batch classifier loss: 0.323196; batch adversarial loss: 0.582386\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356793; batch adversarial loss: 0.572555\n",
      "epoch 164; iter: 0; batch classifier loss: 0.313247; batch adversarial loss: 0.516722\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369495; batch adversarial loss: 0.610994\n",
      "epoch 166; iter: 0; batch classifier loss: 0.326506; batch adversarial loss: 0.620284\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370242; batch adversarial loss: 0.469218\n",
      "epoch 168; iter: 0; batch classifier loss: 0.277925; batch adversarial loss: 0.544405\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327412; batch adversarial loss: 0.544643\n",
      "epoch 170; iter: 0; batch classifier loss: 0.299506; batch adversarial loss: 0.506680\n",
      "epoch 171; iter: 0; batch classifier loss: 0.500509; batch adversarial loss: 0.545202\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372348; batch adversarial loss: 0.554226\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316318; batch adversarial loss: 0.545173\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363103; batch adversarial loss: 0.582691\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330572; batch adversarial loss: 0.583077\n",
      "epoch 176; iter: 0; batch classifier loss: 0.385530; batch adversarial loss: 0.554078\n",
      "epoch 177; iter: 0; batch classifier loss: 0.333408; batch adversarial loss: 0.628948\n",
      "epoch 178; iter: 0; batch classifier loss: 0.312215; batch adversarial loss: 0.468956\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372876; batch adversarial loss: 0.544243\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322796; batch adversarial loss: 0.536064\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345837; batch adversarial loss: 0.525466\n",
      "epoch 182; iter: 0; batch classifier loss: 0.283912; batch adversarial loss: 0.610391\n",
      "epoch 183; iter: 0; batch classifier loss: 0.430854; batch adversarial loss: 0.497660\n",
      "epoch 184; iter: 0; batch classifier loss: 0.297647; batch adversarial loss: 0.573014\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393031; batch adversarial loss: 0.505893\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331540; batch adversarial loss: 0.525226\n",
      "epoch 187; iter: 0; batch classifier loss: 0.267696; batch adversarial loss: 0.477357\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345915; batch adversarial loss: 0.592483\n",
      "epoch 189; iter: 0; batch classifier loss: 0.249492; batch adversarial loss: 0.563640\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309929; batch adversarial loss: 0.506253\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357658; batch adversarial loss: 0.468619\n",
      "epoch 192; iter: 0; batch classifier loss: 0.416226; batch adversarial loss: 0.554918\n",
      "epoch 193; iter: 0; batch classifier loss: 0.260596; batch adversarial loss: 0.629933\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396394; batch adversarial loss: 0.535603\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341112; batch adversarial loss: 0.516703\n",
      "epoch 196; iter: 0; batch classifier loss: 0.398785; batch adversarial loss: 0.572248\n",
      "epoch 197; iter: 0; batch classifier loss: 0.270814; batch adversarial loss: 0.582250\n",
      "epoch 198; iter: 0; batch classifier loss: 0.320993; batch adversarial loss: 0.593354\n",
      "epoch 199; iter: 0; batch classifier loss: 0.311046; batch adversarial loss: 0.676459\n",
      "epoch 0; iter: 0; batch classifier loss: 0.752853; batch adversarial loss: 0.565781\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670458; batch adversarial loss: 0.602334\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551978; batch adversarial loss: 0.609271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.605053; batch adversarial loss: 0.624335\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571037; batch adversarial loss: 0.619257\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555067; batch adversarial loss: 0.669655\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592063; batch adversarial loss: 0.599027\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564886; batch adversarial loss: 0.620406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.626902; batch adversarial loss: 0.606529\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544572; batch adversarial loss: 0.547654\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546166; batch adversarial loss: 0.550890\n",
      "epoch 11; iter: 0; batch classifier loss: 0.578688; batch adversarial loss: 0.579044\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582978; batch adversarial loss: 0.532045\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513694; batch adversarial loss: 0.576611\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507537; batch adversarial loss: 0.622910\n",
      "epoch 15; iter: 0; batch classifier loss: 0.567428; batch adversarial loss: 0.541478\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501434; batch adversarial loss: 0.526513\n",
      "epoch 17; iter: 0; batch classifier loss: 0.476820; batch adversarial loss: 0.546903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488687; batch adversarial loss: 0.679204\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470014; batch adversarial loss: 0.550794\n",
      "epoch 20; iter: 0; batch classifier loss: 0.400918; batch adversarial loss: 0.548649\n",
      "epoch 21; iter: 0; batch classifier loss: 0.401925; batch adversarial loss: 0.554984\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468124; batch adversarial loss: 0.526923\n",
      "epoch 23; iter: 0; batch classifier loss: 0.409562; batch adversarial loss: 0.524482\n",
      "epoch 24; iter: 0; batch classifier loss: 0.472601; batch adversarial loss: 0.469024\n",
      "epoch 25; iter: 0; batch classifier loss: 0.412560; batch adversarial loss: 0.517893\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451156; batch adversarial loss: 0.573909\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517651; batch adversarial loss: 0.596363\n",
      "epoch 28; iter: 0; batch classifier loss: 0.423362; batch adversarial loss: 0.456507\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440190; batch adversarial loss: 0.581303\n",
      "epoch 30; iter: 0; batch classifier loss: 0.500418; batch adversarial loss: 0.499975\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445651; batch adversarial loss: 0.626003\n",
      "epoch 32; iter: 0; batch classifier loss: 0.416937; batch adversarial loss: 0.516187\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434260; batch adversarial loss: 0.489358\n",
      "epoch 34; iter: 0; batch classifier loss: 0.528930; batch adversarial loss: 0.535895\n",
      "epoch 35; iter: 0; batch classifier loss: 0.365610; batch adversarial loss: 0.593071\n",
      "epoch 36; iter: 0; batch classifier loss: 0.378622; batch adversarial loss: 0.506293\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466934; batch adversarial loss: 0.535232\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480188; batch adversarial loss: 0.497123\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439160; batch adversarial loss: 0.488979\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477311; batch adversarial loss: 0.581276\n",
      "epoch 41; iter: 0; batch classifier loss: 0.330120; batch adversarial loss: 0.563053\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450344; batch adversarial loss: 0.507869\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407643; batch adversarial loss: 0.600574\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481755; batch adversarial loss: 0.525986\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432457; batch adversarial loss: 0.497385\n",
      "epoch 46; iter: 0; batch classifier loss: 0.497128; batch adversarial loss: 0.459338\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409998; batch adversarial loss: 0.478371\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370378; batch adversarial loss: 0.573354\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433973; batch adversarial loss: 0.516354\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424929; batch adversarial loss: 0.563723\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390962; batch adversarial loss: 0.516671\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421352; batch adversarial loss: 0.468139\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445710; batch adversarial loss: 0.487698\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430024; batch adversarial loss: 0.563372\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416591; batch adversarial loss: 0.497244\n",
      "epoch 56; iter: 0; batch classifier loss: 0.349603; batch adversarial loss: 0.506447\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389272; batch adversarial loss: 0.545206\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452743; batch adversarial loss: 0.554187\n",
      "epoch 59; iter: 0; batch classifier loss: 0.389677; batch adversarial loss: 0.486782\n",
      "epoch 60; iter: 0; batch classifier loss: 0.472058; batch adversarial loss: 0.525563\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427371; batch adversarial loss: 0.534960\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423620; batch adversarial loss: 0.506614\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409255; batch adversarial loss: 0.478228\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411452; batch adversarial loss: 0.525687\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432631; batch adversarial loss: 0.496695\n",
      "epoch 66; iter: 0; batch classifier loss: 0.453410; batch adversarial loss: 0.592166\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411558; batch adversarial loss: 0.516439\n",
      "epoch 68; iter: 0; batch classifier loss: 0.361933; batch adversarial loss: 0.535205\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407078; batch adversarial loss: 0.516440\n",
      "epoch 70; iter: 0; batch classifier loss: 0.349620; batch adversarial loss: 0.467927\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410362; batch adversarial loss: 0.506867\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433098; batch adversarial loss: 0.458282\n",
      "epoch 73; iter: 0; batch classifier loss: 0.435170; batch adversarial loss: 0.487620\n",
      "epoch 74; iter: 0; batch classifier loss: 0.320257; batch adversarial loss: 0.525579\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403477; batch adversarial loss: 0.582844\n",
      "epoch 76; iter: 0; batch classifier loss: 0.330897; batch adversarial loss: 0.554310\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394681; batch adversarial loss: 0.514817\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351457; batch adversarial loss: 0.486238\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417643; batch adversarial loss: 0.515297\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429832; batch adversarial loss: 0.544233\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417874; batch adversarial loss: 0.478263\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447691; batch adversarial loss: 0.526151\n",
      "epoch 83; iter: 0; batch classifier loss: 0.438499; batch adversarial loss: 0.515281\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405983; batch adversarial loss: 0.534275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383455; batch adversarial loss: 0.535306\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360658; batch adversarial loss: 0.526010\n",
      "epoch 87; iter: 0; batch classifier loss: 0.446769; batch adversarial loss: 0.496977\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391763; batch adversarial loss: 0.592959\n",
      "epoch 89; iter: 0; batch classifier loss: 0.517745; batch adversarial loss: 0.581840\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351010; batch adversarial loss: 0.449147\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413057; batch adversarial loss: 0.574535\n",
      "epoch 92; iter: 0; batch classifier loss: 0.429700; batch adversarial loss: 0.573022\n",
      "epoch 93; iter: 0; batch classifier loss: 0.419124; batch adversarial loss: 0.573205\n",
      "epoch 94; iter: 0; batch classifier loss: 0.366277; batch adversarial loss: 0.506616\n",
      "epoch 95; iter: 0; batch classifier loss: 0.294169; batch adversarial loss: 0.496002\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400030; batch adversarial loss: 0.553276\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405253; batch adversarial loss: 0.620122\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386268; batch adversarial loss: 0.544231\n",
      "epoch 99; iter: 0; batch classifier loss: 0.459723; batch adversarial loss: 0.563799\n",
      "epoch 100; iter: 0; batch classifier loss: 0.395025; batch adversarial loss: 0.497116\n",
      "epoch 101; iter: 0; batch classifier loss: 0.350640; batch adversarial loss: 0.515827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.324376; batch adversarial loss: 0.572750\n",
      "epoch 103; iter: 0; batch classifier loss: 0.454360; batch adversarial loss: 0.515480\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399434; batch adversarial loss: 0.592393\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337138; batch adversarial loss: 0.582504\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362815; batch adversarial loss: 0.524537\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399511; batch adversarial loss: 0.506385\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388953; batch adversarial loss: 0.610820\n",
      "epoch 109; iter: 0; batch classifier loss: 0.411351; batch adversarial loss: 0.564358\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392873; batch adversarial loss: 0.572741\n",
      "epoch 111; iter: 0; batch classifier loss: 0.400618; batch adversarial loss: 0.507488\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347539; batch adversarial loss: 0.553565\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400711; batch adversarial loss: 0.488042\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388216; batch adversarial loss: 0.525727\n",
      "epoch 115; iter: 0; batch classifier loss: 0.408292; batch adversarial loss: 0.497473\n",
      "epoch 116; iter: 0; batch classifier loss: 0.433212; batch adversarial loss: 0.649195\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348215; batch adversarial loss: 0.534831\n",
      "epoch 118; iter: 0; batch classifier loss: 0.327550; batch adversarial loss: 0.553113\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425271; batch adversarial loss: 0.496649\n",
      "epoch 120; iter: 0; batch classifier loss: 0.411603; batch adversarial loss: 0.516727\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339475; batch adversarial loss: 0.535309\n",
      "epoch 122; iter: 0; batch classifier loss: 0.413880; batch adversarial loss: 0.563805\n",
      "epoch 123; iter: 0; batch classifier loss: 0.451339; batch adversarial loss: 0.535168\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379200; batch adversarial loss: 0.506275\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351930; batch adversarial loss: 0.554285\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362009; batch adversarial loss: 0.573682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330639; batch adversarial loss: 0.535295\n",
      "epoch 128; iter: 0; batch classifier loss: 0.426857; batch adversarial loss: 0.544762\n",
      "epoch 129; iter: 0; batch classifier loss: 0.357469; batch adversarial loss: 0.563214\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353517; batch adversarial loss: 0.534687\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375591; batch adversarial loss: 0.525932\n",
      "epoch 132; iter: 0; batch classifier loss: 0.378856; batch adversarial loss: 0.534825\n",
      "epoch 133; iter: 0; batch classifier loss: 0.324663; batch adversarial loss: 0.533820\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367421; batch adversarial loss: 0.553602\n",
      "epoch 135; iter: 0; batch classifier loss: 0.359512; batch adversarial loss: 0.621695\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332206; batch adversarial loss: 0.525732\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344574; batch adversarial loss: 0.573198\n",
      "epoch 138; iter: 0; batch classifier loss: 0.451659; batch adversarial loss: 0.678638\n",
      "epoch 139; iter: 0; batch classifier loss: 0.405687; batch adversarial loss: 0.573607\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386970; batch adversarial loss: 0.562931\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381114; batch adversarial loss: 0.478466\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403528; batch adversarial loss: 0.534847\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399736; batch adversarial loss: 0.506718\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405920; batch adversarial loss: 0.582915\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369124; batch adversarial loss: 0.582026\n",
      "epoch 146; iter: 0; batch classifier loss: 0.335924; batch adversarial loss: 0.449009\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359241; batch adversarial loss: 0.506836\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341996; batch adversarial loss: 0.525268\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322547; batch adversarial loss: 0.527208\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344556; batch adversarial loss: 0.525730\n",
      "epoch 151; iter: 0; batch classifier loss: 0.328633; batch adversarial loss: 0.487701\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349246; batch adversarial loss: 0.516271\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430626; batch adversarial loss: 0.554939\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356216; batch adversarial loss: 0.515448\n",
      "epoch 155; iter: 0; batch classifier loss: 0.333350; batch adversarial loss: 0.468195\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398015; batch adversarial loss: 0.497078\n",
      "epoch 157; iter: 0; batch classifier loss: 0.345377; batch adversarial loss: 0.515861\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327119; batch adversarial loss: 0.506645\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347591; batch adversarial loss: 0.544807\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339639; batch adversarial loss: 0.505450\n",
      "epoch 161; iter: 0; batch classifier loss: 0.403105; batch adversarial loss: 0.602849\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327565; batch adversarial loss: 0.544528\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355241; batch adversarial loss: 0.506151\n",
      "epoch 164; iter: 0; batch classifier loss: 0.461235; batch adversarial loss: 0.515960\n",
      "epoch 165; iter: 0; batch classifier loss: 0.367815; batch adversarial loss: 0.554580\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356913; batch adversarial loss: 0.496954\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374489; batch adversarial loss: 0.457478\n",
      "epoch 168; iter: 0; batch classifier loss: 0.423759; batch adversarial loss: 0.487567\n",
      "epoch 169; iter: 0; batch classifier loss: 0.298177; batch adversarial loss: 0.554502\n",
      "epoch 170; iter: 0; batch classifier loss: 0.401044; batch adversarial loss: 0.581781\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383374; batch adversarial loss: 0.593427\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391507; batch adversarial loss: 0.469016\n",
      "epoch 173; iter: 0; batch classifier loss: 0.428480; batch adversarial loss: 0.535299\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351656; batch adversarial loss: 0.582552\n",
      "epoch 175; iter: 0; batch classifier loss: 0.348831; batch adversarial loss: 0.620096\n",
      "epoch 176; iter: 0; batch classifier loss: 0.398310; batch adversarial loss: 0.573935\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324719; batch adversarial loss: 0.545020\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354359; batch adversarial loss: 0.592875\n",
      "epoch 179; iter: 0; batch classifier loss: 0.388062; batch adversarial loss: 0.478781\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367187; batch adversarial loss: 0.563293\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423172; batch adversarial loss: 0.602440\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322826; batch adversarial loss: 0.574088\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315970; batch adversarial loss: 0.563714\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365036; batch adversarial loss: 0.573443\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348383; batch adversarial loss: 0.553255\n",
      "epoch 186; iter: 0; batch classifier loss: 0.261377; batch adversarial loss: 0.506119\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351237; batch adversarial loss: 0.553300\n",
      "epoch 188; iter: 0; batch classifier loss: 0.457108; batch adversarial loss: 0.582493\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355029; batch adversarial loss: 0.507006\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339192; batch adversarial loss: 0.563404\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382582; batch adversarial loss: 0.657275\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345934; batch adversarial loss: 0.582667\n",
      "epoch 193; iter: 0; batch classifier loss: 0.426152; batch adversarial loss: 0.536171\n",
      "epoch 194; iter: 0; batch classifier loss: 0.317008; batch adversarial loss: 0.592545\n",
      "epoch 195; iter: 0; batch classifier loss: 0.306987; batch adversarial loss: 0.524799\n",
      "epoch 196; iter: 0; batch classifier loss: 0.311463; batch adversarial loss: 0.524950\n",
      "epoch 197; iter: 0; batch classifier loss: 0.294262; batch adversarial loss: 0.535366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.386621; batch adversarial loss: 0.601760\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363450; batch adversarial loss: 0.564117\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703321; batch adversarial loss: 0.734867\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647702; batch adversarial loss: 0.719263\n",
      "epoch 2; iter: 0; batch classifier loss: 0.749709; batch adversarial loss: 0.676286\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537549; batch adversarial loss: 0.645780\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558282; batch adversarial loss: 0.639596\n",
      "epoch 5; iter: 0; batch classifier loss: 0.500746; batch adversarial loss: 0.611497\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570837; batch adversarial loss: 0.615612\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580070; batch adversarial loss: 0.655999\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521248; batch adversarial loss: 0.583018\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573745; batch adversarial loss: 0.607219\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496608; batch adversarial loss: 0.581703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.472696; batch adversarial loss: 0.552563\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480062; batch adversarial loss: 0.559222\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480785; batch adversarial loss: 0.554822\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532388; batch adversarial loss: 0.571715\n",
      "epoch 15; iter: 0; batch classifier loss: 0.433518; batch adversarial loss: 0.594376\n",
      "epoch 16; iter: 0; batch classifier loss: 0.509484; batch adversarial loss: 0.585602\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559246; batch adversarial loss: 0.576582\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471727; batch adversarial loss: 0.546439\n",
      "epoch 19; iter: 0; batch classifier loss: 0.446600; batch adversarial loss: 0.523111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426249; batch adversarial loss: 0.636747\n",
      "epoch 21; iter: 0; batch classifier loss: 0.444898; batch adversarial loss: 0.540113\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473122; batch adversarial loss: 0.565754\n",
      "epoch 23; iter: 0; batch classifier loss: 0.412889; batch adversarial loss: 0.588544\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495991; batch adversarial loss: 0.537448\n",
      "epoch 25; iter: 0; batch classifier loss: 0.583252; batch adversarial loss: 0.536642\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466405; batch adversarial loss: 0.560300\n",
      "epoch 27; iter: 0; batch classifier loss: 0.498099; batch adversarial loss: 0.604298\n",
      "epoch 28; iter: 0; batch classifier loss: 0.449857; batch adversarial loss: 0.582285\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490119; batch adversarial loss: 0.543860\n",
      "epoch 30; iter: 0; batch classifier loss: 0.505219; batch adversarial loss: 0.544455\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463381; batch adversarial loss: 0.531252\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428862; batch adversarial loss: 0.523464\n",
      "epoch 33; iter: 0; batch classifier loss: 0.454020; batch adversarial loss: 0.522051\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411749; batch adversarial loss: 0.580867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432858; batch adversarial loss: 0.587685\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469005; batch adversarial loss: 0.517706\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392784; batch adversarial loss: 0.589526\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409057; batch adversarial loss: 0.571431\n",
      "epoch 39; iter: 0; batch classifier loss: 0.396207; batch adversarial loss: 0.527119\n",
      "epoch 40; iter: 0; batch classifier loss: 0.502045; batch adversarial loss: 0.518816\n",
      "epoch 41; iter: 0; batch classifier loss: 0.488553; batch adversarial loss: 0.519281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414971; batch adversarial loss: 0.666431\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398222; batch adversarial loss: 0.579864\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398688; batch adversarial loss: 0.543385\n",
      "epoch 45; iter: 0; batch classifier loss: 0.528814; batch adversarial loss: 0.527762\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398554; batch adversarial loss: 0.580218\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403417; batch adversarial loss: 0.589438\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383660; batch adversarial loss: 0.535992\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447354; batch adversarial loss: 0.553790\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417484; batch adversarial loss: 0.509696\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399130; batch adversarial loss: 0.527422\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390346; batch adversarial loss: 0.606974\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386389; batch adversarial loss: 0.472794\n",
      "epoch 54; iter: 0; batch classifier loss: 0.468981; batch adversarial loss: 0.598837\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450398; batch adversarial loss: 0.473216\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438082; batch adversarial loss: 0.553740\n",
      "epoch 57; iter: 0; batch classifier loss: 0.375749; batch adversarial loss: 0.509009\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392419; batch adversarial loss: 0.580475\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394145; batch adversarial loss: 0.616111\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384897; batch adversarial loss: 0.526640\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424819; batch adversarial loss: 0.517316\n",
      "epoch 62; iter: 0; batch classifier loss: 0.339600; batch adversarial loss: 0.490251\n",
      "epoch 63; iter: 0; batch classifier loss: 0.365844; batch adversarial loss: 0.589797\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408406; batch adversarial loss: 0.470768\n",
      "epoch 65; iter: 0; batch classifier loss: 0.377326; batch adversarial loss: 0.498320\n",
      "epoch 66; iter: 0; batch classifier loss: 0.399628; batch adversarial loss: 0.535327\n",
      "epoch 67; iter: 0; batch classifier loss: 0.473256; batch adversarial loss: 0.535560\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422205; batch adversarial loss: 0.544527\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376555; batch adversarial loss: 0.535574\n",
      "epoch 70; iter: 0; batch classifier loss: 0.452020; batch adversarial loss: 0.589333\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395116; batch adversarial loss: 0.535884\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457542; batch adversarial loss: 0.517611\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384516; batch adversarial loss: 0.481910\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416855; batch adversarial loss: 0.499914\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389168; batch adversarial loss: 0.544184\n",
      "epoch 76; iter: 0; batch classifier loss: 0.489014; batch adversarial loss: 0.580245\n",
      "epoch 77; iter: 0; batch classifier loss: 0.432382; batch adversarial loss: 0.517774\n",
      "epoch 78; iter: 0; batch classifier loss: 0.327525; batch adversarial loss: 0.581094\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388193; batch adversarial loss: 0.498664\n",
      "epoch 80; iter: 0; batch classifier loss: 0.453263; batch adversarial loss: 0.554045\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414304; batch adversarial loss: 0.535550\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406325; batch adversarial loss: 0.518134\n",
      "epoch 83; iter: 0; batch classifier loss: 0.442617; batch adversarial loss: 0.553862\n",
      "epoch 84; iter: 0; batch classifier loss: 0.335189; batch adversarial loss: 0.535662\n",
      "epoch 85; iter: 0; batch classifier loss: 0.472507; batch adversarial loss: 0.552798\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391347; batch adversarial loss: 0.517817\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371734; batch adversarial loss: 0.535739\n",
      "epoch 88; iter: 0; batch classifier loss: 0.339046; batch adversarial loss: 0.517238\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403957; batch adversarial loss: 0.582303\n",
      "epoch 90; iter: 0; batch classifier loss: 0.421616; batch adversarial loss: 0.445388\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409078; batch adversarial loss: 0.517597\n",
      "epoch 92; iter: 0; batch classifier loss: 0.409238; batch adversarial loss: 0.508157\n",
      "epoch 93; iter: 0; batch classifier loss: 0.332643; batch adversarial loss: 0.590193\n",
      "epoch 94; iter: 0; batch classifier loss: 0.457838; batch adversarial loss: 0.544998\n",
      "epoch 95; iter: 0; batch classifier loss: 0.373940; batch adversarial loss: 0.553870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.400021; batch adversarial loss: 0.535390\n",
      "epoch 97; iter: 0; batch classifier loss: 0.385687; batch adversarial loss: 0.588969\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410592; batch adversarial loss: 0.499122\n",
      "epoch 99; iter: 0; batch classifier loss: 0.318954; batch adversarial loss: 0.607747\n",
      "epoch 100; iter: 0; batch classifier loss: 0.443635; batch adversarial loss: 0.544141\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356289; batch adversarial loss: 0.499165\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355665; batch adversarial loss: 0.452833\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367258; batch adversarial loss: 0.509134\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366597; batch adversarial loss: 0.580212\n",
      "epoch 105; iter: 0; batch classifier loss: 0.344622; batch adversarial loss: 0.481794\n",
      "epoch 106; iter: 0; batch classifier loss: 0.327850; batch adversarial loss: 0.564306\n",
      "epoch 107; iter: 0; batch classifier loss: 0.313515; batch adversarial loss: 0.526352\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357075; batch adversarial loss: 0.642654\n",
      "epoch 109; iter: 0; batch classifier loss: 0.362115; batch adversarial loss: 0.561002\n",
      "epoch 110; iter: 0; batch classifier loss: 0.387623; batch adversarial loss: 0.509690\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391187; batch adversarial loss: 0.527575\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388856; batch adversarial loss: 0.491031\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369525; batch adversarial loss: 0.615045\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344393; batch adversarial loss: 0.571276\n",
      "epoch 115; iter: 0; batch classifier loss: 0.426501; batch adversarial loss: 0.571031\n",
      "epoch 116; iter: 0; batch classifier loss: 0.349165; batch adversarial loss: 0.491092\n",
      "epoch 117; iter: 0; batch classifier loss: 0.318806; batch adversarial loss: 0.562415\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382283; batch adversarial loss: 0.581467\n",
      "epoch 119; iter: 0; batch classifier loss: 0.413057; batch adversarial loss: 0.571424\n",
      "epoch 120; iter: 0; batch classifier loss: 0.251580; batch adversarial loss: 0.507971\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376912; batch adversarial loss: 0.544687\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355026; batch adversarial loss: 0.526474\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376177; batch adversarial loss: 0.552709\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376054; batch adversarial loss: 0.572498\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332350; batch adversarial loss: 0.517229\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347622; batch adversarial loss: 0.490254\n",
      "epoch 127; iter: 0; batch classifier loss: 0.430327; batch adversarial loss: 0.589255\n",
      "epoch 128; iter: 0; batch classifier loss: 0.297539; batch adversarial loss: 0.580528\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376409; batch adversarial loss: 0.571577\n",
      "epoch 130; iter: 0; batch classifier loss: 0.443692; batch adversarial loss: 0.508885\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356809; batch adversarial loss: 0.553786\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350848; batch adversarial loss: 0.544639\n",
      "epoch 133; iter: 0; batch classifier loss: 0.469713; batch adversarial loss: 0.660876\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371434; batch adversarial loss: 0.526087\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338152; batch adversarial loss: 0.580075\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382837; batch adversarial loss: 0.544581\n",
      "epoch 137; iter: 0; batch classifier loss: 0.313602; batch adversarial loss: 0.597311\n",
      "epoch 138; iter: 0; batch classifier loss: 0.296383; batch adversarial loss: 0.661245\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366127; batch adversarial loss: 0.543538\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397239; batch adversarial loss: 0.616548\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326794; batch adversarial loss: 0.607032\n",
      "epoch 142; iter: 0; batch classifier loss: 0.286282; batch adversarial loss: 0.480740\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391090; batch adversarial loss: 0.544367\n",
      "epoch 144; iter: 0; batch classifier loss: 0.329337; batch adversarial loss: 0.508241\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405912; batch adversarial loss: 0.561719\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395858; batch adversarial loss: 0.490668\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410766; batch adversarial loss: 0.644430\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342713; batch adversarial loss: 0.517165\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331194; batch adversarial loss: 0.589018\n",
      "epoch 150; iter: 0; batch classifier loss: 0.303162; batch adversarial loss: 0.536538\n",
      "epoch 151; iter: 0; batch classifier loss: 0.399334; batch adversarial loss: 0.544611\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387218; batch adversarial loss: 0.599019\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321400; batch adversarial loss: 0.535774\n",
      "epoch 154; iter: 0; batch classifier loss: 0.334250; batch adversarial loss: 0.544352\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317872; batch adversarial loss: 0.572173\n",
      "epoch 156; iter: 0; batch classifier loss: 0.288316; batch adversarial loss: 0.553940\n",
      "epoch 157; iter: 0; batch classifier loss: 0.445461; batch adversarial loss: 0.589700\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388438; batch adversarial loss: 0.535895\n",
      "epoch 159; iter: 0; batch classifier loss: 0.340443; batch adversarial loss: 0.554706\n",
      "epoch 160; iter: 0; batch classifier loss: 0.421214; batch adversarial loss: 0.571061\n",
      "epoch 161; iter: 0; batch classifier loss: 0.310888; batch adversarial loss: 0.446114\n",
      "epoch 162; iter: 0; batch classifier loss: 0.392048; batch adversarial loss: 0.634267\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325799; batch adversarial loss: 0.634086\n",
      "epoch 164; iter: 0; batch classifier loss: 0.297245; batch adversarial loss: 0.526680\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359595; batch adversarial loss: 0.570544\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330154; batch adversarial loss: 0.599001\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363110; batch adversarial loss: 0.517976\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332212; batch adversarial loss: 0.598755\n",
      "epoch 169; iter: 0; batch classifier loss: 0.393216; batch adversarial loss: 0.616996\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333945; batch adversarial loss: 0.535019\n",
      "epoch 171; iter: 0; batch classifier loss: 0.316683; batch adversarial loss: 0.518357\n",
      "epoch 172; iter: 0; batch classifier loss: 0.316277; batch adversarial loss: 0.499449\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361090; batch adversarial loss: 0.643937\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380111; batch adversarial loss: 0.597770\n",
      "epoch 175; iter: 0; batch classifier loss: 0.246897; batch adversarial loss: 0.508860\n",
      "epoch 176; iter: 0; batch classifier loss: 0.416572; batch adversarial loss: 0.472378\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360085; batch adversarial loss: 0.561284\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350511; batch adversarial loss: 0.534617\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368848; batch adversarial loss: 0.547146\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338406; batch adversarial loss: 0.563042\n",
      "epoch 181; iter: 0; batch classifier loss: 0.282703; batch adversarial loss: 0.464231\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320054; batch adversarial loss: 0.535034\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355492; batch adversarial loss: 0.519060\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347280; batch adversarial loss: 0.526712\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320134; batch adversarial loss: 0.526868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.381071; batch adversarial loss: 0.554057\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333287; batch adversarial loss: 0.509832\n",
      "epoch 188; iter: 0; batch classifier loss: 0.322612; batch adversarial loss: 0.562667\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340953; batch adversarial loss: 0.598108\n",
      "epoch 190; iter: 0; batch classifier loss: 0.399271; batch adversarial loss: 0.589869\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320362; batch adversarial loss: 0.562158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.296879; batch adversarial loss: 0.544367\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375322; batch adversarial loss: 0.509285\n",
      "epoch 194; iter: 0; batch classifier loss: 0.288535; batch adversarial loss: 0.597674\n",
      "epoch 195; iter: 0; batch classifier loss: 0.299608; batch adversarial loss: 0.606815\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383211; batch adversarial loss: 0.607599\n",
      "epoch 197; iter: 0; batch classifier loss: 0.402820; batch adversarial loss: 0.544962\n",
      "epoch 198; iter: 0; batch classifier loss: 0.339141; batch adversarial loss: 0.535931\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349756; batch adversarial loss: 0.607855\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693117; batch adversarial loss: 0.816546\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595147; batch adversarial loss: 0.848215\n",
      "epoch 2; iter: 0; batch classifier loss: 0.643834; batch adversarial loss: 0.777586\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534306; batch adversarial loss: 0.713189\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566189; batch adversarial loss: 0.683747\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608914; batch adversarial loss: 0.647969\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532225; batch adversarial loss: 0.645140\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575667; batch adversarial loss: 0.602526\n",
      "epoch 8; iter: 0; batch classifier loss: 0.515677; batch adversarial loss: 0.645743\n",
      "epoch 9; iter: 0; batch classifier loss: 0.497961; batch adversarial loss: 0.585200\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546501; batch adversarial loss: 0.601701\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573219; batch adversarial loss: 0.548004\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505767; batch adversarial loss: 0.602620\n",
      "epoch 13; iter: 0; batch classifier loss: 0.467515; batch adversarial loss: 0.535717\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514577; batch adversarial loss: 0.546490\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508882; batch adversarial loss: 0.544717\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523603; batch adversarial loss: 0.604290\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482629; batch adversarial loss: 0.486431\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513033; batch adversarial loss: 0.519006\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471148; batch adversarial loss: 0.532233\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529285; batch adversarial loss: 0.530671\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485782; batch adversarial loss: 0.576995\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469646; batch adversarial loss: 0.574275\n",
      "epoch 23; iter: 0; batch classifier loss: 0.569748; batch adversarial loss: 0.597548\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474979; batch adversarial loss: 0.649997\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451796; batch adversarial loss: 0.555629\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500960; batch adversarial loss: 0.459826\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413611; batch adversarial loss: 0.580697\n",
      "epoch 28; iter: 0; batch classifier loss: 0.534324; batch adversarial loss: 0.572789\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487492; batch adversarial loss: 0.597411\n",
      "epoch 30; iter: 0; batch classifier loss: 0.509592; batch adversarial loss: 0.546838\n",
      "epoch 31; iter: 0; batch classifier loss: 0.385375; batch adversarial loss: 0.564056\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517908; batch adversarial loss: 0.603429\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409704; batch adversarial loss: 0.523420\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447004; batch adversarial loss: 0.468534\n",
      "epoch 35; iter: 0; batch classifier loss: 0.490533; batch adversarial loss: 0.488291\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484602; batch adversarial loss: 0.495722\n",
      "epoch 37; iter: 0; batch classifier loss: 0.453443; batch adversarial loss: 0.577544\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434158; batch adversarial loss: 0.525573\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439611; batch adversarial loss: 0.602848\n",
      "epoch 40; iter: 0; batch classifier loss: 0.433626; batch adversarial loss: 0.543319\n",
      "epoch 41; iter: 0; batch classifier loss: 0.390660; batch adversarial loss: 0.512526\n",
      "epoch 42; iter: 0; batch classifier loss: 0.386586; batch adversarial loss: 0.633136\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433503; batch adversarial loss: 0.515657\n",
      "epoch 44; iter: 0; batch classifier loss: 0.491413; batch adversarial loss: 0.545324\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478326; batch adversarial loss: 0.499063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491309; batch adversarial loss: 0.552345\n",
      "epoch 47; iter: 0; batch classifier loss: 0.522220; batch adversarial loss: 0.563241\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404159; batch adversarial loss: 0.571770\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419795; batch adversarial loss: 0.545667\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420558; batch adversarial loss: 0.490164\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417027; batch adversarial loss: 0.524772\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423188; batch adversarial loss: 0.582624\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414851; batch adversarial loss: 0.591819\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417976; batch adversarial loss: 0.545985\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440557; batch adversarial loss: 0.591656\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430480; batch adversarial loss: 0.579361\n",
      "epoch 57; iter: 0; batch classifier loss: 0.349787; batch adversarial loss: 0.571028\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439137; batch adversarial loss: 0.461453\n",
      "epoch 59; iter: 0; batch classifier loss: 0.525109; batch adversarial loss: 0.497131\n",
      "epoch 60; iter: 0; batch classifier loss: 0.364449; batch adversarial loss: 0.543310\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373707; batch adversarial loss: 0.607212\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428275; batch adversarial loss: 0.526547\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421538; batch adversarial loss: 0.590374\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395058; batch adversarial loss: 0.620083\n",
      "epoch 65; iter: 0; batch classifier loss: 0.496870; batch adversarial loss: 0.535788\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395242; batch adversarial loss: 0.469349\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392601; batch adversarial loss: 0.526463\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397968; batch adversarial loss: 0.543302\n",
      "epoch 69; iter: 0; batch classifier loss: 0.452028; batch adversarial loss: 0.555230\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404957; batch adversarial loss: 0.544629\n",
      "epoch 71; iter: 0; batch classifier loss: 0.441882; batch adversarial loss: 0.620889\n",
      "epoch 72; iter: 0; batch classifier loss: 0.349792; batch adversarial loss: 0.572983\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380764; batch adversarial loss: 0.601579\n",
      "epoch 74; iter: 0; batch classifier loss: 0.333050; batch adversarial loss: 0.507432\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438973; batch adversarial loss: 0.479860\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420619; batch adversarial loss: 0.524652\n",
      "epoch 77; iter: 0; batch classifier loss: 0.438816; batch adversarial loss: 0.517414\n",
      "epoch 78; iter: 0; batch classifier loss: 0.361578; batch adversarial loss: 0.572206\n",
      "epoch 79; iter: 0; batch classifier loss: 0.438899; batch adversarial loss: 0.543042\n",
      "epoch 80; iter: 0; batch classifier loss: 0.391975; batch adversarial loss: 0.518105\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375275; batch adversarial loss: 0.497298\n",
      "epoch 82; iter: 0; batch classifier loss: 0.323138; batch adversarial loss: 0.497694\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394930; batch adversarial loss: 0.497608\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349724; batch adversarial loss: 0.564115\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382041; batch adversarial loss: 0.543379\n",
      "epoch 86; iter: 0; batch classifier loss: 0.393856; batch adversarial loss: 0.617811\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390959; batch adversarial loss: 0.517137\n",
      "epoch 88; iter: 0; batch classifier loss: 0.434531; batch adversarial loss: 0.583698\n",
      "epoch 89; iter: 0; batch classifier loss: 0.418752; batch adversarial loss: 0.582841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.351366; batch adversarial loss: 0.543635\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433603; batch adversarial loss: 0.543614\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406746; batch adversarial loss: 0.583306\n",
      "epoch 93; iter: 0; batch classifier loss: 0.326905; batch adversarial loss: 0.545343\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426197; batch adversarial loss: 0.563365\n",
      "epoch 95; iter: 0; batch classifier loss: 0.479640; batch adversarial loss: 0.469190\n",
      "epoch 96; iter: 0; batch classifier loss: 0.491797; batch adversarial loss: 0.544168\n",
      "epoch 97; iter: 0; batch classifier loss: 0.469850; batch adversarial loss: 0.515926\n",
      "epoch 98; iter: 0; batch classifier loss: 0.399331; batch adversarial loss: 0.517606\n",
      "epoch 99; iter: 0; batch classifier loss: 0.347895; batch adversarial loss: 0.460786\n",
      "epoch 100; iter: 0; batch classifier loss: 0.344260; batch adversarial loss: 0.563206\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392577; batch adversarial loss: 0.544057\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388607; batch adversarial loss: 0.543226\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367628; batch adversarial loss: 0.554096\n",
      "epoch 104; iter: 0; batch classifier loss: 0.346018; batch adversarial loss: 0.629575\n",
      "epoch 105; iter: 0; batch classifier loss: 0.466906; batch adversarial loss: 0.451402\n",
      "epoch 106; iter: 0; batch classifier loss: 0.410606; batch adversarial loss: 0.536657\n",
      "epoch 107; iter: 0; batch classifier loss: 0.279023; batch adversarial loss: 0.592412\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398006; batch adversarial loss: 0.609138\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364996; batch adversarial loss: 0.599976\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375719; batch adversarial loss: 0.554414\n",
      "epoch 111; iter: 0; batch classifier loss: 0.322297; batch adversarial loss: 0.590774\n",
      "epoch 112; iter: 0; batch classifier loss: 0.343959; batch adversarial loss: 0.600524\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346166; batch adversarial loss: 0.508093\n",
      "epoch 114; iter: 0; batch classifier loss: 0.453956; batch adversarial loss: 0.638257\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355143; batch adversarial loss: 0.608719\n",
      "epoch 116; iter: 0; batch classifier loss: 0.383537; batch adversarial loss: 0.536127\n",
      "epoch 117; iter: 0; batch classifier loss: 0.463181; batch adversarial loss: 0.562307\n",
      "epoch 118; iter: 0; batch classifier loss: 0.460049; batch adversarial loss: 0.526424\n",
      "epoch 119; iter: 0; batch classifier loss: 0.436522; batch adversarial loss: 0.592002\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346266; batch adversarial loss: 0.525208\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420580; batch adversarial loss: 0.534456\n",
      "epoch 122; iter: 0; batch classifier loss: 0.473137; batch adversarial loss: 0.573478\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348244; batch adversarial loss: 0.515705\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380371; batch adversarial loss: 0.545168\n",
      "epoch 125; iter: 0; batch classifier loss: 0.338433; batch adversarial loss: 0.573988\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380989; batch adversarial loss: 0.506741\n",
      "epoch 127; iter: 0; batch classifier loss: 0.306041; batch adversarial loss: 0.489081\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432352; batch adversarial loss: 0.572727\n",
      "epoch 129; iter: 0; batch classifier loss: 0.322451; batch adversarial loss: 0.478421\n",
      "epoch 130; iter: 0; batch classifier loss: 0.401771; batch adversarial loss: 0.553042\n",
      "epoch 131; iter: 0; batch classifier loss: 0.352126; batch adversarial loss: 0.535012\n",
      "epoch 132; iter: 0; batch classifier loss: 0.290580; batch adversarial loss: 0.602585\n",
      "epoch 133; iter: 0; batch classifier loss: 0.480548; batch adversarial loss: 0.525023\n",
      "epoch 134; iter: 0; batch classifier loss: 0.446512; batch adversarial loss: 0.573083\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424150; batch adversarial loss: 0.505843\n",
      "epoch 136; iter: 0; batch classifier loss: 0.327429; batch adversarial loss: 0.544343\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370317; batch adversarial loss: 0.534117\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338972; batch adversarial loss: 0.591720\n",
      "epoch 139; iter: 0; batch classifier loss: 0.435314; batch adversarial loss: 0.516478\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327946; batch adversarial loss: 0.468890\n",
      "epoch 141; iter: 0; batch classifier loss: 0.392630; batch adversarial loss: 0.513620\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339756; batch adversarial loss: 0.523561\n",
      "epoch 143; iter: 0; batch classifier loss: 0.390239; batch adversarial loss: 0.526949\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395381; batch adversarial loss: 0.524793\n",
      "epoch 145; iter: 0; batch classifier loss: 0.316954; batch adversarial loss: 0.601637\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388812; batch adversarial loss: 0.553185\n",
      "epoch 147; iter: 0; batch classifier loss: 0.424922; batch adversarial loss: 0.527196\n",
      "epoch 148; iter: 0; batch classifier loss: 0.369370; batch adversarial loss: 0.553926\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377121; batch adversarial loss: 0.525654\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311170; batch adversarial loss: 0.489859\n",
      "epoch 151; iter: 0; batch classifier loss: 0.407575; batch adversarial loss: 0.563206\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348270; batch adversarial loss: 0.600713\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362672; batch adversarial loss: 0.496688\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340693; batch adversarial loss: 0.555252\n",
      "epoch 155; iter: 0; batch classifier loss: 0.312576; batch adversarial loss: 0.562949\n",
      "epoch 156; iter: 0; batch classifier loss: 0.386365; batch adversarial loss: 0.526364\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404702; batch adversarial loss: 0.497564\n",
      "epoch 158; iter: 0; batch classifier loss: 0.359191; batch adversarial loss: 0.544766\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370775; batch adversarial loss: 0.534099\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339799; batch adversarial loss: 0.592287\n",
      "epoch 161; iter: 0; batch classifier loss: 0.327608; batch adversarial loss: 0.485797\n",
      "epoch 162; iter: 0; batch classifier loss: 0.309137; batch adversarial loss: 0.461243\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344257; batch adversarial loss: 0.536808\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328361; batch adversarial loss: 0.468080\n",
      "epoch 165; iter: 0; batch classifier loss: 0.368991; batch adversarial loss: 0.543288\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332920; batch adversarial loss: 0.544447\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395721; batch adversarial loss: 0.553255\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361687; batch adversarial loss: 0.572541\n",
      "epoch 169; iter: 0; batch classifier loss: 0.338471; batch adversarial loss: 0.639808\n",
      "epoch 170; iter: 0; batch classifier loss: 0.419540; batch adversarial loss: 0.517157\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374935; batch adversarial loss: 0.471311\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376374; batch adversarial loss: 0.629507\n",
      "epoch 173; iter: 0; batch classifier loss: 0.365960; batch adversarial loss: 0.479689\n",
      "epoch 174; iter: 0; batch classifier loss: 0.409995; batch adversarial loss: 0.536053\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395875; batch adversarial loss: 0.524626\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374375; batch adversarial loss: 0.573931\n",
      "epoch 177; iter: 0; batch classifier loss: 0.419743; batch adversarial loss: 0.488536\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391961; batch adversarial loss: 0.525387\n",
      "epoch 179; iter: 0; batch classifier loss: 0.410939; batch adversarial loss: 0.542809\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322929; batch adversarial loss: 0.582363\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367934; batch adversarial loss: 0.580723\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383005; batch adversarial loss: 0.515554\n",
      "epoch 183; iter: 0; batch classifier loss: 0.334669; batch adversarial loss: 0.525077\n",
      "epoch 184; iter: 0; batch classifier loss: 0.273818; batch adversarial loss: 0.516767\n",
      "epoch 185; iter: 0; batch classifier loss: 0.400504; batch adversarial loss: 0.536787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.272108; batch adversarial loss: 0.582102\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351135; batch adversarial loss: 0.581968\n",
      "epoch 188; iter: 0; batch classifier loss: 0.441244; batch adversarial loss: 0.610114\n",
      "epoch 189; iter: 0; batch classifier loss: 0.397856; batch adversarial loss: 0.608829\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297934; batch adversarial loss: 0.545178\n",
      "epoch 191; iter: 0; batch classifier loss: 0.299564; batch adversarial loss: 0.468159\n",
      "epoch 192; iter: 0; batch classifier loss: 0.306242; batch adversarial loss: 0.507063\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350682; batch adversarial loss: 0.602357\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407615; batch adversarial loss: 0.537090\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323719; batch adversarial loss: 0.506296\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376080; batch adversarial loss: 0.544438\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353960; batch adversarial loss: 0.543429\n",
      "epoch 198; iter: 0; batch classifier loss: 0.373273; batch adversarial loss: 0.544940\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316381; batch adversarial loss: 0.667269\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739468; batch adversarial loss: 0.709602\n",
      "epoch 1; iter: 0; batch classifier loss: 0.644147; batch adversarial loss: 0.643206\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652727; batch adversarial loss: 0.654862\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565157; batch adversarial loss: 0.612543\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621326; batch adversarial loss: 0.591802\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635225; batch adversarial loss: 0.609862\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541739; batch adversarial loss: 0.596588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550164; batch adversarial loss: 0.595390\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533890; batch adversarial loss: 0.618785\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589751; batch adversarial loss: 0.551659\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549087; batch adversarial loss: 0.660425\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557396; batch adversarial loss: 0.558254\n",
      "epoch 12; iter: 0; batch classifier loss: 0.441448; batch adversarial loss: 0.579467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503757; batch adversarial loss: 0.566114\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524530; batch adversarial loss: 0.531704\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500235; batch adversarial loss: 0.569297\n",
      "epoch 16; iter: 0; batch classifier loss: 0.581839; batch adversarial loss: 0.555737\n",
      "epoch 17; iter: 0; batch classifier loss: 0.548420; batch adversarial loss: 0.543973\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476227; batch adversarial loss: 0.559786\n",
      "epoch 19; iter: 0; batch classifier loss: 0.551963; batch adversarial loss: 0.562369\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474116; batch adversarial loss: 0.583298\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523428; batch adversarial loss: 0.560766\n",
      "epoch 22; iter: 0; batch classifier loss: 0.439956; batch adversarial loss: 0.555956\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504837; batch adversarial loss: 0.469574\n",
      "epoch 24; iter: 0; batch classifier loss: 0.542476; batch adversarial loss: 0.578926\n",
      "epoch 25; iter: 0; batch classifier loss: 0.574628; batch adversarial loss: 0.539891\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432672; batch adversarial loss: 0.599705\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472111; batch adversarial loss: 0.600951\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459887; batch adversarial loss: 0.515300\n",
      "epoch 29; iter: 0; batch classifier loss: 0.503294; batch adversarial loss: 0.572167\n",
      "epoch 30; iter: 0; batch classifier loss: 0.414681; batch adversarial loss: 0.580747\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459769; batch adversarial loss: 0.580024\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448554; batch adversarial loss: 0.562170\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464682; batch adversarial loss: 0.507039\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406193; batch adversarial loss: 0.553418\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433286; batch adversarial loss: 0.502099\n",
      "epoch 36; iter: 0; batch classifier loss: 0.412054; batch adversarial loss: 0.590444\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458419; batch adversarial loss: 0.502466\n",
      "epoch 38; iter: 0; batch classifier loss: 0.416948; batch adversarial loss: 0.509327\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489207; batch adversarial loss: 0.491775\n",
      "epoch 40; iter: 0; batch classifier loss: 0.498572; batch adversarial loss: 0.571664\n",
      "epoch 41; iter: 0; batch classifier loss: 0.485763; batch adversarial loss: 0.491585\n",
      "epoch 42; iter: 0; batch classifier loss: 0.382863; batch adversarial loss: 0.536449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427654; batch adversarial loss: 0.525990\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421808; batch adversarial loss: 0.598307\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478499; batch adversarial loss: 0.571780\n",
      "epoch 46; iter: 0; batch classifier loss: 0.529451; batch adversarial loss: 0.599514\n",
      "epoch 47; iter: 0; batch classifier loss: 0.372942; batch adversarial loss: 0.535918\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424302; batch adversarial loss: 0.625959\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417299; batch adversarial loss: 0.571551\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402710; batch adversarial loss: 0.516447\n",
      "epoch 51; iter: 0; batch classifier loss: 0.496584; batch adversarial loss: 0.518951\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430531; batch adversarial loss: 0.599851\n",
      "epoch 53; iter: 0; batch classifier loss: 0.426433; batch adversarial loss: 0.491406\n",
      "epoch 54; iter: 0; batch classifier loss: 0.371669; batch adversarial loss: 0.580608\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407617; batch adversarial loss: 0.553771\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399011; batch adversarial loss: 0.571672\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404322; batch adversarial loss: 0.571400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.468560; batch adversarial loss: 0.535662\n",
      "epoch 59; iter: 0; batch classifier loss: 0.491421; batch adversarial loss: 0.553736\n",
      "epoch 60; iter: 0; batch classifier loss: 0.419916; batch adversarial loss: 0.625918\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449494; batch adversarial loss: 0.535436\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428683; batch adversarial loss: 0.526404\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418291; batch adversarial loss: 0.562525\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376209; batch adversarial loss: 0.517278\n",
      "epoch 65; iter: 0; batch classifier loss: 0.460903; batch adversarial loss: 0.490392\n",
      "epoch 66; iter: 0; batch classifier loss: 0.444008; batch adversarial loss: 0.553987\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388574; batch adversarial loss: 0.562771\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424415; batch adversarial loss: 0.472233\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447727; batch adversarial loss: 0.572072\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424484; batch adversarial loss: 0.535665\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365351; batch adversarial loss: 0.507727\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404666; batch adversarial loss: 0.599346\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404296; batch adversarial loss: 0.481445\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374209; batch adversarial loss: 0.607862\n",
      "epoch 75; iter: 0; batch classifier loss: 0.394616; batch adversarial loss: 0.553510\n",
      "epoch 76; iter: 0; batch classifier loss: 0.378108; batch adversarial loss: 0.571284\n",
      "epoch 77; iter: 0; batch classifier loss: 0.497656; batch adversarial loss: 0.507895\n",
      "epoch 78; iter: 0; batch classifier loss: 0.343966; batch adversarial loss: 0.580293\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373177; batch adversarial loss: 0.517227\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417991; batch adversarial loss: 0.571355\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414777; batch adversarial loss: 0.571680\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414048; batch adversarial loss: 0.544888\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422689; batch adversarial loss: 0.562875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.454285; batch adversarial loss: 0.598733\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370229; batch adversarial loss: 0.553646\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387044; batch adversarial loss: 0.517152\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384565; batch adversarial loss: 0.526228\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372691; batch adversarial loss: 0.590343\n",
      "epoch 89; iter: 0; batch classifier loss: 0.360302; batch adversarial loss: 0.499102\n",
      "epoch 90; iter: 0; batch classifier loss: 0.445863; batch adversarial loss: 0.498990\n",
      "epoch 91; iter: 0; batch classifier loss: 0.333603; batch adversarial loss: 0.508098\n",
      "epoch 92; iter: 0; batch classifier loss: 0.502298; batch adversarial loss: 0.616780\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341803; batch adversarial loss: 0.517425\n",
      "epoch 94; iter: 0; batch classifier loss: 0.466876; batch adversarial loss: 0.517267\n",
      "epoch 95; iter: 0; batch classifier loss: 0.486231; batch adversarial loss: 0.562976\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431414; batch adversarial loss: 0.553972\n",
      "epoch 97; iter: 0; batch classifier loss: 0.424611; batch adversarial loss: 0.590123\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370797; batch adversarial loss: 0.608096\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369499; batch adversarial loss: 0.535347\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392341; batch adversarial loss: 0.562942\n",
      "epoch 101; iter: 0; batch classifier loss: 0.435283; batch adversarial loss: 0.689912\n",
      "epoch 102; iter: 0; batch classifier loss: 0.321723; batch adversarial loss: 0.526071\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371262; batch adversarial loss: 0.489374\n",
      "epoch 104; iter: 0; batch classifier loss: 0.461092; batch adversarial loss: 0.563001\n",
      "epoch 105; iter: 0; batch classifier loss: 0.446831; batch adversarial loss: 0.508165\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372209; batch adversarial loss: 0.580901\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379939; batch adversarial loss: 0.517406\n",
      "epoch 108; iter: 0; batch classifier loss: 0.508303; batch adversarial loss: 0.544749\n",
      "epoch 109; iter: 0; batch classifier loss: 0.488077; batch adversarial loss: 0.553631\n",
      "epoch 110; iter: 0; batch classifier loss: 0.415396; batch adversarial loss: 0.517700\n",
      "epoch 111; iter: 0; batch classifier loss: 0.373664; batch adversarial loss: 0.563584\n",
      "epoch 112; iter: 0; batch classifier loss: 0.369939; batch adversarial loss: 0.553167\n",
      "epoch 113; iter: 0; batch classifier loss: 0.349691; batch adversarial loss: 0.534748\n",
      "epoch 114; iter: 0; batch classifier loss: 0.464508; batch adversarial loss: 0.535480\n",
      "epoch 115; iter: 0; batch classifier loss: 0.307922; batch adversarial loss: 0.534973\n",
      "epoch 116; iter: 0; batch classifier loss: 0.464288; batch adversarial loss: 0.517143\n",
      "epoch 117; iter: 0; batch classifier loss: 0.424021; batch adversarial loss: 0.481805\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378826; batch adversarial loss: 0.562459\n",
      "epoch 119; iter: 0; batch classifier loss: 0.358326; batch adversarial loss: 0.516906\n",
      "epoch 120; iter: 0; batch classifier loss: 0.316786; batch adversarial loss: 0.545583\n",
      "epoch 121; iter: 0; batch classifier loss: 0.456899; batch adversarial loss: 0.617461\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402672; batch adversarial loss: 0.517548\n",
      "epoch 123; iter: 0; batch classifier loss: 0.450456; batch adversarial loss: 0.516786\n",
      "epoch 124; iter: 0; batch classifier loss: 0.419034; batch adversarial loss: 0.544379\n",
      "epoch 125; iter: 0; batch classifier loss: 0.465802; batch adversarial loss: 0.581314\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406265; batch adversarial loss: 0.535593\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407554; batch adversarial loss: 0.545038\n",
      "epoch 128; iter: 0; batch classifier loss: 0.315605; batch adversarial loss: 0.580809\n",
      "epoch 129; iter: 0; batch classifier loss: 0.312515; batch adversarial loss: 0.490021\n",
      "epoch 130; iter: 0; batch classifier loss: 0.411828; batch adversarial loss: 0.536512\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379992; batch adversarial loss: 0.563186\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382477; batch adversarial loss: 0.544234\n",
      "epoch 133; iter: 0; batch classifier loss: 0.380377; batch adversarial loss: 0.508351\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350391; batch adversarial loss: 0.499006\n",
      "epoch 135; iter: 0; batch classifier loss: 0.429532; batch adversarial loss: 0.598579\n",
      "epoch 136; iter: 0; batch classifier loss: 0.436535; batch adversarial loss: 0.518638\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389097; batch adversarial loss: 0.554635\n",
      "epoch 138; iter: 0; batch classifier loss: 0.428538; batch adversarial loss: 0.571792\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372239; batch adversarial loss: 0.609140\n",
      "epoch 140; iter: 0; batch classifier loss: 0.363942; batch adversarial loss: 0.580795\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357751; batch adversarial loss: 0.626089\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350012; batch adversarial loss: 0.553908\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366721; batch adversarial loss: 0.562722\n",
      "epoch 144; iter: 0; batch classifier loss: 0.330816; batch adversarial loss: 0.517234\n",
      "epoch 145; iter: 0; batch classifier loss: 0.428482; batch adversarial loss: 0.526940\n",
      "epoch 146; iter: 0; batch classifier loss: 0.398059; batch adversarial loss: 0.499044\n",
      "epoch 147; iter: 0; batch classifier loss: 0.323095; batch adversarial loss: 0.563013\n",
      "epoch 148; iter: 0; batch classifier loss: 0.282090; batch adversarial loss: 0.534599\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415041; batch adversarial loss: 0.535738\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340168; batch adversarial loss: 0.463294\n",
      "epoch 151; iter: 0; batch classifier loss: 0.312256; batch adversarial loss: 0.480832\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369780; batch adversarial loss: 0.562786\n",
      "epoch 153; iter: 0; batch classifier loss: 0.347550; batch adversarial loss: 0.543611\n",
      "epoch 154; iter: 0; batch classifier loss: 0.438045; batch adversarial loss: 0.563708\n",
      "epoch 155; iter: 0; batch classifier loss: 0.363811; batch adversarial loss: 0.500101\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358455; batch adversarial loss: 0.635018\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349553; batch adversarial loss: 0.544021\n",
      "epoch 158; iter: 0; batch classifier loss: 0.359314; batch adversarial loss: 0.552823\n",
      "epoch 159; iter: 0; batch classifier loss: 0.490424; batch adversarial loss: 0.541409\n",
      "epoch 160; iter: 0; batch classifier loss: 0.428733; batch adversarial loss: 0.527702\n",
      "epoch 161; iter: 0; batch classifier loss: 0.322146; batch adversarial loss: 0.545335\n",
      "epoch 162; iter: 0; batch classifier loss: 0.419767; batch adversarial loss: 0.426129\n",
      "epoch 163; iter: 0; batch classifier loss: 0.327570; batch adversarial loss: 0.518591\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335928; batch adversarial loss: 0.623841\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342712; batch adversarial loss: 0.580878\n",
      "epoch 166; iter: 0; batch classifier loss: 0.336305; batch adversarial loss: 0.527445\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365711; batch adversarial loss: 0.564030\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380010; batch adversarial loss: 0.561182\n",
      "epoch 169; iter: 0; batch classifier loss: 0.317829; batch adversarial loss: 0.542786\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397234; batch adversarial loss: 0.516339\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388942; batch adversarial loss: 0.425145\n",
      "epoch 172; iter: 0; batch classifier loss: 0.282684; batch adversarial loss: 0.601357\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364161; batch adversarial loss: 0.607961\n",
      "epoch 174; iter: 0; batch classifier loss: 0.313089; batch adversarial loss: 0.553073\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395598; batch adversarial loss: 0.544134\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376793; batch adversarial loss: 0.608400\n",
      "epoch 177; iter: 0; batch classifier loss: 0.405249; batch adversarial loss: 0.507652\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387410; batch adversarial loss: 0.535626\n",
      "epoch 179; iter: 0; batch classifier loss: 0.308586; batch adversarial loss: 0.544561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.323017; batch adversarial loss: 0.617637\n",
      "epoch 181; iter: 0; batch classifier loss: 0.394507; batch adversarial loss: 0.571582\n",
      "epoch 182; iter: 0; batch classifier loss: 0.268662; batch adversarial loss: 0.571853\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341924; batch adversarial loss: 0.553142\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363340; batch adversarial loss: 0.507656\n",
      "epoch 185; iter: 0; batch classifier loss: 0.302641; batch adversarial loss: 0.526335\n",
      "epoch 186; iter: 0; batch classifier loss: 0.402236; batch adversarial loss: 0.544106\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351108; batch adversarial loss: 0.526032\n",
      "epoch 188; iter: 0; batch classifier loss: 0.303495; batch adversarial loss: 0.580313\n",
      "epoch 189; iter: 0; batch classifier loss: 0.391360; batch adversarial loss: 0.581070\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367099; batch adversarial loss: 0.553057\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336845; batch adversarial loss: 0.644311\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376364; batch adversarial loss: 0.544445\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341263; batch adversarial loss: 0.580242\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349369; batch adversarial loss: 0.562469\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338408; batch adversarial loss: 0.517204\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320620; batch adversarial loss: 0.626291\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386857; batch adversarial loss: 0.535321\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340979; batch adversarial loss: 0.517061\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314377; batch adversarial loss: 0.562703\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719580; batch adversarial loss: 0.598314\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586755; batch adversarial loss: 0.623286\n",
      "epoch 2; iter: 0; batch classifier loss: 0.557189; batch adversarial loss: 0.645512\n",
      "epoch 3; iter: 0; batch classifier loss: 0.434257; batch adversarial loss: 0.621307\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553065; batch adversarial loss: 0.598104\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561629; batch adversarial loss: 0.642036\n",
      "epoch 6; iter: 0; batch classifier loss: 0.633446; batch adversarial loss: 0.606373\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519458; batch adversarial loss: 0.617101\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553290; batch adversarial loss: 0.604082\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488670; batch adversarial loss: 0.593677\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559101; batch adversarial loss: 0.597721\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567791; batch adversarial loss: 0.541497\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506598; batch adversarial loss: 0.562929\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569066; batch adversarial loss: 0.634924\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499541; batch adversarial loss: 0.541672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554920; batch adversarial loss: 0.564291\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486575; batch adversarial loss: 0.544824\n",
      "epoch 17; iter: 0; batch classifier loss: 0.461653; batch adversarial loss: 0.577967\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539192; batch adversarial loss: 0.539307\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497011; batch adversarial loss: 0.559458\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476595; batch adversarial loss: 0.526301\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484917; batch adversarial loss: 0.549801\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483782; batch adversarial loss: 0.580781\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528829; batch adversarial loss: 0.587542\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474065; batch adversarial loss: 0.554864\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499143; batch adversarial loss: 0.504455\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480274; batch adversarial loss: 0.553804\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511974; batch adversarial loss: 0.580186\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516216; batch adversarial loss: 0.650472\n",
      "epoch 29; iter: 0; batch classifier loss: 0.551493; batch adversarial loss: 0.536825\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431814; batch adversarial loss: 0.509495\n",
      "epoch 31; iter: 0; batch classifier loss: 0.397406; batch adversarial loss: 0.509200\n",
      "epoch 32; iter: 0; batch classifier loss: 0.486177; batch adversarial loss: 0.517906\n",
      "epoch 33; iter: 0; batch classifier loss: 0.427407; batch adversarial loss: 0.553413\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421190; batch adversarial loss: 0.580546\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451599; batch adversarial loss: 0.481045\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473629; batch adversarial loss: 0.572857\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477218; batch adversarial loss: 0.517584\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422094; batch adversarial loss: 0.451781\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441776; batch adversarial loss: 0.567169\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396745; batch adversarial loss: 0.517601\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407479; batch adversarial loss: 0.523895\n",
      "epoch 42; iter: 0; batch classifier loss: 0.487949; batch adversarial loss: 0.507450\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469974; batch adversarial loss: 0.534650\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412150; batch adversarial loss: 0.503321\n",
      "epoch 45; iter: 0; batch classifier loss: 0.358473; batch adversarial loss: 0.524870\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402939; batch adversarial loss: 0.615248\n",
      "epoch 47; iter: 0; batch classifier loss: 0.530762; batch adversarial loss: 0.577582\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435613; batch adversarial loss: 0.498679\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443898; batch adversarial loss: 0.615505\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420139; batch adversarial loss: 0.496618\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416030; batch adversarial loss: 0.607775\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449684; batch adversarial loss: 0.523399\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417292; batch adversarial loss: 0.538047\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469656; batch adversarial loss: 0.511739\n",
      "epoch 55; iter: 0; batch classifier loss: 0.370129; batch adversarial loss: 0.572235\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442640; batch adversarial loss: 0.495156\n",
      "epoch 57; iter: 0; batch classifier loss: 0.381048; batch adversarial loss: 0.495592\n",
      "epoch 58; iter: 0; batch classifier loss: 0.375225; batch adversarial loss: 0.494728\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400726; batch adversarial loss: 0.472707\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414705; batch adversarial loss: 0.537460\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410794; batch adversarial loss: 0.534221\n",
      "epoch 62; iter: 0; batch classifier loss: 0.477603; batch adversarial loss: 0.586160\n",
      "epoch 63; iter: 0; batch classifier loss: 0.478146; batch adversarial loss: 0.516058\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413424; batch adversarial loss: 0.536080\n",
      "epoch 65; iter: 0; batch classifier loss: 0.476827; batch adversarial loss: 0.488315\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430321; batch adversarial loss: 0.594248\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444841; batch adversarial loss: 0.523813\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418905; batch adversarial loss: 0.575009\n",
      "epoch 69; iter: 0; batch classifier loss: 0.468912; batch adversarial loss: 0.552271\n",
      "epoch 70; iter: 0; batch classifier loss: 0.356261; batch adversarial loss: 0.552970\n",
      "epoch 71; iter: 0; batch classifier loss: 0.375608; batch adversarial loss: 0.582997\n",
      "epoch 72; iter: 0; batch classifier loss: 0.423202; batch adversarial loss: 0.542843\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410356; batch adversarial loss: 0.542812\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385049; batch adversarial loss: 0.531540\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457731; batch adversarial loss: 0.599259\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376664; batch adversarial loss: 0.528892\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392023; batch adversarial loss: 0.571585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.357603; batch adversarial loss: 0.540956\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413874; batch adversarial loss: 0.548646\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430707; batch adversarial loss: 0.513762\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429123; batch adversarial loss: 0.581887\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352156; batch adversarial loss: 0.525565\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415480; batch adversarial loss: 0.558548\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392746; batch adversarial loss: 0.557454\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406097; batch adversarial loss: 0.509160\n",
      "epoch 86; iter: 0; batch classifier loss: 0.454877; batch adversarial loss: 0.574346\n",
      "epoch 87; iter: 0; batch classifier loss: 0.346309; batch adversarial loss: 0.561610\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357531; batch adversarial loss: 0.563701\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452772; batch adversarial loss: 0.564870\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391433; batch adversarial loss: 0.542566\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366262; batch adversarial loss: 0.542886\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386533; batch adversarial loss: 0.552184\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349556; batch adversarial loss: 0.536237\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411618; batch adversarial loss: 0.516908\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365427; batch adversarial loss: 0.554725\n",
      "epoch 96; iter: 0; batch classifier loss: 0.318584; batch adversarial loss: 0.471435\n",
      "epoch 97; iter: 0; batch classifier loss: 0.439208; batch adversarial loss: 0.564458\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375501; batch adversarial loss: 0.567120\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357256; batch adversarial loss: 0.507665\n",
      "epoch 100; iter: 0; batch classifier loss: 0.487083; batch adversarial loss: 0.510257\n",
      "epoch 101; iter: 0; batch classifier loss: 0.424121; batch adversarial loss: 0.461927\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367177; batch adversarial loss: 0.532408\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417725; batch adversarial loss: 0.543826\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420002; batch adversarial loss: 0.472001\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337403; batch adversarial loss: 0.553771\n",
      "epoch 106; iter: 0; batch classifier loss: 0.521859; batch adversarial loss: 0.683460\n",
      "epoch 107; iter: 0; batch classifier loss: 0.440163; batch adversarial loss: 0.480689\n",
      "epoch 108; iter: 0; batch classifier loss: 0.358994; batch adversarial loss: 0.590180\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371353; batch adversarial loss: 0.583027\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370117; batch adversarial loss: 0.589265\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356970; batch adversarial loss: 0.516211\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435246; batch adversarial loss: 0.497951\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374490; batch adversarial loss: 0.551840\n",
      "epoch 114; iter: 0; batch classifier loss: 0.342792; batch adversarial loss: 0.523346\n",
      "epoch 115; iter: 0; batch classifier loss: 0.330375; batch adversarial loss: 0.532745\n",
      "epoch 116; iter: 0; batch classifier loss: 0.326727; batch adversarial loss: 0.490092\n",
      "epoch 117; iter: 0; batch classifier loss: 0.282798; batch adversarial loss: 0.508092\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390685; batch adversarial loss: 0.608124\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396294; batch adversarial loss: 0.548087\n",
      "epoch 120; iter: 0; batch classifier loss: 0.456817; batch adversarial loss: 0.488179\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391120; batch adversarial loss: 0.582798\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380547; batch adversarial loss: 0.513049\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362863; batch adversarial loss: 0.525851\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365218; batch adversarial loss: 0.505959\n",
      "epoch 125; iter: 0; batch classifier loss: 0.476049; batch adversarial loss: 0.546043\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386398; batch adversarial loss: 0.516117\n",
      "epoch 127; iter: 0; batch classifier loss: 0.429962; batch adversarial loss: 0.528843\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367458; batch adversarial loss: 0.561053\n",
      "epoch 129; iter: 0; batch classifier loss: 0.412242; batch adversarial loss: 0.551271\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413735; batch adversarial loss: 0.592031\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383013; batch adversarial loss: 0.646787\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371411; batch adversarial loss: 0.541481\n",
      "epoch 133; iter: 0; batch classifier loss: 0.317205; batch adversarial loss: 0.498009\n",
      "epoch 134; iter: 0; batch classifier loss: 0.450553; batch adversarial loss: 0.523746\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353784; batch adversarial loss: 0.531422\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365956; batch adversarial loss: 0.578683\n",
      "epoch 137; iter: 0; batch classifier loss: 0.412949; batch adversarial loss: 0.527840\n",
      "epoch 138; iter: 0; batch classifier loss: 0.399717; batch adversarial loss: 0.525520\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346549; batch adversarial loss: 0.532943\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340851; batch adversarial loss: 0.548386\n",
      "epoch 141; iter: 0; batch classifier loss: 0.467928; batch adversarial loss: 0.601555\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386995; batch adversarial loss: 0.523723\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396878; batch adversarial loss: 0.554030\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365568; batch adversarial loss: 0.557452\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333001; batch adversarial loss: 0.480008\n",
      "epoch 146; iter: 0; batch classifier loss: 0.354761; batch adversarial loss: 0.509484\n",
      "epoch 147; iter: 0; batch classifier loss: 0.433847; batch adversarial loss: 0.593540\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334969; batch adversarial loss: 0.561421\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352571; batch adversarial loss: 0.499463\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391733; batch adversarial loss: 0.571106\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361885; batch adversarial loss: 0.493941\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343619; batch adversarial loss: 0.530231\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329124; batch adversarial loss: 0.478887\n",
      "epoch 154; iter: 0; batch classifier loss: 0.303026; batch adversarial loss: 0.545185\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388107; batch adversarial loss: 0.519421\n",
      "epoch 156; iter: 0; batch classifier loss: 0.414400; batch adversarial loss: 0.533748\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350316; batch adversarial loss: 0.577046\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364813; batch adversarial loss: 0.585266\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349798; batch adversarial loss: 0.516215\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320787; batch adversarial loss: 0.505215\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316278; batch adversarial loss: 0.523368\n",
      "epoch 162; iter: 0; batch classifier loss: 0.443369; batch adversarial loss: 0.564060\n",
      "epoch 163; iter: 0; batch classifier loss: 0.393219; batch adversarial loss: 0.593238\n",
      "epoch 164; iter: 0; batch classifier loss: 0.415659; batch adversarial loss: 0.542129\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393038; batch adversarial loss: 0.552879\n",
      "epoch 166; iter: 0; batch classifier loss: 0.341167; batch adversarial loss: 0.515597\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367773; batch adversarial loss: 0.489726\n",
      "epoch 168; iter: 0; batch classifier loss: 0.396988; batch adversarial loss: 0.522992\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371626; batch adversarial loss: 0.507946\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386925; batch adversarial loss: 0.609714\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380198; batch adversarial loss: 0.592891\n",
      "epoch 172; iter: 0; batch classifier loss: 0.412261; batch adversarial loss: 0.582147\n",
      "epoch 173; iter: 0; batch classifier loss: 0.389637; batch adversarial loss: 0.582145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.400131; batch adversarial loss: 0.527001\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342804; batch adversarial loss: 0.572796\n",
      "epoch 176; iter: 0; batch classifier loss: 0.309688; batch adversarial loss: 0.556165\n",
      "epoch 177; iter: 0; batch classifier loss: 0.414307; batch adversarial loss: 0.561282\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332239; batch adversarial loss: 0.529030\n",
      "epoch 179; iter: 0; batch classifier loss: 0.451893; batch adversarial loss: 0.598985\n",
      "epoch 180; iter: 0; batch classifier loss: 0.413169; batch adversarial loss: 0.479562\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365204; batch adversarial loss: 0.571835\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342148; batch adversarial loss: 0.540086\n",
      "epoch 183; iter: 0; batch classifier loss: 0.400940; batch adversarial loss: 0.579325\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332037; batch adversarial loss: 0.529753\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349002; batch adversarial loss: 0.575175\n",
      "epoch 186; iter: 0; batch classifier loss: 0.492213; batch adversarial loss: 0.481776\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374453; batch adversarial loss: 0.540829\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353922; batch adversarial loss: 0.576136\n",
      "epoch 189; iter: 0; batch classifier loss: 0.293467; batch adversarial loss: 0.535743\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332848; batch adversarial loss: 0.491733\n",
      "epoch 191; iter: 0; batch classifier loss: 0.307376; batch adversarial loss: 0.568348\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335162; batch adversarial loss: 0.575797\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360920; batch adversarial loss: 0.471964\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338944; batch adversarial loss: 0.517219\n",
      "epoch 195; iter: 0; batch classifier loss: 0.384527; batch adversarial loss: 0.566327\n",
      "epoch 196; iter: 0; batch classifier loss: 0.493947; batch adversarial loss: 0.470269\n",
      "epoch 197; iter: 0; batch classifier loss: 0.343319; batch adversarial loss: 0.610683\n",
      "epoch 198; iter: 0; batch classifier loss: 0.271301; batch adversarial loss: 0.548913\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330890; batch adversarial loss: 0.547722\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702601; batch adversarial loss: 0.746321\n",
      "epoch 1; iter: 0; batch classifier loss: 0.723411; batch adversarial loss: 0.717284\n",
      "epoch 2; iter: 0; batch classifier loss: 0.649573; batch adversarial loss: 0.658839\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612225; batch adversarial loss: 0.621511\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546594; batch adversarial loss: 0.626223\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512180; batch adversarial loss: 0.607088\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544624; batch adversarial loss: 0.623249\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532190; batch adversarial loss: 0.606233\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531069; batch adversarial loss: 0.606087\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510427; batch adversarial loss: 0.596648\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484975; batch adversarial loss: 0.574739\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528048; batch adversarial loss: 0.550179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567596; batch adversarial loss: 0.570093\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513987; batch adversarial loss: 0.629700\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538654; batch adversarial loss: 0.556067\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513664; batch adversarial loss: 0.530544\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523383; batch adversarial loss: 0.544923\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529542; batch adversarial loss: 0.563417\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511280; batch adversarial loss: 0.665170\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519836; batch adversarial loss: 0.542606\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478189; batch adversarial loss: 0.538075\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542165; batch adversarial loss: 0.539751\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502609; batch adversarial loss: 0.567260\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485255; batch adversarial loss: 0.476103\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516792; batch adversarial loss: 0.570976\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493417; batch adversarial loss: 0.532896\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476275; batch adversarial loss: 0.601582\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470501; batch adversarial loss: 0.521890\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487335; batch adversarial loss: 0.551035\n",
      "epoch 29; iter: 0; batch classifier loss: 0.519507; batch adversarial loss: 0.580676\n",
      "epoch 30; iter: 0; batch classifier loss: 0.511080; batch adversarial loss: 0.488812\n",
      "epoch 31; iter: 0; batch classifier loss: 0.503990; batch adversarial loss: 0.523859\n",
      "epoch 32; iter: 0; batch classifier loss: 0.475455; batch adversarial loss: 0.547071\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472279; batch adversarial loss: 0.522876\n",
      "epoch 34; iter: 0; batch classifier loss: 0.515556; batch adversarial loss: 0.564241\n",
      "epoch 35; iter: 0; batch classifier loss: 0.503027; batch adversarial loss: 0.576632\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464089; batch adversarial loss: 0.512845\n",
      "epoch 37; iter: 0; batch classifier loss: 0.522280; batch adversarial loss: 0.596004\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417991; batch adversarial loss: 0.494286\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455986; batch adversarial loss: 0.517475\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470605; batch adversarial loss: 0.497825\n",
      "epoch 41; iter: 0; batch classifier loss: 0.533298; batch adversarial loss: 0.462189\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440396; batch adversarial loss: 0.487018\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460125; batch adversarial loss: 0.542293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.512232; batch adversarial loss: 0.511241\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478372; batch adversarial loss: 0.486619\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447732; batch adversarial loss: 0.580512\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504462; batch adversarial loss: 0.475235\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396128; batch adversarial loss: 0.565726\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422377; batch adversarial loss: 0.573671\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441940; batch adversarial loss: 0.616080\n",
      "epoch 51; iter: 0; batch classifier loss: 0.401498; batch adversarial loss: 0.528726\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420254; batch adversarial loss: 0.508127\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458902; batch adversarial loss: 0.572093\n",
      "epoch 54; iter: 0; batch classifier loss: 0.491292; batch adversarial loss: 0.526576\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441532; batch adversarial loss: 0.599305\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413874; batch adversarial loss: 0.507269\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454842; batch adversarial loss: 0.535574\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424479; batch adversarial loss: 0.506818\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412793; batch adversarial loss: 0.489657\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432738; batch adversarial loss: 0.516481\n",
      "epoch 61; iter: 0; batch classifier loss: 0.471829; batch adversarial loss: 0.488312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396825; batch adversarial loss: 0.479198\n",
      "epoch 63; iter: 0; batch classifier loss: 0.462183; batch adversarial loss: 0.525656\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454486; batch adversarial loss: 0.534946\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395668; batch adversarial loss: 0.572226\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439669; batch adversarial loss: 0.572721\n",
      "epoch 67; iter: 0; batch classifier loss: 0.383294; batch adversarial loss: 0.553741\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424705; batch adversarial loss: 0.649412\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428803; batch adversarial loss: 0.477897\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425820; batch adversarial loss: 0.582994\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412626; batch adversarial loss: 0.535027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.428073; batch adversarial loss: 0.450191\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367229; batch adversarial loss: 0.600189\n",
      "epoch 74; iter: 0; batch classifier loss: 0.343797; batch adversarial loss: 0.601985\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429390; batch adversarial loss: 0.564050\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369053; batch adversarial loss: 0.498350\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435390; batch adversarial loss: 0.552831\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368887; batch adversarial loss: 0.573923\n",
      "epoch 79; iter: 0; batch classifier loss: 0.474514; batch adversarial loss: 0.459498\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432467; batch adversarial loss: 0.497431\n",
      "epoch 81; iter: 0; batch classifier loss: 0.341303; batch adversarial loss: 0.535998\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367264; batch adversarial loss: 0.525860\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394883; batch adversarial loss: 0.516940\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366592; batch adversarial loss: 0.497716\n",
      "epoch 85; iter: 0; batch classifier loss: 0.443633; batch adversarial loss: 0.488191\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403562; batch adversarial loss: 0.592614\n",
      "epoch 87; iter: 0; batch classifier loss: 0.346285; batch adversarial loss: 0.592262\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386051; batch adversarial loss: 0.487169\n",
      "epoch 89; iter: 0; batch classifier loss: 0.359982; batch adversarial loss: 0.553441\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399925; batch adversarial loss: 0.563228\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376368; batch adversarial loss: 0.469259\n",
      "epoch 92; iter: 0; batch classifier loss: 0.460227; batch adversarial loss: 0.554328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.610996\n",
      "epoch 94; iter: 0; batch classifier loss: 0.468583; batch adversarial loss: 0.525160\n",
      "epoch 95; iter: 0; batch classifier loss: 0.438774; batch adversarial loss: 0.582592\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370565; batch adversarial loss: 0.563661\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369191; batch adversarial loss: 0.581638\n",
      "epoch 98; iter: 0; batch classifier loss: 0.350275; batch adversarial loss: 0.497535\n",
      "epoch 99; iter: 0; batch classifier loss: 0.458597; batch adversarial loss: 0.534949\n",
      "epoch 100; iter: 0; batch classifier loss: 0.451107; batch adversarial loss: 0.430409\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370933; batch adversarial loss: 0.554085\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385648; batch adversarial loss: 0.526392\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354919; batch adversarial loss: 0.525722\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434933; batch adversarial loss: 0.497253\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404085; batch adversarial loss: 0.582118\n",
      "epoch 106; iter: 0; batch classifier loss: 0.312421; batch adversarial loss: 0.496171\n",
      "epoch 107; iter: 0; batch classifier loss: 0.447685; batch adversarial loss: 0.516669\n",
      "epoch 108; iter: 0; batch classifier loss: 0.438685; batch adversarial loss: 0.516575\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397331; batch adversarial loss: 0.562688\n",
      "epoch 110; iter: 0; batch classifier loss: 0.358213; batch adversarial loss: 0.591590\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388936; batch adversarial loss: 0.534975\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379965; batch adversarial loss: 0.582662\n",
      "epoch 113; iter: 0; batch classifier loss: 0.388860; batch adversarial loss: 0.506395\n",
      "epoch 114; iter: 0; batch classifier loss: 0.322529; batch adversarial loss: 0.621184\n",
      "epoch 115; iter: 0; batch classifier loss: 0.435076; batch adversarial loss: 0.534326\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371280; batch adversarial loss: 0.563689\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402812; batch adversarial loss: 0.534939\n",
      "epoch 118; iter: 0; batch classifier loss: 0.459371; batch adversarial loss: 0.554635\n",
      "epoch 119; iter: 0; batch classifier loss: 0.365853; batch adversarial loss: 0.554379\n",
      "epoch 120; iter: 0; batch classifier loss: 0.365854; batch adversarial loss: 0.620239\n",
      "epoch 121; iter: 0; batch classifier loss: 0.410110; batch adversarial loss: 0.544601\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388947; batch adversarial loss: 0.468405\n",
      "epoch 123; iter: 0; batch classifier loss: 0.426739; batch adversarial loss: 0.574463\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347438; batch adversarial loss: 0.601122\n",
      "epoch 125; iter: 0; batch classifier loss: 0.403311; batch adversarial loss: 0.563623\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379799; batch adversarial loss: 0.497150\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371990; batch adversarial loss: 0.487869\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353611; batch adversarial loss: 0.477537\n",
      "epoch 129; iter: 0; batch classifier loss: 0.330946; batch adversarial loss: 0.506381\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370888; batch adversarial loss: 0.564236\n",
      "epoch 131; iter: 0; batch classifier loss: 0.423710; batch adversarial loss: 0.526733\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372181; batch adversarial loss: 0.467847\n",
      "epoch 133; iter: 0; batch classifier loss: 0.321004; batch adversarial loss: 0.506339\n",
      "epoch 134; iter: 0; batch classifier loss: 0.326898; batch adversarial loss: 0.534381\n",
      "epoch 135; iter: 0; batch classifier loss: 0.318491; batch adversarial loss: 0.553863\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389012; batch adversarial loss: 0.468854\n",
      "epoch 137; iter: 0; batch classifier loss: 0.327155; batch adversarial loss: 0.563667\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345281; batch adversarial loss: 0.478478\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373836; batch adversarial loss: 0.554730\n",
      "epoch 140; iter: 0; batch classifier loss: 0.444921; batch adversarial loss: 0.487009\n",
      "epoch 141; iter: 0; batch classifier loss: 0.463529; batch adversarial loss: 0.544995\n",
      "epoch 142; iter: 0; batch classifier loss: 0.428130; batch adversarial loss: 0.516522\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405207; batch adversarial loss: 0.592037\n",
      "epoch 144; iter: 0; batch classifier loss: 0.422442; batch adversarial loss: 0.516384\n",
      "epoch 145; iter: 0; batch classifier loss: 0.396382; batch adversarial loss: 0.506663\n",
      "epoch 146; iter: 0; batch classifier loss: 0.398351; batch adversarial loss: 0.468078\n",
      "epoch 147; iter: 0; batch classifier loss: 0.479885; batch adversarial loss: 0.535356\n",
      "epoch 148; iter: 0; batch classifier loss: 0.418736; batch adversarial loss: 0.459166\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354413; batch adversarial loss: 0.487271\n",
      "epoch 150; iter: 0; batch classifier loss: 0.393869; batch adversarial loss: 0.525677\n",
      "epoch 151; iter: 0; batch classifier loss: 0.483995; batch adversarial loss: 0.535206\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353167; batch adversarial loss: 0.496522\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324420; batch adversarial loss: 0.544857\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332986; batch adversarial loss: 0.506584\n",
      "epoch 155; iter: 0; batch classifier loss: 0.277503; batch adversarial loss: 0.497104\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401959; batch adversarial loss: 0.516234\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346631; batch adversarial loss: 0.563679\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347033; batch adversarial loss: 0.516127\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333968; batch adversarial loss: 0.535423\n",
      "epoch 160; iter: 0; batch classifier loss: 0.399138; batch adversarial loss: 0.553538\n",
      "epoch 161; iter: 0; batch classifier loss: 0.340282; batch adversarial loss: 0.468394\n",
      "epoch 162; iter: 0; batch classifier loss: 0.427051; batch adversarial loss: 0.448966\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385796; batch adversarial loss: 0.555126\n",
      "epoch 164; iter: 0; batch classifier loss: 0.295977; batch adversarial loss: 0.487897\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330155; batch adversarial loss: 0.564240\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388868; batch adversarial loss: 0.582280\n",
      "epoch 167; iter: 0; batch classifier loss: 0.311162; batch adversarial loss: 0.469488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.415696; batch adversarial loss: 0.600716\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341720; batch adversarial loss: 0.516229\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315722; batch adversarial loss: 0.553664\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336080; batch adversarial loss: 0.525647\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389505; batch adversarial loss: 0.572072\n",
      "epoch 173; iter: 0; batch classifier loss: 0.390092; batch adversarial loss: 0.515985\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400598; batch adversarial loss: 0.582009\n",
      "epoch 175; iter: 0; batch classifier loss: 0.518025; batch adversarial loss: 0.611031\n",
      "epoch 176; iter: 0; batch classifier loss: 0.389390; batch adversarial loss: 0.487081\n",
      "epoch 177; iter: 0; batch classifier loss: 0.278605; batch adversarial loss: 0.516186\n",
      "epoch 178; iter: 0; batch classifier loss: 0.325684; batch adversarial loss: 0.459202\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350067; batch adversarial loss: 0.535364\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362522; batch adversarial loss: 0.497226\n",
      "epoch 181; iter: 0; batch classifier loss: 0.435434; batch adversarial loss: 0.506397\n",
      "epoch 182; iter: 0; batch classifier loss: 0.305393; batch adversarial loss: 0.496484\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369899; batch adversarial loss: 0.591405\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348972; batch adversarial loss: 0.534813\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390160; batch adversarial loss: 0.506391\n",
      "epoch 186; iter: 0; batch classifier loss: 0.410848; batch adversarial loss: 0.573178\n",
      "epoch 187; iter: 0; batch classifier loss: 0.386102; batch adversarial loss: 0.554814\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343048; batch adversarial loss: 0.611629\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335134; batch adversarial loss: 0.487481\n",
      "epoch 190; iter: 0; batch classifier loss: 0.392736; batch adversarial loss: 0.564166\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356924; batch adversarial loss: 0.525747\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336995; batch adversarial loss: 0.478560\n",
      "epoch 193; iter: 0; batch classifier loss: 0.339577; batch adversarial loss: 0.610165\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384392; batch adversarial loss: 0.497293\n",
      "epoch 195; iter: 0; batch classifier loss: 0.415494; batch adversarial loss: 0.601446\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346469; batch adversarial loss: 0.591711\n",
      "epoch 197; iter: 0; batch classifier loss: 0.450869; batch adversarial loss: 0.544920\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356515; batch adversarial loss: 0.526003\n",
      "epoch 199; iter: 0; batch classifier loss: 0.393740; batch adversarial loss: 0.477813\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679099; batch adversarial loss: 0.755533\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581868; batch adversarial loss: 0.732372\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575308; batch adversarial loss: 0.705985\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538559; batch adversarial loss: 0.666545\n",
      "epoch 4; iter: 0; batch classifier loss: 0.488770; batch adversarial loss: 0.686383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515395; batch adversarial loss: 0.639269\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486655; batch adversarial loss: 0.654673\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568143; batch adversarial loss: 0.625687\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464653; batch adversarial loss: 0.604794\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458942; batch adversarial loss: 0.591550\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491731; batch adversarial loss: 0.586126\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526230; batch adversarial loss: 0.561574\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538539; batch adversarial loss: 0.599749\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548275; batch adversarial loss: 0.558567\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469636; batch adversarial loss: 0.571699\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485491; batch adversarial loss: 0.549798\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483223; batch adversarial loss: 0.550385\n",
      "epoch 17; iter: 0; batch classifier loss: 0.502054; batch adversarial loss: 0.525589\n",
      "epoch 18; iter: 0; batch classifier loss: 0.424974; batch adversarial loss: 0.523524\n",
      "epoch 19; iter: 0; batch classifier loss: 0.388489; batch adversarial loss: 0.559633\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485456; batch adversarial loss: 0.557817\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475937; batch adversarial loss: 0.563976\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485512; batch adversarial loss: 0.563478\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475537; batch adversarial loss: 0.617682\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503860; batch adversarial loss: 0.618721\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462649; batch adversarial loss: 0.588706\n",
      "epoch 26; iter: 0; batch classifier loss: 0.447122; batch adversarial loss: 0.591597\n",
      "epoch 27; iter: 0; batch classifier loss: 0.538193; batch adversarial loss: 0.580320\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429049; batch adversarial loss: 0.560642\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422050; batch adversarial loss: 0.596411\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468790; batch adversarial loss: 0.525908\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422783; batch adversarial loss: 0.581923\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439626; batch adversarial loss: 0.532960\n",
      "epoch 33; iter: 0; batch classifier loss: 0.419988; batch adversarial loss: 0.572276\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415803; batch adversarial loss: 0.574042\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412182; batch adversarial loss: 0.521598\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430221; batch adversarial loss: 0.571887\n",
      "epoch 37; iter: 0; batch classifier loss: 0.384970; batch adversarial loss: 0.579551\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442543; batch adversarial loss: 0.537197\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464815; batch adversarial loss: 0.545425\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431038; batch adversarial loss: 0.562437\n",
      "epoch 41; iter: 0; batch classifier loss: 0.546651; batch adversarial loss: 0.613462\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477765; batch adversarial loss: 0.553814\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365088; batch adversarial loss: 0.613860\n",
      "epoch 44; iter: 0; batch classifier loss: 0.503845; batch adversarial loss: 0.580043\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421873; batch adversarial loss: 0.588700\n",
      "epoch 46; iter: 0; batch classifier loss: 0.453810; batch adversarial loss: 0.542704\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447021; batch adversarial loss: 0.544206\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437415; batch adversarial loss: 0.631407\n",
      "epoch 49; iter: 0; batch classifier loss: 0.387476; batch adversarial loss: 0.598735\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418778; batch adversarial loss: 0.678165\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421871; batch adversarial loss: 0.622404\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400636; batch adversarial loss: 0.526941\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384405; batch adversarial loss: 0.562226\n",
      "epoch 54; iter: 0; batch classifier loss: 0.487745; batch adversarial loss: 0.535665\n",
      "epoch 55; iter: 0; batch classifier loss: 0.360823; batch adversarial loss: 0.572150\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420373; batch adversarial loss: 0.543662\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424170; batch adversarial loss: 0.614399\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380968; batch adversarial loss: 0.596410\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428746; batch adversarial loss: 0.557250\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412542; batch adversarial loss: 0.651214\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441203; batch adversarial loss: 0.604331\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392565; batch adversarial loss: 0.545986\n",
      "epoch 63; iter: 0; batch classifier loss: 0.373518; batch adversarial loss: 0.544179\n",
      "epoch 64; iter: 0; batch classifier loss: 0.360551; batch adversarial loss: 0.514386\n",
      "epoch 65; iter: 0; batch classifier loss: 0.361476; batch adversarial loss: 0.543136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.454273; batch adversarial loss: 0.503927\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387101; batch adversarial loss: 0.598049\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382787; batch adversarial loss: 0.545343\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410593; batch adversarial loss: 0.583724\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476497; batch adversarial loss: 0.510069\n",
      "epoch 71; iter: 0; batch classifier loss: 0.433587; batch adversarial loss: 0.546426\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376881; batch adversarial loss: 0.554035\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373645; batch adversarial loss: 0.546230\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390454; batch adversarial loss: 0.529520\n",
      "epoch 75; iter: 0; batch classifier loss: 0.345689; batch adversarial loss: 0.650758\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398947; batch adversarial loss: 0.604816\n",
      "epoch 77; iter: 0; batch classifier loss: 0.480520; batch adversarial loss: 0.581768\n",
      "epoch 78; iter: 0; batch classifier loss: 0.343897; batch adversarial loss: 0.535457\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403841; batch adversarial loss: 0.499554\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370732; batch adversarial loss: 0.489829\n",
      "epoch 81; iter: 0; batch classifier loss: 0.420798; batch adversarial loss: 0.559542\n",
      "epoch 82; iter: 0; batch classifier loss: 0.347120; batch adversarial loss: 0.544417\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417360; batch adversarial loss: 0.526137\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411267; batch adversarial loss: 0.535948\n",
      "epoch 85; iter: 0; batch classifier loss: 0.379171; batch adversarial loss: 0.482090\n",
      "epoch 86; iter: 0; batch classifier loss: 0.376815; batch adversarial loss: 0.465259\n",
      "epoch 87; iter: 0; batch classifier loss: 0.291197; batch adversarial loss: 0.543927\n",
      "epoch 88; iter: 0; batch classifier loss: 0.307208; batch adversarial loss: 0.498251\n",
      "epoch 89; iter: 0; batch classifier loss: 0.472255; batch adversarial loss: 0.616596\n",
      "epoch 90; iter: 0; batch classifier loss: 0.312784; batch adversarial loss: 0.590561\n",
      "epoch 91; iter: 0; batch classifier loss: 0.435394; batch adversarial loss: 0.533747\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402239; batch adversarial loss: 0.519965\n",
      "epoch 93; iter: 0; batch classifier loss: 0.345789; batch adversarial loss: 0.590100\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336325; batch adversarial loss: 0.558990\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364138; batch adversarial loss: 0.497447\n",
      "epoch 96; iter: 0; batch classifier loss: 0.312416; batch adversarial loss: 0.515288\n",
      "epoch 97; iter: 0; batch classifier loss: 0.434457; batch adversarial loss: 0.543073\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416827; batch adversarial loss: 0.515141\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384612; batch adversarial loss: 0.591555\n",
      "epoch 100; iter: 0; batch classifier loss: 0.310020; batch adversarial loss: 0.565645\n",
      "epoch 101; iter: 0; batch classifier loss: 0.317731; batch adversarial loss: 0.511018\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374827; batch adversarial loss: 0.534749\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401775; batch adversarial loss: 0.597944\n",
      "epoch 104; iter: 0; batch classifier loss: 0.335117; batch adversarial loss: 0.526722\n",
      "epoch 105; iter: 0; batch classifier loss: 0.353214; batch adversarial loss: 0.608602\n",
      "epoch 106; iter: 0; batch classifier loss: 0.347311; batch adversarial loss: 0.613356\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354851; batch adversarial loss: 0.608311\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387356; batch adversarial loss: 0.502248\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403583; batch adversarial loss: 0.484752\n",
      "epoch 110; iter: 0; batch classifier loss: 0.321920; batch adversarial loss: 0.564814\n",
      "epoch 111; iter: 0; batch classifier loss: 0.314820; batch adversarial loss: 0.448484\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363474; batch adversarial loss: 0.597336\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356315; batch adversarial loss: 0.597241\n",
      "epoch 114; iter: 0; batch classifier loss: 0.361476; batch adversarial loss: 0.535779\n",
      "epoch 115; iter: 0; batch classifier loss: 0.321645; batch adversarial loss: 0.562804\n",
      "epoch 116; iter: 0; batch classifier loss: 0.337792; batch adversarial loss: 0.562654\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338258; batch adversarial loss: 0.542776\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351793; batch adversarial loss: 0.570143\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374468; batch adversarial loss: 0.505485\n",
      "epoch 120; iter: 0; batch classifier loss: 0.393125; batch adversarial loss: 0.562558\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335573; batch adversarial loss: 0.552271\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376397; batch adversarial loss: 0.580198\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409686; batch adversarial loss: 0.554758\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386278; batch adversarial loss: 0.579093\n",
      "epoch 125; iter: 0; batch classifier loss: 0.363665; batch adversarial loss: 0.499299\n",
      "epoch 126; iter: 0; batch classifier loss: 0.295165; batch adversarial loss: 0.552977\n",
      "epoch 127; iter: 0; batch classifier loss: 0.323373; batch adversarial loss: 0.660003\n",
      "epoch 128; iter: 0; batch classifier loss: 0.320298; batch adversarial loss: 0.490342\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342417; batch adversarial loss: 0.560913\n",
      "epoch 130; iter: 0; batch classifier loss: 0.379949; batch adversarial loss: 0.542453\n",
      "epoch 131; iter: 0; batch classifier loss: 0.288111; batch adversarial loss: 0.595344\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323616; batch adversarial loss: 0.544753\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353963; batch adversarial loss: 0.562487\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367182; batch adversarial loss: 0.517104\n",
      "epoch 135; iter: 0; batch classifier loss: 0.304685; batch adversarial loss: 0.465912\n",
      "epoch 136; iter: 0; batch classifier loss: 0.498258; batch adversarial loss: 0.527599\n",
      "epoch 137; iter: 0; batch classifier loss: 0.336925; batch adversarial loss: 0.482443\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338827; batch adversarial loss: 0.615615\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313310; batch adversarial loss: 0.598956\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348852; batch adversarial loss: 0.554008\n",
      "epoch 141; iter: 0; batch classifier loss: 0.310141; batch adversarial loss: 0.551435\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384982; batch adversarial loss: 0.490127\n",
      "epoch 143; iter: 0; batch classifier loss: 0.339937; batch adversarial loss: 0.607345\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342753; batch adversarial loss: 0.518191\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398774; batch adversarial loss: 0.571111\n",
      "epoch 146; iter: 0; batch classifier loss: 0.429343; batch adversarial loss: 0.586803\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329664; batch adversarial loss: 0.580833\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378739; batch adversarial loss: 0.608698\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367307; batch adversarial loss: 0.564152\n",
      "epoch 150; iter: 0; batch classifier loss: 0.310151; batch adversarial loss: 0.550217\n",
      "epoch 151; iter: 0; batch classifier loss: 0.404756; batch adversarial loss: 0.521817\n",
      "epoch 152; iter: 0; batch classifier loss: 0.255080; batch adversarial loss: 0.597247\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344309; batch adversarial loss: 0.573499\n",
      "epoch 154; iter: 0; batch classifier loss: 0.439760; batch adversarial loss: 0.563051\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336047; batch adversarial loss: 0.538001\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395151; batch adversarial loss: 0.523296\n",
      "epoch 157; iter: 0; batch classifier loss: 0.354584; batch adversarial loss: 0.507847\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342620; batch adversarial loss: 0.562887\n",
      "epoch 159; iter: 0; batch classifier loss: 0.315993; batch adversarial loss: 0.596837\n",
      "epoch 160; iter: 0; batch classifier loss: 0.434263; batch adversarial loss: 0.526474\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335214; batch adversarial loss: 0.545002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.348077; batch adversarial loss: 0.475501\n",
      "epoch 163; iter: 0; batch classifier loss: 0.466206; batch adversarial loss: 0.564203\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328831; batch adversarial loss: 0.545349\n",
      "epoch 165; iter: 0; batch classifier loss: 0.308783; batch adversarial loss: 0.536395\n",
      "epoch 166; iter: 0; batch classifier loss: 0.403669; batch adversarial loss: 0.545001\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358628; batch adversarial loss: 0.528195\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380954; batch adversarial loss: 0.553677\n",
      "epoch 169; iter: 0; batch classifier loss: 0.314221; batch adversarial loss: 0.563160\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353377; batch adversarial loss: 0.552012\n",
      "epoch 171; iter: 0; batch classifier loss: 0.435894; batch adversarial loss: 0.625849\n",
      "epoch 172; iter: 0; batch classifier loss: 0.312210; batch adversarial loss: 0.569206\n",
      "epoch 173; iter: 0; batch classifier loss: 0.391398; batch adversarial loss: 0.535619\n",
      "epoch 174; iter: 0; batch classifier loss: 0.397193; batch adversarial loss: 0.597144\n",
      "epoch 175; iter: 0; batch classifier loss: 0.316547; batch adversarial loss: 0.542375\n",
      "epoch 176; iter: 0; batch classifier loss: 0.274502; batch adversarial loss: 0.662647\n",
      "epoch 177; iter: 0; batch classifier loss: 0.428000; batch adversarial loss: 0.601005\n",
      "epoch 178; iter: 0; batch classifier loss: 0.321597; batch adversarial loss: 0.553672\n",
      "epoch 179; iter: 0; batch classifier loss: 0.441711; batch adversarial loss: 0.553618\n",
      "epoch 180; iter: 0; batch classifier loss: 0.357866; batch adversarial loss: 0.515824\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338385; batch adversarial loss: 0.647999\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367537; batch adversarial loss: 0.547483\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347646; batch adversarial loss: 0.595190\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375812; batch adversarial loss: 0.590501\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351595; batch adversarial loss: 0.625169\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342695; batch adversarial loss: 0.576337\n",
      "epoch 187; iter: 0; batch classifier loss: 0.414271; batch adversarial loss: 0.597318\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347380; batch adversarial loss: 0.581461\n",
      "epoch 189; iter: 0; batch classifier loss: 0.422967; batch adversarial loss: 0.501693\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332534; batch adversarial loss: 0.561156\n",
      "epoch 191; iter: 0; batch classifier loss: 0.345985; batch adversarial loss: 0.564528\n",
      "epoch 192; iter: 0; batch classifier loss: 0.354395; batch adversarial loss: 0.488806\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402523; batch adversarial loss: 0.554041\n",
      "epoch 194; iter: 0; batch classifier loss: 0.292853; batch adversarial loss: 0.440608\n",
      "epoch 195; iter: 0; batch classifier loss: 0.374336; batch adversarial loss: 0.575046\n",
      "epoch 196; iter: 0; batch classifier loss: 0.395275; batch adversarial loss: 0.544701\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322958; batch adversarial loss: 0.502238\n",
      "epoch 198; iter: 0; batch classifier loss: 0.374960; batch adversarial loss: 0.562915\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386533; batch adversarial loss: 0.536386\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733360; batch adversarial loss: 0.623650\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609194; batch adversarial loss: 0.651067\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583901; batch adversarial loss: 0.621572\n",
      "epoch 3; iter: 0; batch classifier loss: 0.604549; batch adversarial loss: 0.653409\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580509; batch adversarial loss: 0.672895\n",
      "epoch 5; iter: 0; batch classifier loss: 0.615324; batch adversarial loss: 0.641160\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502717; batch adversarial loss: 0.633806\n",
      "epoch 7; iter: 0; batch classifier loss: 0.593097; batch adversarial loss: 0.601515\n",
      "epoch 8; iter: 0; batch classifier loss: 0.647091; batch adversarial loss: 0.587391\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572306; batch adversarial loss: 0.579216\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494416; batch adversarial loss: 0.593958\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586102; batch adversarial loss: 0.556367\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555204; batch adversarial loss: 0.565744\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547814; batch adversarial loss: 0.601129\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512820; batch adversarial loss: 0.586959\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492715; batch adversarial loss: 0.536653\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522618; batch adversarial loss: 0.538307\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485730; batch adversarial loss: 0.475269\n",
      "epoch 18; iter: 0; batch classifier loss: 0.416138; batch adversarial loss: 0.592551\n",
      "epoch 19; iter: 0; batch classifier loss: 0.432500; batch adversarial loss: 0.553953\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506673; batch adversarial loss: 0.512096\n",
      "epoch 21; iter: 0; batch classifier loss: 0.505137; batch adversarial loss: 0.540632\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462858; batch adversarial loss: 0.640135\n",
      "epoch 23; iter: 0; batch classifier loss: 0.405458; batch adversarial loss: 0.554651\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475903; batch adversarial loss: 0.563823\n",
      "epoch 25; iter: 0; batch classifier loss: 0.441007; batch adversarial loss: 0.477295\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428663; batch adversarial loss: 0.545457\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474806; batch adversarial loss: 0.546996\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419330; batch adversarial loss: 0.555638\n",
      "epoch 29; iter: 0; batch classifier loss: 0.401211; batch adversarial loss: 0.570001\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479928; batch adversarial loss: 0.534981\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439459; batch adversarial loss: 0.562959\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444193; batch adversarial loss: 0.556196\n",
      "epoch 33; iter: 0; batch classifier loss: 0.516802; batch adversarial loss: 0.588096\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392195; batch adversarial loss: 0.589540\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446617; batch adversarial loss: 0.580635\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482058; batch adversarial loss: 0.581245\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428261; batch adversarial loss: 0.474507\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475840; batch adversarial loss: 0.535846\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448302; batch adversarial loss: 0.456885\n",
      "epoch 40; iter: 0; batch classifier loss: 0.401788; batch adversarial loss: 0.545467\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420626; batch adversarial loss: 0.500921\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410331; batch adversarial loss: 0.482928\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489291; batch adversarial loss: 0.545718\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474128; batch adversarial loss: 0.607978\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460077; batch adversarial loss: 0.527768\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471060; batch adversarial loss: 0.624191\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418582; batch adversarial loss: 0.535834\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391576; batch adversarial loss: 0.517612\n",
      "epoch 49; iter: 0; batch classifier loss: 0.507058; batch adversarial loss: 0.553474\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435776; batch adversarial loss: 0.608397\n",
      "epoch 51; iter: 0; batch classifier loss: 0.396031; batch adversarial loss: 0.588355\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455323; batch adversarial loss: 0.508292\n",
      "epoch 53; iter: 0; batch classifier loss: 0.478054; batch adversarial loss: 0.499205\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392665; batch adversarial loss: 0.598416\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439574; batch adversarial loss: 0.571081\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445030; batch adversarial loss: 0.524996\n",
      "epoch 57; iter: 0; batch classifier loss: 0.356630; batch adversarial loss: 0.581547\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417848; batch adversarial loss: 0.489865\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476386; batch adversarial loss: 0.580622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.400032; batch adversarial loss: 0.581171\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382513; batch adversarial loss: 0.462489\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386441; batch adversarial loss: 0.569986\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384400; batch adversarial loss: 0.591072\n",
      "epoch 64; iter: 0; batch classifier loss: 0.448324; batch adversarial loss: 0.570375\n",
      "epoch 65; iter: 0; batch classifier loss: 0.525734; batch adversarial loss: 0.491010\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378367; batch adversarial loss: 0.535306\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418108; batch adversarial loss: 0.490390\n",
      "epoch 68; iter: 0; batch classifier loss: 0.360471; batch adversarial loss: 0.563268\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418946; batch adversarial loss: 0.554696\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424272; batch adversarial loss: 0.544371\n",
      "epoch 71; iter: 0; batch classifier loss: 0.323840; batch adversarial loss: 0.563206\n",
      "epoch 72; iter: 0; batch classifier loss: 0.367227; batch adversarial loss: 0.563124\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415831; batch adversarial loss: 0.562727\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380834; batch adversarial loss: 0.509029\n",
      "epoch 75; iter: 0; batch classifier loss: 0.326677; batch adversarial loss: 0.589387\n",
      "epoch 76; iter: 0; batch classifier loss: 0.446057; batch adversarial loss: 0.598307\n",
      "epoch 77; iter: 0; batch classifier loss: 0.431005; batch adversarial loss: 0.518334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394545; batch adversarial loss: 0.537317\n",
      "epoch 79; iter: 0; batch classifier loss: 0.363219; batch adversarial loss: 0.588830\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441668; batch adversarial loss: 0.536660\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424599; batch adversarial loss: 0.553199\n",
      "epoch 82; iter: 0; batch classifier loss: 0.378075; batch adversarial loss: 0.542932\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368207; batch adversarial loss: 0.562294\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407428; batch adversarial loss: 0.508943\n",
      "epoch 85; iter: 0; batch classifier loss: 0.371338; batch adversarial loss: 0.525123\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411433; batch adversarial loss: 0.537182\n",
      "epoch 87; iter: 0; batch classifier loss: 0.419722; batch adversarial loss: 0.544598\n",
      "epoch 88; iter: 0; batch classifier loss: 0.318610; batch adversarial loss: 0.525815\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411623; batch adversarial loss: 0.580374\n",
      "epoch 90; iter: 0; batch classifier loss: 0.389574; batch adversarial loss: 0.610047\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389362; batch adversarial loss: 0.534772\n",
      "epoch 92; iter: 0; batch classifier loss: 0.433273; batch adversarial loss: 0.551677\n",
      "epoch 93; iter: 0; batch classifier loss: 0.459162; batch adversarial loss: 0.515673\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387186; batch adversarial loss: 0.555320\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399700; batch adversarial loss: 0.553805\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418509; batch adversarial loss: 0.517216\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422198; batch adversarial loss: 0.580772\n",
      "epoch 98; iter: 0; batch classifier loss: 0.311537; batch adversarial loss: 0.562407\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378614; batch adversarial loss: 0.525926\n",
      "epoch 100; iter: 0; batch classifier loss: 0.335327; batch adversarial loss: 0.490776\n",
      "epoch 101; iter: 0; batch classifier loss: 0.354393; batch adversarial loss: 0.518061\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372277; batch adversarial loss: 0.489446\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374557; batch adversarial loss: 0.507895\n",
      "epoch 104; iter: 0; batch classifier loss: 0.381745; batch adversarial loss: 0.627244\n",
      "epoch 105; iter: 0; batch classifier loss: 0.374699; batch adversarial loss: 0.542533\n",
      "epoch 106; iter: 0; batch classifier loss: 0.479959; batch adversarial loss: 0.543955\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373153; batch adversarial loss: 0.554097\n",
      "epoch 108; iter: 0; batch classifier loss: 0.434485; batch adversarial loss: 0.518658\n",
      "epoch 109; iter: 0; batch classifier loss: 0.475468; batch adversarial loss: 0.488801\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352028; batch adversarial loss: 0.590989\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387226; batch adversarial loss: 0.536354\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392421; batch adversarial loss: 0.564219\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383755; batch adversarial loss: 0.533349\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368045; batch adversarial loss: 0.462548\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420778; batch adversarial loss: 0.570778\n",
      "epoch 116; iter: 0; batch classifier loss: 0.437753; batch adversarial loss: 0.570560\n",
      "epoch 117; iter: 0; batch classifier loss: 0.302502; batch adversarial loss: 0.510568\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404000; batch adversarial loss: 0.516696\n",
      "epoch 119; iter: 0; batch classifier loss: 0.464210; batch adversarial loss: 0.607569\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377790; batch adversarial loss: 0.571311\n",
      "epoch 121; iter: 0; batch classifier loss: 0.414719; batch adversarial loss: 0.518420\n",
      "epoch 122; iter: 0; batch classifier loss: 0.466310; batch adversarial loss: 0.628062\n",
      "epoch 123; iter: 0; batch classifier loss: 0.426715; batch adversarial loss: 0.554217\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348247; batch adversarial loss: 0.542927\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389140; batch adversarial loss: 0.491072\n",
      "epoch 126; iter: 0; batch classifier loss: 0.393775; batch adversarial loss: 0.590390\n",
      "epoch 127; iter: 0; batch classifier loss: 0.341955; batch adversarial loss: 0.545199\n",
      "epoch 128; iter: 0; batch classifier loss: 0.408325; batch adversarial loss: 0.544341\n",
      "epoch 129; iter: 0; batch classifier loss: 0.353234; batch adversarial loss: 0.642736\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402748; batch adversarial loss: 0.625268\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379365; batch adversarial loss: 0.552868\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382811; batch adversarial loss: 0.500234\n",
      "epoch 133; iter: 0; batch classifier loss: 0.431018; batch adversarial loss: 0.562982\n",
      "epoch 134; iter: 0; batch classifier loss: 0.428254; batch adversarial loss: 0.527794\n",
      "epoch 135; iter: 0; batch classifier loss: 0.291944; batch adversarial loss: 0.543145\n",
      "epoch 136; iter: 0; batch classifier loss: 0.448388; batch adversarial loss: 0.562910\n",
      "epoch 137; iter: 0; batch classifier loss: 0.416681; batch adversarial loss: 0.544132\n",
      "epoch 138; iter: 0; batch classifier loss: 0.441704; batch adversarial loss: 0.500557\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352966; batch adversarial loss: 0.545024\n",
      "epoch 140; iter: 0; batch classifier loss: 0.303447; batch adversarial loss: 0.543345\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329592; batch adversarial loss: 0.544442\n",
      "epoch 142; iter: 0; batch classifier loss: 0.420264; batch adversarial loss: 0.607877\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353902; batch adversarial loss: 0.571832\n",
      "epoch 144; iter: 0; batch classifier loss: 0.433407; batch adversarial loss: 0.562243\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397286; batch adversarial loss: 0.672355\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376558; batch adversarial loss: 0.579503\n",
      "epoch 147; iter: 0; batch classifier loss: 0.380154; batch adversarial loss: 0.490921\n",
      "epoch 148; iter: 0; batch classifier loss: 0.441640; batch adversarial loss: 0.515188\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366724; batch adversarial loss: 0.552302\n",
      "epoch 150; iter: 0; batch classifier loss: 0.415673; batch adversarial loss: 0.517708\n",
      "epoch 151; iter: 0; batch classifier loss: 0.407056; batch adversarial loss: 0.655379\n",
      "epoch 152; iter: 0; batch classifier loss: 0.424528; batch adversarial loss: 0.562280\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407260; batch adversarial loss: 0.535353\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394971; batch adversarial loss: 0.508806\n",
      "epoch 155; iter: 0; batch classifier loss: 0.395801; batch adversarial loss: 0.528274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.323638; batch adversarial loss: 0.454561\n",
      "epoch 157; iter: 0; batch classifier loss: 0.380781; batch adversarial loss: 0.608572\n",
      "epoch 158; iter: 0; batch classifier loss: 0.439263; batch adversarial loss: 0.525546\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398157; batch adversarial loss: 0.498920\n",
      "epoch 160; iter: 0; batch classifier loss: 0.433971; batch adversarial loss: 0.526885\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341706; batch adversarial loss: 0.599116\n",
      "epoch 162; iter: 0; batch classifier loss: 0.287325; batch adversarial loss: 0.534255\n",
      "epoch 163; iter: 0; batch classifier loss: 0.396634; batch adversarial loss: 0.534534\n",
      "epoch 164; iter: 0; batch classifier loss: 0.427682; batch adversarial loss: 0.616488\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348173; batch adversarial loss: 0.535410\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332356; batch adversarial loss: 0.554993\n",
      "epoch 167; iter: 0; batch classifier loss: 0.423243; batch adversarial loss: 0.545301\n",
      "epoch 168; iter: 0; batch classifier loss: 0.414149; batch adversarial loss: 0.535957\n",
      "epoch 169; iter: 0; batch classifier loss: 0.440233; batch adversarial loss: 0.562903\n",
      "epoch 170; iter: 0; batch classifier loss: 0.325079; batch adversarial loss: 0.514684\n",
      "epoch 171; iter: 0; batch classifier loss: 0.452654; batch adversarial loss: 0.555905\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363938; batch adversarial loss: 0.554372\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372843; batch adversarial loss: 0.662647\n",
      "epoch 174; iter: 0; batch classifier loss: 0.312128; batch adversarial loss: 0.500408\n",
      "epoch 175; iter: 0; batch classifier loss: 0.431214; batch adversarial loss: 0.526063\n",
      "epoch 176; iter: 0; batch classifier loss: 0.371188; batch adversarial loss: 0.636278\n",
      "epoch 177; iter: 0; batch classifier loss: 0.350141; batch adversarial loss: 0.572836\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374983; batch adversarial loss: 0.499864\n",
      "epoch 179; iter: 0; batch classifier loss: 0.417631; batch adversarial loss: 0.536802\n",
      "epoch 180; iter: 0; batch classifier loss: 0.377679; batch adversarial loss: 0.542287\n",
      "epoch 181; iter: 0; batch classifier loss: 0.366203; batch adversarial loss: 0.527022\n",
      "epoch 182; iter: 0; batch classifier loss: 0.393072; batch adversarial loss: 0.482859\n",
      "epoch 183; iter: 0; batch classifier loss: 0.295378; batch adversarial loss: 0.597656\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350192; batch adversarial loss: 0.563003\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390283; batch adversarial loss: 0.554909\n",
      "epoch 186; iter: 0; batch classifier loss: 0.403405; batch adversarial loss: 0.553243\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327066; batch adversarial loss: 0.570317\n",
      "epoch 188; iter: 0; batch classifier loss: 0.432563; batch adversarial loss: 0.562779\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404307; batch adversarial loss: 0.600420\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347912; batch adversarial loss: 0.553288\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346966; batch adversarial loss: 0.535500\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323852; batch adversarial loss: 0.581104\n",
      "epoch 193; iter: 0; batch classifier loss: 0.414560; batch adversarial loss: 0.553192\n",
      "epoch 194; iter: 0; batch classifier loss: 0.427961; batch adversarial loss: 0.524839\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351597; batch adversarial loss: 0.536901\n",
      "epoch 196; iter: 0; batch classifier loss: 0.426336; batch adversarial loss: 0.455290\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373550; batch adversarial loss: 0.490279\n",
      "epoch 198; iter: 0; batch classifier loss: 0.304769; batch adversarial loss: 0.582236\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385186; batch adversarial loss: 0.517676\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690541; batch adversarial loss: 0.662346\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628186; batch adversarial loss: 0.628806\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571252; batch adversarial loss: 0.630453\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530822; batch adversarial loss: 0.600688\n",
      "epoch 4; iter: 0; batch classifier loss: 0.526738; batch adversarial loss: 0.630192\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521007; batch adversarial loss: 0.601902\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491636; batch adversarial loss: 0.628727\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606944; batch adversarial loss: 0.597289\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552899; batch adversarial loss: 0.606339\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554036; batch adversarial loss: 0.605761\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540210; batch adversarial loss: 0.582144\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524566; batch adversarial loss: 0.637963\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553633; batch adversarial loss: 0.619223\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525427; batch adversarial loss: 0.614354\n",
      "epoch 14; iter: 0; batch classifier loss: 0.585552; batch adversarial loss: 0.526268\n",
      "epoch 15; iter: 0; batch classifier loss: 0.545678; batch adversarial loss: 0.611538\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506369; batch adversarial loss: 0.544052\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501900; batch adversarial loss: 0.646552\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517184; batch adversarial loss: 0.570445\n",
      "epoch 19; iter: 0; batch classifier loss: 0.464461; batch adversarial loss: 0.596566\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474293; batch adversarial loss: 0.575226\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504052; batch adversarial loss: 0.561295\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443372; batch adversarial loss: 0.518752\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547080; batch adversarial loss: 0.526738\n",
      "epoch 24; iter: 0; batch classifier loss: 0.389055; batch adversarial loss: 0.546209\n",
      "epoch 25; iter: 0; batch classifier loss: 0.416872; batch adversarial loss: 0.582570\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433296; batch adversarial loss: 0.592438\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481148; batch adversarial loss: 0.512323\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452688; batch adversarial loss: 0.604838\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428624; batch adversarial loss: 0.587977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472632; batch adversarial loss: 0.596316\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467704; batch adversarial loss: 0.596537\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520425; batch adversarial loss: 0.588370\n",
      "epoch 33; iter: 0; batch classifier loss: 0.540284; batch adversarial loss: 0.476213\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474441; batch adversarial loss: 0.554313\n",
      "epoch 35; iter: 0; batch classifier loss: 0.380504; batch adversarial loss: 0.599267\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458724; batch adversarial loss: 0.480988\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445240; batch adversarial loss: 0.653362\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425507; batch adversarial loss: 0.510004\n",
      "epoch 39; iter: 0; batch classifier loss: 0.444210; batch adversarial loss: 0.511867\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437313; batch adversarial loss: 0.589595\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416131; batch adversarial loss: 0.485571\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411959; batch adversarial loss: 0.630387\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426059; batch adversarial loss: 0.596734\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488897; batch adversarial loss: 0.474513\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409094; batch adversarial loss: 0.546460\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445923; batch adversarial loss: 0.588340\n",
      "epoch 47; iter: 0; batch classifier loss: 0.517034; batch adversarial loss: 0.483864\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407704; batch adversarial loss: 0.561309\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389445; batch adversarial loss: 0.518922\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395198; batch adversarial loss: 0.473298\n",
      "epoch 51; iter: 0; batch classifier loss: 0.394843; batch adversarial loss: 0.536097\n",
      "epoch 52; iter: 0; batch classifier loss: 0.340679; batch adversarial loss: 0.544779\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428013; batch adversarial loss: 0.533690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.391084; batch adversarial loss: 0.465333\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468776; batch adversarial loss: 0.572097\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411533; batch adversarial loss: 0.545185\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402466; batch adversarial loss: 0.546712\n",
      "epoch 58; iter: 0; batch classifier loss: 0.468245; batch adversarial loss: 0.578935\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400322; batch adversarial loss: 0.528710\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434734; batch adversarial loss: 0.589129\n",
      "epoch 61; iter: 0; batch classifier loss: 0.361505; batch adversarial loss: 0.535937\n",
      "epoch 62; iter: 0; batch classifier loss: 0.347943; batch adversarial loss: 0.500221\n",
      "epoch 63; iter: 0; batch classifier loss: 0.440689; batch adversarial loss: 0.561788\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431629; batch adversarial loss: 0.551277\n",
      "epoch 65; iter: 0; batch classifier loss: 0.342670; batch adversarial loss: 0.552298\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422753; batch adversarial loss: 0.518926\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402432; batch adversarial loss: 0.490664\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443529; batch adversarial loss: 0.599936\n",
      "epoch 69; iter: 0; batch classifier loss: 0.362114; batch adversarial loss: 0.589437\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436240; batch adversarial loss: 0.562447\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407060; batch adversarial loss: 0.605265\n",
      "epoch 72; iter: 0; batch classifier loss: 0.452809; batch adversarial loss: 0.517787\n",
      "epoch 73; iter: 0; batch classifier loss: 0.534346; batch adversarial loss: 0.588132\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465788; batch adversarial loss: 0.614964\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441957; batch adversarial loss: 0.554001\n",
      "epoch 76; iter: 0; batch classifier loss: 0.389517; batch adversarial loss: 0.489938\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423488; batch adversarial loss: 0.509133\n",
      "epoch 78; iter: 0; batch classifier loss: 0.342489; batch adversarial loss: 0.499805\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367108; batch adversarial loss: 0.544905\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356091; batch adversarial loss: 0.606638\n",
      "epoch 81; iter: 0; batch classifier loss: 0.366420; batch adversarial loss: 0.560055\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406616; batch adversarial loss: 0.584857\n",
      "epoch 83; iter: 0; batch classifier loss: 0.323987; batch adversarial loss: 0.570930\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383172; batch adversarial loss: 0.485683\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395663; batch adversarial loss: 0.505929\n",
      "epoch 86; iter: 0; batch classifier loss: 0.347075; batch adversarial loss: 0.684402\n",
      "epoch 87; iter: 0; batch classifier loss: 0.379077; batch adversarial loss: 0.539330\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374142; batch adversarial loss: 0.507263\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385132; batch adversarial loss: 0.515782\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392661; batch adversarial loss: 0.572253\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382168; batch adversarial loss: 0.476122\n",
      "epoch 92; iter: 0; batch classifier loss: 0.325195; batch adversarial loss: 0.538754\n",
      "epoch 93; iter: 0; batch classifier loss: 0.435616; batch adversarial loss: 0.517177\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374819; batch adversarial loss: 0.590518\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416352; batch adversarial loss: 0.553597\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347476; batch adversarial loss: 0.471938\n",
      "epoch 97; iter: 0; batch classifier loss: 0.424502; batch adversarial loss: 0.571452\n",
      "epoch 98; iter: 0; batch classifier loss: 0.444730; batch adversarial loss: 0.526928\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364423; batch adversarial loss: 0.544840\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433058; batch adversarial loss: 0.545213\n",
      "epoch 101; iter: 0; batch classifier loss: 0.440771; batch adversarial loss: 0.553739\n",
      "epoch 102; iter: 0; batch classifier loss: 0.440172; batch adversarial loss: 0.583371\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417895; batch adversarial loss: 0.561980\n",
      "epoch 104; iter: 0; batch classifier loss: 0.429702; batch adversarial loss: 0.591482\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401932; batch adversarial loss: 0.479612\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355455; batch adversarial loss: 0.652588\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412572; batch adversarial loss: 0.621448\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391971; batch adversarial loss: 0.582296\n",
      "epoch 109; iter: 0; batch classifier loss: 0.487016; batch adversarial loss: 0.615034\n",
      "epoch 110; iter: 0; batch classifier loss: 0.380264; batch adversarial loss: 0.571669\n",
      "epoch 111; iter: 0; batch classifier loss: 0.342666; batch adversarial loss: 0.588188\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347657; batch adversarial loss: 0.617997\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360589; batch adversarial loss: 0.499663\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368300; batch adversarial loss: 0.492207\n",
      "epoch 115; iter: 0; batch classifier loss: 0.456480; batch adversarial loss: 0.564016\n",
      "epoch 116; iter: 0; batch classifier loss: 0.491881; batch adversarial loss: 0.500759\n",
      "epoch 117; iter: 0; batch classifier loss: 0.444862; batch adversarial loss: 0.561151\n",
      "epoch 118; iter: 0; batch classifier loss: 0.428094; batch adversarial loss: 0.506537\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334439; batch adversarial loss: 0.515436\n",
      "epoch 120; iter: 0; batch classifier loss: 0.326563; batch adversarial loss: 0.543027\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366569; batch adversarial loss: 0.596131\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404322; batch adversarial loss: 0.607771\n",
      "epoch 123; iter: 0; batch classifier loss: 0.413293; batch adversarial loss: 0.613379\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380701; batch adversarial loss: 0.581366\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356375; batch adversarial loss: 0.544790\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396780; batch adversarial loss: 0.563101\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370355; batch adversarial loss: 0.543430\n",
      "epoch 128; iter: 0; batch classifier loss: 0.265154; batch adversarial loss: 0.520442\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356181; batch adversarial loss: 0.565045\n",
      "epoch 130; iter: 0; batch classifier loss: 0.410451; batch adversarial loss: 0.546724\n",
      "epoch 131; iter: 0; batch classifier loss: 0.411851; batch adversarial loss: 0.570879\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325389; batch adversarial loss: 0.535498\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347138; batch adversarial loss: 0.580865\n",
      "epoch 134; iter: 0; batch classifier loss: 0.410387; batch adversarial loss: 0.554018\n",
      "epoch 135; iter: 0; batch classifier loss: 0.425182; batch adversarial loss: 0.563409\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421150; batch adversarial loss: 0.444676\n",
      "epoch 137; iter: 0; batch classifier loss: 0.315666; batch adversarial loss: 0.554905\n",
      "epoch 138; iter: 0; batch classifier loss: 0.401926; batch adversarial loss: 0.600401\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377830; batch adversarial loss: 0.461678\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325679; batch adversarial loss: 0.544655\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375940; batch adversarial loss: 0.552249\n",
      "epoch 142; iter: 0; batch classifier loss: 0.426032; batch adversarial loss: 0.546084\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399165; batch adversarial loss: 0.579152\n",
      "epoch 144; iter: 0; batch classifier loss: 0.430779; batch adversarial loss: 0.492099\n",
      "epoch 145; iter: 0; batch classifier loss: 0.436142; batch adversarial loss: 0.561331\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373153; batch adversarial loss: 0.537596\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346667; batch adversarial loss: 0.466690\n",
      "epoch 148; iter: 0; batch classifier loss: 0.453145; batch adversarial loss: 0.545991\n",
      "epoch 149; iter: 0; batch classifier loss: 0.465497; batch adversarial loss: 0.544050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150; iter: 0; batch classifier loss: 0.314046; batch adversarial loss: 0.519285\n",
      "epoch 151; iter: 0; batch classifier loss: 0.389578; batch adversarial loss: 0.511801\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364418; batch adversarial loss: 0.587830\n",
      "epoch 153; iter: 0; batch classifier loss: 0.375422; batch adversarial loss: 0.456464\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374189; batch adversarial loss: 0.595731\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359649; batch adversarial loss: 0.581007\n",
      "epoch 156; iter: 0; batch classifier loss: 0.408662; batch adversarial loss: 0.517873\n",
      "epoch 157; iter: 0; batch classifier loss: 0.433590; batch adversarial loss: 0.607477\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362267; batch adversarial loss: 0.508335\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323018; batch adversarial loss: 0.557455\n",
      "epoch 160; iter: 0; batch classifier loss: 0.354175; batch adversarial loss: 0.536102\n",
      "epoch 161; iter: 0; batch classifier loss: 0.466988; batch adversarial loss: 0.526075\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348471; batch adversarial loss: 0.607097\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388436; batch adversarial loss: 0.599783\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354203; batch adversarial loss: 0.489637\n",
      "epoch 165; iter: 0; batch classifier loss: 0.378542; batch adversarial loss: 0.572019\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318276; batch adversarial loss: 0.625930\n",
      "epoch 167; iter: 0; batch classifier loss: 0.404018; batch adversarial loss: 0.524219\n",
      "epoch 168; iter: 0; batch classifier loss: 0.448680; batch adversarial loss: 0.498711\n",
      "epoch 169; iter: 0; batch classifier loss: 0.348266; batch adversarial loss: 0.543005\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367444; batch adversarial loss: 0.595561\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370741; batch adversarial loss: 0.608053\n",
      "epoch 172; iter: 0; batch classifier loss: 0.356497; batch adversarial loss: 0.585736\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392946; batch adversarial loss: 0.543615\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324846; batch adversarial loss: 0.529548\n",
      "epoch 175; iter: 0; batch classifier loss: 0.381646; batch adversarial loss: 0.635706\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340117; batch adversarial loss: 0.608219\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376774; batch adversarial loss: 0.484577\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374571; batch adversarial loss: 0.537794\n",
      "epoch 179; iter: 0; batch classifier loss: 0.375579; batch adversarial loss: 0.602314\n",
      "epoch 180; iter: 0; batch classifier loss: 0.361333; batch adversarial loss: 0.552623\n",
      "epoch 181; iter: 0; batch classifier loss: 0.305962; batch adversarial loss: 0.605682\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357846; batch adversarial loss: 0.588747\n",
      "epoch 183; iter: 0; batch classifier loss: 0.389813; batch adversarial loss: 0.553915\n",
      "epoch 184; iter: 0; batch classifier loss: 0.298185; batch adversarial loss: 0.523190\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358052; batch adversarial loss: 0.579393\n",
      "epoch 186; iter: 0; batch classifier loss: 0.351787; batch adversarial loss: 0.473352\n",
      "epoch 187; iter: 0; batch classifier loss: 0.349865; batch adversarial loss: 0.573747\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376494; batch adversarial loss: 0.524098\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345306; batch adversarial loss: 0.565061\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385408; batch adversarial loss: 0.592337\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355126; batch adversarial loss: 0.493566\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394264; batch adversarial loss: 0.536000\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398501; batch adversarial loss: 0.519706\n",
      "epoch 194; iter: 0; batch classifier loss: 0.346240; batch adversarial loss: 0.546220\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317661; batch adversarial loss: 0.553664\n",
      "epoch 196; iter: 0; batch classifier loss: 0.430943; batch adversarial loss: 0.527252\n",
      "epoch 197; iter: 0; batch classifier loss: 0.283216; batch adversarial loss: 0.527391\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389681; batch adversarial loss: 0.601458\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342096; batch adversarial loss: 0.461263\n",
      "epoch 0; iter: 0; batch classifier loss: 0.620896; batch adversarial loss: 0.732142\n",
      "epoch 1; iter: 0; batch classifier loss: 0.640465; batch adversarial loss: 0.732299\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556199; batch adversarial loss: 0.690519\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598321; batch adversarial loss: 0.659708\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559686; batch adversarial loss: 0.695775\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532152; batch adversarial loss: 0.659349\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569515; batch adversarial loss: 0.656367\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531647; batch adversarial loss: 0.634599\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576630; batch adversarial loss: 0.630728\n",
      "epoch 9; iter: 0; batch classifier loss: 0.607562; batch adversarial loss: 0.557735\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551602; batch adversarial loss: 0.548479\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456753; batch adversarial loss: 0.607907\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492640; batch adversarial loss: 0.529728\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550672; batch adversarial loss: 0.531835\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506183; batch adversarial loss: 0.603500\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496820; batch adversarial loss: 0.609876\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499313; batch adversarial loss: 0.581623\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498831; batch adversarial loss: 0.609007\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482776; batch adversarial loss: 0.598787\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474703; batch adversarial loss: 0.583045\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534809; batch adversarial loss: 0.595105\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523993; batch adversarial loss: 0.564320\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526341; batch adversarial loss: 0.614944\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475089; batch adversarial loss: 0.558808\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508575; batch adversarial loss: 0.587330\n",
      "epoch 25; iter: 0; batch classifier loss: 0.536187; batch adversarial loss: 0.568150\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440263; batch adversarial loss: 0.504452\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510772; batch adversarial loss: 0.544158\n",
      "epoch 28; iter: 0; batch classifier loss: 0.415986; batch adversarial loss: 0.475733\n",
      "epoch 29; iter: 0; batch classifier loss: 0.433287; batch adversarial loss: 0.518939\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453695; batch adversarial loss: 0.475112\n",
      "epoch 31; iter: 0; batch classifier loss: 0.427078; batch adversarial loss: 0.597921\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434215; batch adversarial loss: 0.539855\n",
      "epoch 33; iter: 0; batch classifier loss: 0.510863; batch adversarial loss: 0.556222\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429530; batch adversarial loss: 0.529187\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476066; batch adversarial loss: 0.601441\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495029; batch adversarial loss: 0.511124\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479045; batch adversarial loss: 0.537225\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480215; batch adversarial loss: 0.554204\n",
      "epoch 39; iter: 0; batch classifier loss: 0.488718; batch adversarial loss: 0.519364\n",
      "epoch 40; iter: 0; batch classifier loss: 0.502880; batch adversarial loss: 0.527152\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467802; batch adversarial loss: 0.526959\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446507; batch adversarial loss: 0.577400\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443681; batch adversarial loss: 0.595505\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460364; batch adversarial loss: 0.559042\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450827; batch adversarial loss: 0.516225\n",
      "epoch 46; iter: 0; batch classifier loss: 0.386252; batch adversarial loss: 0.590425\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367152; batch adversarial loss: 0.558376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.422898; batch adversarial loss: 0.553891\n",
      "epoch 49; iter: 0; batch classifier loss: 0.372878; batch adversarial loss: 0.550748\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388924; batch adversarial loss: 0.571646\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427780; batch adversarial loss: 0.489419\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442700; batch adversarial loss: 0.579838\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465610; batch adversarial loss: 0.562821\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411313; batch adversarial loss: 0.498717\n",
      "epoch 55; iter: 0; batch classifier loss: 0.418061; batch adversarial loss: 0.544299\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405238; batch adversarial loss: 0.555359\n",
      "epoch 57; iter: 0; batch classifier loss: 0.375044; batch adversarial loss: 0.439638\n",
      "epoch 58; iter: 0; batch classifier loss: 0.492802; batch adversarial loss: 0.532849\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394346; batch adversarial loss: 0.569592\n",
      "epoch 60; iter: 0; batch classifier loss: 0.483023; batch adversarial loss: 0.555796\n",
      "epoch 61; iter: 0; batch classifier loss: 0.464406; batch adversarial loss: 0.498791\n",
      "epoch 62; iter: 0; batch classifier loss: 0.419969; batch adversarial loss: 0.544301\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454055; batch adversarial loss: 0.535844\n",
      "epoch 64; iter: 0; batch classifier loss: 0.339543; batch adversarial loss: 0.544321\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370797; batch adversarial loss: 0.619291\n",
      "epoch 66; iter: 0; batch classifier loss: 0.388728; batch adversarial loss: 0.543951\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381158; batch adversarial loss: 0.629167\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419128; batch adversarial loss: 0.524296\n",
      "epoch 69; iter: 0; batch classifier loss: 0.474695; batch adversarial loss: 0.552348\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464359; batch adversarial loss: 0.554229\n",
      "epoch 71; iter: 0; batch classifier loss: 0.379751; batch adversarial loss: 0.486918\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391149; batch adversarial loss: 0.544303\n",
      "epoch 73; iter: 0; batch classifier loss: 0.381988; batch adversarial loss: 0.545248\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372169; batch adversarial loss: 0.513811\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447814; batch adversarial loss: 0.514817\n",
      "epoch 76; iter: 0; batch classifier loss: 0.318691; batch adversarial loss: 0.609412\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404764; batch adversarial loss: 0.460957\n",
      "epoch 78; iter: 0; batch classifier loss: 0.467261; batch adversarial loss: 0.514206\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382290; batch adversarial loss: 0.535456\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432592; batch adversarial loss: 0.580951\n",
      "epoch 81; iter: 0; batch classifier loss: 0.485961; batch adversarial loss: 0.646058\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371242; batch adversarial loss: 0.628775\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387919; batch adversarial loss: 0.609774\n",
      "epoch 84; iter: 0; batch classifier loss: 0.501248; batch adversarial loss: 0.516165\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419269; batch adversarial loss: 0.583065\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417073; batch adversarial loss: 0.554137\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406101; batch adversarial loss: 0.468304\n",
      "epoch 88; iter: 0; batch classifier loss: 0.521818; batch adversarial loss: 0.553140\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417999; batch adversarial loss: 0.515849\n",
      "epoch 90; iter: 0; batch classifier loss: 0.343346; batch adversarial loss: 0.563288\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370498; batch adversarial loss: 0.535612\n",
      "epoch 92; iter: 0; batch classifier loss: 0.308311; batch adversarial loss: 0.525691\n",
      "epoch 93; iter: 0; batch classifier loss: 0.484343; batch adversarial loss: 0.525094\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394646; batch adversarial loss: 0.582128\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368957; batch adversarial loss: 0.515246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.455810; batch adversarial loss: 0.582999\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370677; batch adversarial loss: 0.628210\n",
      "epoch 98; iter: 0; batch classifier loss: 0.340492; batch adversarial loss: 0.571845\n",
      "epoch 99; iter: 0; batch classifier loss: 0.446797; batch adversarial loss: 0.517284\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423921; batch adversarial loss: 0.513857\n",
      "epoch 101; iter: 0; batch classifier loss: 0.418202; batch adversarial loss: 0.517454\n",
      "epoch 102; iter: 0; batch classifier loss: 0.433462; batch adversarial loss: 0.497793\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440370; batch adversarial loss: 0.535994\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415392; batch adversarial loss: 0.535462\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413835; batch adversarial loss: 0.498592\n",
      "epoch 106; iter: 0; batch classifier loss: 0.360445; batch adversarial loss: 0.564299\n",
      "epoch 107; iter: 0; batch classifier loss: 0.320380; batch adversarial loss: 0.525827\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378722; batch adversarial loss: 0.545205\n",
      "epoch 109; iter: 0; batch classifier loss: 0.425032; batch adversarial loss: 0.554524\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384461; batch adversarial loss: 0.544622\n",
      "epoch 111; iter: 0; batch classifier loss: 0.328002; batch adversarial loss: 0.553738\n",
      "epoch 112; iter: 0; batch classifier loss: 0.453407; batch adversarial loss: 0.506240\n",
      "epoch 113; iter: 0; batch classifier loss: 0.376863; batch adversarial loss: 0.572610\n",
      "epoch 114; iter: 0; batch classifier loss: 0.466159; batch adversarial loss: 0.534097\n",
      "epoch 115; iter: 0; batch classifier loss: 0.439952; batch adversarial loss: 0.461089\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393042; batch adversarial loss: 0.600019\n",
      "epoch 117; iter: 0; batch classifier loss: 0.437686; batch adversarial loss: 0.553756\n",
      "epoch 118; iter: 0; batch classifier loss: 0.411480; batch adversarial loss: 0.561723\n",
      "epoch 119; iter: 0; batch classifier loss: 0.445739; batch adversarial loss: 0.469718\n",
      "epoch 120; iter: 0; batch classifier loss: 0.393868; batch adversarial loss: 0.508317\n",
      "epoch 121; iter: 0; batch classifier loss: 0.430866; batch adversarial loss: 0.542847\n",
      "epoch 122; iter: 0; batch classifier loss: 0.433511; batch adversarial loss: 0.524479\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389155; batch adversarial loss: 0.497154\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366236; batch adversarial loss: 0.572209\n",
      "epoch 125; iter: 0; batch classifier loss: 0.339310; batch adversarial loss: 0.564227\n",
      "epoch 126; iter: 0; batch classifier loss: 0.448758; batch adversarial loss: 0.590162\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382888; batch adversarial loss: 0.491786\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389231; batch adversarial loss: 0.535879\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340888; batch adversarial loss: 0.551624\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359585; batch adversarial loss: 0.579838\n",
      "epoch 131; iter: 0; batch classifier loss: 0.434262; batch adversarial loss: 0.536380\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414753; batch adversarial loss: 0.524960\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341449; batch adversarial loss: 0.534918\n",
      "epoch 134; iter: 0; batch classifier loss: 0.295512; batch adversarial loss: 0.573098\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320345; batch adversarial loss: 0.514799\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425591; batch adversarial loss: 0.496561\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386332; batch adversarial loss: 0.525155\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365402; batch adversarial loss: 0.553029\n",
      "epoch 139; iter: 0; batch classifier loss: 0.330125; batch adversarial loss: 0.553013\n",
      "epoch 140; iter: 0; batch classifier loss: 0.301767; batch adversarial loss: 0.562983\n",
      "epoch 141; iter: 0; batch classifier loss: 0.459738; batch adversarial loss: 0.487022\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412518; batch adversarial loss: 0.498329\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371464; batch adversarial loss: 0.516607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.325183; batch adversarial loss: 0.526262\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369902; batch adversarial loss: 0.562694\n",
      "epoch 146; iter: 0; batch classifier loss: 0.413862; batch adversarial loss: 0.571669\n",
      "epoch 147; iter: 0; batch classifier loss: 0.306438; batch adversarial loss: 0.562953\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376256; batch adversarial loss: 0.536615\n",
      "epoch 149; iter: 0; batch classifier loss: 0.437783; batch adversarial loss: 0.498845\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381514; batch adversarial loss: 0.583454\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391200; batch adversarial loss: 0.573866\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387236; batch adversarial loss: 0.638438\n",
      "epoch 153; iter: 0; batch classifier loss: 0.396156; batch adversarial loss: 0.516369\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375555; batch adversarial loss: 0.553184\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347844; batch adversarial loss: 0.516536\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390256; batch adversarial loss: 0.591423\n",
      "epoch 157; iter: 0; batch classifier loss: 0.379294; batch adversarial loss: 0.524724\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395617; batch adversarial loss: 0.563065\n",
      "epoch 159; iter: 0; batch classifier loss: 0.402402; batch adversarial loss: 0.620184\n",
      "epoch 160; iter: 0; batch classifier loss: 0.418791; batch adversarial loss: 0.562747\n",
      "epoch 161; iter: 0; batch classifier loss: 0.355881; batch adversarial loss: 0.572960\n",
      "epoch 162; iter: 0; batch classifier loss: 0.354671; batch adversarial loss: 0.580156\n",
      "epoch 163; iter: 0; batch classifier loss: 0.378611; batch adversarial loss: 0.581556\n",
      "epoch 164; iter: 0; batch classifier loss: 0.291330; batch adversarial loss: 0.468637\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342693; batch adversarial loss: 0.535565\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364359; batch adversarial loss: 0.601251\n",
      "epoch 167; iter: 0; batch classifier loss: 0.406984; batch adversarial loss: 0.545088\n",
      "epoch 168; iter: 0; batch classifier loss: 0.346990; batch adversarial loss: 0.497254\n",
      "epoch 169; iter: 0; batch classifier loss: 0.424655; batch adversarial loss: 0.517149\n",
      "epoch 170; iter: 0; batch classifier loss: 0.414099; batch adversarial loss: 0.507180\n",
      "epoch 171; iter: 0; batch classifier loss: 0.397153; batch adversarial loss: 0.545137\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331874; batch adversarial loss: 0.571639\n",
      "epoch 173; iter: 0; batch classifier loss: 0.456654; batch adversarial loss: 0.572966\n",
      "epoch 174; iter: 0; batch classifier loss: 0.407000; batch adversarial loss: 0.525735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380696; batch adversarial loss: 0.516687\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379558; batch adversarial loss: 0.562986\n",
      "epoch 177; iter: 0; batch classifier loss: 0.399489; batch adversarial loss: 0.582757\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337721; batch adversarial loss: 0.535075\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366611; batch adversarial loss: 0.601348\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378391; batch adversarial loss: 0.498047\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386921; batch adversarial loss: 0.572399\n",
      "epoch 182; iter: 0; batch classifier loss: 0.350218; batch adversarial loss: 0.526239\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327097; batch adversarial loss: 0.525855\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397812; batch adversarial loss: 0.515220\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372467; batch adversarial loss: 0.479375\n",
      "epoch 186; iter: 0; batch classifier loss: 0.372487; batch adversarial loss: 0.563922\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353730; batch adversarial loss: 0.516507\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384184; batch adversarial loss: 0.553836\n",
      "epoch 189; iter: 0; batch classifier loss: 0.386211; batch adversarial loss: 0.450640\n",
      "epoch 190; iter: 0; batch classifier loss: 0.420449; batch adversarial loss: 0.564826\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380626; batch adversarial loss: 0.534496\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340516; batch adversarial loss: 0.525498\n",
      "epoch 193; iter: 0; batch classifier loss: 0.303031; batch adversarial loss: 0.506714\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348371; batch adversarial loss: 0.488778\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357163; batch adversarial loss: 0.543937\n",
      "epoch 196; iter: 0; batch classifier loss: 0.404931; batch adversarial loss: 0.552184\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348008; batch adversarial loss: 0.459557\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353180; batch adversarial loss: 0.525811\n",
      "epoch 199; iter: 0; batch classifier loss: 0.305773; batch adversarial loss: 0.497277\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686611; batch adversarial loss: 0.808796\n",
      "epoch 1; iter: 0; batch classifier loss: 0.748607; batch adversarial loss: 0.888091\n",
      "epoch 2; iter: 0; batch classifier loss: 0.888802; batch adversarial loss: 0.873571\n",
      "epoch 3; iter: 0; batch classifier loss: 0.804375; batch adversarial loss: 0.771705\n",
      "epoch 4; iter: 0; batch classifier loss: 0.776973; batch adversarial loss: 0.751676\n",
      "epoch 5; iter: 0; batch classifier loss: 0.679204; batch adversarial loss: 0.690321\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569067; batch adversarial loss: 0.649719\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594838; batch adversarial loss: 0.623862\n",
      "epoch 8; iter: 0; batch classifier loss: 0.630371; batch adversarial loss: 0.574063\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517353; batch adversarial loss: 0.606401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494860; batch adversarial loss: 0.561106\n",
      "epoch 11; iter: 0; batch classifier loss: 0.513038; batch adversarial loss: 0.618867\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499581; batch adversarial loss: 0.524099\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507604; batch adversarial loss: 0.579608\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507890; batch adversarial loss: 0.547657\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560048; batch adversarial loss: 0.614312\n",
      "epoch 16; iter: 0; batch classifier loss: 0.536532; batch adversarial loss: 0.553604\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512888; batch adversarial loss: 0.540242\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487559; batch adversarial loss: 0.563849\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524779; batch adversarial loss: 0.552022\n",
      "epoch 20; iter: 0; batch classifier loss: 0.542628; batch adversarial loss: 0.554287\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477212; batch adversarial loss: 0.563639\n",
      "epoch 22; iter: 0; batch classifier loss: 0.528967; batch adversarial loss: 0.514773\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538354; batch adversarial loss: 0.524731\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446437; batch adversarial loss: 0.507730\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485827; batch adversarial loss: 0.547402\n",
      "epoch 26; iter: 0; batch classifier loss: 0.564563; batch adversarial loss: 0.577571\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518470; batch adversarial loss: 0.487505\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477412; batch adversarial loss: 0.519360\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424708; batch adversarial loss: 0.545174\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533466; batch adversarial loss: 0.584554\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455137; batch adversarial loss: 0.475178\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460253; batch adversarial loss: 0.582013\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439227; batch adversarial loss: 0.507398\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485280; batch adversarial loss: 0.502487\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498809; batch adversarial loss: 0.552285\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443550; batch adversarial loss: 0.537211\n",
      "epoch 37; iter: 0; batch classifier loss: 0.514042; batch adversarial loss: 0.563285\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435057; batch adversarial loss: 0.516745\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427169; batch adversarial loss: 0.486298\n",
      "epoch 40; iter: 0; batch classifier loss: 0.530698; batch adversarial loss: 0.609724\n",
      "epoch 41; iter: 0; batch classifier loss: 0.379567; batch adversarial loss: 0.570570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.490105; batch adversarial loss: 0.548564\n",
      "epoch 43; iter: 0; batch classifier loss: 0.490059; batch adversarial loss: 0.631371\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440198; batch adversarial loss: 0.516250\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376158; batch adversarial loss: 0.481944\n",
      "epoch 46; iter: 0; batch classifier loss: 0.399197; batch adversarial loss: 0.576103\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424247; batch adversarial loss: 0.517959\n",
      "epoch 48; iter: 0; batch classifier loss: 0.474995; batch adversarial loss: 0.518118\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444528; batch adversarial loss: 0.573421\n",
      "epoch 50; iter: 0; batch classifier loss: 0.425543; batch adversarial loss: 0.600290\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445430; batch adversarial loss: 0.528331\n",
      "epoch 52; iter: 0; batch classifier loss: 0.495504; batch adversarial loss: 0.489057\n",
      "epoch 53; iter: 0; batch classifier loss: 0.533413; batch adversarial loss: 0.572248\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404431; batch adversarial loss: 0.525753\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449602; batch adversarial loss: 0.619447\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393418; batch adversarial loss: 0.544477\n",
      "epoch 57; iter: 0; batch classifier loss: 0.518461; batch adversarial loss: 0.460497\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421077; batch adversarial loss: 0.649289\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464553; batch adversarial loss: 0.515826\n",
      "epoch 60; iter: 0; batch classifier loss: 0.468910; batch adversarial loss: 0.591838\n",
      "epoch 61; iter: 0; batch classifier loss: 0.372035; batch adversarial loss: 0.516391\n",
      "epoch 62; iter: 0; batch classifier loss: 0.389542; batch adversarial loss: 0.630285\n",
      "epoch 63; iter: 0; batch classifier loss: 0.393451; batch adversarial loss: 0.553062\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429032; batch adversarial loss: 0.498208\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415525; batch adversarial loss: 0.609606\n",
      "epoch 66; iter: 0; batch classifier loss: 0.477001; batch adversarial loss: 0.544190\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392124; batch adversarial loss: 0.506988\n",
      "epoch 68; iter: 0; batch classifier loss: 0.467740; batch adversarial loss: 0.572119\n",
      "epoch 69; iter: 0; batch classifier loss: 0.353265; batch adversarial loss: 0.503021\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465914; batch adversarial loss: 0.599986\n",
      "epoch 71; iter: 0; batch classifier loss: 0.462415; batch adversarial loss: 0.505842\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379027; batch adversarial loss: 0.519392\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401086; batch adversarial loss: 0.503567\n",
      "epoch 74; iter: 0; batch classifier loss: 0.349422; batch adversarial loss: 0.571231\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403915; batch adversarial loss: 0.487632\n",
      "epoch 76; iter: 0; batch classifier loss: 0.458442; batch adversarial loss: 0.537711\n",
      "epoch 77; iter: 0; batch classifier loss: 0.344804; batch adversarial loss: 0.601727\n",
      "epoch 78; iter: 0; batch classifier loss: 0.462883; batch adversarial loss: 0.637943\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430285; batch adversarial loss: 0.457736\n",
      "epoch 80; iter: 0; batch classifier loss: 0.440799; batch adversarial loss: 0.552130\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381737; batch adversarial loss: 0.527605\n",
      "epoch 82; iter: 0; batch classifier loss: 0.392427; batch adversarial loss: 0.476729\n",
      "epoch 83; iter: 0; batch classifier loss: 0.436850; batch adversarial loss: 0.545806\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406171; batch adversarial loss: 0.567142\n",
      "epoch 85; iter: 0; batch classifier loss: 0.459215; batch adversarial loss: 0.580228\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411553; batch adversarial loss: 0.552735\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374343; batch adversarial loss: 0.588185\n",
      "epoch 88; iter: 0; batch classifier loss: 0.491833; batch adversarial loss: 0.578300\n",
      "epoch 89; iter: 0; batch classifier loss: 0.359266; batch adversarial loss: 0.547696\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340843; batch adversarial loss: 0.621224\n",
      "epoch 91; iter: 0; batch classifier loss: 0.438899; batch adversarial loss: 0.550693\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399114; batch adversarial loss: 0.571456\n",
      "epoch 93; iter: 0; batch classifier loss: 0.351026; batch adversarial loss: 0.590137\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419925; batch adversarial loss: 0.496686\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431459; batch adversarial loss: 0.511920\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373679; batch adversarial loss: 0.493191\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344076; batch adversarial loss: 0.521192\n",
      "epoch 98; iter: 0; batch classifier loss: 0.455321; batch adversarial loss: 0.514392\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366891; batch adversarial loss: 0.518305\n",
      "epoch 100; iter: 0; batch classifier loss: 0.391726; batch adversarial loss: 0.599685\n",
      "epoch 101; iter: 0; batch classifier loss: 0.337263; batch adversarial loss: 0.553846\n",
      "epoch 102; iter: 0; batch classifier loss: 0.450612; batch adversarial loss: 0.471507\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391625; batch adversarial loss: 0.533842\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367860; batch adversarial loss: 0.508776\n",
      "epoch 105; iter: 0; batch classifier loss: 0.439804; batch adversarial loss: 0.585369\n",
      "epoch 106; iter: 0; batch classifier loss: 0.420407; batch adversarial loss: 0.548387\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396216; batch adversarial loss: 0.506044\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398851; batch adversarial loss: 0.600672\n",
      "epoch 109; iter: 0; batch classifier loss: 0.322453; batch adversarial loss: 0.485563\n",
      "epoch 110; iter: 0; batch classifier loss: 0.433445; batch adversarial loss: 0.541634\n",
      "epoch 111; iter: 0; batch classifier loss: 0.329173; batch adversarial loss: 0.560515\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382208; batch adversarial loss: 0.506688\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358123; batch adversarial loss: 0.525492\n",
      "epoch 114; iter: 0; batch classifier loss: 0.411380; batch adversarial loss: 0.526201\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366284; batch adversarial loss: 0.583013\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365189; batch adversarial loss: 0.512498\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408584; batch adversarial loss: 0.509188\n",
      "epoch 118; iter: 0; batch classifier loss: 0.325242; batch adversarial loss: 0.549904\n",
      "epoch 119; iter: 0; batch classifier loss: 0.443570; batch adversarial loss: 0.569980\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358288; batch adversarial loss: 0.487098\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349655; batch adversarial loss: 0.486829\n",
      "epoch 122; iter: 0; batch classifier loss: 0.435663; batch adversarial loss: 0.594239\n",
      "epoch 123; iter: 0; batch classifier loss: 0.358694; batch adversarial loss: 0.532613\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391125; batch adversarial loss: 0.468703\n",
      "epoch 125; iter: 0; batch classifier loss: 0.313660; batch adversarial loss: 0.515897\n",
      "epoch 126; iter: 0; batch classifier loss: 0.416919; batch adversarial loss: 0.510183\n",
      "epoch 127; iter: 0; batch classifier loss: 0.405407; batch adversarial loss: 0.514166\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418490; batch adversarial loss: 0.540805\n",
      "epoch 129; iter: 0; batch classifier loss: 0.321986; batch adversarial loss: 0.526096\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389030; batch adversarial loss: 0.487261\n",
      "epoch 131; iter: 0; batch classifier loss: 0.455535; batch adversarial loss: 0.536686\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370604; batch adversarial loss: 0.486063\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344252; batch adversarial loss: 0.533821\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343366; batch adversarial loss: 0.565571\n",
      "epoch 135; iter: 0; batch classifier loss: 0.414481; batch adversarial loss: 0.554767\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372785; batch adversarial loss: 0.561855\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329973; batch adversarial loss: 0.579277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.320753; batch adversarial loss: 0.510923\n",
      "epoch 139; iter: 0; batch classifier loss: 0.452650; batch adversarial loss: 0.548787\n",
      "epoch 140; iter: 0; batch classifier loss: 0.316590; batch adversarial loss: 0.583009\n",
      "epoch 141; iter: 0; batch classifier loss: 0.404515; batch adversarial loss: 0.488784\n",
      "epoch 142; iter: 0; batch classifier loss: 0.327576; batch adversarial loss: 0.548095\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331328; batch adversarial loss: 0.559681\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389416; batch adversarial loss: 0.573299\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327015; batch adversarial loss: 0.536786\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327748; batch adversarial loss: 0.568800\n",
      "epoch 147; iter: 0; batch classifier loss: 0.406786; batch adversarial loss: 0.446422\n",
      "epoch 148; iter: 0; batch classifier loss: 0.424726; batch adversarial loss: 0.546294\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335774; batch adversarial loss: 0.602422\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351175; batch adversarial loss: 0.512193\n",
      "epoch 151; iter: 0; batch classifier loss: 0.307968; batch adversarial loss: 0.570211\n",
      "epoch 152; iter: 0; batch classifier loss: 0.389227; batch adversarial loss: 0.558919\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338414; batch adversarial loss: 0.511383\n",
      "epoch 154; iter: 0; batch classifier loss: 0.426529; batch adversarial loss: 0.534721\n",
      "epoch 155; iter: 0; batch classifier loss: 0.390269; batch adversarial loss: 0.489251\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376396; batch adversarial loss: 0.515459\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359966; batch adversarial loss: 0.593793\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330724; batch adversarial loss: 0.595607\n",
      "epoch 159; iter: 0; batch classifier loss: 0.440458; batch adversarial loss: 0.446939\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373925; batch adversarial loss: 0.561042\n",
      "epoch 161; iter: 0; batch classifier loss: 0.427684; batch adversarial loss: 0.506606\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364137; batch adversarial loss: 0.491603\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342055; batch adversarial loss: 0.581558\n",
      "epoch 164; iter: 0; batch classifier loss: 0.347871; batch adversarial loss: 0.532303\n",
      "epoch 165; iter: 0; batch classifier loss: 0.332397; batch adversarial loss: 0.595654\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369088; batch adversarial loss: 0.541871\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345117; batch adversarial loss: 0.505306\n",
      "epoch 168; iter: 0; batch classifier loss: 0.278484; batch adversarial loss: 0.560818\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330246; batch adversarial loss: 0.534605\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369592; batch adversarial loss: 0.417764\n",
      "epoch 171; iter: 0; batch classifier loss: 0.314797; batch adversarial loss: 0.540850\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398860; batch adversarial loss: 0.525857\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292504; batch adversarial loss: 0.515446\n",
      "epoch 174; iter: 0; batch classifier loss: 0.417685; batch adversarial loss: 0.553813\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376361; batch adversarial loss: 0.562315\n",
      "epoch 176; iter: 0; batch classifier loss: 0.314570; batch adversarial loss: 0.504537\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389359; batch adversarial loss: 0.591779\n",
      "epoch 178; iter: 0; batch classifier loss: 0.293730; batch adversarial loss: 0.516593\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391511; batch adversarial loss: 0.566764\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374257; batch adversarial loss: 0.552250\n",
      "epoch 181; iter: 0; batch classifier loss: 0.329483; batch adversarial loss: 0.529572\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366972; batch adversarial loss: 0.524387\n",
      "epoch 183; iter: 0; batch classifier loss: 0.409632; batch adversarial loss: 0.547240\n",
      "epoch 184; iter: 0; batch classifier loss: 0.367928; batch adversarial loss: 0.565511\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308112; batch adversarial loss: 0.565790\n",
      "epoch 186; iter: 0; batch classifier loss: 0.333668; batch adversarial loss: 0.447232\n",
      "epoch 187; iter: 0; batch classifier loss: 0.410480; batch adversarial loss: 0.522877\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347661; batch adversarial loss: 0.553084\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361220; batch adversarial loss: 0.476102\n",
      "epoch 190; iter: 0; batch classifier loss: 0.513368; batch adversarial loss: 0.500292\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324435; batch adversarial loss: 0.505108\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293302; batch adversarial loss: 0.497593\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335264; batch adversarial loss: 0.598619\n",
      "epoch 194; iter: 0; batch classifier loss: 0.339879; batch adversarial loss: 0.525337\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312621; batch adversarial loss: 0.527302\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335175; batch adversarial loss: 0.480000\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368231; batch adversarial loss: 0.486978\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362971; batch adversarial loss: 0.548434\n",
      "epoch 199; iter: 0; batch classifier loss: 0.324048; batch adversarial loss: 0.464829\n",
      "epoch 0; iter: 0; batch classifier loss: 0.755924; batch adversarial loss: 0.662109\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577661; batch adversarial loss: 0.639728\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610655; batch adversarial loss: 0.643035\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591604; batch adversarial loss: 0.637341\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600371; batch adversarial loss: 0.612050\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558843; batch adversarial loss: 0.630784\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508382; batch adversarial loss: 0.597839\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441615; batch adversarial loss: 0.548206\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583011; batch adversarial loss: 0.584473\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549073; batch adversarial loss: 0.568066\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511320; batch adversarial loss: 0.607006\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521415; batch adversarial loss: 0.578824\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531642; batch adversarial loss: 0.584877\n",
      "epoch 13; iter: 0; batch classifier loss: 0.609211; batch adversarial loss: 0.591236\n",
      "epoch 14; iter: 0; batch classifier loss: 0.492183; batch adversarial loss: 0.544082\n",
      "epoch 15; iter: 0; batch classifier loss: 0.442785; batch adversarial loss: 0.621441\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532698; batch adversarial loss: 0.572762\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525331; batch adversarial loss: 0.588242\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493346; batch adversarial loss: 0.637444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478678; batch adversarial loss: 0.633489\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485861; batch adversarial loss: 0.609694\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468068; batch adversarial loss: 0.542868\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472406; batch adversarial loss: 0.555133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.544612; batch adversarial loss: 0.627885\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473088; batch adversarial loss: 0.562160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492916; batch adversarial loss: 0.556099\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487004; batch adversarial loss: 0.529427\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480361; batch adversarial loss: 0.547075\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459487; batch adversarial loss: 0.518899\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438057; batch adversarial loss: 0.419394\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465956; batch adversarial loss: 0.547717\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500606; batch adversarial loss: 0.504693\n",
      "epoch 32; iter: 0; batch classifier loss: 0.373979; batch adversarial loss: 0.518475\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434185; batch adversarial loss: 0.553369\n",
      "epoch 34; iter: 0; batch classifier loss: 0.402274; batch adversarial loss: 0.554625\n",
      "epoch 35; iter: 0; batch classifier loss: 0.513749; batch adversarial loss: 0.465483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.475714; batch adversarial loss: 0.564286\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473691; batch adversarial loss: 0.508720\n",
      "epoch 38; iter: 0; batch classifier loss: 0.357787; batch adversarial loss: 0.562754\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468340; batch adversarial loss: 0.516903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429698; batch adversarial loss: 0.554335\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432159; batch adversarial loss: 0.480196\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427921; batch adversarial loss: 0.553233\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433627; batch adversarial loss: 0.552484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434557; batch adversarial loss: 0.509741\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445651; batch adversarial loss: 0.572151\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411894; batch adversarial loss: 0.573238\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409953; batch adversarial loss: 0.535404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461126; batch adversarial loss: 0.536449\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419883; batch adversarial loss: 0.554178\n",
      "epoch 50; iter: 0; batch classifier loss: 0.350463; batch adversarial loss: 0.552102\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453005; batch adversarial loss: 0.561641\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387532; batch adversarial loss: 0.581366\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480975; batch adversarial loss: 0.609850\n",
      "epoch 54; iter: 0; batch classifier loss: 0.387452; batch adversarial loss: 0.580086\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377737; batch adversarial loss: 0.481007\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466158; batch adversarial loss: 0.589155\n",
      "epoch 57; iter: 0; batch classifier loss: 0.483641; batch adversarial loss: 0.525559\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430797; batch adversarial loss: 0.506133\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431152; batch adversarial loss: 0.544973\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455236; batch adversarial loss: 0.571779\n",
      "epoch 61; iter: 0; batch classifier loss: 0.356584; batch adversarial loss: 0.581631\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398786; batch adversarial loss: 0.563147\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391866; batch adversarial loss: 0.628620\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359262; batch adversarial loss: 0.515530\n",
      "epoch 65; iter: 0; batch classifier loss: 0.378524; batch adversarial loss: 0.554184\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403237; batch adversarial loss: 0.581157\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400538; batch adversarial loss: 0.589458\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356659; batch adversarial loss: 0.424580\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425604; batch adversarial loss: 0.544049\n",
      "epoch 70; iter: 0; batch classifier loss: 0.400658; batch adversarial loss: 0.561113\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380945; batch adversarial loss: 0.534641\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442013; batch adversarial loss: 0.543243\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383500; batch adversarial loss: 0.496718\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410486; batch adversarial loss: 0.552983\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438868; batch adversarial loss: 0.573120\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375778; batch adversarial loss: 0.617059\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396450; batch adversarial loss: 0.507329\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448824; batch adversarial loss: 0.580690\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413798; batch adversarial loss: 0.507294\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406541; batch adversarial loss: 0.673099\n",
      "epoch 81; iter: 0; batch classifier loss: 0.490330; batch adversarial loss: 0.497104\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418340; batch adversarial loss: 0.534389\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425446; batch adversarial loss: 0.571636\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353864; batch adversarial loss: 0.544507\n",
      "epoch 85; iter: 0; batch classifier loss: 0.330750; batch adversarial loss: 0.552376\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369711; batch adversarial loss: 0.507615\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386739; batch adversarial loss: 0.562939\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360217; batch adversarial loss: 0.469996\n",
      "epoch 89; iter: 0; batch classifier loss: 0.462762; batch adversarial loss: 0.616484\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388856; batch adversarial loss: 0.535119\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334223; batch adversarial loss: 0.536336\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388713; batch adversarial loss: 0.462106\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384015; batch adversarial loss: 0.559631\n",
      "epoch 94; iter: 0; batch classifier loss: 0.438474; batch adversarial loss: 0.536338\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414096; batch adversarial loss: 0.590720\n",
      "epoch 96; iter: 0; batch classifier loss: 0.412251; batch adversarial loss: 0.562186\n",
      "epoch 97; iter: 0; batch classifier loss: 0.431363; batch adversarial loss: 0.523383\n",
      "epoch 98; iter: 0; batch classifier loss: 0.428906; batch adversarial loss: 0.610304\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408837; batch adversarial loss: 0.498568\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388246; batch adversarial loss: 0.545893\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392884; batch adversarial loss: 0.517439\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377585; batch adversarial loss: 0.450087\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382780; batch adversarial loss: 0.536759\n",
      "epoch 104; iter: 0; batch classifier loss: 0.309195; batch adversarial loss: 0.542761\n",
      "epoch 105; iter: 0; batch classifier loss: 0.393698; batch adversarial loss: 0.619493\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404001; batch adversarial loss: 0.516589\n",
      "epoch 107; iter: 0; batch classifier loss: 0.288461; batch adversarial loss: 0.553848\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390063; batch adversarial loss: 0.573165\n",
      "epoch 109; iter: 0; batch classifier loss: 0.289763; batch adversarial loss: 0.480503\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362367; batch adversarial loss: 0.507865\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378873; batch adversarial loss: 0.580686\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396940; batch adversarial loss: 0.517881\n",
      "epoch 113; iter: 0; batch classifier loss: 0.468691; batch adversarial loss: 0.525482\n",
      "epoch 114; iter: 0; batch classifier loss: 0.352422; batch adversarial loss: 0.563046\n",
      "epoch 115; iter: 0; batch classifier loss: 0.337877; batch adversarial loss: 0.693854\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380788; batch adversarial loss: 0.516597\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367364; batch adversarial loss: 0.600669\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351892; batch adversarial loss: 0.462423\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376265; batch adversarial loss: 0.600462\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407945; batch adversarial loss: 0.524927\n",
      "epoch 121; iter: 0; batch classifier loss: 0.307851; batch adversarial loss: 0.562391\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417186; batch adversarial loss: 0.507664\n",
      "epoch 123; iter: 0; batch classifier loss: 0.325811; batch adversarial loss: 0.550237\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361520; batch adversarial loss: 0.547187\n",
      "epoch 125; iter: 0; batch classifier loss: 0.328472; batch adversarial loss: 0.580772\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412147; batch adversarial loss: 0.506292\n",
      "epoch 127; iter: 0; batch classifier loss: 0.500647; batch adversarial loss: 0.496870\n",
      "epoch 128; iter: 0; batch classifier loss: 0.298858; batch adversarial loss: 0.509113\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361332; batch adversarial loss: 0.580303\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393555; batch adversarial loss: 0.563051\n",
      "epoch 131; iter: 0; batch classifier loss: 0.402185; batch adversarial loss: 0.552225\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351744; batch adversarial loss: 0.607173\n",
      "epoch 133; iter: 0; batch classifier loss: 0.434254; batch adversarial loss: 0.635996\n",
      "epoch 134; iter: 0; batch classifier loss: 0.311877; batch adversarial loss: 0.581390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.424072; batch adversarial loss: 0.573367\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386023; batch adversarial loss: 0.587867\n",
      "epoch 137; iter: 0; batch classifier loss: 0.318469; batch adversarial loss: 0.552774\n",
      "epoch 138; iter: 0; batch classifier loss: 0.433321; batch adversarial loss: 0.612377\n",
      "epoch 139; iter: 0; batch classifier loss: 0.318696; batch adversarial loss: 0.608505\n",
      "epoch 140; iter: 0; batch classifier loss: 0.301315; batch adversarial loss: 0.576646\n",
      "epoch 141; iter: 0; batch classifier loss: 0.279250; batch adversarial loss: 0.515372\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359032; batch adversarial loss: 0.543143\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363862; batch adversarial loss: 0.544272\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408378; batch adversarial loss: 0.532906\n",
      "epoch 145; iter: 0; batch classifier loss: 0.391786; batch adversarial loss: 0.479450\n",
      "epoch 146; iter: 0; batch classifier loss: 0.413004; batch adversarial loss: 0.508408\n",
      "epoch 147; iter: 0; batch classifier loss: 0.467460; batch adversarial loss: 0.470666\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367084; batch adversarial loss: 0.529394\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351168; batch adversarial loss: 0.497100\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338049; batch adversarial loss: 0.482139\n",
      "epoch 151; iter: 0; batch classifier loss: 0.339631; batch adversarial loss: 0.570065\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370078; batch adversarial loss: 0.610848\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402239; batch adversarial loss: 0.533956\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381349; batch adversarial loss: 0.563555\n",
      "epoch 155; iter: 0; batch classifier loss: 0.381657; batch adversarial loss: 0.490035\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401478; batch adversarial loss: 0.471219\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362047; batch adversarial loss: 0.499163\n",
      "epoch 158; iter: 0; batch classifier loss: 0.305217; batch adversarial loss: 0.535492\n",
      "epoch 159; iter: 0; batch classifier loss: 0.447778; batch adversarial loss: 0.573139\n",
      "epoch 160; iter: 0; batch classifier loss: 0.338928; batch adversarial loss: 0.562586\n",
      "epoch 161; iter: 0; batch classifier loss: 0.328579; batch adversarial loss: 0.607258\n",
      "epoch 162; iter: 0; batch classifier loss: 0.282125; batch adversarial loss: 0.616571\n",
      "epoch 163; iter: 0; batch classifier loss: 0.461337; batch adversarial loss: 0.517218\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402776; batch adversarial loss: 0.601141\n",
      "epoch 165; iter: 0; batch classifier loss: 0.370026; batch adversarial loss: 0.497964\n",
      "epoch 166; iter: 0; batch classifier loss: 0.399510; batch adversarial loss: 0.526912\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393316; batch adversarial loss: 0.562085\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376880; batch adversarial loss: 0.507401\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385761; batch adversarial loss: 0.478672\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346271; batch adversarial loss: 0.560855\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396075; batch adversarial loss: 0.564407\n",
      "epoch 172; iter: 0; batch classifier loss: 0.304933; batch adversarial loss: 0.553939\n",
      "epoch 173; iter: 0; batch classifier loss: 0.313180; batch adversarial loss: 0.617128\n",
      "epoch 174; iter: 0; batch classifier loss: 0.383014; batch adversarial loss: 0.534768\n",
      "epoch 175; iter: 0; batch classifier loss: 0.438341; batch adversarial loss: 0.514331\n",
      "epoch 176; iter: 0; batch classifier loss: 0.406124; batch adversarial loss: 0.531361\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335755; batch adversarial loss: 0.524068\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363850; batch adversarial loss: 0.545549\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383105; batch adversarial loss: 0.523213\n",
      "epoch 180; iter: 0; batch classifier loss: 0.321915; batch adversarial loss: 0.585162\n",
      "epoch 181; iter: 0; batch classifier loss: 0.302141; batch adversarial loss: 0.547208\n",
      "epoch 182; iter: 0; batch classifier loss: 0.275559; batch adversarial loss: 0.480073\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358127; batch adversarial loss: 0.497370\n",
      "epoch 184; iter: 0; batch classifier loss: 0.291517; batch adversarial loss: 0.443715\n",
      "epoch 185; iter: 0; batch classifier loss: 0.359705; batch adversarial loss: 0.632945\n",
      "epoch 186; iter: 0; batch classifier loss: 0.410597; batch adversarial loss: 0.564306\n",
      "epoch 187; iter: 0; batch classifier loss: 0.380827; batch adversarial loss: 0.488176\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366598; batch adversarial loss: 0.608077\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309015; batch adversarial loss: 0.532792\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344704; batch adversarial loss: 0.506011\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354507; batch adversarial loss: 0.599182\n",
      "epoch 192; iter: 0; batch classifier loss: 0.374892; batch adversarial loss: 0.589372\n",
      "epoch 193; iter: 0; batch classifier loss: 0.412484; batch adversarial loss: 0.572202\n",
      "epoch 194; iter: 0; batch classifier loss: 0.392969; batch adversarial loss: 0.544193\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347586; batch adversarial loss: 0.487183\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336870; batch adversarial loss: 0.570854\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327827; batch adversarial loss: 0.543443\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321130; batch adversarial loss: 0.534986\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309916; batch adversarial loss: 0.647267\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770604; batch adversarial loss: 1.107208\n",
      "epoch 1; iter: 0; batch classifier loss: 0.929636; batch adversarial loss: 1.246087\n",
      "epoch 2; iter: 0; batch classifier loss: 1.014034; batch adversarial loss: 1.128205\n",
      "epoch 3; iter: 0; batch classifier loss: 1.111511; batch adversarial loss: 1.054139\n",
      "epoch 4; iter: 0; batch classifier loss: 1.024159; batch adversarial loss: 0.944512\n",
      "epoch 5; iter: 0; batch classifier loss: 1.249303; batch adversarial loss: 0.929443\n",
      "epoch 6; iter: 0; batch classifier loss: 1.140919; batch adversarial loss: 0.830833\n",
      "epoch 7; iter: 0; batch classifier loss: 0.923827; batch adversarial loss: 0.749033\n",
      "epoch 8; iter: 0; batch classifier loss: 0.807924; batch adversarial loss: 0.700477\n",
      "epoch 9; iter: 0; batch classifier loss: 0.735737; batch adversarial loss: 0.625843\n",
      "epoch 10; iter: 0; batch classifier loss: 0.609378; batch adversarial loss: 0.592133\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557337; batch adversarial loss: 0.599693\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572812; batch adversarial loss: 0.591073\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540635; batch adversarial loss: 0.605770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553100; batch adversarial loss: 0.610892\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521864; batch adversarial loss: 0.579462\n",
      "epoch 16; iter: 0; batch classifier loss: 0.565071; batch adversarial loss: 0.579694\n",
      "epoch 17; iter: 0; batch classifier loss: 0.563106; batch adversarial loss: 0.545898\n",
      "epoch 18; iter: 0; batch classifier loss: 0.558893; batch adversarial loss: 0.573791\n",
      "epoch 19; iter: 0; batch classifier loss: 0.570487; batch adversarial loss: 0.557424\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494836; batch adversarial loss: 0.630411\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527005; batch adversarial loss: 0.584566\n",
      "epoch 22; iter: 0; batch classifier loss: 0.540635; batch adversarial loss: 0.541534\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470053; batch adversarial loss: 0.591706\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491484; batch adversarial loss: 0.511401\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504731; batch adversarial loss: 0.541894\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519200; batch adversarial loss: 0.561542\n",
      "epoch 27; iter: 0; batch classifier loss: 0.524307; batch adversarial loss: 0.629743\n",
      "epoch 28; iter: 0; batch classifier loss: 0.519537; batch adversarial loss: 0.549264\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452801; batch adversarial loss: 0.563738\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476734; batch adversarial loss: 0.569919\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445283; batch adversarial loss: 0.511455\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438071; batch adversarial loss: 0.551789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.435381; batch adversarial loss: 0.568756\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501039; batch adversarial loss: 0.507394\n",
      "epoch 35; iter: 0; batch classifier loss: 0.530912; batch adversarial loss: 0.573096\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435373; batch adversarial loss: 0.569715\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442176; batch adversarial loss: 0.601780\n",
      "epoch 38; iter: 0; batch classifier loss: 0.393775; batch adversarial loss: 0.582091\n",
      "epoch 39; iter: 0; batch classifier loss: 0.545343; batch adversarial loss: 0.582676\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446190; batch adversarial loss: 0.480988\n",
      "epoch 41; iter: 0; batch classifier loss: 0.502087; batch adversarial loss: 0.602882\n",
      "epoch 42; iter: 0; batch classifier loss: 0.487707; batch adversarial loss: 0.522783\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464461; batch adversarial loss: 0.602389\n",
      "epoch 44; iter: 0; batch classifier loss: 0.453562; batch adversarial loss: 0.620868\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430717; batch adversarial loss: 0.427412\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448387; batch adversarial loss: 0.589496\n",
      "epoch 47; iter: 0; batch classifier loss: 0.498132; batch adversarial loss: 0.590288\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481178; batch adversarial loss: 0.585896\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476974; batch adversarial loss: 0.588644\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408870; batch adversarial loss: 0.499448\n",
      "epoch 51; iter: 0; batch classifier loss: 0.402640; batch adversarial loss: 0.534571\n",
      "epoch 52; iter: 0; batch classifier loss: 0.514696; batch adversarial loss: 0.551865\n",
      "epoch 53; iter: 0; batch classifier loss: 0.463894; batch adversarial loss: 0.466632\n",
      "epoch 54; iter: 0; batch classifier loss: 0.485024; batch adversarial loss: 0.562470\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426933; batch adversarial loss: 0.582402\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440147; batch adversarial loss: 0.508232\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387023; batch adversarial loss: 0.574733\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429007; batch adversarial loss: 0.545704\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431809; batch adversarial loss: 0.507450\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406510; batch adversarial loss: 0.526020\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432036; batch adversarial loss: 0.488823\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434931; batch adversarial loss: 0.555349\n",
      "epoch 63; iter: 0; batch classifier loss: 0.361470; batch adversarial loss: 0.570088\n",
      "epoch 64; iter: 0; batch classifier loss: 0.392819; batch adversarial loss: 0.480542\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394805; batch adversarial loss: 0.509250\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429044; batch adversarial loss: 0.525795\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436320; batch adversarial loss: 0.553383\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424623; batch adversarial loss: 0.554695\n",
      "epoch 69; iter: 0; batch classifier loss: 0.356734; batch adversarial loss: 0.526760\n",
      "epoch 70; iter: 0; batch classifier loss: 0.484647; batch adversarial loss: 0.607206\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402184; batch adversarial loss: 0.617562\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416828; batch adversarial loss: 0.589436\n",
      "epoch 73; iter: 0; batch classifier loss: 0.444042; batch adversarial loss: 0.544493\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426829; batch adversarial loss: 0.553147\n",
      "epoch 75; iter: 0; batch classifier loss: 0.368058; batch adversarial loss: 0.526464\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430770; batch adversarial loss: 0.599142\n",
      "epoch 77; iter: 0; batch classifier loss: 0.431350; batch adversarial loss: 0.599127\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375674; batch adversarial loss: 0.508190\n",
      "epoch 79; iter: 0; batch classifier loss: 0.423393; batch adversarial loss: 0.553618\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418285; batch adversarial loss: 0.535020\n",
      "epoch 81; iter: 0; batch classifier loss: 0.442816; batch adversarial loss: 0.572074\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372951; batch adversarial loss: 0.535359\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388189; batch adversarial loss: 0.626280\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443374; batch adversarial loss: 0.535551\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415754; batch adversarial loss: 0.553930\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446111; batch adversarial loss: 0.553865\n",
      "epoch 87; iter: 0; batch classifier loss: 0.437061; batch adversarial loss: 0.545040\n",
      "epoch 88; iter: 0; batch classifier loss: 0.300773; batch adversarial loss: 0.572014\n",
      "epoch 89; iter: 0; batch classifier loss: 0.426159; batch adversarial loss: 0.635776\n",
      "epoch 90; iter: 0; batch classifier loss: 0.361527; batch adversarial loss: 0.553355\n",
      "epoch 91; iter: 0; batch classifier loss: 0.459979; batch adversarial loss: 0.489337\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405237; batch adversarial loss: 0.553581\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418664; batch adversarial loss: 0.578825\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368170; batch adversarial loss: 0.481564\n",
      "epoch 95; iter: 0; batch classifier loss: 0.443563; batch adversarial loss: 0.543508\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367075; batch adversarial loss: 0.563536\n",
      "epoch 97; iter: 0; batch classifier loss: 0.398145; batch adversarial loss: 0.518734\n",
      "epoch 98; iter: 0; batch classifier loss: 0.333219; batch adversarial loss: 0.572291\n",
      "epoch 99; iter: 0; batch classifier loss: 0.406419; batch adversarial loss: 0.580029\n",
      "epoch 100; iter: 0; batch classifier loss: 0.366083; batch adversarial loss: 0.553295\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414927; batch adversarial loss: 0.517233\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394262; batch adversarial loss: 0.555094\n",
      "epoch 103; iter: 0; batch classifier loss: 0.333340; batch adversarial loss: 0.499193\n",
      "epoch 104; iter: 0; batch classifier loss: 0.337264; batch adversarial loss: 0.517705\n",
      "epoch 105; iter: 0; batch classifier loss: 0.453183; batch adversarial loss: 0.597713\n",
      "epoch 106; iter: 0; batch classifier loss: 0.405095; batch adversarial loss: 0.553759\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372399; batch adversarial loss: 0.552889\n",
      "epoch 108; iter: 0; batch classifier loss: 0.408232; batch adversarial loss: 0.554770\n",
      "epoch 109; iter: 0; batch classifier loss: 0.378214; batch adversarial loss: 0.534202\n",
      "epoch 110; iter: 0; batch classifier loss: 0.319681; batch adversarial loss: 0.517451\n",
      "epoch 111; iter: 0; batch classifier loss: 0.352576; batch adversarial loss: 0.526405\n",
      "epoch 112; iter: 0; batch classifier loss: 0.344152; batch adversarial loss: 0.517161\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333360; batch adversarial loss: 0.599129\n",
      "epoch 114; iter: 0; batch classifier loss: 0.292170; batch adversarial loss: 0.525954\n",
      "epoch 115; iter: 0; batch classifier loss: 0.434216; batch adversarial loss: 0.544623\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335695; batch adversarial loss: 0.571645\n",
      "epoch 117; iter: 0; batch classifier loss: 0.309114; batch adversarial loss: 0.480431\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368480; batch adversarial loss: 0.526700\n",
      "epoch 119; iter: 0; batch classifier loss: 0.308349; batch adversarial loss: 0.516875\n",
      "epoch 120; iter: 0; batch classifier loss: 0.492101; batch adversarial loss: 0.562140\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394989; batch adversarial loss: 0.498698\n",
      "epoch 122; iter: 0; batch classifier loss: 0.446786; batch adversarial loss: 0.481007\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379608; batch adversarial loss: 0.635326\n",
      "epoch 124; iter: 0; batch classifier loss: 0.301921; batch adversarial loss: 0.553712\n",
      "epoch 125; iter: 0; batch classifier loss: 0.339745; batch adversarial loss: 0.443600\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368296; batch adversarial loss: 0.490173\n",
      "epoch 127; iter: 0; batch classifier loss: 0.328294; batch adversarial loss: 0.624998\n",
      "epoch 128; iter: 0; batch classifier loss: 0.314128; batch adversarial loss: 0.580905\n",
      "epoch 129; iter: 0; batch classifier loss: 0.286491; batch adversarial loss: 0.599532\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383545; batch adversarial loss: 0.617969\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350209; batch adversarial loss: 0.589858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.364152; batch adversarial loss: 0.506582\n",
      "epoch 133; iter: 0; batch classifier loss: 0.440563; batch adversarial loss: 0.480633\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379479; batch adversarial loss: 0.552801\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336114; batch adversarial loss: 0.526598\n",
      "epoch 136; iter: 0; batch classifier loss: 0.311906; batch adversarial loss: 0.572747\n",
      "epoch 137; iter: 0; batch classifier loss: 0.355131; batch adversarial loss: 0.553241\n",
      "epoch 138; iter: 0; batch classifier loss: 0.399488; batch adversarial loss: 0.526111\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363128; batch adversarial loss: 0.580344\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349085; batch adversarial loss: 0.507656\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344578; batch adversarial loss: 0.607909\n",
      "epoch 142; iter: 0; batch classifier loss: 0.385769; batch adversarial loss: 0.588985\n",
      "epoch 143; iter: 0; batch classifier loss: 0.418759; batch adversarial loss: 0.535817\n",
      "epoch 144; iter: 0; batch classifier loss: 0.402067; batch adversarial loss: 0.490544\n",
      "epoch 145; iter: 0; batch classifier loss: 0.324374; batch adversarial loss: 0.542964\n",
      "epoch 146; iter: 0; batch classifier loss: 0.307022; batch adversarial loss: 0.525623\n",
      "epoch 147; iter: 0; batch classifier loss: 0.293830; batch adversarial loss: 0.608757\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334837; batch adversarial loss: 0.580203\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388246; batch adversarial loss: 0.643125\n",
      "epoch 150; iter: 0; batch classifier loss: 0.323023; batch adversarial loss: 0.580749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347493; batch adversarial loss: 0.479547\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365446; batch adversarial loss: 0.454159\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357739; batch adversarial loss: 0.471405\n",
      "epoch 154; iter: 0; batch classifier loss: 0.316933; batch adversarial loss: 0.533701\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324236; batch adversarial loss: 0.507636\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352986; batch adversarial loss: 0.590253\n",
      "epoch 157; iter: 0; batch classifier loss: 0.285016; batch adversarial loss: 0.543659\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315180; batch adversarial loss: 0.600320\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322181; batch adversarial loss: 0.544163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.315854; batch adversarial loss: 0.553500\n",
      "epoch 161; iter: 0; batch classifier loss: 0.416222; batch adversarial loss: 0.489744\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329759; batch adversarial loss: 0.553884\n",
      "epoch 163; iter: 0; batch classifier loss: 0.327921; batch adversarial loss: 0.619713\n",
      "epoch 164; iter: 0; batch classifier loss: 0.304958; batch adversarial loss: 0.527812\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352796; batch adversarial loss: 0.580319\n",
      "epoch 166; iter: 0; batch classifier loss: 0.439253; batch adversarial loss: 0.624732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.297979; batch adversarial loss: 0.545011\n",
      "epoch 168; iter: 0; batch classifier loss: 0.383838; batch adversarial loss: 0.600517\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407186; batch adversarial loss: 0.498780\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354720; batch adversarial loss: 0.553201\n",
      "epoch 171; iter: 0; batch classifier loss: 0.312738; batch adversarial loss: 0.525656\n",
      "epoch 172; iter: 0; batch classifier loss: 0.313004; batch adversarial loss: 0.507929\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380018; batch adversarial loss: 0.571703\n",
      "epoch 174; iter: 0; batch classifier loss: 0.388068; batch adversarial loss: 0.507006\n",
      "epoch 175; iter: 0; batch classifier loss: 0.428906; batch adversarial loss: 0.572673\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339919; batch adversarial loss: 0.543297\n",
      "epoch 177; iter: 0; batch classifier loss: 0.281330; batch adversarial loss: 0.543557\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369486; batch adversarial loss: 0.579659\n",
      "epoch 179; iter: 0; batch classifier loss: 0.320261; batch adversarial loss: 0.498071\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328671; batch adversarial loss: 0.524916\n",
      "epoch 181; iter: 0; batch classifier loss: 0.274596; batch adversarial loss: 0.470801\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391448; batch adversarial loss: 0.526957\n",
      "epoch 183; iter: 0; batch classifier loss: 0.289637; batch adversarial loss: 0.554197\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342595; batch adversarial loss: 0.582926\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383948; batch adversarial loss: 0.589863\n",
      "epoch 186; iter: 0; batch classifier loss: 0.416891; batch adversarial loss: 0.626603\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341639; batch adversarial loss: 0.627179\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392952; batch adversarial loss: 0.571267\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305671; batch adversarial loss: 0.524991\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331293; batch adversarial loss: 0.490344\n",
      "epoch 191; iter: 0; batch classifier loss: 0.285374; batch adversarial loss: 0.562795\n",
      "epoch 192; iter: 0; batch classifier loss: 0.301949; batch adversarial loss: 0.592334\n",
      "epoch 193; iter: 0; batch classifier loss: 0.312332; batch adversarial loss: 0.516609\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357486; batch adversarial loss: 0.491342\n",
      "epoch 195; iter: 0; batch classifier loss: 0.345055; batch adversarial loss: 0.571687\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314327; batch adversarial loss: 0.498367\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329219; batch adversarial loss: 0.589529\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309842; batch adversarial loss: 0.617594\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374292; batch adversarial loss: 0.453566\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741765; batch adversarial loss: 0.878219\n",
      "epoch 1; iter: 0; batch classifier loss: 0.734956; batch adversarial loss: 0.977053\n",
      "epoch 2; iter: 0; batch classifier loss: 0.727450; batch adversarial loss: 0.939555\n",
      "epoch 3; iter: 0; batch classifier loss: 0.728652; batch adversarial loss: 0.873333\n",
      "epoch 4; iter: 0; batch classifier loss: 0.715464; batch adversarial loss: 0.771983\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594385; batch adversarial loss: 0.713524\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590151; batch adversarial loss: 0.702550\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498275; batch adversarial loss: 0.607248\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554417; batch adversarial loss: 0.622489\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507257; batch adversarial loss: 0.624759\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541334; batch adversarial loss: 0.601124\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533799; batch adversarial loss: 0.582982\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513555; batch adversarial loss: 0.580813\n",
      "epoch 13; iter: 0; batch classifier loss: 0.454839; batch adversarial loss: 0.591598\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534149; batch adversarial loss: 0.609392\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513303; batch adversarial loss: 0.540935\n",
      "epoch 16; iter: 0; batch classifier loss: 0.463468; batch adversarial loss: 0.568584\n",
      "epoch 17; iter: 0; batch classifier loss: 0.611308; batch adversarial loss: 0.559818\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526324; batch adversarial loss: 0.573719\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521848; batch adversarial loss: 0.518399\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502973; batch adversarial loss: 0.573256\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514413; batch adversarial loss: 0.519230\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468464; batch adversarial loss: 0.575593\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539278; batch adversarial loss: 0.573224\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490410; batch adversarial loss: 0.558275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455752; batch adversarial loss: 0.565253\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543299; batch adversarial loss: 0.566824\n",
      "epoch 27; iter: 0; batch classifier loss: 0.554151; batch adversarial loss: 0.509133\n",
      "epoch 28; iter: 0; batch classifier loss: 0.546917; batch adversarial loss: 0.497917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477940; batch adversarial loss: 0.527912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.473057; batch adversarial loss: 0.556742\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458109; batch adversarial loss: 0.563419\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420472; batch adversarial loss: 0.593883\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414535; batch adversarial loss: 0.531843\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456264; batch adversarial loss: 0.572010\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448859; batch adversarial loss: 0.523993\n",
      "epoch 36; iter: 0; batch classifier loss: 0.538414; batch adversarial loss: 0.509640\n",
      "epoch 37; iter: 0; batch classifier loss: 0.478331; batch adversarial loss: 0.569710\n",
      "epoch 38; iter: 0; batch classifier loss: 0.426888; batch adversarial loss: 0.475514\n",
      "epoch 39; iter: 0; batch classifier loss: 0.383743; batch adversarial loss: 0.554261\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476350; batch adversarial loss: 0.521388\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440323; batch adversarial loss: 0.551685\n",
      "epoch 42; iter: 0; batch classifier loss: 0.524884; batch adversarial loss: 0.528678\n",
      "epoch 43; iter: 0; batch classifier loss: 0.389848; batch adversarial loss: 0.510199\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405133; batch adversarial loss: 0.564341\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440088; batch adversarial loss: 0.516860\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388771; batch adversarial loss: 0.526407\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449270; batch adversarial loss: 0.498568\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495206; batch adversarial loss: 0.516166\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446111; batch adversarial loss: 0.535584\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422370; batch adversarial loss: 0.545011\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405437; batch adversarial loss: 0.517258\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391547; batch adversarial loss: 0.526044\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413417; batch adversarial loss: 0.488907\n",
      "epoch 54; iter: 0; batch classifier loss: 0.444294; batch adversarial loss: 0.563358\n",
      "epoch 55; iter: 0; batch classifier loss: 0.471599; batch adversarial loss: 0.545376\n",
      "epoch 56; iter: 0; batch classifier loss: 0.500524; batch adversarial loss: 0.534604\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393758; batch adversarial loss: 0.562241\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441247; batch adversarial loss: 0.508230\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429352; batch adversarial loss: 0.525821\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410427; batch adversarial loss: 0.498290\n",
      "epoch 61; iter: 0; batch classifier loss: 0.465137; batch adversarial loss: 0.553870\n",
      "epoch 62; iter: 0; batch classifier loss: 0.488174; batch adversarial loss: 0.627652\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449086; batch adversarial loss: 0.600090\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397294; batch adversarial loss: 0.572600\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445300; batch adversarial loss: 0.526124\n",
      "epoch 66; iter: 0; batch classifier loss: 0.491818; batch adversarial loss: 0.479972\n",
      "epoch 67; iter: 0; batch classifier loss: 0.464465; batch adversarial loss: 0.470722\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422888; batch adversarial loss: 0.572141\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424061; batch adversarial loss: 0.563077\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343253; batch adversarial loss: 0.535188\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396590; batch adversarial loss: 0.553716\n",
      "epoch 72; iter: 0; batch classifier loss: 0.269225; batch adversarial loss: 0.507584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355401; batch adversarial loss: 0.636887\n",
      "epoch 74; iter: 0; batch classifier loss: 0.354127; batch adversarial loss: 0.646204\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429547; batch adversarial loss: 0.563179\n",
      "epoch 76; iter: 0; batch classifier loss: 0.468308; batch adversarial loss: 0.507445\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393712; batch adversarial loss: 0.489991\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352884; batch adversarial loss: 0.480127\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374771; batch adversarial loss: 0.581912\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414452; batch adversarial loss: 0.506661\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443148; batch adversarial loss: 0.452269\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386461; batch adversarial loss: 0.461391\n",
      "epoch 83; iter: 0; batch classifier loss: 0.393213; batch adversarial loss: 0.535679\n",
      "epoch 84; iter: 0; batch classifier loss: 0.460432; batch adversarial loss: 0.442518\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427913; batch adversarial loss: 0.526480\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384030; batch adversarial loss: 0.581246\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391396; batch adversarial loss: 0.544061\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400623; batch adversarial loss: 0.534962\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387450; batch adversarial loss: 0.562948\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375598; batch adversarial loss: 0.581582\n",
      "epoch 91; iter: 0; batch classifier loss: 0.449238; batch adversarial loss: 0.507867\n",
      "epoch 92; iter: 0; batch classifier loss: 0.430778; batch adversarial loss: 0.636256\n",
      "epoch 93; iter: 0; batch classifier loss: 0.355782; batch adversarial loss: 0.517244\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435858; batch adversarial loss: 0.534810\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407165; batch adversarial loss: 0.553539\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390478; batch adversarial loss: 0.516908\n",
      "epoch 97; iter: 0; batch classifier loss: 0.345692; batch adversarial loss: 0.581118\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398389; batch adversarial loss: 0.534920\n",
      "epoch 99; iter: 0; batch classifier loss: 0.432624; batch adversarial loss: 0.543999\n",
      "epoch 100; iter: 0; batch classifier loss: 0.342567; batch adversarial loss: 0.507667\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374063; batch adversarial loss: 0.544243\n",
      "epoch 102; iter: 0; batch classifier loss: 0.405033; batch adversarial loss: 0.544896\n",
      "epoch 103; iter: 0; batch classifier loss: 0.324331; batch adversarial loss: 0.525673\n",
      "epoch 104; iter: 0; batch classifier loss: 0.340798; batch adversarial loss: 0.506910\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413011; batch adversarial loss: 0.517158\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355642; batch adversarial loss: 0.526297\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354938; batch adversarial loss: 0.544492\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390911; batch adversarial loss: 0.535087\n",
      "epoch 109; iter: 0; batch classifier loss: 0.432290; batch adversarial loss: 0.573159\n",
      "epoch 110; iter: 0; batch classifier loss: 0.454681; batch adversarial loss: 0.507960\n",
      "epoch 111; iter: 0; batch classifier loss: 0.435601; batch adversarial loss: 0.590785\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394697; batch adversarial loss: 0.618603\n",
      "epoch 113; iter: 0; batch classifier loss: 0.414317; batch adversarial loss: 0.534944\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384442; batch adversarial loss: 0.544811\n",
      "epoch 115; iter: 0; batch classifier loss: 0.430996; batch adversarial loss: 0.607865\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385381; batch adversarial loss: 0.481142\n",
      "epoch 117; iter: 0; batch classifier loss: 0.335292; batch adversarial loss: 0.535959\n",
      "epoch 118; iter: 0; batch classifier loss: 0.480090; batch adversarial loss: 0.525507\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378638; batch adversarial loss: 0.590359\n",
      "epoch 120; iter: 0; batch classifier loss: 0.329393; batch adversarial loss: 0.507647\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375302; batch adversarial loss: 0.479615\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388603; batch adversarial loss: 0.600368\n",
      "epoch 123; iter: 0; batch classifier loss: 0.410290; batch adversarial loss: 0.562962\n",
      "epoch 124; iter: 0; batch classifier loss: 0.411643; batch adversarial loss: 0.498349\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395133; batch adversarial loss: 0.627425\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375942; batch adversarial loss: 0.534841\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349296; batch adversarial loss: 0.552592\n",
      "epoch 128; iter: 0; batch classifier loss: 0.333644; batch adversarial loss: 0.561350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.383303; batch adversarial loss: 0.571980\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361771; batch adversarial loss: 0.572702\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438519; batch adversarial loss: 0.526265\n",
      "epoch 132; iter: 0; batch classifier loss: 0.344786; batch adversarial loss: 0.525858\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387964; batch adversarial loss: 0.498868\n",
      "epoch 134; iter: 0; batch classifier loss: 0.313604; batch adversarial loss: 0.488825\n",
      "epoch 135; iter: 0; batch classifier loss: 0.458110; batch adversarial loss: 0.516806\n",
      "epoch 136; iter: 0; batch classifier loss: 0.442440; batch adversarial loss: 0.590820\n",
      "epoch 137; iter: 0; batch classifier loss: 0.321166; batch adversarial loss: 0.572311\n",
      "epoch 138; iter: 0; batch classifier loss: 0.299351; batch adversarial loss: 0.590970\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374650; batch adversarial loss: 0.488633\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337326; batch adversarial loss: 0.535057\n",
      "epoch 141; iter: 0; batch classifier loss: 0.393847; batch adversarial loss: 0.507576\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398107; batch adversarial loss: 0.572487\n",
      "epoch 143; iter: 0; batch classifier loss: 0.426287; batch adversarial loss: 0.480068\n",
      "epoch 144; iter: 0; batch classifier loss: 0.382868; batch adversarial loss: 0.590116\n",
      "epoch 145; iter: 0; batch classifier loss: 0.360358; batch adversarial loss: 0.579876\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339750; batch adversarial loss: 0.553119\n",
      "epoch 147; iter: 0; batch classifier loss: 0.319763; batch adversarial loss: 0.580194\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376438; batch adversarial loss: 0.470746\n",
      "epoch 149; iter: 0; batch classifier loss: 0.289549; batch adversarial loss: 0.526121\n",
      "epoch 150; iter: 0; batch classifier loss: 0.345400; batch adversarial loss: 0.525411\n",
      "epoch 151; iter: 0; batch classifier loss: 0.329833; batch adversarial loss: 0.572258\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390886; batch adversarial loss: 0.600268\n",
      "epoch 153; iter: 0; batch classifier loss: 0.442329; batch adversarial loss: 0.526307\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390228; batch adversarial loss: 0.534981\n",
      "epoch 155; iter: 0; batch classifier loss: 0.425724; batch adversarial loss: 0.572304\n",
      "epoch 156; iter: 0; batch classifier loss: 0.419313; batch adversarial loss: 0.507667\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312237; batch adversarial loss: 0.535508\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388590; batch adversarial loss: 0.498901\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394037; batch adversarial loss: 0.617756\n",
      "epoch 160; iter: 0; batch classifier loss: 0.424132; batch adversarial loss: 0.608386\n",
      "epoch 161; iter: 0; batch classifier loss: 0.460157; batch adversarial loss: 0.471100\n",
      "epoch 162; iter: 0; batch classifier loss: 0.393856; batch adversarial loss: 0.572520\n",
      "epoch 163; iter: 0; batch classifier loss: 0.424931; batch adversarial loss: 0.516969\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341240; batch adversarial loss: 0.664317\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373534; batch adversarial loss: 0.525570\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335492; batch adversarial loss: 0.516684\n",
      "epoch 167; iter: 0; batch classifier loss: 0.355105; batch adversarial loss: 0.591018\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363047; batch adversarial loss: 0.525823\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370840; batch adversarial loss: 0.498020\n",
      "epoch 170; iter: 0; batch classifier loss: 0.372474; batch adversarial loss: 0.535211\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374318; batch adversarial loss: 0.600060\n",
      "epoch 172; iter: 0; batch classifier loss: 0.316564; batch adversarial loss: 0.581675\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383590; batch adversarial loss: 0.544310\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338498; batch adversarial loss: 0.489257\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366260; batch adversarial loss: 0.636869\n",
      "epoch 176; iter: 0; batch classifier loss: 0.294369; batch adversarial loss: 0.581429\n",
      "epoch 177; iter: 0; batch classifier loss: 0.399634; batch adversarial loss: 0.507212\n",
      "epoch 178; iter: 0; batch classifier loss: 0.409270; batch adversarial loss: 0.544136\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339720; batch adversarial loss: 0.516291\n",
      "epoch 180; iter: 0; batch classifier loss: 0.394664; batch adversarial loss: 0.571053\n",
      "epoch 181; iter: 0; batch classifier loss: 0.318591; batch adversarial loss: 0.553620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351485; batch adversarial loss: 0.617932\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327380; batch adversarial loss: 0.498498\n",
      "epoch 184; iter: 0; batch classifier loss: 0.501778; batch adversarial loss: 0.526317\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332670; batch adversarial loss: 0.580822\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375038; batch adversarial loss: 0.554217\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336894; batch adversarial loss: 0.507549\n",
      "epoch 188; iter: 0; batch classifier loss: 0.390075; batch adversarial loss: 0.508227\n",
      "epoch 189; iter: 0; batch classifier loss: 0.273453; batch adversarial loss: 0.470867\n",
      "epoch 190; iter: 0; batch classifier loss: 0.398138; batch adversarial loss: 0.544990\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392204; batch adversarial loss: 0.563169\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335604; batch adversarial loss: 0.516301\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345592; batch adversarial loss: 0.553568\n",
      "epoch 194; iter: 0; batch classifier loss: 0.458933; batch adversarial loss: 0.609389\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327790; batch adversarial loss: 0.546158\n",
      "epoch 196; iter: 0; batch classifier loss: 0.287669; batch adversarial loss: 0.525205\n",
      "epoch 197; iter: 0; batch classifier loss: 0.398519; batch adversarial loss: 0.618054\n",
      "epoch 198; iter: 0; batch classifier loss: 0.344260; batch adversarial loss: 0.525996\n",
      "epoch 199; iter: 0; batch classifier loss: 0.236606; batch adversarial loss: 0.572219\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753712; batch adversarial loss: 0.757188\n",
      "epoch 1; iter: 0; batch classifier loss: 0.641477; batch adversarial loss: 0.712865\n",
      "epoch 2; iter: 0; batch classifier loss: 0.634361; batch adversarial loss: 0.671615\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605955; batch adversarial loss: 0.658522\n",
      "epoch 4; iter: 0; batch classifier loss: 0.648154; batch adversarial loss: 0.623289\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578045; batch adversarial loss: 0.593655\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533188; batch adversarial loss: 0.609737\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498111; batch adversarial loss: 0.543763\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601420; batch adversarial loss: 0.566822\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545423; batch adversarial loss: 0.535473\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496268; batch adversarial loss: 0.515028\n",
      "epoch 11; iter: 0; batch classifier loss: 0.614602; batch adversarial loss: 0.528705\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550937; batch adversarial loss: 0.554460\n",
      "epoch 13; iter: 0; batch classifier loss: 0.562353; batch adversarial loss: 0.588404\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525025; batch adversarial loss: 0.530538\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500569; batch adversarial loss: 0.519795\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464675; batch adversarial loss: 0.522237\n",
      "epoch 17; iter: 0; batch classifier loss: 0.469515; batch adversarial loss: 0.621061\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549425; batch adversarial loss: 0.633658\n",
      "epoch 19; iter: 0; batch classifier loss: 0.452916; batch adversarial loss: 0.482700\n",
      "epoch 20; iter: 0; batch classifier loss: 0.557437; batch adversarial loss: 0.560236\n",
      "epoch 21; iter: 0; batch classifier loss: 0.401408; batch adversarial loss: 0.521869\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466159; batch adversarial loss: 0.644112\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538385; batch adversarial loss: 0.599485\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489552; batch adversarial loss: 0.529213\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432383; batch adversarial loss: 0.612567\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497138; batch adversarial loss: 0.493758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.421266; batch adversarial loss: 0.579865\n",
      "epoch 28; iter: 0; batch classifier loss: 0.541205; batch adversarial loss: 0.557384\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495641; batch adversarial loss: 0.598383\n",
      "epoch 30; iter: 0; batch classifier loss: 0.497744; batch adversarial loss: 0.528189\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439394; batch adversarial loss: 0.507741\n",
      "epoch 32; iter: 0; batch classifier loss: 0.456516; batch adversarial loss: 0.481723\n",
      "epoch 33; iter: 0; batch classifier loss: 0.537885; batch adversarial loss: 0.472403\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466043; batch adversarial loss: 0.527665\n",
      "epoch 35; iter: 0; batch classifier loss: 0.524857; batch adversarial loss: 0.562398\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492220; batch adversarial loss: 0.508950\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469117; batch adversarial loss: 0.554478\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482284; batch adversarial loss: 0.590048\n",
      "epoch 39; iter: 0; batch classifier loss: 0.387895; batch adversarial loss: 0.517934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390960; batch adversarial loss: 0.545330\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377692; batch adversarial loss: 0.592412\n",
      "epoch 42; iter: 0; batch classifier loss: 0.595267; batch adversarial loss: 0.459016\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467217; batch adversarial loss: 0.591513\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429369; batch adversarial loss: 0.526345\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434458; batch adversarial loss: 0.555848\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479852; batch adversarial loss: 0.555878\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350463; batch adversarial loss: 0.594394\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453494; batch adversarial loss: 0.554263\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427652; batch adversarial loss: 0.592382\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451854; batch adversarial loss: 0.650139\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481061; batch adversarial loss: 0.487201\n",
      "epoch 52; iter: 0; batch classifier loss: 0.486832; batch adversarial loss: 0.524741\n",
      "epoch 53; iter: 0; batch classifier loss: 0.447811; batch adversarial loss: 0.659994\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417021; batch adversarial loss: 0.497248\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436402; batch adversarial loss: 0.516177\n",
      "epoch 56; iter: 0; batch classifier loss: 0.486924; batch adversarial loss: 0.525238\n",
      "epoch 57; iter: 0; batch classifier loss: 0.433217; batch adversarial loss: 0.525633\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413309; batch adversarial loss: 0.486658\n",
      "epoch 59; iter: 0; batch classifier loss: 0.489773; batch adversarial loss: 0.544425\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432685; batch adversarial loss: 0.612421\n",
      "epoch 61; iter: 0; batch classifier loss: 0.462375; batch adversarial loss: 0.477466\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391886; batch adversarial loss: 0.553894\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421012; batch adversarial loss: 0.486811\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401168; batch adversarial loss: 0.466147\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466457; batch adversarial loss: 0.457364\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396409; batch adversarial loss: 0.524074\n",
      "epoch 67; iter: 0; batch classifier loss: 0.346230; batch adversarial loss: 0.553878\n",
      "epoch 68; iter: 0; batch classifier loss: 0.475095; batch adversarial loss: 0.544978\n",
      "epoch 69; iter: 0; batch classifier loss: 0.456286; batch adversarial loss: 0.523936\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397639; batch adversarial loss: 0.574908\n",
      "epoch 71; iter: 0; batch classifier loss: 0.503776; batch adversarial loss: 0.535862\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433299; batch adversarial loss: 0.564991\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408271; batch adversarial loss: 0.515891\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460023; batch adversarial loss: 0.535169\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425195; batch adversarial loss: 0.545777\n",
      "epoch 76; iter: 0; batch classifier loss: 0.423539; batch adversarial loss: 0.468219\n",
      "epoch 77; iter: 0; batch classifier loss: 0.447894; batch adversarial loss: 0.554024\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368146; batch adversarial loss: 0.572427\n",
      "epoch 79; iter: 0; batch classifier loss: 0.456804; batch adversarial loss: 0.631738\n",
      "epoch 80; iter: 0; batch classifier loss: 0.388820; batch adversarial loss: 0.506202\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385195; batch adversarial loss: 0.516394\n",
      "epoch 82; iter: 0; batch classifier loss: 0.370266; batch adversarial loss: 0.536178\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345227; batch adversarial loss: 0.582719\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381309; batch adversarial loss: 0.486481\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395617; batch adversarial loss: 0.603152\n",
      "epoch 86; iter: 0; batch classifier loss: 0.429435; batch adversarial loss: 0.621566\n",
      "epoch 87; iter: 0; batch classifier loss: 0.438029; batch adversarial loss: 0.486631\n",
      "epoch 88; iter: 0; batch classifier loss: 0.464489; batch adversarial loss: 0.535410\n",
      "epoch 89; iter: 0; batch classifier loss: 0.484196; batch adversarial loss: 0.573656\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374485; batch adversarial loss: 0.505986\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412971; batch adversarial loss: 0.505597\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393235; batch adversarial loss: 0.438063\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366858; batch adversarial loss: 0.524291\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377519; batch adversarial loss: 0.544915\n",
      "epoch 95; iter: 0; batch classifier loss: 0.369812; batch adversarial loss: 0.533908\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429535; batch adversarial loss: 0.554962\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355143; batch adversarial loss: 0.506464\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339945; batch adversarial loss: 0.555728\n",
      "epoch 99; iter: 0; batch classifier loss: 0.321884; batch adversarial loss: 0.486811\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385137; batch adversarial loss: 0.553373\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393821; batch adversarial loss: 0.533956\n",
      "epoch 102; iter: 0; batch classifier loss: 0.445494; batch adversarial loss: 0.495855\n",
      "epoch 103; iter: 0; batch classifier loss: 0.393298; batch adversarial loss: 0.535133\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361321; batch adversarial loss: 0.458844\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401324; batch adversarial loss: 0.477875\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391066; batch adversarial loss: 0.487200\n",
      "epoch 107; iter: 0; batch classifier loss: 0.390417; batch adversarial loss: 0.564360\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379757; batch adversarial loss: 0.574593\n",
      "epoch 109; iter: 0; batch classifier loss: 0.443342; batch adversarial loss: 0.477567\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402577; batch adversarial loss: 0.505594\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378693; batch adversarial loss: 0.486665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.458456; batch adversarial loss: 0.486509\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374442; batch adversarial loss: 0.563657\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386510; batch adversarial loss: 0.582914\n",
      "epoch 115; iter: 0; batch classifier loss: 0.361667; batch adversarial loss: 0.515706\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370816; batch adversarial loss: 0.487839\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389533; batch adversarial loss: 0.535579\n",
      "epoch 118; iter: 0; batch classifier loss: 0.490445; batch adversarial loss: 0.494514\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428096; batch adversarial loss: 0.515531\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352608; batch adversarial loss: 0.544890\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375218; batch adversarial loss: 0.506445\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364311; batch adversarial loss: 0.515537\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408979; batch adversarial loss: 0.467645\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403188; batch adversarial loss: 0.563463\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371784; batch adversarial loss: 0.535246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.384320; batch adversarial loss: 0.564135\n",
      "epoch 127; iter: 0; batch classifier loss: 0.363969; batch adversarial loss: 0.573352\n",
      "epoch 128; iter: 0; batch classifier loss: 0.289154; batch adversarial loss: 0.525552\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324327; batch adversarial loss: 0.544846\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391594; batch adversarial loss: 0.554399\n",
      "epoch 131; iter: 0; batch classifier loss: 0.412548; batch adversarial loss: 0.535579\n",
      "epoch 132; iter: 0; batch classifier loss: 0.332801; batch adversarial loss: 0.524803\n",
      "epoch 133; iter: 0; batch classifier loss: 0.305355; batch adversarial loss: 0.601339\n",
      "epoch 134; iter: 0; batch classifier loss: 0.419477; batch adversarial loss: 0.495997\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381007; batch adversarial loss: 0.533882\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404938; batch adversarial loss: 0.553730\n",
      "epoch 137; iter: 0; batch classifier loss: 0.429472; batch adversarial loss: 0.563283\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381215; batch adversarial loss: 0.594070\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342215; batch adversarial loss: 0.497051\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384616; batch adversarial loss: 0.495568\n",
      "epoch 141; iter: 0; batch classifier loss: 0.441103; batch adversarial loss: 0.467617\n",
      "epoch 142; iter: 0; batch classifier loss: 0.366585; batch adversarial loss: 0.495400\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399136; batch adversarial loss: 0.525625\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337658; batch adversarial loss: 0.496657\n",
      "epoch 145; iter: 0; batch classifier loss: 0.395907; batch adversarial loss: 0.496318\n",
      "epoch 146; iter: 0; batch classifier loss: 0.314059; batch adversarial loss: 0.622926\n",
      "epoch 147; iter: 0; batch classifier loss: 0.328662; batch adversarial loss: 0.398940\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330377; batch adversarial loss: 0.506196\n",
      "epoch 149; iter: 0; batch classifier loss: 0.446606; batch adversarial loss: 0.496278\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384413; batch adversarial loss: 0.496369\n",
      "epoch 151; iter: 0; batch classifier loss: 0.360116; batch adversarial loss: 0.486367\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320693; batch adversarial loss: 0.525336\n",
      "epoch 153; iter: 0; batch classifier loss: 0.414312; batch adversarial loss: 0.612621\n",
      "epoch 154; iter: 0; batch classifier loss: 0.309910; batch adversarial loss: 0.564083\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362420; batch adversarial loss: 0.632313\n",
      "epoch 156; iter: 0; batch classifier loss: 0.394015; batch adversarial loss: 0.457643\n",
      "epoch 157; iter: 0; batch classifier loss: 0.307105; batch adversarial loss: 0.554622\n",
      "epoch 158; iter: 0; batch classifier loss: 0.417615; batch adversarial loss: 0.563779\n",
      "epoch 159; iter: 0; batch classifier loss: 0.453298; batch adversarial loss: 0.515648\n",
      "epoch 160; iter: 0; batch classifier loss: 0.359382; batch adversarial loss: 0.544752\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383750; batch adversarial loss: 0.534986\n",
      "epoch 162; iter: 0; batch classifier loss: 0.323175; batch adversarial loss: 0.506252\n",
      "epoch 163; iter: 0; batch classifier loss: 0.420777; batch adversarial loss: 0.564352\n",
      "epoch 164; iter: 0; batch classifier loss: 0.384882; batch adversarial loss: 0.563971\n",
      "epoch 165; iter: 0; batch classifier loss: 0.312692; batch adversarial loss: 0.554328\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359667; batch adversarial loss: 0.592846\n",
      "epoch 167; iter: 0; batch classifier loss: 0.333560; batch adversarial loss: 0.554306\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363002; batch adversarial loss: 0.506273\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367543; batch adversarial loss: 0.505959\n",
      "epoch 170; iter: 0; batch classifier loss: 0.392824; batch adversarial loss: 0.612351\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382766; batch adversarial loss: 0.525397\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373536; batch adversarial loss: 0.603039\n",
      "epoch 173; iter: 0; batch classifier loss: 0.326482; batch adversarial loss: 0.603185\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341681; batch adversarial loss: 0.622873\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332037; batch adversarial loss: 0.545256\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366740; batch adversarial loss: 0.495306\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406628; batch adversarial loss: 0.497433\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343692; batch adversarial loss: 0.514940\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339054; batch adversarial loss: 0.682404\n",
      "epoch 180; iter: 0; batch classifier loss: 0.434748; batch adversarial loss: 0.514541\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343964; batch adversarial loss: 0.602577\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364229; batch adversarial loss: 0.521389\n",
      "epoch 183; iter: 0; batch classifier loss: 0.280170; batch adversarial loss: 0.602663\n",
      "epoch 184; iter: 0; batch classifier loss: 0.393268; batch adversarial loss: 0.478354\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368776; batch adversarial loss: 0.673042\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373161; batch adversarial loss: 0.564460\n",
      "epoch 187; iter: 0; batch classifier loss: 0.331241; batch adversarial loss: 0.497780\n",
      "epoch 188; iter: 0; batch classifier loss: 0.430389; batch adversarial loss: 0.516774\n",
      "epoch 189; iter: 0; batch classifier loss: 0.387490; batch adversarial loss: 0.592025\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346151; batch adversarial loss: 0.497030\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370262; batch adversarial loss: 0.496413\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398427; batch adversarial loss: 0.507175\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359790; batch adversarial loss: 0.554155\n",
      "epoch 194; iter: 0; batch classifier loss: 0.410813; batch adversarial loss: 0.611765\n",
      "epoch 195; iter: 0; batch classifier loss: 0.472071; batch adversarial loss: 0.573418\n",
      "epoch 196; iter: 0; batch classifier loss: 0.375101; batch adversarial loss: 0.573092\n",
      "epoch 197; iter: 0; batch classifier loss: 0.330429; batch adversarial loss: 0.525650\n",
      "epoch 198; iter: 0; batch classifier loss: 0.367945; batch adversarial loss: 0.544965\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340433; batch adversarial loss: 0.496951\n",
      "epoch 0; iter: 0; batch classifier loss: 0.855594; batch adversarial loss: 0.620202\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595483; batch adversarial loss: 0.637814\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593069; batch adversarial loss: 0.626294\n",
      "epoch 3; iter: 0; batch classifier loss: 0.549797; batch adversarial loss: 0.639274\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548031; batch adversarial loss: 0.591678\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509896; batch adversarial loss: 0.619011\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520450; batch adversarial loss: 0.613204\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510443; batch adversarial loss: 0.571540\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574498; batch adversarial loss: 0.635125\n",
      "epoch 9; iter: 0; batch classifier loss: 0.658886; batch adversarial loss: 0.581996\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501605; batch adversarial loss: 0.613832\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495981; batch adversarial loss: 0.534720\n",
      "epoch 12; iter: 0; batch classifier loss: 0.596037; batch adversarial loss: 0.621952\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509202; batch adversarial loss: 0.538486\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514330; batch adversarial loss: 0.545341\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525064; batch adversarial loss: 0.553313\n",
      "epoch 16; iter: 0; batch classifier loss: 0.546214; batch adversarial loss: 0.563612\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525156; batch adversarial loss: 0.574565\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518888; batch adversarial loss: 0.559175\n",
      "epoch 19; iter: 0; batch classifier loss: 0.540679; batch adversarial loss: 0.588331\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461048; batch adversarial loss: 0.489660\n",
      "epoch 21; iter: 0; batch classifier loss: 0.576541; batch adversarial loss: 0.558191\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485258; batch adversarial loss: 0.550709\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490439; batch adversarial loss: 0.571483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.436851; batch adversarial loss: 0.530434\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467851; batch adversarial loss: 0.578991\n",
      "epoch 26; iter: 0; batch classifier loss: 0.521454; batch adversarial loss: 0.555462\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413112; batch adversarial loss: 0.588937\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413239; batch adversarial loss: 0.537857\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456164; batch adversarial loss: 0.553467\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443471; batch adversarial loss: 0.578793\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463449; batch adversarial loss: 0.596753\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474268; batch adversarial loss: 0.590729\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482925; batch adversarial loss: 0.506706\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429364; batch adversarial loss: 0.527251\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458604; batch adversarial loss: 0.500504\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438606; batch adversarial loss: 0.481662\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499315; batch adversarial loss: 0.590190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476997; batch adversarial loss: 0.535324\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500403; batch adversarial loss: 0.526393\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480701; batch adversarial loss: 0.509354\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428644; batch adversarial loss: 0.619049\n",
      "epoch 42; iter: 0; batch classifier loss: 0.566181; batch adversarial loss: 0.599597\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383371; batch adversarial loss: 0.579949\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424117; batch adversarial loss: 0.507175\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420503; batch adversarial loss: 0.488667\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397152; batch adversarial loss: 0.590330\n",
      "epoch 47; iter: 0; batch classifier loss: 0.512534; batch adversarial loss: 0.571514\n",
      "epoch 48; iter: 0; batch classifier loss: 0.361029; batch adversarial loss: 0.526433\n",
      "epoch 49; iter: 0; batch classifier loss: 0.499812; batch adversarial loss: 0.499237\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400835; batch adversarial loss: 0.451367\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453246; batch adversarial loss: 0.488348\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475180; batch adversarial loss: 0.535220\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411544; batch adversarial loss: 0.535428\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413244; batch adversarial loss: 0.645838\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408432; batch adversarial loss: 0.572076\n",
      "epoch 56; iter: 0; batch classifier loss: 0.406928; batch adversarial loss: 0.545142\n",
      "epoch 57; iter: 0; batch classifier loss: 0.418192; batch adversarial loss: 0.591058\n",
      "epoch 58; iter: 0; batch classifier loss: 0.364311; batch adversarial loss: 0.471062\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429530; batch adversarial loss: 0.544438\n",
      "epoch 60; iter: 0; batch classifier loss: 0.375192; batch adversarial loss: 0.508212\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420698; batch adversarial loss: 0.469535\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422390; batch adversarial loss: 0.617679\n",
      "epoch 63; iter: 0; batch classifier loss: 0.348412; batch adversarial loss: 0.553009\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438852; batch adversarial loss: 0.571306\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444729; batch adversarial loss: 0.524146\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459617; batch adversarial loss: 0.541759\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412062; batch adversarial loss: 0.520666\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421960; batch adversarial loss: 0.525620\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387702; batch adversarial loss: 0.592140\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391515; batch adversarial loss: 0.524281\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417888; batch adversarial loss: 0.477161\n",
      "epoch 72; iter: 0; batch classifier loss: 0.454524; batch adversarial loss: 0.526424\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377801; batch adversarial loss: 0.561086\n",
      "epoch 74; iter: 0; batch classifier loss: 0.335044; batch adversarial loss: 0.569889\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382946; batch adversarial loss: 0.528949\n",
      "epoch 76; iter: 0; batch classifier loss: 0.341975; batch adversarial loss: 0.517911\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413485; batch adversarial loss: 0.562394\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359373; batch adversarial loss: 0.602615\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403996; batch adversarial loss: 0.480560\n",
      "epoch 80; iter: 0; batch classifier loss: 0.428732; batch adversarial loss: 0.636361\n",
      "epoch 81; iter: 0; batch classifier loss: 0.461492; batch adversarial loss: 0.592012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358009; batch adversarial loss: 0.564196\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411015; batch adversarial loss: 0.535772\n",
      "epoch 84; iter: 0; batch classifier loss: 0.475865; batch adversarial loss: 0.561749\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410322; batch adversarial loss: 0.446163\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383842; batch adversarial loss: 0.526888\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402722; batch adversarial loss: 0.599132\n",
      "epoch 88; iter: 0; batch classifier loss: 0.317249; batch adversarial loss: 0.560790\n",
      "epoch 89; iter: 0; batch classifier loss: 0.331134; batch adversarial loss: 0.598925\n",
      "epoch 90; iter: 0; batch classifier loss: 0.347469; batch adversarial loss: 0.481514\n",
      "epoch 91; iter: 0; batch classifier loss: 0.335523; batch adversarial loss: 0.580744\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355297; batch adversarial loss: 0.552325\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366564; batch adversarial loss: 0.562866\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358969; batch adversarial loss: 0.595643\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322211; batch adversarial loss: 0.537275\n",
      "epoch 96; iter: 0; batch classifier loss: 0.461448; batch adversarial loss: 0.534789\n",
      "epoch 97; iter: 0; batch classifier loss: 0.474959; batch adversarial loss: 0.581263\n",
      "epoch 98; iter: 0; batch classifier loss: 0.348237; batch adversarial loss: 0.506147\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393232; batch adversarial loss: 0.563378\n",
      "epoch 100; iter: 0; batch classifier loss: 0.428325; batch adversarial loss: 0.534948\n",
      "epoch 101; iter: 0; batch classifier loss: 0.445923; batch adversarial loss: 0.608936\n",
      "epoch 102; iter: 0; batch classifier loss: 0.432219; batch adversarial loss: 0.572096\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381991; batch adversarial loss: 0.581212\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371884; batch adversarial loss: 0.518182\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432501; batch adversarial loss: 0.600928\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388093; batch adversarial loss: 0.600997\n",
      "epoch 107; iter: 0; batch classifier loss: 0.385006; batch adversarial loss: 0.562872\n",
      "epoch 108; iter: 0; batch classifier loss: 0.428921; batch adversarial loss: 0.432937\n",
      "epoch 109; iter: 0; batch classifier loss: 0.310332; batch adversarial loss: 0.553631\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353467; batch adversarial loss: 0.562976\n",
      "epoch 111; iter: 0; batch classifier loss: 0.400805; batch adversarial loss: 0.442535\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359748; batch adversarial loss: 0.497771\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405481; batch adversarial loss: 0.525657\n",
      "epoch 114; iter: 0; batch classifier loss: 0.406354; batch adversarial loss: 0.562936\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405664; batch adversarial loss: 0.609613\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396953; batch adversarial loss: 0.553713\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348412; batch adversarial loss: 0.628322\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393444; batch adversarial loss: 0.563520\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399004; batch adversarial loss: 0.506142\n",
      "epoch 120; iter: 0; batch classifier loss: 0.297537; batch adversarial loss: 0.600268\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356508; batch adversarial loss: 0.608474\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362181; batch adversarial loss: 0.656912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.440677; batch adversarial loss: 0.581371\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367364; batch adversarial loss: 0.508692\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390681; batch adversarial loss: 0.497795\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391711; batch adversarial loss: 0.498573\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422605; batch adversarial loss: 0.608398\n",
      "epoch 128; iter: 0; batch classifier loss: 0.354116; batch adversarial loss: 0.562997\n",
      "epoch 129; iter: 0; batch classifier loss: 0.294826; batch adversarial loss: 0.610772\n",
      "epoch 130; iter: 0; batch classifier loss: 0.293258; batch adversarial loss: 0.507971\n",
      "epoch 131; iter: 0; batch classifier loss: 0.322599; batch adversarial loss: 0.518255\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414385; batch adversarial loss: 0.480195\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388403; batch adversarial loss: 0.508613\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366247; batch adversarial loss: 0.571883\n",
      "epoch 135; iter: 0; batch classifier loss: 0.451261; batch adversarial loss: 0.598559\n",
      "epoch 136; iter: 0; batch classifier loss: 0.290177; batch adversarial loss: 0.544330\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334754; batch adversarial loss: 0.580357\n",
      "epoch 138; iter: 0; batch classifier loss: 0.437048; batch adversarial loss: 0.516694\n",
      "epoch 139; iter: 0; batch classifier loss: 0.330312; batch adversarial loss: 0.471855\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365641; batch adversarial loss: 0.553329\n",
      "epoch 141; iter: 0; batch classifier loss: 0.430341; batch adversarial loss: 0.471727\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326830; batch adversarial loss: 0.535692\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369708; batch adversarial loss: 0.544436\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372270; batch adversarial loss: 0.489057\n",
      "epoch 145; iter: 0; batch classifier loss: 0.434632; batch adversarial loss: 0.562657\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381528; batch adversarial loss: 0.526631\n",
      "epoch 147; iter: 0; batch classifier loss: 0.341750; batch adversarial loss: 0.544576\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354943; batch adversarial loss: 0.516656\n",
      "epoch 149; iter: 0; batch classifier loss: 0.327004; batch adversarial loss: 0.581793\n",
      "epoch 150; iter: 0; batch classifier loss: 0.366602; batch adversarial loss: 0.525732\n",
      "epoch 151; iter: 0; batch classifier loss: 0.468161; batch adversarial loss: 0.544245\n",
      "epoch 152; iter: 0; batch classifier loss: 0.437063; batch adversarial loss: 0.535095\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333888; batch adversarial loss: 0.488553\n",
      "epoch 154; iter: 0; batch classifier loss: 0.430246; batch adversarial loss: 0.581527\n",
      "epoch 155; iter: 0; batch classifier loss: 0.375338; batch adversarial loss: 0.544265\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349172; batch adversarial loss: 0.581340\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371174; batch adversarial loss: 0.600196\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353859; batch adversarial loss: 0.571903\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371061; batch adversarial loss: 0.599695\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356746; batch adversarial loss: 0.581506\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339923; batch adversarial loss: 0.553584\n",
      "epoch 162; iter: 0; batch classifier loss: 0.367229; batch adversarial loss: 0.636912\n",
      "epoch 163; iter: 0; batch classifier loss: 0.411280; batch adversarial loss: 0.571984\n",
      "epoch 164; iter: 0; batch classifier loss: 0.430630; batch adversarial loss: 0.590852\n",
      "epoch 165; iter: 0; batch classifier loss: 0.364438; batch adversarial loss: 0.563127\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342404; batch adversarial loss: 0.562845\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342813; batch adversarial loss: 0.590802\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372707; batch adversarial loss: 0.553521\n",
      "epoch 169; iter: 0; batch classifier loss: 0.404775; batch adversarial loss: 0.563048\n",
      "epoch 170; iter: 0; batch classifier loss: 0.415298; batch adversarial loss: 0.609812\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338496; batch adversarial loss: 0.414479\n",
      "epoch 172; iter: 0; batch classifier loss: 0.408584; batch adversarial loss: 0.525972\n",
      "epoch 173; iter: 0; batch classifier loss: 0.450965; batch adversarial loss: 0.563145\n",
      "epoch 174; iter: 0; batch classifier loss: 0.335149; batch adversarial loss: 0.553501\n",
      "epoch 175; iter: 0; batch classifier loss: 0.353030; batch adversarial loss: 0.618195\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372508; batch adversarial loss: 0.590422\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356938; batch adversarial loss: 0.516773\n",
      "epoch 178; iter: 0; batch classifier loss: 0.466157; batch adversarial loss: 0.600233\n",
      "epoch 179; iter: 0; batch classifier loss: 0.375975; batch adversarial loss: 0.618849\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324053; batch adversarial loss: 0.442386\n",
      "epoch 181; iter: 0; batch classifier loss: 0.307131; batch adversarial loss: 0.562903\n",
      "epoch 182; iter: 0; batch classifier loss: 0.361617; batch adversarial loss: 0.461381\n",
      "epoch 183; iter: 0; batch classifier loss: 0.423980; batch adversarial loss: 0.479902\n",
      "epoch 184; iter: 0; batch classifier loss: 0.393654; batch adversarial loss: 0.535040\n",
      "epoch 185; iter: 0; batch classifier loss: 0.293935; batch adversarial loss: 0.600306\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358023; batch adversarial loss: 0.581451\n",
      "epoch 187; iter: 0; batch classifier loss: 0.426109; batch adversarial loss: 0.581682\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363241; batch adversarial loss: 0.627967\n",
      "epoch 189; iter: 0; batch classifier loss: 0.413319; batch adversarial loss: 0.516604\n",
      "epoch 190; iter: 0; batch classifier loss: 0.371043; batch adversarial loss: 0.645467\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335008; batch adversarial loss: 0.516757\n",
      "epoch 192; iter: 0; batch classifier loss: 0.366595; batch adversarial loss: 0.516750\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327139; batch adversarial loss: 0.618854\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356776; batch adversarial loss: 0.534616\n",
      "epoch 195; iter: 0; batch classifier loss: 0.320857; batch adversarial loss: 0.590803\n",
      "epoch 196; iter: 0; batch classifier loss: 0.350366; batch adversarial loss: 0.497443\n",
      "epoch 197; iter: 0; batch classifier loss: 0.382958; batch adversarial loss: 0.542976\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383809; batch adversarial loss: 0.620129\n",
      "epoch 199; iter: 0; batch classifier loss: 0.296931; batch adversarial loss: 0.599195\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658516; batch adversarial loss: 0.794265\n",
      "epoch 1; iter: 0; batch classifier loss: 0.864383; batch adversarial loss: 0.966662\n",
      "epoch 2; iter: 0; batch classifier loss: 0.950755; batch adversarial loss: 0.893683\n",
      "epoch 3; iter: 0; batch classifier loss: 0.913395; batch adversarial loss: 0.803275\n",
      "epoch 4; iter: 0; batch classifier loss: 0.855607; batch adversarial loss: 0.760635\n",
      "epoch 5; iter: 0; batch classifier loss: 0.695904; batch adversarial loss: 0.698543\n",
      "epoch 6; iter: 0; batch classifier loss: 0.603687; batch adversarial loss: 0.647204\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575336; batch adversarial loss: 0.602551\n",
      "epoch 8; iter: 0; batch classifier loss: 0.609975; batch adversarial loss: 0.584661\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533960; batch adversarial loss: 0.578311\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516188; batch adversarial loss: 0.559847\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542935; batch adversarial loss: 0.579962\n",
      "epoch 12; iter: 0; batch classifier loss: 0.624452; batch adversarial loss: 0.552245\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506967; batch adversarial loss: 0.559819\n",
      "epoch 14; iter: 0; batch classifier loss: 0.439974; batch adversarial loss: 0.592874\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546661; batch adversarial loss: 0.567702\n",
      "epoch 16; iter: 0; batch classifier loss: 0.556048; batch adversarial loss: 0.543218\n",
      "epoch 17; iter: 0; batch classifier loss: 0.577913; batch adversarial loss: 0.556039\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535211; batch adversarial loss: 0.560886\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535587; batch adversarial loss: 0.567187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491307; batch adversarial loss: 0.603762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.527235; batch adversarial loss: 0.580259\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515326; batch adversarial loss: 0.536456\n",
      "epoch 23; iter: 0; batch classifier loss: 0.469807; batch adversarial loss: 0.524853\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499088; batch adversarial loss: 0.582634\n",
      "epoch 25; iter: 0; batch classifier loss: 0.507476; batch adversarial loss: 0.564181\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491059; batch adversarial loss: 0.584946\n",
      "epoch 27; iter: 0; batch classifier loss: 0.551713; batch adversarial loss: 0.586856\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468799; batch adversarial loss: 0.516150\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454687; batch adversarial loss: 0.479207\n",
      "epoch 30; iter: 0; batch classifier loss: 0.589201; batch adversarial loss: 0.626515\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484843; batch adversarial loss: 0.521429\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474843; batch adversarial loss: 0.536079\n",
      "epoch 33; iter: 0; batch classifier loss: 0.520365; batch adversarial loss: 0.432513\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466042; batch adversarial loss: 0.583317\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434609; batch adversarial loss: 0.532518\n",
      "epoch 36; iter: 0; batch classifier loss: 0.498484; batch adversarial loss: 0.559852\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459114; batch adversarial loss: 0.573773\n",
      "epoch 38; iter: 0; batch classifier loss: 0.360772; batch adversarial loss: 0.561252\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427003; batch adversarial loss: 0.521159\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431833; batch adversarial loss: 0.476055\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462231; batch adversarial loss: 0.619553\n",
      "epoch 42; iter: 0; batch classifier loss: 0.494712; batch adversarial loss: 0.582432\n",
      "epoch 43; iter: 0; batch classifier loss: 0.416945; batch adversarial loss: 0.509823\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375598; batch adversarial loss: 0.517011\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438991; batch adversarial loss: 0.557117\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451933; batch adversarial loss: 0.580511\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467418; batch adversarial loss: 0.624563\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406699; batch adversarial loss: 0.535813\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449823; batch adversarial loss: 0.546040\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430550; batch adversarial loss: 0.449283\n",
      "epoch 51; iter: 0; batch classifier loss: 0.301331; batch adversarial loss: 0.555001\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450014; batch adversarial loss: 0.562877\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359900; batch adversarial loss: 0.607340\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442155; batch adversarial loss: 0.579507\n",
      "epoch 55; iter: 0; batch classifier loss: 0.307957; batch adversarial loss: 0.562098\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431669; batch adversarial loss: 0.527502\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405039; batch adversarial loss: 0.580621\n",
      "epoch 58; iter: 0; batch classifier loss: 0.331109; batch adversarial loss: 0.544858\n",
      "epoch 59; iter: 0; batch classifier loss: 0.448066; batch adversarial loss: 0.616449\n",
      "epoch 60; iter: 0; batch classifier loss: 0.355471; batch adversarial loss: 0.589280\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399846; batch adversarial loss: 0.554597\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425499; batch adversarial loss: 0.579721\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430138; batch adversarial loss: 0.519399\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372721; batch adversarial loss: 0.560918\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374149; batch adversarial loss: 0.606127\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396707; batch adversarial loss: 0.588079\n",
      "epoch 67; iter: 0; batch classifier loss: 0.393279; batch adversarial loss: 0.525362\n",
      "epoch 68; iter: 0; batch classifier loss: 0.371263; batch adversarial loss: 0.578326\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382793; batch adversarial loss: 0.548730\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426527; batch adversarial loss: 0.444736\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417284; batch adversarial loss: 0.482529\n",
      "epoch 72; iter: 0; batch classifier loss: 0.364480; batch adversarial loss: 0.631605\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387250; batch adversarial loss: 0.560836\n",
      "epoch 74; iter: 0; batch classifier loss: 0.468374; batch adversarial loss: 0.444594\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370999; batch adversarial loss: 0.500609\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370440; batch adversarial loss: 0.572058\n",
      "epoch 77; iter: 0; batch classifier loss: 0.315248; batch adversarial loss: 0.664140\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359767; batch adversarial loss: 0.544314\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397556; batch adversarial loss: 0.481849\n",
      "epoch 80; iter: 0; batch classifier loss: 0.353074; batch adversarial loss: 0.526768\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394589; batch adversarial loss: 0.561353\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420384; batch adversarial loss: 0.550192\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356413; batch adversarial loss: 0.550958\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349058; batch adversarial loss: 0.508598\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383311; batch adversarial loss: 0.561154\n",
      "epoch 86; iter: 0; batch classifier loss: 0.456061; batch adversarial loss: 0.569173\n",
      "epoch 87; iter: 0; batch classifier loss: 0.460733; batch adversarial loss: 0.631450\n",
      "epoch 88; iter: 0; batch classifier loss: 0.318386; batch adversarial loss: 0.610280\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387060; batch adversarial loss: 0.537427\n",
      "epoch 90; iter: 0; batch classifier loss: 0.436521; batch adversarial loss: 0.545130\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423117; batch adversarial loss: 0.599143\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425319; batch adversarial loss: 0.598798\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394094; batch adversarial loss: 0.606296\n",
      "epoch 94; iter: 0; batch classifier loss: 0.331734; batch adversarial loss: 0.562939\n",
      "epoch 95; iter: 0; batch classifier loss: 0.374526; batch adversarial loss: 0.481992\n",
      "epoch 96; iter: 0; batch classifier loss: 0.411438; batch adversarial loss: 0.526293\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393201; batch adversarial loss: 0.563699\n",
      "epoch 98; iter: 0; batch classifier loss: 0.308684; batch adversarial loss: 0.579209\n",
      "epoch 99; iter: 0; batch classifier loss: 0.457673; batch adversarial loss: 0.534295\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404844; batch adversarial loss: 0.469888\n",
      "epoch 101; iter: 0; batch classifier loss: 0.321232; batch adversarial loss: 0.628954\n",
      "epoch 102; iter: 0; batch classifier loss: 0.343779; batch adversarial loss: 0.552134\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383122; batch adversarial loss: 0.538495\n",
      "epoch 104; iter: 0; batch classifier loss: 0.394979; batch adversarial loss: 0.500396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362441; batch adversarial loss: 0.531008\n",
      "epoch 106; iter: 0; batch classifier loss: 0.420450; batch adversarial loss: 0.534593\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399627; batch adversarial loss: 0.588842\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336410; batch adversarial loss: 0.571615\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380908; batch adversarial loss: 0.520261\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350152; batch adversarial loss: 0.471909\n",
      "epoch 111; iter: 0; batch classifier loss: 0.328843; batch adversarial loss: 0.519104\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389364; batch adversarial loss: 0.507898\n",
      "epoch 113; iter: 0; batch classifier loss: 0.402576; batch adversarial loss: 0.616965\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380160; batch adversarial loss: 0.479738\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370172; batch adversarial loss: 0.598999\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356292; batch adversarial loss: 0.623381\n",
      "epoch 117; iter: 0; batch classifier loss: 0.324992; batch adversarial loss: 0.563974\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394923; batch adversarial loss: 0.579968\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344850; batch adversarial loss: 0.534669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.302071; batch adversarial loss: 0.582059\n",
      "epoch 121; iter: 0; batch classifier loss: 0.330914; batch adversarial loss: 0.597483\n",
      "epoch 122; iter: 0; batch classifier loss: 0.433015; batch adversarial loss: 0.562302\n",
      "epoch 123; iter: 0; batch classifier loss: 0.340413; batch adversarial loss: 0.587377\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393703; batch adversarial loss: 0.541411\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415239; batch adversarial loss: 0.583025\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376511; batch adversarial loss: 0.590202\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422319; batch adversarial loss: 0.526444\n",
      "epoch 128; iter: 0; batch classifier loss: 0.248128; batch adversarial loss: 0.485964\n",
      "epoch 129; iter: 0; batch classifier loss: 0.449506; batch adversarial loss: 0.544883\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356629; batch adversarial loss: 0.499811\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338778; batch adversarial loss: 0.629224\n",
      "epoch 132; iter: 0; batch classifier loss: 0.343953; batch adversarial loss: 0.561354\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353705; batch adversarial loss: 0.589407\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399028; batch adversarial loss: 0.511253\n",
      "epoch 135; iter: 0; batch classifier loss: 0.310975; batch adversarial loss: 0.543462\n",
      "epoch 136; iter: 0; batch classifier loss: 0.447278; batch adversarial loss: 0.525493\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341603; batch adversarial loss: 0.592426\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335552; batch adversarial loss: 0.635383\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357363; batch adversarial loss: 0.527365\n",
      "epoch 140; iter: 0; batch classifier loss: 0.331505; batch adversarial loss: 0.436019\n",
      "epoch 141; iter: 0; batch classifier loss: 0.269382; batch adversarial loss: 0.517221\n",
      "epoch 142; iter: 0; batch classifier loss: 0.456917; batch adversarial loss: 0.527623\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394891; batch adversarial loss: 0.563806\n",
      "epoch 144; iter: 0; batch classifier loss: 0.292698; batch adversarial loss: 0.560632\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346862; batch adversarial loss: 0.598952\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353488; batch adversarial loss: 0.518059\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332608; batch adversarial loss: 0.564471\n",
      "epoch 148; iter: 0; batch classifier loss: 0.355740; batch adversarial loss: 0.472363\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370022; batch adversarial loss: 0.525217\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381724; batch adversarial loss: 0.589792\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349373; batch adversarial loss: 0.609210\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377708; batch adversarial loss: 0.525639\n",
      "epoch 153; iter: 0; batch classifier loss: 0.375553; batch adversarial loss: 0.561985\n",
      "epoch 154; iter: 0; batch classifier loss: 0.288709; batch adversarial loss: 0.581176\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350229; batch adversarial loss: 0.543601\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402438; batch adversarial loss: 0.578910\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335909; batch adversarial loss: 0.590813\n",
      "epoch 158; iter: 0; batch classifier loss: 0.320880; batch adversarial loss: 0.517977\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322588; batch adversarial loss: 0.632901\n",
      "epoch 160; iter: 0; batch classifier loss: 0.338080; batch adversarial loss: 0.515136\n",
      "epoch 161; iter: 0; batch classifier loss: 0.407053; batch adversarial loss: 0.527037\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366290; batch adversarial loss: 0.544346\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380445; batch adversarial loss: 0.561915\n",
      "epoch 164; iter: 0; batch classifier loss: 0.311700; batch adversarial loss: 0.527466\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397273; batch adversarial loss: 0.536009\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308902; batch adversarial loss: 0.581621\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346088; batch adversarial loss: 0.535297\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327322; batch adversarial loss: 0.526164\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321478; batch adversarial loss: 0.535770\n",
      "epoch 170; iter: 0; batch classifier loss: 0.435173; batch adversarial loss: 0.517855\n",
      "epoch 171; iter: 0; batch classifier loss: 0.325906; batch adversarial loss: 0.454721\n",
      "epoch 172; iter: 0; batch classifier loss: 0.401668; batch adversarial loss: 0.490615\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315613; batch adversarial loss: 0.578802\n",
      "epoch 174; iter: 0; batch classifier loss: 0.314691; batch adversarial loss: 0.562156\n",
      "epoch 175; iter: 0; batch classifier loss: 0.316512; batch adversarial loss: 0.535524\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368891; batch adversarial loss: 0.509804\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336045; batch adversarial loss: 0.561508\n",
      "epoch 178; iter: 0; batch classifier loss: 0.288922; batch adversarial loss: 0.500327\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362216; batch adversarial loss: 0.580490\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358304; batch adversarial loss: 0.510453\n",
      "epoch 181; iter: 0; batch classifier loss: 0.514063; batch adversarial loss: 0.571745\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370093; batch adversarial loss: 0.588595\n",
      "epoch 183; iter: 0; batch classifier loss: 0.306061; batch adversarial loss: 0.570965\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350761; batch adversarial loss: 0.516767\n",
      "epoch 185; iter: 0; batch classifier loss: 0.340051; batch adversarial loss: 0.501592\n",
      "epoch 186; iter: 0; batch classifier loss: 0.418343; batch adversarial loss: 0.554070\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360983; batch adversarial loss: 0.500211\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362142; batch adversarial loss: 0.544151\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309502; batch adversarial loss: 0.542947\n",
      "epoch 190; iter: 0; batch classifier loss: 0.302896; batch adversarial loss: 0.597471\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373678; batch adversarial loss: 0.562824\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363569; batch adversarial loss: 0.577672\n",
      "epoch 193; iter: 0; batch classifier loss: 0.394718; batch adversarial loss: 0.544390\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315225; batch adversarial loss: 0.517122\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343040; batch adversarial loss: 0.605914\n",
      "epoch 196; iter: 0; batch classifier loss: 0.286605; batch adversarial loss: 0.587273\n",
      "epoch 197; iter: 0; batch classifier loss: 0.310778; batch adversarial loss: 0.588222\n",
      "epoch 198; iter: 0; batch classifier loss: 0.305643; batch adversarial loss: 0.525975\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364093; batch adversarial loss: 0.582608\n",
      "epoch 0; iter: 0; batch classifier loss: 0.863742; batch adversarial loss: 0.933906\n",
      "epoch 1; iter: 0; batch classifier loss: 0.804608; batch adversarial loss: 0.805013\n",
      "epoch 2; iter: 0; batch classifier loss: 0.759282; batch adversarial loss: 0.786422\n",
      "epoch 3; iter: 0; batch classifier loss: 0.702724; batch adversarial loss: 0.737328\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562193; batch adversarial loss: 0.617695\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533548; batch adversarial loss: 0.686461\n",
      "epoch 6; iter: 0; batch classifier loss: 0.531439; batch adversarial loss: 0.630465\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559384; batch adversarial loss: 0.569453\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539500; batch adversarial loss: 0.609828\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524776; batch adversarial loss: 0.553815\n",
      "epoch 10; iter: 0; batch classifier loss: 0.583245; batch adversarial loss: 0.543728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543829; batch adversarial loss: 0.593280\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543645; batch adversarial loss: 0.611903\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477998; batch adversarial loss: 0.609438\n",
      "epoch 14; iter: 0; batch classifier loss: 0.562863; batch adversarial loss: 0.613722\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510390; batch adversarial loss: 0.612996\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526552; batch adversarial loss: 0.585740\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515500; batch adversarial loss: 0.526116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.467698; batch adversarial loss: 0.545404\n",
      "epoch 19; iter: 0; batch classifier loss: 0.467969; batch adversarial loss: 0.530941\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499943; batch adversarial loss: 0.552385\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530134; batch adversarial loss: 0.507554\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512619; batch adversarial loss: 0.581935\n",
      "epoch 23; iter: 0; batch classifier loss: 0.570334; batch adversarial loss: 0.567988\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483953; batch adversarial loss: 0.475179\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535741; batch adversarial loss: 0.544154\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450253; batch adversarial loss: 0.498935\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468878; batch adversarial loss: 0.457245\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477757; batch adversarial loss: 0.525095\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520320; batch adversarial loss: 0.528446\n",
      "epoch 30; iter: 0; batch classifier loss: 0.517942; batch adversarial loss: 0.539742\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453078; batch adversarial loss: 0.598619\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510409; batch adversarial loss: 0.576792\n",
      "epoch 33; iter: 0; batch classifier loss: 0.524561; batch adversarial loss: 0.625160\n",
      "epoch 34; iter: 0; batch classifier loss: 0.539322; batch adversarial loss: 0.551143\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423337; batch adversarial loss: 0.518534\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426118; batch adversarial loss: 0.482391\n",
      "epoch 37; iter: 0; batch classifier loss: 0.518066; batch adversarial loss: 0.583987\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497087; batch adversarial loss: 0.569453\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434949; batch adversarial loss: 0.529005\n",
      "epoch 40; iter: 0; batch classifier loss: 0.532685; batch adversarial loss: 0.511154\n",
      "epoch 41; iter: 0; batch classifier loss: 0.574818; batch adversarial loss: 0.502427\n",
      "epoch 42; iter: 0; batch classifier loss: 0.566969; batch adversarial loss: 0.631064\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429719; batch adversarial loss: 0.593127\n",
      "epoch 44; iter: 0; batch classifier loss: 0.479725; batch adversarial loss: 0.508743\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485161; batch adversarial loss: 0.564566\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441356; batch adversarial loss: 0.517649\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450246; batch adversarial loss: 0.563288\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457863; batch adversarial loss: 0.463494\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439650; batch adversarial loss: 0.601516\n",
      "epoch 50; iter: 0; batch classifier loss: 0.342545; batch adversarial loss: 0.563517\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453649; batch adversarial loss: 0.564761\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466870; batch adversarial loss: 0.499186\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427472; batch adversarial loss: 0.498190\n",
      "epoch 54; iter: 0; batch classifier loss: 0.511107; batch adversarial loss: 0.620458\n",
      "epoch 55; iter: 0; batch classifier loss: 0.506800; batch adversarial loss: 0.592366\n",
      "epoch 56; iter: 0; batch classifier loss: 0.364909; batch adversarial loss: 0.572985\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426602; batch adversarial loss: 0.527288\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410805; batch adversarial loss: 0.601773\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425086; batch adversarial loss: 0.553567\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384741; batch adversarial loss: 0.590540\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446231; batch adversarial loss: 0.488558\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441463; batch adversarial loss: 0.525792\n",
      "epoch 63; iter: 0; batch classifier loss: 0.482974; batch adversarial loss: 0.545021\n",
      "epoch 64; iter: 0; batch classifier loss: 0.503340; batch adversarial loss: 0.563054\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394231; batch adversarial loss: 0.487815\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406474; batch adversarial loss: 0.488194\n",
      "epoch 67; iter: 0; batch classifier loss: 0.469199; batch adversarial loss: 0.544326\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402025; batch adversarial loss: 0.516295\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412728; batch adversarial loss: 0.497499\n",
      "epoch 70; iter: 0; batch classifier loss: 0.466869; batch adversarial loss: 0.506807\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437174; batch adversarial loss: 0.553828\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355032; batch adversarial loss: 0.590833\n",
      "epoch 73; iter: 0; batch classifier loss: 0.492622; batch adversarial loss: 0.506844\n",
      "epoch 74; iter: 0; batch classifier loss: 0.449536; batch adversarial loss: 0.506714\n",
      "epoch 75; iter: 0; batch classifier loss: 0.376500; batch adversarial loss: 0.562660\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359369; batch adversarial loss: 0.601186\n",
      "epoch 77; iter: 0; batch classifier loss: 0.533087; batch adversarial loss: 0.544004\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390973; batch adversarial loss: 0.638035\n",
      "epoch 79; iter: 0; batch classifier loss: 0.471297; batch adversarial loss: 0.544727\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398186; batch adversarial loss: 0.497638\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414495; batch adversarial loss: 0.497312\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365351; batch adversarial loss: 0.526259\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375584; batch adversarial loss: 0.553837\n",
      "epoch 84; iter: 0; batch classifier loss: 0.469829; batch adversarial loss: 0.506597\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434740; batch adversarial loss: 0.450063\n",
      "epoch 86; iter: 0; batch classifier loss: 0.451366; batch adversarial loss: 0.563992\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356463; batch adversarial loss: 0.640008\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358433; batch adversarial loss: 0.449598\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403437; batch adversarial loss: 0.459779\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392500; batch adversarial loss: 0.477480\n",
      "epoch 91; iter: 0; batch classifier loss: 0.378275; batch adversarial loss: 0.608278\n",
      "epoch 92; iter: 0; batch classifier loss: 0.445968; batch adversarial loss: 0.620479\n",
      "epoch 93; iter: 0; batch classifier loss: 0.445849; batch adversarial loss: 0.508442\n",
      "epoch 94; iter: 0; batch classifier loss: 0.487317; batch adversarial loss: 0.516548\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347892; batch adversarial loss: 0.542652\n",
      "epoch 96; iter: 0; batch classifier loss: 0.439970; batch adversarial loss: 0.619488\n",
      "epoch 97; iter: 0; batch classifier loss: 0.446162; batch adversarial loss: 0.468291\n",
      "epoch 98; iter: 0; batch classifier loss: 0.425549; batch adversarial loss: 0.545008\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359048; batch adversarial loss: 0.591817\n",
      "epoch 100; iter: 0; batch classifier loss: 0.459180; batch adversarial loss: 0.553513\n",
      "epoch 101; iter: 0; batch classifier loss: 0.440737; batch adversarial loss: 0.535916\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388717; batch adversarial loss: 0.536223\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389225; batch adversarial loss: 0.589928\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351402; batch adversarial loss: 0.512685\n",
      "epoch 105; iter: 0; batch classifier loss: 0.437370; batch adversarial loss: 0.542709\n",
      "epoch 106; iter: 0; batch classifier loss: 0.358746; batch adversarial loss: 0.540677\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407020; batch adversarial loss: 0.573189\n",
      "epoch 108; iter: 0; batch classifier loss: 0.451507; batch adversarial loss: 0.527244\n",
      "epoch 109; iter: 0; batch classifier loss: 0.399095; batch adversarial loss: 0.593328\n",
      "epoch 110; iter: 0; batch classifier loss: 0.355437; batch adversarial loss: 0.534538\n",
      "epoch 111; iter: 0; batch classifier loss: 0.455604; batch adversarial loss: 0.515447\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387368; batch adversarial loss: 0.553961\n",
      "epoch 113; iter: 0; batch classifier loss: 0.361094; batch adversarial loss: 0.592741\n",
      "epoch 114; iter: 0; batch classifier loss: 0.310270; batch adversarial loss: 0.593552\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346257; batch adversarial loss: 0.478181\n",
      "epoch 116; iter: 0; batch classifier loss: 0.429442; batch adversarial loss: 0.609188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.346783; batch adversarial loss: 0.514909\n",
      "epoch 118; iter: 0; batch classifier loss: 0.444718; batch adversarial loss: 0.541815\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382558; batch adversarial loss: 0.599757\n",
      "epoch 120; iter: 0; batch classifier loss: 0.332496; batch adversarial loss: 0.547271\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355514; batch adversarial loss: 0.570968\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387984; batch adversarial loss: 0.553323\n",
      "epoch 123; iter: 0; batch classifier loss: 0.477560; batch adversarial loss: 0.535078\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340224; batch adversarial loss: 0.450915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397377; batch adversarial loss: 0.564574\n",
      "epoch 126; iter: 0; batch classifier loss: 0.429437; batch adversarial loss: 0.601682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.436958; batch adversarial loss: 0.619495\n",
      "epoch 128; iter: 0; batch classifier loss: 0.514358; batch adversarial loss: 0.527506\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377945; batch adversarial loss: 0.468933\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385942; batch adversarial loss: 0.468688\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385605; batch adversarial loss: 0.544243\n",
      "epoch 132; iter: 0; batch classifier loss: 0.374767; batch adversarial loss: 0.485940\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357586; batch adversarial loss: 0.535523\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400613; batch adversarial loss: 0.563786\n",
      "epoch 135; iter: 0; batch classifier loss: 0.426175; batch adversarial loss: 0.516350\n",
      "epoch 136; iter: 0; batch classifier loss: 0.444267; batch adversarial loss: 0.505483\n",
      "epoch 137; iter: 0; batch classifier loss: 0.404206; batch adversarial loss: 0.527688\n",
      "epoch 138; iter: 0; batch classifier loss: 0.407444; batch adversarial loss: 0.608704\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357062; batch adversarial loss: 0.517545\n",
      "epoch 140; iter: 0; batch classifier loss: 0.411933; batch adversarial loss: 0.524151\n",
      "epoch 141; iter: 0; batch classifier loss: 0.395641; batch adversarial loss: 0.592808\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363587; batch adversarial loss: 0.525971\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399757; batch adversarial loss: 0.535195\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361619; batch adversarial loss: 0.506325\n",
      "epoch 145; iter: 0; batch classifier loss: 0.430657; batch adversarial loss: 0.582446\n",
      "epoch 146; iter: 0; batch classifier loss: 0.438382; batch adversarial loss: 0.589756\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338320; batch adversarial loss: 0.544810\n",
      "epoch 148; iter: 0; batch classifier loss: 0.393477; batch adversarial loss: 0.505451\n",
      "epoch 149; iter: 0; batch classifier loss: 0.291940; batch adversarial loss: 0.515205\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370997; batch adversarial loss: 0.503705\n",
      "epoch 151; iter: 0; batch classifier loss: 0.331369; batch adversarial loss: 0.478185\n",
      "epoch 152; iter: 0; batch classifier loss: 0.435762; batch adversarial loss: 0.554425\n",
      "epoch 153; iter: 0; batch classifier loss: 0.411299; batch adversarial loss: 0.599235\n",
      "epoch 154; iter: 0; batch classifier loss: 0.327473; batch adversarial loss: 0.526823\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412491; batch adversarial loss: 0.508314\n",
      "epoch 156; iter: 0; batch classifier loss: 0.394973; batch adversarial loss: 0.574650\n",
      "epoch 157; iter: 0; batch classifier loss: 0.394366; batch adversarial loss: 0.497008\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378919; batch adversarial loss: 0.603535\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415803; batch adversarial loss: 0.535637\n",
      "epoch 160; iter: 0; batch classifier loss: 0.430415; batch adversarial loss: 0.516017\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368177; batch adversarial loss: 0.555695\n",
      "epoch 162; iter: 0; batch classifier loss: 0.302937; batch adversarial loss: 0.581154\n",
      "epoch 163; iter: 0; batch classifier loss: 0.289181; batch adversarial loss: 0.572269\n",
      "epoch 164; iter: 0; batch classifier loss: 0.313390; batch adversarial loss: 0.563786\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375922; batch adversarial loss: 0.591415\n",
      "epoch 166; iter: 0; batch classifier loss: 0.407157; batch adversarial loss: 0.582961\n",
      "epoch 167; iter: 0; batch classifier loss: 0.414097; batch adversarial loss: 0.611142\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351157; batch adversarial loss: 0.517079\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385772; batch adversarial loss: 0.601558\n",
      "epoch 170; iter: 0; batch classifier loss: 0.273013; batch adversarial loss: 0.564763\n",
      "epoch 171; iter: 0; batch classifier loss: 0.391658; batch adversarial loss: 0.544490\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370122; batch adversarial loss: 0.506035\n",
      "epoch 173; iter: 0; batch classifier loss: 0.420049; batch adversarial loss: 0.545171\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360271; batch adversarial loss: 0.525981\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351320; batch adversarial loss: 0.506307\n",
      "epoch 176; iter: 0; batch classifier loss: 0.420775; batch adversarial loss: 0.487565\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339577; batch adversarial loss: 0.497458\n",
      "epoch 178; iter: 0; batch classifier loss: 0.424202; batch adversarial loss: 0.535024\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374367; batch adversarial loss: 0.554244\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337228; batch adversarial loss: 0.544628\n",
      "epoch 181; iter: 0; batch classifier loss: 0.403374; batch adversarial loss: 0.563732\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318651; batch adversarial loss: 0.592437\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371529; batch adversarial loss: 0.591970\n",
      "epoch 184; iter: 0; batch classifier loss: 0.451029; batch adversarial loss: 0.590847\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368088; batch adversarial loss: 0.515264\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353636; batch adversarial loss: 0.507168\n",
      "epoch 187; iter: 0; batch classifier loss: 0.422082; batch adversarial loss: 0.544243\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375006; batch adversarial loss: 0.573255\n",
      "epoch 189; iter: 0; batch classifier loss: 0.396643; batch adversarial loss: 0.573436\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365980; batch adversarial loss: 0.524832\n",
      "epoch 191; iter: 0; batch classifier loss: 0.318785; batch adversarial loss: 0.545039\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338261; batch adversarial loss: 0.497699\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359227; batch adversarial loss: 0.516168\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382069; batch adversarial loss: 0.516038\n",
      "epoch 195; iter: 0; batch classifier loss: 0.285395; batch adversarial loss: 0.526631\n",
      "epoch 196; iter: 0; batch classifier loss: 0.413844; batch adversarial loss: 0.526281\n",
      "epoch 197; iter: 0; batch classifier loss: 0.346868; batch adversarial loss: 0.488021\n",
      "epoch 198; iter: 0; batch classifier loss: 0.418899; batch adversarial loss: 0.591606\n",
      "epoch 199; iter: 0; batch classifier loss: 0.443167; batch adversarial loss: 0.498189\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692199; batch adversarial loss: 0.807855\n",
      "epoch 1; iter: 0; batch classifier loss: 0.848454; batch adversarial loss: 0.957304\n",
      "epoch 2; iter: 0; batch classifier loss: 0.925561; batch adversarial loss: 0.884161\n",
      "epoch 3; iter: 0; batch classifier loss: 0.974420; batch adversarial loss: 0.804402\n",
      "epoch 4; iter: 0; batch classifier loss: 0.888019; batch adversarial loss: 0.724299\n",
      "epoch 5; iter: 0; batch classifier loss: 0.892879; batch adversarial loss: 0.679415\n",
      "epoch 6; iter: 0; batch classifier loss: 0.676417; batch adversarial loss: 0.637246\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534529; batch adversarial loss: 0.624111\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595494; batch adversarial loss: 0.600315\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547970; batch adversarial loss: 0.603301\n",
      "epoch 10; iter: 0; batch classifier loss: 0.527842; batch adversarial loss: 0.581754\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504089; batch adversarial loss: 0.601847\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509466; batch adversarial loss: 0.562216\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484960; batch adversarial loss: 0.572297\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442552; batch adversarial loss: 0.535148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.501763; batch adversarial loss: 0.606349\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503667; batch adversarial loss: 0.543506\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512258; batch adversarial loss: 0.581390\n",
      "epoch 18; iter: 0; batch classifier loss: 0.569821; batch adversarial loss: 0.565089\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489635; batch adversarial loss: 0.561137\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449359; batch adversarial loss: 0.540119\n",
      "epoch 21; iter: 0; batch classifier loss: 0.506212; batch adversarial loss: 0.618718\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498036; batch adversarial loss: 0.526797\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452850; batch adversarial loss: 0.530199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512109; batch adversarial loss: 0.533807\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474132; batch adversarial loss: 0.538153\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499766; batch adversarial loss: 0.505123\n",
      "epoch 27; iter: 0; batch classifier loss: 0.536185; batch adversarial loss: 0.481582\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498326; batch adversarial loss: 0.570132\n",
      "epoch 29; iter: 0; batch classifier loss: 0.503632; batch adversarial loss: 0.561564\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455029; batch adversarial loss: 0.513668\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464212; batch adversarial loss: 0.604304\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425484; batch adversarial loss: 0.481915\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463617; batch adversarial loss: 0.536232\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496630; batch adversarial loss: 0.459419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451402; batch adversarial loss: 0.543406\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448753; batch adversarial loss: 0.474803\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456887; batch adversarial loss: 0.590071\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450915; batch adversarial loss: 0.449262\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501001; batch adversarial loss: 0.582522\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488868; batch adversarial loss: 0.552003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458313; batch adversarial loss: 0.590974\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405756; batch adversarial loss: 0.516438\n",
      "epoch 43; iter: 0; batch classifier loss: 0.468091; batch adversarial loss: 0.500179\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411055; batch adversarial loss: 0.416859\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403839; batch adversarial loss: 0.528393\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431547; batch adversarial loss: 0.443293\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413912; batch adversarial loss: 0.515792\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379662; batch adversarial loss: 0.497347\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402758; batch adversarial loss: 0.581033\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459043; batch adversarial loss: 0.535947\n",
      "epoch 51; iter: 0; batch classifier loss: 0.473088; batch adversarial loss: 0.461699\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438011; batch adversarial loss: 0.582682\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388276; batch adversarial loss: 0.564028\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425284; batch adversarial loss: 0.498125\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411555; batch adversarial loss: 0.506730\n",
      "epoch 56; iter: 0; batch classifier loss: 0.376456; batch adversarial loss: 0.478749\n",
      "epoch 57; iter: 0; batch classifier loss: 0.469144; batch adversarial loss: 0.507015\n",
      "epoch 58; iter: 0; batch classifier loss: 0.502431; batch adversarial loss: 0.478775\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423154; batch adversarial loss: 0.553455\n",
      "epoch 60; iter: 0; batch classifier loss: 0.459813; batch adversarial loss: 0.525382\n",
      "epoch 61; iter: 0; batch classifier loss: 0.363125; batch adversarial loss: 0.600473\n",
      "epoch 62; iter: 0; batch classifier loss: 0.464895; batch adversarial loss: 0.524880\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449408; batch adversarial loss: 0.469890\n",
      "epoch 64; iter: 0; batch classifier loss: 0.491574; batch adversarial loss: 0.516079\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411578; batch adversarial loss: 0.544580\n",
      "epoch 66; iter: 0; batch classifier loss: 0.359740; batch adversarial loss: 0.515745\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381602; batch adversarial loss: 0.581617\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378502; batch adversarial loss: 0.534338\n",
      "epoch 69; iter: 0; batch classifier loss: 0.379237; batch adversarial loss: 0.533451\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459128; batch adversarial loss: 0.581279\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402049; batch adversarial loss: 0.535783\n",
      "epoch 72; iter: 0; batch classifier loss: 0.362118; batch adversarial loss: 0.553172\n",
      "epoch 73; iter: 0; batch classifier loss: 0.399206; batch adversarial loss: 0.560884\n",
      "epoch 74; iter: 0; batch classifier loss: 0.326930; batch adversarial loss: 0.541770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.331201; batch adversarial loss: 0.581423\n",
      "epoch 76; iter: 0; batch classifier loss: 0.466071; batch adversarial loss: 0.515782\n",
      "epoch 77; iter: 0; batch classifier loss: 0.361676; batch adversarial loss: 0.525931\n",
      "epoch 78; iter: 0; batch classifier loss: 0.342993; batch adversarial loss: 0.581173\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408441; batch adversarial loss: 0.563876\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366709; batch adversarial loss: 0.514421\n",
      "epoch 81; iter: 0; batch classifier loss: 0.380456; batch adversarial loss: 0.516214\n",
      "epoch 82; iter: 0; batch classifier loss: 0.364852; batch adversarial loss: 0.554152\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411087; batch adversarial loss: 0.544716\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435660; batch adversarial loss: 0.581821\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366867; batch adversarial loss: 0.458124\n",
      "epoch 86; iter: 0; batch classifier loss: 0.347064; batch adversarial loss: 0.533747\n",
      "epoch 87; iter: 0; batch classifier loss: 0.315639; batch adversarial loss: 0.563283\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389691; batch adversarial loss: 0.516550\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409297; batch adversarial loss: 0.515987\n",
      "epoch 90; iter: 0; batch classifier loss: 0.330567; batch adversarial loss: 0.600012\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434844; batch adversarial loss: 0.541421\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404699; batch adversarial loss: 0.572270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.487921; batch adversarial loss: 0.551504\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372482; batch adversarial loss: 0.526936\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347521; batch adversarial loss: 0.468918\n",
      "epoch 96; iter: 0; batch classifier loss: 0.325627; batch adversarial loss: 0.563806\n",
      "epoch 97; iter: 0; batch classifier loss: 0.314406; batch adversarial loss: 0.450932\n",
      "epoch 98; iter: 0; batch classifier loss: 0.322387; batch adversarial loss: 0.553899\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386352; batch adversarial loss: 0.572796\n",
      "epoch 100; iter: 0; batch classifier loss: 0.362702; batch adversarial loss: 0.486946\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405083; batch adversarial loss: 0.640219\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369969; batch adversarial loss: 0.517437\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373958; batch adversarial loss: 0.526286\n",
      "epoch 104; iter: 0; batch classifier loss: 0.442205; batch adversarial loss: 0.525260\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342468; batch adversarial loss: 0.535568\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333775; batch adversarial loss: 0.515494\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396537; batch adversarial loss: 0.525837\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375529; batch adversarial loss: 0.469424\n",
      "epoch 109; iter: 0; batch classifier loss: 0.317573; batch adversarial loss: 0.617313\n",
      "epoch 110; iter: 0; batch classifier loss: 0.448250; batch adversarial loss: 0.529932\n",
      "epoch 111; iter: 0; batch classifier loss: 0.284634; batch adversarial loss: 0.554258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.358885; batch adversarial loss: 0.468073\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353359; batch adversarial loss: 0.555057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.323783; batch adversarial loss: 0.516601\n",
      "epoch 115; iter: 0; batch classifier loss: 0.320371; batch adversarial loss: 0.480456\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377973; batch adversarial loss: 0.522979\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363135; batch adversarial loss: 0.517821\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374612; batch adversarial loss: 0.532945\n",
      "epoch 119; iter: 0; batch classifier loss: 0.319726; batch adversarial loss: 0.590625\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349087; batch adversarial loss: 0.469450\n",
      "epoch 121; iter: 0; batch classifier loss: 0.337226; batch adversarial loss: 0.495344\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352240; batch adversarial loss: 0.564388\n",
      "epoch 123; iter: 0; batch classifier loss: 0.330041; batch adversarial loss: 0.459672\n",
      "epoch 124; iter: 0; batch classifier loss: 0.302190; batch adversarial loss: 0.515438\n",
      "epoch 125; iter: 0; batch classifier loss: 0.297849; batch adversarial loss: 0.497516\n",
      "epoch 126; iter: 0; batch classifier loss: 0.401203; batch adversarial loss: 0.631838\n",
      "epoch 127; iter: 0; batch classifier loss: 0.441078; batch adversarial loss: 0.496868\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340928; batch adversarial loss: 0.553960\n",
      "epoch 129; iter: 0; batch classifier loss: 0.506041; batch adversarial loss: 0.611525\n",
      "epoch 130; iter: 0; batch classifier loss: 0.328888; batch adversarial loss: 0.544604\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349024; batch adversarial loss: 0.545166\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414914; batch adversarial loss: 0.451364\n",
      "epoch 133; iter: 0; batch classifier loss: 0.330184; batch adversarial loss: 0.507099\n",
      "epoch 134; iter: 0; batch classifier loss: 0.348737; batch adversarial loss: 0.591882\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380666; batch adversarial loss: 0.610967\n",
      "epoch 136; iter: 0; batch classifier loss: 0.309695; batch adversarial loss: 0.525300\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385383; batch adversarial loss: 0.515488\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364497; batch adversarial loss: 0.600713\n",
      "epoch 139; iter: 0; batch classifier loss: 0.326196; batch adversarial loss: 0.561913\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377229; batch adversarial loss: 0.609062\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323034; batch adversarial loss: 0.536045\n",
      "epoch 142; iter: 0; batch classifier loss: 0.416661; batch adversarial loss: 0.477462\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368684; batch adversarial loss: 0.535690\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362242; batch adversarial loss: 0.611609\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319245; batch adversarial loss: 0.524920\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404155; batch adversarial loss: 0.535461\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322584; batch adversarial loss: 0.543745\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381573; batch adversarial loss: 0.515649\n",
      "epoch 149; iter: 0; batch classifier loss: 0.337047; batch adversarial loss: 0.554328\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353967; batch adversarial loss: 0.478115\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325471; batch adversarial loss: 0.488598\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338083; batch adversarial loss: 0.554119\n",
      "epoch 153; iter: 0; batch classifier loss: 0.264923; batch adversarial loss: 0.544909\n",
      "epoch 154; iter: 0; batch classifier loss: 0.306309; batch adversarial loss: 0.535499\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369685; batch adversarial loss: 0.496849\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359233; batch adversarial loss: 0.620335\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312903; batch adversarial loss: 0.592709\n",
      "epoch 158; iter: 0; batch classifier loss: 0.302367; batch adversarial loss: 0.580008\n",
      "epoch 159; iter: 0; batch classifier loss: 0.340287; batch adversarial loss: 0.554703\n",
      "epoch 160; iter: 0; batch classifier loss: 0.388397; batch adversarial loss: 0.526592\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380758; batch adversarial loss: 0.498771\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364772; batch adversarial loss: 0.543077\n",
      "epoch 163; iter: 0; batch classifier loss: 0.312699; batch adversarial loss: 0.477832\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330449; batch adversarial loss: 0.610771\n",
      "epoch 165; iter: 0; batch classifier loss: 0.351546; batch adversarial loss: 0.566099\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389538; batch adversarial loss: 0.536178\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363502; batch adversarial loss: 0.534950\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372919; batch adversarial loss: 0.497960\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342691; batch adversarial loss: 0.573036\n",
      "epoch 170; iter: 0; batch classifier loss: 0.305910; batch adversarial loss: 0.533022\n",
      "epoch 171; iter: 0; batch classifier loss: 0.403035; batch adversarial loss: 0.527594\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346599; batch adversarial loss: 0.602020\n",
      "epoch 173; iter: 0; batch classifier loss: 0.395192; batch adversarial loss: 0.507664\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347177; batch adversarial loss: 0.544626\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308478; batch adversarial loss: 0.507201\n",
      "epoch 176; iter: 0; batch classifier loss: 0.306139; batch adversarial loss: 0.545542\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358474; batch adversarial loss: 0.553991\n",
      "epoch 178; iter: 0; batch classifier loss: 0.315697; batch adversarial loss: 0.448226\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329768; batch adversarial loss: 0.506461\n",
      "epoch 180; iter: 0; batch classifier loss: 0.342878; batch adversarial loss: 0.572739\n",
      "epoch 181; iter: 0; batch classifier loss: 0.242659; batch adversarial loss: 0.553072\n",
      "epoch 182; iter: 0; batch classifier loss: 0.258689; batch adversarial loss: 0.573045\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379070; batch adversarial loss: 0.525152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.291142; batch adversarial loss: 0.525296\n",
      "epoch 185; iter: 0; batch classifier loss: 0.292576; batch adversarial loss: 0.486515\n",
      "epoch 186; iter: 0; batch classifier loss: 0.271729; batch adversarial loss: 0.487628\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370647; batch adversarial loss: 0.505311\n",
      "epoch 188; iter: 0; batch classifier loss: 0.340243; batch adversarial loss: 0.525943\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346826; batch adversarial loss: 0.602240\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343013; batch adversarial loss: 0.599422\n",
      "epoch 191; iter: 0; batch classifier loss: 0.265674; batch adversarial loss: 0.572683\n",
      "epoch 192; iter: 0; batch classifier loss: 0.289182; batch adversarial loss: 0.545113\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331327; batch adversarial loss: 0.515900\n",
      "epoch 194; iter: 0; batch classifier loss: 0.275070; batch adversarial loss: 0.563601\n",
      "epoch 195; iter: 0; batch classifier loss: 0.400137; batch adversarial loss: 0.583115\n",
      "epoch 196; iter: 0; batch classifier loss: 0.284214; batch adversarial loss: 0.534537\n",
      "epoch 197; iter: 0; batch classifier loss: 0.282032; batch adversarial loss: 0.468280\n",
      "epoch 198; iter: 0; batch classifier loss: 0.300401; batch adversarial loss: 0.535456\n",
      "epoch 199; iter: 0; batch classifier loss: 0.358204; batch adversarial loss: 0.496820\n",
      "epoch 0; iter: 0; batch classifier loss: 0.798073; batch adversarial loss: 0.880242\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613421; batch adversarial loss: 0.808499\n",
      "epoch 2; iter: 0; batch classifier loss: 0.596402; batch adversarial loss: 0.716629\n",
      "epoch 3; iter: 0; batch classifier loss: 0.574096; batch adversarial loss: 0.691809\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539299; batch adversarial loss: 0.651138\n",
      "epoch 5; iter: 0; batch classifier loss: 0.622084; batch adversarial loss: 0.628696\n",
      "epoch 6; iter: 0; batch classifier loss: 0.609236; batch adversarial loss: 0.627765\n",
      "epoch 7; iter: 0; batch classifier loss: 0.511521; batch adversarial loss: 0.608198\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536550; batch adversarial loss: 0.608515\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542482; batch adversarial loss: 0.627790\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543029; batch adversarial loss: 0.558496\n",
      "epoch 11; iter: 0; batch classifier loss: 0.479580; batch adversarial loss: 0.542973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.583197; batch adversarial loss: 0.587138\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504321; batch adversarial loss: 0.578584\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548689; batch adversarial loss: 0.542223\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512538; batch adversarial loss: 0.556824\n",
      "epoch 16; iter: 0; batch classifier loss: 0.479706; batch adversarial loss: 0.495822\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522043; batch adversarial loss: 0.559679\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508844; batch adversarial loss: 0.527273\n",
      "epoch 19; iter: 0; batch classifier loss: 0.549963; batch adversarial loss: 0.497227\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514732; batch adversarial loss: 0.601207\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488362; batch adversarial loss: 0.471333\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473796; batch adversarial loss: 0.572707\n",
      "epoch 23; iter: 0; batch classifier loss: 0.403367; batch adversarial loss: 0.536197\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453745; batch adversarial loss: 0.584443\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521798; batch adversarial loss: 0.558009\n",
      "epoch 26; iter: 0; batch classifier loss: 0.557313; batch adversarial loss: 0.545731\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480966; batch adversarial loss: 0.576799\n",
      "epoch 28; iter: 0; batch classifier loss: 0.424338; batch adversarial loss: 0.560004\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495769; batch adversarial loss: 0.492616\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504310; batch adversarial loss: 0.549044\n",
      "epoch 31; iter: 0; batch classifier loss: 0.519809; batch adversarial loss: 0.557817\n",
      "epoch 32; iter: 0; batch classifier loss: 0.508466; batch adversarial loss: 0.531363\n",
      "epoch 33; iter: 0; batch classifier loss: 0.431320; batch adversarial loss: 0.572788\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485653; batch adversarial loss: 0.513852\n",
      "epoch 35; iter: 0; batch classifier loss: 0.372097; batch adversarial loss: 0.545589\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496443; batch adversarial loss: 0.561682\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429053; batch adversarial loss: 0.518490\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447019; batch adversarial loss: 0.562256\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445035; batch adversarial loss: 0.499412\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419282; batch adversarial loss: 0.535472\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473553; batch adversarial loss: 0.572317\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481873; batch adversarial loss: 0.498745\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454553; batch adversarial loss: 0.526381\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438784; batch adversarial loss: 0.431596\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405592; batch adversarial loss: 0.544468\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495454; batch adversarial loss: 0.525961\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431102; batch adversarial loss: 0.534230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.380767; batch adversarial loss: 0.517246\n",
      "epoch 49; iter: 0; batch classifier loss: 0.507447; batch adversarial loss: 0.584365\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402920; batch adversarial loss: 0.522405\n",
      "epoch 51; iter: 0; batch classifier loss: 0.371038; batch adversarial loss: 0.524827\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433592; batch adversarial loss: 0.486235\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417658; batch adversarial loss: 0.532832\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414670; batch adversarial loss: 0.578476\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448370; batch adversarial loss: 0.530462\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430797; batch adversarial loss: 0.527111\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389759; batch adversarial loss: 0.552942\n",
      "epoch 58; iter: 0; batch classifier loss: 0.363477; batch adversarial loss: 0.580099\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391939; batch adversarial loss: 0.679616\n",
      "epoch 60; iter: 0; batch classifier loss: 0.364865; batch adversarial loss: 0.460303\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395599; batch adversarial loss: 0.516598\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425548; batch adversarial loss: 0.567233\n",
      "epoch 63; iter: 0; batch classifier loss: 0.472940; batch adversarial loss: 0.545078\n",
      "epoch 64; iter: 0; batch classifier loss: 0.311322; batch adversarial loss: 0.480625\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412459; batch adversarial loss: 0.572975\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443463; batch adversarial loss: 0.553316\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410297; batch adversarial loss: 0.583088\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377007; batch adversarial loss: 0.517538\n",
      "epoch 69; iter: 0; batch classifier loss: 0.332875; batch adversarial loss: 0.534281\n",
      "epoch 70; iter: 0; batch classifier loss: 0.342266; batch adversarial loss: 0.554453\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403448; batch adversarial loss: 0.574371\n",
      "epoch 72; iter: 0; batch classifier loss: 0.449866; batch adversarial loss: 0.619681\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369937; batch adversarial loss: 0.496767\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397562; batch adversarial loss: 0.611645\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357520; batch adversarial loss: 0.485911\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380736; batch adversarial loss: 0.468446\n",
      "epoch 77; iter: 0; batch classifier loss: 0.365622; batch adversarial loss: 0.478914\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406707; batch adversarial loss: 0.479486\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425557; batch adversarial loss: 0.610785\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421949; batch adversarial loss: 0.516501\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403537; batch adversarial loss: 0.507032\n",
      "epoch 82; iter: 0; batch classifier loss: 0.392812; batch adversarial loss: 0.515630\n",
      "epoch 83; iter: 0; batch classifier loss: 0.359967; batch adversarial loss: 0.506660\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416661; batch adversarial loss: 0.440017\n",
      "epoch 85; iter: 0; batch classifier loss: 0.312359; batch adversarial loss: 0.554040\n",
      "epoch 86; iter: 0; batch classifier loss: 0.296048; batch adversarial loss: 0.478295\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393612; batch adversarial loss: 0.469300\n",
      "epoch 88; iter: 0; batch classifier loss: 0.444465; batch adversarial loss: 0.525843\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373865; batch adversarial loss: 0.497397\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359530; batch adversarial loss: 0.535760\n",
      "epoch 91; iter: 0; batch classifier loss: 0.419884; batch adversarial loss: 0.544241\n",
      "epoch 92; iter: 0; batch classifier loss: 0.369808; batch adversarial loss: 0.486645\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371165; batch adversarial loss: 0.524719\n",
      "epoch 94; iter: 0; batch classifier loss: 0.352988; batch adversarial loss: 0.496741\n",
      "epoch 95; iter: 0; batch classifier loss: 0.310972; batch adversarial loss: 0.504564\n",
      "epoch 96; iter: 0; batch classifier loss: 0.365514; batch adversarial loss: 0.504920\n",
      "epoch 97; iter: 0; batch classifier loss: 0.321642; batch adversarial loss: 0.649261\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396390; batch adversarial loss: 0.564495\n",
      "epoch 99; iter: 0; batch classifier loss: 0.437810; batch adversarial loss: 0.536477\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423376; batch adversarial loss: 0.602308\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362628; batch adversarial loss: 0.583923\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342128; batch adversarial loss: 0.582843\n",
      "epoch 103; iter: 0; batch classifier loss: 0.332511; batch adversarial loss: 0.554954\n",
      "epoch 104; iter: 0; batch classifier loss: 0.338049; batch adversarial loss: 0.553878\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424034; batch adversarial loss: 0.487004\n",
      "epoch 106; iter: 0; batch classifier loss: 0.431330; batch adversarial loss: 0.487233\n",
      "epoch 107; iter: 0; batch classifier loss: 0.440352; batch adversarial loss: 0.431030\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383083; batch adversarial loss: 0.506136\n",
      "epoch 109; iter: 0; batch classifier loss: 0.393656; batch adversarial loss: 0.516625\n",
      "epoch 110; iter: 0; batch classifier loss: 0.485043; batch adversarial loss: 0.516416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.417260; batch adversarial loss: 0.591747\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347160; batch adversarial loss: 0.554291\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368357; batch adversarial loss: 0.535111\n",
      "epoch 114; iter: 0; batch classifier loss: 0.309334; batch adversarial loss: 0.487571\n",
      "epoch 115; iter: 0; batch classifier loss: 0.376779; batch adversarial loss: 0.515987\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412488; batch adversarial loss: 0.468693\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365267; batch adversarial loss: 0.544547\n",
      "epoch 118; iter: 0; batch classifier loss: 0.464502; batch adversarial loss: 0.447506\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388769; batch adversarial loss: 0.486366\n",
      "epoch 120; iter: 0; batch classifier loss: 0.411151; batch adversarial loss: 0.622461\n",
      "epoch 121; iter: 0; batch classifier loss: 0.321593; batch adversarial loss: 0.524777\n",
      "epoch 122; iter: 0; batch classifier loss: 0.299686; batch adversarial loss: 0.506077\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351568; batch adversarial loss: 0.487914\n",
      "epoch 124; iter: 0; batch classifier loss: 0.304111; batch adversarial loss: 0.535273\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376466; batch adversarial loss: 0.525979\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334416; batch adversarial loss: 0.535343\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329548; batch adversarial loss: 0.516175\n",
      "epoch 128; iter: 0; batch classifier loss: 0.339580; batch adversarial loss: 0.544582\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367915; batch adversarial loss: 0.582624\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340813; batch adversarial loss: 0.649297\n",
      "epoch 131; iter: 0; batch classifier loss: 0.299201; batch adversarial loss: 0.468342\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354734; batch adversarial loss: 0.563751\n",
      "epoch 133; iter: 0; batch classifier loss: 0.319240; batch adversarial loss: 0.554209\n",
      "epoch 134; iter: 0; batch classifier loss: 0.391774; batch adversarial loss: 0.487218\n",
      "epoch 135; iter: 0; batch classifier loss: 0.317678; batch adversarial loss: 0.544533\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348928; batch adversarial loss: 0.554071\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371184; batch adversarial loss: 0.525838\n",
      "epoch 138; iter: 0; batch classifier loss: 0.311084; batch adversarial loss: 0.525354\n",
      "epoch 139; iter: 0; batch classifier loss: 0.326469; batch adversarial loss: 0.563226\n",
      "epoch 140; iter: 0; batch classifier loss: 0.406640; batch adversarial loss: 0.565527\n",
      "epoch 141; iter: 0; batch classifier loss: 0.397259; batch adversarial loss: 0.496870\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384450; batch adversarial loss: 0.429515\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348669; batch adversarial loss: 0.564792\n",
      "epoch 144; iter: 0; batch classifier loss: 0.429382; batch adversarial loss: 0.477726\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372261; batch adversarial loss: 0.545462\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371052; batch adversarial loss: 0.582792\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349475; batch adversarial loss: 0.535419\n",
      "epoch 148; iter: 0; batch classifier loss: 0.447631; batch adversarial loss: 0.477902\n",
      "epoch 149; iter: 0; batch classifier loss: 0.302707; batch adversarial loss: 0.631419\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384731; batch adversarial loss: 0.601706\n",
      "epoch 151; iter: 0; batch classifier loss: 0.380844; batch adversarial loss: 0.505929\n",
      "epoch 152; iter: 0; batch classifier loss: 0.314677; batch adversarial loss: 0.572398\n",
      "epoch 153; iter: 0; batch classifier loss: 0.439239; batch adversarial loss: 0.564058\n",
      "epoch 154; iter: 0; batch classifier loss: 0.383025; batch adversarial loss: 0.553551\n",
      "epoch 155; iter: 0; batch classifier loss: 0.286298; batch adversarial loss: 0.525908\n",
      "epoch 156; iter: 0; batch classifier loss: 0.313689; batch adversarial loss: 0.506698\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393819; batch adversarial loss: 0.554101\n",
      "epoch 158; iter: 0; batch classifier loss: 0.413468; batch adversarial loss: 0.525856\n",
      "epoch 159; iter: 0; batch classifier loss: 0.420875; batch adversarial loss: 0.592317\n",
      "epoch 160; iter: 0; batch classifier loss: 0.391265; batch adversarial loss: 0.487870\n",
      "epoch 161; iter: 0; batch classifier loss: 0.445515; batch adversarial loss: 0.515934\n",
      "epoch 162; iter: 0; batch classifier loss: 0.338700; batch adversarial loss: 0.487853\n",
      "epoch 163; iter: 0; batch classifier loss: 0.337304; batch adversarial loss: 0.525859\n",
      "epoch 164; iter: 0; batch classifier loss: 0.419452; batch adversarial loss: 0.506287\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318118; batch adversarial loss: 0.515799\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380848; batch adversarial loss: 0.572771\n",
      "epoch 167; iter: 0; batch classifier loss: 0.322464; batch adversarial loss: 0.563745\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366616; batch adversarial loss: 0.611556\n",
      "epoch 169; iter: 0; batch classifier loss: 0.301636; batch adversarial loss: 0.487339\n",
      "epoch 170; iter: 0; batch classifier loss: 0.313603; batch adversarial loss: 0.601986\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320717; batch adversarial loss: 0.506560\n",
      "epoch 172; iter: 0; batch classifier loss: 0.340767; batch adversarial loss: 0.459058\n",
      "epoch 173; iter: 0; batch classifier loss: 0.368634; batch adversarial loss: 0.496147\n",
      "epoch 174; iter: 0; batch classifier loss: 0.328256; batch adversarial loss: 0.467659\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357666; batch adversarial loss: 0.524925\n",
      "epoch 176; iter: 0; batch classifier loss: 0.299918; batch adversarial loss: 0.496120\n",
      "epoch 177; iter: 0; batch classifier loss: 0.317092; batch adversarial loss: 0.563226\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331976; batch adversarial loss: 0.592143\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351638; batch adversarial loss: 0.554133\n",
      "epoch 180; iter: 0; batch classifier loss: 0.271022; batch adversarial loss: 0.572381\n",
      "epoch 181; iter: 0; batch classifier loss: 0.286085; batch adversarial loss: 0.574194\n",
      "epoch 182; iter: 0; batch classifier loss: 0.462306; batch adversarial loss: 0.467650\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342228; batch adversarial loss: 0.602853\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383992; batch adversarial loss: 0.620477\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336623; batch adversarial loss: 0.583062\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355297; batch adversarial loss: 0.487767\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334338; batch adversarial loss: 0.545135\n",
      "epoch 188; iter: 0; batch classifier loss: 0.331474; batch adversarial loss: 0.601758\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380298; batch adversarial loss: 0.525874\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368608; batch adversarial loss: 0.592349\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338676; batch adversarial loss: 0.553911\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365634; batch adversarial loss: 0.478485\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331066; batch adversarial loss: 0.544502\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336621; batch adversarial loss: 0.543994\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302748; batch adversarial loss: 0.553860\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314186; batch adversarial loss: 0.506035\n",
      "epoch 197; iter: 0; batch classifier loss: 0.286936; batch adversarial loss: 0.515520\n",
      "epoch 198; iter: 0; batch classifier loss: 0.296537; batch adversarial loss: 0.534914\n",
      "epoch 199; iter: 0; batch classifier loss: 0.373239; batch adversarial loss: 0.535242\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715341; batch adversarial loss: 0.879122\n",
      "epoch 1; iter: 0; batch classifier loss: 0.738102; batch adversarial loss: 0.890028\n",
      "epoch 2; iter: 0; batch classifier loss: 0.735388; batch adversarial loss: 0.828850\n",
      "epoch 3; iter: 0; batch classifier loss: 0.676209; batch adversarial loss: 0.762203\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614877; batch adversarial loss: 0.695914\n",
      "epoch 5; iter: 0; batch classifier loss: 0.475283; batch adversarial loss: 0.658758\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528337; batch adversarial loss: 0.624814\n",
      "epoch 7; iter: 0; batch classifier loss: 0.621070; batch adversarial loss: 0.618039\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520073; batch adversarial loss: 0.603879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.548908; batch adversarial loss: 0.613038\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499062; batch adversarial loss: 0.623135\n",
      "epoch 11; iter: 0; batch classifier loss: 0.603214; batch adversarial loss: 0.610954\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571892; batch adversarial loss: 0.582475\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553156; batch adversarial loss: 0.586500\n",
      "epoch 14; iter: 0; batch classifier loss: 0.570347; batch adversarial loss: 0.530918\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533717; batch adversarial loss: 0.541015\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531068; batch adversarial loss: 0.542691\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509404; batch adversarial loss: 0.565014\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499040; batch adversarial loss: 0.598012\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504928; batch adversarial loss: 0.523214\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465070; batch adversarial loss: 0.546888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480743; batch adversarial loss: 0.586099\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478362; batch adversarial loss: 0.602763\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485349; batch adversarial loss: 0.583641\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480405; batch adversarial loss: 0.581567\n",
      "epoch 25; iter: 0; batch classifier loss: 0.542630; batch adversarial loss: 0.569865\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432621; batch adversarial loss: 0.603435\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455793; batch adversarial loss: 0.616990\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456814; batch adversarial loss: 0.606143\n",
      "epoch 29; iter: 0; batch classifier loss: 0.551402; batch adversarial loss: 0.550753\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436348; batch adversarial loss: 0.582452\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470106; batch adversarial loss: 0.549794\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448817; batch adversarial loss: 0.572434\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451353; batch adversarial loss: 0.627592\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448823; batch adversarial loss: 0.572192\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465541; batch adversarial loss: 0.579401\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464429; batch adversarial loss: 0.554364\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428195; batch adversarial loss: 0.595596\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455224; batch adversarial loss: 0.562462\n",
      "epoch 39; iter: 0; batch classifier loss: 0.379901; batch adversarial loss: 0.467780\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463990; batch adversarial loss: 0.554547\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443989; batch adversarial loss: 0.580093\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462882; batch adversarial loss: 0.561714\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418064; batch adversarial loss: 0.554617\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483547; batch adversarial loss: 0.579085\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429973; batch adversarial loss: 0.643623\n",
      "epoch 46; iter: 0; batch classifier loss: 0.391228; batch adversarial loss: 0.536227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.502392; batch adversarial loss: 0.535326\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418485; batch adversarial loss: 0.614452\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449487; batch adversarial loss: 0.544013\n",
      "epoch 50; iter: 0; batch classifier loss: 0.360295; batch adversarial loss: 0.517286\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448805; batch adversarial loss: 0.560282\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445587; batch adversarial loss: 0.553570\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391726; batch adversarial loss: 0.565927\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422371; batch adversarial loss: 0.561410\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449068; batch adversarial loss: 0.555564\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414919; batch adversarial loss: 0.588908\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441153; batch adversarial loss: 0.594806\n",
      "epoch 58; iter: 0; batch classifier loss: 0.484643; batch adversarial loss: 0.580681\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457486; batch adversarial loss: 0.578574\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409257; batch adversarial loss: 0.526808\n",
      "epoch 61; iter: 0; batch classifier loss: 0.447432; batch adversarial loss: 0.460442\n",
      "epoch 62; iter: 0; batch classifier loss: 0.470792; batch adversarial loss: 0.490735\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384450; batch adversarial loss: 0.499167\n",
      "epoch 64; iter: 0; batch classifier loss: 0.353017; batch adversarial loss: 0.508254\n",
      "epoch 65; iter: 0; batch classifier loss: 0.471878; batch adversarial loss: 0.499377\n",
      "epoch 66; iter: 0; batch classifier loss: 0.393929; batch adversarial loss: 0.555861\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425313; batch adversarial loss: 0.527522\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391547; batch adversarial loss: 0.492018\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401674; batch adversarial loss: 0.560958\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417862; batch adversarial loss: 0.526564\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391164; batch adversarial loss: 0.517306\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380266; batch adversarial loss: 0.578866\n",
      "epoch 73; iter: 0; batch classifier loss: 0.514352; batch adversarial loss: 0.520495\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415421; batch adversarial loss: 0.589430\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371649; batch adversarial loss: 0.479110\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399747; batch adversarial loss: 0.554160\n",
      "epoch 77; iter: 0; batch classifier loss: 0.343746; batch adversarial loss: 0.549589\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448571; batch adversarial loss: 0.560348\n",
      "epoch 79; iter: 0; batch classifier loss: 0.276621; batch adversarial loss: 0.480278\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398202; batch adversarial loss: 0.543796\n",
      "epoch 81; iter: 0; batch classifier loss: 0.329022; batch adversarial loss: 0.554672\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415263; batch adversarial loss: 0.534090\n",
      "epoch 83; iter: 0; batch classifier loss: 0.357123; batch adversarial loss: 0.563445\n",
      "epoch 84; iter: 0; batch classifier loss: 0.470639; batch adversarial loss: 0.651938\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431078; batch adversarial loss: 0.561833\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380630; batch adversarial loss: 0.536911\n",
      "epoch 87; iter: 0; batch classifier loss: 0.271857; batch adversarial loss: 0.544873\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377348; batch adversarial loss: 0.489943\n",
      "epoch 89; iter: 0; batch classifier loss: 0.477551; batch adversarial loss: 0.578923\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401685; batch adversarial loss: 0.606880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.331487; batch adversarial loss: 0.508075\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402853; batch adversarial loss: 0.580567\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394616; batch adversarial loss: 0.508628\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380685; batch adversarial loss: 0.482234\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394912; batch adversarial loss: 0.591029\n",
      "epoch 96; iter: 0; batch classifier loss: 0.319098; batch adversarial loss: 0.561696\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437593; batch adversarial loss: 0.552390\n",
      "epoch 98; iter: 0; batch classifier loss: 0.297552; batch adversarial loss: 0.544766\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390911; batch adversarial loss: 0.596875\n",
      "epoch 100; iter: 0; batch classifier loss: 0.455386; batch adversarial loss: 0.525964\n",
      "epoch 101; iter: 0; batch classifier loss: 0.513407; batch adversarial loss: 0.525740\n",
      "epoch 102; iter: 0; batch classifier loss: 0.455854; batch adversarial loss: 0.597873\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379457; batch adversarial loss: 0.577701\n",
      "epoch 104; iter: 0; batch classifier loss: 0.329787; batch adversarial loss: 0.535683\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416967; batch adversarial loss: 0.615963\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384480; batch adversarial loss: 0.508282\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364057; batch adversarial loss: 0.520363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.333596; batch adversarial loss: 0.517195\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363023; batch adversarial loss: 0.498244\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398600; batch adversarial loss: 0.572029\n",
      "epoch 111; iter: 0; batch classifier loss: 0.290499; batch adversarial loss: 0.562194\n",
      "epoch 112; iter: 0; batch classifier loss: 0.329275; batch adversarial loss: 0.525947\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417335; batch adversarial loss: 0.498312\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402750; batch adversarial loss: 0.580547\n",
      "epoch 115; iter: 0; batch classifier loss: 0.458217; batch adversarial loss: 0.588250\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343281; batch adversarial loss: 0.545117\n",
      "epoch 117; iter: 0; batch classifier loss: 0.404431; batch adversarial loss: 0.552916\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352065; batch adversarial loss: 0.517749\n",
      "epoch 119; iter: 0; batch classifier loss: 0.357652; batch adversarial loss: 0.535681\n",
      "epoch 120; iter: 0; batch classifier loss: 0.340246; batch adversarial loss: 0.598688\n",
      "epoch 121; iter: 0; batch classifier loss: 0.448019; batch adversarial loss: 0.567847\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410377; batch adversarial loss: 0.535644\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351104; batch adversarial loss: 0.528022\n",
      "epoch 124; iter: 0; batch classifier loss: 0.333143; batch adversarial loss: 0.563772\n",
      "epoch 125; iter: 0; batch classifier loss: 0.339251; batch adversarial loss: 0.589307\n",
      "epoch 126; iter: 0; batch classifier loss: 0.393551; batch adversarial loss: 0.535649\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380828; batch adversarial loss: 0.579909\n",
      "epoch 128; iter: 0; batch classifier loss: 0.406485; batch adversarial loss: 0.578467\n",
      "epoch 129; iter: 0; batch classifier loss: 0.466946; batch adversarial loss: 0.588107\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358857; batch adversarial loss: 0.535986\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384067; batch adversarial loss: 0.499229\n",
      "epoch 132; iter: 0; batch classifier loss: 0.387328; batch adversarial loss: 0.545018\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372727; batch adversarial loss: 0.517022\n",
      "epoch 134; iter: 0; batch classifier loss: 0.336511; batch adversarial loss: 0.624447\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380092; batch adversarial loss: 0.590576\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371123; batch adversarial loss: 0.600552\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368941; batch adversarial loss: 0.578705\n",
      "epoch 138; iter: 0; batch classifier loss: 0.418741; batch adversarial loss: 0.588375\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349221; batch adversarial loss: 0.509501\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335636; batch adversarial loss: 0.634204\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339676; batch adversarial loss: 0.587884\n",
      "epoch 142; iter: 0; batch classifier loss: 0.372278; batch adversarial loss: 0.490237\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354946; batch adversarial loss: 0.535679\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406976; batch adversarial loss: 0.598338\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319730; batch adversarial loss: 0.527617\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380019; batch adversarial loss: 0.546627\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347625; batch adversarial loss: 0.482120\n",
      "epoch 148; iter: 0; batch classifier loss: 0.302577; batch adversarial loss: 0.544909\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339247; batch adversarial loss: 0.569265\n",
      "epoch 150; iter: 0; batch classifier loss: 0.333563; batch adversarial loss: 0.573088\n",
      "epoch 151; iter: 0; batch classifier loss: 0.430506; batch adversarial loss: 0.581204\n",
      "epoch 152; iter: 0; batch classifier loss: 0.428647; batch adversarial loss: 0.473856\n",
      "epoch 153; iter: 0; batch classifier loss: 0.420809; batch adversarial loss: 0.640496\n",
      "epoch 154; iter: 0; batch classifier loss: 0.325651; batch adversarial loss: 0.510673\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336715; batch adversarial loss: 0.474247\n",
      "epoch 156; iter: 0; batch classifier loss: 0.435213; batch adversarial loss: 0.534569\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375669; batch adversarial loss: 0.597747\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384242; batch adversarial loss: 0.501366\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337311; batch adversarial loss: 0.615874\n",
      "epoch 160; iter: 0; batch classifier loss: 0.313324; batch adversarial loss: 0.545020\n",
      "epoch 161; iter: 0; batch classifier loss: 0.382936; batch adversarial loss: 0.571231\n",
      "epoch 162; iter: 0; batch classifier loss: 0.446192; batch adversarial loss: 0.563430\n",
      "epoch 163; iter: 0; batch classifier loss: 0.389419; batch adversarial loss: 0.498490\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397113; batch adversarial loss: 0.554362\n",
      "epoch 165; iter: 0; batch classifier loss: 0.453348; batch adversarial loss: 0.490535\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365915; batch adversarial loss: 0.663678\n",
      "epoch 167; iter: 0; batch classifier loss: 0.424244; batch adversarial loss: 0.554487\n",
      "epoch 168; iter: 0; batch classifier loss: 0.400267; batch adversarial loss: 0.614624\n",
      "epoch 169; iter: 0; batch classifier loss: 0.335265; batch adversarial loss: 0.525030\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360177; batch adversarial loss: 0.581274\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358726; batch adversarial loss: 0.554000\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318726; batch adversarial loss: 0.624217\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354963; batch adversarial loss: 0.562150\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381840; batch adversarial loss: 0.455119\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330079; batch adversarial loss: 0.569108\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336188; batch adversarial loss: 0.561696\n",
      "epoch 177; iter: 0; batch classifier loss: 0.325859; batch adversarial loss: 0.500105\n",
      "epoch 178; iter: 0; batch classifier loss: 0.392576; batch adversarial loss: 0.526393\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391667; batch adversarial loss: 0.516155\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351882; batch adversarial loss: 0.598389\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387214; batch adversarial loss: 0.490513\n",
      "epoch 182; iter: 0; batch classifier loss: 0.330445; batch adversarial loss: 0.552418\n",
      "epoch 183; iter: 0; batch classifier loss: 0.419180; batch adversarial loss: 0.582459\n",
      "epoch 184; iter: 0; batch classifier loss: 0.349272; batch adversarial loss: 0.489209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.276568; batch adversarial loss: 0.623813\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363949; batch adversarial loss: 0.536870\n",
      "epoch 187; iter: 0; batch classifier loss: 0.315600; batch adversarial loss: 0.561432\n",
      "epoch 188; iter: 0; batch classifier loss: 0.327952; batch adversarial loss: 0.528444\n",
      "epoch 189; iter: 0; batch classifier loss: 0.434156; batch adversarial loss: 0.581707\n",
      "epoch 190; iter: 0; batch classifier loss: 0.369203; batch adversarial loss: 0.509081\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392251; batch adversarial loss: 0.527915\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363611; batch adversarial loss: 0.553548\n",
      "epoch 193; iter: 0; batch classifier loss: 0.310763; batch adversarial loss: 0.544572\n",
      "epoch 194; iter: 0; batch classifier loss: 0.414663; batch adversarial loss: 0.509538\n",
      "epoch 195; iter: 0; batch classifier loss: 0.360019; batch adversarial loss: 0.498501\n",
      "epoch 196; iter: 0; batch classifier loss: 0.410426; batch adversarial loss: 0.534730\n",
      "epoch 197; iter: 0; batch classifier loss: 0.409674; batch adversarial loss: 0.543558\n",
      "epoch 198; iter: 0; batch classifier loss: 0.311169; batch adversarial loss: 0.561756\n",
      "epoch 199; iter: 0; batch classifier loss: 0.378658; batch adversarial loss: 0.588327\n",
      "epoch 0; iter: 0; batch classifier loss: 0.765559; batch adversarial loss: 0.983295\n",
      "epoch 1; iter: 0; batch classifier loss: 0.825723; batch adversarial loss: 1.102363\n",
      "epoch 2; iter: 0; batch classifier loss: 0.918081; batch adversarial loss: 1.026705\n",
      "epoch 3; iter: 0; batch classifier loss: 1.046853; batch adversarial loss: 1.001745\n",
      "epoch 4; iter: 0; batch classifier loss: 0.963264; batch adversarial loss: 0.886348\n",
      "epoch 5; iter: 0; batch classifier loss: 0.854204; batch adversarial loss: 0.809636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.833453; batch adversarial loss: 0.824549\n",
      "epoch 7; iter: 0; batch classifier loss: 0.781767; batch adversarial loss: 0.758240\n",
      "epoch 8; iter: 0; batch classifier loss: 0.694554; batch adversarial loss: 0.693097\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600782; batch adversarial loss: 0.619618\n",
      "epoch 10; iter: 0; batch classifier loss: 0.655374; batch adversarial loss: 0.666954\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564018; batch adversarial loss: 0.589297\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555768; batch adversarial loss: 0.598591\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599623; batch adversarial loss: 0.563098\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533815; batch adversarial loss: 0.630645\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501539; batch adversarial loss: 0.494592\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542402; batch adversarial loss: 0.581601\n",
      "epoch 17; iter: 0; batch classifier loss: 0.502365; batch adversarial loss: 0.604077\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514672; batch adversarial loss: 0.574262\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515930; batch adversarial loss: 0.540711\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495678; batch adversarial loss: 0.552515\n",
      "epoch 21; iter: 0; batch classifier loss: 0.576968; batch adversarial loss: 0.551633\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526951; batch adversarial loss: 0.540579\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505873; batch adversarial loss: 0.652879\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483679; batch adversarial loss: 0.520907\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452233; batch adversarial loss: 0.505715\n",
      "epoch 26; iter: 0; batch classifier loss: 0.516584; batch adversarial loss: 0.589019\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462154; batch adversarial loss: 0.578326\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506677; batch adversarial loss: 0.569730\n",
      "epoch 29; iter: 0; batch classifier loss: 0.537087; batch adversarial loss: 0.626309\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463877; batch adversarial loss: 0.570952\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506942; batch adversarial loss: 0.504929\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495723; batch adversarial loss: 0.585725\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514673; batch adversarial loss: 0.567284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469290; batch adversarial loss: 0.532828\n",
      "epoch 35; iter: 0; batch classifier loss: 0.519188; batch adversarial loss: 0.545173\n",
      "epoch 36; iter: 0; batch classifier loss: 0.510502; batch adversarial loss: 0.570347\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466880; batch adversarial loss: 0.572099\n",
      "epoch 38; iter: 0; batch classifier loss: 0.519017; batch adversarial loss: 0.554167\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463412; batch adversarial loss: 0.617334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467134; batch adversarial loss: 0.534413\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431282; batch adversarial loss: 0.596688\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454492; batch adversarial loss: 0.552116\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397925; batch adversarial loss: 0.595500\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411930; batch adversarial loss: 0.592145\n",
      "epoch 45; iter: 0; batch classifier loss: 0.389847; batch adversarial loss: 0.552977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.362676; batch adversarial loss: 0.569479\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453574; batch adversarial loss: 0.591573\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483179; batch adversarial loss: 0.586497\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435853; batch adversarial loss: 0.517997\n",
      "epoch 50; iter: 0; batch classifier loss: 0.445644; batch adversarial loss: 0.539541\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430683; batch adversarial loss: 0.567146\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411633; batch adversarial loss: 0.528467\n",
      "epoch 53; iter: 0; batch classifier loss: 0.483213; batch adversarial loss: 0.571537\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410403; batch adversarial loss: 0.522547\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417951; batch adversarial loss: 0.518622\n",
      "epoch 56; iter: 0; batch classifier loss: 0.369237; batch adversarial loss: 0.532686\n",
      "epoch 57; iter: 0; batch classifier loss: 0.330620; batch adversarial loss: 0.526906\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455412; batch adversarial loss: 0.581663\n",
      "epoch 59; iter: 0; batch classifier loss: 0.381237; batch adversarial loss: 0.543091\n",
      "epoch 60; iter: 0; batch classifier loss: 0.335126; batch adversarial loss: 0.504729\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435143; batch adversarial loss: 0.557139\n",
      "epoch 62; iter: 0; batch classifier loss: 0.350389; batch adversarial loss: 0.508701\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388505; batch adversarial loss: 0.516608\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432888; batch adversarial loss: 0.473476\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426225; batch adversarial loss: 0.498163\n",
      "epoch 66; iter: 0; batch classifier loss: 0.327093; batch adversarial loss: 0.507666\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381894; batch adversarial loss: 0.618921\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383900; batch adversarial loss: 0.464671\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389628; batch adversarial loss: 0.480033\n",
      "epoch 70; iter: 0; batch classifier loss: 0.350213; batch adversarial loss: 0.604943\n",
      "epoch 71; iter: 0; batch classifier loss: 0.383422; batch adversarial loss: 0.507356\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358283; batch adversarial loss: 0.562862\n",
      "epoch 73; iter: 0; batch classifier loss: 0.453464; batch adversarial loss: 0.556049\n",
      "epoch 74; iter: 0; batch classifier loss: 0.485919; batch adversarial loss: 0.514845\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396958; batch adversarial loss: 0.569553\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381694; batch adversarial loss: 0.524814\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372972; batch adversarial loss: 0.438918\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387558; batch adversarial loss: 0.473848\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368602; batch adversarial loss: 0.519017\n",
      "epoch 80; iter: 0; batch classifier loss: 0.450252; batch adversarial loss: 0.506687\n",
      "epoch 81; iter: 0; batch classifier loss: 0.314121; batch adversarial loss: 0.517725\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403360; batch adversarial loss: 0.596880\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341417; batch adversarial loss: 0.591963\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402342; batch adversarial loss: 0.522636\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349721; batch adversarial loss: 0.577464\n",
      "epoch 86; iter: 0; batch classifier loss: 0.354367; batch adversarial loss: 0.565969\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423894; batch adversarial loss: 0.607718\n",
      "epoch 88; iter: 0; batch classifier loss: 0.295282; batch adversarial loss: 0.471021\n",
      "epoch 89; iter: 0; batch classifier loss: 0.479286; batch adversarial loss: 0.464660\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369470; batch adversarial loss: 0.616297\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376368; batch adversarial loss: 0.601242\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398610; batch adversarial loss: 0.491511\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455955; batch adversarial loss: 0.552462\n",
      "epoch 94; iter: 0; batch classifier loss: 0.339396; batch adversarial loss: 0.628564\n",
      "epoch 95; iter: 0; batch classifier loss: 0.403499; batch adversarial loss: 0.526918\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350268; batch adversarial loss: 0.487433\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364782; batch adversarial loss: 0.525684\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339145; batch adversarial loss: 0.553038\n",
      "epoch 99; iter: 0; batch classifier loss: 0.406346; batch adversarial loss: 0.552398\n",
      "epoch 100; iter: 0; batch classifier loss: 0.356518; batch adversarial loss: 0.546617\n",
      "epoch 101; iter: 0; batch classifier loss: 0.388128; batch adversarial loss: 0.524525\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407592; batch adversarial loss: 0.546862\n",
      "epoch 103; iter: 0; batch classifier loss: 0.347198; batch adversarial loss: 0.543892\n",
      "epoch 104; iter: 0; batch classifier loss: 0.359987; batch adversarial loss: 0.543924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.382747; batch adversarial loss: 0.582863\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370481; batch adversarial loss: 0.579574\n",
      "epoch 107; iter: 0; batch classifier loss: 0.483259; batch adversarial loss: 0.628334\n",
      "epoch 108; iter: 0; batch classifier loss: 0.344660; batch adversarial loss: 0.581103\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386709; batch adversarial loss: 0.684690\n",
      "epoch 110; iter: 0; batch classifier loss: 0.319485; batch adversarial loss: 0.600941\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368365; batch adversarial loss: 0.535935\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353553; batch adversarial loss: 0.517300\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333720; batch adversarial loss: 0.590543\n",
      "epoch 114; iter: 0; batch classifier loss: 0.337241; batch adversarial loss: 0.591307\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382801; batch adversarial loss: 0.553445\n",
      "epoch 116; iter: 0; batch classifier loss: 0.285958; batch adversarial loss: 0.488357\n",
      "epoch 117; iter: 0; batch classifier loss: 0.332750; batch adversarial loss: 0.572967\n",
      "epoch 118; iter: 0; batch classifier loss: 0.323053; batch adversarial loss: 0.600736\n",
      "epoch 119; iter: 0; batch classifier loss: 0.389418; batch adversarial loss: 0.607314\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418551; batch adversarial loss: 0.533776\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385560; batch adversarial loss: 0.460543\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381030; batch adversarial loss: 0.444696\n",
      "epoch 123; iter: 0; batch classifier loss: 0.412228; batch adversarial loss: 0.571240\n",
      "epoch 124; iter: 0; batch classifier loss: 0.417627; batch adversarial loss: 0.508423\n",
      "epoch 125; iter: 0; batch classifier loss: 0.352808; batch adversarial loss: 0.508563\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357405; batch adversarial loss: 0.609447\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387283; batch adversarial loss: 0.573197\n",
      "epoch 128; iter: 0; batch classifier loss: 0.272094; batch adversarial loss: 0.527141\n",
      "epoch 129; iter: 0; batch classifier loss: 0.405607; batch adversarial loss: 0.562593\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370292; batch adversarial loss: 0.592134\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381977; batch adversarial loss: 0.571333\n",
      "epoch 132; iter: 0; batch classifier loss: 0.417205; batch adversarial loss: 0.599452\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411882; batch adversarial loss: 0.470909\n",
      "epoch 134; iter: 0; batch classifier loss: 0.362295; batch adversarial loss: 0.509630\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376685; batch adversarial loss: 0.507867\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341605; batch adversarial loss: 0.535541\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401245; batch adversarial loss: 0.535451\n",
      "epoch 138; iter: 0; batch classifier loss: 0.330084; batch adversarial loss: 0.526861\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360717; batch adversarial loss: 0.550928\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337032; batch adversarial loss: 0.535688\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364387; batch adversarial loss: 0.482531\n",
      "epoch 142; iter: 0; batch classifier loss: 0.422185; batch adversarial loss: 0.580701\n",
      "epoch 143; iter: 0; batch classifier loss: 0.482677; batch adversarial loss: 0.508227\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341061; batch adversarial loss: 0.562225\n",
      "epoch 145; iter: 0; batch classifier loss: 0.343637; batch adversarial loss: 0.592095\n",
      "epoch 146; iter: 0; batch classifier loss: 0.412156; batch adversarial loss: 0.527102\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327601; batch adversarial loss: 0.610940\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391450; batch adversarial loss: 0.599014\n",
      "epoch 149; iter: 0; batch classifier loss: 0.357538; batch adversarial loss: 0.615739\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367093; batch adversarial loss: 0.508498\n",
      "epoch 151; iter: 0; batch classifier loss: 0.324945; batch adversarial loss: 0.571980\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346196; batch adversarial loss: 0.646459\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338415; batch adversarial loss: 0.543695\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379946; batch adversarial loss: 0.553603\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371065; batch adversarial loss: 0.617051\n",
      "epoch 156; iter: 0; batch classifier loss: 0.447794; batch adversarial loss: 0.426277\n",
      "epoch 157; iter: 0; batch classifier loss: 0.308820; batch adversarial loss: 0.488132\n",
      "epoch 158; iter: 0; batch classifier loss: 0.275257; batch adversarial loss: 0.543902\n",
      "epoch 159; iter: 0; batch classifier loss: 0.378948; batch adversarial loss: 0.479435\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321661; batch adversarial loss: 0.488681\n",
      "epoch 161; iter: 0; batch classifier loss: 0.403617; batch adversarial loss: 0.579498\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325677; batch adversarial loss: 0.556329\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326895; batch adversarial loss: 0.518659\n",
      "epoch 164; iter: 0; batch classifier loss: 0.370329; batch adversarial loss: 0.572039\n",
      "epoch 165; iter: 0; batch classifier loss: 0.396067; batch adversarial loss: 0.591904\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343235; batch adversarial loss: 0.536739\n",
      "epoch 167; iter: 0; batch classifier loss: 0.414527; batch adversarial loss: 0.554055\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322874; batch adversarial loss: 0.563532\n",
      "epoch 169; iter: 0; batch classifier loss: 0.461499; batch adversarial loss: 0.497423\n",
      "epoch 170; iter: 0; batch classifier loss: 0.370584; batch adversarial loss: 0.562597\n",
      "epoch 171; iter: 0; batch classifier loss: 0.306607; batch adversarial loss: 0.525633\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365074; batch adversarial loss: 0.498697\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382734; batch adversarial loss: 0.581962\n",
      "epoch 174; iter: 0; batch classifier loss: 0.298626; batch adversarial loss: 0.554805\n",
      "epoch 175; iter: 0; batch classifier loss: 0.361062; batch adversarial loss: 0.535286\n",
      "epoch 176; iter: 0; batch classifier loss: 0.373472; batch adversarial loss: 0.480352\n",
      "epoch 177; iter: 0; batch classifier loss: 0.463665; batch adversarial loss: 0.517622\n",
      "epoch 178; iter: 0; batch classifier loss: 0.312872; batch adversarial loss: 0.571970\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346029; batch adversarial loss: 0.581941\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369299; batch adversarial loss: 0.454417\n",
      "epoch 181; iter: 0; batch classifier loss: 0.312375; batch adversarial loss: 0.525789\n",
      "epoch 182; iter: 0; batch classifier loss: 0.323716; batch adversarial loss: 0.489051\n",
      "epoch 183; iter: 0; batch classifier loss: 0.249443; batch adversarial loss: 0.544281\n",
      "epoch 184; iter: 0; batch classifier loss: 0.316459; batch adversarial loss: 0.488796\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372355; batch adversarial loss: 0.618182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399993; batch adversarial loss: 0.583655\n",
      "epoch 187; iter: 0; batch classifier loss: 0.262269; batch adversarial loss: 0.528978\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345680; batch adversarial loss: 0.490460\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375030; batch adversarial loss: 0.571347\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390373; batch adversarial loss: 0.543835\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370051; batch adversarial loss: 0.517116\n",
      "epoch 192; iter: 0; batch classifier loss: 0.314681; batch adversarial loss: 0.634903\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284537; batch adversarial loss: 0.683896\n",
      "epoch 194; iter: 0; batch classifier loss: 0.281276; batch adversarial loss: 0.517523\n",
      "epoch 195; iter: 0; batch classifier loss: 0.268110; batch adversarial loss: 0.507455\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316088; batch adversarial loss: 0.532980\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312322; batch adversarial loss: 0.526187\n",
      "epoch 198; iter: 0; batch classifier loss: 0.300085; batch adversarial loss: 0.516629\n",
      "epoch 199; iter: 0; batch classifier loss: 0.394780; batch adversarial loss: 0.487306\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688001; batch adversarial loss: 0.642072\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596069; batch adversarial loss: 0.638246\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594665; batch adversarial loss: 0.664246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.556229; batch adversarial loss: 0.626254\n",
      "epoch 4; iter: 0; batch classifier loss: 0.534225; batch adversarial loss: 0.619150\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573387; batch adversarial loss: 0.637367\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509403; batch adversarial loss: 0.610875\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527773; batch adversarial loss: 0.534592\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533233; batch adversarial loss: 0.556073\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539274; batch adversarial loss: 0.607205\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529431; batch adversarial loss: 0.592745\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577603; batch adversarial loss: 0.489625\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467541; batch adversarial loss: 0.575529\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549652; batch adversarial loss: 0.543248\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467739; batch adversarial loss: 0.476441\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485824; batch adversarial loss: 0.560635\n",
      "epoch 16; iter: 0; batch classifier loss: 0.459015; batch adversarial loss: 0.569863\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492919; batch adversarial loss: 0.589411\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452775; batch adversarial loss: 0.547665\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516356; batch adversarial loss: 0.554225\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551724; batch adversarial loss: 0.570635\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541889; batch adversarial loss: 0.508834\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456792; batch adversarial loss: 0.555905\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479371; batch adversarial loss: 0.568186\n",
      "epoch 24; iter: 0; batch classifier loss: 0.525354; batch adversarial loss: 0.549580\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453824; batch adversarial loss: 0.557680\n",
      "epoch 26; iter: 0; batch classifier loss: 0.521709; batch adversarial loss: 0.591908\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460404; batch adversarial loss: 0.571167\n",
      "epoch 28; iter: 0; batch classifier loss: 0.393401; batch adversarial loss: 0.558304\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474200; batch adversarial loss: 0.501817\n",
      "epoch 30; iter: 0; batch classifier loss: 0.419277; batch adversarial loss: 0.554880\n",
      "epoch 31; iter: 0; batch classifier loss: 0.393970; batch adversarial loss: 0.494836\n",
      "epoch 32; iter: 0; batch classifier loss: 0.492293; batch adversarial loss: 0.509110\n",
      "epoch 33; iter: 0; batch classifier loss: 0.407054; batch adversarial loss: 0.616459\n",
      "epoch 34; iter: 0; batch classifier loss: 0.385867; batch adversarial loss: 0.598643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474926; batch adversarial loss: 0.445146\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487225; batch adversarial loss: 0.590167\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454341; batch adversarial loss: 0.572216\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381516; batch adversarial loss: 0.461408\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478962; batch adversarial loss: 0.618750\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456521; batch adversarial loss: 0.628027\n",
      "epoch 41; iter: 0; batch classifier loss: 0.390298; batch adversarial loss: 0.553778\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443445; batch adversarial loss: 0.553280\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469747; batch adversarial loss: 0.488430\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448679; batch adversarial loss: 0.498220\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469081; batch adversarial loss: 0.554792\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469668; batch adversarial loss: 0.470056\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450726; batch adversarial loss: 0.553383\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406906; batch adversarial loss: 0.535464\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472959; batch adversarial loss: 0.562942\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463358; batch adversarial loss: 0.506545\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428971; batch adversarial loss: 0.562910\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391487; batch adversarial loss: 0.516602\n",
      "epoch 53; iter: 0; batch classifier loss: 0.500913; batch adversarial loss: 0.573602\n",
      "epoch 54; iter: 0; batch classifier loss: 0.390349; batch adversarial loss: 0.563221\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440609; batch adversarial loss: 0.564726\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417329; batch adversarial loss: 0.525518\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390631; batch adversarial loss: 0.561003\n",
      "epoch 58; iter: 0; batch classifier loss: 0.415040; batch adversarial loss: 0.515762\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412494; batch adversarial loss: 0.515928\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396747; batch adversarial loss: 0.573213\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467405; batch adversarial loss: 0.572137\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417286; batch adversarial loss: 0.555967\n",
      "epoch 63; iter: 0; batch classifier loss: 0.466559; batch adversarial loss: 0.580464\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418167; batch adversarial loss: 0.580852\n",
      "epoch 65; iter: 0; batch classifier loss: 0.356724; batch adversarial loss: 0.530859\n",
      "epoch 66; iter: 0; batch classifier loss: 0.349120; batch adversarial loss: 0.582467\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411604; batch adversarial loss: 0.553210\n",
      "epoch 68; iter: 0; batch classifier loss: 0.461097; batch adversarial loss: 0.592034\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378560; batch adversarial loss: 0.600473\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427790; batch adversarial loss: 0.535435\n",
      "epoch 71; iter: 0; batch classifier loss: 0.464695; batch adversarial loss: 0.527151\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414539; batch adversarial loss: 0.631060\n",
      "epoch 73; iter: 0; batch classifier loss: 0.363438; batch adversarial loss: 0.525241\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388795; batch adversarial loss: 0.554991\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391744; batch adversarial loss: 0.451361\n",
      "epoch 76; iter: 0; batch classifier loss: 0.447561; batch adversarial loss: 0.579604\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389927; batch adversarial loss: 0.544079\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370900; batch adversarial loss: 0.589997\n",
      "epoch 79; iter: 0; batch classifier loss: 0.453351; batch adversarial loss: 0.490822\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363177; batch adversarial loss: 0.580696\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369749; batch adversarial loss: 0.534408\n",
      "epoch 82; iter: 0; batch classifier loss: 0.449889; batch adversarial loss: 0.507053\n",
      "epoch 83; iter: 0; batch classifier loss: 0.464035; batch adversarial loss: 0.515185\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430827; batch adversarial loss: 0.541638\n",
      "epoch 85; iter: 0; batch classifier loss: 0.374443; batch adversarial loss: 0.574962\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405078; batch adversarial loss: 0.480418\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382255; batch adversarial loss: 0.509671\n",
      "epoch 88; iter: 0; batch classifier loss: 0.457155; batch adversarial loss: 0.493812\n",
      "epoch 89; iter: 0; batch classifier loss: 0.453082; batch adversarial loss: 0.591018\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355742; batch adversarial loss: 0.527830\n",
      "epoch 91; iter: 0; batch classifier loss: 0.429940; batch adversarial loss: 0.527535\n",
      "epoch 92; iter: 0; batch classifier loss: 0.426507; batch adversarial loss: 0.449773\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379182; batch adversarial loss: 0.533469\n",
      "epoch 94; iter: 0; batch classifier loss: 0.388212; batch adversarial loss: 0.630530\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368301; batch adversarial loss: 0.571655\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372313; batch adversarial loss: 0.517784\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399241; batch adversarial loss: 0.442560\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357256; batch adversarial loss: 0.517561\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382623; batch adversarial loss: 0.571160\n",
      "epoch 100; iter: 0; batch classifier loss: 0.447663; batch adversarial loss: 0.508953\n",
      "epoch 101; iter: 0; batch classifier loss: 0.318790; batch adversarial loss: 0.602754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.360866; batch adversarial loss: 0.571921\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376584; batch adversarial loss: 0.497863\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344853; batch adversarial loss: 0.562582\n",
      "epoch 105; iter: 0; batch classifier loss: 0.338154; batch adversarial loss: 0.533804\n",
      "epoch 106; iter: 0; batch classifier loss: 0.324324; batch adversarial loss: 0.488052\n",
      "epoch 107; iter: 0; batch classifier loss: 0.356168; batch adversarial loss: 0.580728\n",
      "epoch 108; iter: 0; batch classifier loss: 0.415830; batch adversarial loss: 0.558772\n",
      "epoch 109; iter: 0; batch classifier loss: 0.409218; batch adversarial loss: 0.489730\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411792; batch adversarial loss: 0.563397\n",
      "epoch 111; iter: 0; batch classifier loss: 0.337066; batch adversarial loss: 0.507943\n",
      "epoch 112; iter: 0; batch classifier loss: 0.453598; batch adversarial loss: 0.517429\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345041; batch adversarial loss: 0.591223\n",
      "epoch 114; iter: 0; batch classifier loss: 0.371632; batch adversarial loss: 0.535398\n",
      "epoch 115; iter: 0; batch classifier loss: 0.424143; batch adversarial loss: 0.497270\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402216; batch adversarial loss: 0.563154\n",
      "epoch 117; iter: 0; batch classifier loss: 0.395970; batch adversarial loss: 0.477351\n",
      "epoch 118; iter: 0; batch classifier loss: 0.328857; batch adversarial loss: 0.491051\n",
      "epoch 119; iter: 0; batch classifier loss: 0.359610; batch adversarial loss: 0.594182\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369568; batch adversarial loss: 0.488547\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373100; batch adversarial loss: 0.460888\n",
      "epoch 122; iter: 0; batch classifier loss: 0.334974; batch adversarial loss: 0.582098\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423819; batch adversarial loss: 0.469931\n",
      "epoch 124; iter: 0; batch classifier loss: 0.537186; batch adversarial loss: 0.506147\n",
      "epoch 125; iter: 0; batch classifier loss: 0.318400; batch adversarial loss: 0.573006\n",
      "epoch 126; iter: 0; batch classifier loss: 0.442628; batch adversarial loss: 0.497561\n",
      "epoch 127; iter: 0; batch classifier loss: 0.361206; batch adversarial loss: 0.570577\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373837; batch adversarial loss: 0.532411\n",
      "epoch 129; iter: 0; batch classifier loss: 0.325215; batch adversarial loss: 0.554984\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385232; batch adversarial loss: 0.531917\n",
      "epoch 131; iter: 0; batch classifier loss: 0.378331; batch adversarial loss: 0.526281\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340984; batch adversarial loss: 0.521468\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352367; batch adversarial loss: 0.636077\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395917; batch adversarial loss: 0.543601\n",
      "epoch 135; iter: 0; batch classifier loss: 0.291867; batch adversarial loss: 0.559560\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392131; batch adversarial loss: 0.534560\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329181; batch adversarial loss: 0.508444\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414470; batch adversarial loss: 0.590546\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397981; batch adversarial loss: 0.476926\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378715; batch adversarial loss: 0.525353\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399577; batch adversarial loss: 0.484906\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354780; batch adversarial loss: 0.528245\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331672; batch adversarial loss: 0.535980\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347240; batch adversarial loss: 0.597620\n",
      "epoch 145; iter: 0; batch classifier loss: 0.373173; batch adversarial loss: 0.456615\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385468; batch adversarial loss: 0.491324\n",
      "epoch 147; iter: 0; batch classifier loss: 0.407588; batch adversarial loss: 0.590421\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410967; batch adversarial loss: 0.471689\n",
      "epoch 149; iter: 0; batch classifier loss: 0.303483; batch adversarial loss: 0.499128\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359701; batch adversarial loss: 0.562406\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354033; batch adversarial loss: 0.559209\n",
      "epoch 152; iter: 0; batch classifier loss: 0.413533; batch adversarial loss: 0.535379\n",
      "epoch 153; iter: 0; batch classifier loss: 0.299483; batch adversarial loss: 0.559413\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343085; batch adversarial loss: 0.589845\n",
      "epoch 155; iter: 0; batch classifier loss: 0.303520; batch adversarial loss: 0.480591\n",
      "epoch 156; iter: 0; batch classifier loss: 0.322060; batch adversarial loss: 0.497285\n",
      "epoch 157; iter: 0; batch classifier loss: 0.409894; batch adversarial loss: 0.516695\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363684; batch adversarial loss: 0.627377\n",
      "epoch 159; iter: 0; batch classifier loss: 0.414339; batch adversarial loss: 0.583465\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335317; batch adversarial loss: 0.552448\n",
      "epoch 161; iter: 0; batch classifier loss: 0.289565; batch adversarial loss: 0.555253\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394074; batch adversarial loss: 0.565122\n",
      "epoch 163; iter: 0; batch classifier loss: 0.408302; batch adversarial loss: 0.495942\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375696; batch adversarial loss: 0.591547\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343192; batch adversarial loss: 0.531357\n",
      "epoch 166; iter: 0; batch classifier loss: 0.338865; batch adversarial loss: 0.540932\n",
      "epoch 167; iter: 0; batch classifier loss: 0.405886; batch adversarial loss: 0.507816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.295075; batch adversarial loss: 0.560832\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357230; batch adversarial loss: 0.555489\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371483; batch adversarial loss: 0.489397\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348187; batch adversarial loss: 0.536801\n",
      "epoch 172; iter: 0; batch classifier loss: 0.405187; batch adversarial loss: 0.543904\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363473; batch adversarial loss: 0.577567\n",
      "epoch 174; iter: 0; batch classifier loss: 0.424611; batch adversarial loss: 0.564341\n",
      "epoch 175; iter: 0; batch classifier loss: 0.358206; batch adversarial loss: 0.518299\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344945; batch adversarial loss: 0.674815\n",
      "epoch 177; iter: 0; batch classifier loss: 0.327816; batch adversarial loss: 0.601805\n",
      "epoch 178; iter: 0; batch classifier loss: 0.401555; batch adversarial loss: 0.508308\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366888; batch adversarial loss: 0.602140\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390848; batch adversarial loss: 0.585647\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420743; batch adversarial loss: 0.522649\n",
      "epoch 182; iter: 0; batch classifier loss: 0.306536; batch adversarial loss: 0.397330\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333260; batch adversarial loss: 0.526940\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401330; batch adversarial loss: 0.607160\n",
      "epoch 185; iter: 0; batch classifier loss: 0.304926; batch adversarial loss: 0.569896\n",
      "epoch 186; iter: 0; batch classifier loss: 0.306612; batch adversarial loss: 0.515332\n",
      "epoch 187; iter: 0; batch classifier loss: 0.379791; batch adversarial loss: 0.497038\n",
      "epoch 188; iter: 0; batch classifier loss: 0.301429; batch adversarial loss: 0.420150\n",
      "epoch 189; iter: 0; batch classifier loss: 0.276123; batch adversarial loss: 0.562512\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384379; batch adversarial loss: 0.550554\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363930; batch adversarial loss: 0.489644\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373104; batch adversarial loss: 0.442622\n",
      "epoch 193; iter: 0; batch classifier loss: 0.423545; batch adversarial loss: 0.551247\n",
      "epoch 194; iter: 0; batch classifier loss: 0.331240; batch adversarial loss: 0.534490\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346711; batch adversarial loss: 0.534403\n",
      "epoch 196; iter: 0; batch classifier loss: 0.436797; batch adversarial loss: 0.532652\n",
      "epoch 197; iter: 0; batch classifier loss: 0.295997; batch adversarial loss: 0.533942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.350066; batch adversarial loss: 0.532515\n",
      "epoch 199; iter: 0; batch classifier loss: 0.407815; batch adversarial loss: 0.553885\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736100; batch adversarial loss: 0.609789\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605901; batch adversarial loss: 0.630656\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624727; batch adversarial loss: 0.618454\n",
      "epoch 3; iter: 0; batch classifier loss: 0.626520; batch adversarial loss: 0.647529\n",
      "epoch 4; iter: 0; batch classifier loss: 0.536017; batch adversarial loss: 0.649576\n",
      "epoch 5; iter: 0; batch classifier loss: 0.519789; batch adversarial loss: 0.692068\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598093; batch adversarial loss: 0.601503\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604154; batch adversarial loss: 0.633852\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483774; batch adversarial loss: 0.567420\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522718; batch adversarial loss: 0.585719\n",
      "epoch 10; iter: 0; batch classifier loss: 0.563646; batch adversarial loss: 0.584459\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523788; batch adversarial loss: 0.539285\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457712; batch adversarial loss: 0.603690\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508177; batch adversarial loss: 0.569383\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564190; batch adversarial loss: 0.571452\n",
      "epoch 15; iter: 0; batch classifier loss: 0.582207; batch adversarial loss: 0.552668\n",
      "epoch 16; iter: 0; batch classifier loss: 0.566350; batch adversarial loss: 0.545250\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539923; batch adversarial loss: 0.568829\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514659; batch adversarial loss: 0.633866\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522358; batch adversarial loss: 0.597577\n",
      "epoch 20; iter: 0; batch classifier loss: 0.593528; batch adversarial loss: 0.574398\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516576; batch adversarial loss: 0.639820\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481524; batch adversarial loss: 0.555650\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443000; batch adversarial loss: 0.521922\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427995; batch adversarial loss: 0.574899\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511185; batch adversarial loss: 0.538222\n",
      "epoch 26; iter: 0; batch classifier loss: 0.419908; batch adversarial loss: 0.450978\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440359; batch adversarial loss: 0.518204\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459595; batch adversarial loss: 0.551237\n",
      "epoch 29; iter: 0; batch classifier loss: 0.503108; batch adversarial loss: 0.564165\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499322; batch adversarial loss: 0.563005\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492787; batch adversarial loss: 0.588633\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459364; batch adversarial loss: 0.545159\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420203; batch adversarial loss: 0.553540\n",
      "epoch 34; iter: 0; batch classifier loss: 0.533308; batch adversarial loss: 0.499551\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410173; batch adversarial loss: 0.531115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440992; batch adversarial loss: 0.539269\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386683; batch adversarial loss: 0.598010\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474783; batch adversarial loss: 0.524897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427939; batch adversarial loss: 0.580335\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409268; batch adversarial loss: 0.522012\n",
      "epoch 41; iter: 0; batch classifier loss: 0.490813; batch adversarial loss: 0.528932\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449773; batch adversarial loss: 0.527932\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442512; batch adversarial loss: 0.489870\n",
      "epoch 44; iter: 0; batch classifier loss: 0.475265; batch adversarial loss: 0.625535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409325; batch adversarial loss: 0.517968\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397344; batch adversarial loss: 0.509092\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484676; batch adversarial loss: 0.478904\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465757; batch adversarial loss: 0.609194\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398412; batch adversarial loss: 0.534481\n",
      "epoch 50; iter: 0; batch classifier loss: 0.528838; batch adversarial loss: 0.607850\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446860; batch adversarial loss: 0.610817\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424363; batch adversarial loss: 0.469274\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414835; batch adversarial loss: 0.553547\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451396; batch adversarial loss: 0.525401\n",
      "epoch 55; iter: 0; batch classifier loss: 0.358256; batch adversarial loss: 0.619103\n",
      "epoch 56; iter: 0; batch classifier loss: 0.379010; batch adversarial loss: 0.535322\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440638; batch adversarial loss: 0.545348\n",
      "epoch 58; iter: 0; batch classifier loss: 0.293678; batch adversarial loss: 0.569281\n",
      "epoch 59; iter: 0; batch classifier loss: 0.463134; batch adversarial loss: 0.525774\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418010; batch adversarial loss: 0.582002\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409467; batch adversarial loss: 0.449477\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414002; batch adversarial loss: 0.527286\n",
      "epoch 63; iter: 0; batch classifier loss: 0.479468; batch adversarial loss: 0.535445\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424258; batch adversarial loss: 0.535752\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443291; batch adversarial loss: 0.505364\n",
      "epoch 66; iter: 0; batch classifier loss: 0.391587; batch adversarial loss: 0.598182\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435876; batch adversarial loss: 0.550104\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443113; batch adversarial loss: 0.525163\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395098; batch adversarial loss: 0.505705\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445090; batch adversarial loss: 0.554542\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426297; batch adversarial loss: 0.570907\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386900; batch adversarial loss: 0.555596\n",
      "epoch 73; iter: 0; batch classifier loss: 0.420029; batch adversarial loss: 0.643969\n",
      "epoch 74; iter: 0; batch classifier loss: 0.365698; batch adversarial loss: 0.569103\n",
      "epoch 75; iter: 0; batch classifier loss: 0.464713; batch adversarial loss: 0.588021\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380195; batch adversarial loss: 0.500987\n",
      "epoch 77; iter: 0; batch classifier loss: 0.505076; batch adversarial loss: 0.528680\n",
      "epoch 78; iter: 0; batch classifier loss: 0.454859; batch adversarial loss: 0.526188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430215; batch adversarial loss: 0.571507\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437254; batch adversarial loss: 0.509098\n",
      "epoch 81; iter: 0; batch classifier loss: 0.439564; batch adversarial loss: 0.518112\n",
      "epoch 82; iter: 0; batch classifier loss: 0.445130; batch adversarial loss: 0.518350\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371802; batch adversarial loss: 0.491648\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405018; batch adversarial loss: 0.597251\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377507; batch adversarial loss: 0.543570\n",
      "epoch 86; iter: 0; batch classifier loss: 0.462942; batch adversarial loss: 0.561296\n",
      "epoch 87; iter: 0; batch classifier loss: 0.329372; batch adversarial loss: 0.607953\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392630; batch adversarial loss: 0.605518\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410118; batch adversarial loss: 0.606951\n",
      "epoch 90; iter: 0; batch classifier loss: 0.437557; batch adversarial loss: 0.589320\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383023; batch adversarial loss: 0.588518\n",
      "epoch 92; iter: 0; batch classifier loss: 0.330710; batch adversarial loss: 0.535435\n",
      "epoch 93; iter: 0; batch classifier loss: 0.434849; batch adversarial loss: 0.564416\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392600; batch adversarial loss: 0.516199\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424800; batch adversarial loss: 0.517217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.351319; batch adversarial loss: 0.553283\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396814; batch adversarial loss: 0.543891\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382412; batch adversarial loss: 0.590604\n",
      "epoch 99; iter: 0; batch classifier loss: 0.411208; batch adversarial loss: 0.554094\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387524; batch adversarial loss: 0.555060\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405517; batch adversarial loss: 0.517290\n",
      "epoch 102; iter: 0; batch classifier loss: 0.421132; batch adversarial loss: 0.629056\n",
      "epoch 103; iter: 0; batch classifier loss: 0.308846; batch adversarial loss: 0.534905\n",
      "epoch 104; iter: 0; batch classifier loss: 0.414226; batch adversarial loss: 0.619264\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415628; batch adversarial loss: 0.497573\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407193; batch adversarial loss: 0.534823\n",
      "epoch 107; iter: 0; batch classifier loss: 0.524186; batch adversarial loss: 0.470629\n",
      "epoch 108; iter: 0; batch classifier loss: 0.330627; batch adversarial loss: 0.534869\n",
      "epoch 109; iter: 0; batch classifier loss: 0.393012; batch adversarial loss: 0.553378\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392752; batch adversarial loss: 0.618021\n",
      "epoch 111; iter: 0; batch classifier loss: 0.402659; batch adversarial loss: 0.554086\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355222; batch adversarial loss: 0.581800\n",
      "epoch 113; iter: 0; batch classifier loss: 0.427921; batch adversarial loss: 0.563153\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364491; batch adversarial loss: 0.590758\n",
      "epoch 115; iter: 0; batch classifier loss: 0.344576; batch adversarial loss: 0.525576\n",
      "epoch 116; iter: 0; batch classifier loss: 0.308946; batch adversarial loss: 0.645880\n",
      "epoch 117; iter: 0; batch classifier loss: 0.489057; batch adversarial loss: 0.571784\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394631; batch adversarial loss: 0.619069\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385303; batch adversarial loss: 0.572244\n",
      "epoch 120; iter: 0; batch classifier loss: 0.359803; batch adversarial loss: 0.488462\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361681; batch adversarial loss: 0.534802\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385983; batch adversarial loss: 0.526067\n",
      "epoch 123; iter: 0; batch classifier loss: 0.406845; batch adversarial loss: 0.470703\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353555; batch adversarial loss: 0.527083\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377844; batch adversarial loss: 0.609734\n",
      "epoch 126; iter: 0; batch classifier loss: 0.378738; batch adversarial loss: 0.610198\n",
      "epoch 127; iter: 0; batch classifier loss: 0.424519; batch adversarial loss: 0.562621\n",
      "epoch 128; iter: 0; batch classifier loss: 0.315522; batch adversarial loss: 0.553610\n",
      "epoch 129; iter: 0; batch classifier loss: 0.392493; batch adversarial loss: 0.544403\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372002; batch adversarial loss: 0.563040\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331044; batch adversarial loss: 0.535234\n",
      "epoch 132; iter: 0; batch classifier loss: 0.417660; batch adversarial loss: 0.628044\n",
      "epoch 133; iter: 0; batch classifier loss: 0.337254; batch adversarial loss: 0.628074\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384806; batch adversarial loss: 0.507425\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388602; batch adversarial loss: 0.628167\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381816; batch adversarial loss: 0.516462\n",
      "epoch 137; iter: 0; batch classifier loss: 0.330489; batch adversarial loss: 0.544663\n",
      "epoch 138; iter: 0; batch classifier loss: 0.410587; batch adversarial loss: 0.516952\n",
      "epoch 139; iter: 0; batch classifier loss: 0.399073; batch adversarial loss: 0.525874\n",
      "epoch 140; iter: 0; batch classifier loss: 0.363090; batch adversarial loss: 0.535268\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390822; batch adversarial loss: 0.581503\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397600; batch adversarial loss: 0.628214\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406646; batch adversarial loss: 0.516590\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396015; batch adversarial loss: 0.544719\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334990; batch adversarial loss: 0.479301\n",
      "epoch 146; iter: 0; batch classifier loss: 0.421794; batch adversarial loss: 0.590907\n",
      "epoch 147; iter: 0; batch classifier loss: 0.435347; batch adversarial loss: 0.553897\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381785; batch adversarial loss: 0.544810\n",
      "epoch 149; iter: 0; batch classifier loss: 0.312861; batch adversarial loss: 0.572295\n",
      "epoch 150; iter: 0; batch classifier loss: 0.331925; batch adversarial loss: 0.655160\n",
      "epoch 151; iter: 0; batch classifier loss: 0.319442; batch adversarial loss: 0.470949\n",
      "epoch 152; iter: 0; batch classifier loss: 0.327936; batch adversarial loss: 0.526027\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356465; batch adversarial loss: 0.507513\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350043; batch adversarial loss: 0.572654\n",
      "epoch 155; iter: 0; batch classifier loss: 0.312855; batch adversarial loss: 0.582170\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354268; batch adversarial loss: 0.572052\n",
      "epoch 157; iter: 0; batch classifier loss: 0.432262; batch adversarial loss: 0.516919\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361828; batch adversarial loss: 0.571819\n",
      "epoch 159; iter: 0; batch classifier loss: 0.427525; batch adversarial loss: 0.581699\n",
      "epoch 160; iter: 0; batch classifier loss: 0.402546; batch adversarial loss: 0.516910\n",
      "epoch 161; iter: 0; batch classifier loss: 0.294790; batch adversarial loss: 0.507480\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311571; batch adversarial loss: 0.553916\n",
      "epoch 163; iter: 0; batch classifier loss: 0.333912; batch adversarial loss: 0.581266\n",
      "epoch 164; iter: 0; batch classifier loss: 0.433682; batch adversarial loss: 0.442614\n",
      "epoch 165; iter: 0; batch classifier loss: 0.338128; batch adversarial loss: 0.516813\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384465; batch adversarial loss: 0.572348\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359587; batch adversarial loss: 0.572915\n",
      "epoch 168; iter: 0; batch classifier loss: 0.288946; batch adversarial loss: 0.516893\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355493; batch adversarial loss: 0.498227\n",
      "epoch 170; iter: 0; batch classifier loss: 0.289921; batch adversarial loss: 0.535040\n",
      "epoch 171; iter: 0; batch classifier loss: 0.360559; batch adversarial loss: 0.497872\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360206; batch adversarial loss: 0.591110\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385306; batch adversarial loss: 0.618737\n",
      "epoch 174; iter: 0; batch classifier loss: 0.333454; batch adversarial loss: 0.553599\n",
      "epoch 175; iter: 0; batch classifier loss: 0.347057; batch adversarial loss: 0.572504\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397984; batch adversarial loss: 0.600146\n",
      "epoch 177; iter: 0; batch classifier loss: 0.333027; batch adversarial loss: 0.563045\n",
      "epoch 178; iter: 0; batch classifier loss: 0.438104; batch adversarial loss: 0.581817\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389563; batch adversarial loss: 0.581187\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396507; batch adversarial loss: 0.470301\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344480; batch adversarial loss: 0.479402\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389007; batch adversarial loss: 0.516517\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344634; batch adversarial loss: 0.516866\n",
      "epoch 184; iter: 0; batch classifier loss: 0.298240; batch adversarial loss: 0.488896\n",
      "epoch 185; iter: 0; batch classifier loss: 0.386303; batch adversarial loss: 0.516416\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327869; batch adversarial loss: 0.535069\n",
      "epoch 187; iter: 0; batch classifier loss: 0.400644; batch adversarial loss: 0.590950\n",
      "epoch 188; iter: 0; batch classifier loss: 0.326031; batch adversarial loss: 0.507230\n",
      "epoch 189; iter: 0; batch classifier loss: 0.296379; batch adversarial loss: 0.516427\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333818; batch adversarial loss: 0.581542\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320273; batch adversarial loss: 0.470331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.391933; batch adversarial loss: 0.572650\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309491; batch adversarial loss: 0.646477\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362391; batch adversarial loss: 0.526266\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322083; batch adversarial loss: 0.488939\n",
      "epoch 196; iter: 0; batch classifier loss: 0.368754; batch adversarial loss: 0.553628\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354639; batch adversarial loss: 0.525875\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317625; batch adversarial loss: 0.498155\n",
      "epoch 199; iter: 0; batch classifier loss: 0.325974; batch adversarial loss: 0.507447\n",
      "epoch 0; iter: 0; batch classifier loss: 0.648882; batch adversarial loss: 0.673311\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571271; batch adversarial loss: 0.686186\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630593; batch adversarial loss: 0.657360\n",
      "epoch 3; iter: 0; batch classifier loss: 0.564036; batch adversarial loss: 0.630138\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568194; batch adversarial loss: 0.604279\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571204; batch adversarial loss: 0.572552\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568269; batch adversarial loss: 0.572033\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514899; batch adversarial loss: 0.539318\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539750; batch adversarial loss: 0.532331\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565620; batch adversarial loss: 0.567266\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498634; batch adversarial loss: 0.567537\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548041; batch adversarial loss: 0.645502\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545267; batch adversarial loss: 0.563510\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547116; batch adversarial loss: 0.647722\n",
      "epoch 14; iter: 0; batch classifier loss: 0.590363; batch adversarial loss: 0.623038\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494861; batch adversarial loss: 0.579201\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494603; batch adversarial loss: 0.601857\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535759; batch adversarial loss: 0.640001\n",
      "epoch 18; iter: 0; batch classifier loss: 0.480519; batch adversarial loss: 0.571273\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487071; batch adversarial loss: 0.585221\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482389; batch adversarial loss: 0.534037\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509575; batch adversarial loss: 0.566675\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479916; batch adversarial loss: 0.529249\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472959; batch adversarial loss: 0.576100\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490707; batch adversarial loss: 0.574471\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523784; batch adversarial loss: 0.514774\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480993; batch adversarial loss: 0.504746\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466456; batch adversarial loss: 0.560848\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491557; batch adversarial loss: 0.497375\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482720; batch adversarial loss: 0.663161\n",
      "epoch 30; iter: 0; batch classifier loss: 0.535993; batch adversarial loss: 0.559045\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467318; batch adversarial loss: 0.447203\n",
      "epoch 32; iter: 0; batch classifier loss: 0.476433; batch adversarial loss: 0.557627\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483542; batch adversarial loss: 0.522666\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485735; batch adversarial loss: 0.533190\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475218; batch adversarial loss: 0.546510\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461388; batch adversarial loss: 0.592272\n",
      "epoch 37; iter: 0; batch classifier loss: 0.419545; batch adversarial loss: 0.551147\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425842; batch adversarial loss: 0.485655\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491226; batch adversarial loss: 0.553182\n",
      "epoch 40; iter: 0; batch classifier loss: 0.511035; batch adversarial loss: 0.525158\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471434; batch adversarial loss: 0.516598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.354252; batch adversarial loss: 0.544261\n",
      "epoch 43; iter: 0; batch classifier loss: 0.374896; batch adversarial loss: 0.525679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481746; batch adversarial loss: 0.529464\n",
      "epoch 45; iter: 0; batch classifier loss: 0.373730; batch adversarial loss: 0.572019\n",
      "epoch 46; iter: 0; batch classifier loss: 0.475593; batch adversarial loss: 0.532469\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423164; batch adversarial loss: 0.580566\n",
      "epoch 48; iter: 0; batch classifier loss: 0.512694; batch adversarial loss: 0.455750\n",
      "epoch 49; iter: 0; batch classifier loss: 0.425425; batch adversarial loss: 0.645394\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432364; batch adversarial loss: 0.554596\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436637; batch adversarial loss: 0.544653\n",
      "epoch 52; iter: 0; batch classifier loss: 0.360006; batch adversarial loss: 0.545374\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449188; batch adversarial loss: 0.554542\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411764; batch adversarial loss: 0.609239\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413621; batch adversarial loss: 0.518559\n",
      "epoch 56; iter: 0; batch classifier loss: 0.386138; batch adversarial loss: 0.499390\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399883; batch adversarial loss: 0.535260\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400008; batch adversarial loss: 0.635012\n",
      "epoch 59; iter: 0; batch classifier loss: 0.381421; batch adversarial loss: 0.554403\n",
      "epoch 60; iter: 0; batch classifier loss: 0.458540; batch adversarial loss: 0.518026\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418046; batch adversarial loss: 0.536457\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424829; batch adversarial loss: 0.526384\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442362; batch adversarial loss: 0.571865\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466619; batch adversarial loss: 0.544894\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402868; batch adversarial loss: 0.598441\n",
      "epoch 66; iter: 0; batch classifier loss: 0.349076; batch adversarial loss: 0.554881\n",
      "epoch 67; iter: 0; batch classifier loss: 0.439198; batch adversarial loss: 0.470087\n",
      "epoch 68; iter: 0; batch classifier loss: 0.360434; batch adversarial loss: 0.617836\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422073; batch adversarial loss: 0.479563\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422142; batch adversarial loss: 0.525932\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387331; batch adversarial loss: 0.599329\n",
      "epoch 72; iter: 0; batch classifier loss: 0.350290; batch adversarial loss: 0.507382\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394665; batch adversarial loss: 0.589792\n",
      "epoch 74; iter: 0; batch classifier loss: 0.398399; batch adversarial loss: 0.581556\n",
      "epoch 75; iter: 0; batch classifier loss: 0.452665; batch adversarial loss: 0.535098\n",
      "epoch 76; iter: 0; batch classifier loss: 0.355218; batch adversarial loss: 0.553936\n",
      "epoch 77; iter: 0; batch classifier loss: 0.397152; batch adversarial loss: 0.563191\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372615; batch adversarial loss: 0.543578\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399100; batch adversarial loss: 0.424361\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437186; batch adversarial loss: 0.580061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.328942; batch adversarial loss: 0.579607\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381533; batch adversarial loss: 0.526204\n",
      "epoch 83; iter: 0; batch classifier loss: 0.463611; batch adversarial loss: 0.554978\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396220; batch adversarial loss: 0.499504\n",
      "epoch 85; iter: 0; batch classifier loss: 0.341377; batch adversarial loss: 0.562931\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380880; batch adversarial loss: 0.553872\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396334; batch adversarial loss: 0.461800\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368313; batch adversarial loss: 0.582792\n",
      "epoch 89; iter: 0; batch classifier loss: 0.416908; batch adversarial loss: 0.573390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.400883; batch adversarial loss: 0.553033\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361689; batch adversarial loss: 0.581223\n",
      "epoch 92; iter: 0; batch classifier loss: 0.447576; batch adversarial loss: 0.571438\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349461; batch adversarial loss: 0.581388\n",
      "epoch 94; iter: 0; batch classifier loss: 0.324677; batch adversarial loss: 0.506884\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375404; batch adversarial loss: 0.562373\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392928; batch adversarial loss: 0.525095\n",
      "epoch 97; iter: 0; batch classifier loss: 0.444241; batch adversarial loss: 0.517922\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390818; batch adversarial loss: 0.581433\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395555; batch adversarial loss: 0.526213\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365406; batch adversarial loss: 0.581957\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379251; batch adversarial loss: 0.608210\n",
      "epoch 102; iter: 0; batch classifier loss: 0.451047; batch adversarial loss: 0.544910\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352878; batch adversarial loss: 0.544406\n",
      "epoch 104; iter: 0; batch classifier loss: 0.340393; batch adversarial loss: 0.572406\n",
      "epoch 105; iter: 0; batch classifier loss: 0.458662; batch adversarial loss: 0.488032\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359024; batch adversarial loss: 0.544904\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388586; batch adversarial loss: 0.479695\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363714; batch adversarial loss: 0.497824\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331320; batch adversarial loss: 0.544498\n",
      "epoch 110; iter: 0; batch classifier loss: 0.308687; batch adversarial loss: 0.580499\n",
      "epoch 111; iter: 0; batch classifier loss: 0.428900; batch adversarial loss: 0.489051\n",
      "epoch 112; iter: 0; batch classifier loss: 0.413984; batch adversarial loss: 0.479562\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357453; batch adversarial loss: 0.563321\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349753; batch adversarial loss: 0.563122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390525; batch adversarial loss: 0.517394\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398018; batch adversarial loss: 0.544367\n",
      "epoch 117; iter: 0; batch classifier loss: 0.361384; batch adversarial loss: 0.535485\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390278; batch adversarial loss: 0.609346\n",
      "epoch 119; iter: 0; batch classifier loss: 0.333327; batch adversarial loss: 0.618326\n",
      "epoch 120; iter: 0; batch classifier loss: 0.434926; batch adversarial loss: 0.526076\n",
      "epoch 121; iter: 0; batch classifier loss: 0.277619; batch adversarial loss: 0.572284\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346162; batch adversarial loss: 0.572032\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390058; batch adversarial loss: 0.571990\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372790; batch adversarial loss: 0.646072\n",
      "epoch 125; iter: 0; batch classifier loss: 0.312689; batch adversarial loss: 0.507400\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369995; batch adversarial loss: 0.571997\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360014; batch adversarial loss: 0.489010\n",
      "epoch 128; iter: 0; batch classifier loss: 0.354964; batch adversarial loss: 0.535614\n",
      "epoch 129; iter: 0; batch classifier loss: 0.305665; batch adversarial loss: 0.618530\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388713; batch adversarial loss: 0.507364\n",
      "epoch 131; iter: 0; batch classifier loss: 0.429640; batch adversarial loss: 0.525862\n",
      "epoch 132; iter: 0; batch classifier loss: 0.460270; batch adversarial loss: 0.563286\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358324; batch adversarial loss: 0.535442\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338610; batch adversarial loss: 0.489396\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351274; batch adversarial loss: 0.535358\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363054; batch adversarial loss: 0.636386\n",
      "epoch 137; iter: 0; batch classifier loss: 0.380977; batch adversarial loss: 0.580934\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363565; batch adversarial loss: 0.544477\n",
      "epoch 139; iter: 0; batch classifier loss: 0.336487; batch adversarial loss: 0.572031\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325031; batch adversarial loss: 0.636353\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381614; batch adversarial loss: 0.544298\n",
      "epoch 142; iter: 0; batch classifier loss: 0.416563; batch adversarial loss: 0.526047\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368345; batch adversarial loss: 0.581166\n",
      "epoch 144; iter: 0; batch classifier loss: 0.300213; batch adversarial loss: 0.563449\n",
      "epoch 145; iter: 0; batch classifier loss: 0.389007; batch adversarial loss: 0.498323\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382392; batch adversarial loss: 0.516859\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332842; batch adversarial loss: 0.517136\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405054; batch adversarial loss: 0.507609\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316835; batch adversarial loss: 0.516701\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358662; batch adversarial loss: 0.498106\n",
      "epoch 151; iter: 0; batch classifier loss: 0.335170; batch adversarial loss: 0.507974\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339708; batch adversarial loss: 0.526175\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327717; batch adversarial loss: 0.544601\n",
      "epoch 154; iter: 0; batch classifier loss: 0.367014; batch adversarial loss: 0.664315\n",
      "epoch 155; iter: 0; batch classifier loss: 0.309516; batch adversarial loss: 0.553868\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354922; batch adversarial loss: 0.507715\n",
      "epoch 157; iter: 0; batch classifier loss: 0.432065; batch adversarial loss: 0.535299\n",
      "epoch 158; iter: 0; batch classifier loss: 0.461937; batch adversarial loss: 0.526205\n",
      "epoch 159; iter: 0; batch classifier loss: 0.318959; batch adversarial loss: 0.553721\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342730; batch adversarial loss: 0.526286\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366032; batch adversarial loss: 0.498378\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385835; batch adversarial loss: 0.544536\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328451; batch adversarial loss: 0.563001\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351808; batch adversarial loss: 0.489093\n",
      "epoch 165; iter: 0; batch classifier loss: 0.408838; batch adversarial loss: 0.544550\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387908; batch adversarial loss: 0.526037\n",
      "epoch 167; iter: 0; batch classifier loss: 0.443167; batch adversarial loss: 0.535452\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323312; batch adversarial loss: 0.507724\n",
      "epoch 169; iter: 0; batch classifier loss: 0.323093; batch adversarial loss: 0.581264\n",
      "epoch 170; iter: 0; batch classifier loss: 0.384768; batch adversarial loss: 0.526170\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326014; batch adversarial loss: 0.572450\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374604; batch adversarial loss: 0.498134\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349164; batch adversarial loss: 0.553564\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343016; batch adversarial loss: 0.480054\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392069; batch adversarial loss: 0.497912\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380758; batch adversarial loss: 0.489544\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344717; batch adversarial loss: 0.479856\n",
      "epoch 178; iter: 0; batch classifier loss: 0.409554; batch adversarial loss: 0.554423\n",
      "epoch 179; iter: 0; batch classifier loss: 0.342741; batch adversarial loss: 0.497652\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358121; batch adversarial loss: 0.524262\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334484; batch adversarial loss: 0.507642\n",
      "epoch 182; iter: 0; batch classifier loss: 0.369623; batch adversarial loss: 0.461058\n",
      "epoch 183; iter: 0; batch classifier loss: 0.394116; batch adversarial loss: 0.516409\n",
      "epoch 184; iter: 0; batch classifier loss: 0.298357; batch adversarial loss: 0.506790\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393520; batch adversarial loss: 0.516889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.357305; batch adversarial loss: 0.572332\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338161; batch adversarial loss: 0.542726\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374904; batch adversarial loss: 0.572917\n",
      "epoch 189; iter: 0; batch classifier loss: 0.424302; batch adversarial loss: 0.545364\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365579; batch adversarial loss: 0.600229\n",
      "epoch 191; iter: 0; batch classifier loss: 0.411902; batch adversarial loss: 0.498822\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320284; batch adversarial loss: 0.563620\n",
      "epoch 193; iter: 0; batch classifier loss: 0.424565; batch adversarial loss: 0.526101\n",
      "epoch 194; iter: 0; batch classifier loss: 0.303439; batch adversarial loss: 0.535128\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349089; batch adversarial loss: 0.563043\n",
      "epoch 196; iter: 0; batch classifier loss: 0.318537; batch adversarial loss: 0.525868\n",
      "epoch 197; iter: 0; batch classifier loss: 0.313041; batch adversarial loss: 0.535634\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390515; batch adversarial loss: 0.590237\n",
      "epoch 199; iter: 0; batch classifier loss: 0.310983; batch adversarial loss: 0.535574\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690411; batch adversarial loss: 0.634566\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555832; batch adversarial loss: 0.635570\n",
      "epoch 2; iter: 0; batch classifier loss: 0.602750; batch adversarial loss: 0.646345\n",
      "epoch 3; iter: 0; batch classifier loss: 0.486825; batch adversarial loss: 0.635261\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587015; batch adversarial loss: 0.643454\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533707; batch adversarial loss: 0.613935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593185; batch adversarial loss: 0.597701\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533002; batch adversarial loss: 0.573946\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549075; batch adversarial loss: 0.593955\n",
      "epoch 9; iter: 0; batch classifier loss: 0.583228; batch adversarial loss: 0.615819\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552894; batch adversarial loss: 0.572953\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547624; batch adversarial loss: 0.609876\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562620; batch adversarial loss: 0.613095\n",
      "epoch 13; iter: 0; batch classifier loss: 0.603415; batch adversarial loss: 0.553549\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559383; batch adversarial loss: 0.584574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.467906; batch adversarial loss: 0.535832\n",
      "epoch 16; iter: 0; batch classifier loss: 0.474679; batch adversarial loss: 0.538380\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524600; batch adversarial loss: 0.487243\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501918; batch adversarial loss: 0.580923\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471157; batch adversarial loss: 0.561576\n",
      "epoch 20; iter: 0; batch classifier loss: 0.569182; batch adversarial loss: 0.607580\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467716; batch adversarial loss: 0.540842\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491090; batch adversarial loss: 0.638361\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467925; batch adversarial loss: 0.593805\n",
      "epoch 24; iter: 0; batch classifier loss: 0.390668; batch adversarial loss: 0.503851\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533144; batch adversarial loss: 0.575212\n",
      "epoch 26; iter: 0; batch classifier loss: 0.504209; batch adversarial loss: 0.559733\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445601; batch adversarial loss: 0.531266\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506303; batch adversarial loss: 0.513578\n",
      "epoch 29; iter: 0; batch classifier loss: 0.433024; batch adversarial loss: 0.614203\n",
      "epoch 30; iter: 0; batch classifier loss: 0.521171; batch adversarial loss: 0.513874\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433701; batch adversarial loss: 0.529991\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465566; batch adversarial loss: 0.490969\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435328; batch adversarial loss: 0.546546\n",
      "epoch 34; iter: 0; batch classifier loss: 0.524791; batch adversarial loss: 0.490087\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461009; batch adversarial loss: 0.471067\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503019; batch adversarial loss: 0.497545\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463789; batch adversarial loss: 0.526775\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449778; batch adversarial loss: 0.497925\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482790; batch adversarial loss: 0.534756\n",
      "epoch 40; iter: 0; batch classifier loss: 0.386640; batch adversarial loss: 0.561932\n",
      "epoch 41; iter: 0; batch classifier loss: 0.518317; batch adversarial loss: 0.525929\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439383; batch adversarial loss: 0.517906\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470886; batch adversarial loss: 0.533321\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431109; batch adversarial loss: 0.517635\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435438; batch adversarial loss: 0.576829\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429323; batch adversarial loss: 0.517293\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409888; batch adversarial loss: 0.593165\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449030; batch adversarial loss: 0.583112\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412416; batch adversarial loss: 0.525576\n",
      "epoch 50; iter: 0; batch classifier loss: 0.545399; batch adversarial loss: 0.526083\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483647; batch adversarial loss: 0.498581\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467648; batch adversarial loss: 0.563180\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384142; batch adversarial loss: 0.554266\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425840; batch adversarial loss: 0.534693\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395075; batch adversarial loss: 0.525932\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434679; batch adversarial loss: 0.562332\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395098; batch adversarial loss: 0.572663\n",
      "epoch 58; iter: 0; batch classifier loss: 0.432955; batch adversarial loss: 0.545077\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422808; batch adversarial loss: 0.553223\n",
      "epoch 60; iter: 0; batch classifier loss: 0.365055; batch adversarial loss: 0.525904\n",
      "epoch 61; iter: 0; batch classifier loss: 0.479972; batch adversarial loss: 0.535408\n",
      "epoch 62; iter: 0; batch classifier loss: 0.491673; batch adversarial loss: 0.506123\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409917; batch adversarial loss: 0.534555\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437039; batch adversarial loss: 0.476801\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467652; batch adversarial loss: 0.523109\n",
      "epoch 66; iter: 0; batch classifier loss: 0.490090; batch adversarial loss: 0.505021\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426104; batch adversarial loss: 0.495558\n",
      "epoch 68; iter: 0; batch classifier loss: 0.543430; batch adversarial loss: 0.496390\n",
      "epoch 69; iter: 0; batch classifier loss: 0.368384; batch adversarial loss: 0.518273\n",
      "epoch 70; iter: 0; batch classifier loss: 0.432283; batch adversarial loss: 0.555365\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402965; batch adversarial loss: 0.563149\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416958; batch adversarial loss: 0.528624\n",
      "epoch 73; iter: 0; batch classifier loss: 0.450853; batch adversarial loss: 0.562606\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364038; batch adversarial loss: 0.527898\n",
      "epoch 75; iter: 0; batch classifier loss: 0.419917; batch adversarial loss: 0.581428\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461368; batch adversarial loss: 0.589867\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419190; batch adversarial loss: 0.525842\n",
      "epoch 78; iter: 0; batch classifier loss: 0.511489; batch adversarial loss: 0.499040\n",
      "epoch 79; iter: 0; batch classifier loss: 0.351390; batch adversarial loss: 0.497444\n",
      "epoch 80; iter: 0; batch classifier loss: 0.425738; batch adversarial loss: 0.488489\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378337; batch adversarial loss: 0.616775\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384353; batch adversarial loss: 0.550959\n",
      "epoch 83; iter: 0; batch classifier loss: 0.393115; batch adversarial loss: 0.514273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.477300; batch adversarial loss: 0.516045\n",
      "epoch 85; iter: 0; batch classifier loss: 0.484373; batch adversarial loss: 0.525788\n",
      "epoch 86; iter: 0; batch classifier loss: 0.422197; batch adversarial loss: 0.543406\n",
      "epoch 87; iter: 0; batch classifier loss: 0.349286; batch adversarial loss: 0.554127\n",
      "epoch 88; iter: 0; batch classifier loss: 0.468845; batch adversarial loss: 0.514353\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363006; batch adversarial loss: 0.522408\n",
      "epoch 90; iter: 0; batch classifier loss: 0.439947; batch adversarial loss: 0.499382\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408223; batch adversarial loss: 0.532619\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414228; batch adversarial loss: 0.516198\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383754; batch adversarial loss: 0.628420\n",
      "epoch 94; iter: 0; batch classifier loss: 0.486650; batch adversarial loss: 0.551425\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407221; batch adversarial loss: 0.552104\n",
      "epoch 96; iter: 0; batch classifier loss: 0.427934; batch adversarial loss: 0.484072\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394759; batch adversarial loss: 0.572701\n",
      "epoch 98; iter: 0; batch classifier loss: 0.423607; batch adversarial loss: 0.439986\n",
      "epoch 99; iter: 0; batch classifier loss: 0.431791; batch adversarial loss: 0.546427\n",
      "epoch 100; iter: 0; batch classifier loss: 0.459080; batch adversarial loss: 0.498714\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407401; batch adversarial loss: 0.648048\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374153; batch adversarial loss: 0.683286\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398812; batch adversarial loss: 0.526085\n",
      "epoch 104; iter: 0; batch classifier loss: 0.444319; batch adversarial loss: 0.485820\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409215; batch adversarial loss: 0.427586\n",
      "epoch 106; iter: 0; batch classifier loss: 0.425566; batch adversarial loss: 0.636884\n",
      "epoch 107; iter: 0; batch classifier loss: 0.408640; batch adversarial loss: 0.500642\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407116; batch adversarial loss: 0.571810\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388690; batch adversarial loss: 0.578353\n",
      "epoch 110; iter: 0; batch classifier loss: 0.404905; batch adversarial loss: 0.476162\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361073; batch adversarial loss: 0.485084\n",
      "epoch 112; iter: 0; batch classifier loss: 0.329945; batch adversarial loss: 0.534024\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371373; batch adversarial loss: 0.392855\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410280; batch adversarial loss: 0.584654\n",
      "epoch 115; iter: 0; batch classifier loss: 0.362031; batch adversarial loss: 0.515482\n",
      "epoch 116; iter: 0; batch classifier loss: 0.403804; batch adversarial loss: 0.506532\n",
      "epoch 117; iter: 0; batch classifier loss: 0.307126; batch adversarial loss: 0.535235\n",
      "epoch 118; iter: 0; batch classifier loss: 0.329956; batch adversarial loss: 0.508293\n",
      "epoch 119; iter: 0; batch classifier loss: 0.430873; batch adversarial loss: 0.533747\n",
      "epoch 120; iter: 0; batch classifier loss: 0.461156; batch adversarial loss: 0.504281\n",
      "epoch 121; iter: 0; batch classifier loss: 0.425561; batch adversarial loss: 0.537340\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381492; batch adversarial loss: 0.562118\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375732; batch adversarial loss: 0.551483\n",
      "epoch 124; iter: 0; batch classifier loss: 0.383470; batch adversarial loss: 0.528611\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413539; batch adversarial loss: 0.433099\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412497; batch adversarial loss: 0.579649\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367256; batch adversarial loss: 0.590091\n",
      "epoch 128; iter: 0; batch classifier loss: 0.407797; batch adversarial loss: 0.487282\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402398; batch adversarial loss: 0.581507\n",
      "epoch 130; iter: 0; batch classifier loss: 0.334310; batch adversarial loss: 0.553613\n",
      "epoch 131; iter: 0; batch classifier loss: 0.415736; batch adversarial loss: 0.498129\n",
      "epoch 132; iter: 0; batch classifier loss: 0.407864; batch adversarial loss: 0.523348\n",
      "epoch 133; iter: 0; batch classifier loss: 0.404979; batch adversarial loss: 0.525845\n",
      "epoch 134; iter: 0; batch classifier loss: 0.299461; batch adversarial loss: 0.552839\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387704; batch adversarial loss: 0.628367\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359412; batch adversarial loss: 0.551562\n",
      "epoch 137; iter: 0; batch classifier loss: 0.295908; batch adversarial loss: 0.590437\n",
      "epoch 138; iter: 0; batch classifier loss: 0.462685; batch adversarial loss: 0.505228\n",
      "epoch 139; iter: 0; batch classifier loss: 0.348315; batch adversarial loss: 0.524044\n",
      "epoch 140; iter: 0; batch classifier loss: 0.372378; batch adversarial loss: 0.580925\n",
      "epoch 141; iter: 0; batch classifier loss: 0.318578; batch adversarial loss: 0.602087\n",
      "epoch 142; iter: 0; batch classifier loss: 0.373435; batch adversarial loss: 0.565250\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376208; batch adversarial loss: 0.534825\n",
      "epoch 144; iter: 0; batch classifier loss: 0.416390; batch adversarial loss: 0.467612\n",
      "epoch 145; iter: 0; batch classifier loss: 0.247835; batch adversarial loss: 0.553350\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353750; batch adversarial loss: 0.629737\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329689; batch adversarial loss: 0.541830\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364860; batch adversarial loss: 0.534740\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341214; batch adversarial loss: 0.526797\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391723; batch adversarial loss: 0.507270\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344659; batch adversarial loss: 0.545938\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365093; batch adversarial loss: 0.525765\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362234; batch adversarial loss: 0.541986\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394871; batch adversarial loss: 0.574574\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314523; batch adversarial loss: 0.513475\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357697; batch adversarial loss: 0.542256\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385151; batch adversarial loss: 0.497804\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368976; batch adversarial loss: 0.514042\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362917; batch adversarial loss: 0.552941\n",
      "epoch 160; iter: 0; batch classifier loss: 0.303318; batch adversarial loss: 0.589502\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376152; batch adversarial loss: 0.592997\n",
      "epoch 162; iter: 0; batch classifier loss: 0.300794; batch adversarial loss: 0.611426\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374431; batch adversarial loss: 0.527373\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392427; batch adversarial loss: 0.562069\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358361; batch adversarial loss: 0.496903\n",
      "epoch 166; iter: 0; batch classifier loss: 0.385369; batch adversarial loss: 0.599199\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335963; batch adversarial loss: 0.552163\n",
      "epoch 168; iter: 0; batch classifier loss: 0.419899; batch adversarial loss: 0.504620\n",
      "epoch 169; iter: 0; batch classifier loss: 0.364799; batch adversarial loss: 0.523315\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397519; batch adversarial loss: 0.516234\n",
      "epoch 171; iter: 0; batch classifier loss: 0.433071; batch adversarial loss: 0.515290\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344891; batch adversarial loss: 0.486677\n",
      "epoch 173; iter: 0; batch classifier loss: 0.418476; batch adversarial loss: 0.543787\n",
      "epoch 174; iter: 0; batch classifier loss: 0.489123; batch adversarial loss: 0.533544\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356903; batch adversarial loss: 0.497561\n",
      "epoch 176; iter: 0; batch classifier loss: 0.307318; batch adversarial loss: 0.582964\n",
      "epoch 177; iter: 0; batch classifier loss: 0.454801; batch adversarial loss: 0.610517\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332147; batch adversarial loss: 0.563343\n",
      "epoch 179; iter: 0; batch classifier loss: 0.311934; batch adversarial loss: 0.547729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.321063; batch adversarial loss: 0.543754\n",
      "epoch 181; iter: 0; batch classifier loss: 0.326140; batch adversarial loss: 0.480961\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318949; batch adversarial loss: 0.536585\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352584; batch adversarial loss: 0.523587\n",
      "epoch 184; iter: 0; batch classifier loss: 0.368309; batch adversarial loss: 0.490014\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308825; batch adversarial loss: 0.575297\n",
      "epoch 186; iter: 0; batch classifier loss: 0.419871; batch adversarial loss: 0.422478\n",
      "epoch 187; iter: 0; batch classifier loss: 0.431681; batch adversarial loss: 0.516083\n",
      "epoch 188; iter: 0; batch classifier loss: 0.432386; batch adversarial loss: 0.487961\n",
      "epoch 189; iter: 0; batch classifier loss: 0.278189; batch adversarial loss: 0.488036\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338308; batch adversarial loss: 0.562055\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364283; batch adversarial loss: 0.542816\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365959; batch adversarial loss: 0.528499\n",
      "epoch 193; iter: 0; batch classifier loss: 0.430118; batch adversarial loss: 0.620609\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342016; batch adversarial loss: 0.534626\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361281; batch adversarial loss: 0.475324\n",
      "epoch 196; iter: 0; batch classifier loss: 0.421826; batch adversarial loss: 0.504710\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360482; batch adversarial loss: 0.543831\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319711; batch adversarial loss: 0.584265\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365582; batch adversarial loss: 0.544181\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692867; batch adversarial loss: 0.795783\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605640; batch adversarial loss: 0.741273\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593458; batch adversarial loss: 0.690010\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641879; batch adversarial loss: 0.648898\n",
      "epoch 4; iter: 0; batch classifier loss: 0.570825; batch adversarial loss: 0.674197\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532728; batch adversarial loss: 0.657566\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532066; batch adversarial loss: 0.644291\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594060; batch adversarial loss: 0.602239\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552904; batch adversarial loss: 0.574820\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562173; batch adversarial loss: 0.581174\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504962; batch adversarial loss: 0.542916\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562417; batch adversarial loss: 0.606548\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533799; batch adversarial loss: 0.520065\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489420; batch adversarial loss: 0.611431\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523870; batch adversarial loss: 0.562263\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470500; batch adversarial loss: 0.531111\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518017; batch adversarial loss: 0.535791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492848; batch adversarial loss: 0.629807\n",
      "epoch 18; iter: 0; batch classifier loss: 0.464058; batch adversarial loss: 0.559442\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523600; batch adversarial loss: 0.581479\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518374; batch adversarial loss: 0.542403\n",
      "epoch 21; iter: 0; batch classifier loss: 0.505047; batch adversarial loss: 0.558413\n",
      "epoch 22; iter: 0; batch classifier loss: 0.554370; batch adversarial loss: 0.600972\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528270; batch adversarial loss: 0.548440\n",
      "epoch 24; iter: 0; batch classifier loss: 0.428369; batch adversarial loss: 0.601679\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510936; batch adversarial loss: 0.553708\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479293; batch adversarial loss: 0.510323\n",
      "epoch 27; iter: 0; batch classifier loss: 0.534903; batch adversarial loss: 0.572094\n",
      "epoch 28; iter: 0; batch classifier loss: 0.436365; batch adversarial loss: 0.535053\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413281; batch adversarial loss: 0.574929\n",
      "epoch 30; iter: 0; batch classifier loss: 0.396151; batch adversarial loss: 0.436221\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445995; batch adversarial loss: 0.606496\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348455; batch adversarial loss: 0.548490\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462906; batch adversarial loss: 0.556523\n",
      "epoch 34; iter: 0; batch classifier loss: 0.489558; batch adversarial loss: 0.542127\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434876; batch adversarial loss: 0.620336\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469246; batch adversarial loss: 0.569465\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481253; batch adversarial loss: 0.602110\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441793; batch adversarial loss: 0.607774\n",
      "epoch 39; iter: 0; batch classifier loss: 0.408311; batch adversarial loss: 0.512238\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383313; batch adversarial loss: 0.569452\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429967; batch adversarial loss: 0.563723\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424286; batch adversarial loss: 0.555707\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424065; batch adversarial loss: 0.545574\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400519; batch adversarial loss: 0.500948\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377967; batch adversarial loss: 0.522728\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406836; batch adversarial loss: 0.576558\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438343; batch adversarial loss: 0.543232\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379723; batch adversarial loss: 0.535726\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390361; batch adversarial loss: 0.554506\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421564; batch adversarial loss: 0.570046\n",
      "epoch 51; iter: 0; batch classifier loss: 0.412677; batch adversarial loss: 0.505786\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382474; batch adversarial loss: 0.589139\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422313; batch adversarial loss: 0.644822\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413716; batch adversarial loss: 0.526966\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389428; batch adversarial loss: 0.541348\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426516; batch adversarial loss: 0.518411\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398560; batch adversarial loss: 0.535167\n",
      "epoch 58; iter: 0; batch classifier loss: 0.432855; batch adversarial loss: 0.506645\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416344; batch adversarial loss: 0.581206\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397648; batch adversarial loss: 0.491190\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420698; batch adversarial loss: 0.599376\n",
      "epoch 62; iter: 0; batch classifier loss: 0.372233; batch adversarial loss: 0.608543\n",
      "epoch 63; iter: 0; batch classifier loss: 0.458961; batch adversarial loss: 0.551576\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377727; batch adversarial loss: 0.551967\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425208; batch adversarial loss: 0.570753\n",
      "epoch 66; iter: 0; batch classifier loss: 0.461654; batch adversarial loss: 0.563026\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372373; batch adversarial loss: 0.517253\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390911; batch adversarial loss: 0.553215\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412225; batch adversarial loss: 0.553543\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430331; batch adversarial loss: 0.566358\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373958; batch adversarial loss: 0.523221\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381029; batch adversarial loss: 0.516074\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415789; batch adversarial loss: 0.583545\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417759; batch adversarial loss: 0.505943\n",
      "epoch 75; iter: 0; batch classifier loss: 0.452531; batch adversarial loss: 0.557102\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422263; batch adversarial loss: 0.487105\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385969; batch adversarial loss: 0.592717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.442531; batch adversarial loss: 0.544730\n",
      "epoch 79; iter: 0; batch classifier loss: 0.363973; batch adversarial loss: 0.527855\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417210; batch adversarial loss: 0.597284\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368455; batch adversarial loss: 0.496788\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377396; batch adversarial loss: 0.519276\n",
      "epoch 83; iter: 0; batch classifier loss: 0.427735; batch adversarial loss: 0.570446\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381318; batch adversarial loss: 0.536529\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383516; batch adversarial loss: 0.573283\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389030; batch adversarial loss: 0.601719\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406442; batch adversarial loss: 0.468609\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402244; batch adversarial loss: 0.489607\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367509; batch adversarial loss: 0.507559\n",
      "epoch 90; iter: 0; batch classifier loss: 0.414667; batch adversarial loss: 0.497551\n",
      "epoch 91; iter: 0; batch classifier loss: 0.500850; batch adversarial loss: 0.514998\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418283; batch adversarial loss: 0.596147\n",
      "epoch 93; iter: 0; batch classifier loss: 0.322693; batch adversarial loss: 0.561596\n",
      "epoch 94; iter: 0; batch classifier loss: 0.456418; batch adversarial loss: 0.600028\n",
      "epoch 95; iter: 0; batch classifier loss: 0.406057; batch adversarial loss: 0.545464\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381137; batch adversarial loss: 0.486559\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418582; batch adversarial loss: 0.592933\n",
      "epoch 98; iter: 0; batch classifier loss: 0.355572; batch adversarial loss: 0.506884\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373258; batch adversarial loss: 0.535817\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408605; batch adversarial loss: 0.521744\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420046; batch adversarial loss: 0.582006\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392695; batch adversarial loss: 0.583632\n",
      "epoch 103; iter: 0; batch classifier loss: 0.349339; batch adversarial loss: 0.498318\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374080; batch adversarial loss: 0.580875\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380362; batch adversarial loss: 0.583901\n",
      "epoch 106; iter: 0; batch classifier loss: 0.339719; batch adversarial loss: 0.553993\n",
      "epoch 107; iter: 0; batch classifier loss: 0.360033; batch adversarial loss: 0.563484\n",
      "epoch 108; iter: 0; batch classifier loss: 0.440404; batch adversarial loss: 0.506588\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412921; batch adversarial loss: 0.543485\n",
      "epoch 110; iter: 0; batch classifier loss: 0.453282; batch adversarial loss: 0.540926\n",
      "epoch 111; iter: 0; batch classifier loss: 0.448887; batch adversarial loss: 0.572699\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402696; batch adversarial loss: 0.545049\n",
      "epoch 113; iter: 0; batch classifier loss: 0.306068; batch adversarial loss: 0.543681\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369444; batch adversarial loss: 0.524344\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389646; batch adversarial loss: 0.458541\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348377; batch adversarial loss: 0.542958\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377181; batch adversarial loss: 0.588253\n",
      "epoch 118; iter: 0; batch classifier loss: 0.482608; batch adversarial loss: 0.576074\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339124; batch adversarial loss: 0.583672\n",
      "epoch 120; iter: 0; batch classifier loss: 0.329273; batch adversarial loss: 0.485791\n",
      "epoch 121; iter: 0; batch classifier loss: 0.427760; batch adversarial loss: 0.536748\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355156; batch adversarial loss: 0.552244\n",
      "epoch 123; iter: 0; batch classifier loss: 0.382630; batch adversarial loss: 0.555843\n",
      "epoch 124; iter: 0; batch classifier loss: 0.312489; batch adversarial loss: 0.573850\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437833; batch adversarial loss: 0.536402\n",
      "epoch 126; iter: 0; batch classifier loss: 0.425641; batch adversarial loss: 0.544807\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340688; batch adversarial loss: 0.612470\n",
      "epoch 128; iter: 0; batch classifier loss: 0.423329; batch adversarial loss: 0.534846\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340739; batch adversarial loss: 0.507229\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382832; batch adversarial loss: 0.571899\n",
      "epoch 131; iter: 0; batch classifier loss: 0.390324; batch adversarial loss: 0.509128\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353779; batch adversarial loss: 0.561671\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396974; batch adversarial loss: 0.507068\n",
      "epoch 134; iter: 0; batch classifier loss: 0.445425; batch adversarial loss: 0.583118\n",
      "epoch 135; iter: 0; batch classifier loss: 0.403595; batch adversarial loss: 0.592288\n",
      "epoch 136; iter: 0; batch classifier loss: 0.461761; batch adversarial loss: 0.516256\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328774; batch adversarial loss: 0.572862\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348859; batch adversarial loss: 0.471414\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402180; batch adversarial loss: 0.580592\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401650; batch adversarial loss: 0.543554\n",
      "epoch 141; iter: 0; batch classifier loss: 0.396522; batch adversarial loss: 0.563306\n",
      "epoch 142; iter: 0; batch classifier loss: 0.448634; batch adversarial loss: 0.598701\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391876; batch adversarial loss: 0.598049\n",
      "epoch 144; iter: 0; batch classifier loss: 0.321053; batch adversarial loss: 0.526374\n",
      "epoch 145; iter: 0; batch classifier loss: 0.401392; batch adversarial loss: 0.469041\n",
      "epoch 146; iter: 0; batch classifier loss: 0.338061; batch adversarial loss: 0.583365\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336421; batch adversarial loss: 0.560682\n",
      "epoch 148; iter: 0; batch classifier loss: 0.394646; batch adversarial loss: 0.517367\n",
      "epoch 149; iter: 0; batch classifier loss: 0.390126; batch adversarial loss: 0.560699\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369874; batch adversarial loss: 0.566243\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370824; batch adversarial loss: 0.544447\n",
      "epoch 152; iter: 0; batch classifier loss: 0.316979; batch adversarial loss: 0.536617\n",
      "epoch 153; iter: 0; batch classifier loss: 0.419210; batch adversarial loss: 0.697409\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389840; batch adversarial loss: 0.591724\n",
      "epoch 155; iter: 0; batch classifier loss: 0.471821; batch adversarial loss: 0.573488\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337934; batch adversarial loss: 0.525523\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344201; batch adversarial loss: 0.443568\n",
      "epoch 158; iter: 0; batch classifier loss: 0.300514; batch adversarial loss: 0.536259\n",
      "epoch 159; iter: 0; batch classifier loss: 0.382997; batch adversarial loss: 0.523593\n",
      "epoch 160; iter: 0; batch classifier loss: 0.441551; batch adversarial loss: 0.591296\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346637; batch adversarial loss: 0.546242\n",
      "epoch 162; iter: 0; batch classifier loss: 0.367048; batch adversarial loss: 0.541986\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402893; batch adversarial loss: 0.562267\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400010; batch adversarial loss: 0.582598\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374786; batch adversarial loss: 0.532697\n",
      "epoch 166; iter: 0; batch classifier loss: 0.299253; batch adversarial loss: 0.487057\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376774; batch adversarial loss: 0.568872\n",
      "epoch 168; iter: 0; batch classifier loss: 0.403277; batch adversarial loss: 0.683987\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382592; batch adversarial loss: 0.556988\n",
      "epoch 170; iter: 0; batch classifier loss: 0.407586; batch adversarial loss: 0.515222\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370386; batch adversarial loss: 0.621015\n",
      "epoch 172; iter: 0; batch classifier loss: 0.302668; batch adversarial loss: 0.508207\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430035; batch adversarial loss: 0.450123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.337752; batch adversarial loss: 0.598534\n",
      "epoch 175; iter: 0; batch classifier loss: 0.415516; batch adversarial loss: 0.504099\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343160; batch adversarial loss: 0.581991\n",
      "epoch 177; iter: 0; batch classifier loss: 0.419542; batch adversarial loss: 0.600228\n",
      "epoch 178; iter: 0; batch classifier loss: 0.483820; batch adversarial loss: 0.496311\n",
      "epoch 179; iter: 0; batch classifier loss: 0.411073; batch adversarial loss: 0.512198\n",
      "epoch 180; iter: 0; batch classifier loss: 0.416466; batch adversarial loss: 0.497103\n",
      "epoch 181; iter: 0; batch classifier loss: 0.254943; batch adversarial loss: 0.607666\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378421; batch adversarial loss: 0.554488\n",
      "epoch 183; iter: 0; batch classifier loss: 0.361537; batch adversarial loss: 0.561033\n",
      "epoch 184; iter: 0; batch classifier loss: 0.297704; batch adversarial loss: 0.565947\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365556; batch adversarial loss: 0.478944\n",
      "epoch 186; iter: 0; batch classifier loss: 0.409770; batch adversarial loss: 0.555176\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313142; batch adversarial loss: 0.500131\n",
      "epoch 188; iter: 0; batch classifier loss: 0.380873; batch adversarial loss: 0.584124\n",
      "epoch 189; iter: 0; batch classifier loss: 0.428924; batch adversarial loss: 0.456482\n",
      "epoch 190; iter: 0; batch classifier loss: 0.300154; batch adversarial loss: 0.506567\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316925; batch adversarial loss: 0.524535\n",
      "epoch 192; iter: 0; batch classifier loss: 0.289683; batch adversarial loss: 0.480256\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378363; batch adversarial loss: 0.589999\n",
      "epoch 194; iter: 0; batch classifier loss: 0.317897; batch adversarial loss: 0.514855\n",
      "epoch 195; iter: 0; batch classifier loss: 0.331520; batch adversarial loss: 0.498200\n",
      "epoch 196; iter: 0; batch classifier loss: 0.478363; batch adversarial loss: 0.493780\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335299; batch adversarial loss: 0.575426\n",
      "epoch 198; iter: 0; batch classifier loss: 0.290057; batch adversarial loss: 0.514983\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332359; batch adversarial loss: 0.573216\n",
      "epoch 0; iter: 0; batch classifier loss: 0.660550; batch adversarial loss: 0.687684\n",
      "epoch 1; iter: 0; batch classifier loss: 0.547653; batch adversarial loss: 0.662495\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561263; batch adversarial loss: 0.640873\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583356; batch adversarial loss: 0.624506\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562251; batch adversarial loss: 0.641764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599656; batch adversarial loss: 0.551047\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555382; batch adversarial loss: 0.581291\n",
      "epoch 7; iter: 0; batch classifier loss: 0.468482; batch adversarial loss: 0.532299\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550027; batch adversarial loss: 0.594333\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536829; batch adversarial loss: 0.572989\n",
      "epoch 10; iter: 0; batch classifier loss: 0.614756; batch adversarial loss: 0.632072\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586055; batch adversarial loss: 0.627048\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564272; batch adversarial loss: 0.612556\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500806; batch adversarial loss: 0.575741\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531696; batch adversarial loss: 0.608089\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469611; batch adversarial loss: 0.553505\n",
      "epoch 16; iter: 0; batch classifier loss: 0.597509; batch adversarial loss: 0.567838\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477510; batch adversarial loss: 0.545716\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483986; batch adversarial loss: 0.543352\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525515; batch adversarial loss: 0.560926\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534415; batch adversarial loss: 0.518970\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515516; batch adversarial loss: 0.563028\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491251; batch adversarial loss: 0.529440\n",
      "epoch 23; iter: 0; batch classifier loss: 0.383027; batch adversarial loss: 0.542563\n",
      "epoch 24; iter: 0; batch classifier loss: 0.415166; batch adversarial loss: 0.556840\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557488; batch adversarial loss: 0.507664\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448900; batch adversarial loss: 0.523565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.403927; batch adversarial loss: 0.487900\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452632; batch adversarial loss: 0.528207\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473232; batch adversarial loss: 0.525574\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483578; batch adversarial loss: 0.511700\n",
      "epoch 31; iter: 0; batch classifier loss: 0.406836; batch adversarial loss: 0.501917\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436136; batch adversarial loss: 0.556273\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468740; batch adversarial loss: 0.491807\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431669; batch adversarial loss: 0.535136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.533225; batch adversarial loss: 0.562056\n",
      "epoch 36; iter: 0; batch classifier loss: 0.413522; batch adversarial loss: 0.517849\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402556; batch adversarial loss: 0.537921\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460448; batch adversarial loss: 0.524519\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432535; batch adversarial loss: 0.571620\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406383; batch adversarial loss: 0.562312\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472635; batch adversarial loss: 0.581896\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454267; batch adversarial loss: 0.592654\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406176; batch adversarial loss: 0.564093\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396192; batch adversarial loss: 0.626016\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443841; batch adversarial loss: 0.534233\n",
      "epoch 46; iter: 0; batch classifier loss: 0.404689; batch adversarial loss: 0.646472\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451651; batch adversarial loss: 0.563794\n",
      "epoch 48; iter: 0; batch classifier loss: 0.467697; batch adversarial loss: 0.498159\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391158; batch adversarial loss: 0.572234\n",
      "epoch 50; iter: 0; batch classifier loss: 0.398399; batch adversarial loss: 0.591493\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428845; batch adversarial loss: 0.507377\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444412; batch adversarial loss: 0.573394\n",
      "epoch 53; iter: 0; batch classifier loss: 0.503855; batch adversarial loss: 0.572630\n",
      "epoch 54; iter: 0; batch classifier loss: 0.339180; batch adversarial loss: 0.480438\n",
      "epoch 55; iter: 0; batch classifier loss: 0.288707; batch adversarial loss: 0.479949\n",
      "epoch 56; iter: 0; batch classifier loss: 0.470494; batch adversarial loss: 0.488794\n",
      "epoch 57; iter: 0; batch classifier loss: 0.358200; batch adversarial loss: 0.516444\n",
      "epoch 58; iter: 0; batch classifier loss: 0.406078; batch adversarial loss: 0.562879\n",
      "epoch 59; iter: 0; batch classifier loss: 0.336873; batch adversarial loss: 0.581722\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425883; batch adversarial loss: 0.561537\n",
      "epoch 61; iter: 0; batch classifier loss: 0.369497; batch adversarial loss: 0.655733\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397715; batch adversarial loss: 0.544738\n",
      "epoch 63; iter: 0; batch classifier loss: 0.362874; batch adversarial loss: 0.544432\n",
      "epoch 64; iter: 0; batch classifier loss: 0.374353; batch adversarial loss: 0.573216\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390112; batch adversarial loss: 0.534723\n",
      "epoch 66; iter: 0; batch classifier loss: 0.342300; batch adversarial loss: 0.563219\n",
      "epoch 67; iter: 0; batch classifier loss: 0.375038; batch adversarial loss: 0.468669\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408535; batch adversarial loss: 0.517430\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419187; batch adversarial loss: 0.582360\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431844; batch adversarial loss: 0.498786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.413965; batch adversarial loss: 0.488495\n",
      "epoch 72; iter: 0; batch classifier loss: 0.335089; batch adversarial loss: 0.592092\n",
      "epoch 73; iter: 0; batch classifier loss: 0.358133; batch adversarial loss: 0.534731\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380257; batch adversarial loss: 0.553618\n",
      "epoch 75; iter: 0; batch classifier loss: 0.349987; batch adversarial loss: 0.507961\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406729; batch adversarial loss: 0.488370\n",
      "epoch 77; iter: 0; batch classifier loss: 0.363841; batch adversarial loss: 0.553951\n",
      "epoch 78; iter: 0; batch classifier loss: 0.467057; batch adversarial loss: 0.496825\n",
      "epoch 79; iter: 0; batch classifier loss: 0.347729; batch adversarial loss: 0.591290\n",
      "epoch 80; iter: 0; batch classifier loss: 0.461281; batch adversarial loss: 0.507854\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388155; batch adversarial loss: 0.525092\n",
      "epoch 82; iter: 0; batch classifier loss: 0.328584; batch adversarial loss: 0.591348\n",
      "epoch 83; iter: 0; batch classifier loss: 0.479533; batch adversarial loss: 0.516712\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395836; batch adversarial loss: 0.554317\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393882; batch adversarial loss: 0.498167\n",
      "epoch 86; iter: 0; batch classifier loss: 0.452689; batch adversarial loss: 0.573588\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418000; batch adversarial loss: 0.544333\n",
      "epoch 88; iter: 0; batch classifier loss: 0.463002; batch adversarial loss: 0.600773\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419814; batch adversarial loss: 0.582056\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362802; batch adversarial loss: 0.507402\n",
      "epoch 91; iter: 0; batch classifier loss: 0.332687; batch adversarial loss: 0.526645\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365180; batch adversarial loss: 0.553983\n",
      "epoch 93; iter: 0; batch classifier loss: 0.423552; batch adversarial loss: 0.533395\n",
      "epoch 94; iter: 0; batch classifier loss: 0.529115; batch adversarial loss: 0.562699\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427623; batch adversarial loss: 0.563241\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376429; batch adversarial loss: 0.545031\n",
      "epoch 97; iter: 0; batch classifier loss: 0.426496; batch adversarial loss: 0.470356\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393609; batch adversarial loss: 0.507006\n",
      "epoch 99; iter: 0; batch classifier loss: 0.389897; batch adversarial loss: 0.442100\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410784; batch adversarial loss: 0.582926\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401175; batch adversarial loss: 0.563030\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340606; batch adversarial loss: 0.610094\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429094; batch adversarial loss: 0.516726\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365594; batch adversarial loss: 0.591078\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385085; batch adversarial loss: 0.591179\n",
      "epoch 106; iter: 0; batch classifier loss: 0.368518; batch adversarial loss: 0.542512\n",
      "epoch 107; iter: 0; batch classifier loss: 0.448290; batch adversarial loss: 0.535344\n",
      "epoch 108; iter: 0; batch classifier loss: 0.315130; batch adversarial loss: 0.535267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.393831; batch adversarial loss: 0.590116\n",
      "epoch 110; iter: 0; batch classifier loss: 0.324309; batch adversarial loss: 0.515679\n",
      "epoch 111; iter: 0; batch classifier loss: 0.357337; batch adversarial loss: 0.572690\n",
      "epoch 112; iter: 0; batch classifier loss: 0.309676; batch adversarial loss: 0.590887\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405112; batch adversarial loss: 0.507940\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327052; batch adversarial loss: 0.533538\n",
      "epoch 115; iter: 0; batch classifier loss: 0.414859; batch adversarial loss: 0.516164\n",
      "epoch 116; iter: 0; batch classifier loss: 0.336729; batch adversarial loss: 0.448680\n",
      "epoch 117; iter: 0; batch classifier loss: 0.352571; batch adversarial loss: 0.517229\n",
      "epoch 118; iter: 0; batch classifier loss: 0.450160; batch adversarial loss: 0.531635\n",
      "epoch 119; iter: 0; batch classifier loss: 0.330250; batch adversarial loss: 0.552820\n",
      "epoch 120; iter: 0; batch classifier loss: 0.476380; batch adversarial loss: 0.507625\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335055; batch adversarial loss: 0.590029\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372621; batch adversarial loss: 0.538029\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396172; batch adversarial loss: 0.480710\n",
      "epoch 124; iter: 0; batch classifier loss: 0.446719; batch adversarial loss: 0.507086\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373651; batch adversarial loss: 0.600284\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375242; batch adversarial loss: 0.544601\n",
      "epoch 127; iter: 0; batch classifier loss: 0.405187; batch adversarial loss: 0.477590\n",
      "epoch 128; iter: 0; batch classifier loss: 0.481380; batch adversarial loss: 0.525022\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395788; batch adversarial loss: 0.433194\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374591; batch adversarial loss: 0.562266\n",
      "epoch 131; iter: 0; batch classifier loss: 0.358525; batch adversarial loss: 0.601187\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329973; batch adversarial loss: 0.487855\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341710; batch adversarial loss: 0.517113\n",
      "epoch 134; iter: 0; batch classifier loss: 0.292799; batch adversarial loss: 0.545138\n",
      "epoch 135; iter: 0; batch classifier loss: 0.308026; batch adversarial loss: 0.498746\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339134; batch adversarial loss: 0.580381\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370547; batch adversarial loss: 0.509853\n",
      "epoch 138; iter: 0; batch classifier loss: 0.436732; batch adversarial loss: 0.574782\n",
      "epoch 139; iter: 0; batch classifier loss: 0.413348; batch adversarial loss: 0.508169\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341693; batch adversarial loss: 0.554353\n",
      "epoch 141; iter: 0; batch classifier loss: 0.388842; batch adversarial loss: 0.526597\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375012; batch adversarial loss: 0.506932\n",
      "epoch 143; iter: 0; batch classifier loss: 0.419325; batch adversarial loss: 0.489136\n",
      "epoch 144; iter: 0; batch classifier loss: 0.355376; batch adversarial loss: 0.516691\n",
      "epoch 145; iter: 0; batch classifier loss: 0.304495; batch adversarial loss: 0.554380\n",
      "epoch 146; iter: 0; batch classifier loss: 0.438540; batch adversarial loss: 0.526988\n",
      "epoch 147; iter: 0; batch classifier loss: 0.430440; batch adversarial loss: 0.601495\n",
      "epoch 148; iter: 0; batch classifier loss: 0.361343; batch adversarial loss: 0.544532\n",
      "epoch 149; iter: 0; batch classifier loss: 0.398011; batch adversarial loss: 0.553665\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339310; batch adversarial loss: 0.525891\n",
      "epoch 151; iter: 0; batch classifier loss: 0.440056; batch adversarial loss: 0.572732\n",
      "epoch 152; iter: 0; batch classifier loss: 0.412534; batch adversarial loss: 0.544807\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376003; batch adversarial loss: 0.573054\n",
      "epoch 154; iter: 0; batch classifier loss: 0.398628; batch adversarial loss: 0.459821\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336932; batch adversarial loss: 0.553703\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361462; batch adversarial loss: 0.470280\n",
      "epoch 157; iter: 0; batch classifier loss: 0.396273; batch adversarial loss: 0.619362\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378584; batch adversarial loss: 0.563337\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322709; batch adversarial loss: 0.588926\n",
      "epoch 160; iter: 0; batch classifier loss: 0.446499; batch adversarial loss: 0.534148\n",
      "epoch 161; iter: 0; batch classifier loss: 0.440804; batch adversarial loss: 0.573672\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358470; batch adversarial loss: 0.536727\n",
      "epoch 163; iter: 0; batch classifier loss: 0.329279; batch adversarial loss: 0.488741\n",
      "epoch 164; iter: 0; batch classifier loss: 0.390220; batch adversarial loss: 0.546269\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379481; batch adversarial loss: 0.506650\n",
      "epoch 166; iter: 0; batch classifier loss: 0.362009; batch adversarial loss: 0.533535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.349005; batch adversarial loss: 0.509082\n",
      "epoch 168; iter: 0; batch classifier loss: 0.337049; batch adversarial loss: 0.488872\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332554; batch adversarial loss: 0.537127\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382546; batch adversarial loss: 0.479465\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335938; batch adversarial loss: 0.580426\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359066; batch adversarial loss: 0.572036\n",
      "epoch 173; iter: 0; batch classifier loss: 0.259822; batch adversarial loss: 0.608683\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368121; batch adversarial loss: 0.581613\n",
      "epoch 175; iter: 0; batch classifier loss: 0.411670; batch adversarial loss: 0.573269\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338862; batch adversarial loss: 0.626513\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344717; batch adversarial loss: 0.497410\n",
      "epoch 178; iter: 0; batch classifier loss: 0.422398; batch adversarial loss: 0.552889\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334153; batch adversarial loss: 0.600836\n",
      "epoch 180; iter: 0; batch classifier loss: 0.401425; batch adversarial loss: 0.497320\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342773; batch adversarial loss: 0.571507\n",
      "epoch 182; iter: 0; batch classifier loss: 0.394740; batch adversarial loss: 0.554268\n",
      "epoch 183; iter: 0; batch classifier loss: 0.304187; batch adversarial loss: 0.516420\n",
      "epoch 184; iter: 0; batch classifier loss: 0.398168; batch adversarial loss: 0.515854\n",
      "epoch 185; iter: 0; batch classifier loss: 0.279870; batch adversarial loss: 0.573237\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382156; batch adversarial loss: 0.564515\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338786; batch adversarial loss: 0.563922\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369830; batch adversarial loss: 0.484058\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368924; batch adversarial loss: 0.583270\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339962; batch adversarial loss: 0.543383\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360856; batch adversarial loss: 0.563135\n",
      "epoch 192; iter: 0; batch classifier loss: 0.312017; batch adversarial loss: 0.478176\n",
      "epoch 193; iter: 0; batch classifier loss: 0.495797; batch adversarial loss: 0.639889\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403252; batch adversarial loss: 0.450730\n",
      "epoch 195; iter: 0; batch classifier loss: 0.329671; batch adversarial loss: 0.572968\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338553; batch adversarial loss: 0.534327\n",
      "epoch 197; iter: 0; batch classifier loss: 0.397647; batch adversarial loss: 0.553148\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384308; batch adversarial loss: 0.619349\n",
      "epoch 199; iter: 0; batch classifier loss: 0.353344; batch adversarial loss: 0.497308\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687694; batch adversarial loss: 0.616292\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618051; batch adversarial loss: 0.657966\n",
      "epoch 2; iter: 0; batch classifier loss: 0.531044; batch adversarial loss: 0.635843\n",
      "epoch 3; iter: 0; batch classifier loss: 0.646004; batch adversarial loss: 0.602582\n",
      "epoch 4; iter: 0; batch classifier loss: 0.505207; batch adversarial loss: 0.643930\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600904; batch adversarial loss: 0.649945\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570757; batch adversarial loss: 0.666119\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550226; batch adversarial loss: 0.559595\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491663; batch adversarial loss: 0.600051\n",
      "epoch 9; iter: 0; batch classifier loss: 0.491961; batch adversarial loss: 0.549945\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531725; batch adversarial loss: 0.587138\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564511; batch adversarial loss: 0.545250\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525328; batch adversarial loss: 0.537175\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533472; batch adversarial loss: 0.589000\n",
      "epoch 14; iter: 0; batch classifier loss: 0.551394; batch adversarial loss: 0.576656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480855; batch adversarial loss: 0.549405\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508115; batch adversarial loss: 0.551110\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500956; batch adversarial loss: 0.522251\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478127; batch adversarial loss: 0.527674\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530705; batch adversarial loss: 0.592531\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493026; batch adversarial loss: 0.530657\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477554; batch adversarial loss: 0.607884\n",
      "epoch 22; iter: 0; batch classifier loss: 0.417187; batch adversarial loss: 0.577185\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470896; batch adversarial loss: 0.606916\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516733; batch adversarial loss: 0.498981\n",
      "epoch 25; iter: 0; batch classifier loss: 0.477805; batch adversarial loss: 0.550011\n",
      "epoch 26; iter: 0; batch classifier loss: 0.436763; batch adversarial loss: 0.629481\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485960; batch adversarial loss: 0.488723\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483882; batch adversarial loss: 0.570717\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505509; batch adversarial loss: 0.553216\n",
      "epoch 30; iter: 0; batch classifier loss: 0.541765; batch adversarial loss: 0.536737\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515591; batch adversarial loss: 0.579628\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420949; batch adversarial loss: 0.545000\n",
      "epoch 33; iter: 0; batch classifier loss: 0.396524; batch adversarial loss: 0.550272\n",
      "epoch 34; iter: 0; batch classifier loss: 0.514965; batch adversarial loss: 0.481248\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420174; batch adversarial loss: 0.569524\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446144; batch adversarial loss: 0.540305\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429620; batch adversarial loss: 0.642598\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452185; batch adversarial loss: 0.519575\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463623; batch adversarial loss: 0.516654\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442080; batch adversarial loss: 0.580983\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466358; batch adversarial loss: 0.528403\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378664; batch adversarial loss: 0.590809\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409314; batch adversarial loss: 0.528220\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375446; batch adversarial loss: 0.561447\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472595; batch adversarial loss: 0.483444\n",
      "epoch 46; iter: 0; batch classifier loss: 0.470691; batch adversarial loss: 0.508217\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483304; batch adversarial loss: 0.596029\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406486; batch adversarial loss: 0.536240\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440053; batch adversarial loss: 0.554249\n",
      "epoch 50; iter: 0; batch classifier loss: 0.380532; batch adversarial loss: 0.537419\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440489; batch adversarial loss: 0.516567\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382601; batch adversarial loss: 0.559395\n",
      "epoch 53; iter: 0; batch classifier loss: 0.387314; batch adversarial loss: 0.497933\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394153; batch adversarial loss: 0.518655\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486844; batch adversarial loss: 0.593148\n",
      "epoch 56; iter: 0; batch classifier loss: 0.374396; batch adversarial loss: 0.517490\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445431; batch adversarial loss: 0.511172\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465352; batch adversarial loss: 0.551852\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371722; batch adversarial loss: 0.557585\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441044; batch adversarial loss: 0.541608\n",
      "epoch 61; iter: 0; batch classifier loss: 0.480411; batch adversarial loss: 0.604624\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378636; batch adversarial loss: 0.492253\n",
      "epoch 63; iter: 0; batch classifier loss: 0.478208; batch adversarial loss: 0.570208\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425819; batch adversarial loss: 0.599873\n",
      "epoch 65; iter: 0; batch classifier loss: 0.463095; batch adversarial loss: 0.561182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.372631; batch adversarial loss: 0.538618\n",
      "epoch 67; iter: 0; batch classifier loss: 0.468268; batch adversarial loss: 0.566354\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432646; batch adversarial loss: 0.593533\n",
      "epoch 69; iter: 0; batch classifier loss: 0.469807; batch adversarial loss: 0.537695\n",
      "epoch 70; iter: 0; batch classifier loss: 0.456426; batch adversarial loss: 0.477659\n",
      "epoch 71; iter: 0; batch classifier loss: 0.468295; batch adversarial loss: 0.556657\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.595122\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369071; batch adversarial loss: 0.628917\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418727; batch adversarial loss: 0.543276\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427548; batch adversarial loss: 0.618101\n",
      "epoch 76; iter: 0; batch classifier loss: 0.481911; batch adversarial loss: 0.530670\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388346; batch adversarial loss: 0.565085\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350560; batch adversarial loss: 0.522590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393256; batch adversarial loss: 0.554106\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402482; batch adversarial loss: 0.639105\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351061; batch adversarial loss: 0.540375\n",
      "epoch 82; iter: 0; batch classifier loss: 0.351771; batch adversarial loss: 0.494063\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403705; batch adversarial loss: 0.474521\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446952; batch adversarial loss: 0.585431\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419478; batch adversarial loss: 0.534039\n",
      "epoch 86; iter: 0; batch classifier loss: 0.364908; batch adversarial loss: 0.484057\n",
      "epoch 87; iter: 0; batch classifier loss: 0.464707; batch adversarial loss: 0.562251\n",
      "epoch 88; iter: 0; batch classifier loss: 0.463064; batch adversarial loss: 0.546669\n",
      "epoch 89; iter: 0; batch classifier loss: 0.423647; batch adversarial loss: 0.598707\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394384; batch adversarial loss: 0.494393\n",
      "epoch 91; iter: 0; batch classifier loss: 0.438232; batch adversarial loss: 0.516695\n",
      "epoch 92; iter: 0; batch classifier loss: 0.575137; batch adversarial loss: 0.543690\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400292; batch adversarial loss: 0.544456\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433318; batch adversarial loss: 0.550357\n",
      "epoch 95; iter: 0; batch classifier loss: 0.350147; batch adversarial loss: 0.582021\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373523; batch adversarial loss: 0.530848\n",
      "epoch 97; iter: 0; batch classifier loss: 0.329936; batch adversarial loss: 0.607711\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375461; batch adversarial loss: 0.497673\n",
      "epoch 99; iter: 0; batch classifier loss: 0.371439; batch adversarial loss: 0.534555\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393519; batch adversarial loss: 0.538092\n",
      "epoch 101; iter: 0; batch classifier loss: 0.419492; batch adversarial loss: 0.604459\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379402; batch adversarial loss: 0.531111\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366166; batch adversarial loss: 0.505655\n",
      "epoch 104; iter: 0; batch classifier loss: 0.315854; batch adversarial loss: 0.530636\n",
      "epoch 105; iter: 0; batch classifier loss: 0.469210; batch adversarial loss: 0.434796\n",
      "epoch 106; iter: 0; batch classifier loss: 0.484390; batch adversarial loss: 0.523101\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346638; batch adversarial loss: 0.567814\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351128; batch adversarial loss: 0.516667\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403064; batch adversarial loss: 0.501441\n",
      "epoch 110; iter: 0; batch classifier loss: 0.342965; batch adversarial loss: 0.544907\n",
      "epoch 111; iter: 0; batch classifier loss: 0.338036; batch adversarial loss: 0.527159\n",
      "epoch 112; iter: 0; batch classifier loss: 0.504347; batch adversarial loss: 0.506277\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419791; batch adversarial loss: 0.599962\n",
      "epoch 114; iter: 0; batch classifier loss: 0.484229; batch adversarial loss: 0.554124\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355628; batch adversarial loss: 0.539606\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389461; batch adversarial loss: 0.516939\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389412; batch adversarial loss: 0.571436\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381593; batch adversarial loss: 0.583346\n",
      "epoch 119; iter: 0; batch classifier loss: 0.332702; batch adversarial loss: 0.638785\n",
      "epoch 120; iter: 0; batch classifier loss: 0.457172; batch adversarial loss: 0.535307\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371897; batch adversarial loss: 0.493588\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402282; batch adversarial loss: 0.527978\n",
      "epoch 123; iter: 0; batch classifier loss: 0.435318; batch adversarial loss: 0.533425\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354787; batch adversarial loss: 0.568155\n",
      "epoch 125; iter: 0; batch classifier loss: 0.428704; batch adversarial loss: 0.553044\n",
      "epoch 126; iter: 0; batch classifier loss: 0.440593; batch adversarial loss: 0.551996\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366044; batch adversarial loss: 0.501326\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404135; batch adversarial loss: 0.548250\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434630; batch adversarial loss: 0.517679\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396037; batch adversarial loss: 0.503547\n",
      "epoch 131; iter: 0; batch classifier loss: 0.397882; batch adversarial loss: 0.505911\n",
      "epoch 132; iter: 0; batch classifier loss: 0.326583; batch adversarial loss: 0.586673\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326182; batch adversarial loss: 0.596918\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399764; batch adversarial loss: 0.563255\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388240; batch adversarial loss: 0.535203\n",
      "epoch 136; iter: 0; batch classifier loss: 0.429808; batch adversarial loss: 0.544807\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374074; batch adversarial loss: 0.497723\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393919; batch adversarial loss: 0.568501\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363077; batch adversarial loss: 0.537317\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348372; batch adversarial loss: 0.491072\n",
      "epoch 141; iter: 0; batch classifier loss: 0.373741; batch adversarial loss: 0.593181\n",
      "epoch 142; iter: 0; batch classifier loss: 0.437135; batch adversarial loss: 0.543881\n",
      "epoch 143; iter: 0; batch classifier loss: 0.423484; batch adversarial loss: 0.583946\n",
      "epoch 144; iter: 0; batch classifier loss: 0.315367; batch adversarial loss: 0.517896\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341201; batch adversarial loss: 0.585775\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385630; batch adversarial loss: 0.468602\n",
      "epoch 147; iter: 0; batch classifier loss: 0.321442; batch adversarial loss: 0.504376\n",
      "epoch 148; iter: 0; batch classifier loss: 0.457958; batch adversarial loss: 0.624233\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370401; batch adversarial loss: 0.584502\n",
      "epoch 150; iter: 0; batch classifier loss: 0.287698; batch adversarial loss: 0.610929\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365570; batch adversarial loss: 0.573304\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349742; batch adversarial loss: 0.566389\n",
      "epoch 153; iter: 0; batch classifier loss: 0.263588; batch adversarial loss: 0.628163\n",
      "epoch 154; iter: 0; batch classifier loss: 0.380968; batch adversarial loss: 0.472406\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419398; batch adversarial loss: 0.577808\n",
      "epoch 156; iter: 0; batch classifier loss: 0.459006; batch adversarial loss: 0.525166\n",
      "epoch 157; iter: 0; batch classifier loss: 0.446379; batch adversarial loss: 0.569938\n",
      "epoch 158; iter: 0; batch classifier loss: 0.474484; batch adversarial loss: 0.528736\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390788; batch adversarial loss: 0.590014\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358473; batch adversarial loss: 0.557880\n",
      "epoch 161; iter: 0; batch classifier loss: 0.371989; batch adversarial loss: 0.422481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.343896; batch adversarial loss: 0.579815\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373582; batch adversarial loss: 0.488376\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368862; batch adversarial loss: 0.566950\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369497; batch adversarial loss: 0.601798\n",
      "epoch 166; iter: 0; batch classifier loss: 0.427832; batch adversarial loss: 0.489018\n",
      "epoch 167; iter: 0; batch classifier loss: 0.361372; batch adversarial loss: 0.552400\n",
      "epoch 168; iter: 0; batch classifier loss: 0.334744; batch adversarial loss: 0.516154\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349302; batch adversarial loss: 0.610116\n",
      "epoch 170; iter: 0; batch classifier loss: 0.504020; batch adversarial loss: 0.582770\n",
      "epoch 171; iter: 0; batch classifier loss: 0.458307; batch adversarial loss: 0.544020\n",
      "epoch 172; iter: 0; batch classifier loss: 0.361126; batch adversarial loss: 0.537269\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404556; batch adversarial loss: 0.494567\n",
      "epoch 174; iter: 0; batch classifier loss: 0.394099; batch adversarial loss: 0.575698\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336880; batch adversarial loss: 0.623848\n",
      "epoch 176; iter: 0; batch classifier loss: 0.407744; batch adversarial loss: 0.639596\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336303; batch adversarial loss: 0.543245\n",
      "epoch 178; iter: 0; batch classifier loss: 0.442358; batch adversarial loss: 0.509012\n",
      "epoch 179; iter: 0; batch classifier loss: 0.381601; batch adversarial loss: 0.542580\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366459; batch adversarial loss: 0.548142\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383040; batch adversarial loss: 0.631514\n",
      "epoch 182; iter: 0; batch classifier loss: 0.460201; batch adversarial loss: 0.520394\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342830; batch adversarial loss: 0.607584\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370523; batch adversarial loss: 0.555746\n",
      "epoch 185; iter: 0; batch classifier loss: 0.317123; batch adversarial loss: 0.495572\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357499; batch adversarial loss: 0.539459\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385790; batch adversarial loss: 0.534616\n",
      "epoch 188; iter: 0; batch classifier loss: 0.380392; batch adversarial loss: 0.554284\n",
      "epoch 189; iter: 0; batch classifier loss: 0.411815; batch adversarial loss: 0.560655\n",
      "epoch 190; iter: 0; batch classifier loss: 0.413918; batch adversarial loss: 0.585462\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355597; batch adversarial loss: 0.525248\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345480; batch adversarial loss: 0.568807\n",
      "epoch 193; iter: 0; batch classifier loss: 0.328565; batch adversarial loss: 0.546068\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344971; batch adversarial loss: 0.578159\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387094; batch adversarial loss: 0.575657\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315847; batch adversarial loss: 0.518665\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386073; batch adversarial loss: 0.522273\n",
      "epoch 198; iter: 0; batch classifier loss: 0.406471; batch adversarial loss: 0.582840\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309972; batch adversarial loss: 0.587581\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721717; batch adversarial loss: 0.587033\n",
      "epoch 1; iter: 0; batch classifier loss: 0.638662; batch adversarial loss: 0.637239\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562656; batch adversarial loss: 0.659815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566816; batch adversarial loss: 0.639545\n",
      "epoch 4; iter: 0; batch classifier loss: 0.475710; batch adversarial loss: 0.651285\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516602; batch adversarial loss: 0.662128\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546370; batch adversarial loss: 0.638738\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555369; batch adversarial loss: 0.629137\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568865; batch adversarial loss: 0.607235\n",
      "epoch 9; iter: 0; batch classifier loss: 0.609435; batch adversarial loss: 0.597745\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539301; batch adversarial loss: 0.606805\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577798; batch adversarial loss: 0.608658\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540037; batch adversarial loss: 0.631995\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564379; batch adversarial loss: 0.522846\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477311; batch adversarial loss: 0.530873\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477573; batch adversarial loss: 0.643532\n",
      "epoch 16; iter: 0; batch classifier loss: 0.566909; batch adversarial loss: 0.533235\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546354; batch adversarial loss: 0.531394\n",
      "epoch 18; iter: 0; batch classifier loss: 0.562855; batch adversarial loss: 0.587340\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461469; batch adversarial loss: 0.510220\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522403; batch adversarial loss: 0.586308\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453550; batch adversarial loss: 0.545327\n",
      "epoch 22; iter: 0; batch classifier loss: 0.411095; batch adversarial loss: 0.539270\n",
      "epoch 23; iter: 0; batch classifier loss: 0.498946; batch adversarial loss: 0.513476\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457230; batch adversarial loss: 0.564399\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494300; batch adversarial loss: 0.565099\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480201; batch adversarial loss: 0.571985\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433766; batch adversarial loss: 0.510546\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459603; batch adversarial loss: 0.537239\n",
      "epoch 29; iter: 0; batch classifier loss: 0.459935; batch adversarial loss: 0.571888\n",
      "epoch 30; iter: 0; batch classifier loss: 0.426185; batch adversarial loss: 0.536888\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464389; batch adversarial loss: 0.536261\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510148; batch adversarial loss: 0.544341\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481909; batch adversarial loss: 0.535932\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453955; batch adversarial loss: 0.598551\n",
      "epoch 35; iter: 0; batch classifier loss: 0.546534; batch adversarial loss: 0.615969\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446562; batch adversarial loss: 0.634299\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381670; batch adversarial loss: 0.553733\n",
      "epoch 38; iter: 0; batch classifier loss: 0.462857; batch adversarial loss: 0.580792\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407645; batch adversarial loss: 0.589550\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441146; batch adversarial loss: 0.553608\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398584; batch adversarial loss: 0.481129\n",
      "epoch 42; iter: 0; batch classifier loss: 0.523524; batch adversarial loss: 0.581434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460318; batch adversarial loss: 0.598939\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438472; batch adversarial loss: 0.598922\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464079; batch adversarial loss: 0.488810\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461165; batch adversarial loss: 0.535170\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436726; batch adversarial loss: 0.442261\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393208; batch adversarial loss: 0.471914\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401004; batch adversarial loss: 0.607488\n",
      "epoch 50; iter: 0; batch classifier loss: 0.348984; batch adversarial loss: 0.499369\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416412; batch adversarial loss: 0.535913\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438602; batch adversarial loss: 0.553692\n",
      "epoch 53; iter: 0; batch classifier loss: 0.473483; batch adversarial loss: 0.535073\n",
      "epoch 54; iter: 0; batch classifier loss: 0.381173; batch adversarial loss: 0.589619\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414005; batch adversarial loss: 0.553888\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436024; batch adversarial loss: 0.599322\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412546; batch adversarial loss: 0.553668\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407237; batch adversarial loss: 0.607576\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421075; batch adversarial loss: 0.544554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.416604; batch adversarial loss: 0.542668\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399503; batch adversarial loss: 0.517982\n",
      "epoch 62; iter: 0; batch classifier loss: 0.412887; batch adversarial loss: 0.507685\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377039; batch adversarial loss: 0.534325\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393199; batch adversarial loss: 0.508878\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379926; batch adversarial loss: 0.560760\n",
      "epoch 66; iter: 0; batch classifier loss: 0.356925; batch adversarial loss: 0.544438\n",
      "epoch 67; iter: 0; batch classifier loss: 0.490361; batch adversarial loss: 0.516315\n",
      "epoch 68; iter: 0; batch classifier loss: 0.398384; batch adversarial loss: 0.542753\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428820; batch adversarial loss: 0.457162\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414532; batch adversarial loss: 0.546685\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416532; batch adversarial loss: 0.445790\n",
      "epoch 72; iter: 0; batch classifier loss: 0.484858; batch adversarial loss: 0.482052\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383827; batch adversarial loss: 0.508650\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396552; batch adversarial loss: 0.525297\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399048; batch adversarial loss: 0.546528\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369968; batch adversarial loss: 0.581563\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421252; batch adversarial loss: 0.580949\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416538; batch adversarial loss: 0.517777\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389769; batch adversarial loss: 0.517644\n",
      "epoch 80; iter: 0; batch classifier loss: 0.424775; batch adversarial loss: 0.516589\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394702; batch adversarial loss: 0.609969\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390047; batch adversarial loss: 0.515486\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368520; batch adversarial loss: 0.598890\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416610; batch adversarial loss: 0.544850\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401742; batch adversarial loss: 0.551931\n",
      "epoch 86; iter: 0; batch classifier loss: 0.444603; batch adversarial loss: 0.589552\n",
      "epoch 87; iter: 0; batch classifier loss: 0.329930; batch adversarial loss: 0.489684\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386303; batch adversarial loss: 0.562028\n",
      "epoch 89; iter: 0; batch classifier loss: 0.330826; batch adversarial loss: 0.536896\n",
      "epoch 90; iter: 0; batch classifier loss: 0.358307; batch adversarial loss: 0.581351\n",
      "epoch 91; iter: 0; batch classifier loss: 0.313811; batch adversarial loss: 0.573074\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414190; batch adversarial loss: 0.599645\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356167; batch adversarial loss: 0.534543\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358514; batch adversarial loss: 0.533938\n",
      "epoch 95; iter: 0; batch classifier loss: 0.350558; batch adversarial loss: 0.517932\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408180; batch adversarial loss: 0.507681\n",
      "epoch 97; iter: 0; batch classifier loss: 0.443080; batch adversarial loss: 0.634916\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400411; batch adversarial loss: 0.580661\n",
      "epoch 99; iter: 0; batch classifier loss: 0.437233; batch adversarial loss: 0.572358\n",
      "epoch 100; iter: 0; batch classifier loss: 0.359650; batch adversarial loss: 0.570616\n",
      "epoch 101; iter: 0; batch classifier loss: 0.439631; batch adversarial loss: 0.508584\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357643; batch adversarial loss: 0.553877\n",
      "epoch 103; iter: 0; batch classifier loss: 0.293565; batch adversarial loss: 0.507892\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373339; batch adversarial loss: 0.589371\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424256; batch adversarial loss: 0.497963\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409967; batch adversarial loss: 0.480439\n",
      "epoch 107; iter: 0; batch classifier loss: 0.408992; batch adversarial loss: 0.534786\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385973; batch adversarial loss: 0.553649\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344297; batch adversarial loss: 0.550497\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359769; batch adversarial loss: 0.569189\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359047; batch adversarial loss: 0.535806\n",
      "epoch 112; iter: 0; batch classifier loss: 0.440599; batch adversarial loss: 0.608271\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417111; batch adversarial loss: 0.573462\n",
      "epoch 114; iter: 0; batch classifier loss: 0.425217; batch adversarial loss: 0.560398\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387104; batch adversarial loss: 0.593695\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369628; batch adversarial loss: 0.582410\n",
      "epoch 117; iter: 0; batch classifier loss: 0.305567; batch adversarial loss: 0.553724\n",
      "epoch 118; iter: 0; batch classifier loss: 0.348481; batch adversarial loss: 0.563993\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354808; batch adversarial loss: 0.589504\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338595; batch adversarial loss: 0.461906\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344387; batch adversarial loss: 0.469720\n",
      "epoch 122; iter: 0; batch classifier loss: 0.433973; batch adversarial loss: 0.544341\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350119; batch adversarial loss: 0.546601\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374653; batch adversarial loss: 0.562214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349842; batch adversarial loss: 0.607832\n",
      "epoch 126; iter: 0; batch classifier loss: 0.302826; batch adversarial loss: 0.489272\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377958; batch adversarial loss: 0.553528\n",
      "epoch 128; iter: 0; batch classifier loss: 0.388685; batch adversarial loss: 0.489495\n",
      "epoch 129; iter: 0; batch classifier loss: 0.415830; batch adversarial loss: 0.526069\n",
      "epoch 130; iter: 0; batch classifier loss: 0.378444; batch adversarial loss: 0.534907\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372772; batch adversarial loss: 0.580202\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330807; batch adversarial loss: 0.562095\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374021; batch adversarial loss: 0.554810\n",
      "epoch 134; iter: 0; batch classifier loss: 0.432346; batch adversarial loss: 0.543775\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337145; batch adversarial loss: 0.500018\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357281; batch adversarial loss: 0.589003\n",
      "epoch 137; iter: 0; batch classifier loss: 0.309880; batch adversarial loss: 0.500408\n",
      "epoch 138; iter: 0; batch classifier loss: 0.351383; batch adversarial loss: 0.481257\n",
      "epoch 139; iter: 0; batch classifier loss: 0.430756; batch adversarial loss: 0.509187\n",
      "epoch 140; iter: 0; batch classifier loss: 0.433504; batch adversarial loss: 0.563087\n",
      "epoch 141; iter: 0; batch classifier loss: 0.469142; batch adversarial loss: 0.562943\n",
      "epoch 142; iter: 0; batch classifier loss: 0.311077; batch adversarial loss: 0.589395\n",
      "epoch 143; iter: 0; batch classifier loss: 0.325671; batch adversarial loss: 0.488523\n",
      "epoch 144; iter: 0; batch classifier loss: 0.278875; batch adversarial loss: 0.545146\n",
      "epoch 145; iter: 0; batch classifier loss: 0.311041; batch adversarial loss: 0.552547\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388504; batch adversarial loss: 0.580359\n",
      "epoch 147; iter: 0; batch classifier loss: 0.321876; batch adversarial loss: 0.581831\n",
      "epoch 148; iter: 0; batch classifier loss: 0.418317; batch adversarial loss: 0.598053\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382069; batch adversarial loss: 0.536790\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370264; batch adversarial loss: 0.625886\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367014; batch adversarial loss: 0.536470\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346785; batch adversarial loss: 0.562305\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334927; batch adversarial loss: 0.508084\n",
      "epoch 154; iter: 0; batch classifier loss: 0.310014; batch adversarial loss: 0.525805\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360082; batch adversarial loss: 0.508885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.349929; batch adversarial loss: 0.526717\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349195; batch adversarial loss: 0.562514\n",
      "epoch 158; iter: 0; batch classifier loss: 0.399847; batch adversarial loss: 0.588586\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337890; batch adversarial loss: 0.599141\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308899; batch adversarial loss: 0.499176\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347287; batch adversarial loss: 0.507347\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361621; batch adversarial loss: 0.581881\n",
      "epoch 163; iter: 0; batch classifier loss: 0.423755; batch adversarial loss: 0.536340\n",
      "epoch 164; iter: 0; batch classifier loss: 0.396673; batch adversarial loss: 0.479896\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355922; batch adversarial loss: 0.606619\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330902; batch adversarial loss: 0.525440\n",
      "epoch 167; iter: 0; batch classifier loss: 0.284133; batch adversarial loss: 0.489002\n",
      "epoch 168; iter: 0; batch classifier loss: 0.425753; batch adversarial loss: 0.673837\n",
      "epoch 169; iter: 0; batch classifier loss: 0.377186; batch adversarial loss: 0.581097\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355734; batch adversarial loss: 0.535517\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389736; batch adversarial loss: 0.626854\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318113; batch adversarial loss: 0.504846\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349716; batch adversarial loss: 0.526685\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370589; batch adversarial loss: 0.534818\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332122; batch adversarial loss: 0.532946\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378651; batch adversarial loss: 0.598107\n",
      "epoch 177; iter: 0; batch classifier loss: 0.301574; batch adversarial loss: 0.580039\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367994; batch adversarial loss: 0.545222\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318963; batch adversarial loss: 0.600272\n",
      "epoch 180; iter: 0; batch classifier loss: 0.310097; batch adversarial loss: 0.552367\n",
      "epoch 181; iter: 0; batch classifier loss: 0.274668; batch adversarial loss: 0.561544\n",
      "epoch 182; iter: 0; batch classifier loss: 0.315919; batch adversarial loss: 0.499065\n",
      "epoch 183; iter: 0; batch classifier loss: 0.392897; batch adversarial loss: 0.599379\n",
      "epoch 184; iter: 0; batch classifier loss: 0.523958; batch adversarial loss: 0.553438\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328343; batch adversarial loss: 0.662818\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340006; batch adversarial loss: 0.580180\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371879; batch adversarial loss: 0.526472\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368654; batch adversarial loss: 0.525547\n",
      "epoch 189; iter: 0; batch classifier loss: 0.392644; batch adversarial loss: 0.506585\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352224; batch adversarial loss: 0.551917\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330756; batch adversarial loss: 0.569125\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327681; batch adversarial loss: 0.527578\n",
      "epoch 193; iter: 0; batch classifier loss: 0.358934; batch adversarial loss: 0.491065\n",
      "epoch 194; iter: 0; batch classifier loss: 0.331073; batch adversarial loss: 0.564138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319849; batch adversarial loss: 0.508711\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358860; batch adversarial loss: 0.552469\n",
      "epoch 197; iter: 0; batch classifier loss: 0.415973; batch adversarial loss: 0.545317\n",
      "epoch 198; iter: 0; batch classifier loss: 0.280436; batch adversarial loss: 0.561761\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337289; batch adversarial loss: 0.545652\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727783; batch adversarial loss: 0.849668\n",
      "epoch 1; iter: 0; batch classifier loss: 0.671380; batch adversarial loss: 0.826413\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599189; batch adversarial loss: 0.800793\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618388; batch adversarial loss: 0.681858\n",
      "epoch 4; iter: 0; batch classifier loss: 0.505227; batch adversarial loss: 0.680395\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551587; batch adversarial loss: 0.683886\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534445; batch adversarial loss: 0.669971\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558178; batch adversarial loss: 0.651571\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525004; batch adversarial loss: 0.614234\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537490; batch adversarial loss: 0.638533\n",
      "epoch 10; iter: 0; batch classifier loss: 0.534993; batch adversarial loss: 0.581742\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529075; batch adversarial loss: 0.575856\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506770; batch adversarial loss: 0.559138\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486300; batch adversarial loss: 0.578869\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533651; batch adversarial loss: 0.565909\n",
      "epoch 15; iter: 0; batch classifier loss: 0.441797; batch adversarial loss: 0.566839\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518317; batch adversarial loss: 0.486136\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504346; batch adversarial loss: 0.539414\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520760; batch adversarial loss: 0.495970\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511825; batch adversarial loss: 0.587187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473677; batch adversarial loss: 0.554717\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474069; batch adversarial loss: 0.567495\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514490; batch adversarial loss: 0.590389\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511614; batch adversarial loss: 0.553270\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489993; batch adversarial loss: 0.569985\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513368; batch adversarial loss: 0.515897\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489714; batch adversarial loss: 0.608211\n",
      "epoch 27; iter: 0; batch classifier loss: 0.496546; batch adversarial loss: 0.638886\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496888; batch adversarial loss: 0.505826\n",
      "epoch 29; iter: 0; batch classifier loss: 0.540329; batch adversarial loss: 0.542749\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424618; batch adversarial loss: 0.500448\n",
      "epoch 31; iter: 0; batch classifier loss: 0.524489; batch adversarial loss: 0.458143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432112; batch adversarial loss: 0.535424\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445737; batch adversarial loss: 0.622020\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445914; batch adversarial loss: 0.562638\n",
      "epoch 35; iter: 0; batch classifier loss: 0.413646; batch adversarial loss: 0.574262\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418654; batch adversarial loss: 0.617086\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499052; batch adversarial loss: 0.526833\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429904; batch adversarial loss: 0.561210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466236; batch adversarial loss: 0.476362\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407392; batch adversarial loss: 0.591183\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481888; batch adversarial loss: 0.534767\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472916; batch adversarial loss: 0.562259\n",
      "epoch 43; iter: 0; batch classifier loss: 0.373414; batch adversarial loss: 0.562055\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431035; batch adversarial loss: 0.572742\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413166; batch adversarial loss: 0.599438\n",
      "epoch 46; iter: 0; batch classifier loss: 0.499014; batch adversarial loss: 0.589608\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438123; batch adversarial loss: 0.554486\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448923; batch adversarial loss: 0.472356\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452895; batch adversarial loss: 0.563586\n",
      "epoch 50; iter: 0; batch classifier loss: 0.491288; batch adversarial loss: 0.517392\n",
      "epoch 51; iter: 0; batch classifier loss: 0.489376; batch adversarial loss: 0.525784\n",
      "epoch 52; iter: 0; batch classifier loss: 0.478393; batch adversarial loss: 0.507275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.481129; batch adversarial loss: 0.581155\n",
      "epoch 54; iter: 0; batch classifier loss: 0.491928; batch adversarial loss: 0.525906\n",
      "epoch 55; iter: 0; batch classifier loss: 0.488696; batch adversarial loss: 0.581182\n",
      "epoch 56; iter: 0; batch classifier loss: 0.488273; batch adversarial loss: 0.581181\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395509; batch adversarial loss: 0.600186\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452321; batch adversarial loss: 0.525990\n",
      "epoch 59; iter: 0; batch classifier loss: 0.347993; batch adversarial loss: 0.627007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.509380; batch adversarial loss: 0.645996\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413433; batch adversarial loss: 0.526245\n",
      "epoch 62; iter: 0; batch classifier loss: 0.481378; batch adversarial loss: 0.526509\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419737; batch adversarial loss: 0.581292\n",
      "epoch 64; iter: 0; batch classifier loss: 0.433956; batch adversarial loss: 0.561672\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442059; batch adversarial loss: 0.582021\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460587; batch adversarial loss: 0.600392\n",
      "epoch 67; iter: 0; batch classifier loss: 0.371732; batch adversarial loss: 0.619680\n",
      "epoch 68; iter: 0; batch classifier loss: 0.368582; batch adversarial loss: 0.516507\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447632; batch adversarial loss: 0.497733\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399103; batch adversarial loss: 0.666582\n",
      "epoch 71; iter: 0; batch classifier loss: 0.444075; batch adversarial loss: 0.525886\n",
      "epoch 72; iter: 0; batch classifier loss: 0.451997; batch adversarial loss: 0.516242\n",
      "epoch 73; iter: 0; batch classifier loss: 0.452302; batch adversarial loss: 0.563555\n",
      "epoch 74; iter: 0; batch classifier loss: 0.402865; batch adversarial loss: 0.498006\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360573; batch adversarial loss: 0.479648\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397164; batch adversarial loss: 0.535121\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393806; batch adversarial loss: 0.441508\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393319; batch adversarial loss: 0.646980\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430943; batch adversarial loss: 0.581780\n",
      "epoch 80; iter: 0; batch classifier loss: 0.410165; batch adversarial loss: 0.497987\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399245; batch adversarial loss: 0.497911\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411416; batch adversarial loss: 0.665467\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394704; batch adversarial loss: 0.553628\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421484; batch adversarial loss: 0.489292\n",
      "epoch 85; iter: 0; batch classifier loss: 0.503931; batch adversarial loss: 0.609709\n",
      "epoch 86; iter: 0; batch classifier loss: 0.496233; batch adversarial loss: 0.479495\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420683; batch adversarial loss: 0.479521\n",
      "epoch 88; iter: 0; batch classifier loss: 0.448232; batch adversarial loss: 0.516836\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378454; batch adversarial loss: 0.517379\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444731; batch adversarial loss: 0.544544\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393119; batch adversarial loss: 0.553719\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421911; batch adversarial loss: 0.507552\n",
      "epoch 93; iter: 0; batch classifier loss: 0.406753; batch adversarial loss: 0.591010\n",
      "epoch 94; iter: 0; batch classifier loss: 0.399801; batch adversarial loss: 0.479443\n",
      "epoch 95; iter: 0; batch classifier loss: 0.341533; batch adversarial loss: 0.581852\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420888; batch adversarial loss: 0.544154\n",
      "epoch 97; iter: 0; batch classifier loss: 0.448871; batch adversarial loss: 0.479347\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388009; batch adversarial loss: 0.535274\n",
      "epoch 99; iter: 0; batch classifier loss: 0.374128; batch adversarial loss: 0.544705\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348404; batch adversarial loss: 0.432810\n",
      "epoch 101; iter: 0; batch classifier loss: 0.445778; batch adversarial loss: 0.572202\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367214; batch adversarial loss: 0.563133\n",
      "epoch 103; iter: 0; batch classifier loss: 0.335624; batch adversarial loss: 0.628352\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348944; batch adversarial loss: 0.562488\n",
      "epoch 105; iter: 0; batch classifier loss: 0.376468; batch adversarial loss: 0.562474\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394288; batch adversarial loss: 0.627882\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377479; batch adversarial loss: 0.591055\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380000; batch adversarial loss: 0.553600\n",
      "epoch 109; iter: 0; batch classifier loss: 0.405325; batch adversarial loss: 0.497687\n",
      "epoch 110; iter: 0; batch classifier loss: 0.467289; batch adversarial loss: 0.544521\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382869; batch adversarial loss: 0.470550\n",
      "epoch 112; iter: 0; batch classifier loss: 0.420429; batch adversarial loss: 0.526235\n",
      "epoch 113; iter: 0; batch classifier loss: 0.397267; batch adversarial loss: 0.507235\n",
      "epoch 114; iter: 0; batch classifier loss: 0.454662; batch adversarial loss: 0.516100\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350803; batch adversarial loss: 0.498102\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376475; batch adversarial loss: 0.563242\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368797; batch adversarial loss: 0.636841\n",
      "epoch 118; iter: 0; batch classifier loss: 0.418564; batch adversarial loss: 0.479869\n",
      "epoch 119; iter: 0; batch classifier loss: 0.400520; batch adversarial loss: 0.526113\n",
      "epoch 120; iter: 0; batch classifier loss: 0.334892; batch adversarial loss: 0.525780\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419519; batch adversarial loss: 0.507387\n",
      "epoch 122; iter: 0; batch classifier loss: 0.414815; batch adversarial loss: 0.581904\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390966; batch adversarial loss: 0.488780\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405067; batch adversarial loss: 0.479435\n",
      "epoch 125; iter: 0; batch classifier loss: 0.363992; batch adversarial loss: 0.562713\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400308; batch adversarial loss: 0.488155\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391627; batch adversarial loss: 0.581347\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418240; batch adversarial loss: 0.544478\n",
      "epoch 129; iter: 0; batch classifier loss: 0.313378; batch adversarial loss: 0.534445\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383452; batch adversarial loss: 0.470556\n",
      "epoch 131; iter: 0; batch classifier loss: 0.430536; batch adversarial loss: 0.507480\n",
      "epoch 132; iter: 0; batch classifier loss: 0.444933; batch adversarial loss: 0.544410\n",
      "epoch 133; iter: 0; batch classifier loss: 0.445260; batch adversarial loss: 0.563650\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344659; batch adversarial loss: 0.525696\n",
      "epoch 135; iter: 0; batch classifier loss: 0.491924; batch adversarial loss: 0.535009\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416828; batch adversarial loss: 0.525500\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371878; batch adversarial loss: 0.618607\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366807; batch adversarial loss: 0.580877\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388094; batch adversarial loss: 0.581207\n",
      "epoch 140; iter: 0; batch classifier loss: 0.427289; batch adversarial loss: 0.544052\n",
      "epoch 141; iter: 0; batch classifier loss: 0.408024; batch adversarial loss: 0.563139\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341752; batch adversarial loss: 0.589480\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374078; batch adversarial loss: 0.591601\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357319; batch adversarial loss: 0.451745\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390975; batch adversarial loss: 0.543706\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388410; batch adversarial loss: 0.589194\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322158; batch adversarial loss: 0.517165\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395379; batch adversarial loss: 0.468307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.389717; batch adversarial loss: 0.533541\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351820; batch adversarial loss: 0.545673\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376116; batch adversarial loss: 0.481617\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351765; batch adversarial loss: 0.535299\n",
      "epoch 153; iter: 0; batch classifier loss: 0.306174; batch adversarial loss: 0.555875\n",
      "epoch 154; iter: 0; batch classifier loss: 0.413721; batch adversarial loss: 0.536714\n",
      "epoch 155; iter: 0; batch classifier loss: 0.386988; batch adversarial loss: 0.544393\n",
      "epoch 156; iter: 0; batch classifier loss: 0.423481; batch adversarial loss: 0.497586\n",
      "epoch 157; iter: 0; batch classifier loss: 0.460846; batch adversarial loss: 0.608764\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397046; batch adversarial loss: 0.496147\n",
      "epoch 159; iter: 0; batch classifier loss: 0.321073; batch adversarial loss: 0.506504\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406743; batch adversarial loss: 0.619732\n",
      "epoch 161; iter: 0; batch classifier loss: 0.381768; batch adversarial loss: 0.556045\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360340; batch adversarial loss: 0.480122\n",
      "epoch 163; iter: 0; batch classifier loss: 0.428399; batch adversarial loss: 0.563134\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353773; batch adversarial loss: 0.496823\n",
      "epoch 165; iter: 0; batch classifier loss: 0.338522; batch adversarial loss: 0.599252\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359013; batch adversarial loss: 0.600901\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347459; batch adversarial loss: 0.471766\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353352; batch adversarial loss: 0.526337\n",
      "epoch 169; iter: 0; batch classifier loss: 0.277213; batch adversarial loss: 0.525867\n",
      "epoch 170; iter: 0; batch classifier loss: 0.343195; batch adversarial loss: 0.479141\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349400; batch adversarial loss: 0.505548\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384564; batch adversarial loss: 0.460392\n",
      "epoch 173; iter: 0; batch classifier loss: 0.308931; batch adversarial loss: 0.610524\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372649; batch adversarial loss: 0.516404\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382730; batch adversarial loss: 0.516515\n",
      "epoch 176; iter: 0; batch classifier loss: 0.431172; batch adversarial loss: 0.525554\n",
      "epoch 177; iter: 0; batch classifier loss: 0.488380; batch adversarial loss: 0.629168\n",
      "epoch 178; iter: 0; batch classifier loss: 0.303969; batch adversarial loss: 0.535090\n",
      "epoch 179; iter: 0; batch classifier loss: 0.360419; batch adversarial loss: 0.534616\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343075; batch adversarial loss: 0.460471\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350902; batch adversarial loss: 0.526476\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380889; batch adversarial loss: 0.572441\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387706; batch adversarial loss: 0.498350\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352460; batch adversarial loss: 0.553999\n",
      "epoch 185; iter: 0; batch classifier loss: 0.394139; batch adversarial loss: 0.628186\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357148; batch adversarial loss: 0.571320\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393246; batch adversarial loss: 0.526090\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381836; batch adversarial loss: 0.524653\n",
      "epoch 189; iter: 0; batch classifier loss: 0.284211; batch adversarial loss: 0.553813\n",
      "epoch 190; iter: 0; batch classifier loss: 0.474342; batch adversarial loss: 0.515674\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390466; batch adversarial loss: 0.562456\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327861; batch adversarial loss: 0.544503\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349913; batch adversarial loss: 0.526085\n",
      "epoch 194; iter: 0; batch classifier loss: 0.401790; batch adversarial loss: 0.582103\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375317; batch adversarial loss: 0.469734\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338080; batch adversarial loss: 0.590262\n",
      "epoch 197; iter: 0; batch classifier loss: 0.393179; batch adversarial loss: 0.609077\n",
      "epoch 198; iter: 0; batch classifier loss: 0.318139; batch adversarial loss: 0.535799\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386006; batch adversarial loss: 0.433188\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707339; batch adversarial loss: 0.691135\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577391; batch adversarial loss: 0.663235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581403; batch adversarial loss: 0.640000\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578191; batch adversarial loss: 0.606778\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634273; batch adversarial loss: 0.594373\n",
      "epoch 5; iter: 0; batch classifier loss: 0.460122; batch adversarial loss: 0.627144\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586946; batch adversarial loss: 0.590901\n",
      "epoch 7; iter: 0; batch classifier loss: 0.521338; batch adversarial loss: 0.584399\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451284; batch adversarial loss: 0.572287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557246; batch adversarial loss: 0.596417\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541413; batch adversarial loss: 0.542119\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508075; batch adversarial loss: 0.548401\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526450; batch adversarial loss: 0.607311\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496378; batch adversarial loss: 0.541396\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501952; batch adversarial loss: 0.511430\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575526; batch adversarial loss: 0.548542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.567025; batch adversarial loss: 0.568576\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499331; batch adversarial loss: 0.549143\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499789; batch adversarial loss: 0.570183\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498900; batch adversarial loss: 0.598978\n",
      "epoch 20; iter: 0; batch classifier loss: 0.570402; batch adversarial loss: 0.562513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473847; batch adversarial loss: 0.502653\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525614; batch adversarial loss: 0.510069\n",
      "epoch 23; iter: 0; batch classifier loss: 0.557393; batch adversarial loss: 0.584357\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463413; batch adversarial loss: 0.488656\n",
      "epoch 25; iter: 0; batch classifier loss: 0.459324; batch adversarial loss: 0.539669\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496352; batch adversarial loss: 0.515148\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537972; batch adversarial loss: 0.560222\n",
      "epoch 28; iter: 0; batch classifier loss: 0.467064; batch adversarial loss: 0.526211\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524716; batch adversarial loss: 0.546984\n",
      "epoch 30; iter: 0; batch classifier loss: 0.547339; batch adversarial loss: 0.486757\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471839; batch adversarial loss: 0.524894\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458365; batch adversarial loss: 0.508525\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420611; batch adversarial loss: 0.573495\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482430; batch adversarial loss: 0.554999\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452596; batch adversarial loss: 0.545215\n",
      "epoch 36; iter: 0; batch classifier loss: 0.509612; batch adversarial loss: 0.537998\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441371; batch adversarial loss: 0.554267\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448775; batch adversarial loss: 0.648573\n",
      "epoch 39; iter: 0; batch classifier loss: 0.531312; batch adversarial loss: 0.589313\n",
      "epoch 40; iter: 0; batch classifier loss: 0.549317; batch adversarial loss: 0.498470\n",
      "epoch 41; iter: 0; batch classifier loss: 0.500363; batch adversarial loss: 0.550578\n",
      "epoch 42; iter: 0; batch classifier loss: 0.525319; batch adversarial loss: 0.510369\n",
      "epoch 43; iter: 0; batch classifier loss: 0.512925; batch adversarial loss: 0.468114\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414990; batch adversarial loss: 0.481388\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450632; batch adversarial loss: 0.561282\n",
      "epoch 46; iter: 0; batch classifier loss: 0.379920; batch adversarial loss: 0.558905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.416231; batch adversarial loss: 0.571311\n",
      "epoch 48; iter: 0; batch classifier loss: 0.477122; batch adversarial loss: 0.550511\n",
      "epoch 49; iter: 0; batch classifier loss: 0.497414; batch adversarial loss: 0.525246\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410651; batch adversarial loss: 0.510016\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424979; batch adversarial loss: 0.512569\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392056; batch adversarial loss: 0.442858\n",
      "epoch 53; iter: 0; batch classifier loss: 0.435498; batch adversarial loss: 0.560673\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433176; batch adversarial loss: 0.504301\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439539; batch adversarial loss: 0.543438\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437541; batch adversarial loss: 0.647469\n",
      "epoch 57; iter: 0; batch classifier loss: 0.449941; batch adversarial loss: 0.534449\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450489; batch adversarial loss: 0.638091\n",
      "epoch 59; iter: 0; batch classifier loss: 0.506607; batch adversarial loss: 0.517359\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423475; batch adversarial loss: 0.539871\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409378; batch adversarial loss: 0.589690\n",
      "epoch 62; iter: 0; batch classifier loss: 0.465138; batch adversarial loss: 0.598323\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415705; batch adversarial loss: 0.545614\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419340; batch adversarial loss: 0.447192\n",
      "epoch 65; iter: 0; batch classifier loss: 0.391550; batch adversarial loss: 0.524940\n",
      "epoch 66; iter: 0; batch classifier loss: 0.472038; batch adversarial loss: 0.513577\n",
      "epoch 67; iter: 0; batch classifier loss: 0.491509; batch adversarial loss: 0.584448\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403820; batch adversarial loss: 0.543522\n",
      "epoch 69; iter: 0; batch classifier loss: 0.364621; batch adversarial loss: 0.520234\n",
      "epoch 70; iter: 0; batch classifier loss: 0.452842; batch adversarial loss: 0.551675\n",
      "epoch 71; iter: 0; batch classifier loss: 0.465042; batch adversarial loss: 0.514397\n",
      "epoch 72; iter: 0; batch classifier loss: 0.493860; batch adversarial loss: 0.570511\n",
      "epoch 73; iter: 0; batch classifier loss: 0.488387; batch adversarial loss: 0.424123\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444325; batch adversarial loss: 0.525756\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448138; batch adversarial loss: 0.558891\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376307; batch adversarial loss: 0.471219\n",
      "epoch 77; iter: 0; batch classifier loss: 0.364901; batch adversarial loss: 0.489412\n",
      "epoch 78; iter: 0; batch classifier loss: 0.460967; batch adversarial loss: 0.545021\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413407; batch adversarial loss: 0.533392\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370964; batch adversarial loss: 0.553621\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360788; batch adversarial loss: 0.514443\n",
      "epoch 82; iter: 0; batch classifier loss: 0.438005; batch adversarial loss: 0.552486\n",
      "epoch 83; iter: 0; batch classifier loss: 0.446959; batch adversarial loss: 0.609252\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389743; batch adversarial loss: 0.534302\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389355; batch adversarial loss: 0.563225\n",
      "epoch 86; iter: 0; batch classifier loss: 0.437948; batch adversarial loss: 0.552355\n",
      "epoch 87; iter: 0; batch classifier loss: 0.451099; batch adversarial loss: 0.536691\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413695; batch adversarial loss: 0.498533\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395703; batch adversarial loss: 0.532116\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412753; batch adversarial loss: 0.505189\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367309; batch adversarial loss: 0.549829\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383441; batch adversarial loss: 0.516237\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394159; batch adversarial loss: 0.532350\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372794; batch adversarial loss: 0.582705\n",
      "epoch 95; iter: 0; batch classifier loss: 0.339058; batch adversarial loss: 0.532900\n",
      "epoch 96; iter: 0; batch classifier loss: 0.333713; batch adversarial loss: 0.618808\n",
      "epoch 97; iter: 0; batch classifier loss: 0.335180; batch adversarial loss: 0.516636\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368607; batch adversarial loss: 0.573584\n",
      "epoch 99; iter: 0; batch classifier loss: 0.467330; batch adversarial loss: 0.582140\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393250; batch adversarial loss: 0.497997\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376481; batch adversarial loss: 0.634847\n",
      "epoch 102; iter: 0; batch classifier loss: 0.421675; batch adversarial loss: 0.526922\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426951; batch adversarial loss: 0.532401\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364864; batch adversarial loss: 0.522243\n",
      "epoch 105; iter: 0; batch classifier loss: 0.434747; batch adversarial loss: 0.564857\n",
      "epoch 106; iter: 0; batch classifier loss: 0.410365; batch adversarial loss: 0.525431\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402071; batch adversarial loss: 0.590506\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400054; batch adversarial loss: 0.590601\n",
      "epoch 109; iter: 0; batch classifier loss: 0.404481; batch adversarial loss: 0.534640\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356313; batch adversarial loss: 0.560565\n",
      "epoch 111; iter: 0; batch classifier loss: 0.371569; batch adversarial loss: 0.438630\n",
      "epoch 112; iter: 0; batch classifier loss: 0.406052; batch adversarial loss: 0.517852\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371115; batch adversarial loss: 0.505370\n",
      "epoch 114; iter: 0; batch classifier loss: 0.440905; batch adversarial loss: 0.518843\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345685; batch adversarial loss: 0.558353\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389619; batch adversarial loss: 0.489432\n",
      "epoch 117; iter: 0; batch classifier loss: 0.473938; batch adversarial loss: 0.511420\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404224; batch adversarial loss: 0.535941\n",
      "epoch 119; iter: 0; batch classifier loss: 0.316707; batch adversarial loss: 0.535973\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344812; batch adversarial loss: 0.608609\n",
      "epoch 121; iter: 0; batch classifier loss: 0.352688; batch adversarial loss: 0.544877\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409254; batch adversarial loss: 0.692608\n",
      "epoch 123; iter: 0; batch classifier loss: 0.473314; batch adversarial loss: 0.582526\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342820; batch adversarial loss: 0.686755\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382589; batch adversarial loss: 0.517723\n",
      "epoch 126; iter: 0; batch classifier loss: 0.385021; batch adversarial loss: 0.562826\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388573; batch adversarial loss: 0.543963\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365320; batch adversarial loss: 0.576337\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386172; batch adversarial loss: 0.592596\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398568; batch adversarial loss: 0.619483\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388205; batch adversarial loss: 0.562800\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370962; batch adversarial loss: 0.580386\n",
      "epoch 133; iter: 0; batch classifier loss: 0.307823; batch adversarial loss: 0.495251\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338253; batch adversarial loss: 0.511865\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394774; batch adversarial loss: 0.534162\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411548; batch adversarial loss: 0.552096\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372466; batch adversarial loss: 0.514643\n",
      "epoch 138; iter: 0; batch classifier loss: 0.343401; batch adversarial loss: 0.579713\n",
      "epoch 139; iter: 0; batch classifier loss: 0.414751; batch adversarial loss: 0.546566\n",
      "epoch 140; iter: 0; batch classifier loss: 0.392779; batch adversarial loss: 0.595172\n",
      "epoch 141; iter: 0; batch classifier loss: 0.370518; batch adversarial loss: 0.551404\n",
      "epoch 142; iter: 0; batch classifier loss: 0.319451; batch adversarial loss: 0.502376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.460590; batch adversarial loss: 0.498825\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366484; batch adversarial loss: 0.488921\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352654; batch adversarial loss: 0.546646\n",
      "epoch 146; iter: 0; batch classifier loss: 0.370387; batch adversarial loss: 0.528091\n",
      "epoch 147; iter: 0; batch classifier loss: 0.296765; batch adversarial loss: 0.535579\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356475; batch adversarial loss: 0.534638\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343009; batch adversarial loss: 0.506408\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360087; batch adversarial loss: 0.541714\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347939; batch adversarial loss: 0.518479\n",
      "epoch 152; iter: 0; batch classifier loss: 0.421980; batch adversarial loss: 0.516102\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358477; batch adversarial loss: 0.440758\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389498; batch adversarial loss: 0.610235\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327974; batch adversarial loss: 0.556154\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359709; batch adversarial loss: 0.507791\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384158; batch adversarial loss: 0.536953\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395877; batch adversarial loss: 0.468276\n",
      "epoch 159; iter: 0; batch classifier loss: 0.405733; batch adversarial loss: 0.564329\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339080; batch adversarial loss: 0.517324\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374129; batch adversarial loss: 0.554564\n",
      "epoch 162; iter: 0; batch classifier loss: 0.380185; batch adversarial loss: 0.470063\n",
      "epoch 163; iter: 0; batch classifier loss: 0.275214; batch adversarial loss: 0.563180\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380754; batch adversarial loss: 0.573266\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397963; batch adversarial loss: 0.533183\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349251; batch adversarial loss: 0.518695\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321855; batch adversarial loss: 0.497256\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388123; batch adversarial loss: 0.508596\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371239; batch adversarial loss: 0.515476\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342000; batch adversarial loss: 0.612194\n",
      "epoch 171; iter: 0; batch classifier loss: 0.312185; batch adversarial loss: 0.552811\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353867; batch adversarial loss: 0.580558\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346637; batch adversarial loss: 0.592655\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396258; batch adversarial loss: 0.515078\n",
      "epoch 175; iter: 0; batch classifier loss: 0.310727; batch adversarial loss: 0.505771\n",
      "epoch 176; iter: 0; batch classifier loss: 0.448404; batch adversarial loss: 0.529328\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361525; batch adversarial loss: 0.514052\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344735; batch adversarial loss: 0.555975\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351480; batch adversarial loss: 0.554427\n",
      "epoch 180; iter: 0; batch classifier loss: 0.431866; batch adversarial loss: 0.561451\n",
      "epoch 181; iter: 0; batch classifier loss: 0.403152; batch adversarial loss: 0.534401\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357681; batch adversarial loss: 0.611118\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343319; batch adversarial loss: 0.489586\n",
      "epoch 184; iter: 0; batch classifier loss: 0.412093; batch adversarial loss: 0.489530\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331602; batch adversarial loss: 0.477964\n",
      "epoch 186; iter: 0; batch classifier loss: 0.410263; batch adversarial loss: 0.487030\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356592; batch adversarial loss: 0.496971\n",
      "epoch 188; iter: 0; batch classifier loss: 0.265950; batch adversarial loss: 0.514525\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345150; batch adversarial loss: 0.572753\n",
      "epoch 190; iter: 0; batch classifier loss: 0.403878; batch adversarial loss: 0.524793\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354016; batch adversarial loss: 0.551876\n",
      "epoch 192; iter: 0; batch classifier loss: 0.383075; batch adversarial loss: 0.561838\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375739; batch adversarial loss: 0.598746\n",
      "epoch 194; iter: 0; batch classifier loss: 0.352634; batch adversarial loss: 0.552376\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366434; batch adversarial loss: 0.570911\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360111; batch adversarial loss: 0.590463\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364682; batch adversarial loss: 0.615922\n",
      "epoch 198; iter: 0; batch classifier loss: 0.410470; batch adversarial loss: 0.537514\n",
      "epoch 199; iter: 0; batch classifier loss: 0.455216; batch adversarial loss: 0.573165\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691715; batch adversarial loss: 0.661562\n",
      "epoch 1; iter: 0; batch classifier loss: 0.652508; batch adversarial loss: 0.650224\n",
      "epoch 2; iter: 0; batch classifier loss: 0.592146; batch adversarial loss: 0.638009\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573483; batch adversarial loss: 0.613757\n",
      "epoch 4; iter: 0; batch classifier loss: 0.578802; batch adversarial loss: 0.629827\n",
      "epoch 5; iter: 0; batch classifier loss: 0.542432; batch adversarial loss: 0.621226\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571108; batch adversarial loss: 0.608670\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542163; batch adversarial loss: 0.620197\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580788; batch adversarial loss: 0.600974\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509711; batch adversarial loss: 0.568581\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503130; batch adversarial loss: 0.582601\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546686; batch adversarial loss: 0.612771\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492685; batch adversarial loss: 0.615425\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530547; batch adversarial loss: 0.587055\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502424; batch adversarial loss: 0.601871\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508616; batch adversarial loss: 0.543325\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571383; batch adversarial loss: 0.588091\n",
      "epoch 17; iter: 0; batch classifier loss: 0.563819; batch adversarial loss: 0.525648\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525255; batch adversarial loss: 0.589357\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461574; batch adversarial loss: 0.556301\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527934; batch adversarial loss: 0.651650\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544323; batch adversarial loss: 0.621072\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513583; batch adversarial loss: 0.573263\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501858; batch adversarial loss: 0.589618\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454412; batch adversarial loss: 0.559676\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504537; batch adversarial loss: 0.549551\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508821; batch adversarial loss: 0.538313\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494450; batch adversarial loss: 0.541949\n",
      "epoch 28; iter: 0; batch classifier loss: 0.436626; batch adversarial loss: 0.510917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511794; batch adversarial loss: 0.582466\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454246; batch adversarial loss: 0.562606\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433345; batch adversarial loss: 0.563707\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439059; batch adversarial loss: 0.623786\n",
      "epoch 33; iter: 0; batch classifier loss: 0.317507; batch adversarial loss: 0.526346\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471036; batch adversarial loss: 0.440245\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469253; batch adversarial loss: 0.506710\n",
      "epoch 36; iter: 0; batch classifier loss: 0.343468; batch adversarial loss: 0.522150\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418326; batch adversarial loss: 0.556574\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406855; batch adversarial loss: 0.516740\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473925; batch adversarial loss: 0.580150\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464890; batch adversarial loss: 0.499778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.474893; batch adversarial loss: 0.545744\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438293; batch adversarial loss: 0.511344\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439353; batch adversarial loss: 0.526617\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456619; batch adversarial loss: 0.581711\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453995; batch adversarial loss: 0.615458\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383205; batch adversarial loss: 0.483715\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463754; batch adversarial loss: 0.458380\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416689; batch adversarial loss: 0.527739\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383091; batch adversarial loss: 0.535792\n",
      "epoch 50; iter: 0; batch classifier loss: 0.335725; batch adversarial loss: 0.580820\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405044; batch adversarial loss: 0.500043\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419237; batch adversarial loss: 0.544369\n",
      "epoch 53; iter: 0; batch classifier loss: 0.473044; batch adversarial loss: 0.580915\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422442; batch adversarial loss: 0.526516\n",
      "epoch 55; iter: 0; batch classifier loss: 0.427879; batch adversarial loss: 0.589549\n",
      "epoch 56; iter: 0; batch classifier loss: 0.384999; batch adversarial loss: 0.615964\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441190; batch adversarial loss: 0.544940\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471289; batch adversarial loss: 0.597767\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413781; batch adversarial loss: 0.507908\n",
      "epoch 60; iter: 0; batch classifier loss: 0.358087; batch adversarial loss: 0.535412\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396710; batch adversarial loss: 0.616651\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408381; batch adversarial loss: 0.509301\n",
      "epoch 63; iter: 0; batch classifier loss: 0.486158; batch adversarial loss: 0.534665\n",
      "epoch 64; iter: 0; batch classifier loss: 0.433998; batch adversarial loss: 0.607853\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439507; batch adversarial loss: 0.598297\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413631; batch adversarial loss: 0.517291\n",
      "epoch 67; iter: 0; batch classifier loss: 0.357283; batch adversarial loss: 0.489817\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395393; batch adversarial loss: 0.544535\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426380; batch adversarial loss: 0.607655\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398335; batch adversarial loss: 0.553663\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407609; batch adversarial loss: 0.562027\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434031; batch adversarial loss: 0.553505\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392824; batch adversarial loss: 0.526041\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397065; batch adversarial loss: 0.536636\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422874; batch adversarial loss: 0.525365\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418834; batch adversarial loss: 0.571467\n",
      "epoch 77; iter: 0; batch classifier loss: 0.328861; batch adversarial loss: 0.507873\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407575; batch adversarial loss: 0.563291\n",
      "epoch 79; iter: 0; batch classifier loss: 0.457067; batch adversarial loss: 0.499028\n",
      "epoch 80; iter: 0; batch classifier loss: 0.459051; batch adversarial loss: 0.544452\n",
      "epoch 81; iter: 0; batch classifier loss: 0.483470; batch adversarial loss: 0.590387\n",
      "epoch 82; iter: 0; batch classifier loss: 0.510034; batch adversarial loss: 0.525967\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417230; batch adversarial loss: 0.500101\n",
      "epoch 84; iter: 0; batch classifier loss: 0.484071; batch adversarial loss: 0.607930\n",
      "epoch 85; iter: 0; batch classifier loss: 0.313623; batch adversarial loss: 0.536533\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391745; batch adversarial loss: 0.525963\n",
      "epoch 87; iter: 0; batch classifier loss: 0.476691; batch adversarial loss: 0.616408\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383954; batch adversarial loss: 0.571938\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363673; batch adversarial loss: 0.535705\n",
      "epoch 90; iter: 0; batch classifier loss: 0.354167; batch adversarial loss: 0.552670\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400400; batch adversarial loss: 0.616460\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388756; batch adversarial loss: 0.518032\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417103; batch adversarial loss: 0.545246\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433505; batch adversarial loss: 0.590193\n",
      "epoch 95; iter: 0; batch classifier loss: 0.370841; batch adversarial loss: 0.572286\n",
      "epoch 96; iter: 0; batch classifier loss: 0.311566; batch adversarial loss: 0.553300\n",
      "epoch 97; iter: 0; batch classifier loss: 0.353719; batch adversarial loss: 0.581022\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389644; batch adversarial loss: 0.480690\n",
      "epoch 99; iter: 0; batch classifier loss: 0.513668; batch adversarial loss: 0.535292\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390366; batch adversarial loss: 0.590559\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344002; batch adversarial loss: 0.544921\n",
      "epoch 102; iter: 0; batch classifier loss: 0.346127; batch adversarial loss: 0.400999\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438973; batch adversarial loss: 0.553073\n",
      "epoch 104; iter: 0; batch classifier loss: 0.439601; batch adversarial loss: 0.518111\n",
      "epoch 105; iter: 0; batch classifier loss: 0.346523; batch adversarial loss: 0.562464\n",
      "epoch 106; iter: 0; batch classifier loss: 0.445358; batch adversarial loss: 0.563291\n",
      "epoch 107; iter: 0; batch classifier loss: 0.470200; batch adversarial loss: 0.507408\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348828; batch adversarial loss: 0.589689\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364779; batch adversarial loss: 0.534840\n",
      "epoch 110; iter: 0; batch classifier loss: 0.327896; batch adversarial loss: 0.553392\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398542; batch adversarial loss: 0.544311\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368914; batch adversarial loss: 0.527198\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387771; batch adversarial loss: 0.517548\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383759; batch adversarial loss: 0.526308\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336929; batch adversarial loss: 0.509085\n",
      "epoch 116; iter: 0; batch classifier loss: 0.455694; batch adversarial loss: 0.508026\n",
      "epoch 117; iter: 0; batch classifier loss: 0.366037; batch adversarial loss: 0.535658\n",
      "epoch 118; iter: 0; batch classifier loss: 0.294402; batch adversarial loss: 0.544885\n",
      "epoch 119; iter: 0; batch classifier loss: 0.481203; batch adversarial loss: 0.590254\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344630; batch adversarial loss: 0.590093\n",
      "epoch 121; iter: 0; batch classifier loss: 0.377563; batch adversarial loss: 0.489627\n",
      "epoch 122; iter: 0; batch classifier loss: 0.473263; batch adversarial loss: 0.526885\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357905; batch adversarial loss: 0.553631\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382431; batch adversarial loss: 0.579957\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408677; batch adversarial loss: 0.481358\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372070; batch adversarial loss: 0.535894\n",
      "epoch 127; iter: 0; batch classifier loss: 0.409425; batch adversarial loss: 0.490876\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369174; batch adversarial loss: 0.480795\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344553; batch adversarial loss: 0.580576\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348334; batch adversarial loss: 0.579702\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383652; batch adversarial loss: 0.544221\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403962; batch adversarial loss: 0.508473\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376116; batch adversarial loss: 0.535170\n",
      "epoch 134; iter: 0; batch classifier loss: 0.427927; batch adversarial loss: 0.517183\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408356; batch adversarial loss: 0.553551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411560; batch adversarial loss: 0.544632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.397181; batch adversarial loss: 0.598857\n",
      "epoch 138; iter: 0; batch classifier loss: 0.407266; batch adversarial loss: 0.617115\n",
      "epoch 139; iter: 0; batch classifier loss: 0.351804; batch adversarial loss: 0.499370\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341282; batch adversarial loss: 0.562213\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350110; batch adversarial loss: 0.599026\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381808; batch adversarial loss: 0.553706\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352342; batch adversarial loss: 0.499715\n",
      "epoch 144; iter: 0; batch classifier loss: 0.438516; batch adversarial loss: 0.599335\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331718; batch adversarial loss: 0.553694\n",
      "epoch 146; iter: 0; batch classifier loss: 0.323204; batch adversarial loss: 0.589585\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365928; batch adversarial loss: 0.598414\n",
      "epoch 148; iter: 0; batch classifier loss: 0.413787; batch adversarial loss: 0.499826\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319151; batch adversarial loss: 0.607805\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350448; batch adversarial loss: 0.544634\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345328; batch adversarial loss: 0.616611\n",
      "epoch 152; iter: 0; batch classifier loss: 0.436037; batch adversarial loss: 0.525857\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371009; batch adversarial loss: 0.589731\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370091; batch adversarial loss: 0.625988\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360123; batch adversarial loss: 0.571623\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381984; batch adversarial loss: 0.590111\n",
      "epoch 157; iter: 0; batch classifier loss: 0.465131; batch adversarial loss: 0.590149\n",
      "epoch 158; iter: 0; batch classifier loss: 0.387232; batch adversarial loss: 0.471471\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356276; batch adversarial loss: 0.516612\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351719; batch adversarial loss: 0.534805\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370738; batch adversarial loss: 0.581327\n",
      "epoch 162; iter: 0; batch classifier loss: 0.396276; batch adversarial loss: 0.517741\n",
      "epoch 163; iter: 0; batch classifier loss: 0.425104; batch adversarial loss: 0.562383\n",
      "epoch 164; iter: 0; batch classifier loss: 0.374677; batch adversarial loss: 0.481754\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344371; batch adversarial loss: 0.426745\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349042; batch adversarial loss: 0.563700\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341945; batch adversarial loss: 0.571767\n",
      "epoch 168; iter: 0; batch classifier loss: 0.449773; batch adversarial loss: 0.481512\n",
      "epoch 169; iter: 0; batch classifier loss: 0.317718; batch adversarial loss: 0.553315\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361760; batch adversarial loss: 0.499775\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334552; batch adversarial loss: 0.579934\n",
      "epoch 172; iter: 0; batch classifier loss: 0.320746; batch adversarial loss: 0.471922\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359785; batch adversarial loss: 0.616413\n",
      "epoch 174; iter: 0; batch classifier loss: 0.379092; batch adversarial loss: 0.445011\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395859; batch adversarial loss: 0.498427\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393816; batch adversarial loss: 0.490481\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318913; batch adversarial loss: 0.644110\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369208; batch adversarial loss: 0.598738\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358063; batch adversarial loss: 0.572173\n",
      "epoch 180; iter: 0; batch classifier loss: 0.403306; batch adversarial loss: 0.544591\n",
      "epoch 181; iter: 0; batch classifier loss: 0.458343; batch adversarial loss: 0.534801\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399656; batch adversarial loss: 0.589540\n",
      "epoch 183; iter: 0; batch classifier loss: 0.434130; batch adversarial loss: 0.518090\n",
      "epoch 184; iter: 0; batch classifier loss: 0.403664; batch adversarial loss: 0.600316\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355637; batch adversarial loss: 0.616586\n",
      "epoch 186; iter: 0; batch classifier loss: 0.406205; batch adversarial loss: 0.607268\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369040; batch adversarial loss: 0.571734\n",
      "epoch 188; iter: 0; batch classifier loss: 0.307213; batch adversarial loss: 0.562734\n",
      "epoch 189; iter: 0; batch classifier loss: 0.314373; batch adversarial loss: 0.572128\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346282; batch adversarial loss: 0.498789\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390142; batch adversarial loss: 0.553214\n",
      "epoch 192; iter: 0; batch classifier loss: 0.388786; batch adversarial loss: 0.508486\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335840; batch adversarial loss: 0.543789\n",
      "epoch 194; iter: 0; batch classifier loss: 0.428229; batch adversarial loss: 0.588936\n",
      "epoch 195; iter: 0; batch classifier loss: 0.385965; batch adversarial loss: 0.536308\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342368; batch adversarial loss: 0.571771\n",
      "epoch 197; iter: 0; batch classifier loss: 0.415965; batch adversarial loss: 0.481631\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371176; batch adversarial loss: 0.553600\n",
      "epoch 199; iter: 0; batch classifier loss: 0.305761; batch adversarial loss: 0.527448\n",
      "epoch 0; iter: 0; batch classifier loss: 0.597633; batch adversarial loss: 0.566797\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605776; batch adversarial loss: 0.698287\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600857; batch adversarial loss: 0.694108\n",
      "epoch 3; iter: 0; batch classifier loss: 0.584053; batch adversarial loss: 0.748282\n",
      "epoch 4; iter: 0; batch classifier loss: 0.625717; batch adversarial loss: 0.671250\n",
      "epoch 5; iter: 0; batch classifier loss: 0.628008; batch adversarial loss: 0.649992\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518344; batch adversarial loss: 0.622966\n",
      "epoch 7; iter: 0; batch classifier loss: 0.608750; batch adversarial loss: 0.596576\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610865; batch adversarial loss: 0.660813\n",
      "epoch 9; iter: 0; batch classifier loss: 0.625832; batch adversarial loss: 0.582354\n",
      "epoch 10; iter: 0; batch classifier loss: 0.590484; batch adversarial loss: 0.681673\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543411; batch adversarial loss: 0.574620\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551797; batch adversarial loss: 0.629706\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498882; batch adversarial loss: 0.605697\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449008; batch adversarial loss: 0.611296\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560230; batch adversarial loss: 0.628553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.516056; batch adversarial loss: 0.535978\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520329; batch adversarial loss: 0.589390\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557657; batch adversarial loss: 0.582182\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471702; batch adversarial loss: 0.562733\n",
      "epoch 20; iter: 0; batch classifier loss: 0.486642; batch adversarial loss: 0.532075\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539593; batch adversarial loss: 0.584640\n",
      "epoch 22; iter: 0; batch classifier loss: 0.426182; batch adversarial loss: 0.475686\n",
      "epoch 23; iter: 0; batch classifier loss: 0.377339; batch adversarial loss: 0.514704\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436263; batch adversarial loss: 0.566758\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449096; batch adversarial loss: 0.548202\n",
      "epoch 26; iter: 0; batch classifier loss: 0.560012; batch adversarial loss: 0.560332\n",
      "epoch 27; iter: 0; batch classifier loss: 0.568534; batch adversarial loss: 0.583668\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452967; batch adversarial loss: 0.534876\n",
      "epoch 29; iter: 0; batch classifier loss: 0.403224; batch adversarial loss: 0.540731\n",
      "epoch 30; iter: 0; batch classifier loss: 0.517010; batch adversarial loss: 0.511243\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457161; batch adversarial loss: 0.553497\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443949; batch adversarial loss: 0.488876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.455923; batch adversarial loss: 0.644672\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441950; batch adversarial loss: 0.572207\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450690; batch adversarial loss: 0.494488\n",
      "epoch 36; iter: 0; batch classifier loss: 0.419269; batch adversarial loss: 0.509989\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493208; batch adversarial loss: 0.505141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409999; batch adversarial loss: 0.601697\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471068; batch adversarial loss: 0.503187\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507364; batch adversarial loss: 0.570814\n",
      "epoch 41; iter: 0; batch classifier loss: 0.368011; batch adversarial loss: 0.507060\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433089; batch adversarial loss: 0.528970\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423037; batch adversarial loss: 0.486287\n",
      "epoch 44; iter: 0; batch classifier loss: 0.523161; batch adversarial loss: 0.615760\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472817; batch adversarial loss: 0.569567\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436192; batch adversarial loss: 0.579204\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401027; batch adversarial loss: 0.467148\n",
      "epoch 48; iter: 0; batch classifier loss: 0.499694; batch adversarial loss: 0.578805\n",
      "epoch 49; iter: 0; batch classifier loss: 0.479831; batch adversarial loss: 0.500398\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457795; batch adversarial loss: 0.493820\n",
      "epoch 51; iter: 0; batch classifier loss: 0.385145; batch adversarial loss: 0.523069\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413774; batch adversarial loss: 0.488860\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411756; batch adversarial loss: 0.531578\n",
      "epoch 54; iter: 0; batch classifier loss: 0.484789; batch adversarial loss: 0.562111\n",
      "epoch 55; iter: 0; batch classifier loss: 0.328405; batch adversarial loss: 0.549151\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378769; batch adversarial loss: 0.542409\n",
      "epoch 57; iter: 0; batch classifier loss: 0.360297; batch adversarial loss: 0.522803\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442945; batch adversarial loss: 0.643181\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466023; batch adversarial loss: 0.484325\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446923; batch adversarial loss: 0.619033\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460436; batch adversarial loss: 0.563312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.404609; batch adversarial loss: 0.516896\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394235; batch adversarial loss: 0.626425\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423972; batch adversarial loss: 0.505890\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424973; batch adversarial loss: 0.473271\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418036; batch adversarial loss: 0.572491\n",
      "epoch 67; iter: 0; batch classifier loss: 0.427841; batch adversarial loss: 0.490425\n",
      "epoch 68; iter: 0; batch classifier loss: 0.431674; batch adversarial loss: 0.588920\n",
      "epoch 69; iter: 0; batch classifier loss: 0.450778; batch adversarial loss: 0.586344\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431895; batch adversarial loss: 0.563874\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409696; batch adversarial loss: 0.536948\n",
      "epoch 72; iter: 0; batch classifier loss: 0.451015; batch adversarial loss: 0.600719\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384040; batch adversarial loss: 0.494017\n",
      "epoch 74; iter: 0; batch classifier loss: 0.351175; batch adversarial loss: 0.524645\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385561; batch adversarial loss: 0.501990\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387958; batch adversarial loss: 0.534285\n",
      "epoch 77; iter: 0; batch classifier loss: 0.535113; batch adversarial loss: 0.542674\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447169; batch adversarial loss: 0.544415\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430045; batch adversarial loss: 0.606036\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438578; batch adversarial loss: 0.564183\n",
      "epoch 81; iter: 0; batch classifier loss: 0.483912; batch adversarial loss: 0.470174\n",
      "epoch 82; iter: 0; batch classifier loss: 0.471465; batch adversarial loss: 0.522943\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412504; batch adversarial loss: 0.649675\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404660; batch adversarial loss: 0.608571\n",
      "epoch 85; iter: 0; batch classifier loss: 0.426478; batch adversarial loss: 0.593079\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358122; batch adversarial loss: 0.544567\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371307; batch adversarial loss: 0.544961\n",
      "epoch 88; iter: 0; batch classifier loss: 0.404898; batch adversarial loss: 0.556932\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384001; batch adversarial loss: 0.575169\n",
      "epoch 90; iter: 0; batch classifier loss: 0.366622; batch adversarial loss: 0.525787\n",
      "epoch 91; iter: 0; batch classifier loss: 0.335242; batch adversarial loss: 0.563265\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424255; batch adversarial loss: 0.512257\n",
      "epoch 93; iter: 0; batch classifier loss: 0.373557; batch adversarial loss: 0.583108\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426644; batch adversarial loss: 0.482939\n",
      "epoch 95; iter: 0; batch classifier loss: 0.454017; batch adversarial loss: 0.562776\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408465; batch adversarial loss: 0.562353\n",
      "epoch 97; iter: 0; batch classifier loss: 0.428366; batch adversarial loss: 0.670918\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395151; batch adversarial loss: 0.599975\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390168; batch adversarial loss: 0.501038\n",
      "epoch 100; iter: 0; batch classifier loss: 0.299571; batch adversarial loss: 0.589260\n",
      "epoch 101; iter: 0; batch classifier loss: 0.433936; batch adversarial loss: 0.518387\n",
      "epoch 102; iter: 0; batch classifier loss: 0.459070; batch adversarial loss: 0.618068\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398856; batch adversarial loss: 0.630238\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352003; batch adversarial loss: 0.549317\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432710; batch adversarial loss: 0.535832\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398191; batch adversarial loss: 0.543411\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388468; batch adversarial loss: 0.540222\n",
      "epoch 108; iter: 0; batch classifier loss: 0.409486; batch adversarial loss: 0.521855\n",
      "epoch 109; iter: 0; batch classifier loss: 0.471244; batch adversarial loss: 0.549660\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367409; batch adversarial loss: 0.535637\n",
      "epoch 111; iter: 0; batch classifier loss: 0.472037; batch adversarial loss: 0.521353\n",
      "epoch 112; iter: 0; batch classifier loss: 0.424095; batch adversarial loss: 0.588425\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347040; batch adversarial loss: 0.538965\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364242; batch adversarial loss: 0.540011\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381574; batch adversarial loss: 0.540244\n",
      "epoch 116; iter: 0; batch classifier loss: 0.505719; batch adversarial loss: 0.608240\n",
      "epoch 117; iter: 0; batch classifier loss: 0.401687; batch adversarial loss: 0.546058\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354497; batch adversarial loss: 0.556457\n",
      "epoch 119; iter: 0; batch classifier loss: 0.439334; batch adversarial loss: 0.488190\n",
      "epoch 120; iter: 0; batch classifier loss: 0.297893; batch adversarial loss: 0.560571\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362758; batch adversarial loss: 0.599889\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350791; batch adversarial loss: 0.572241\n",
      "epoch 123; iter: 0; batch classifier loss: 0.382635; batch adversarial loss: 0.483694\n",
      "epoch 124; iter: 0; batch classifier loss: 0.415790; batch adversarial loss: 0.492842\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404788; batch adversarial loss: 0.513960\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358247; batch adversarial loss: 0.492790\n",
      "epoch 127; iter: 0; batch classifier loss: 0.465621; batch adversarial loss: 0.580649\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415416; batch adversarial loss: 0.555360\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368982; batch adversarial loss: 0.559084\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373357; batch adversarial loss: 0.590604\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381256; batch adversarial loss: 0.598199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.256897; batch adversarial loss: 0.480721\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347988; batch adversarial loss: 0.508012\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371724; batch adversarial loss: 0.613395\n",
      "epoch 135; iter: 0; batch classifier loss: 0.359864; batch adversarial loss: 0.498868\n",
      "epoch 136; iter: 0; batch classifier loss: 0.317793; batch adversarial loss: 0.556065\n",
      "epoch 137; iter: 0; batch classifier loss: 0.314522; batch adversarial loss: 0.577813\n",
      "epoch 138; iter: 0; batch classifier loss: 0.477208; batch adversarial loss: 0.489873\n",
      "epoch 139; iter: 0; batch classifier loss: 0.461551; batch adversarial loss: 0.542998\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386950; batch adversarial loss: 0.514724\n",
      "epoch 141; iter: 0; batch classifier loss: 0.372126; batch adversarial loss: 0.490683\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371545; batch adversarial loss: 0.520186\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355496; batch adversarial loss: 0.542842\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401220; batch adversarial loss: 0.483723\n",
      "epoch 145; iter: 0; batch classifier loss: 0.431439; batch adversarial loss: 0.600372\n",
      "epoch 146; iter: 0; batch classifier loss: 0.462622; batch adversarial loss: 0.602004\n",
      "epoch 147; iter: 0; batch classifier loss: 0.271210; batch adversarial loss: 0.623594\n",
      "epoch 148; iter: 0; batch classifier loss: 0.439953; batch adversarial loss: 0.528133\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405919; batch adversarial loss: 0.585273\n",
      "epoch 150; iter: 0; batch classifier loss: 0.347266; batch adversarial loss: 0.569193\n",
      "epoch 151; iter: 0; batch classifier loss: 0.359060; batch adversarial loss: 0.586192\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378798; batch adversarial loss: 0.521795\n",
      "epoch 153; iter: 0; batch classifier loss: 0.331596; batch adversarial loss: 0.502425\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404573; batch adversarial loss: 0.499985\n",
      "epoch 155; iter: 0; batch classifier loss: 0.320716; batch adversarial loss: 0.549516\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337331; batch adversarial loss: 0.562511\n",
      "epoch 157; iter: 0; batch classifier loss: 0.396265; batch adversarial loss: 0.608438\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347611; batch adversarial loss: 0.562390\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344581; batch adversarial loss: 0.632022\n",
      "epoch 160; iter: 0; batch classifier loss: 0.405825; batch adversarial loss: 0.517183\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356508; batch adversarial loss: 0.612096\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390091; batch adversarial loss: 0.426982\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328162; batch adversarial loss: 0.470527\n",
      "epoch 164; iter: 0; batch classifier loss: 0.349563; batch adversarial loss: 0.553156\n",
      "epoch 165; iter: 0; batch classifier loss: 0.400954; batch adversarial loss: 0.506201\n",
      "epoch 166; iter: 0; batch classifier loss: 0.275509; batch adversarial loss: 0.570731\n",
      "epoch 167; iter: 0; batch classifier loss: 0.351363; batch adversarial loss: 0.550676\n",
      "epoch 168; iter: 0; batch classifier loss: 0.427978; batch adversarial loss: 0.571096\n",
      "epoch 169; iter: 0; batch classifier loss: 0.421885; batch adversarial loss: 0.470838\n",
      "epoch 170; iter: 0; batch classifier loss: 0.399000; batch adversarial loss: 0.567073\n",
      "epoch 171; iter: 0; batch classifier loss: 0.469753; batch adversarial loss: 0.568143\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379471; batch adversarial loss: 0.532057\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381236; batch adversarial loss: 0.551450\n",
      "epoch 174; iter: 0; batch classifier loss: 0.329131; batch adversarial loss: 0.554547\n",
      "epoch 175; iter: 0; batch classifier loss: 0.404406; batch adversarial loss: 0.521682\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395902; batch adversarial loss: 0.518840\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340960; batch adversarial loss: 0.528097\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369261; batch adversarial loss: 0.559851\n",
      "epoch 179; iter: 0; batch classifier loss: 0.401997; batch adversarial loss: 0.503318\n",
      "epoch 180; iter: 0; batch classifier loss: 0.426088; batch adversarial loss: 0.580825\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379566; batch adversarial loss: 0.545427\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375892; batch adversarial loss: 0.532304\n",
      "epoch 183; iter: 0; batch classifier loss: 0.390848; batch adversarial loss: 0.632808\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356178; batch adversarial loss: 0.598384\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383054; batch adversarial loss: 0.505329\n",
      "epoch 186; iter: 0; batch classifier loss: 0.410297; batch adversarial loss: 0.484882\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322816; batch adversarial loss: 0.511966\n",
      "epoch 188; iter: 0; batch classifier loss: 0.377120; batch adversarial loss: 0.509000\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395495; batch adversarial loss: 0.637580\n",
      "epoch 190; iter: 0; batch classifier loss: 0.411018; batch adversarial loss: 0.505728\n",
      "epoch 191; iter: 0; batch classifier loss: 0.393410; batch adversarial loss: 0.624775\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319313; batch adversarial loss: 0.602420\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383481; batch adversarial loss: 0.574204\n",
      "epoch 194; iter: 0; batch classifier loss: 0.404257; batch adversarial loss: 0.508094\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319240; batch adversarial loss: 0.454913\n",
      "epoch 196; iter: 0; batch classifier loss: 0.369124; batch adversarial loss: 0.590454\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353220; batch adversarial loss: 0.457734\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359279; batch adversarial loss: 0.555021\n",
      "epoch 199; iter: 0; batch classifier loss: 0.296285; batch adversarial loss: 0.481367\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727390; batch adversarial loss: 0.649902\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618669; batch adversarial loss: 0.640282\n",
      "epoch 2; iter: 0; batch classifier loss: 0.502412; batch adversarial loss: 0.654172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580348; batch adversarial loss: 0.608733\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532043; batch adversarial loss: 0.620704\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571702; batch adversarial loss: 0.580262\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595835; batch adversarial loss: 0.595348\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528356; batch adversarial loss: 0.655316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569003; batch adversarial loss: 0.641735\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511301; batch adversarial loss: 0.631618\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496240; batch adversarial loss: 0.582425\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489215; batch adversarial loss: 0.618397\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578757; batch adversarial loss: 0.598500\n",
      "epoch 13; iter: 0; batch classifier loss: 0.529913; batch adversarial loss: 0.576788\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504652; batch adversarial loss: 0.634199\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490012; batch adversarial loss: 0.551640\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542446; batch adversarial loss: 0.557654\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489075; batch adversarial loss: 0.561014\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557756; batch adversarial loss: 0.586142\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506301; batch adversarial loss: 0.572371\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480742; batch adversarial loss: 0.573235\n",
      "epoch 21; iter: 0; batch classifier loss: 0.529418; batch adversarial loss: 0.523793\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503704; batch adversarial loss: 0.572714\n",
      "epoch 23; iter: 0; batch classifier loss: 0.510630; batch adversarial loss: 0.616690\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519245; batch adversarial loss: 0.570121\n",
      "epoch 25; iter: 0; batch classifier loss: 0.408516; batch adversarial loss: 0.571717\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450593; batch adversarial loss: 0.529116\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444302; batch adversarial loss: 0.479355\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485108; batch adversarial loss: 0.478799\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474123; batch adversarial loss: 0.622583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.444754; batch adversarial loss: 0.621974\n",
      "epoch 31; iter: 0; batch classifier loss: 0.552556; batch adversarial loss: 0.510290\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490503; batch adversarial loss: 0.577525\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460024; batch adversarial loss: 0.553629\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430511; batch adversarial loss: 0.553246\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404032; batch adversarial loss: 0.527587\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438391; batch adversarial loss: 0.524235\n",
      "epoch 37; iter: 0; batch classifier loss: 0.370703; batch adversarial loss: 0.491760\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467617; batch adversarial loss: 0.556566\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417013; batch adversarial loss: 0.631708\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405120; batch adversarial loss: 0.544981\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388897; batch adversarial loss: 0.598017\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422696; batch adversarial loss: 0.527560\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445791; batch adversarial loss: 0.525965\n",
      "epoch 44; iter: 0; batch classifier loss: 0.345354; batch adversarial loss: 0.524703\n",
      "epoch 45; iter: 0; batch classifier loss: 0.494630; batch adversarial loss: 0.535160\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414929; batch adversarial loss: 0.523058\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441237; batch adversarial loss: 0.571733\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405531; batch adversarial loss: 0.499904\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442040; batch adversarial loss: 0.544131\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402194; batch adversarial loss: 0.636154\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449651; batch adversarial loss: 0.598143\n",
      "epoch 52; iter: 0; batch classifier loss: 0.384246; batch adversarial loss: 0.545782\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444274; batch adversarial loss: 0.553636\n",
      "epoch 54; iter: 0; batch classifier loss: 0.550161; batch adversarial loss: 0.471524\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416313; batch adversarial loss: 0.508168\n",
      "epoch 56; iter: 0; batch classifier loss: 0.455913; batch adversarial loss: 0.581911\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402350; batch adversarial loss: 0.534514\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450954; batch adversarial loss: 0.519609\n",
      "epoch 59; iter: 0; batch classifier loss: 0.455130; batch adversarial loss: 0.527378\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376681; batch adversarial loss: 0.518018\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433345; batch adversarial loss: 0.471304\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417247; batch adversarial loss: 0.545312\n",
      "epoch 63; iter: 0; batch classifier loss: 0.345580; batch adversarial loss: 0.564097\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436226; batch adversarial loss: 0.571700\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408143; batch adversarial loss: 0.657039\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387339; batch adversarial loss: 0.545019\n",
      "epoch 67; iter: 0; batch classifier loss: 0.398563; batch adversarial loss: 0.573545\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437090; batch adversarial loss: 0.580833\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378733; batch adversarial loss: 0.571612\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391478; batch adversarial loss: 0.608134\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417086; batch adversarial loss: 0.626720\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432427; batch adversarial loss: 0.525863\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371463; batch adversarial loss: 0.525811\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447849; batch adversarial loss: 0.544319\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427641; batch adversarial loss: 0.607827\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369273; batch adversarial loss: 0.489274\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387413; batch adversarial loss: 0.488976\n",
      "epoch 78; iter: 0; batch classifier loss: 0.504149; batch adversarial loss: 0.498558\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410585; batch adversarial loss: 0.562053\n",
      "epoch 80; iter: 0; batch classifier loss: 0.459244; batch adversarial loss: 0.571422\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396590; batch adversarial loss: 0.553138\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420511; batch adversarial loss: 0.598752\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377214; batch adversarial loss: 0.526765\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393148; batch adversarial loss: 0.552062\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410379; batch adversarial loss: 0.516813\n",
      "epoch 86; iter: 0; batch classifier loss: 0.452633; batch adversarial loss: 0.634718\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390559; batch adversarial loss: 0.608292\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425679; batch adversarial loss: 0.572689\n",
      "epoch 89; iter: 0; batch classifier loss: 0.320996; batch adversarial loss: 0.526209\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365666; batch adversarial loss: 0.518789\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389935; batch adversarial loss: 0.519890\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386666; batch adversarial loss: 0.600574\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417852; batch adversarial loss: 0.545017\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375365; batch adversarial loss: 0.507855\n",
      "epoch 95; iter: 0; batch classifier loss: 0.356458; batch adversarial loss: 0.580636\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414699; batch adversarial loss: 0.544007\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370839; batch adversarial loss: 0.535821\n",
      "epoch 98; iter: 0; batch classifier loss: 0.346579; batch adversarial loss: 0.508626\n",
      "epoch 99; iter: 0; batch classifier loss: 0.436358; batch adversarial loss: 0.571921\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399830; batch adversarial loss: 0.590347\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395054; batch adversarial loss: 0.608931\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326894; batch adversarial loss: 0.580299\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371836; batch adversarial loss: 0.581719\n",
      "epoch 104; iter: 0; batch classifier loss: 0.320243; batch adversarial loss: 0.507808\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368362; batch adversarial loss: 0.580618\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363687; batch adversarial loss: 0.488904\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380934; batch adversarial loss: 0.609711\n",
      "epoch 108; iter: 0; batch classifier loss: 0.372369; batch adversarial loss: 0.536420\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387599; batch adversarial loss: 0.553939\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390061; batch adversarial loss: 0.526456\n",
      "epoch 111; iter: 0; batch classifier loss: 0.346195; batch adversarial loss: 0.572946\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362708; batch adversarial loss: 0.498663\n",
      "epoch 113; iter: 0; batch classifier loss: 0.479668; batch adversarial loss: 0.500034\n",
      "epoch 114; iter: 0; batch classifier loss: 0.450138; batch adversarial loss: 0.580168\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412480; batch adversarial loss: 0.534399\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361044; batch adversarial loss: 0.526306\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391364; batch adversarial loss: 0.544537\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383009; batch adversarial loss: 0.544445\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334012; batch adversarial loss: 0.470924\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375377; batch adversarial loss: 0.526514\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419602; batch adversarial loss: 0.508810\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418731; batch adversarial loss: 0.498961\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423498; batch adversarial loss: 0.552788\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398452; batch adversarial loss: 0.536177\n",
      "epoch 125; iter: 0; batch classifier loss: 0.436193; batch adversarial loss: 0.591605\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382358; batch adversarial loss: 0.553785\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362808; batch adversarial loss: 0.591196\n",
      "epoch 128; iter: 0; batch classifier loss: 0.309059; batch adversarial loss: 0.546468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.367044; batch adversarial loss: 0.526855\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389506; batch adversarial loss: 0.495825\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382520; batch adversarial loss: 0.562187\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403850; batch adversarial loss: 0.563755\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399787; batch adversarial loss: 0.523067\n",
      "epoch 134; iter: 0; batch classifier loss: 0.292680; batch adversarial loss: 0.495758\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413715; batch adversarial loss: 0.536339\n",
      "epoch 136; iter: 0; batch classifier loss: 0.417561; batch adversarial loss: 0.552442\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396571; batch adversarial loss: 0.499663\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403491; batch adversarial loss: 0.564590\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345400; batch adversarial loss: 0.481550\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349185; batch adversarial loss: 0.537176\n",
      "epoch 141; iter: 0; batch classifier loss: 0.315804; batch adversarial loss: 0.544983\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351346; batch adversarial loss: 0.589138\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373306; batch adversarial loss: 0.589299\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348762; batch adversarial loss: 0.527204\n",
      "epoch 145; iter: 0; batch classifier loss: 0.302665; batch adversarial loss: 0.598933\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365732; batch adversarial loss: 0.426563\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374771; batch adversarial loss: 0.616548\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378798; batch adversarial loss: 0.517921\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366743; batch adversarial loss: 0.480484\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381638; batch adversarial loss: 0.598194\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375420; batch adversarial loss: 0.516403\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343748; batch adversarial loss: 0.577291\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352405; batch adversarial loss: 0.625088\n",
      "epoch 154; iter: 0; batch classifier loss: 0.418430; batch adversarial loss: 0.507235\n",
      "epoch 155; iter: 0; batch classifier loss: 0.378202; batch adversarial loss: 0.634420\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333593; batch adversarial loss: 0.537235\n",
      "epoch 157; iter: 0; batch classifier loss: 0.407653; batch adversarial loss: 0.544824\n",
      "epoch 158; iter: 0; batch classifier loss: 0.258031; batch adversarial loss: 0.516023\n",
      "epoch 159; iter: 0; batch classifier loss: 0.417261; batch adversarial loss: 0.564848\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347847; batch adversarial loss: 0.551394\n",
      "epoch 161; iter: 0; batch classifier loss: 0.437442; batch adversarial loss: 0.571914\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386689; batch adversarial loss: 0.528948\n",
      "epoch 163; iter: 0; batch classifier loss: 0.387337; batch adversarial loss: 0.508010\n",
      "epoch 164; iter: 0; batch classifier loss: 0.320882; batch adversarial loss: 0.617610\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319773; batch adversarial loss: 0.617733\n",
      "epoch 166; iter: 0; batch classifier loss: 0.457410; batch adversarial loss: 0.600803\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384848; batch adversarial loss: 0.526561\n",
      "epoch 168; iter: 0; batch classifier loss: 0.444537; batch adversarial loss: 0.544054\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382744; batch adversarial loss: 0.562094\n",
      "epoch 170; iter: 0; batch classifier loss: 0.341374; batch adversarial loss: 0.562544\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382590; batch adversarial loss: 0.571963\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363294; batch adversarial loss: 0.545845\n",
      "epoch 173; iter: 0; batch classifier loss: 0.393086; batch adversarial loss: 0.517348\n",
      "epoch 174; iter: 0; batch classifier loss: 0.417704; batch adversarial loss: 0.599480\n",
      "epoch 175; iter: 0; batch classifier loss: 0.379259; batch adversarial loss: 0.462884\n",
      "epoch 176; iter: 0; batch classifier loss: 0.314750; batch adversarial loss: 0.552341\n",
      "epoch 177; iter: 0; batch classifier loss: 0.328497; batch adversarial loss: 0.581388\n",
      "epoch 178; iter: 0; batch classifier loss: 0.393690; batch adversarial loss: 0.552671\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345348; batch adversarial loss: 0.545283\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371697; batch adversarial loss: 0.489842\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311002; batch adversarial loss: 0.552817\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375794; batch adversarial loss: 0.525741\n",
      "epoch 183; iter: 0; batch classifier loss: 0.301210; batch adversarial loss: 0.544111\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337444; batch adversarial loss: 0.471411\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308199; batch adversarial loss: 0.644774\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324640; batch adversarial loss: 0.508615\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369517; batch adversarial loss: 0.581697\n",
      "epoch 188; iter: 0; batch classifier loss: 0.407881; batch adversarial loss: 0.498672\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404425; batch adversarial loss: 0.599470\n",
      "epoch 190; iter: 0; batch classifier loss: 0.313762; batch adversarial loss: 0.534887\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373470; batch adversarial loss: 0.471680\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335459; batch adversarial loss: 0.506327\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372765; batch adversarial loss: 0.581838\n",
      "epoch 194; iter: 0; batch classifier loss: 0.328028; batch adversarial loss: 0.517083\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334783; batch adversarial loss: 0.553644\n",
      "epoch 196; iter: 0; batch classifier loss: 0.353053; batch adversarial loss: 0.572585\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345546; batch adversarial loss: 0.563890\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377213; batch adversarial loss: 0.452584\n",
      "epoch 199; iter: 0; batch classifier loss: 0.412707; batch adversarial loss: 0.480109\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657136; batch adversarial loss: 0.789038\n",
      "epoch 1; iter: 0; batch classifier loss: 0.697260; batch adversarial loss: 0.840697\n",
      "epoch 2; iter: 0; batch classifier loss: 0.772764; batch adversarial loss: 0.812069\n",
      "epoch 3; iter: 0; batch classifier loss: 0.940442; batch adversarial loss: 0.746715\n",
      "epoch 4; iter: 0; batch classifier loss: 0.878698; batch adversarial loss: 0.692454\n",
      "epoch 5; iter: 0; batch classifier loss: 0.883523; batch adversarial loss: 0.635695\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599857; batch adversarial loss: 0.615024\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563214; batch adversarial loss: 0.609386\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535077; batch adversarial loss: 0.580096\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586869; batch adversarial loss: 0.549787\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515295; batch adversarial loss: 0.580286\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568001; batch adversarial loss: 0.568225\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514115; batch adversarial loss: 0.603694\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554230; batch adversarial loss: 0.566668\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514305; batch adversarial loss: 0.563206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486990; batch adversarial loss: 0.594158\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460140; batch adversarial loss: 0.540779\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492371; batch adversarial loss: 0.544194\n",
      "epoch 18; iter: 0; batch classifier loss: 0.449642; batch adversarial loss: 0.579667\n",
      "epoch 19; iter: 0; batch classifier loss: 0.572757; batch adversarial loss: 0.522905\n",
      "epoch 20; iter: 0; batch classifier loss: 0.562588; batch adversarial loss: 0.581751\n",
      "epoch 21; iter: 0; batch classifier loss: 0.560181; batch adversarial loss: 0.570893\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494997; batch adversarial loss: 0.543251\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515914; batch adversarial loss: 0.532604\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458151; batch adversarial loss: 0.619402\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433813; batch adversarial loss: 0.534202\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479175; batch adversarial loss: 0.540926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.501202; batch adversarial loss: 0.590037\n",
      "epoch 28; iter: 0; batch classifier loss: 0.524879; batch adversarial loss: 0.567341\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464591; batch adversarial loss: 0.575390\n",
      "epoch 30; iter: 0; batch classifier loss: 0.567294; batch adversarial loss: 0.502239\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468365; batch adversarial loss: 0.524188\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444467; batch adversarial loss: 0.538264\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443605; batch adversarial loss: 0.465011\n",
      "epoch 34; iter: 0; batch classifier loss: 0.524707; batch adversarial loss: 0.579911\n",
      "epoch 35; iter: 0; batch classifier loss: 0.364671; batch adversarial loss: 0.536695\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465322; batch adversarial loss: 0.498218\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429764; batch adversarial loss: 0.643088\n",
      "epoch 38; iter: 0; batch classifier loss: 0.525289; batch adversarial loss: 0.537356\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447039; batch adversarial loss: 0.561739\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422197; batch adversarial loss: 0.510960\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425505; batch adversarial loss: 0.564955\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440305; batch adversarial loss: 0.582942\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409409; batch adversarial loss: 0.488963\n",
      "epoch 44; iter: 0; batch classifier loss: 0.387884; batch adversarial loss: 0.544553\n",
      "epoch 45; iter: 0; batch classifier loss: 0.380053; batch adversarial loss: 0.580687\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441663; batch adversarial loss: 0.563682\n",
      "epoch 47; iter: 0; batch classifier loss: 0.374141; batch adversarial loss: 0.645326\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370957; batch adversarial loss: 0.543616\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385004; batch adversarial loss: 0.526995\n",
      "epoch 50; iter: 0; batch classifier loss: 0.335519; batch adversarial loss: 0.500351\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421027; batch adversarial loss: 0.562813\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389138; batch adversarial loss: 0.542402\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393775; batch adversarial loss: 0.552324\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449537; batch adversarial loss: 0.608735\n",
      "epoch 55; iter: 0; batch classifier loss: 0.375502; batch adversarial loss: 0.666235\n",
      "epoch 56; iter: 0; batch classifier loss: 0.480666; batch adversarial loss: 0.571574\n",
      "epoch 57; iter: 0; batch classifier loss: 0.388813; batch adversarial loss: 0.523215\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427418; batch adversarial loss: 0.514826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.503357; batch adversarial loss: 0.485088\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379374; batch adversarial loss: 0.573079\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385478; batch adversarial loss: 0.515727\n",
      "epoch 62; iter: 0; batch classifier loss: 0.368848; batch adversarial loss: 0.524617\n",
      "epoch 63; iter: 0; batch classifier loss: 0.364058; batch adversarial loss: 0.476382\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434778; batch adversarial loss: 0.589675\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467139; batch adversarial loss: 0.482496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418758; batch adversarial loss: 0.517563\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445191; batch adversarial loss: 0.526848\n",
      "epoch 68; iter: 0; batch classifier loss: 0.368845; batch adversarial loss: 0.571287\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382530; batch adversarial loss: 0.515367\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410704; batch adversarial loss: 0.612793\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387966; batch adversarial loss: 0.470488\n",
      "epoch 72; iter: 0; batch classifier loss: 0.378993; batch adversarial loss: 0.579522\n",
      "epoch 73; iter: 0; batch classifier loss: 0.360695; batch adversarial loss: 0.581976\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374190; batch adversarial loss: 0.619321\n",
      "epoch 75; iter: 0; batch classifier loss: 0.442177; batch adversarial loss: 0.517767\n",
      "epoch 76; iter: 0; batch classifier loss: 0.323103; batch adversarial loss: 0.471290\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360247; batch adversarial loss: 0.498041\n",
      "epoch 78; iter: 0; batch classifier loss: 0.353839; batch adversarial loss: 0.496332\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392982; batch adversarial loss: 0.553036\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395528; batch adversarial loss: 0.562440\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356127; batch adversarial loss: 0.611527\n",
      "epoch 82; iter: 0; batch classifier loss: 0.325557; batch adversarial loss: 0.565944\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372590; batch adversarial loss: 0.526239\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410568; batch adversarial loss: 0.572600\n",
      "epoch 85; iter: 0; batch classifier loss: 0.468163; batch adversarial loss: 0.581309\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371911; batch adversarial loss: 0.470396\n",
      "epoch 87; iter: 0; batch classifier loss: 0.327417; batch adversarial loss: 0.572174\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356618; batch adversarial loss: 0.592027\n",
      "epoch 89; iter: 0; batch classifier loss: 0.324643; batch adversarial loss: 0.544419\n",
      "epoch 90; iter: 0; batch classifier loss: 0.298771; batch adversarial loss: 0.571858\n",
      "epoch 91; iter: 0; batch classifier loss: 0.344441; batch adversarial loss: 0.544848\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396132; batch adversarial loss: 0.581563\n",
      "epoch 93; iter: 0; batch classifier loss: 0.296953; batch adversarial loss: 0.610205\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406366; batch adversarial loss: 0.581592\n",
      "epoch 95; iter: 0; batch classifier loss: 0.366269; batch adversarial loss: 0.638348\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326836; batch adversarial loss: 0.488109\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375703; batch adversarial loss: 0.600786\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364062; batch adversarial loss: 0.497415\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344400; batch adversarial loss: 0.563479\n",
      "epoch 100; iter: 0; batch classifier loss: 0.354263; batch adversarial loss: 0.553804\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365639; batch adversarial loss: 0.497667\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409848; batch adversarial loss: 0.572580\n",
      "epoch 103; iter: 0; batch classifier loss: 0.432083; batch adversarial loss: 0.544655\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373997; batch adversarial loss: 0.487522\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365345; batch adversarial loss: 0.516092\n",
      "epoch 106; iter: 0; batch classifier loss: 0.308801; batch adversarial loss: 0.526131\n",
      "epoch 107; iter: 0; batch classifier loss: 0.331236; batch adversarial loss: 0.544722\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352773; batch adversarial loss: 0.507452\n",
      "epoch 109; iter: 0; batch classifier loss: 0.329295; batch adversarial loss: 0.507327\n",
      "epoch 110; iter: 0; batch classifier loss: 0.334597; batch adversarial loss: 0.638159\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388331; batch adversarial loss: 0.459899\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347034; batch adversarial loss: 0.562600\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419488; batch adversarial loss: 0.516036\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382773; batch adversarial loss: 0.526091\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326756; batch adversarial loss: 0.610281\n",
      "epoch 116; iter: 0; batch classifier loss: 0.321092; batch adversarial loss: 0.610042\n",
      "epoch 117; iter: 0; batch classifier loss: 0.421922; batch adversarial loss: 0.553859\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340543; batch adversarial loss: 0.619555\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410885; batch adversarial loss: 0.544099\n",
      "epoch 120; iter: 0; batch classifier loss: 0.351185; batch adversarial loss: 0.592396\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348472; batch adversarial loss: 0.526379\n",
      "epoch 122; iter: 0; batch classifier loss: 0.333489; batch adversarial loss: 0.582185\n",
      "epoch 123; iter: 0; batch classifier loss: 0.393050; batch adversarial loss: 0.581681\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338399; batch adversarial loss: 0.479387\n",
      "epoch 125; iter: 0; batch classifier loss: 0.301251; batch adversarial loss: 0.572522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.423511; batch adversarial loss: 0.563015\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329613; batch adversarial loss: 0.496961\n",
      "epoch 128; iter: 0; batch classifier loss: 0.299260; batch adversarial loss: 0.563187\n",
      "epoch 129; iter: 0; batch classifier loss: 0.287735; batch adversarial loss: 0.553566\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373247; batch adversarial loss: 0.497041\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349052; batch adversarial loss: 0.582390\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341200; batch adversarial loss: 0.506649\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344043; batch adversarial loss: 0.517189\n",
      "epoch 134; iter: 0; batch classifier loss: 0.429796; batch adversarial loss: 0.543661\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377583; batch adversarial loss: 0.544097\n",
      "epoch 136; iter: 0; batch classifier loss: 0.337338; batch adversarial loss: 0.487782\n",
      "epoch 137; iter: 0; batch classifier loss: 0.282507; batch adversarial loss: 0.553684\n",
      "epoch 138; iter: 0; batch classifier loss: 0.330756; batch adversarial loss: 0.554530\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352131; batch adversarial loss: 0.524493\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337784; batch adversarial loss: 0.451016\n",
      "epoch 141; iter: 0; batch classifier loss: 0.354512; batch adversarial loss: 0.563664\n",
      "epoch 142; iter: 0; batch classifier loss: 0.300540; batch adversarial loss: 0.572430\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414368; batch adversarial loss: 0.507422\n",
      "epoch 144; iter: 0; batch classifier loss: 0.323032; batch adversarial loss: 0.488784\n",
      "epoch 145; iter: 0; batch classifier loss: 0.322265; batch adversarial loss: 0.469882\n",
      "epoch 146; iter: 0; batch classifier loss: 0.320300; batch adversarial loss: 0.515896\n",
      "epoch 147; iter: 0; batch classifier loss: 0.341532; batch adversarial loss: 0.553907\n",
      "epoch 148; iter: 0; batch classifier loss: 0.306997; batch adversarial loss: 0.525714\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342768; batch adversarial loss: 0.572269\n",
      "epoch 150; iter: 0; batch classifier loss: 0.313310; batch adversarial loss: 0.582042\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386674; batch adversarial loss: 0.535281\n",
      "epoch 152; iter: 0; batch classifier loss: 0.310639; batch adversarial loss: 0.620630\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349242; batch adversarial loss: 0.478876\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353850; batch adversarial loss: 0.591378\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355694; batch adversarial loss: 0.544055\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357190; batch adversarial loss: 0.525113\n",
      "epoch 157; iter: 0; batch classifier loss: 0.322479; batch adversarial loss: 0.487565\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363668; batch adversarial loss: 0.478789\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348597; batch adversarial loss: 0.554404\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314973; batch adversarial loss: 0.573130\n",
      "epoch 161; iter: 0; batch classifier loss: 0.294057; batch adversarial loss: 0.525447\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344845; batch adversarial loss: 0.553988\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311690; batch adversarial loss: 0.535316\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358107; batch adversarial loss: 0.506561\n",
      "epoch 165; iter: 0; batch classifier loss: 0.395660; batch adversarial loss: 0.573143\n",
      "epoch 166; iter: 0; batch classifier loss: 0.262786; batch adversarial loss: 0.544585\n",
      "epoch 167; iter: 0; batch classifier loss: 0.293483; batch adversarial loss: 0.535157\n",
      "epoch 168; iter: 0; batch classifier loss: 0.404183; batch adversarial loss: 0.544720\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322651; batch adversarial loss: 0.582357\n",
      "epoch 170; iter: 0; batch classifier loss: 0.435310; batch adversarial loss: 0.515920\n",
      "epoch 171; iter: 0; batch classifier loss: 0.294045; batch adversarial loss: 0.525407\n",
      "epoch 172; iter: 0; batch classifier loss: 0.283596; batch adversarial loss: 0.507595\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343143; batch adversarial loss: 0.534491\n",
      "epoch 174; iter: 0; batch classifier loss: 0.313736; batch adversarial loss: 0.601582\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314160; batch adversarial loss: 0.571771\n",
      "epoch 176; iter: 0; batch classifier loss: 0.322887; batch adversarial loss: 0.610576\n",
      "epoch 177; iter: 0; batch classifier loss: 0.262693; batch adversarial loss: 0.600554\n",
      "epoch 178; iter: 0; batch classifier loss: 0.313079; batch adversarial loss: 0.563689\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356363; batch adversarial loss: 0.478876\n",
      "epoch 180; iter: 0; batch classifier loss: 0.294861; batch adversarial loss: 0.601050\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365610; batch adversarial loss: 0.535028\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387880; batch adversarial loss: 0.535312\n",
      "epoch 183; iter: 0; batch classifier loss: 0.291957; batch adversarial loss: 0.545034\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347299; batch adversarial loss: 0.592119\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367133; batch adversarial loss: 0.478558\n",
      "epoch 186; iter: 0; batch classifier loss: 0.420987; batch adversarial loss: 0.478705\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342459; batch adversarial loss: 0.571269\n",
      "epoch 188; iter: 0; batch classifier loss: 0.298185; batch adversarial loss: 0.572017\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292395; batch adversarial loss: 0.525631\n",
      "epoch 190; iter: 0; batch classifier loss: 0.289864; batch adversarial loss: 0.563080\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356804; batch adversarial loss: 0.553298\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348117; batch adversarial loss: 0.507850\n",
      "epoch 193; iter: 0; batch classifier loss: 0.301954; batch adversarial loss: 0.619132\n",
      "epoch 194; iter: 0; batch classifier loss: 0.232842; batch adversarial loss: 0.572780\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327938; batch adversarial loss: 0.572745\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332719; batch adversarial loss: 0.611227\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318173; batch adversarial loss: 0.563221\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331313; batch adversarial loss: 0.582796\n",
      "epoch 199; iter: 0; batch classifier loss: 0.273232; batch adversarial loss: 0.506211\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708592; batch adversarial loss: 0.792462\n",
      "epoch 1; iter: 0; batch classifier loss: 0.743052; batch adversarial loss: 0.845171\n",
      "epoch 2; iter: 0; batch classifier loss: 0.891752; batch adversarial loss: 0.807923\n",
      "epoch 3; iter: 0; batch classifier loss: 0.963280; batch adversarial loss: 0.734460\n",
      "epoch 4; iter: 0; batch classifier loss: 0.829610; batch adversarial loss: 0.674435\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614320; batch adversarial loss: 0.615191\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550050; batch adversarial loss: 0.612395\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604104; batch adversarial loss: 0.587306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558195; batch adversarial loss: 0.601277\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521168; batch adversarial loss: 0.579607\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513861; batch adversarial loss: 0.596350\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559693; batch adversarial loss: 0.582212\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544452; batch adversarial loss: 0.570143\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509946; batch adversarial loss: 0.595618\n",
      "epoch 14; iter: 0; batch classifier loss: 0.492085; batch adversarial loss: 0.507617\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483827; batch adversarial loss: 0.577347\n",
      "epoch 16; iter: 0; batch classifier loss: 0.462300; batch adversarial loss: 0.554947\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484546; batch adversarial loss: 0.561751\n",
      "epoch 18; iter: 0; batch classifier loss: 0.554517; batch adversarial loss: 0.532412\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530200; batch adversarial loss: 0.563422\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463698; batch adversarial loss: 0.533056\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538336; batch adversarial loss: 0.591996\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480487; batch adversarial loss: 0.504132\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491523; batch adversarial loss: 0.506689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.391111; batch adversarial loss: 0.522179\n",
      "epoch 25; iter: 0; batch classifier loss: 0.590397; batch adversarial loss: 0.555188\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467989; batch adversarial loss: 0.551031\n",
      "epoch 27; iter: 0; batch classifier loss: 0.524369; batch adversarial loss: 0.500741\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432319; batch adversarial loss: 0.627091\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480321; batch adversarial loss: 0.564690\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450091; batch adversarial loss: 0.548877\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437847; batch adversarial loss: 0.530906\n",
      "epoch 32; iter: 0; batch classifier loss: 0.418770; batch adversarial loss: 0.590303\n",
      "epoch 33; iter: 0; batch classifier loss: 0.487204; batch adversarial loss: 0.545970\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437448; batch adversarial loss: 0.538942\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454675; batch adversarial loss: 0.439301\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445588; batch adversarial loss: 0.536898\n",
      "epoch 37; iter: 0; batch classifier loss: 0.474821; batch adversarial loss: 0.511109\n",
      "epoch 38; iter: 0; batch classifier loss: 0.367516; batch adversarial loss: 0.553487\n",
      "epoch 39; iter: 0; batch classifier loss: 0.351013; batch adversarial loss: 0.544511\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446462; batch adversarial loss: 0.529567\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484626; batch adversarial loss: 0.493010\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422692; batch adversarial loss: 0.596462\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459464; batch adversarial loss: 0.588305\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414483; batch adversarial loss: 0.527965\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441010; batch adversarial loss: 0.637572\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429504; batch adversarial loss: 0.644836\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435893; batch adversarial loss: 0.501378\n",
      "epoch 48; iter: 0; batch classifier loss: 0.522931; batch adversarial loss: 0.618871\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420273; batch adversarial loss: 0.491613\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415647; batch adversarial loss: 0.490387\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417152; batch adversarial loss: 0.572000\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408300; batch adversarial loss: 0.562917\n",
      "epoch 53; iter: 0; batch classifier loss: 0.368242; batch adversarial loss: 0.545088\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443986; batch adversarial loss: 0.534609\n",
      "epoch 55; iter: 0; batch classifier loss: 0.373294; batch adversarial loss: 0.499771\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457258; batch adversarial loss: 0.507945\n",
      "epoch 57; iter: 0; batch classifier loss: 0.434501; batch adversarial loss: 0.489266\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419316; batch adversarial loss: 0.489902\n",
      "epoch 59; iter: 0; batch classifier loss: 0.353434; batch adversarial loss: 0.618482\n",
      "epoch 60; iter: 0; batch classifier loss: 0.351727; batch adversarial loss: 0.562917\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460937; batch adversarial loss: 0.507649\n",
      "epoch 62; iter: 0; batch classifier loss: 0.340005; batch adversarial loss: 0.599908\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391789; batch adversarial loss: 0.526397\n",
      "epoch 64; iter: 0; batch classifier loss: 0.457873; batch adversarial loss: 0.507690\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425427; batch adversarial loss: 0.488656\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421758; batch adversarial loss: 0.553997\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405119; batch adversarial loss: 0.526237\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400855; batch adversarial loss: 0.517188\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359137; batch adversarial loss: 0.498661\n",
      "epoch 70; iter: 0; batch classifier loss: 0.381347; batch adversarial loss: 0.580785\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435177; batch adversarial loss: 0.534876\n",
      "epoch 72; iter: 0; batch classifier loss: 0.341890; batch adversarial loss: 0.571884\n",
      "epoch 73; iter: 0; batch classifier loss: 0.358077; batch adversarial loss: 0.524809\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386328; batch adversarial loss: 0.476868\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373421; batch adversarial loss: 0.563562\n",
      "epoch 76; iter: 0; batch classifier loss: 0.336641; batch adversarial loss: 0.515559\n",
      "epoch 77; iter: 0; batch classifier loss: 0.313288; batch adversarial loss: 0.598612\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407625; batch adversarial loss: 0.580684\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440957; batch adversarial loss: 0.585937\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436224; batch adversarial loss: 0.507480\n",
      "epoch 81; iter: 0; batch classifier loss: 0.321355; batch adversarial loss: 0.546359\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374383; batch adversarial loss: 0.674249\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407516; batch adversarial loss: 0.497067\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376500; batch adversarial loss: 0.506786\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398327; batch adversarial loss: 0.516988\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390512; batch adversarial loss: 0.543525\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377677; batch adversarial loss: 0.591848\n",
      "epoch 88; iter: 0; batch classifier loss: 0.380409; batch adversarial loss: 0.515390\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357705; batch adversarial loss: 0.553475\n",
      "epoch 90; iter: 0; batch classifier loss: 0.327309; batch adversarial loss: 0.580737\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360262; batch adversarial loss: 0.423334\n",
      "epoch 92; iter: 0; batch classifier loss: 0.436609; batch adversarial loss: 0.505525\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357387; batch adversarial loss: 0.512758\n",
      "epoch 94; iter: 0; batch classifier loss: 0.369939; batch adversarial loss: 0.524982\n",
      "epoch 95; iter: 0; batch classifier loss: 0.434668; batch adversarial loss: 0.529007\n",
      "epoch 96; iter: 0; batch classifier loss: 0.413519; batch adversarial loss: 0.513650\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411720; batch adversarial loss: 0.545304\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364435; batch adversarial loss: 0.534023\n",
      "epoch 99; iter: 0; batch classifier loss: 0.379935; batch adversarial loss: 0.561719\n",
      "epoch 100; iter: 0; batch classifier loss: 0.286943; batch adversarial loss: 0.526868\n",
      "epoch 101; iter: 0; batch classifier loss: 0.409548; batch adversarial loss: 0.545532\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407780; batch adversarial loss: 0.579598\n",
      "epoch 103; iter: 0; batch classifier loss: 0.339348; batch adversarial loss: 0.560552\n",
      "epoch 104; iter: 0; batch classifier loss: 0.303338; batch adversarial loss: 0.625709\n",
      "epoch 105; iter: 0; batch classifier loss: 0.346587; batch adversarial loss: 0.666380\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328941; batch adversarial loss: 0.538832\n",
      "epoch 107; iter: 0; batch classifier loss: 0.321695; batch adversarial loss: 0.508271\n",
      "epoch 108; iter: 0; batch classifier loss: 0.339165; batch adversarial loss: 0.554514\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364157; batch adversarial loss: 0.556046\n",
      "epoch 110; iter: 0; batch classifier loss: 0.321327; batch adversarial loss: 0.592686\n",
      "epoch 111; iter: 0; batch classifier loss: 0.324966; batch adversarial loss: 0.563134\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414750; batch adversarial loss: 0.561371\n",
      "epoch 113; iter: 0; batch classifier loss: 0.336365; batch adversarial loss: 0.564656\n",
      "epoch 114; iter: 0; batch classifier loss: 0.421537; batch adversarial loss: 0.509064\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407649; batch adversarial loss: 0.527594\n",
      "epoch 116; iter: 0; batch classifier loss: 0.429621; batch adversarial loss: 0.508103\n",
      "epoch 117; iter: 0; batch classifier loss: 0.410545; batch adversarial loss: 0.489505\n",
      "epoch 118; iter: 0; batch classifier loss: 0.285486; batch adversarial loss: 0.488544\n",
      "epoch 119; iter: 0; batch classifier loss: 0.335747; batch adversarial loss: 0.536944\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338036; batch adversarial loss: 0.599643\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380727; batch adversarial loss: 0.609453\n",
      "epoch 122; iter: 0; batch classifier loss: 0.320693; batch adversarial loss: 0.563705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.256355; batch adversarial loss: 0.553921\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371191; batch adversarial loss: 0.526295\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389299; batch adversarial loss: 0.562487\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363928; batch adversarial loss: 0.508186\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382311; batch adversarial loss: 0.553991\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357012; batch adversarial loss: 0.489964\n",
      "epoch 129; iter: 0; batch classifier loss: 0.331727; batch adversarial loss: 0.536100\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425906; batch adversarial loss: 0.508254\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356767; batch adversarial loss: 0.555461\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312522; batch adversarial loss: 0.573701\n",
      "epoch 133; iter: 0; batch classifier loss: 0.300551; batch adversarial loss: 0.534040\n",
      "epoch 134; iter: 0; batch classifier loss: 0.433273; batch adversarial loss: 0.452572\n",
      "epoch 135; iter: 0; batch classifier loss: 0.326241; batch adversarial loss: 0.627684\n",
      "epoch 136; iter: 0; batch classifier loss: 0.435341; batch adversarial loss: 0.581164\n",
      "epoch 137; iter: 0; batch classifier loss: 0.345321; batch adversarial loss: 0.443724\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341906; batch adversarial loss: 0.534816\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358989; batch adversarial loss: 0.507767\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365117; batch adversarial loss: 0.545336\n",
      "epoch 141; iter: 0; batch classifier loss: 0.302609; batch adversarial loss: 0.553549\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375898; batch adversarial loss: 0.599882\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369218; batch adversarial loss: 0.591495\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302264; batch adversarial loss: 0.591756\n",
      "epoch 145; iter: 0; batch classifier loss: 0.329263; batch adversarial loss: 0.543557\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363677; batch adversarial loss: 0.515378\n",
      "epoch 147; iter: 0; batch classifier loss: 0.404213; batch adversarial loss: 0.497896\n",
      "epoch 148; iter: 0; batch classifier loss: 0.393122; batch adversarial loss: 0.517962\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362510; batch adversarial loss: 0.589744\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359415; batch adversarial loss: 0.599461\n",
      "epoch 151; iter: 0; batch classifier loss: 0.343294; batch adversarial loss: 0.506719\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377614; batch adversarial loss: 0.524048\n",
      "epoch 153; iter: 0; batch classifier loss: 0.307658; batch adversarial loss: 0.572579\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354328; batch adversarial loss: 0.489513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.272921; batch adversarial loss: 0.554385\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399010; batch adversarial loss: 0.580495\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328419; batch adversarial loss: 0.552631\n",
      "epoch 158; iter: 0; batch classifier loss: 0.377830; batch adversarial loss: 0.580591\n",
      "epoch 159; iter: 0; batch classifier loss: 0.424342; batch adversarial loss: 0.553259\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369981; batch adversarial loss: 0.580598\n",
      "epoch 161; iter: 0; batch classifier loss: 0.386023; batch adversarial loss: 0.571379\n",
      "epoch 162; iter: 0; batch classifier loss: 0.310373; batch adversarial loss: 0.507221\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321003; batch adversarial loss: 0.572728\n",
      "epoch 164; iter: 0; batch classifier loss: 0.308992; batch adversarial loss: 0.536032\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346541; batch adversarial loss: 0.608633\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346649; batch adversarial loss: 0.479256\n",
      "epoch 167; iter: 0; batch classifier loss: 0.388994; batch adversarial loss: 0.534170\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358504; batch adversarial loss: 0.580990\n",
      "epoch 169; iter: 0; batch classifier loss: 0.389508; batch adversarial loss: 0.562307\n",
      "epoch 170; iter: 0; batch classifier loss: 0.321062; batch adversarial loss: 0.516210\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351509; batch adversarial loss: 0.534874\n",
      "epoch 172; iter: 0; batch classifier loss: 0.301914; batch adversarial loss: 0.544421\n",
      "epoch 173; iter: 0; batch classifier loss: 0.391498; batch adversarial loss: 0.571117\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353990; batch adversarial loss: 0.543738\n",
      "epoch 175; iter: 0; batch classifier loss: 0.341138; batch adversarial loss: 0.592273\n",
      "epoch 176; iter: 0; batch classifier loss: 0.296552; batch adversarial loss: 0.487717\n",
      "epoch 177; iter: 0; batch classifier loss: 0.304054; batch adversarial loss: 0.543247\n",
      "epoch 178; iter: 0; batch classifier loss: 0.285501; batch adversarial loss: 0.533773\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379527; batch adversarial loss: 0.469045\n",
      "epoch 180; iter: 0; batch classifier loss: 0.285994; batch adversarial loss: 0.507269\n",
      "epoch 181; iter: 0; batch classifier loss: 0.290162; batch adversarial loss: 0.563004\n",
      "epoch 182; iter: 0; batch classifier loss: 0.256805; batch adversarial loss: 0.610724\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382778; batch adversarial loss: 0.526657\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366290; batch adversarial loss: 0.535403\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371039; batch adversarial loss: 0.479948\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312895; batch adversarial loss: 0.478657\n",
      "epoch 187; iter: 0; batch classifier loss: 0.267243; batch adversarial loss: 0.525244\n",
      "epoch 188; iter: 0; batch classifier loss: 0.268216; batch adversarial loss: 0.563932\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295467; batch adversarial loss: 0.469980\n",
      "epoch 190; iter: 0; batch classifier loss: 0.330024; batch adversarial loss: 0.606944\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354768; batch adversarial loss: 0.525993\n",
      "epoch 192; iter: 0; batch classifier loss: 0.271500; batch adversarial loss: 0.534335\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325581; batch adversarial loss: 0.496961\n",
      "epoch 194; iter: 0; batch classifier loss: 0.279134; batch adversarial loss: 0.533973\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327345; batch adversarial loss: 0.565058\n",
      "epoch 196; iter: 0; batch classifier loss: 0.292735; batch adversarial loss: 0.580642\n",
      "epoch 197; iter: 0; batch classifier loss: 0.265509; batch adversarial loss: 0.499654\n",
      "epoch 198; iter: 0; batch classifier loss: 0.294933; batch adversarial loss: 0.554327\n",
      "epoch 199; iter: 0; batch classifier loss: 0.313538; batch adversarial loss: 0.590872\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700825; batch adversarial loss: 0.766552\n",
      "epoch 1; iter: 0; batch classifier loss: 0.544325; batch adversarial loss: 0.732820\n",
      "epoch 2; iter: 0; batch classifier loss: 0.665026; batch adversarial loss: 0.692799\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534263; batch adversarial loss: 0.658666\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562158; batch adversarial loss: 0.654990\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633058; batch adversarial loss: 0.604542\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568860; batch adversarial loss: 0.648547\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489674; batch adversarial loss: 0.592006\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578013; batch adversarial loss: 0.578311\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508318; batch adversarial loss: 0.557941\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594142; batch adversarial loss: 0.589212\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547684; batch adversarial loss: 0.575282\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484373; batch adversarial loss: 0.558887\n",
      "epoch 13; iter: 0; batch classifier loss: 0.586409; batch adversarial loss: 0.577195\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521950; batch adversarial loss: 0.524537\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469713; batch adversarial loss: 0.545507\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541751; batch adversarial loss: 0.603781\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471747; batch adversarial loss: 0.504158\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519626; batch adversarial loss: 0.576716\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513394; batch adversarial loss: 0.642787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.540338; batch adversarial loss: 0.480541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.478311; batch adversarial loss: 0.602694\n",
      "epoch 22; iter: 0; batch classifier loss: 0.520131; batch adversarial loss: 0.553095\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485916; batch adversarial loss: 0.581130\n",
      "epoch 24; iter: 0; batch classifier loss: 0.417352; batch adversarial loss: 0.545560\n",
      "epoch 25; iter: 0; batch classifier loss: 0.445476; batch adversarial loss: 0.568125\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484173; batch adversarial loss: 0.545992\n",
      "epoch 27; iter: 0; batch classifier loss: 0.515715; batch adversarial loss: 0.539434\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435059; batch adversarial loss: 0.517001\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440077; batch adversarial loss: 0.579252\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457956; batch adversarial loss: 0.579891\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475215; batch adversarial loss: 0.530104\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449483; batch adversarial loss: 0.539075\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477299; batch adversarial loss: 0.527408\n",
      "epoch 34; iter: 0; batch classifier loss: 0.463351; batch adversarial loss: 0.504800\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447074; batch adversarial loss: 0.586776\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487768; batch adversarial loss: 0.519496\n",
      "epoch 37; iter: 0; batch classifier loss: 0.453808; batch adversarial loss: 0.579521\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424278; batch adversarial loss: 0.585807\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440104; batch adversarial loss: 0.544765\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444650; batch adversarial loss: 0.603239\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465972; batch adversarial loss: 0.474092\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443449; batch adversarial loss: 0.534807\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399839; batch adversarial loss: 0.481298\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411799; batch adversarial loss: 0.588920\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414327; batch adversarial loss: 0.533557\n",
      "epoch 46; iter: 0; batch classifier loss: 0.364488; batch adversarial loss: 0.580573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395064; batch adversarial loss: 0.572620\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473305; batch adversarial loss: 0.525995\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391064; batch adversarial loss: 0.579724\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394863; batch adversarial loss: 0.643156\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482803; batch adversarial loss: 0.624475\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470239; batch adversarial loss: 0.573974\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375361; batch adversarial loss: 0.529654\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435257; batch adversarial loss: 0.500287\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432700; batch adversarial loss: 0.515072\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394329; batch adversarial loss: 0.477781\n",
      "epoch 57; iter: 0; batch classifier loss: 0.394293; batch adversarial loss: 0.529080\n",
      "epoch 58; iter: 0; batch classifier loss: 0.415143; batch adversarial loss: 0.588830\n",
      "epoch 59; iter: 0; batch classifier loss: 0.311902; batch adversarial loss: 0.546134\n",
      "epoch 60; iter: 0; batch classifier loss: 0.472027; batch adversarial loss: 0.540340\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385540; batch adversarial loss: 0.497911\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479659; batch adversarial loss: 0.517073\n",
      "epoch 63; iter: 0; batch classifier loss: 0.382661; batch adversarial loss: 0.630213\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403965; batch adversarial loss: 0.592946\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374542; batch adversarial loss: 0.633963\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386302; batch adversarial loss: 0.555413\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460190; batch adversarial loss: 0.544199\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404660; batch adversarial loss: 0.634572\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442126; batch adversarial loss: 0.482332\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352680; batch adversarial loss: 0.582638\n",
      "epoch 71; iter: 0; batch classifier loss: 0.415109; batch adversarial loss: 0.528148\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427794; batch adversarial loss: 0.483791\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383170; batch adversarial loss: 0.544051\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408221; batch adversarial loss: 0.525673\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369306; batch adversarial loss: 0.564995\n",
      "epoch 76; iter: 0; batch classifier loss: 0.485689; batch adversarial loss: 0.542311\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375773; batch adversarial loss: 0.514714\n",
      "epoch 78; iter: 0; batch classifier loss: 0.469859; batch adversarial loss: 0.528714\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397067; batch adversarial loss: 0.519422\n",
      "epoch 80; iter: 0; batch classifier loss: 0.332959; batch adversarial loss: 0.572969\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391532; batch adversarial loss: 0.547036\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457921; batch adversarial loss: 0.592282\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377432; batch adversarial loss: 0.525840\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370939; batch adversarial loss: 0.517742\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401429; batch adversarial loss: 0.543201\n",
      "epoch 86; iter: 0; batch classifier loss: 0.333258; batch adversarial loss: 0.616931\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383268; batch adversarial loss: 0.541609\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413418; batch adversarial loss: 0.515088\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400056; batch adversarial loss: 0.581491\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348236; batch adversarial loss: 0.529643\n",
      "epoch 91; iter: 0; batch classifier loss: 0.287729; batch adversarial loss: 0.479090\n",
      "epoch 92; iter: 0; batch classifier loss: 0.437922; batch adversarial loss: 0.579409\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377729; batch adversarial loss: 0.570919\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406579; batch adversarial loss: 0.553716\n",
      "epoch 95; iter: 0; batch classifier loss: 0.404181; batch adversarial loss: 0.579462\n",
      "epoch 96; iter: 0; batch classifier loss: 0.346356; batch adversarial loss: 0.580524\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400030; batch adversarial loss: 0.545831\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358263; batch adversarial loss: 0.546367\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417516; batch adversarial loss: 0.496242\n",
      "epoch 100; iter: 0; batch classifier loss: 0.320693; batch adversarial loss: 0.578242\n",
      "epoch 101; iter: 0; batch classifier loss: 0.435217; batch adversarial loss: 0.634027\n",
      "epoch 102; iter: 0; batch classifier loss: 0.325659; batch adversarial loss: 0.535089\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364390; batch adversarial loss: 0.571164\n",
      "epoch 104; iter: 0; batch classifier loss: 0.343213; batch adversarial loss: 0.583508\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442982; batch adversarial loss: 0.643502\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333598; batch adversarial loss: 0.554301\n",
      "epoch 107; iter: 0; batch classifier loss: 0.332137; batch adversarial loss: 0.597956\n",
      "epoch 108; iter: 0; batch classifier loss: 0.437804; batch adversarial loss: 0.554680\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375464; batch adversarial loss: 0.507674\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411992; batch adversarial loss: 0.581504\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348763; batch adversarial loss: 0.547138\n",
      "epoch 112; iter: 0; batch classifier loss: 0.346000; batch adversarial loss: 0.534891\n",
      "epoch 113; iter: 0; batch classifier loss: 0.428349; batch adversarial loss: 0.607952\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362807; batch adversarial loss: 0.488672\n",
      "epoch 115; iter: 0; batch classifier loss: 0.395506; batch adversarial loss: 0.515839\n",
      "epoch 116; iter: 0; batch classifier loss: 0.349203; batch adversarial loss: 0.591291\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374090; batch adversarial loss: 0.500527\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375859; batch adversarial loss: 0.582866\n",
      "epoch 119; iter: 0; batch classifier loss: 0.310750; batch adversarial loss: 0.554353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.349803; batch adversarial loss: 0.441726\n",
      "epoch 121; iter: 0; batch classifier loss: 0.410538; batch adversarial loss: 0.532567\n",
      "epoch 122; iter: 0; batch classifier loss: 0.336774; batch adversarial loss: 0.571763\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403852; batch adversarial loss: 0.496692\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370509; batch adversarial loss: 0.617691\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379404; batch adversarial loss: 0.596549\n",
      "epoch 126; iter: 0; batch classifier loss: 0.434699; batch adversarial loss: 0.554438\n",
      "epoch 127; iter: 0; batch classifier loss: 0.437901; batch adversarial loss: 0.534969\n",
      "epoch 128; iter: 0; batch classifier loss: 0.320270; batch adversarial loss: 0.488138\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388377; batch adversarial loss: 0.517536\n",
      "epoch 130; iter: 0; batch classifier loss: 0.350315; batch adversarial loss: 0.503035\n",
      "epoch 131; iter: 0; batch classifier loss: 0.313958; batch adversarial loss: 0.615711\n",
      "epoch 132; iter: 0; batch classifier loss: 0.279822; batch adversarial loss: 0.588287\n",
      "epoch 133; iter: 0; batch classifier loss: 0.444492; batch adversarial loss: 0.558652\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379435; batch adversarial loss: 0.500144\n",
      "epoch 135; iter: 0; batch classifier loss: 0.393121; batch adversarial loss: 0.499200\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357745; batch adversarial loss: 0.499828\n",
      "epoch 137; iter: 0; batch classifier loss: 0.406596; batch adversarial loss: 0.582412\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363275; batch adversarial loss: 0.517982\n",
      "epoch 139; iter: 0; batch classifier loss: 0.404728; batch adversarial loss: 0.562099\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384574; batch adversarial loss: 0.555204\n",
      "epoch 141; iter: 0; batch classifier loss: 0.321360; batch adversarial loss: 0.573663\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393233; batch adversarial loss: 0.516893\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361954; batch adversarial loss: 0.533962\n",
      "epoch 144; iter: 0; batch classifier loss: 0.335856; batch adversarial loss: 0.590439\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340527; batch adversarial loss: 0.618922\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400148; batch adversarial loss: 0.618148\n",
      "epoch 147; iter: 0; batch classifier loss: 0.386953; batch adversarial loss: 0.475334\n",
      "epoch 148; iter: 0; batch classifier loss: 0.383716; batch adversarial loss: 0.507342\n",
      "epoch 149; iter: 0; batch classifier loss: 0.467167; batch adversarial loss: 0.479339\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370602; batch adversarial loss: 0.505335\n",
      "epoch 151; iter: 0; batch classifier loss: 0.383407; batch adversarial loss: 0.496866\n",
      "epoch 152; iter: 0; batch classifier loss: 0.328950; batch adversarial loss: 0.550944\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346848; batch adversarial loss: 0.526552\n",
      "epoch 154; iter: 0; batch classifier loss: 0.435681; batch adversarial loss: 0.497979\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379858; batch adversarial loss: 0.544541\n",
      "epoch 156; iter: 0; batch classifier loss: 0.369830; batch adversarial loss: 0.622249\n",
      "epoch 157; iter: 0; batch classifier loss: 0.378455; batch adversarial loss: 0.446328\n",
      "epoch 158; iter: 0; batch classifier loss: 0.426888; batch adversarial loss: 0.589479\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367041; batch adversarial loss: 0.536580\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337255; batch adversarial loss: 0.538221\n",
      "epoch 161; iter: 0; batch classifier loss: 0.364306; batch adversarial loss: 0.450192\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361497; batch adversarial loss: 0.573057\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343037; batch adversarial loss: 0.507142\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372295; batch adversarial loss: 0.638597\n",
      "epoch 165; iter: 0; batch classifier loss: 0.426094; batch adversarial loss: 0.535592\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365726; batch adversarial loss: 0.442470\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393355; batch adversarial loss: 0.607937\n",
      "epoch 168; iter: 0; batch classifier loss: 0.381135; batch adversarial loss: 0.582440\n",
      "epoch 169; iter: 0; batch classifier loss: 0.431195; batch adversarial loss: 0.488288\n",
      "epoch 170; iter: 0; batch classifier loss: 0.409484; batch adversarial loss: 0.516144\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392564; batch adversarial loss: 0.562673\n",
      "epoch 172; iter: 0; batch classifier loss: 0.449297; batch adversarial loss: 0.517291\n",
      "epoch 173; iter: 0; batch classifier loss: 0.388539; batch adversarial loss: 0.485728\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348126; batch adversarial loss: 0.463349\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342856; batch adversarial loss: 0.481703\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374884; batch adversarial loss: 0.526545\n",
      "epoch 177; iter: 0; batch classifier loss: 0.413144; batch adversarial loss: 0.561351\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350531; batch adversarial loss: 0.570970\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333725; batch adversarial loss: 0.533774\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362607; batch adversarial loss: 0.556275\n",
      "epoch 181; iter: 0; batch classifier loss: 0.427389; batch adversarial loss: 0.544100\n",
      "epoch 182; iter: 0; batch classifier loss: 0.458415; batch adversarial loss: 0.445711\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352980; batch adversarial loss: 0.497057\n",
      "epoch 184; iter: 0; batch classifier loss: 0.316869; batch adversarial loss: 0.581773\n",
      "epoch 185; iter: 0; batch classifier loss: 0.343138; batch adversarial loss: 0.593465\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365003; batch adversarial loss: 0.544194\n",
      "epoch 187; iter: 0; batch classifier loss: 0.474627; batch adversarial loss: 0.563897\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343975; batch adversarial loss: 0.563372\n",
      "epoch 189; iter: 0; batch classifier loss: 0.392439; batch adversarial loss: 0.578165\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357461; batch adversarial loss: 0.624957\n",
      "epoch 191; iter: 0; batch classifier loss: 0.415850; batch adversarial loss: 0.555501\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319033; batch adversarial loss: 0.508287\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350555; batch adversarial loss: 0.541712\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376674; batch adversarial loss: 0.432246\n",
      "epoch 195; iter: 0; batch classifier loss: 0.391374; batch adversarial loss: 0.552831\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343545; batch adversarial loss: 0.551554\n",
      "epoch 197; iter: 0; batch classifier loss: 0.407447; batch adversarial loss: 0.591086\n",
      "epoch 198; iter: 0; batch classifier loss: 0.344315; batch adversarial loss: 0.539088\n",
      "epoch 199; iter: 0; batch classifier loss: 0.430347; batch adversarial loss: 0.468321\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726686; batch adversarial loss: 0.601088\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628182; batch adversarial loss: 0.631488\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610045; batch adversarial loss: 0.650257\n",
      "epoch 3; iter: 0; batch classifier loss: 0.526207; batch adversarial loss: 0.655593\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569146; batch adversarial loss: 0.641196\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531297; batch adversarial loss: 0.618749\n",
      "epoch 6; iter: 0; batch classifier loss: 0.474552; batch adversarial loss: 0.580160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543889; batch adversarial loss: 0.577607\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499685; batch adversarial loss: 0.588877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544675; batch adversarial loss: 0.602653\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545932; batch adversarial loss: 0.513276\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509879; batch adversarial loss: 0.581832\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567592; batch adversarial loss: 0.606155\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578040; batch adversarial loss: 0.614535\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532773; batch adversarial loss: 0.568366\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528909; batch adversarial loss: 0.563236\n",
      "epoch 16; iter: 0; batch classifier loss: 0.587967; batch adversarial loss: 0.569519\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508299; batch adversarial loss: 0.531427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.483772; batch adversarial loss: 0.542840\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524494; batch adversarial loss: 0.531174\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485693; batch adversarial loss: 0.502999\n",
      "epoch 21; iter: 0; batch classifier loss: 0.463333; batch adversarial loss: 0.645486\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433082; batch adversarial loss: 0.509402\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465433; batch adversarial loss: 0.507243\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494305; batch adversarial loss: 0.521948\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446658; batch adversarial loss: 0.571320\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501381; batch adversarial loss: 0.536753\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500846; batch adversarial loss: 0.593376\n",
      "epoch 28; iter: 0; batch classifier loss: 0.458393; batch adversarial loss: 0.557380\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432208; batch adversarial loss: 0.560694\n",
      "epoch 30; iter: 0; batch classifier loss: 0.370012; batch adversarial loss: 0.546302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471066; batch adversarial loss: 0.502460\n",
      "epoch 32; iter: 0; batch classifier loss: 0.391301; batch adversarial loss: 0.517981\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461324; batch adversarial loss: 0.510552\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448021; batch adversarial loss: 0.510221\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429647; batch adversarial loss: 0.507588\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470920; batch adversarial loss: 0.546535\n",
      "epoch 37; iter: 0; batch classifier loss: 0.509049; batch adversarial loss: 0.543712\n",
      "epoch 38; iter: 0; batch classifier loss: 0.359664; batch adversarial loss: 0.526722\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454348; batch adversarial loss: 0.600369\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399630; batch adversarial loss: 0.545303\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451018; batch adversarial loss: 0.572011\n",
      "epoch 42; iter: 0; batch classifier loss: 0.413973; batch adversarial loss: 0.535247\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463185; batch adversarial loss: 0.535286\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431627; batch adversarial loss: 0.544506\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450407; batch adversarial loss: 0.562977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407235; batch adversarial loss: 0.535283\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417914; batch adversarial loss: 0.535112\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483981; batch adversarial loss: 0.535226\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447271; batch adversarial loss: 0.544483\n",
      "epoch 50; iter: 0; batch classifier loss: 0.378194; batch adversarial loss: 0.497061\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417043; batch adversarial loss: 0.499126\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455200; batch adversarial loss: 0.590488\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375101; batch adversarial loss: 0.525853\n",
      "epoch 54; iter: 0; batch classifier loss: 0.371275; batch adversarial loss: 0.517846\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425995; batch adversarial loss: 0.536084\n",
      "epoch 56; iter: 0; batch classifier loss: 0.375509; batch adversarial loss: 0.563717\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413882; batch adversarial loss: 0.592004\n",
      "epoch 58; iter: 0; batch classifier loss: 0.328820; batch adversarial loss: 0.506925\n",
      "epoch 59; iter: 0; batch classifier loss: 0.520224; batch adversarial loss: 0.553954\n",
      "epoch 60; iter: 0; batch classifier loss: 0.465058; batch adversarial loss: 0.572441\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432097; batch adversarial loss: 0.535164\n",
      "epoch 62; iter: 0; batch classifier loss: 0.385376; batch adversarial loss: 0.525928\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438345; batch adversarial loss: 0.610042\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390202; batch adversarial loss: 0.619481\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395712; batch adversarial loss: 0.516395\n",
      "epoch 66; iter: 0; batch classifier loss: 0.489642; batch adversarial loss: 0.544411\n",
      "epoch 67; iter: 0; batch classifier loss: 0.471845; batch adversarial loss: 0.544667\n",
      "epoch 68; iter: 0; batch classifier loss: 0.481869; batch adversarial loss: 0.525837\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397172; batch adversarial loss: 0.516293\n",
      "epoch 70; iter: 0; batch classifier loss: 0.504631; batch adversarial loss: 0.535026\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400609; batch adversarial loss: 0.544210\n",
      "epoch 72; iter: 0; batch classifier loss: 0.453593; batch adversarial loss: 0.469763\n",
      "epoch 73; iter: 0; batch classifier loss: 0.449478; batch adversarial loss: 0.478925\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414242; batch adversarial loss: 0.553635\n",
      "epoch 75; iter: 0; batch classifier loss: 0.302755; batch adversarial loss: 0.507396\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406684; batch adversarial loss: 0.563080\n",
      "epoch 77; iter: 0; batch classifier loss: 0.363170; batch adversarial loss: 0.479362\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350650; batch adversarial loss: 0.507114\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390272; batch adversarial loss: 0.610340\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418220; batch adversarial loss: 0.516353\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409583; batch adversarial loss: 0.572425\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384234; batch adversarial loss: 0.581497\n",
      "epoch 83; iter: 0; batch classifier loss: 0.424455; batch adversarial loss: 0.572437\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380536; batch adversarial loss: 0.544489\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389203; batch adversarial loss: 0.563098\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370593; batch adversarial loss: 0.517012\n",
      "epoch 87; iter: 0; batch classifier loss: 0.459462; batch adversarial loss: 0.553767\n",
      "epoch 88; iter: 0; batch classifier loss: 0.318451; batch adversarial loss: 0.637835\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393478; batch adversarial loss: 0.478987\n",
      "epoch 90; iter: 0; batch classifier loss: 0.328861; batch adversarial loss: 0.535139\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403817; batch adversarial loss: 0.571903\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406857; batch adversarial loss: 0.525412\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404940; batch adversarial loss: 0.507568\n",
      "epoch 94; iter: 0; batch classifier loss: 0.457378; batch adversarial loss: 0.590727\n",
      "epoch 95; iter: 0; batch classifier loss: 0.313971; batch adversarial loss: 0.488918\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377133; batch adversarial loss: 0.544599\n",
      "epoch 97; iter: 0; batch classifier loss: 0.417248; batch adversarial loss: 0.609803\n",
      "epoch 98; iter: 0; batch classifier loss: 0.350998; batch adversarial loss: 0.674846\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390409; batch adversarial loss: 0.572174\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374266; batch adversarial loss: 0.507718\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336923; batch adversarial loss: 0.563486\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369755; batch adversarial loss: 0.581613\n",
      "epoch 103; iter: 0; batch classifier loss: 0.415825; batch adversarial loss: 0.534912\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402007; batch adversarial loss: 0.525784\n",
      "epoch 105; iter: 0; batch classifier loss: 0.350272; batch adversarial loss: 0.590704\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362706; batch adversarial loss: 0.470534\n",
      "epoch 107; iter: 0; batch classifier loss: 0.326190; batch adversarial loss: 0.469995\n",
      "epoch 108; iter: 0; batch classifier loss: 0.444171; batch adversarial loss: 0.572767\n",
      "epoch 109; iter: 0; batch classifier loss: 0.444098; batch adversarial loss: 0.506933\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371079; batch adversarial loss: 0.497822\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403166; batch adversarial loss: 0.488338\n",
      "epoch 112; iter: 0; batch classifier loss: 0.346325; batch adversarial loss: 0.573367\n",
      "epoch 113; iter: 0; batch classifier loss: 0.483278; batch adversarial loss: 0.544718\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377835; batch adversarial loss: 0.562748\n",
      "epoch 115; iter: 0; batch classifier loss: 0.313511; batch adversarial loss: 0.516554\n",
      "epoch 116; iter: 0; batch classifier loss: 0.354176; batch adversarial loss: 0.526429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.340201; batch adversarial loss: 0.655432\n",
      "epoch 118; iter: 0; batch classifier loss: 0.396044; batch adversarial loss: 0.591132\n",
      "epoch 119; iter: 0; batch classifier loss: 0.486764; batch adversarial loss: 0.479913\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366280; batch adversarial loss: 0.562072\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379872; batch adversarial loss: 0.516580\n",
      "epoch 122; iter: 0; batch classifier loss: 0.319086; batch adversarial loss: 0.553607\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336105; batch adversarial loss: 0.544027\n",
      "epoch 124; iter: 0; batch classifier loss: 0.448755; batch adversarial loss: 0.544831\n",
      "epoch 125; iter: 0; batch classifier loss: 0.448528; batch adversarial loss: 0.498113\n",
      "epoch 126; iter: 0; batch classifier loss: 0.346657; batch adversarial loss: 0.526040\n",
      "epoch 127; iter: 0; batch classifier loss: 0.449168; batch adversarial loss: 0.572612\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373251; batch adversarial loss: 0.534946\n",
      "epoch 129; iter: 0; batch classifier loss: 0.381063; batch adversarial loss: 0.460583\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386223; batch adversarial loss: 0.544693\n",
      "epoch 131; iter: 0; batch classifier loss: 0.396879; batch adversarial loss: 0.525986\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363521; batch adversarial loss: 0.582056\n",
      "epoch 133; iter: 0; batch classifier loss: 0.414444; batch adversarial loss: 0.498610\n",
      "epoch 134; iter: 0; batch classifier loss: 0.445700; batch adversarial loss: 0.497939\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358861; batch adversarial loss: 0.525692\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357927; batch adversarial loss: 0.507170\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407783; batch adversarial loss: 0.460637\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349087; batch adversarial loss: 0.535656\n",
      "epoch 139; iter: 0; batch classifier loss: 0.420379; batch adversarial loss: 0.544586\n",
      "epoch 140; iter: 0; batch classifier loss: 0.426855; batch adversarial loss: 0.525718\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326925; batch adversarial loss: 0.545130\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338272; batch adversarial loss: 0.479171\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414141; batch adversarial loss: 0.515629\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302065; batch adversarial loss: 0.600441\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332569; batch adversarial loss: 0.470193\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404420; batch adversarial loss: 0.534938\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374391; batch adversarial loss: 0.562805\n",
      "epoch 148; iter: 0; batch classifier loss: 0.421117; batch adversarial loss: 0.526027\n",
      "epoch 149; iter: 0; batch classifier loss: 0.313029; batch adversarial loss: 0.525967\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364784; batch adversarial loss: 0.582239\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391910; batch adversarial loss: 0.563451\n",
      "epoch 152; iter: 0; batch classifier loss: 0.337275; batch adversarial loss: 0.572576\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369668; batch adversarial loss: 0.488768\n",
      "epoch 154; iter: 0; batch classifier loss: 0.341041; batch adversarial loss: 0.609405\n",
      "epoch 155; iter: 0; batch classifier loss: 0.446963; batch adversarial loss: 0.684636\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363379; batch adversarial loss: 0.506974\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393910; batch adversarial loss: 0.563250\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386517; batch adversarial loss: 0.488416\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375147; batch adversarial loss: 0.535398\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406097; batch adversarial loss: 0.534794\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329924; batch adversarial loss: 0.591188\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329439; batch adversarial loss: 0.591202\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334844; batch adversarial loss: 0.572806\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368757; batch adversarial loss: 0.553580\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344103; batch adversarial loss: 0.553748\n",
      "epoch 166; iter: 0; batch classifier loss: 0.399614; batch adversarial loss: 0.487749\n",
      "epoch 167; iter: 0; batch classifier loss: 0.288553; batch adversarial loss: 0.562174\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363819; batch adversarial loss: 0.573016\n",
      "epoch 169; iter: 0; batch classifier loss: 0.361331; batch adversarial loss: 0.544194\n",
      "epoch 170; iter: 0; batch classifier loss: 0.302018; batch adversarial loss: 0.571166\n",
      "epoch 171; iter: 0; batch classifier loss: 0.371623; batch adversarial loss: 0.506996\n",
      "epoch 172; iter: 0; batch classifier loss: 0.369305; batch adversarial loss: 0.441955\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385644; batch adversarial loss: 0.497533\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400927; batch adversarial loss: 0.553783\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322025; batch adversarial loss: 0.573059\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400248; batch adversarial loss: 0.488602\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344773; batch adversarial loss: 0.591550\n",
      "epoch 178; iter: 0; batch classifier loss: 0.329261; batch adversarial loss: 0.506708\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343109; batch adversarial loss: 0.517555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.320379; batch adversarial loss: 0.471620\n",
      "epoch 181; iter: 0; batch classifier loss: 0.335544; batch adversarial loss: 0.555024\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358610; batch adversarial loss: 0.573498\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370159; batch adversarial loss: 0.554127\n",
      "epoch 184; iter: 0; batch classifier loss: 0.403719; batch adversarial loss: 0.544727\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389846; batch adversarial loss: 0.572268\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414473; batch adversarial loss: 0.506542\n",
      "epoch 187; iter: 0; batch classifier loss: 0.406176; batch adversarial loss: 0.469950\n",
      "epoch 188; iter: 0; batch classifier loss: 0.460766; batch adversarial loss: 0.600902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335001; batch adversarial loss: 0.404853\n",
      "epoch 190; iter: 0; batch classifier loss: 0.373784; batch adversarial loss: 0.534969\n",
      "epoch 191; iter: 0; batch classifier loss: 0.334640; batch adversarial loss: 0.628295\n",
      "epoch 192; iter: 0; batch classifier loss: 0.425421; batch adversarial loss: 0.562811\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360023; batch adversarial loss: 0.544488\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341193; batch adversarial loss: 0.525899\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342970; batch adversarial loss: 0.544449\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362595; batch adversarial loss: 0.543816\n",
      "epoch 197; iter: 0; batch classifier loss: 0.278421; batch adversarial loss: 0.534465\n",
      "epoch 198; iter: 0; batch classifier loss: 0.422676; batch adversarial loss: 0.619001\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348988; batch adversarial loss: 0.442524\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704360; batch adversarial loss: 0.660911\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595728; batch adversarial loss: 0.646163\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580075; batch adversarial loss: 0.619902\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581331; batch adversarial loss: 0.612068\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541211; batch adversarial loss: 0.639445\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532303; batch adversarial loss: 0.611086\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538134; batch adversarial loss: 0.572218\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564001; batch adversarial loss: 0.577927\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560904; batch adversarial loss: 0.585190\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487556; batch adversarial loss: 0.595877\n",
      "epoch 10; iter: 0; batch classifier loss: 0.596006; batch adversarial loss: 0.580409\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556643; batch adversarial loss: 0.602956\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558600; batch adversarial loss: 0.589929\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559483; batch adversarial loss: 0.586243\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524988; batch adversarial loss: 0.570537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.492570; batch adversarial loss: 0.522524\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505486; batch adversarial loss: 0.595761\n",
      "epoch 17; iter: 0; batch classifier loss: 0.446037; batch adversarial loss: 0.517457\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540164; batch adversarial loss: 0.516706\n",
      "epoch 19; iter: 0; batch classifier loss: 0.449296; batch adversarial loss: 0.552414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499343; batch adversarial loss: 0.521312\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519020; batch adversarial loss: 0.622891\n",
      "epoch 22; iter: 0; batch classifier loss: 0.542511; batch adversarial loss: 0.563175\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461828; batch adversarial loss: 0.576479\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478733; batch adversarial loss: 0.554271\n",
      "epoch 25; iter: 0; batch classifier loss: 0.468704; batch adversarial loss: 0.605651\n",
      "epoch 26; iter: 0; batch classifier loss: 0.525264; batch adversarial loss: 0.524809\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495463; batch adversarial loss: 0.558842\n",
      "epoch 28; iter: 0; batch classifier loss: 0.518432; batch adversarial loss: 0.589183\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462468; batch adversarial loss: 0.586062\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438129; batch adversarial loss: 0.494246\n",
      "epoch 31; iter: 0; batch classifier loss: 0.549459; batch adversarial loss: 0.577862\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450069; batch adversarial loss: 0.546032\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456401; batch adversarial loss: 0.502195\n",
      "epoch 34; iter: 0; batch classifier loss: 0.386863; batch adversarial loss: 0.591448\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485690; batch adversarial loss: 0.582017\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433570; batch adversarial loss: 0.535473\n",
      "epoch 37; iter: 0; batch classifier loss: 0.405680; batch adversarial loss: 0.570703\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468749; batch adversarial loss: 0.537284\n",
      "epoch 39; iter: 0; batch classifier loss: 0.510458; batch adversarial loss: 0.546884\n",
      "epoch 40; iter: 0; batch classifier loss: 0.378236; batch adversarial loss: 0.599204\n",
      "epoch 41; iter: 0; batch classifier loss: 0.369601; batch adversarial loss: 0.489649\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445149; batch adversarial loss: 0.462141\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482417; batch adversarial loss: 0.555170\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439514; batch adversarial loss: 0.498593\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455995; batch adversarial loss: 0.526276\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406686; batch adversarial loss: 0.497799\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416460; batch adversarial loss: 0.471090\n",
      "epoch 48; iter: 0; batch classifier loss: 0.474903; batch adversarial loss: 0.489099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418668; batch adversarial loss: 0.460877\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449840; batch adversarial loss: 0.535486\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462594; batch adversarial loss: 0.517558\n",
      "epoch 52; iter: 0; batch classifier loss: 0.489110; batch adversarial loss: 0.487957\n",
      "epoch 53; iter: 0; batch classifier loss: 0.369530; batch adversarial loss: 0.516588\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427983; batch adversarial loss: 0.553042\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413304; batch adversarial loss: 0.543755\n",
      "epoch 56; iter: 0; batch classifier loss: 0.385983; batch adversarial loss: 0.534247\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454050; batch adversarial loss: 0.544261\n",
      "epoch 58; iter: 0; batch classifier loss: 0.470583; batch adversarial loss: 0.523322\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407495; batch adversarial loss: 0.571802\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439924; batch adversarial loss: 0.593364\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445379; batch adversarial loss: 0.556328\n",
      "epoch 62; iter: 0; batch classifier loss: 0.456044; batch adversarial loss: 0.535371\n",
      "epoch 63; iter: 0; batch classifier loss: 0.329568; batch adversarial loss: 0.563846\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429805; batch adversarial loss: 0.514820\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449871; batch adversarial loss: 0.578110\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417805; batch adversarial loss: 0.479079\n",
      "epoch 67; iter: 0; batch classifier loss: 0.309178; batch adversarial loss: 0.450429\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393096; batch adversarial loss: 0.630832\n",
      "epoch 69; iter: 0; batch classifier loss: 0.360150; batch adversarial loss: 0.554997\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414138; batch adversarial loss: 0.462758\n",
      "epoch 71; iter: 0; batch classifier loss: 0.401683; batch adversarial loss: 0.527018\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416775; batch adversarial loss: 0.544378\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421563; batch adversarial loss: 0.516931\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389685; batch adversarial loss: 0.609946\n",
      "epoch 75; iter: 0; batch classifier loss: 0.331228; batch adversarial loss: 0.498844\n",
      "epoch 76; iter: 0; batch classifier loss: 0.472062; batch adversarial loss: 0.636683\n",
      "epoch 77; iter: 0; batch classifier loss: 0.449292; batch adversarial loss: 0.535569\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350141; batch adversarial loss: 0.479948\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376501; batch adversarial loss: 0.553435\n",
      "epoch 80; iter: 0; batch classifier loss: 0.345170; batch adversarial loss: 0.581841\n",
      "epoch 81; iter: 0; batch classifier loss: 0.447029; batch adversarial loss: 0.638673\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414172; batch adversarial loss: 0.609568\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422226; batch adversarial loss: 0.554035\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409109; batch adversarial loss: 0.571747\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431882; batch adversarial loss: 0.581780\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414376; batch adversarial loss: 0.478862\n",
      "epoch 87; iter: 0; batch classifier loss: 0.403784; batch adversarial loss: 0.600653\n",
      "epoch 88; iter: 0; batch classifier loss: 0.286270; batch adversarial loss: 0.526331\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452403; batch adversarial loss: 0.489579\n",
      "epoch 90; iter: 0; batch classifier loss: 0.493592; batch adversarial loss: 0.469631\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372652; batch adversarial loss: 0.489241\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394832; batch adversarial loss: 0.581595\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392862; batch adversarial loss: 0.507673\n",
      "epoch 94; iter: 0; batch classifier loss: 0.409920; batch adversarial loss: 0.571980\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395462; batch adversarial loss: 0.590871\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364904; batch adversarial loss: 0.627696\n",
      "epoch 97; iter: 0; batch classifier loss: 0.373996; batch adversarial loss: 0.581744\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400562; batch adversarial loss: 0.618629\n",
      "epoch 99; iter: 0; batch classifier loss: 0.472018; batch adversarial loss: 0.516716\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408843; batch adversarial loss: 0.525877\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421296; batch adversarial loss: 0.507221\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372774; batch adversarial loss: 0.563048\n",
      "epoch 103; iter: 0; batch classifier loss: 0.324466; batch adversarial loss: 0.535298\n",
      "epoch 104; iter: 0; batch classifier loss: 0.359466; batch adversarial loss: 0.526000\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369197; batch adversarial loss: 0.619140\n",
      "epoch 106; iter: 0; batch classifier loss: 0.305224; batch adversarial loss: 0.563404\n",
      "epoch 107; iter: 0; batch classifier loss: 0.330728; batch adversarial loss: 0.544289\n",
      "epoch 108; iter: 0; batch classifier loss: 0.425210; batch adversarial loss: 0.525750\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406151; batch adversarial loss: 0.507381\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377997; batch adversarial loss: 0.507317\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369697; batch adversarial loss: 0.600791\n",
      "epoch 112; iter: 0; batch classifier loss: 0.504133; batch adversarial loss: 0.544297\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374850; batch adversarial loss: 0.479206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.351565; batch adversarial loss: 0.562657\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348574; batch adversarial loss: 0.552975\n",
      "epoch 116; iter: 0; batch classifier loss: 0.342353; batch adversarial loss: 0.506147\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365088; batch adversarial loss: 0.523829\n",
      "epoch 118; iter: 0; batch classifier loss: 0.328151; batch adversarial loss: 0.535779\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380703; batch adversarial loss: 0.507683\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337862; batch adversarial loss: 0.610269\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395173; batch adversarial loss: 0.544496\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356527; batch adversarial loss: 0.563225\n",
      "epoch 123; iter: 0; batch classifier loss: 0.456452; batch adversarial loss: 0.545000\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379421; batch adversarial loss: 0.627806\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371464; batch adversarial loss: 0.544055\n",
      "epoch 126; iter: 0; batch classifier loss: 0.461674; batch adversarial loss: 0.469254\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378343; batch adversarial loss: 0.591144\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353207; batch adversarial loss: 0.563035\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402580; batch adversarial loss: 0.581236\n",
      "epoch 130; iter: 0; batch classifier loss: 0.304378; batch adversarial loss: 0.600474\n",
      "epoch 131; iter: 0; batch classifier loss: 0.424884; batch adversarial loss: 0.554629\n",
      "epoch 132; iter: 0; batch classifier loss: 0.410875; batch adversarial loss: 0.517326\n",
      "epoch 133; iter: 0; batch classifier loss: 0.332663; batch adversarial loss: 0.627541\n",
      "epoch 134; iter: 0; batch classifier loss: 0.438638; batch adversarial loss: 0.535438\n",
      "epoch 135; iter: 0; batch classifier loss: 0.379573; batch adversarial loss: 0.627600\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370458; batch adversarial loss: 0.525889\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407523; batch adversarial loss: 0.665404\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379841; batch adversarial loss: 0.544282\n",
      "epoch 139; iter: 0; batch classifier loss: 0.448987; batch adversarial loss: 0.562939\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396141; batch adversarial loss: 0.590851\n",
      "epoch 141; iter: 0; batch classifier loss: 0.408680; batch adversarial loss: 0.600405\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358194; batch adversarial loss: 0.460954\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385232; batch adversarial loss: 0.581314\n",
      "epoch 144; iter: 0; batch classifier loss: 0.353290; batch adversarial loss: 0.553465\n",
      "epoch 145; iter: 0; batch classifier loss: 0.413453; batch adversarial loss: 0.507099\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352198; batch adversarial loss: 0.536019\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410024; batch adversarial loss: 0.489535\n",
      "epoch 148; iter: 0; batch classifier loss: 0.382712; batch adversarial loss: 0.515810\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343810; batch adversarial loss: 0.460489\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382283; batch adversarial loss: 0.479333\n",
      "epoch 151; iter: 0; batch classifier loss: 0.411207; batch adversarial loss: 0.535475\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364097; batch adversarial loss: 0.525745\n",
      "epoch 153; iter: 0; batch classifier loss: 0.429204; batch adversarial loss: 0.506891\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320626; batch adversarial loss: 0.544575\n",
      "epoch 155; iter: 0; batch classifier loss: 0.443152; batch adversarial loss: 0.563152\n",
      "epoch 156; iter: 0; batch classifier loss: 0.409548; batch adversarial loss: 0.544400\n",
      "epoch 157; iter: 0; batch classifier loss: 0.391027; batch adversarial loss: 0.609515\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347441; batch adversarial loss: 0.544479\n",
      "epoch 159; iter: 0; batch classifier loss: 0.436499; batch adversarial loss: 0.497737\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350860; batch adversarial loss: 0.544631\n",
      "epoch 161; iter: 0; batch classifier loss: 0.314999; batch adversarial loss: 0.507070\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371245; batch adversarial loss: 0.498384\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340955; batch adversarial loss: 0.497943\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385159; batch adversarial loss: 0.543259\n",
      "epoch 165; iter: 0; batch classifier loss: 0.312891; batch adversarial loss: 0.534628\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377547; batch adversarial loss: 0.526142\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370848; batch adversarial loss: 0.497730\n",
      "epoch 168; iter: 0; batch classifier loss: 0.448577; batch adversarial loss: 0.554108\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321118; batch adversarial loss: 0.498217\n",
      "epoch 170; iter: 0; batch classifier loss: 0.460027; batch adversarial loss: 0.545275\n",
      "epoch 171; iter: 0; batch classifier loss: 0.429563; batch adversarial loss: 0.572063\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359658; batch adversarial loss: 0.563865\n",
      "epoch 173; iter: 0; batch classifier loss: 0.398424; batch adversarial loss: 0.582213\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396475; batch adversarial loss: 0.544311\n",
      "epoch 175; iter: 0; batch classifier loss: 0.433090; batch adversarial loss: 0.545091\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369918; batch adversarial loss: 0.600741\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381659; batch adversarial loss: 0.572483\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369470; batch adversarial loss: 0.544669\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406831; batch adversarial loss: 0.610685\n",
      "epoch 180; iter: 0; batch classifier loss: 0.419528; batch adversarial loss: 0.516309\n",
      "epoch 181; iter: 0; batch classifier loss: 0.306885; batch adversarial loss: 0.571884\n",
      "epoch 182; iter: 0; batch classifier loss: 0.297357; batch adversarial loss: 0.591705\n",
      "epoch 183; iter: 0; batch classifier loss: 0.413534; batch adversarial loss: 0.572667\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379751; batch adversarial loss: 0.554318\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371547; batch adversarial loss: 0.582043\n",
      "epoch 186; iter: 0; batch classifier loss: 0.307326; batch adversarial loss: 0.563193\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369296; batch adversarial loss: 0.562996\n",
      "epoch 188; iter: 0; batch classifier loss: 0.412372; batch adversarial loss: 0.563380\n",
      "epoch 189; iter: 0; batch classifier loss: 0.393063; batch adversarial loss: 0.591407\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338910; batch adversarial loss: 0.581811\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323927; batch adversarial loss: 0.507130\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365823; batch adversarial loss: 0.600427\n",
      "epoch 193; iter: 0; batch classifier loss: 0.271097; batch adversarial loss: 0.525911\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362168; batch adversarial loss: 0.553700\n",
      "epoch 195; iter: 0; batch classifier loss: 0.260363; batch adversarial loss: 0.507362\n",
      "epoch 196; iter: 0; batch classifier loss: 0.388084; batch adversarial loss: 0.591054\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332942; batch adversarial loss: 0.544539\n",
      "epoch 198; iter: 0; batch classifier loss: 0.290148; batch adversarial loss: 0.553982\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381529; batch adversarial loss: 0.553706\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662740; batch adversarial loss: 0.589455\n",
      "epoch 1; iter: 0; batch classifier loss: 0.646692; batch adversarial loss: 0.699918\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625547; batch adversarial loss: 0.701609\n",
      "epoch 3; iter: 0; batch classifier loss: 0.689104; batch adversarial loss: 0.697279\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601858; batch adversarial loss: 0.653093\n",
      "epoch 5; iter: 0; batch classifier loss: 0.499319; batch adversarial loss: 0.690136\n",
      "epoch 6; iter: 0; batch classifier loss: 0.646840; batch adversarial loss: 0.643164\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587170; batch adversarial loss: 0.624335\n",
      "epoch 8; iter: 0; batch classifier loss: 0.614617; batch adversarial loss: 0.628076\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585381; batch adversarial loss: 0.597118\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533873; batch adversarial loss: 0.559011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.572545; batch adversarial loss: 0.552048\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510625; batch adversarial loss: 0.622032\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507298; batch adversarial loss: 0.570064\n",
      "epoch 14; iter: 0; batch classifier loss: 0.585870; batch adversarial loss: 0.508549\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519645; batch adversarial loss: 0.510197\n",
      "epoch 16; iter: 0; batch classifier loss: 0.455254; batch adversarial loss: 0.502932\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576524; batch adversarial loss: 0.539801\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458034; batch adversarial loss: 0.621660\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508201; batch adversarial loss: 0.574660\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436020; batch adversarial loss: 0.528657\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471049; batch adversarial loss: 0.572471\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489122; batch adversarial loss: 0.512482\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458486; batch adversarial loss: 0.572230\n",
      "epoch 24; iter: 0; batch classifier loss: 0.472721; batch adversarial loss: 0.439723\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489576; batch adversarial loss: 0.528317\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479095; batch adversarial loss: 0.606669\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445922; batch adversarial loss: 0.693228\n",
      "epoch 28; iter: 0; batch classifier loss: 0.559983; batch adversarial loss: 0.571564\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474307; batch adversarial loss: 0.554235\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510763; batch adversarial loss: 0.571228\n",
      "epoch 31; iter: 0; batch classifier loss: 0.527296; batch adversarial loss: 0.481260\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433356; batch adversarial loss: 0.481087\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425427; batch adversarial loss: 0.593673\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426906; batch adversarial loss: 0.588320\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511829; batch adversarial loss: 0.545149\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422537; batch adversarial loss: 0.561357\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422706; batch adversarial loss: 0.525489\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451952; batch adversarial loss: 0.487234\n",
      "epoch 39; iter: 0; batch classifier loss: 0.389562; batch adversarial loss: 0.556491\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429831; batch adversarial loss: 0.546608\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402823; batch adversarial loss: 0.501438\n",
      "epoch 42; iter: 0; batch classifier loss: 0.525282; batch adversarial loss: 0.499734\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407883; batch adversarial loss: 0.553426\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463591; batch adversarial loss: 0.570133\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397086; batch adversarial loss: 0.498838\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432450; batch adversarial loss: 0.570282\n",
      "epoch 47; iter: 0; batch classifier loss: 0.545077; batch adversarial loss: 0.544759\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432061; batch adversarial loss: 0.571574\n",
      "epoch 49; iter: 0; batch classifier loss: 0.525808; batch adversarial loss: 0.580151\n",
      "epoch 50; iter: 0; batch classifier loss: 0.488613; batch adversarial loss: 0.615622\n",
      "epoch 51; iter: 0; batch classifier loss: 0.479852; batch adversarial loss: 0.526853\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469730; batch adversarial loss: 0.500530\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408302; batch adversarial loss: 0.490380\n",
      "epoch 54; iter: 0; batch classifier loss: 0.377119; batch adversarial loss: 0.623834\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397855; batch adversarial loss: 0.508385\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436875; batch adversarial loss: 0.579401\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423135; batch adversarial loss: 0.563825\n",
      "epoch 58; iter: 0; batch classifier loss: 0.376997; batch adversarial loss: 0.590721\n",
      "epoch 59; iter: 0; batch classifier loss: 0.434341; batch adversarial loss: 0.508186\n",
      "epoch 60; iter: 0; batch classifier loss: 0.491450; batch adversarial loss: 0.644779\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432225; batch adversarial loss: 0.489708\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401288; batch adversarial loss: 0.580352\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459515; batch adversarial loss: 0.580658\n",
      "epoch 64; iter: 0; batch classifier loss: 0.469642; batch adversarial loss: 0.598338\n",
      "epoch 65; iter: 0; batch classifier loss: 0.471372; batch adversarial loss: 0.581508\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425087; batch adversarial loss: 0.470493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407843; batch adversarial loss: 0.535232\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413057; batch adversarial loss: 0.581479\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377343; batch adversarial loss: 0.581158\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396976; batch adversarial loss: 0.553782\n",
      "epoch 71; iter: 0; batch classifier loss: 0.360729; batch adversarial loss: 0.553485\n",
      "epoch 72; iter: 0; batch classifier loss: 0.359129; batch adversarial loss: 0.462932\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393067; batch adversarial loss: 0.490343\n",
      "epoch 74; iter: 0; batch classifier loss: 0.456395; batch adversarial loss: 0.526242\n",
      "epoch 75; iter: 0; batch classifier loss: 0.390217; batch adversarial loss: 0.507934\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371933; batch adversarial loss: 0.607500\n",
      "epoch 77; iter: 0; batch classifier loss: 0.444533; batch adversarial loss: 0.561535\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347070; batch adversarial loss: 0.510579\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370195; batch adversarial loss: 0.509346\n",
      "epoch 80; iter: 0; batch classifier loss: 0.478815; batch adversarial loss: 0.577295\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422083; batch adversarial loss: 0.643119\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342836; batch adversarial loss: 0.555423\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398328; batch adversarial loss: 0.526736\n",
      "epoch 84; iter: 0; batch classifier loss: 0.462056; batch adversarial loss: 0.572809\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361313; batch adversarial loss: 0.634997\n",
      "epoch 86; iter: 0; batch classifier loss: 0.326223; batch adversarial loss: 0.564659\n",
      "epoch 87; iter: 0; batch classifier loss: 0.318870; batch adversarial loss: 0.572457\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362455; batch adversarial loss: 0.445850\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410103; batch adversarial loss: 0.518234\n",
      "epoch 90; iter: 0; batch classifier loss: 0.400840; batch adversarial loss: 0.572453\n",
      "epoch 91; iter: 0; batch classifier loss: 0.331263; batch adversarial loss: 0.489079\n",
      "epoch 92; iter: 0; batch classifier loss: 0.443213; batch adversarial loss: 0.580948\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393383; batch adversarial loss: 0.600294\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348011; batch adversarial loss: 0.517225\n",
      "epoch 95; iter: 0; batch classifier loss: 0.367697; batch adversarial loss: 0.553394\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419591; batch adversarial loss: 0.517083\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378691; batch adversarial loss: 0.526191\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406613; batch adversarial loss: 0.553747\n",
      "epoch 99; iter: 0; batch classifier loss: 0.389763; batch adversarial loss: 0.572733\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413975; batch adversarial loss: 0.608915\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395509; batch adversarial loss: 0.590301\n",
      "epoch 102; iter: 0; batch classifier loss: 0.356052; batch adversarial loss: 0.526192\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369257; batch adversarial loss: 0.581050\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434478; batch adversarial loss: 0.499337\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394101; batch adversarial loss: 0.553365\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434390; batch adversarial loss: 0.489488\n",
      "epoch 107; iter: 0; batch classifier loss: 0.443734; batch adversarial loss: 0.561239\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355152; batch adversarial loss: 0.570475\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351595; batch adversarial loss: 0.581305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.433786; batch adversarial loss: 0.525407\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369378; batch adversarial loss: 0.527735\n",
      "epoch 112; iter: 0; batch classifier loss: 0.426296; batch adversarial loss: 0.542189\n",
      "epoch 113; iter: 0; batch classifier loss: 0.312983; batch adversarial loss: 0.509141\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373838; batch adversarial loss: 0.497516\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328067; batch adversarial loss: 0.525025\n",
      "epoch 116; iter: 0; batch classifier loss: 0.452392; batch adversarial loss: 0.488302\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407827; batch adversarial loss: 0.527614\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342322; batch adversarial loss: 0.518492\n",
      "epoch 119; iter: 0; batch classifier loss: 0.453447; batch adversarial loss: 0.583147\n",
      "epoch 120; iter: 0; batch classifier loss: 0.426005; batch adversarial loss: 0.619793\n",
      "epoch 121; iter: 0; batch classifier loss: 0.425842; batch adversarial loss: 0.626820\n",
      "epoch 122; iter: 0; batch classifier loss: 0.375272; batch adversarial loss: 0.517013\n",
      "epoch 123; iter: 0; batch classifier loss: 0.430836; batch adversarial loss: 0.525934\n",
      "epoch 124; iter: 0; batch classifier loss: 0.444012; batch adversarial loss: 0.510006\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355789; batch adversarial loss: 0.515898\n",
      "epoch 126; iter: 0; batch classifier loss: 0.439936; batch adversarial loss: 0.624574\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388059; batch adversarial loss: 0.578424\n",
      "epoch 128; iter: 0; batch classifier loss: 0.428753; batch adversarial loss: 0.519753\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367777; batch adversarial loss: 0.526745\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357967; batch adversarial loss: 0.515390\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321966; batch adversarial loss: 0.480649\n",
      "epoch 132; iter: 0; batch classifier loss: 0.410611; batch adversarial loss: 0.589505\n",
      "epoch 133; iter: 0; batch classifier loss: 0.286228; batch adversarial loss: 0.590871\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368473; batch adversarial loss: 0.654663\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408980; batch adversarial loss: 0.553182\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357279; batch adversarial loss: 0.598454\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386489; batch adversarial loss: 0.535453\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355871; batch adversarial loss: 0.562491\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416574; batch adversarial loss: 0.517271\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364024; batch adversarial loss: 0.553679\n",
      "epoch 141; iter: 0; batch classifier loss: 0.310601; batch adversarial loss: 0.563029\n",
      "epoch 142; iter: 0; batch classifier loss: 0.458995; batch adversarial loss: 0.563168\n",
      "epoch 143; iter: 0; batch classifier loss: 0.417792; batch adversarial loss: 0.562807\n",
      "epoch 144; iter: 0; batch classifier loss: 0.310928; batch adversarial loss: 0.636413\n",
      "epoch 145; iter: 0; batch classifier loss: 0.424136; batch adversarial loss: 0.590788\n",
      "epoch 146; iter: 0; batch classifier loss: 0.405044; batch adversarial loss: 0.572403\n",
      "epoch 147; iter: 0; batch classifier loss: 0.396935; batch adversarial loss: 0.508562\n",
      "epoch 148; iter: 0; batch classifier loss: 0.380676; batch adversarial loss: 0.517884\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379851; batch adversarial loss: 0.572346\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354620; batch adversarial loss: 0.544760\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382030; batch adversarial loss: 0.571943\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395779; batch adversarial loss: 0.617636\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393324; batch adversarial loss: 0.526942\n",
      "epoch 154; iter: 0; batch classifier loss: 0.453081; batch adversarial loss: 0.599553\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355184; batch adversarial loss: 0.571775\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391377; batch adversarial loss: 0.535387\n",
      "epoch 157; iter: 0; batch classifier loss: 0.433444; batch adversarial loss: 0.490295\n",
      "epoch 158; iter: 0; batch classifier loss: 0.428263; batch adversarial loss: 0.562639\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361454; batch adversarial loss: 0.562165\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318769; batch adversarial loss: 0.517866\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412059; batch adversarial loss: 0.589541\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385716; batch adversarial loss: 0.562425\n",
      "epoch 163; iter: 0; batch classifier loss: 0.281132; batch adversarial loss: 0.544470\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361675; batch adversarial loss: 0.499031\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394419; batch adversarial loss: 0.599722\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357383; batch adversarial loss: 0.526188\n",
      "epoch 167; iter: 0; batch classifier loss: 0.412900; batch adversarial loss: 0.507654\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330228; batch adversarial loss: 0.570929\n",
      "epoch 169; iter: 0; batch classifier loss: 0.402635; batch adversarial loss: 0.617068\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345856; batch adversarial loss: 0.526760\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373160; batch adversarial loss: 0.472155\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375653; batch adversarial loss: 0.644869\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378886; batch adversarial loss: 0.536262\n",
      "epoch 174; iter: 0; batch classifier loss: 0.422056; batch adversarial loss: 0.526412\n",
      "epoch 175; iter: 0; batch classifier loss: 0.371265; batch adversarial loss: 0.598882\n",
      "epoch 176; iter: 0; batch classifier loss: 0.409570; batch adversarial loss: 0.562913\n",
      "epoch 177; iter: 0; batch classifier loss: 0.350849; batch adversarial loss: 0.598945\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417092; batch adversarial loss: 0.553881\n",
      "epoch 179; iter: 0; batch classifier loss: 0.388676; batch adversarial loss: 0.571698\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414924; batch adversarial loss: 0.508542\n",
      "epoch 181; iter: 0; batch classifier loss: 0.356303; batch adversarial loss: 0.553887\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333726; batch adversarial loss: 0.517334\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366419; batch adversarial loss: 0.553109\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401782; batch adversarial loss: 0.544555\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349596; batch adversarial loss: 0.544358\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334938; batch adversarial loss: 0.508419\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360841; batch adversarial loss: 0.535223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330983; batch adversarial loss: 0.572116\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371329; batch adversarial loss: 0.490170\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407018; batch adversarial loss: 0.608365\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320352; batch adversarial loss: 0.562982\n",
      "epoch 192; iter: 0; batch classifier loss: 0.426229; batch adversarial loss: 0.535707\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345918; batch adversarial loss: 0.553608\n",
      "epoch 194; iter: 0; batch classifier loss: 0.431634; batch adversarial loss: 0.553480\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310192; batch adversarial loss: 0.590021\n",
      "epoch 196; iter: 0; batch classifier loss: 0.276845; batch adversarial loss: 0.517551\n",
      "epoch 197; iter: 0; batch classifier loss: 0.288430; batch adversarial loss: 0.471790\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301852; batch adversarial loss: 0.508011\n",
      "epoch 199; iter: 0; batch classifier loss: 0.395782; batch adversarial loss: 0.571606\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674315; batch adversarial loss: 0.675429\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596021; batch adversarial loss: 0.628683\n",
      "epoch 2; iter: 0; batch classifier loss: 0.538266; batch adversarial loss: 0.619586\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556312; batch adversarial loss: 0.646380\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603330; batch adversarial loss: 0.632181\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550789; batch adversarial loss: 0.614812\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578705; batch adversarial loss: 0.612136\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535294; batch adversarial loss: 0.622380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.503859; batch adversarial loss: 0.543218\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524039; batch adversarial loss: 0.573143\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539005; batch adversarial loss: 0.532525\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575115; batch adversarial loss: 0.547262\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509537; batch adversarial loss: 0.559891\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500531; batch adversarial loss: 0.567516\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489358; batch adversarial loss: 0.463881\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537262; batch adversarial loss: 0.582384\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484555; batch adversarial loss: 0.569611\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533571; batch adversarial loss: 0.591228\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477953; batch adversarial loss: 0.511479\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535084; batch adversarial loss: 0.549894\n",
      "epoch 20; iter: 0; batch classifier loss: 0.447056; batch adversarial loss: 0.550228\n",
      "epoch 21; iter: 0; batch classifier loss: 0.559578; batch adversarial loss: 0.568458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480969; batch adversarial loss: 0.520898\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539369; batch adversarial loss: 0.506242\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462115; batch adversarial loss: 0.514728\n",
      "epoch 25; iter: 0; batch classifier loss: 0.382226; batch adversarial loss: 0.508164\n",
      "epoch 26; iter: 0; batch classifier loss: 0.427058; batch adversarial loss: 0.538244\n",
      "epoch 27; iter: 0; batch classifier loss: 0.423352; batch adversarial loss: 0.531213\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498626; batch adversarial loss: 0.527808\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477314; batch adversarial loss: 0.554136\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461239; batch adversarial loss: 0.512096\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417911; batch adversarial loss: 0.588054\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462877; batch adversarial loss: 0.560967\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442768; batch adversarial loss: 0.544692\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415446; batch adversarial loss: 0.569231\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499523; batch adversarial loss: 0.525203\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466028; batch adversarial loss: 0.527609\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450618; batch adversarial loss: 0.476807\n",
      "epoch 38; iter: 0; batch classifier loss: 0.404004; batch adversarial loss: 0.562393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404763; batch adversarial loss: 0.488277\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507432; batch adversarial loss: 0.581044\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444638; batch adversarial loss: 0.538466\n",
      "epoch 42; iter: 0; batch classifier loss: 0.435473; batch adversarial loss: 0.467437\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425720; batch adversarial loss: 0.563068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448678; batch adversarial loss: 0.523908\n",
      "epoch 45; iter: 0; batch classifier loss: 0.410534; batch adversarial loss: 0.611014\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434605; batch adversarial loss: 0.532743\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418441; batch adversarial loss: 0.498398\n",
      "epoch 48; iter: 0; batch classifier loss: 0.466044; batch adversarial loss: 0.526472\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390590; batch adversarial loss: 0.440091\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473245; batch adversarial loss: 0.554222\n",
      "epoch 51; iter: 0; batch classifier loss: 0.473047; batch adversarial loss: 0.500695\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443309; batch adversarial loss: 0.499119\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399685; batch adversarial loss: 0.518581\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448256; batch adversarial loss: 0.614966\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460548; batch adversarial loss: 0.613792\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440410; batch adversarial loss: 0.578242\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471262; batch adversarial loss: 0.643866\n",
      "epoch 58; iter: 0; batch classifier loss: 0.461969; batch adversarial loss: 0.537283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426597; batch adversarial loss: 0.552669\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393707; batch adversarial loss: 0.582640\n",
      "epoch 61; iter: 0; batch classifier loss: 0.355323; batch adversarial loss: 0.553124\n",
      "epoch 62; iter: 0; batch classifier loss: 0.462083; batch adversarial loss: 0.571170\n",
      "epoch 63; iter: 0; batch classifier loss: 0.466010; batch adversarial loss: 0.563820\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348244; batch adversarial loss: 0.571680\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447197; batch adversarial loss: 0.525162\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405780; batch adversarial loss: 0.545240\n",
      "epoch 67; iter: 0; batch classifier loss: 0.334140; batch adversarial loss: 0.506132\n",
      "epoch 68; iter: 0; batch classifier loss: 0.372486; batch adversarial loss: 0.507928\n",
      "epoch 69; iter: 0; batch classifier loss: 0.481955; batch adversarial loss: 0.564184\n",
      "epoch 70; iter: 0; batch classifier loss: 0.334325; batch adversarial loss: 0.582526\n",
      "epoch 71; iter: 0; batch classifier loss: 0.383766; batch adversarial loss: 0.610840\n",
      "epoch 72; iter: 0; batch classifier loss: 0.409820; batch adversarial loss: 0.478192\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405018; batch adversarial loss: 0.591242\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418111; batch adversarial loss: 0.609779\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405343; batch adversarial loss: 0.498360\n",
      "epoch 76; iter: 0; batch classifier loss: 0.351662; batch adversarial loss: 0.553825\n",
      "epoch 77; iter: 0; batch classifier loss: 0.431328; batch adversarial loss: 0.526315\n",
      "epoch 78; iter: 0; batch classifier loss: 0.486743; batch adversarial loss: 0.498137\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383105; batch adversarial loss: 0.553792\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371711; batch adversarial loss: 0.573232\n",
      "epoch 81; iter: 0; batch classifier loss: 0.525317; batch adversarial loss: 0.525859\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376556; batch adversarial loss: 0.553708\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371832; batch adversarial loss: 0.610540\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386098; batch adversarial loss: 0.516129\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385127; batch adversarial loss: 0.553739\n",
      "epoch 86; iter: 0; batch classifier loss: 0.296988; batch adversarial loss: 0.488427\n",
      "epoch 87; iter: 0; batch classifier loss: 0.470784; batch adversarial loss: 0.554543\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352251; batch adversarial loss: 0.469294\n",
      "epoch 89; iter: 0; batch classifier loss: 0.322112; batch adversarial loss: 0.582339\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362988; batch adversarial loss: 0.535360\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380647; batch adversarial loss: 0.516368\n",
      "epoch 92; iter: 0; batch classifier loss: 0.452243; batch adversarial loss: 0.459988\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381133; batch adversarial loss: 0.478482\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433818; batch adversarial loss: 0.488132\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398090; batch adversarial loss: 0.535056\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384426; batch adversarial loss: 0.581422\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400577; batch adversarial loss: 0.543995\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384207; batch adversarial loss: 0.544290\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361194; batch adversarial loss: 0.588753\n",
      "epoch 100; iter: 0; batch classifier loss: 0.333269; batch adversarial loss: 0.531418\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356363; batch adversarial loss: 0.543358\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342522; batch adversarial loss: 0.554973\n",
      "epoch 103; iter: 0; batch classifier loss: 0.410515; batch adversarial loss: 0.554692\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377005; batch adversarial loss: 0.604621\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385766; batch adversarial loss: 0.499236\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393336; batch adversarial loss: 0.561720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.340229; batch adversarial loss: 0.480924\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381494; batch adversarial loss: 0.575712\n",
      "epoch 109; iter: 0; batch classifier loss: 0.382944; batch adversarial loss: 0.516175\n",
      "epoch 110; iter: 0; batch classifier loss: 0.355517; batch adversarial loss: 0.516346\n",
      "epoch 111; iter: 0; batch classifier loss: 0.413905; batch adversarial loss: 0.544742\n",
      "epoch 112; iter: 0; batch classifier loss: 0.329248; batch adversarial loss: 0.612403\n",
      "epoch 113; iter: 0; batch classifier loss: 0.344550; batch adversarial loss: 0.592059\n",
      "epoch 114; iter: 0; batch classifier loss: 0.408185; batch adversarial loss: 0.611514\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423174; batch adversarial loss: 0.546000\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420899; batch adversarial loss: 0.600764\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371641; batch adversarial loss: 0.628783\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385433; batch adversarial loss: 0.534818\n",
      "epoch 119; iter: 0; batch classifier loss: 0.463060; batch adversarial loss: 0.570908\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401101; batch adversarial loss: 0.477689\n",
      "epoch 121; iter: 0; batch classifier loss: 0.331059; batch adversarial loss: 0.487446\n",
      "epoch 122; iter: 0; batch classifier loss: 0.393809; batch adversarial loss: 0.612002\n",
      "epoch 123; iter: 0; batch classifier loss: 0.422991; batch adversarial loss: 0.516109\n",
      "epoch 124; iter: 0; batch classifier loss: 0.416788; batch adversarial loss: 0.450749\n",
      "epoch 125; iter: 0; batch classifier loss: 0.414500; batch adversarial loss: 0.508194\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392580; batch adversarial loss: 0.572998\n",
      "epoch 127; iter: 0; batch classifier loss: 0.316936; batch adversarial loss: 0.496693\n",
      "epoch 128; iter: 0; batch classifier loss: 0.374051; batch adversarial loss: 0.516355\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413262; batch adversarial loss: 0.562454\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396641; batch adversarial loss: 0.544773\n",
      "epoch 131; iter: 0; batch classifier loss: 0.323028; batch adversarial loss: 0.535569\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413494; batch adversarial loss: 0.506732\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402011; batch adversarial loss: 0.516927\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373614; batch adversarial loss: 0.535462\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354819; batch adversarial loss: 0.506442\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399638; batch adversarial loss: 0.479130\n",
      "epoch 137; iter: 0; batch classifier loss: 0.303922; batch adversarial loss: 0.517013\n",
      "epoch 138; iter: 0; batch classifier loss: 0.332561; batch adversarial loss: 0.469857\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369300; batch adversarial loss: 0.515994\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354774; batch adversarial loss: 0.507459\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364130; batch adversarial loss: 0.544131\n",
      "epoch 142; iter: 0; batch classifier loss: 0.357392; batch adversarial loss: 0.497931\n",
      "epoch 143; iter: 0; batch classifier loss: 0.428022; batch adversarial loss: 0.609761\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376401; batch adversarial loss: 0.478947\n",
      "epoch 145; iter: 0; batch classifier loss: 0.288399; batch adversarial loss: 0.461050\n",
      "epoch 146; iter: 0; batch classifier loss: 0.387133; batch adversarial loss: 0.524445\n",
      "epoch 147; iter: 0; batch classifier loss: 0.448908; batch adversarial loss: 0.497791\n",
      "epoch 148; iter: 0; batch classifier loss: 0.377784; batch adversarial loss: 0.488023\n",
      "epoch 149; iter: 0; batch classifier loss: 0.299674; batch adversarial loss: 0.534686\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421689; batch adversarial loss: 0.534320\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432784; batch adversarial loss: 0.497959\n",
      "epoch 152; iter: 0; batch classifier loss: 0.411728; batch adversarial loss: 0.535713\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351620; batch adversarial loss: 0.638471\n",
      "epoch 154; iter: 0; batch classifier loss: 0.415071; batch adversarial loss: 0.553238\n",
      "epoch 155; iter: 0; batch classifier loss: 0.435504; batch adversarial loss: 0.516396\n",
      "epoch 156; iter: 0; batch classifier loss: 0.353653; batch adversarial loss: 0.496923\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346290; batch adversarial loss: 0.544684\n",
      "epoch 158; iter: 0; batch classifier loss: 0.331984; batch adversarial loss: 0.573018\n",
      "epoch 159; iter: 0; batch classifier loss: 0.334565; batch adversarial loss: 0.563575\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319452; batch adversarial loss: 0.515874\n",
      "epoch 161; iter: 0; batch classifier loss: 0.331965; batch adversarial loss: 0.544678\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365635; batch adversarial loss: 0.516148\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366371; batch adversarial loss: 0.600190\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336238; batch adversarial loss: 0.543199\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358502; batch adversarial loss: 0.507009\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357521; batch adversarial loss: 0.630566\n",
      "epoch 167; iter: 0; batch classifier loss: 0.451171; batch adversarial loss: 0.498959\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388871; batch adversarial loss: 0.525775\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380382; batch adversarial loss: 0.599101\n",
      "epoch 170; iter: 0; batch classifier loss: 0.430751; batch adversarial loss: 0.564132\n",
      "epoch 171; iter: 0; batch classifier loss: 0.309001; batch adversarial loss: 0.535480\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381401; batch adversarial loss: 0.582797\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302207; batch adversarial loss: 0.572999\n",
      "epoch 174; iter: 0; batch classifier loss: 0.418732; batch adversarial loss: 0.536116\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382829; batch adversarial loss: 0.451012\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370629; batch adversarial loss: 0.487004\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335244; batch adversarial loss: 0.525451\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360618; batch adversarial loss: 0.629655\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364212; batch adversarial loss: 0.488680\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374248; batch adversarial loss: 0.582576\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338059; batch adversarial loss: 0.572783\n",
      "epoch 182; iter: 0; batch classifier loss: 0.263252; batch adversarial loss: 0.535792\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353723; batch adversarial loss: 0.525130\n",
      "epoch 184; iter: 0; batch classifier loss: 0.443702; batch adversarial loss: 0.524586\n",
      "epoch 185; iter: 0; batch classifier loss: 0.388895; batch adversarial loss: 0.563074\n",
      "epoch 186; iter: 0; batch classifier loss: 0.351465; batch adversarial loss: 0.553913\n",
      "epoch 187; iter: 0; batch classifier loss: 0.269682; batch adversarial loss: 0.544137\n",
      "epoch 188; iter: 0; batch classifier loss: 0.295537; batch adversarial loss: 0.544754\n",
      "epoch 189; iter: 0; batch classifier loss: 0.389471; batch adversarial loss: 0.590900\n",
      "epoch 190; iter: 0; batch classifier loss: 0.354624; batch adversarial loss: 0.534825\n",
      "epoch 191; iter: 0; batch classifier loss: 0.431108; batch adversarial loss: 0.525961\n",
      "epoch 192; iter: 0; batch classifier loss: 0.434469; batch adversarial loss: 0.526077\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370349; batch adversarial loss: 0.516709\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330590; batch adversarial loss: 0.544696\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379039; batch adversarial loss: 0.543460\n",
      "epoch 196; iter: 0; batch classifier loss: 0.428171; batch adversarial loss: 0.582518\n",
      "epoch 197; iter: 0; batch classifier loss: 0.289675; batch adversarial loss: 0.563959\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375775; batch adversarial loss: 0.535663\n",
      "epoch 199; iter: 0; batch classifier loss: 0.336684; batch adversarial loss: 0.552630\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703959; batch adversarial loss: 0.775037\n",
      "epoch 1; iter: 0; batch classifier loss: 0.707064; batch adversarial loss: 0.743196\n",
      "epoch 2; iter: 0; batch classifier loss: 0.708256; batch adversarial loss: 0.697847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.561495; batch adversarial loss: 0.649389\n",
      "epoch 4; iter: 0; batch classifier loss: 0.525886; batch adversarial loss: 0.632633\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533525; batch adversarial loss: 0.600370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572157; batch adversarial loss: 0.609262\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542495; batch adversarial loss: 0.590511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543102; batch adversarial loss: 0.606750\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479278; batch adversarial loss: 0.576585\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564740; batch adversarial loss: 0.628116\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459116; batch adversarial loss: 0.555688\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498462; batch adversarial loss: 0.553653\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557352; batch adversarial loss: 0.530438\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472734; batch adversarial loss: 0.578675\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522272; batch adversarial loss: 0.600880\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552047; batch adversarial loss: 0.521922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462754; batch adversarial loss: 0.544731\n",
      "epoch 18; iter: 0; batch classifier loss: 0.459418; batch adversarial loss: 0.564619\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482706; batch adversarial loss: 0.590252\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477943; batch adversarial loss: 0.538367\n",
      "epoch 21; iter: 0; batch classifier loss: 0.463384; batch adversarial loss: 0.569163\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468035; batch adversarial loss: 0.510273\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525303; batch adversarial loss: 0.597080\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456253; batch adversarial loss: 0.525940\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457802; batch adversarial loss: 0.558306\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493685; batch adversarial loss: 0.592357\n",
      "epoch 27; iter: 0; batch classifier loss: 0.533007; batch adversarial loss: 0.594794\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451648; batch adversarial loss: 0.547427\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445217; batch adversarial loss: 0.574161\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459606; batch adversarial loss: 0.575523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421330; batch adversarial loss: 0.533122\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448482; batch adversarial loss: 0.503754\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469368; batch adversarial loss: 0.555734\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427307; batch adversarial loss: 0.550230\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390278; batch adversarial loss: 0.541978\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434878; batch adversarial loss: 0.563620\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451858; batch adversarial loss: 0.607327\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436383; batch adversarial loss: 0.531664\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455484; batch adversarial loss: 0.529992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.433165; batch adversarial loss: 0.526779\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468251; batch adversarial loss: 0.565230\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444562; batch adversarial loss: 0.598867\n",
      "epoch 43; iter: 0; batch classifier loss: 0.507475; batch adversarial loss: 0.616690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.367973; batch adversarial loss: 0.545191\n",
      "epoch 45; iter: 0; batch classifier loss: 0.378179; batch adversarial loss: 0.500729\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432368; batch adversarial loss: 0.580589\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464958; batch adversarial loss: 0.571707\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461962; batch adversarial loss: 0.660807\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424532; batch adversarial loss: 0.562506\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412628; batch adversarial loss: 0.580698\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404124; batch adversarial loss: 0.526709\n",
      "epoch 52; iter: 0; batch classifier loss: 0.359649; batch adversarial loss: 0.499443\n",
      "epoch 53; iter: 0; batch classifier loss: 0.376076; batch adversarial loss: 0.553700\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426113; batch adversarial loss: 0.571461\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423975; batch adversarial loss: 0.526033\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378521; batch adversarial loss: 0.516068\n",
      "epoch 57; iter: 0; batch classifier loss: 0.520380; batch adversarial loss: 0.543977\n",
      "epoch 58; iter: 0; batch classifier loss: 0.341000; batch adversarial loss: 0.536577\n",
      "epoch 59; iter: 0; batch classifier loss: 0.356054; batch adversarial loss: 0.544568\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410973; batch adversarial loss: 0.552578\n",
      "epoch 61; iter: 0; batch classifier loss: 0.487151; batch adversarial loss: 0.552752\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459988; batch adversarial loss: 0.545920\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398603; batch adversarial loss: 0.544106\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463525; batch adversarial loss: 0.517004\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437483; batch adversarial loss: 0.607378\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400023; batch adversarial loss: 0.516578\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380879; batch adversarial loss: 0.536193\n",
      "epoch 68; iter: 0; batch classifier loss: 0.370728; batch adversarial loss: 0.552297\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377158; batch adversarial loss: 0.572450\n",
      "epoch 70; iter: 0; batch classifier loss: 0.474194; batch adversarial loss: 0.518478\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390793; batch adversarial loss: 0.535461\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448454; batch adversarial loss: 0.471618\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403894; batch adversarial loss: 0.571883\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394123; batch adversarial loss: 0.544855\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382202; batch adversarial loss: 0.583708\n",
      "epoch 76; iter: 0; batch classifier loss: 0.320189; batch adversarial loss: 0.499263\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375761; batch adversarial loss: 0.526889\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438088; batch adversarial loss: 0.588842\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396833; batch adversarial loss: 0.580587\n",
      "epoch 80; iter: 0; batch classifier loss: 0.364799; batch adversarial loss: 0.599625\n",
      "epoch 81; iter: 0; batch classifier loss: 0.440509; batch adversarial loss: 0.499596\n",
      "epoch 82; iter: 0; batch classifier loss: 0.370412; batch adversarial loss: 0.526730\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448266; batch adversarial loss: 0.489518\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388222; batch adversarial loss: 0.552968\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395441; batch adversarial loss: 0.543438\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377349; batch adversarial loss: 0.526519\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352049; batch adversarial loss: 0.516550\n",
      "epoch 88; iter: 0; batch classifier loss: 0.453998; batch adversarial loss: 0.625221\n",
      "epoch 89; iter: 0; batch classifier loss: 0.321290; batch adversarial loss: 0.579469\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362873; batch adversarial loss: 0.562919\n",
      "epoch 91; iter: 0; batch classifier loss: 0.347529; batch adversarial loss: 0.514425\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405383; batch adversarial loss: 0.634672\n",
      "epoch 93; iter: 0; batch classifier loss: 0.424126; batch adversarial loss: 0.561968\n",
      "epoch 94; iter: 0; batch classifier loss: 0.393819; batch adversarial loss: 0.551966\n",
      "epoch 95; iter: 0; batch classifier loss: 0.316463; batch adversarial loss: 0.590140\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430361; batch adversarial loss: 0.517142\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388012; batch adversarial loss: 0.580358\n",
      "epoch 98; iter: 0; batch classifier loss: 0.464024; batch adversarial loss: 0.535116\n",
      "epoch 99; iter: 0; batch classifier loss: 0.374578; batch adversarial loss: 0.589616\n",
      "epoch 100; iter: 0; batch classifier loss: 0.466071; batch adversarial loss: 0.553552\n",
      "epoch 101; iter: 0; batch classifier loss: 0.455945; batch adversarial loss: 0.598392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.424981; batch adversarial loss: 0.588529\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411431; batch adversarial loss: 0.481431\n",
      "epoch 104; iter: 0; batch classifier loss: 0.320640; batch adversarial loss: 0.525972\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394921; batch adversarial loss: 0.560041\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386047; batch adversarial loss: 0.537333\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413339; batch adversarial loss: 0.553101\n",
      "epoch 108; iter: 0; batch classifier loss: 0.325074; batch adversarial loss: 0.535988\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402162; batch adversarial loss: 0.591005\n",
      "epoch 110; iter: 0; batch classifier loss: 0.295058; batch adversarial loss: 0.590583\n",
      "epoch 111; iter: 0; batch classifier loss: 0.390145; batch adversarial loss: 0.543666\n",
      "epoch 112; iter: 0; batch classifier loss: 0.341403; batch adversarial loss: 0.489302\n",
      "epoch 113; iter: 0; batch classifier loss: 0.300071; batch adversarial loss: 0.661160\n",
      "epoch 114; iter: 0; batch classifier loss: 0.302137; batch adversarial loss: 0.545665\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401871; batch adversarial loss: 0.563987\n",
      "epoch 116; iter: 0; batch classifier loss: 0.354669; batch adversarial loss: 0.444175\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374507; batch adversarial loss: 0.564495\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390080; batch adversarial loss: 0.508579\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380443; batch adversarial loss: 0.443845\n",
      "epoch 120; iter: 0; batch classifier loss: 0.336609; batch adversarial loss: 0.470082\n",
      "epoch 121; iter: 0; batch classifier loss: 0.312472; batch adversarial loss: 0.581509\n",
      "epoch 122; iter: 0; batch classifier loss: 0.430023; batch adversarial loss: 0.571931\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388642; batch adversarial loss: 0.553682\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336188; batch adversarial loss: 0.544467\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392307; batch adversarial loss: 0.525909\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406303; batch adversarial loss: 0.598595\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354806; batch adversarial loss: 0.507929\n",
      "epoch 128; iter: 0; batch classifier loss: 0.382338; batch adversarial loss: 0.498789\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398825; batch adversarial loss: 0.563116\n",
      "epoch 130; iter: 0; batch classifier loss: 0.329000; batch adversarial loss: 0.554008\n",
      "epoch 131; iter: 0; batch classifier loss: 0.393995; batch adversarial loss: 0.589880\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327589; batch adversarial loss: 0.635980\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383222; batch adversarial loss: 0.617703\n",
      "epoch 134; iter: 0; batch classifier loss: 0.330095; batch adversarial loss: 0.598627\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371149; batch adversarial loss: 0.545290\n",
      "epoch 136; iter: 0; batch classifier loss: 0.321701; batch adversarial loss: 0.554088\n",
      "epoch 137; iter: 0; batch classifier loss: 0.390439; batch adversarial loss: 0.590568\n",
      "epoch 138; iter: 0; batch classifier loss: 0.412718; batch adversarial loss: 0.563430\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372546; batch adversarial loss: 0.525155\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391320; batch adversarial loss: 0.627394\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322797; batch adversarial loss: 0.553216\n",
      "epoch 142; iter: 0; batch classifier loss: 0.300379; batch adversarial loss: 0.571875\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346458; batch adversarial loss: 0.599108\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349299; batch adversarial loss: 0.444153\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397079; batch adversarial loss: 0.544435\n",
      "epoch 146; iter: 0; batch classifier loss: 0.440943; batch adversarial loss: 0.589958\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332615; batch adversarial loss: 0.534800\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345510; batch adversarial loss: 0.527786\n",
      "epoch 149; iter: 0; batch classifier loss: 0.381698; batch adversarial loss: 0.590564\n",
      "epoch 150; iter: 0; batch classifier loss: 0.422454; batch adversarial loss: 0.579497\n",
      "epoch 151; iter: 0; batch classifier loss: 0.303866; batch adversarial loss: 0.534777\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374296; batch adversarial loss: 0.508832\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389488; batch adversarial loss: 0.542989\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321123; batch adversarial loss: 0.479925\n",
      "epoch 155; iter: 0; batch classifier loss: 0.361582; batch adversarial loss: 0.617317\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347098; batch adversarial loss: 0.525903\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369966; batch adversarial loss: 0.471226\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365427; batch adversarial loss: 0.579749\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380586; batch adversarial loss: 0.555018\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398198; batch adversarial loss: 0.526654\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354923; batch adversarial loss: 0.626480\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365748; batch adversarial loss: 0.562244\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345808; batch adversarial loss: 0.525569\n",
      "epoch 164; iter: 0; batch classifier loss: 0.437228; batch adversarial loss: 0.571411\n",
      "epoch 165; iter: 0; batch classifier loss: 0.419635; batch adversarial loss: 0.590315\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359599; batch adversarial loss: 0.517061\n",
      "epoch 167; iter: 0; batch classifier loss: 0.277764; batch adversarial loss: 0.497165\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377701; batch adversarial loss: 0.510328\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339605; batch adversarial loss: 0.487996\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319771; batch adversarial loss: 0.498899\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362317; batch adversarial loss: 0.481725\n",
      "epoch 172; iter: 0; batch classifier loss: 0.386844; batch adversarial loss: 0.570665\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342812; batch adversarial loss: 0.534785\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369501; batch adversarial loss: 0.535816\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346006; batch adversarial loss: 0.544151\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319258; batch adversarial loss: 0.516549\n",
      "epoch 177; iter: 0; batch classifier loss: 0.332356; batch adversarial loss: 0.545577\n",
      "epoch 178; iter: 0; batch classifier loss: 0.406350; batch adversarial loss: 0.535731\n",
      "epoch 179; iter: 0; batch classifier loss: 0.397676; batch adversarial loss: 0.535073\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339233; batch adversarial loss: 0.544453\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342362; batch adversarial loss: 0.516400\n",
      "epoch 182; iter: 0; batch classifier loss: 0.388531; batch adversarial loss: 0.562232\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358770; batch adversarial loss: 0.561250\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339406; batch adversarial loss: 0.581791\n",
      "epoch 185; iter: 0; batch classifier loss: 0.403530; batch adversarial loss: 0.580461\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376626; batch adversarial loss: 0.553998\n",
      "epoch 187; iter: 0; batch classifier loss: 0.387132; batch adversarial loss: 0.553363\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386909; batch adversarial loss: 0.543446\n",
      "epoch 189; iter: 0; batch classifier loss: 0.321663; batch adversarial loss: 0.607757\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357058; batch adversarial loss: 0.562194\n",
      "epoch 191; iter: 0; batch classifier loss: 0.358350; batch adversarial loss: 0.527363\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319809; batch adversarial loss: 0.454739\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332238; batch adversarial loss: 0.472645\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318819; batch adversarial loss: 0.582115\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343470; batch adversarial loss: 0.606966\n",
      "epoch 196; iter: 0; batch classifier loss: 0.377404; batch adversarial loss: 0.508920\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356650; batch adversarial loss: 0.472172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.341750; batch adversarial loss: 0.480886\n",
      "epoch 199; iter: 0; batch classifier loss: 0.304421; batch adversarial loss: 0.553859\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693558; batch adversarial loss: 0.908421\n",
      "epoch 1; iter: 0; batch classifier loss: 0.753558; batch adversarial loss: 1.148633\n",
      "epoch 2; iter: 0; batch classifier loss: 0.912716; batch adversarial loss: 1.155447\n",
      "epoch 3; iter: 0; batch classifier loss: 1.065618; batch adversarial loss: 1.027782\n",
      "epoch 4; iter: 0; batch classifier loss: 0.994032; batch adversarial loss: 0.954941\n",
      "epoch 5; iter: 0; batch classifier loss: 0.791740; batch adversarial loss: 0.874145\n",
      "epoch 6; iter: 0; batch classifier loss: 0.882219; batch adversarial loss: 0.787723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.805428; batch adversarial loss: 0.741219\n",
      "epoch 8; iter: 0; batch classifier loss: 0.662406; batch adversarial loss: 0.687276\n",
      "epoch 9; iter: 0; batch classifier loss: 0.632294; batch adversarial loss: 0.621946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578111; batch adversarial loss: 0.622032\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563772; batch adversarial loss: 0.628234\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496942; batch adversarial loss: 0.571655\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522279; batch adversarial loss: 0.584272\n",
      "epoch 14; iter: 0; batch classifier loss: 0.598065; batch adversarial loss: 0.600561\n",
      "epoch 15; iter: 0; batch classifier loss: 0.436296; batch adversarial loss: 0.565758\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491159; batch adversarial loss: 0.564046\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481974; batch adversarial loss: 0.572189\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536122; batch adversarial loss: 0.569781\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488219; batch adversarial loss: 0.561825\n",
      "epoch 20; iter: 0; batch classifier loss: 0.533516; batch adversarial loss: 0.631016\n",
      "epoch 21; iter: 0; batch classifier loss: 0.594200; batch adversarial loss: 0.503208\n",
      "epoch 22; iter: 0; batch classifier loss: 0.499417; batch adversarial loss: 0.585759\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539645; batch adversarial loss: 0.581996\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466007; batch adversarial loss: 0.550277\n",
      "epoch 25; iter: 0; batch classifier loss: 0.408057; batch adversarial loss: 0.592988\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484806; batch adversarial loss: 0.544496\n",
      "epoch 27; iter: 0; batch classifier loss: 0.514810; batch adversarial loss: 0.539655\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484846; batch adversarial loss: 0.563330\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394271; batch adversarial loss: 0.579705\n",
      "epoch 30; iter: 0; batch classifier loss: 0.381432; batch adversarial loss: 0.595211\n",
      "epoch 31; iter: 0; batch classifier loss: 0.434087; batch adversarial loss: 0.587035\n",
      "epoch 32; iter: 0; batch classifier loss: 0.518703; batch adversarial loss: 0.512943\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456268; batch adversarial loss: 0.478168\n",
      "epoch 34; iter: 0; batch classifier loss: 0.508292; batch adversarial loss: 0.509782\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423952; batch adversarial loss: 0.561699\n",
      "epoch 36; iter: 0; batch classifier loss: 0.524283; batch adversarial loss: 0.542261\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452409; batch adversarial loss: 0.534116\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437316; batch adversarial loss: 0.558696\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460600; batch adversarial loss: 0.515386\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450110; batch adversarial loss: 0.566201\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449905; batch adversarial loss: 0.545569\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443538; batch adversarial loss: 0.597294\n",
      "epoch 43; iter: 0; batch classifier loss: 0.506469; batch adversarial loss: 0.549408\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434622; batch adversarial loss: 0.592778\n",
      "epoch 45; iter: 0; batch classifier loss: 0.321257; batch adversarial loss: 0.572553\n",
      "epoch 46; iter: 0; batch classifier loss: 0.393414; batch adversarial loss: 0.607021\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424383; batch adversarial loss: 0.574107\n",
      "epoch 48; iter: 0; batch classifier loss: 0.458246; batch adversarial loss: 0.531649\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442095; batch adversarial loss: 0.576278\n",
      "epoch 50; iter: 0; batch classifier loss: 0.504919; batch adversarial loss: 0.531864\n",
      "epoch 51; iter: 0; batch classifier loss: 0.420848; batch adversarial loss: 0.590442\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436624; batch adversarial loss: 0.543413\n",
      "epoch 53; iter: 0; batch classifier loss: 0.357174; batch adversarial loss: 0.556930\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435369; batch adversarial loss: 0.561916\n",
      "epoch 55; iter: 0; batch classifier loss: 0.455365; batch adversarial loss: 0.453439\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414099; batch adversarial loss: 0.597638\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428711; batch adversarial loss: 0.525750\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423113; batch adversarial loss: 0.609879\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394981; batch adversarial loss: 0.524919\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396426; batch adversarial loss: 0.574782\n",
      "epoch 61; iter: 0; batch classifier loss: 0.370580; batch adversarial loss: 0.548247\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440773; batch adversarial loss: 0.538504\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431767; batch adversarial loss: 0.598999\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425443; batch adversarial loss: 0.500611\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419927; batch adversarial loss: 0.544416\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429463; batch adversarial loss: 0.561125\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409798; batch adversarial loss: 0.542863\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432381; batch adversarial loss: 0.499073\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401994; batch adversarial loss: 0.581768\n",
      "epoch 70; iter: 0; batch classifier loss: 0.449925; batch adversarial loss: 0.542414\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451319; batch adversarial loss: 0.526220\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383979; batch adversarial loss: 0.554354\n",
      "epoch 73; iter: 0; batch classifier loss: 0.310272; batch adversarial loss: 0.536187\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363152; batch adversarial loss: 0.531356\n",
      "epoch 75; iter: 0; batch classifier loss: 0.376010; batch adversarial loss: 0.631008\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382020; batch adversarial loss: 0.560825\n",
      "epoch 77; iter: 0; batch classifier loss: 0.334316; batch adversarial loss: 0.628437\n",
      "epoch 78; iter: 0; batch classifier loss: 0.425569; batch adversarial loss: 0.574037\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392545; batch adversarial loss: 0.544902\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358526; batch adversarial loss: 0.540014\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373191; batch adversarial loss: 0.502182\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361073; batch adversarial loss: 0.590303\n",
      "epoch 83; iter: 0; batch classifier loss: 0.464874; batch adversarial loss: 0.592685\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354013; batch adversarial loss: 0.544730\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404582; batch adversarial loss: 0.546965\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360256; batch adversarial loss: 0.544136\n",
      "epoch 87; iter: 0; batch classifier loss: 0.452202; batch adversarial loss: 0.533584\n",
      "epoch 88; iter: 0; batch classifier loss: 0.305380; batch adversarial loss: 0.581514\n",
      "epoch 89; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.590950\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405686; batch adversarial loss: 0.501534\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375988; batch adversarial loss: 0.598822\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411068; batch adversarial loss: 0.558596\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390157; batch adversarial loss: 0.517240\n",
      "epoch 94; iter: 0; batch classifier loss: 0.353395; batch adversarial loss: 0.533884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.380769; batch adversarial loss: 0.552901\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376702; batch adversarial loss: 0.602878\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437782; batch adversarial loss: 0.484185\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375011; batch adversarial loss: 0.522370\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382816; batch adversarial loss: 0.551643\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372310; batch adversarial loss: 0.524651\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420448; batch adversarial loss: 0.587643\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416822; batch adversarial loss: 0.470455\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404189; batch adversarial loss: 0.499206\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385599; batch adversarial loss: 0.462446\n",
      "epoch 105; iter: 0; batch classifier loss: 0.366479; batch adversarial loss: 0.516178\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363539; batch adversarial loss: 0.535368\n",
      "epoch 107; iter: 0; batch classifier loss: 0.448089; batch adversarial loss: 0.561323\n",
      "epoch 108; iter: 0; batch classifier loss: 0.335073; batch adversarial loss: 0.555365\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397135; batch adversarial loss: 0.516565\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382314; batch adversarial loss: 0.481613\n",
      "epoch 111; iter: 0; batch classifier loss: 0.335461; batch adversarial loss: 0.554762\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349794; batch adversarial loss: 0.574096\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384754; batch adversarial loss: 0.507766\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360763; batch adversarial loss: 0.590370\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339962; batch adversarial loss: 0.564597\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420921; batch adversarial loss: 0.579393\n",
      "epoch 117; iter: 0; batch classifier loss: 0.455274; batch adversarial loss: 0.573533\n",
      "epoch 118; iter: 0; batch classifier loss: 0.309111; batch adversarial loss: 0.570382\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377216; batch adversarial loss: 0.581233\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338771; batch adversarial loss: 0.568113\n",
      "epoch 121; iter: 0; batch classifier loss: 0.417358; batch adversarial loss: 0.519033\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326028; batch adversarial loss: 0.573767\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362847; batch adversarial loss: 0.475007\n",
      "epoch 124; iter: 0; batch classifier loss: 0.351786; batch adversarial loss: 0.525614\n",
      "epoch 125; iter: 0; batch classifier loss: 0.315218; batch adversarial loss: 0.553421\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372121; batch adversarial loss: 0.614621\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394615; batch adversarial loss: 0.545887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325410; batch adversarial loss: 0.596175\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370013; batch adversarial loss: 0.509054\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364786; batch adversarial loss: 0.527580\n",
      "epoch 131; iter: 0; batch classifier loss: 0.409287; batch adversarial loss: 0.554395\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421280; batch adversarial loss: 0.536182\n",
      "epoch 133; iter: 0; batch classifier loss: 0.359972; batch adversarial loss: 0.581780\n",
      "epoch 134; iter: 0; batch classifier loss: 0.297101; batch adversarial loss: 0.554007\n",
      "epoch 135; iter: 0; batch classifier loss: 0.390971; batch adversarial loss: 0.678731\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334835; batch adversarial loss: 0.544786\n",
      "epoch 137; iter: 0; batch classifier loss: 0.314602; batch adversarial loss: 0.589434\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349045; batch adversarial loss: 0.499719\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415472; batch adversarial loss: 0.589847\n",
      "epoch 140; iter: 0; batch classifier loss: 0.331831; batch adversarial loss: 0.625516\n",
      "epoch 141; iter: 0; batch classifier loss: 0.333540; batch adversarial loss: 0.508190\n",
      "epoch 142; iter: 0; batch classifier loss: 0.291113; batch adversarial loss: 0.608949\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412993; batch adversarial loss: 0.581139\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302259; batch adversarial loss: 0.536023\n",
      "epoch 145; iter: 0; batch classifier loss: 0.368744; batch adversarial loss: 0.534956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.294350; batch adversarial loss: 0.527256\n",
      "epoch 147; iter: 0; batch classifier loss: 0.375889; batch adversarial loss: 0.563250\n",
      "epoch 148; iter: 0; batch classifier loss: 0.280796; batch adversarial loss: 0.544273\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362032; batch adversarial loss: 0.617685\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400071; batch adversarial loss: 0.589962\n",
      "epoch 151; iter: 0; batch classifier loss: 0.291432; batch adversarial loss: 0.534583\n",
      "epoch 152; iter: 0; batch classifier loss: 0.288799; batch adversarial loss: 0.608488\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346443; batch adversarial loss: 0.571447\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389506; batch adversarial loss: 0.535449\n",
      "epoch 155; iter: 0; batch classifier loss: 0.422661; batch adversarial loss: 0.517863\n",
      "epoch 156; iter: 0; batch classifier loss: 0.335908; batch adversarial loss: 0.554019\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340418; batch adversarial loss: 0.534639\n",
      "epoch 158; iter: 0; batch classifier loss: 0.324558; batch adversarial loss: 0.552773\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363337; batch adversarial loss: 0.572639\n",
      "epoch 160; iter: 0; batch classifier loss: 0.290756; batch adversarial loss: 0.553176\n",
      "epoch 161; iter: 0; batch classifier loss: 0.449322; batch adversarial loss: 0.590813\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363921; batch adversarial loss: 0.480467\n",
      "epoch 163; iter: 0; batch classifier loss: 0.332649; batch adversarial loss: 0.572515\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334051; batch adversarial loss: 0.517855\n",
      "epoch 165; iter: 0; batch classifier loss: 0.409681; batch adversarial loss: 0.517295\n",
      "epoch 166; iter: 0; batch classifier loss: 0.401201; batch adversarial loss: 0.562706\n",
      "epoch 167; iter: 0; batch classifier loss: 0.291838; batch adversarial loss: 0.562877\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335894; batch adversarial loss: 0.553545\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337752; batch adversarial loss: 0.553204\n",
      "epoch 170; iter: 0; batch classifier loss: 0.390358; batch adversarial loss: 0.508024\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347461; batch adversarial loss: 0.535466\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331993; batch adversarial loss: 0.535038\n",
      "epoch 173; iter: 0; batch classifier loss: 0.326707; batch adversarial loss: 0.608528\n",
      "epoch 174; iter: 0; batch classifier loss: 0.298933; batch adversarial loss: 0.526331\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362319; batch adversarial loss: 0.607947\n",
      "epoch 176; iter: 0; batch classifier loss: 0.392150; batch adversarial loss: 0.625900\n",
      "epoch 177; iter: 0; batch classifier loss: 0.373564; batch adversarial loss: 0.580973\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337381; batch adversarial loss: 0.626631\n",
      "epoch 179; iter: 0; batch classifier loss: 0.317202; batch adversarial loss: 0.617598\n",
      "epoch 180; iter: 0; batch classifier loss: 0.276236; batch adversarial loss: 0.535407\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320829; batch adversarial loss: 0.608268\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324130; batch adversarial loss: 0.580686\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354543; batch adversarial loss: 0.599169\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352764; batch adversarial loss: 0.562559\n",
      "epoch 185; iter: 0; batch classifier loss: 0.280256; batch adversarial loss: 0.526046\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346665; batch adversarial loss: 0.644515\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351083; batch adversarial loss: 0.517606\n",
      "epoch 188; iter: 0; batch classifier loss: 0.323497; batch adversarial loss: 0.562541\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364492; batch adversarial loss: 0.562282\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323070; batch adversarial loss: 0.526553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.355737; batch adversarial loss: 0.617310\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313177; batch adversarial loss: 0.571718\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333578; batch adversarial loss: 0.553702\n",
      "epoch 194; iter: 0; batch classifier loss: 0.314239; batch adversarial loss: 0.516645\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347358; batch adversarial loss: 0.572028\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366391; batch adversarial loss: 0.462050\n",
      "epoch 197; iter: 0; batch classifier loss: 0.346763; batch adversarial loss: 0.544361\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359256; batch adversarial loss: 0.535457\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349011; batch adversarial loss: 0.581167\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701320; batch adversarial loss: 0.688228\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587303; batch adversarial loss: 0.643483\n",
      "epoch 2; iter: 0; batch classifier loss: 0.642950; batch adversarial loss: 0.633513\n",
      "epoch 3; iter: 0; batch classifier loss: 0.633008; batch adversarial loss: 0.584914\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591975; batch adversarial loss: 0.612918\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583811; batch adversarial loss: 0.591976\n",
      "epoch 6; iter: 0; batch classifier loss: 0.594446; batch adversarial loss: 0.583570\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559795; batch adversarial loss: 0.582974\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495886; batch adversarial loss: 0.584211\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499228; batch adversarial loss: 0.574187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531333; batch adversarial loss: 0.627833\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575560; batch adversarial loss: 0.570706\n",
      "epoch 12; iter: 0; batch classifier loss: 0.574622; batch adversarial loss: 0.563931\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549708; batch adversarial loss: 0.649135\n",
      "epoch 14; iter: 0; batch classifier loss: 0.645576; batch adversarial loss: 0.583671\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512045; batch adversarial loss: 0.596504\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497999; batch adversarial loss: 0.563872\n",
      "epoch 17; iter: 0; batch classifier loss: 0.445996; batch adversarial loss: 0.573205\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520409; batch adversarial loss: 0.623268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490213; batch adversarial loss: 0.634741\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530786; batch adversarial loss: 0.536563\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504162; batch adversarial loss: 0.540168\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482468; batch adversarial loss: 0.654350\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507492; batch adversarial loss: 0.540462\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502802; batch adversarial loss: 0.528083\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482619; batch adversarial loss: 0.550010\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473183; batch adversarial loss: 0.515832\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511463; batch adversarial loss: 0.516020\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442657; batch adversarial loss: 0.562510\n",
      "epoch 29; iter: 0; batch classifier loss: 0.404807; batch adversarial loss: 0.554539\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434568; batch adversarial loss: 0.487821\n",
      "epoch 31; iter: 0; batch classifier loss: 0.552416; batch adversarial loss: 0.452715\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436208; batch adversarial loss: 0.519909\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507209; batch adversarial loss: 0.579518\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544330; batch adversarial loss: 0.518841\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455894; batch adversarial loss: 0.561810\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418952; batch adversarial loss: 0.517931\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402075; batch adversarial loss: 0.597270\n",
      "epoch 38; iter: 0; batch classifier loss: 0.491902; batch adversarial loss: 0.527508\n",
      "epoch 39; iter: 0; batch classifier loss: 0.413622; batch adversarial loss: 0.563262\n",
      "epoch 40; iter: 0; batch classifier loss: 0.380070; batch adversarial loss: 0.598534\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421738; batch adversarial loss: 0.552620\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448763; batch adversarial loss: 0.534634\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453954; batch adversarial loss: 0.553387\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440981; batch adversarial loss: 0.516716\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382022; batch adversarial loss: 0.517871\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381831; batch adversarial loss: 0.595946\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447731; batch adversarial loss: 0.564424\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461184; batch adversarial loss: 0.499796\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397370; batch adversarial loss: 0.617016\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414525; batch adversarial loss: 0.545027\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400968; batch adversarial loss: 0.624738\n",
      "epoch 52; iter: 0; batch classifier loss: 0.485105; batch adversarial loss: 0.497807\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404229; batch adversarial loss: 0.569773\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445390; batch adversarial loss: 0.580924\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417546; batch adversarial loss: 0.499461\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451330; batch adversarial loss: 0.563810\n",
      "epoch 57; iter: 0; batch classifier loss: 0.475535; batch adversarial loss: 0.554503\n",
      "epoch 58; iter: 0; batch classifier loss: 0.383798; batch adversarial loss: 0.572777\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427992; batch adversarial loss: 0.546112\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405514; batch adversarial loss: 0.608910\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451666; batch adversarial loss: 0.543490\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408394; batch adversarial loss: 0.591621\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409447; batch adversarial loss: 0.534303\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422742; batch adversarial loss: 0.600361\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410438; batch adversarial loss: 0.608700\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423604; batch adversarial loss: 0.507787\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387394; batch adversarial loss: 0.609379\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437042; batch adversarial loss: 0.572289\n",
      "epoch 69; iter: 0; batch classifier loss: 0.348933; batch adversarial loss: 0.534926\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431260; batch adversarial loss: 0.573185\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484001; batch adversarial loss: 0.517356\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419898; batch adversarial loss: 0.544570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408949; batch adversarial loss: 0.544453\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423904; batch adversarial loss: 0.498811\n",
      "epoch 75; iter: 0; batch classifier loss: 0.338896; batch adversarial loss: 0.617648\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409359; batch adversarial loss: 0.635154\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433554; batch adversarial loss: 0.517298\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401710; batch adversarial loss: 0.544855\n",
      "epoch 79; iter: 0; batch classifier loss: 0.468607; batch adversarial loss: 0.617443\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427020; batch adversarial loss: 0.507673\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378563; batch adversarial loss: 0.554314\n",
      "epoch 82; iter: 0; batch classifier loss: 0.433924; batch adversarial loss: 0.571488\n",
      "epoch 83; iter: 0; batch classifier loss: 0.424903; batch adversarial loss: 0.589301\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374057; batch adversarial loss: 0.545384\n",
      "epoch 85; iter: 0; batch classifier loss: 0.423759; batch adversarial loss: 0.544410\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399280; batch adversarial loss: 0.516477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385861; batch adversarial loss: 0.572025\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415045; batch adversarial loss: 0.571030\n",
      "epoch 89; iter: 0; batch classifier loss: 0.420599; batch adversarial loss: 0.572385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.420456; batch adversarial loss: 0.544233\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385613; batch adversarial loss: 0.572112\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396648; batch adversarial loss: 0.507681\n",
      "epoch 93; iter: 0; batch classifier loss: 0.484556; batch adversarial loss: 0.580625\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384119; batch adversarial loss: 0.544438\n",
      "epoch 95; iter: 0; batch classifier loss: 0.355071; batch adversarial loss: 0.527385\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408336; batch adversarial loss: 0.598027\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334932; batch adversarial loss: 0.617945\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364110; batch adversarial loss: 0.580008\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359851; batch adversarial loss: 0.616530\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399228; batch adversarial loss: 0.535180\n",
      "epoch 101; iter: 0; batch classifier loss: 0.478439; batch adversarial loss: 0.490128\n",
      "epoch 102; iter: 0; batch classifier loss: 0.356571; batch adversarial loss: 0.554307\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362610; batch adversarial loss: 0.608075\n",
      "epoch 104; iter: 0; batch classifier loss: 0.440411; batch adversarial loss: 0.535952\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404392; batch adversarial loss: 0.526596\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335846; batch adversarial loss: 0.579460\n",
      "epoch 107; iter: 0; batch classifier loss: 0.416355; batch adversarial loss: 0.535766\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400672; batch adversarial loss: 0.454033\n",
      "epoch 109; iter: 0; batch classifier loss: 0.307811; batch adversarial loss: 0.551985\n",
      "epoch 110; iter: 0; batch classifier loss: 0.432926; batch adversarial loss: 0.509025\n",
      "epoch 111; iter: 0; batch classifier loss: 0.383346; batch adversarial loss: 0.545916\n",
      "epoch 112; iter: 0; batch classifier loss: 0.445320; batch adversarial loss: 0.544351\n",
      "epoch 113; iter: 0; batch classifier loss: 0.460201; batch adversarial loss: 0.589347\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359642; batch adversarial loss: 0.589778\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388937; batch adversarial loss: 0.508956\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400708; batch adversarial loss: 0.561841\n",
      "epoch 117; iter: 0; batch classifier loss: 0.461261; batch adversarial loss: 0.544598\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366019; batch adversarial loss: 0.525771\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386878; batch adversarial loss: 0.517829\n",
      "epoch 120; iter: 0; batch classifier loss: 0.409700; batch adversarial loss: 0.525702\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390286; batch adversarial loss: 0.571829\n",
      "epoch 122; iter: 0; batch classifier loss: 0.401320; batch adversarial loss: 0.573014\n",
      "epoch 123; iter: 0; batch classifier loss: 0.431930; batch adversarial loss: 0.543841\n",
      "epoch 124; iter: 0; batch classifier loss: 0.390198; batch adversarial loss: 0.589709\n",
      "epoch 125; iter: 0; batch classifier loss: 0.406740; batch adversarial loss: 0.562240\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406126; batch adversarial loss: 0.598107\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389198; batch adversarial loss: 0.499760\n",
      "epoch 128; iter: 0; batch classifier loss: 0.430666; batch adversarial loss: 0.617444\n",
      "epoch 129; iter: 0; batch classifier loss: 0.338236; batch adversarial loss: 0.526854\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394740; batch adversarial loss: 0.617144\n",
      "epoch 131; iter: 0; batch classifier loss: 0.408915; batch adversarial loss: 0.516884\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406244; batch adversarial loss: 0.562857\n",
      "epoch 133; iter: 0; batch classifier loss: 0.316676; batch adversarial loss: 0.626395\n",
      "epoch 134; iter: 0; batch classifier loss: 0.308527; batch adversarial loss: 0.490649\n",
      "epoch 135; iter: 0; batch classifier loss: 0.339643; batch adversarial loss: 0.489319\n",
      "epoch 136; iter: 0; batch classifier loss: 0.307627; batch adversarial loss: 0.598825\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375508; batch adversarial loss: 0.535050\n",
      "epoch 138; iter: 0; batch classifier loss: 0.444976; batch adversarial loss: 0.462061\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335165; batch adversarial loss: 0.507859\n",
      "epoch 140; iter: 0; batch classifier loss: 0.410608; batch adversarial loss: 0.498339\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387972; batch adversarial loss: 0.481478\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376094; batch adversarial loss: 0.561990\n",
      "epoch 143; iter: 0; batch classifier loss: 0.437588; batch adversarial loss: 0.627008\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390818; batch adversarial loss: 0.490760\n",
      "epoch 145; iter: 0; batch classifier loss: 0.345336; batch adversarial loss: 0.599098\n",
      "epoch 146; iter: 0; batch classifier loss: 0.428913; batch adversarial loss: 0.535986\n",
      "epoch 147; iter: 0; batch classifier loss: 0.441869; batch adversarial loss: 0.643265\n",
      "epoch 148; iter: 0; batch classifier loss: 0.460597; batch adversarial loss: 0.472334\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331605; batch adversarial loss: 0.581741\n",
      "epoch 150; iter: 0; batch classifier loss: 0.406700; batch adversarial loss: 0.580217\n",
      "epoch 151; iter: 0; batch classifier loss: 0.314139; batch adversarial loss: 0.508024\n",
      "epoch 152; iter: 0; batch classifier loss: 0.358578; batch adversarial loss: 0.525206\n",
      "epoch 153; iter: 0; batch classifier loss: 0.378451; batch adversarial loss: 0.553146\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365135; batch adversarial loss: 0.562097\n",
      "epoch 155; iter: 0; batch classifier loss: 0.319205; batch adversarial loss: 0.526494\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403055; batch adversarial loss: 0.525563\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344187; batch adversarial loss: 0.527769\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344516; batch adversarial loss: 0.490520\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366502; batch adversarial loss: 0.636088\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344758; batch adversarial loss: 0.660908\n",
      "epoch 161; iter: 0; batch classifier loss: 0.401663; batch adversarial loss: 0.581042\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358144; batch adversarial loss: 0.554513\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369083; batch adversarial loss: 0.607495\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387125; batch adversarial loss: 0.543545\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348602; batch adversarial loss: 0.590027\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367803; batch adversarial loss: 0.517495\n",
      "epoch 167; iter: 0; batch classifier loss: 0.373429; batch adversarial loss: 0.526520\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332897; batch adversarial loss: 0.589589\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386633; batch adversarial loss: 0.526497\n",
      "epoch 170; iter: 0; batch classifier loss: 0.400930; batch adversarial loss: 0.544954\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383866; batch adversarial loss: 0.535758\n",
      "epoch 172; iter: 0; batch classifier loss: 0.308314; batch adversarial loss: 0.500001\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350547; batch adversarial loss: 0.571957\n",
      "epoch 174; iter: 0; batch classifier loss: 0.333253; batch adversarial loss: 0.534897\n",
      "epoch 175; iter: 0; batch classifier loss: 0.350264; batch adversarial loss: 0.573241\n",
      "epoch 176; iter: 0; batch classifier loss: 0.451817; batch adversarial loss: 0.625087\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363096; batch adversarial loss: 0.544131\n",
      "epoch 178; iter: 0; batch classifier loss: 0.422544; batch adversarial loss: 0.580866\n",
      "epoch 179; iter: 0; batch classifier loss: 0.373622; batch adversarial loss: 0.562443\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318668; batch adversarial loss: 0.508754\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342479; batch adversarial loss: 0.553672\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387920; batch adversarial loss: 0.608696\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388128; batch adversarial loss: 0.535567\n",
      "epoch 184; iter: 0; batch classifier loss: 0.429934; batch adversarial loss: 0.545648\n",
      "epoch 185; iter: 0; batch classifier loss: 0.327684; batch adversarial loss: 0.580714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.359962; batch adversarial loss: 0.553723\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395674; batch adversarial loss: 0.526355\n",
      "epoch 188; iter: 0; batch classifier loss: 0.320409; batch adversarial loss: 0.581983\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341082; batch adversarial loss: 0.689797\n",
      "epoch 190; iter: 0; batch classifier loss: 0.406503; batch adversarial loss: 0.535013\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355537; batch adversarial loss: 0.489847\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326263; batch adversarial loss: 0.642878\n",
      "epoch 193; iter: 0; batch classifier loss: 0.421356; batch adversarial loss: 0.552613\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324753; batch adversarial loss: 0.580948\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361240; batch adversarial loss: 0.499580\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366768; batch adversarial loss: 0.581973\n",
      "epoch 197; iter: 0; batch classifier loss: 0.371856; batch adversarial loss: 0.555159\n",
      "epoch 198; iter: 0; batch classifier loss: 0.351331; batch adversarial loss: 0.516792\n",
      "epoch 199; iter: 0; batch classifier loss: 0.457796; batch adversarial loss: 0.517946\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713946; batch adversarial loss: 0.749045\n",
      "epoch 1; iter: 0; batch classifier loss: 0.693730; batch adversarial loss: 0.729364\n",
      "epoch 2; iter: 0; batch classifier loss: 0.654037; batch adversarial loss: 0.669064\n",
      "epoch 3; iter: 0; batch classifier loss: 0.631259; batch adversarial loss: 0.634183\n",
      "epoch 4; iter: 0; batch classifier loss: 0.556679; batch adversarial loss: 0.638273\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588569; batch adversarial loss: 0.615244\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533573; batch adversarial loss: 0.622729\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565801; batch adversarial loss: 0.629531\n",
      "epoch 8; iter: 0; batch classifier loss: 0.548864; batch adversarial loss: 0.602603\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509776; batch adversarial loss: 0.543653\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552873; batch adversarial loss: 0.591577\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565584; batch adversarial loss: 0.550964\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537507; batch adversarial loss: 0.572495\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522686; batch adversarial loss: 0.586371\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499021; batch adversarial loss: 0.554310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475476; batch adversarial loss: 0.591424\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507326; batch adversarial loss: 0.550587\n",
      "epoch 17; iter: 0; batch classifier loss: 0.549515; batch adversarial loss: 0.586773\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501827; batch adversarial loss: 0.564724\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465844; batch adversarial loss: 0.573322\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491184; batch adversarial loss: 0.554011\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484874; batch adversarial loss: 0.629250\n",
      "epoch 22; iter: 0; batch classifier loss: 0.488840; batch adversarial loss: 0.493248\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474511; batch adversarial loss: 0.579059\n",
      "epoch 24; iter: 0; batch classifier loss: 0.439182; batch adversarial loss: 0.561854\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433989; batch adversarial loss: 0.577027\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433810; batch adversarial loss: 0.532755\n",
      "epoch 27; iter: 0; batch classifier loss: 0.382624; batch adversarial loss: 0.547322\n",
      "epoch 28; iter: 0; batch classifier loss: 0.443078; batch adversarial loss: 0.539981\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451004; batch adversarial loss: 0.603691\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470995; batch adversarial loss: 0.564285\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454735; batch adversarial loss: 0.603708\n",
      "epoch 32; iter: 0; batch classifier loss: 0.374803; batch adversarial loss: 0.538485\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477689; batch adversarial loss: 0.589891\n",
      "epoch 34; iter: 0; batch classifier loss: 0.524409; batch adversarial loss: 0.586962\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449268; batch adversarial loss: 0.519427\n",
      "epoch 36; iter: 0; batch classifier loss: 0.375018; batch adversarial loss: 0.493598\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424734; batch adversarial loss: 0.510510\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467941; batch adversarial loss: 0.554118\n",
      "epoch 39; iter: 0; batch classifier loss: 0.400221; batch adversarial loss: 0.562147\n",
      "epoch 40; iter: 0; batch classifier loss: 0.485989; batch adversarial loss: 0.544942\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407983; batch adversarial loss: 0.544797\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383798; batch adversarial loss: 0.553437\n",
      "epoch 43; iter: 0; batch classifier loss: 0.514950; batch adversarial loss: 0.544899\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403560; batch adversarial loss: 0.535755\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376873; batch adversarial loss: 0.571319\n",
      "epoch 46; iter: 0; batch classifier loss: 0.375942; batch adversarial loss: 0.580156\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424432; batch adversarial loss: 0.500416\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442520; batch adversarial loss: 0.438565\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436827; batch adversarial loss: 0.509240\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443843; batch adversarial loss: 0.596111\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427153; batch adversarial loss: 0.448152\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411870; batch adversarial loss: 0.505752\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428757; batch adversarial loss: 0.507187\n",
      "epoch 54; iter: 0; batch classifier loss: 0.347429; batch adversarial loss: 0.502329\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426944; batch adversarial loss: 0.543510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436965; batch adversarial loss: 0.542471\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390395; batch adversarial loss: 0.594394\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411160; batch adversarial loss: 0.601362\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419149; batch adversarial loss: 0.558108\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376565; batch adversarial loss: 0.518191\n",
      "epoch 61; iter: 0; batch classifier loss: 0.325596; batch adversarial loss: 0.583968\n",
      "epoch 62; iter: 0; batch classifier loss: 0.500475; batch adversarial loss: 0.526758\n",
      "epoch 63; iter: 0; batch classifier loss: 0.508998; batch adversarial loss: 0.508613\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406354; batch adversarial loss: 0.568348\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416066; batch adversarial loss: 0.569786\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437595; batch adversarial loss: 0.571541\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366393; batch adversarial loss: 0.538908\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400373; batch adversarial loss: 0.643481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.381734; batch adversarial loss: 0.526238\n",
      "epoch 70; iter: 0; batch classifier loss: 0.498512; batch adversarial loss: 0.536235\n",
      "epoch 71; iter: 0; batch classifier loss: 0.466648; batch adversarial loss: 0.472205\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419389; batch adversarial loss: 0.552090\n",
      "epoch 73; iter: 0; batch classifier loss: 0.337804; batch adversarial loss: 0.558406\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397930; batch adversarial loss: 0.569040\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441618; batch adversarial loss: 0.561679\n",
      "epoch 76; iter: 0; batch classifier loss: 0.455890; batch adversarial loss: 0.621350\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412880; batch adversarial loss: 0.527498\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397278; batch adversarial loss: 0.536750\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420448; batch adversarial loss: 0.522183\n",
      "epoch 80; iter: 0; batch classifier loss: 0.355316; batch adversarial loss: 0.527788\n",
      "epoch 81; iter: 0; batch classifier loss: 0.463747; batch adversarial loss: 0.597146\n",
      "epoch 82; iter: 0; batch classifier loss: 0.425007; batch adversarial loss: 0.591187\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441414; batch adversarial loss: 0.525012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.442794; batch adversarial loss: 0.600771\n",
      "epoch 85; iter: 0; batch classifier loss: 0.437456; batch adversarial loss: 0.581991\n",
      "epoch 86; iter: 0; batch classifier loss: 0.393229; batch adversarial loss: 0.573579\n",
      "epoch 87; iter: 0; batch classifier loss: 0.305623; batch adversarial loss: 0.626675\n",
      "epoch 88; iter: 0; batch classifier loss: 0.445195; batch adversarial loss: 0.619274\n",
      "epoch 89; iter: 0; batch classifier loss: 0.437606; batch adversarial loss: 0.562195\n",
      "epoch 90; iter: 0; batch classifier loss: 0.416903; batch adversarial loss: 0.567815\n",
      "epoch 91; iter: 0; batch classifier loss: 0.477450; batch adversarial loss: 0.501666\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388882; batch adversarial loss: 0.570661\n",
      "epoch 93; iter: 0; batch classifier loss: 0.526415; batch adversarial loss: 0.573020\n",
      "epoch 94; iter: 0; batch classifier loss: 0.497476; batch adversarial loss: 0.535636\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347246; batch adversarial loss: 0.470834\n",
      "epoch 96; iter: 0; batch classifier loss: 0.328707; batch adversarial loss: 0.526058\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396101; batch adversarial loss: 0.599780\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359069; batch adversarial loss: 0.533322\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424614; batch adversarial loss: 0.580159\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411549; batch adversarial loss: 0.516474\n",
      "epoch 101; iter: 0; batch classifier loss: 0.469944; batch adversarial loss: 0.572390\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388228; batch adversarial loss: 0.606633\n",
      "epoch 103; iter: 0; batch classifier loss: 0.338731; batch adversarial loss: 0.575006\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349199; batch adversarial loss: 0.516256\n",
      "epoch 105; iter: 0; batch classifier loss: 0.322782; batch adversarial loss: 0.564303\n",
      "epoch 106; iter: 0; batch classifier loss: 0.418769; batch adversarial loss: 0.544857\n",
      "epoch 107; iter: 0; batch classifier loss: 0.427647; batch adversarial loss: 0.633538\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420875; batch adversarial loss: 0.529467\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384445; batch adversarial loss: 0.536570\n",
      "epoch 110; iter: 0; batch classifier loss: 0.333109; batch adversarial loss: 0.591091\n",
      "epoch 111; iter: 0; batch classifier loss: 0.497242; batch adversarial loss: 0.588824\n",
      "epoch 112; iter: 0; batch classifier loss: 0.420396; batch adversarial loss: 0.612848\n",
      "epoch 113; iter: 0; batch classifier loss: 0.429674; batch adversarial loss: 0.547477\n",
      "epoch 114; iter: 0; batch classifier loss: 0.439045; batch adversarial loss: 0.651890\n",
      "epoch 115; iter: 0; batch classifier loss: 0.449400; batch adversarial loss: 0.564236\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410030; batch adversarial loss: 0.535205\n",
      "epoch 117; iter: 0; batch classifier loss: 0.427067; batch adversarial loss: 0.572502\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402292; batch adversarial loss: 0.634915\n",
      "epoch 119; iter: 0; batch classifier loss: 0.406206; batch adversarial loss: 0.505964\n",
      "epoch 120; iter: 0; batch classifier loss: 0.336851; batch adversarial loss: 0.569977\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398793; batch adversarial loss: 0.533459\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421523; batch adversarial loss: 0.491490\n",
      "epoch 123; iter: 0; batch classifier loss: 0.391078; batch adversarial loss: 0.529725\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393292; batch adversarial loss: 0.534678\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398997; batch adversarial loss: 0.536359\n",
      "epoch 126; iter: 0; batch classifier loss: 0.417801; batch adversarial loss: 0.524736\n",
      "epoch 127; iter: 0; batch classifier loss: 0.392360; batch adversarial loss: 0.621235\n",
      "epoch 128; iter: 0; batch classifier loss: 0.316795; batch adversarial loss: 0.565515\n",
      "epoch 129; iter: 0; batch classifier loss: 0.445264; batch adversarial loss: 0.529855\n",
      "epoch 130; iter: 0; batch classifier loss: 0.478751; batch adversarial loss: 0.597798\n",
      "epoch 131; iter: 0; batch classifier loss: 0.499318; batch adversarial loss: 0.529061\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353232; batch adversarial loss: 0.544906\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352834; batch adversarial loss: 0.587862\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352588; batch adversarial loss: 0.533149\n",
      "epoch 135; iter: 0; batch classifier loss: 0.511932; batch adversarial loss: 0.612482\n",
      "epoch 136; iter: 0; batch classifier loss: 0.424098; batch adversarial loss: 0.566442\n",
      "epoch 137; iter: 0; batch classifier loss: 0.416115; batch adversarial loss: 0.588856\n",
      "epoch 138; iter: 0; batch classifier loss: 0.265015; batch adversarial loss: 0.507862\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401899; batch adversarial loss: 0.480334\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396201; batch adversarial loss: 0.481187\n",
      "epoch 141; iter: 0; batch classifier loss: 0.333416; batch adversarial loss: 0.558410\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386613; batch adversarial loss: 0.568149\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378252; batch adversarial loss: 0.556104\n",
      "epoch 144; iter: 0; batch classifier loss: 0.414099; batch adversarial loss: 0.576497\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319702; batch adversarial loss: 0.588901\n",
      "epoch 146; iter: 0; batch classifier loss: 0.520066; batch adversarial loss: 0.506618\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344530; batch adversarial loss: 0.559490\n",
      "epoch 148; iter: 0; batch classifier loss: 0.428433; batch adversarial loss: 0.526953\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376483; batch adversarial loss: 0.543306\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354901; batch adversarial loss: 0.555907\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373194; batch adversarial loss: 0.565173\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364009; batch adversarial loss: 0.528943\n",
      "epoch 153; iter: 0; batch classifier loss: 0.396068; batch adversarial loss: 0.553406\n",
      "epoch 154; iter: 0; batch classifier loss: 0.260727; batch adversarial loss: 0.499860\n",
      "epoch 155; iter: 0; batch classifier loss: 0.279047; batch adversarial loss: 0.573525\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374566; batch adversarial loss: 0.591039\n",
      "epoch 157; iter: 0; batch classifier loss: 0.440539; batch adversarial loss: 0.496794\n",
      "epoch 158; iter: 0; batch classifier loss: 0.414312; batch adversarial loss: 0.545967\n",
      "epoch 159; iter: 0; batch classifier loss: 0.428373; batch adversarial loss: 0.549087\n",
      "epoch 160; iter: 0; batch classifier loss: 0.442159; batch adversarial loss: 0.507096\n",
      "epoch 161; iter: 0; batch classifier loss: 0.336596; batch adversarial loss: 0.600527\n",
      "epoch 162; iter: 0; batch classifier loss: 0.442674; batch adversarial loss: 0.590036\n",
      "epoch 163; iter: 0; batch classifier loss: 0.371952; batch adversarial loss: 0.519896\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337225; batch adversarial loss: 0.559568\n",
      "epoch 165; iter: 0; batch classifier loss: 0.408497; batch adversarial loss: 0.577295\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388995; batch adversarial loss: 0.582585\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341505; batch adversarial loss: 0.615992\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392469; batch adversarial loss: 0.538013\n",
      "epoch 169; iter: 0; batch classifier loss: 0.237526; batch adversarial loss: 0.526761\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339126; batch adversarial loss: 0.481202\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408172; batch adversarial loss: 0.559421\n",
      "epoch 172; iter: 0; batch classifier loss: 0.488230; batch adversarial loss: 0.586416\n",
      "epoch 173; iter: 0; batch classifier loss: 0.379897; batch adversarial loss: 0.526844\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362387; batch adversarial loss: 0.567126\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357585; batch adversarial loss: 0.550566\n",
      "epoch 176; iter: 0; batch classifier loss: 0.461277; batch adversarial loss: 0.474732\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319314; batch adversarial loss: 0.543052\n",
      "epoch 178; iter: 0; batch classifier loss: 0.402596; batch adversarial loss: 0.488490\n",
      "epoch 179; iter: 0; batch classifier loss: 0.312913; batch adversarial loss: 0.582351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.320992; batch adversarial loss: 0.599951\n",
      "epoch 181; iter: 0; batch classifier loss: 0.306024; batch adversarial loss: 0.537592\n",
      "epoch 182; iter: 0; batch classifier loss: 0.407368; batch adversarial loss: 0.551471\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354504; batch adversarial loss: 0.552804\n",
      "epoch 184; iter: 0; batch classifier loss: 0.307824; batch adversarial loss: 0.498867\n",
      "epoch 185; iter: 0; batch classifier loss: 0.443874; batch adversarial loss: 0.519266\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386417; batch adversarial loss: 0.498420\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333794; batch adversarial loss: 0.496144\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404685; batch adversarial loss: 0.579330\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356445; batch adversarial loss: 0.643122\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380478; batch adversarial loss: 0.521040\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372674; batch adversarial loss: 0.518101\n",
      "epoch 192; iter: 0; batch classifier loss: 0.390282; batch adversarial loss: 0.563559\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307429; batch adversarial loss: 0.546017\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344015; batch adversarial loss: 0.528547\n",
      "epoch 195; iter: 0; batch classifier loss: 0.396883; batch adversarial loss: 0.562546\n",
      "epoch 196; iter: 0; batch classifier loss: 0.377581; batch adversarial loss: 0.570608\n",
      "epoch 197; iter: 0; batch classifier loss: 0.391748; batch adversarial loss: 0.499239\n",
      "epoch 198; iter: 0; batch classifier loss: 0.357688; batch adversarial loss: 0.562069\n",
      "epoch 199; iter: 0; batch classifier loss: 0.445120; batch adversarial loss: 0.536912\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715029; batch adversarial loss: 0.845822\n",
      "epoch 1; iter: 0; batch classifier loss: 0.821892; batch adversarial loss: 0.937931\n",
      "epoch 2; iter: 0; batch classifier loss: 0.936669; batch adversarial loss: 0.865856\n",
      "epoch 3; iter: 0; batch classifier loss: 0.935727; batch adversarial loss: 0.793942\n",
      "epoch 4; iter: 0; batch classifier loss: 0.941734; batch adversarial loss: 0.719864\n",
      "epoch 5; iter: 0; batch classifier loss: 0.946606; batch adversarial loss: 0.689245\n",
      "epoch 6; iter: 0; batch classifier loss: 0.694635; batch adversarial loss: 0.646195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531538; batch adversarial loss: 0.603066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539703; batch adversarial loss: 0.570817\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526191; batch adversarial loss: 0.620792\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579172; batch adversarial loss: 0.598169\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521142; batch adversarial loss: 0.602418\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540159; batch adversarial loss: 0.590019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527723; batch adversarial loss: 0.563083\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518036; batch adversarial loss: 0.556336\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490003; batch adversarial loss: 0.529542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512201; batch adversarial loss: 0.575088\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494030; batch adversarial loss: 0.542815\n",
      "epoch 18; iter: 0; batch classifier loss: 0.606264; batch adversarial loss: 0.614711\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564852; batch adversarial loss: 0.567729\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532056; batch adversarial loss: 0.610461\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469757; batch adversarial loss: 0.623263\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443551; batch adversarial loss: 0.627644\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527260; batch adversarial loss: 0.558374\n",
      "epoch 24; iter: 0; batch classifier loss: 0.472388; batch adversarial loss: 0.618191\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488611; batch adversarial loss: 0.558983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442676; batch adversarial loss: 0.504681\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482219; batch adversarial loss: 0.436315\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488848; batch adversarial loss: 0.610639\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481642; batch adversarial loss: 0.600580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510967; batch adversarial loss: 0.586653\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417771; batch adversarial loss: 0.596930\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500920; batch adversarial loss: 0.544663\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404680; batch adversarial loss: 0.554607\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470963; batch adversarial loss: 0.521622\n",
      "epoch 35; iter: 0; batch classifier loss: 0.509708; batch adversarial loss: 0.547050\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490052; batch adversarial loss: 0.607230\n",
      "epoch 37; iter: 0; batch classifier loss: 0.569810; batch adversarial loss: 0.477355\n",
      "epoch 38; iter: 0; batch classifier loss: 0.372018; batch adversarial loss: 0.591733\n",
      "epoch 39; iter: 0; batch classifier loss: 0.373449; batch adversarial loss: 0.514215\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412594; batch adversarial loss: 0.545507\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432828; batch adversarial loss: 0.675439\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411088; batch adversarial loss: 0.625742\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365984; batch adversarial loss: 0.576276\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427293; batch adversarial loss: 0.564500\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411703; batch adversarial loss: 0.526079\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425905; batch adversarial loss: 0.506943\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403016; batch adversarial loss: 0.581043\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387940; batch adversarial loss: 0.502451\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377433; batch adversarial loss: 0.539863\n",
      "epoch 50; iter: 0; batch classifier loss: 0.466177; batch adversarial loss: 0.537955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441702; batch adversarial loss: 0.530248\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414606; batch adversarial loss: 0.526579\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414464; batch adversarial loss: 0.509531\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443976; batch adversarial loss: 0.517177\n",
      "epoch 55; iter: 0; batch classifier loss: 0.467574; batch adversarial loss: 0.567177\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445491; batch adversarial loss: 0.533706\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454877; batch adversarial loss: 0.518224\n",
      "epoch 58; iter: 0; batch classifier loss: 0.341725; batch adversarial loss: 0.511379\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445267; batch adversarial loss: 0.517599\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401541; batch adversarial loss: 0.508655\n",
      "epoch 61; iter: 0; batch classifier loss: 0.456938; batch adversarial loss: 0.491062\n",
      "epoch 62; iter: 0; batch classifier loss: 0.310361; batch adversarial loss: 0.628130\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425497; batch adversarial loss: 0.545534\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359953; batch adversarial loss: 0.544506\n",
      "epoch 65; iter: 0; batch classifier loss: 0.350199; batch adversarial loss: 0.517912\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385643; batch adversarial loss: 0.589732\n",
      "epoch 67; iter: 0; batch classifier loss: 0.396939; batch adversarial loss: 0.562282\n",
      "epoch 68; iter: 0; batch classifier loss: 0.350014; batch adversarial loss: 0.509545\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373437; batch adversarial loss: 0.598160\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359481; batch adversarial loss: 0.526220\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390557; batch adversarial loss: 0.534903\n",
      "epoch 72; iter: 0; batch classifier loss: 0.360919; batch adversarial loss: 0.525149\n",
      "epoch 73; iter: 0; batch classifier loss: 0.351087; batch adversarial loss: 0.553289\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374114; batch adversarial loss: 0.582056\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366198; batch adversarial loss: 0.518622\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359399; batch adversarial loss: 0.580814\n",
      "epoch 77; iter: 0; batch classifier loss: 0.350011; batch adversarial loss: 0.554725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.400933; batch adversarial loss: 0.518406\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387220; batch adversarial loss: 0.517611\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380459; batch adversarial loss: 0.507654\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376561; batch adversarial loss: 0.572170\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389618; batch adversarial loss: 0.590166\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411668; batch adversarial loss: 0.507237\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371273; batch adversarial loss: 0.517897\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361167; batch adversarial loss: 0.527057\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408906; batch adversarial loss: 0.580423\n",
      "epoch 87; iter: 0; batch classifier loss: 0.388885; batch adversarial loss: 0.535739\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369041; batch adversarial loss: 0.653626\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402959; batch adversarial loss: 0.496984\n",
      "epoch 90; iter: 0; batch classifier loss: 0.343760; batch adversarial loss: 0.683563\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334896; batch adversarial loss: 0.635405\n",
      "epoch 92; iter: 0; batch classifier loss: 0.306231; batch adversarial loss: 0.544737\n",
      "epoch 93; iter: 0; batch classifier loss: 0.382677; batch adversarial loss: 0.472449\n",
      "epoch 94; iter: 0; batch classifier loss: 0.351095; batch adversarial loss: 0.507938\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394491; batch adversarial loss: 0.545144\n",
      "epoch 96; iter: 0; batch classifier loss: 0.456345; batch adversarial loss: 0.508045\n",
      "epoch 97; iter: 0; batch classifier loss: 0.319909; batch adversarial loss: 0.517303\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401594; batch adversarial loss: 0.507546\n",
      "epoch 99; iter: 0; batch classifier loss: 0.321899; batch adversarial loss: 0.526504\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400807; batch adversarial loss: 0.479346\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426416; batch adversarial loss: 0.590220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331504; batch adversarial loss: 0.554272\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429122; batch adversarial loss: 0.489993\n",
      "epoch 104; iter: 0; batch classifier loss: 0.339595; batch adversarial loss: 0.490392\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337467; batch adversarial loss: 0.544575\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381165; batch adversarial loss: 0.571898\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374628; batch adversarial loss: 0.535527\n",
      "epoch 108; iter: 0; batch classifier loss: 0.317056; batch adversarial loss: 0.544375\n",
      "epoch 109; iter: 0; batch classifier loss: 0.382727; batch adversarial loss: 0.480602\n",
      "epoch 110; iter: 0; batch classifier loss: 0.292948; batch adversarial loss: 0.571978\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398072; batch adversarial loss: 0.535998\n",
      "epoch 112; iter: 0; batch classifier loss: 0.307959; batch adversarial loss: 0.589884\n",
      "epoch 113; iter: 0; batch classifier loss: 0.253102; batch adversarial loss: 0.471091\n",
      "epoch 114; iter: 0; batch classifier loss: 0.269995; batch adversarial loss: 0.516605\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332560; batch adversarial loss: 0.518035\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369604; batch adversarial loss: 0.608376\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381143; batch adversarial loss: 0.481146\n",
      "epoch 118; iter: 0; batch classifier loss: 0.263250; batch adversarial loss: 0.543797\n",
      "epoch 119; iter: 0; batch classifier loss: 0.299633; batch adversarial loss: 0.506518\n",
      "epoch 120; iter: 0; batch classifier loss: 0.368430; batch adversarial loss: 0.524007\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361413; batch adversarial loss: 0.588519\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377923; batch adversarial loss: 0.534095\n",
      "epoch 123; iter: 0; batch classifier loss: 0.338909; batch adversarial loss: 0.516329\n",
      "epoch 124; iter: 0; batch classifier loss: 0.341229; batch adversarial loss: 0.535229\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334387; batch adversarial loss: 0.609081\n",
      "epoch 126; iter: 0; batch classifier loss: 0.410745; batch adversarial loss: 0.553821\n",
      "epoch 127; iter: 0; batch classifier loss: 0.317208; batch adversarial loss: 0.553261\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351356; batch adversarial loss: 0.562647\n",
      "epoch 129; iter: 0; batch classifier loss: 0.269228; batch adversarial loss: 0.589776\n",
      "epoch 130; iter: 0; batch classifier loss: 0.305062; batch adversarial loss: 0.562954\n",
      "epoch 131; iter: 0; batch classifier loss: 0.314290; batch adversarial loss: 0.581122\n",
      "epoch 132; iter: 0; batch classifier loss: 0.277232; batch adversarial loss: 0.516852\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356744; batch adversarial loss: 0.508183\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381506; batch adversarial loss: 0.498939\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376468; batch adversarial loss: 0.507874\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371553; batch adversarial loss: 0.607709\n",
      "epoch 137; iter: 0; batch classifier loss: 0.300784; batch adversarial loss: 0.553407\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366145; batch adversarial loss: 0.591120\n",
      "epoch 139; iter: 0; batch classifier loss: 0.325444; batch adversarial loss: 0.507190\n",
      "epoch 140; iter: 0; batch classifier loss: 0.289331; batch adversarial loss: 0.564424\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367314; batch adversarial loss: 0.552811\n",
      "epoch 142; iter: 0; batch classifier loss: 0.251994; batch adversarial loss: 0.636283\n",
      "epoch 143; iter: 0; batch classifier loss: 0.297942; batch adversarial loss: 0.461912\n",
      "epoch 144; iter: 0; batch classifier loss: 0.291332; batch adversarial loss: 0.472158\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377306; batch adversarial loss: 0.545184\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366851; batch adversarial loss: 0.570031\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373181; batch adversarial loss: 0.580498\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349500; batch adversarial loss: 0.608957\n",
      "epoch 149; iter: 0; batch classifier loss: 0.326338; batch adversarial loss: 0.598789\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342761; batch adversarial loss: 0.553748\n",
      "epoch 151; iter: 0; batch classifier loss: 0.292011; batch adversarial loss: 0.564250\n",
      "epoch 152; iter: 0; batch classifier loss: 0.292327; batch adversarial loss: 0.527969\n",
      "epoch 153; iter: 0; batch classifier loss: 0.313032; batch adversarial loss: 0.516968\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346400; batch adversarial loss: 0.553263\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314323; batch adversarial loss: 0.580095\n",
      "epoch 156; iter: 0; batch classifier loss: 0.322799; batch adversarial loss: 0.606215\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370679; batch adversarial loss: 0.563142\n",
      "epoch 158; iter: 0; batch classifier loss: 0.379793; batch adversarial loss: 0.528411\n",
      "epoch 159; iter: 0; batch classifier loss: 0.293862; batch adversarial loss: 0.470897\n",
      "epoch 160; iter: 0; batch classifier loss: 0.281923; batch adversarial loss: 0.489409\n",
      "epoch 161; iter: 0; batch classifier loss: 0.293097; batch adversarial loss: 0.407480\n",
      "epoch 162; iter: 0; batch classifier loss: 0.333201; batch adversarial loss: 0.534399\n",
      "epoch 163; iter: 0; batch classifier loss: 0.272548; batch adversarial loss: 0.564000\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351519; batch adversarial loss: 0.591795\n",
      "epoch 165; iter: 0; batch classifier loss: 0.367580; batch adversarial loss: 0.552789\n",
      "epoch 166; iter: 0; batch classifier loss: 0.273324; batch adversarial loss: 0.664527\n",
      "epoch 167; iter: 0; batch classifier loss: 0.233473; batch adversarial loss: 0.535399\n",
      "epoch 168; iter: 0; batch classifier loss: 0.371647; batch adversarial loss: 0.599444\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343775; batch adversarial loss: 0.535561\n",
      "epoch 170; iter: 0; batch classifier loss: 0.331359; batch adversarial loss: 0.591280\n",
      "epoch 171; iter: 0; batch classifier loss: 0.293006; batch adversarial loss: 0.553616\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378344; batch adversarial loss: 0.526765\n",
      "epoch 173; iter: 0; batch classifier loss: 0.326337; batch adversarial loss: 0.543372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.363947; batch adversarial loss: 0.634705\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395147; batch adversarial loss: 0.564634\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328033; batch adversarial loss: 0.572099\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369559; batch adversarial loss: 0.526136\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332387; batch adversarial loss: 0.499918\n",
      "epoch 179; iter: 0; batch classifier loss: 0.299297; batch adversarial loss: 0.499044\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333103; batch adversarial loss: 0.604437\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337051; batch adversarial loss: 0.560892\n",
      "epoch 182; iter: 0; batch classifier loss: 0.255534; batch adversarial loss: 0.528931\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370649; batch adversarial loss: 0.598496\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331620; batch adversarial loss: 0.500081\n",
      "epoch 185; iter: 0; batch classifier loss: 0.271537; batch adversarial loss: 0.608315\n",
      "epoch 186; iter: 0; batch classifier loss: 0.272406; batch adversarial loss: 0.489186\n",
      "epoch 187; iter: 0; batch classifier loss: 0.299317; batch adversarial loss: 0.571190\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346927; batch adversarial loss: 0.608210\n",
      "epoch 189; iter: 0; batch classifier loss: 0.321003; batch adversarial loss: 0.553591\n",
      "epoch 190; iter: 0; batch classifier loss: 0.258139; batch adversarial loss: 0.562556\n",
      "epoch 191; iter: 0; batch classifier loss: 0.232973; batch adversarial loss: 0.581599\n",
      "epoch 192; iter: 0; batch classifier loss: 0.403300; batch adversarial loss: 0.553096\n",
      "epoch 193; iter: 0; batch classifier loss: 0.273983; batch adversarial loss: 0.627618\n",
      "epoch 194; iter: 0; batch classifier loss: 0.280018; batch adversarial loss: 0.599085\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327201; batch adversarial loss: 0.571961\n",
      "epoch 196; iter: 0; batch classifier loss: 0.290415; batch adversarial loss: 0.590209\n",
      "epoch 197; iter: 0; batch classifier loss: 0.308438; batch adversarial loss: 0.435430\n",
      "epoch 198; iter: 0; batch classifier loss: 0.298755; batch adversarial loss: 0.536245\n",
      "epoch 199; iter: 0; batch classifier loss: 0.263770; batch adversarial loss: 0.571993\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669093; batch adversarial loss: 0.576836\n",
      "epoch 1; iter: 0; batch classifier loss: 0.648470; batch adversarial loss: 0.640656\n",
      "epoch 2; iter: 0; batch classifier loss: 0.719906; batch adversarial loss: 0.734958\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585913; batch adversarial loss: 0.737187\n",
      "epoch 4; iter: 0; batch classifier loss: 0.625230; batch adversarial loss: 0.666546\n",
      "epoch 5; iter: 0; batch classifier loss: 0.659221; batch adversarial loss: 0.674899\n",
      "epoch 6; iter: 0; batch classifier loss: 0.613566; batch adversarial loss: 0.631886\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559791; batch adversarial loss: 0.627146\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579980; batch adversarial loss: 0.613046\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546775; batch adversarial loss: 0.596401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.602454; batch adversarial loss: 0.636798\n",
      "epoch 11; iter: 0; batch classifier loss: 0.606230; batch adversarial loss: 0.693474\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572651; batch adversarial loss: 0.670254\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544945; batch adversarial loss: 0.521208\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554657; batch adversarial loss: 0.581652\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570105; batch adversarial loss: 0.580131\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511111; batch adversarial loss: 0.628278\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503478; batch adversarial loss: 0.553874\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530155; batch adversarial loss: 0.569154\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448169; batch adversarial loss: 0.553004\n",
      "epoch 20; iter: 0; batch classifier loss: 0.553299; batch adversarial loss: 0.588273\n",
      "epoch 21; iter: 0; batch classifier loss: 0.531415; batch adversarial loss: 0.648032\n",
      "epoch 22; iter: 0; batch classifier loss: 0.528822; batch adversarial loss: 0.602599\n",
      "epoch 23; iter: 0; batch classifier loss: 0.529065; batch adversarial loss: 0.635472\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440545; batch adversarial loss: 0.680677\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466551; batch adversarial loss: 0.612935\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440765; batch adversarial loss: 0.510005\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453131; batch adversarial loss: 0.561527\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493277; batch adversarial loss: 0.632164\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482411; batch adversarial loss: 0.553585\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422744; batch adversarial loss: 0.535339\n",
      "epoch 31; iter: 0; batch classifier loss: 0.519635; batch adversarial loss: 0.545556\n",
      "epoch 32; iter: 0; batch classifier loss: 0.502957; batch adversarial loss: 0.510151\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406362; batch adversarial loss: 0.536709\n",
      "epoch 34; iter: 0; batch classifier loss: 0.538358; batch adversarial loss: 0.526503\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457165; batch adversarial loss: 0.547859\n",
      "epoch 36; iter: 0; batch classifier loss: 0.386924; batch adversarial loss: 0.542630\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409036; batch adversarial loss: 0.496065\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470208; batch adversarial loss: 0.538569\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403384; batch adversarial loss: 0.544883\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490842; batch adversarial loss: 0.580983\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417737; batch adversarial loss: 0.558500\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428712; batch adversarial loss: 0.569071\n",
      "epoch 43; iter: 0; batch classifier loss: 0.503514; batch adversarial loss: 0.503825\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473041; batch adversarial loss: 0.531904\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433194; batch adversarial loss: 0.524952\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417948; batch adversarial loss: 0.551080\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444135; batch adversarial loss: 0.522780\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478423; batch adversarial loss: 0.636312\n",
      "epoch 49; iter: 0; batch classifier loss: 0.524983; batch adversarial loss: 0.570882\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395356; batch adversarial loss: 0.550414\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469088; batch adversarial loss: 0.557564\n",
      "epoch 52; iter: 0; batch classifier loss: 0.397020; batch adversarial loss: 0.566851\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427424; batch adversarial loss: 0.510185\n",
      "epoch 54; iter: 0; batch classifier loss: 0.458663; batch adversarial loss: 0.588528\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482516; batch adversarial loss: 0.572306\n",
      "epoch 56; iter: 0; batch classifier loss: 0.513205; batch adversarial loss: 0.543067\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382487; batch adversarial loss: 0.550376\n",
      "epoch 58; iter: 0; batch classifier loss: 0.412662; batch adversarial loss: 0.617051\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410939; batch adversarial loss: 0.562929\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421488; batch adversarial loss: 0.544487\n",
      "epoch 61; iter: 0; batch classifier loss: 0.371669; batch adversarial loss: 0.505740\n",
      "epoch 62; iter: 0; batch classifier loss: 0.505466; batch adversarial loss: 0.609569\n",
      "epoch 63; iter: 0; batch classifier loss: 0.469822; batch adversarial loss: 0.533471\n",
      "epoch 64; iter: 0; batch classifier loss: 0.453068; batch adversarial loss: 0.585749\n",
      "epoch 65; iter: 0; batch classifier loss: 0.468465; batch adversarial loss: 0.518734\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435686; batch adversarial loss: 0.528346\n",
      "epoch 67; iter: 0; batch classifier loss: 0.527073; batch adversarial loss: 0.543543\n",
      "epoch 68; iter: 0; batch classifier loss: 0.477372; batch adversarial loss: 0.558965\n",
      "epoch 69; iter: 0; batch classifier loss: 0.450612; batch adversarial loss: 0.522051\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393252; batch adversarial loss: 0.617531\n",
      "epoch 71; iter: 0; batch classifier loss: 0.457112; batch adversarial loss: 0.599789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.385960; batch adversarial loss: 0.538473\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440598; batch adversarial loss: 0.567419\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416343; batch adversarial loss: 0.584154\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413793; batch adversarial loss: 0.564548\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385189; batch adversarial loss: 0.500708\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436022; batch adversarial loss: 0.422489\n",
      "epoch 78; iter: 0; batch classifier loss: 0.463160; batch adversarial loss: 0.551498\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396599; batch adversarial loss: 0.575551\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447941; batch adversarial loss: 0.546359\n",
      "epoch 81; iter: 0; batch classifier loss: 0.441788; batch adversarial loss: 0.597488\n",
      "epoch 82; iter: 0; batch classifier loss: 0.481967; batch adversarial loss: 0.493002\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419056; batch adversarial loss: 0.527480\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408066; batch adversarial loss: 0.545442\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363299; batch adversarial loss: 0.465269\n",
      "epoch 86; iter: 0; batch classifier loss: 0.342156; batch adversarial loss: 0.533783\n",
      "epoch 87; iter: 0; batch classifier loss: 0.334141; batch adversarial loss: 0.578891\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433536; batch adversarial loss: 0.579401\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413717; batch adversarial loss: 0.515973\n",
      "epoch 90; iter: 0; batch classifier loss: 0.400918; batch adversarial loss: 0.491559\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390681; batch adversarial loss: 0.544221\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386028; batch adversarial loss: 0.498513\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363673; batch adversarial loss: 0.543984\n",
      "epoch 94; iter: 0; batch classifier loss: 0.481688; batch adversarial loss: 0.547227\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347815; batch adversarial loss: 0.525037\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394739; batch adversarial loss: 0.573919\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397048; batch adversarial loss: 0.509940\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385211; batch adversarial loss: 0.527389\n",
      "epoch 99; iter: 0; batch classifier loss: 0.352595; batch adversarial loss: 0.582039\n",
      "epoch 100; iter: 0; batch classifier loss: 0.436812; batch adversarial loss: 0.526517\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408640; batch adversarial loss: 0.588934\n",
      "epoch 102; iter: 0; batch classifier loss: 0.505420; batch adversarial loss: 0.475175\n",
      "epoch 103; iter: 0; batch classifier loss: 0.288496; batch adversarial loss: 0.623740\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376037; batch adversarial loss: 0.527423\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416130; batch adversarial loss: 0.579900\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386487; batch adversarial loss: 0.508523\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436719; batch adversarial loss: 0.616697\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420729; batch adversarial loss: 0.480761\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400752; batch adversarial loss: 0.553387\n",
      "epoch 110; iter: 0; batch classifier loss: 0.346255; batch adversarial loss: 0.554410\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344473; batch adversarial loss: 0.543327\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396755; batch adversarial loss: 0.546097\n",
      "epoch 113; iter: 0; batch classifier loss: 0.376057; batch adversarial loss: 0.552161\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363502; batch adversarial loss: 0.506265\n",
      "epoch 115; iter: 0; batch classifier loss: 0.485156; batch adversarial loss: 0.635452\n",
      "epoch 116; iter: 0; batch classifier loss: 0.437349; batch adversarial loss: 0.535799\n",
      "epoch 117; iter: 0; batch classifier loss: 0.483341; batch adversarial loss: 0.537729\n",
      "epoch 118; iter: 0; batch classifier loss: 0.321800; batch adversarial loss: 0.617665\n",
      "epoch 119; iter: 0; batch classifier loss: 0.438958; batch adversarial loss: 0.573752\n",
      "epoch 120; iter: 0; batch classifier loss: 0.412495; batch adversarial loss: 0.519631\n",
      "epoch 121; iter: 0; batch classifier loss: 0.367040; batch adversarial loss: 0.518180\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382441; batch adversarial loss: 0.650903\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425729; batch adversarial loss: 0.641905\n",
      "epoch 124; iter: 0; batch classifier loss: 0.431539; batch adversarial loss: 0.517302\n",
      "epoch 125; iter: 0; batch classifier loss: 0.403748; batch adversarial loss: 0.499633\n",
      "epoch 126; iter: 0; batch classifier loss: 0.308551; batch adversarial loss: 0.525973\n",
      "epoch 127; iter: 0; batch classifier loss: 0.440912; batch adversarial loss: 0.606775\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338866; batch adversarial loss: 0.534795\n",
      "epoch 129; iter: 0; batch classifier loss: 0.451157; batch adversarial loss: 0.547080\n",
      "epoch 130; iter: 0; batch classifier loss: 0.315448; batch adversarial loss: 0.552609\n",
      "epoch 131; iter: 0; batch classifier loss: 0.285480; batch adversarial loss: 0.470016\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402281; batch adversarial loss: 0.564461\n",
      "epoch 133; iter: 0; batch classifier loss: 0.384760; batch adversarial loss: 0.508624\n",
      "epoch 134; iter: 0; batch classifier loss: 0.436661; batch adversarial loss: 0.589883\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351157; batch adversarial loss: 0.552152\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373868; batch adversarial loss: 0.560113\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396398; batch adversarial loss: 0.598591\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394179; batch adversarial loss: 0.588556\n",
      "epoch 139; iter: 0; batch classifier loss: 0.319666; batch adversarial loss: 0.518770\n",
      "epoch 140; iter: 0; batch classifier loss: 0.438267; batch adversarial loss: 0.501899\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367193; batch adversarial loss: 0.536068\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356197; batch adversarial loss: 0.624933\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361169; batch adversarial loss: 0.615943\n",
      "epoch 144; iter: 0; batch classifier loss: 0.404481; batch adversarial loss: 0.607323\n",
      "epoch 145; iter: 0; batch classifier loss: 0.421860; batch adversarial loss: 0.562375\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343836; batch adversarial loss: 0.571134\n",
      "epoch 147; iter: 0; batch classifier loss: 0.399462; batch adversarial loss: 0.525678\n",
      "epoch 148; iter: 0; batch classifier loss: 0.283763; batch adversarial loss: 0.509673\n",
      "epoch 149; iter: 0; batch classifier loss: 0.424703; batch adversarial loss: 0.625594\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351342; batch adversarial loss: 0.461544\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390610; batch adversarial loss: 0.617622\n",
      "epoch 152; iter: 0; batch classifier loss: 0.450877; batch adversarial loss: 0.509406\n",
      "epoch 153; iter: 0; batch classifier loss: 0.412707; batch adversarial loss: 0.669382\n",
      "epoch 154; iter: 0; batch classifier loss: 0.411618; batch adversarial loss: 0.580630\n",
      "epoch 155; iter: 0; batch classifier loss: 0.443236; batch adversarial loss: 0.598377\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398433; batch adversarial loss: 0.544888\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324628; batch adversarial loss: 0.535258\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362452; batch adversarial loss: 0.525908\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373955; batch adversarial loss: 0.535828\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376974; batch adversarial loss: 0.527436\n",
      "epoch 161; iter: 0; batch classifier loss: 0.323717; batch adversarial loss: 0.561614\n",
      "epoch 162; iter: 0; batch classifier loss: 0.321896; batch adversarial loss: 0.499277\n",
      "epoch 163; iter: 0; batch classifier loss: 0.416125; batch adversarial loss: 0.599000\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375884; batch adversarial loss: 0.570463\n",
      "epoch 165; iter: 0; batch classifier loss: 0.447929; batch adversarial loss: 0.580732\n",
      "epoch 166; iter: 0; batch classifier loss: 0.419303; batch adversarial loss: 0.517739\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362888; batch adversarial loss: 0.642515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.365743; batch adversarial loss: 0.525916\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372127; batch adversarial loss: 0.499086\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380427; batch adversarial loss: 0.490443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.449823; batch adversarial loss: 0.561335\n",
      "epoch 172; iter: 0; batch classifier loss: 0.314796; batch adversarial loss: 0.599466\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410829; batch adversarial loss: 0.535775\n",
      "epoch 174; iter: 0; batch classifier loss: 0.335175; batch adversarial loss: 0.490525\n",
      "epoch 175; iter: 0; batch classifier loss: 0.391424; batch adversarial loss: 0.598978\n",
      "epoch 176; iter: 0; batch classifier loss: 0.449866; batch adversarial loss: 0.589690\n",
      "epoch 177; iter: 0; batch classifier loss: 0.402671; batch adversarial loss: 0.526098\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335894; batch adversarial loss: 0.571787\n",
      "epoch 179; iter: 0; batch classifier loss: 0.421641; batch adversarial loss: 0.500616\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382077; batch adversarial loss: 0.509291\n",
      "epoch 181; iter: 0; batch classifier loss: 0.444355; batch adversarial loss: 0.563247\n",
      "epoch 182; iter: 0; batch classifier loss: 0.394733; batch adversarial loss: 0.454700\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370245; batch adversarial loss: 0.536332\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372079; batch adversarial loss: 0.605858\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368352; batch adversarial loss: 0.599151\n",
      "epoch 186; iter: 0; batch classifier loss: 0.300239; batch adversarial loss: 0.563153\n",
      "epoch 187; iter: 0; batch classifier loss: 0.423071; batch adversarial loss: 0.535641\n",
      "epoch 188; iter: 0; batch classifier loss: 0.389483; batch adversarial loss: 0.508943\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346973; batch adversarial loss: 0.562995\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329516; batch adversarial loss: 0.518054\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330853; batch adversarial loss: 0.553413\n",
      "epoch 192; iter: 0; batch classifier loss: 0.426380; batch adversarial loss: 0.526480\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378262; batch adversarial loss: 0.571290\n",
      "epoch 194; iter: 0; batch classifier loss: 0.306128; batch adversarial loss: 0.579964\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397444; batch adversarial loss: 0.571852\n",
      "epoch 196; iter: 0; batch classifier loss: 0.350619; batch adversarial loss: 0.608381\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344801; batch adversarial loss: 0.544202\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324799; batch adversarial loss: 0.509667\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315730; batch adversarial loss: 0.607094\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725815; batch adversarial loss: 0.736890\n",
      "epoch 1; iter: 0; batch classifier loss: 0.664517; batch adversarial loss: 0.697116\n",
      "epoch 2; iter: 0; batch classifier loss: 0.544400; batch adversarial loss: 0.641706\n",
      "epoch 3; iter: 0; batch classifier loss: 0.620364; batch adversarial loss: 0.662507\n",
      "epoch 4; iter: 0; batch classifier loss: 0.493441; batch adversarial loss: 0.656888\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537307; batch adversarial loss: 0.611428\n",
      "epoch 6; iter: 0; batch classifier loss: 0.507973; batch adversarial loss: 0.610933\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510039; batch adversarial loss: 0.618078\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572160; batch adversarial loss: 0.593614\n",
      "epoch 9; iter: 0; batch classifier loss: 0.515212; batch adversarial loss: 0.577425\n",
      "epoch 10; iter: 0; batch classifier loss: 0.601381; batch adversarial loss: 0.580989\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542337; batch adversarial loss: 0.569034\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497799; batch adversarial loss: 0.596750\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541319; batch adversarial loss: 0.544034\n",
      "epoch 14; iter: 0; batch classifier loss: 0.574699; batch adversarial loss: 0.537949\n",
      "epoch 15; iter: 0; batch classifier loss: 0.449513; batch adversarial loss: 0.627936\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476097; batch adversarial loss: 0.554777\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459117; batch adversarial loss: 0.559220\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478590; batch adversarial loss: 0.483245\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482744; batch adversarial loss: 0.558178\n",
      "epoch 20; iter: 0; batch classifier loss: 0.567611; batch adversarial loss: 0.541349\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525267; batch adversarial loss: 0.563461\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471112; batch adversarial loss: 0.592577\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467771; batch adversarial loss: 0.573923\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496420; batch adversarial loss: 0.510919\n",
      "epoch 25; iter: 0; batch classifier loss: 0.416934; batch adversarial loss: 0.558458\n",
      "epoch 26; iter: 0; batch classifier loss: 0.570107; batch adversarial loss: 0.571500\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482238; batch adversarial loss: 0.533055\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485911; batch adversarial loss: 0.585253\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439842; batch adversarial loss: 0.524810\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495465; batch adversarial loss: 0.553799\n",
      "epoch 31; iter: 0; batch classifier loss: 0.404446; batch adversarial loss: 0.547576\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420975; batch adversarial loss: 0.528574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467266; batch adversarial loss: 0.484950\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398234; batch adversarial loss: 0.535424\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485133; batch adversarial loss: 0.613960\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478668; batch adversarial loss: 0.526402\n",
      "epoch 37; iter: 0; batch classifier loss: 0.362335; batch adversarial loss: 0.589304\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473145; batch adversarial loss: 0.475812\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457806; batch adversarial loss: 0.553793\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434497; batch adversarial loss: 0.482931\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469944; batch adversarial loss: 0.580986\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463704; batch adversarial loss: 0.518095\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492481; batch adversarial loss: 0.571232\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468146; batch adversarial loss: 0.535876\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435041; batch adversarial loss: 0.526357\n",
      "epoch 46; iter: 0; batch classifier loss: 0.473918; batch adversarial loss: 0.553023\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438624; batch adversarial loss: 0.544175\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404677; batch adversarial loss: 0.508476\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407663; batch adversarial loss: 0.499052\n",
      "epoch 50; iter: 0; batch classifier loss: 0.360444; batch adversarial loss: 0.563975\n",
      "epoch 51; iter: 0; batch classifier loss: 0.395567; batch adversarial loss: 0.562201\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427300; batch adversarial loss: 0.606498\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452174; batch adversarial loss: 0.516708\n",
      "epoch 54; iter: 0; batch classifier loss: 0.356750; batch adversarial loss: 0.607871\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482097; batch adversarial loss: 0.519172\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408081; batch adversarial loss: 0.643876\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425444; batch adversarial loss: 0.571489\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407623; batch adversarial loss: 0.554136\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425689; batch adversarial loss: 0.509338\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402117; batch adversarial loss: 0.553716\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396105; batch adversarial loss: 0.560274\n",
      "epoch 62; iter: 0; batch classifier loss: 0.375903; batch adversarial loss: 0.463144\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384210; batch adversarial loss: 0.544604\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384777; batch adversarial loss: 0.562936\n",
      "epoch 65; iter: 0; batch classifier loss: 0.364572; batch adversarial loss: 0.579790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.385093; batch adversarial loss: 0.479628\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384559; batch adversarial loss: 0.497528\n",
      "epoch 68; iter: 0; batch classifier loss: 0.456677; batch adversarial loss: 0.590772\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397689; batch adversarial loss: 0.579858\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413060; batch adversarial loss: 0.543956\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429285; batch adversarial loss: 0.444772\n",
      "epoch 72; iter: 0; batch classifier loss: 0.332705; batch adversarial loss: 0.562413\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355930; batch adversarial loss: 0.544528\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384029; batch adversarial loss: 0.637474\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393715; batch adversarial loss: 0.635261\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391402; batch adversarial loss: 0.635399\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372341; batch adversarial loss: 0.563234\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365131; batch adversarial loss: 0.601071\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362262; batch adversarial loss: 0.626061\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470388; batch adversarial loss: 0.435061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400809; batch adversarial loss: 0.463607\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352643; batch adversarial loss: 0.444386\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371633; batch adversarial loss: 0.471923\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410767; batch adversarial loss: 0.601006\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344795; batch adversarial loss: 0.536206\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371263; batch adversarial loss: 0.563778\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398126; batch adversarial loss: 0.446658\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395228; batch adversarial loss: 0.571958\n",
      "epoch 89; iter: 0; batch classifier loss: 0.416736; batch adversarial loss: 0.579484\n",
      "epoch 90; iter: 0; batch classifier loss: 0.361253; batch adversarial loss: 0.607549\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433295; batch adversarial loss: 0.627969\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384591; batch adversarial loss: 0.552256\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368113; batch adversarial loss: 0.562240\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452871; batch adversarial loss: 0.526316\n",
      "epoch 95; iter: 0; batch classifier loss: 0.299841; batch adversarial loss: 0.608376\n",
      "epoch 96; iter: 0; batch classifier loss: 0.363530; batch adversarial loss: 0.525083\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411513; batch adversarial loss: 0.499460\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392428; batch adversarial loss: 0.515575\n",
      "epoch 99; iter: 0; batch classifier loss: 0.333182; batch adversarial loss: 0.554724\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421664; batch adversarial loss: 0.571411\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363112; batch adversarial loss: 0.490201\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386792; batch adversarial loss: 0.515052\n",
      "epoch 103; iter: 0; batch classifier loss: 0.319180; batch adversarial loss: 0.607820\n",
      "epoch 104; iter: 0; batch classifier loss: 0.388781; batch adversarial loss: 0.560968\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361064; batch adversarial loss: 0.513665\n",
      "epoch 106; iter: 0; batch classifier loss: 0.342570; batch adversarial loss: 0.553139\n",
      "epoch 107; iter: 0; batch classifier loss: 0.461924; batch adversarial loss: 0.518768\n",
      "epoch 108; iter: 0; batch classifier loss: 0.374378; batch adversarial loss: 0.599978\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365177; batch adversarial loss: 0.561917\n",
      "epoch 110; iter: 0; batch classifier loss: 0.470295; batch adversarial loss: 0.598842\n",
      "epoch 111; iter: 0; batch classifier loss: 0.426381; batch adversarial loss: 0.589320\n",
      "epoch 112; iter: 0; batch classifier loss: 0.417212; batch adversarial loss: 0.625691\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383184; batch adversarial loss: 0.527456\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362001; batch adversarial loss: 0.563251\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373634; batch adversarial loss: 0.469320\n",
      "epoch 116; iter: 0; batch classifier loss: 0.463365; batch adversarial loss: 0.536905\n",
      "epoch 117; iter: 0; batch classifier loss: 0.294015; batch adversarial loss: 0.561852\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381804; batch adversarial loss: 0.517739\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363048; batch adversarial loss: 0.637133\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399758; batch adversarial loss: 0.609516\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392407; batch adversarial loss: 0.527130\n",
      "epoch 122; iter: 0; batch classifier loss: 0.414886; batch adversarial loss: 0.578796\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403005; batch adversarial loss: 0.560347\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368073; batch adversarial loss: 0.515854\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391086; batch adversarial loss: 0.535668\n",
      "epoch 126; iter: 0; batch classifier loss: 0.324012; batch adversarial loss: 0.536990\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355250; batch adversarial loss: 0.544798\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361323; batch adversarial loss: 0.435463\n",
      "epoch 129; iter: 0; batch classifier loss: 0.292728; batch adversarial loss: 0.616843\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398493; batch adversarial loss: 0.552660\n",
      "epoch 131; iter: 0; batch classifier loss: 0.346311; batch adversarial loss: 0.545047\n",
      "epoch 132; iter: 0; batch classifier loss: 0.374918; batch adversarial loss: 0.582316\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302591; batch adversarial loss: 0.486843\n",
      "epoch 134; iter: 0; batch classifier loss: 0.257396; batch adversarial loss: 0.516397\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363582; batch adversarial loss: 0.571213\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369167; batch adversarial loss: 0.526154\n",
      "epoch 137; iter: 0; batch classifier loss: 0.362599; batch adversarial loss: 0.536044\n",
      "epoch 138; iter: 0; batch classifier loss: 0.410256; batch adversarial loss: 0.554418\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381809; batch adversarial loss: 0.599043\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371091; batch adversarial loss: 0.624902\n",
      "epoch 141; iter: 0; batch classifier loss: 0.294127; batch adversarial loss: 0.527322\n",
      "epoch 142; iter: 0; batch classifier loss: 0.399632; batch adversarial loss: 0.505189\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306973; batch adversarial loss: 0.618271\n",
      "epoch 144; iter: 0; batch classifier loss: 0.345116; batch adversarial loss: 0.551977\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339409; batch adversarial loss: 0.617802\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366101; batch adversarial loss: 0.552979\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379464; batch adversarial loss: 0.545382\n",
      "epoch 148; iter: 0; batch classifier loss: 0.320473; batch adversarial loss: 0.560982\n",
      "epoch 149; iter: 0; batch classifier loss: 0.348468; batch adversarial loss: 0.508382\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361253; batch adversarial loss: 0.516618\n",
      "epoch 151; iter: 0; batch classifier loss: 0.331416; batch adversarial loss: 0.617184\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386281; batch adversarial loss: 0.518019\n",
      "epoch 153; iter: 0; batch classifier loss: 0.426084; batch adversarial loss: 0.601102\n",
      "epoch 154; iter: 0; batch classifier loss: 0.411943; batch adversarial loss: 0.590953\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351107; batch adversarial loss: 0.545493\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341535; batch adversarial loss: 0.608758\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359222; batch adversarial loss: 0.581921\n",
      "epoch 158; iter: 0; batch classifier loss: 0.372603; batch adversarial loss: 0.596181\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383071; batch adversarial loss: 0.606716\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347000; batch adversarial loss: 0.561446\n",
      "epoch 161; iter: 0; batch classifier loss: 0.421041; batch adversarial loss: 0.524729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.418157; batch adversarial loss: 0.543888\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380396; batch adversarial loss: 0.498797\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387571; batch adversarial loss: 0.507325\n",
      "epoch 165; iter: 0; batch classifier loss: 0.303159; batch adversarial loss: 0.517804\n",
      "epoch 166; iter: 0; batch classifier loss: 0.405678; batch adversarial loss: 0.572451\n",
      "epoch 167; iter: 0; batch classifier loss: 0.402465; batch adversarial loss: 0.491069\n",
      "epoch 168; iter: 0; batch classifier loss: 0.350697; batch adversarial loss: 0.570954\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403126; batch adversarial loss: 0.488849\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353936; batch adversarial loss: 0.591491\n",
      "epoch 171; iter: 0; batch classifier loss: 0.291500; batch adversarial loss: 0.497421\n",
      "epoch 172; iter: 0; batch classifier loss: 0.337489; batch adversarial loss: 0.599948\n",
      "epoch 173; iter: 0; batch classifier loss: 0.396992; batch adversarial loss: 0.536325\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371926; batch adversarial loss: 0.569017\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306350; batch adversarial loss: 0.564161\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360053; batch adversarial loss: 0.626150\n",
      "epoch 177; iter: 0; batch classifier loss: 0.285261; batch adversarial loss: 0.452994\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361972; batch adversarial loss: 0.517229\n",
      "epoch 179; iter: 0; batch classifier loss: 0.376408; batch adversarial loss: 0.608292\n",
      "epoch 180; iter: 0; batch classifier loss: 0.281503; batch adversarial loss: 0.498270\n",
      "epoch 181; iter: 0; batch classifier loss: 0.336939; batch adversarial loss: 0.534915\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378181; batch adversarial loss: 0.515334\n",
      "epoch 183; iter: 0; batch classifier loss: 0.289892; batch adversarial loss: 0.472679\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352492; batch adversarial loss: 0.582299\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371767; batch adversarial loss: 0.545792\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383853; batch adversarial loss: 0.552604\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327266; batch adversarial loss: 0.601021\n",
      "epoch 188; iter: 0; batch classifier loss: 0.350533; batch adversarial loss: 0.561751\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350148; batch adversarial loss: 0.580813\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329512; batch adversarial loss: 0.564194\n",
      "epoch 191; iter: 0; batch classifier loss: 0.408927; batch adversarial loss: 0.525241\n",
      "epoch 192; iter: 0; batch classifier loss: 0.405011; batch adversarial loss: 0.472942\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389603; batch adversarial loss: 0.545215\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364580; batch adversarial loss: 0.517742\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390587; batch adversarial loss: 0.583063\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355005; batch adversarial loss: 0.579534\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353125; batch adversarial loss: 0.571071\n",
      "epoch 198; iter: 0; batch classifier loss: 0.398076; batch adversarial loss: 0.599124\n",
      "epoch 199; iter: 0; batch classifier loss: 0.391200; batch adversarial loss: 0.599737\n",
      "epoch 0; iter: 0; batch classifier loss: 0.652387; batch adversarial loss: 0.682699\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567486; batch adversarial loss: 0.667979\n",
      "epoch 2; iter: 0; batch classifier loss: 0.601284; batch adversarial loss: 0.640455\n",
      "epoch 3; iter: 0; batch classifier loss: 0.688116; batch adversarial loss: 0.653841\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585840; batch adversarial loss: 0.650628\n",
      "epoch 5; iter: 0; batch classifier loss: 0.603925; batch adversarial loss: 0.632738\n",
      "epoch 6; iter: 0; batch classifier loss: 0.493533; batch adversarial loss: 0.570471\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553278; batch adversarial loss: 0.540229\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547027; batch adversarial loss: 0.618870\n",
      "epoch 9; iter: 0; batch classifier loss: 0.498916; batch adversarial loss: 0.647904\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570089; batch adversarial loss: 0.601703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529573; batch adversarial loss: 0.570788\n",
      "epoch 12; iter: 0; batch classifier loss: 0.477442; batch adversarial loss: 0.639327\n",
      "epoch 13; iter: 0; batch classifier loss: 0.590621; batch adversarial loss: 0.553397\n",
      "epoch 14; iter: 0; batch classifier loss: 0.447492; batch adversarial loss: 0.573248\n",
      "epoch 15; iter: 0; batch classifier loss: 0.479653; batch adversarial loss: 0.591055\n",
      "epoch 16; iter: 0; batch classifier loss: 0.407108; batch adversarial loss: 0.566767\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479213; batch adversarial loss: 0.521404\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506867; batch adversarial loss: 0.519451\n",
      "epoch 19; iter: 0; batch classifier loss: 0.551230; batch adversarial loss: 0.558697\n",
      "epoch 20; iter: 0; batch classifier loss: 0.575801; batch adversarial loss: 0.540750\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510279; batch adversarial loss: 0.546574\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469645; batch adversarial loss: 0.523471\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504597; batch adversarial loss: 0.610233\n",
      "epoch 24; iter: 0; batch classifier loss: 0.544130; batch adversarial loss: 0.611004\n",
      "epoch 25; iter: 0; batch classifier loss: 0.545644; batch adversarial loss: 0.493269\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457367; batch adversarial loss: 0.519800\n",
      "epoch 27; iter: 0; batch classifier loss: 0.524161; batch adversarial loss: 0.580237\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515002; batch adversarial loss: 0.589111\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465752; batch adversarial loss: 0.548345\n",
      "epoch 30; iter: 0; batch classifier loss: 0.523463; batch adversarial loss: 0.573034\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443503; batch adversarial loss: 0.597477\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497260; batch adversarial loss: 0.516145\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453590; batch adversarial loss: 0.550436\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423254; batch adversarial loss: 0.515598\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491934; batch adversarial loss: 0.501703\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449636; batch adversarial loss: 0.533928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.484420; batch adversarial loss: 0.546928\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488412; batch adversarial loss: 0.525226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477632; batch adversarial loss: 0.547800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458941; batch adversarial loss: 0.553388\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425512; batch adversarial loss: 0.580816\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460034; batch adversarial loss: 0.553087\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486331; batch adversarial loss: 0.592018\n",
      "epoch 44; iter: 0; batch classifier loss: 0.511315; batch adversarial loss: 0.487643\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445919; batch adversarial loss: 0.553636\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433046; batch adversarial loss: 0.535680\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480920; batch adversarial loss: 0.580368\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417564; batch adversarial loss: 0.534497\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421623; batch adversarial loss: 0.590588\n",
      "epoch 50; iter: 0; batch classifier loss: 0.358217; batch adversarial loss: 0.526511\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415295; batch adversarial loss: 0.553097\n",
      "epoch 52; iter: 0; batch classifier loss: 0.331827; batch adversarial loss: 0.535231\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422810; batch adversarial loss: 0.621402\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419984; batch adversarial loss: 0.581855\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405384; batch adversarial loss: 0.609737\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393067; batch adversarial loss: 0.526461\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401625; batch adversarial loss: 0.536458\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389800; batch adversarial loss: 0.471091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.406759; batch adversarial loss: 0.487876\n",
      "epoch 60; iter: 0; batch classifier loss: 0.486100; batch adversarial loss: 0.497592\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395596; batch adversarial loss: 0.525478\n",
      "epoch 62; iter: 0; batch classifier loss: 0.467176; batch adversarial loss: 0.537504\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376034; batch adversarial loss: 0.469604\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429330; batch adversarial loss: 0.497718\n",
      "epoch 65; iter: 0; batch classifier loss: 0.399365; batch adversarial loss: 0.488555\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446569; batch adversarial loss: 0.525245\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385474; batch adversarial loss: 0.517487\n",
      "epoch 68; iter: 0; batch classifier loss: 0.332050; batch adversarial loss: 0.583126\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451851; batch adversarial loss: 0.562444\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417725; batch adversarial loss: 0.467149\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377910; batch adversarial loss: 0.470241\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429280; batch adversarial loss: 0.583804\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389055; batch adversarial loss: 0.619189\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471613; batch adversarial loss: 0.524764\n",
      "epoch 75; iter: 0; batch classifier loss: 0.444382; batch adversarial loss: 0.554499\n",
      "epoch 76; iter: 0; batch classifier loss: 0.488699; batch adversarial loss: 0.498309\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433645; batch adversarial loss: 0.554760\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413868; batch adversarial loss: 0.516492\n",
      "epoch 79; iter: 0; batch classifier loss: 0.479917; batch adversarial loss: 0.497531\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401999; batch adversarial loss: 0.572448\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358369; batch adversarial loss: 0.572124\n",
      "epoch 82; iter: 0; batch classifier loss: 0.347184; batch adversarial loss: 0.562891\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400270; batch adversarial loss: 0.582431\n",
      "epoch 84; iter: 0; batch classifier loss: 0.428551; batch adversarial loss: 0.600181\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409267; batch adversarial loss: 0.498026\n",
      "epoch 86; iter: 0; batch classifier loss: 0.480955; batch adversarial loss: 0.543691\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387262; batch adversarial loss: 0.582607\n",
      "epoch 88; iter: 0; batch classifier loss: 0.435284; batch adversarial loss: 0.600734\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452690; batch adversarial loss: 0.571942\n",
      "epoch 90; iter: 0; batch classifier loss: 0.414213; batch adversarial loss: 0.581662\n",
      "epoch 91; iter: 0; batch classifier loss: 0.347054; batch adversarial loss: 0.581687\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382558; batch adversarial loss: 0.432683\n",
      "epoch 93; iter: 0; batch classifier loss: 0.350742; batch adversarial loss: 0.545817\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382272; batch adversarial loss: 0.553936\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400524; batch adversarial loss: 0.534956\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396050; batch adversarial loss: 0.582467\n",
      "epoch 97; iter: 0; batch classifier loss: 0.419351; batch adversarial loss: 0.562781\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373814; batch adversarial loss: 0.563151\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367491; batch adversarial loss: 0.590556\n",
      "epoch 100; iter: 0; batch classifier loss: 0.369898; batch adversarial loss: 0.496872\n",
      "epoch 101; iter: 0; batch classifier loss: 0.409595; batch adversarial loss: 0.534687\n",
      "epoch 102; iter: 0; batch classifier loss: 0.387908; batch adversarial loss: 0.479443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346353; batch adversarial loss: 0.469866\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393667; batch adversarial loss: 0.535233\n",
      "epoch 105; iter: 0; batch classifier loss: 0.431341; batch adversarial loss: 0.525839\n",
      "epoch 106; iter: 0; batch classifier loss: 0.463205; batch adversarial loss: 0.609063\n",
      "epoch 107; iter: 0; batch classifier loss: 0.439216; batch adversarial loss: 0.636867\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369948; batch adversarial loss: 0.554119\n",
      "epoch 109; iter: 0; batch classifier loss: 0.409340; batch adversarial loss: 0.573343\n",
      "epoch 110; iter: 0; batch classifier loss: 0.374538; batch adversarial loss: 0.507374\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372091; batch adversarial loss: 0.572469\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356468; batch adversarial loss: 0.534664\n",
      "epoch 113; iter: 0; batch classifier loss: 0.342662; batch adversarial loss: 0.534173\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351845; batch adversarial loss: 0.515256\n",
      "epoch 115; iter: 0; batch classifier loss: 0.402995; batch adversarial loss: 0.498803\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366538; batch adversarial loss: 0.561347\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399611; batch adversarial loss: 0.515747\n",
      "epoch 118; iter: 0; batch classifier loss: 0.468802; batch adversarial loss: 0.479123\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385899; batch adversarial loss: 0.506922\n",
      "epoch 120; iter: 0; batch classifier loss: 0.307141; batch adversarial loss: 0.534172\n",
      "epoch 121; iter: 0; batch classifier loss: 0.450423; batch adversarial loss: 0.543555\n",
      "epoch 122; iter: 0; batch classifier loss: 0.440585; batch adversarial loss: 0.582559\n",
      "epoch 123; iter: 0; batch classifier loss: 0.460957; batch adversarial loss: 0.648647\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418076; batch adversarial loss: 0.561411\n",
      "epoch 125; iter: 0; batch classifier loss: 0.453982; batch adversarial loss: 0.545144\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396508; batch adversarial loss: 0.562087\n",
      "epoch 127; iter: 0; batch classifier loss: 0.425385; batch adversarial loss: 0.554267\n",
      "epoch 128; iter: 0; batch classifier loss: 0.388216; batch adversarial loss: 0.572918\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380654; batch adversarial loss: 0.516971\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348315; batch adversarial loss: 0.470490\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414208; batch adversarial loss: 0.572086\n",
      "epoch 132; iter: 0; batch classifier loss: 0.399389; batch adversarial loss: 0.535580\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408102; batch adversarial loss: 0.525397\n",
      "epoch 134; iter: 0; batch classifier loss: 0.412267; batch adversarial loss: 0.591052\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373338; batch adversarial loss: 0.507556\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387452; batch adversarial loss: 0.553964\n",
      "epoch 137; iter: 0; batch classifier loss: 0.327887; batch adversarial loss: 0.468717\n",
      "epoch 138; iter: 0; batch classifier loss: 0.391420; batch adversarial loss: 0.600700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371157; batch adversarial loss: 0.488454\n",
      "epoch 140; iter: 0; batch classifier loss: 0.395733; batch adversarial loss: 0.478579\n",
      "epoch 141; iter: 0; batch classifier loss: 0.410638; batch adversarial loss: 0.535445\n",
      "epoch 142; iter: 0; batch classifier loss: 0.449118; batch adversarial loss: 0.497919\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381868; batch adversarial loss: 0.553469\n",
      "epoch 144; iter: 0; batch classifier loss: 0.471423; batch adversarial loss: 0.553097\n",
      "epoch 145; iter: 0; batch classifier loss: 0.428410; batch adversarial loss: 0.525567\n",
      "epoch 146; iter: 0; batch classifier loss: 0.386562; batch adversarial loss: 0.590914\n",
      "epoch 147; iter: 0; batch classifier loss: 0.409194; batch adversarial loss: 0.563186\n",
      "epoch 148; iter: 0; batch classifier loss: 0.422763; batch adversarial loss: 0.515992\n",
      "epoch 149; iter: 0; batch classifier loss: 0.466340; batch adversarial loss: 0.487375\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356567; batch adversarial loss: 0.601692\n",
      "epoch 151; iter: 0; batch classifier loss: 0.439305; batch adversarial loss: 0.609583\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384264; batch adversarial loss: 0.507237\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321785; batch adversarial loss: 0.610213\n",
      "epoch 154; iter: 0; batch classifier loss: 0.428767; batch adversarial loss: 0.498177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.348069; batch adversarial loss: 0.581714\n",
      "epoch 156; iter: 0; batch classifier loss: 0.327308; batch adversarial loss: 0.563059\n",
      "epoch 157; iter: 0; batch classifier loss: 0.441478; batch adversarial loss: 0.544255\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363725; batch adversarial loss: 0.637788\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373532; batch adversarial loss: 0.544872\n",
      "epoch 160; iter: 0; batch classifier loss: 0.454535; batch adversarial loss: 0.534658\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318602; batch adversarial loss: 0.601903\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364906; batch adversarial loss: 0.601534\n",
      "epoch 163; iter: 0; batch classifier loss: 0.426684; batch adversarial loss: 0.628540\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394212; batch adversarial loss: 0.600877\n",
      "epoch 165; iter: 0; batch classifier loss: 0.336099; batch adversarial loss: 0.487752\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357009; batch adversarial loss: 0.564685\n",
      "epoch 167; iter: 0; batch classifier loss: 0.299865; batch adversarial loss: 0.535761\n",
      "epoch 168; iter: 0; batch classifier loss: 0.421571; batch adversarial loss: 0.507065\n",
      "epoch 169; iter: 0; batch classifier loss: 0.448672; batch adversarial loss: 0.488609\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368967; batch adversarial loss: 0.655999\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353360; batch adversarial loss: 0.507321\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330773; batch adversarial loss: 0.582133\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355856; batch adversarial loss: 0.544159\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345098; batch adversarial loss: 0.487913\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346609; batch adversarial loss: 0.628269\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387004; batch adversarial loss: 0.488568\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339684; batch adversarial loss: 0.544458\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416597; batch adversarial loss: 0.582545\n",
      "epoch 179; iter: 0; batch classifier loss: 0.304678; batch adversarial loss: 0.544540\n",
      "epoch 180; iter: 0; batch classifier loss: 0.435755; batch adversarial loss: 0.563302\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355347; batch adversarial loss: 0.535227\n",
      "epoch 182; iter: 0; batch classifier loss: 0.309314; batch adversarial loss: 0.572779\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373286; batch adversarial loss: 0.469945\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329329; batch adversarial loss: 0.590912\n",
      "epoch 185; iter: 0; batch classifier loss: 0.482097; batch adversarial loss: 0.619145\n",
      "epoch 186; iter: 0; batch classifier loss: 0.403049; batch adversarial loss: 0.610214\n",
      "epoch 187; iter: 0; batch classifier loss: 0.429757; batch adversarial loss: 0.563926\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352398; batch adversarial loss: 0.479337\n",
      "epoch 189; iter: 0; batch classifier loss: 0.415166; batch adversarial loss: 0.535152\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321774; batch adversarial loss: 0.441983\n",
      "epoch 191; iter: 0; batch classifier loss: 0.416765; batch adversarial loss: 0.590709\n",
      "epoch 192; iter: 0; batch classifier loss: 0.399906; batch adversarial loss: 0.534912\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395043; batch adversarial loss: 0.479131\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382975; batch adversarial loss: 0.506917\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353496; batch adversarial loss: 0.563062\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373975; batch adversarial loss: 0.534939\n",
      "epoch 197; iter: 0; batch classifier loss: 0.385060; batch adversarial loss: 0.563406\n",
      "epoch 198; iter: 0; batch classifier loss: 0.427891; batch adversarial loss: 0.553554\n",
      "epoch 199; iter: 0; batch classifier loss: 0.420684; batch adversarial loss: 0.507128\n",
      "epoch 0; iter: 0; batch classifier loss: 0.855850; batch adversarial loss: 1.152717\n",
      "epoch 1; iter: 0; batch classifier loss: 0.902229; batch adversarial loss: 1.235608\n",
      "epoch 2; iter: 0; batch classifier loss: 0.937904; batch adversarial loss: 1.167847\n",
      "epoch 3; iter: 0; batch classifier loss: 1.147596; batch adversarial loss: 1.121900\n",
      "epoch 4; iter: 0; batch classifier loss: 1.127627; batch adversarial loss: 1.024397\n",
      "epoch 5; iter: 0; batch classifier loss: 1.067559; batch adversarial loss: 0.926405\n",
      "epoch 6; iter: 0; batch classifier loss: 1.224985; batch adversarial loss: 0.882848\n",
      "epoch 7; iter: 0; batch classifier loss: 1.051997; batch adversarial loss: 0.811112\n",
      "epoch 8; iter: 0; batch classifier loss: 0.964203; batch adversarial loss: 0.744842\n",
      "epoch 9; iter: 0; batch classifier loss: 0.855496; batch adversarial loss: 0.699913\n",
      "epoch 10; iter: 0; batch classifier loss: 0.805413; batch adversarial loss: 0.661670\n",
      "epoch 11; iter: 0; batch classifier loss: 0.649848; batch adversarial loss: 0.657623\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545223; batch adversarial loss: 0.572212\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543945; batch adversarial loss: 0.581476\n",
      "epoch 14; iter: 0; batch classifier loss: 0.625993; batch adversarial loss: 0.574528\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506228; batch adversarial loss: 0.580050\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542882; batch adversarial loss: 0.543488\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531439; batch adversarial loss: 0.513820\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497687; batch adversarial loss: 0.578079\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481822; batch adversarial loss: 0.540277\n",
      "epoch 20; iter: 0; batch classifier loss: 0.520200; batch adversarial loss: 0.574780\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524849; batch adversarial loss: 0.592829\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496386; batch adversarial loss: 0.583425\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508554; batch adversarial loss: 0.527254\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460757; batch adversarial loss: 0.527651\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502678; batch adversarial loss: 0.560743\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460949; batch adversarial loss: 0.614157\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493495; batch adversarial loss: 0.548692\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432046; batch adversarial loss: 0.599107\n",
      "epoch 29; iter: 0; batch classifier loss: 0.531182; batch adversarial loss: 0.501032\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430396; batch adversarial loss: 0.591040\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462690; batch adversarial loss: 0.629641\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465776; batch adversarial loss: 0.499044\n",
      "epoch 33; iter: 0; batch classifier loss: 0.428375; batch adversarial loss: 0.509370\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447760; batch adversarial loss: 0.579249\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511068; batch adversarial loss: 0.586052\n",
      "epoch 36; iter: 0; batch classifier loss: 0.408777; batch adversarial loss: 0.522272\n",
      "epoch 37; iter: 0; batch classifier loss: 0.435699; batch adversarial loss: 0.535040\n",
      "epoch 38; iter: 0; batch classifier loss: 0.556183; batch adversarial loss: 0.560079\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411900; batch adversarial loss: 0.521666\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398662; batch adversarial loss: 0.538690\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436512; batch adversarial loss: 0.488596\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420543; batch adversarial loss: 0.555752\n",
      "epoch 43; iter: 0; batch classifier loss: 0.499607; batch adversarial loss: 0.521022\n",
      "epoch 44; iter: 0; batch classifier loss: 0.523917; batch adversarial loss: 0.611464\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444003; batch adversarial loss: 0.593092\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434461; batch adversarial loss: 0.589586\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444494; batch adversarial loss: 0.575340\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439754; batch adversarial loss: 0.517089\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447186; batch adversarial loss: 0.462323\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417185; batch adversarial loss: 0.524208\n",
      "epoch 51; iter: 0; batch classifier loss: 0.403247; batch adversarial loss: 0.549173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442466; batch adversarial loss: 0.580634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.409518; batch adversarial loss: 0.498068\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446159; batch adversarial loss: 0.592693\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446727; batch adversarial loss: 0.546776\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408598; batch adversarial loss: 0.501859\n",
      "epoch 57; iter: 0; batch classifier loss: 0.310553; batch adversarial loss: 0.545287\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401646; batch adversarial loss: 0.546570\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413408; batch adversarial loss: 0.609617\n",
      "epoch 60; iter: 0; batch classifier loss: 0.493353; batch adversarial loss: 0.569964\n",
      "epoch 61; iter: 0; batch classifier loss: 0.431493; batch adversarial loss: 0.497788\n",
      "epoch 62; iter: 0; batch classifier loss: 0.488608; batch adversarial loss: 0.600267\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434048; batch adversarial loss: 0.545389\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407930; batch adversarial loss: 0.517377\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365526; batch adversarial loss: 0.554023\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452622; batch adversarial loss: 0.508981\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402140; batch adversarial loss: 0.509255\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391966; batch adversarial loss: 0.526705\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389133; batch adversarial loss: 0.516710\n",
      "epoch 70; iter: 0; batch classifier loss: 0.506038; batch adversarial loss: 0.581382\n",
      "epoch 71; iter: 0; batch classifier loss: 0.440341; batch adversarial loss: 0.534853\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401822; batch adversarial loss: 0.470943\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375465; batch adversarial loss: 0.590202\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410333; batch adversarial loss: 0.608703\n",
      "epoch 75; iter: 0; batch classifier loss: 0.346867; batch adversarial loss: 0.581236\n",
      "epoch 76; iter: 0; batch classifier loss: 0.340800; batch adversarial loss: 0.535384\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351279; batch adversarial loss: 0.553886\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347499; batch adversarial loss: 0.535499\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343078; batch adversarial loss: 0.517069\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371611; batch adversarial loss: 0.498852\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413085; batch adversarial loss: 0.544616\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394929; batch adversarial loss: 0.535252\n",
      "epoch 83; iter: 0; batch classifier loss: 0.431822; batch adversarial loss: 0.572477\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412145; batch adversarial loss: 0.553760\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380483; batch adversarial loss: 0.553909\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365654; batch adversarial loss: 0.507817\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455667; batch adversarial loss: 0.572686\n",
      "epoch 88; iter: 0; batch classifier loss: 0.349623; batch adversarial loss: 0.590981\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432003; batch adversarial loss: 0.488941\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391446; batch adversarial loss: 0.498181\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412229; batch adversarial loss: 0.536161\n",
      "epoch 92; iter: 0; batch classifier loss: 0.341354; batch adversarial loss: 0.526412\n",
      "epoch 93; iter: 0; batch classifier loss: 0.320847; batch adversarial loss: 0.563452\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410455; batch adversarial loss: 0.507617\n",
      "epoch 95; iter: 0; batch classifier loss: 0.336643; batch adversarial loss: 0.581766\n",
      "epoch 96; iter: 0; batch classifier loss: 0.467391; batch adversarial loss: 0.508103\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404864; batch adversarial loss: 0.515966\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365965; batch adversarial loss: 0.498253\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414715; batch adversarial loss: 0.516893\n",
      "epoch 100; iter: 0; batch classifier loss: 0.301453; batch adversarial loss: 0.525916\n",
      "epoch 101; iter: 0; batch classifier loss: 0.329216; batch adversarial loss: 0.563313\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363777; batch adversarial loss: 0.507074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390343; batch adversarial loss: 0.600255\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369137; batch adversarial loss: 0.526681\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394822; batch adversarial loss: 0.488479\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359138; batch adversarial loss: 0.470771\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372004; batch adversarial loss: 0.498250\n",
      "epoch 108; iter: 0; batch classifier loss: 0.446176; batch adversarial loss: 0.526127\n",
      "epoch 109; iter: 0; batch classifier loss: 0.335271; batch adversarial loss: 0.562369\n",
      "epoch 110; iter: 0; batch classifier loss: 0.334234; batch adversarial loss: 0.572907\n",
      "epoch 111; iter: 0; batch classifier loss: 0.330612; batch adversarial loss: 0.627264\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391940; batch adversarial loss: 0.543146\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343041; batch adversarial loss: 0.600041\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426743; batch adversarial loss: 0.544256\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423763; batch adversarial loss: 0.460984\n",
      "epoch 116; iter: 0; batch classifier loss: 0.329556; batch adversarial loss: 0.488455\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377457; batch adversarial loss: 0.526053\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383045; batch adversarial loss: 0.498322\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323382; batch adversarial loss: 0.432791\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388373; batch adversarial loss: 0.618350\n",
      "epoch 121; iter: 0; batch classifier loss: 0.283210; batch adversarial loss: 0.508379\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367869; batch adversarial loss: 0.590799\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367530; batch adversarial loss: 0.525870\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405638; batch adversarial loss: 0.524795\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350012; batch adversarial loss: 0.599725\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369353; batch adversarial loss: 0.452169\n",
      "epoch 127; iter: 0; batch classifier loss: 0.265447; batch adversarial loss: 0.479194\n",
      "epoch 128; iter: 0; batch classifier loss: 0.406258; batch adversarial loss: 0.555114\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337430; batch adversarial loss: 0.535496\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376145; batch adversarial loss: 0.534356\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385915; batch adversarial loss: 0.488936\n",
      "epoch 132; iter: 0; batch classifier loss: 0.298574; batch adversarial loss: 0.497633\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411010; batch adversarial loss: 0.526091\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343052; batch adversarial loss: 0.599969\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375239; batch adversarial loss: 0.573085\n",
      "epoch 136; iter: 0; batch classifier loss: 0.299889; batch adversarial loss: 0.516300\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383644; batch adversarial loss: 0.572461\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359540; batch adversarial loss: 0.517098\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377572; batch adversarial loss: 0.536245\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329481; batch adversarial loss: 0.572137\n",
      "epoch 141; iter: 0; batch classifier loss: 0.388811; batch adversarial loss: 0.572397\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375786; batch adversarial loss: 0.619225\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346094; batch adversarial loss: 0.627519\n",
      "epoch 144; iter: 0; batch classifier loss: 0.309297; batch adversarial loss: 0.555265\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355254; batch adversarial loss: 0.545758\n",
      "epoch 146; iter: 0; batch classifier loss: 0.415882; batch adversarial loss: 0.599974\n",
      "epoch 147; iter: 0; batch classifier loss: 0.371807; batch adversarial loss: 0.581032\n",
      "epoch 148; iter: 0; batch classifier loss: 0.404720; batch adversarial loss: 0.525494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.320266; batch adversarial loss: 0.590356\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352055; batch adversarial loss: 0.590326\n",
      "epoch 151; iter: 0; batch classifier loss: 0.316872; batch adversarial loss: 0.563572\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382794; batch adversarial loss: 0.499727\n",
      "epoch 153; iter: 0; batch classifier loss: 0.302566; batch adversarial loss: 0.591185\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363345; batch adversarial loss: 0.563891\n",
      "epoch 155; iter: 0; batch classifier loss: 0.318908; batch adversarial loss: 0.646781\n",
      "epoch 156; iter: 0; batch classifier loss: 0.299945; batch adversarial loss: 0.581077\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.461508\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323811; batch adversarial loss: 0.461371\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400484; batch adversarial loss: 0.525231\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337906; batch adversarial loss: 0.563655\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316734; batch adversarial loss: 0.525958\n",
      "epoch 162; iter: 0; batch classifier loss: 0.310597; batch adversarial loss: 0.544375\n",
      "epoch 163; iter: 0; batch classifier loss: 0.282914; batch adversarial loss: 0.525600\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373904; batch adversarial loss: 0.525609\n",
      "epoch 165; iter: 0; batch classifier loss: 0.274284; batch adversarial loss: 0.527367\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323723; batch adversarial loss: 0.516304\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347779; batch adversarial loss: 0.581498\n",
      "epoch 168; iter: 0; batch classifier loss: 0.250011; batch adversarial loss: 0.497944\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403691; batch adversarial loss: 0.516630\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319141; batch adversarial loss: 0.498229\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349429; batch adversarial loss: 0.535704\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358957; batch adversarial loss: 0.516596\n",
      "epoch 173; iter: 0; batch classifier loss: 0.379759; batch adversarial loss: 0.517068\n",
      "epoch 174; iter: 0; batch classifier loss: 0.307199; batch adversarial loss: 0.516894\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395386; batch adversarial loss: 0.600180\n",
      "epoch 176; iter: 0; batch classifier loss: 0.226754; batch adversarial loss: 0.562339\n",
      "epoch 177; iter: 0; batch classifier loss: 0.418352; batch adversarial loss: 0.535277\n",
      "epoch 178; iter: 0; batch classifier loss: 0.292367; batch adversarial loss: 0.461826\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391779; batch adversarial loss: 0.526645\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358049; batch adversarial loss: 0.506944\n",
      "epoch 181; iter: 0; batch classifier loss: 0.448699; batch adversarial loss: 0.554928\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352926; batch adversarial loss: 0.489131\n",
      "epoch 183; iter: 0; batch classifier loss: 0.228488; batch adversarial loss: 0.517434\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330291; batch adversarial loss: 0.534801\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358084; batch adversarial loss: 0.562494\n",
      "epoch 186; iter: 0; batch classifier loss: 0.351246; batch adversarial loss: 0.487137\n",
      "epoch 187; iter: 0; batch classifier loss: 0.412962; batch adversarial loss: 0.655829\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346178; batch adversarial loss: 0.526357\n",
      "epoch 189; iter: 0; batch classifier loss: 0.270892; batch adversarial loss: 0.553352\n",
      "epoch 190; iter: 0; batch classifier loss: 0.298369; batch adversarial loss: 0.581675\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364950; batch adversarial loss: 0.525758\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297519; batch adversarial loss: 0.592085\n",
      "epoch 193; iter: 0; batch classifier loss: 0.272483; batch adversarial loss: 0.507313\n",
      "epoch 194; iter: 0; batch classifier loss: 0.414098; batch adversarial loss: 0.592574\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342637; batch adversarial loss: 0.544070\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366741; batch adversarial loss: 0.507889\n",
      "epoch 197; iter: 0; batch classifier loss: 0.230195; batch adversarial loss: 0.552485\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383947; batch adversarial loss: 0.535467\n",
      "epoch 199; iter: 0; batch classifier loss: 0.300668; batch adversarial loss: 0.580994\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670391; batch adversarial loss: 0.749909\n",
      "epoch 1; iter: 0; batch classifier loss: 0.659744; batch adversarial loss: 0.754405\n",
      "epoch 2; iter: 0; batch classifier loss: 0.724636; batch adversarial loss: 0.716139\n",
      "epoch 3; iter: 0; batch classifier loss: 0.636010; batch adversarial loss: 0.652901\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607370; batch adversarial loss: 0.654186\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544465; batch adversarial loss: 0.605396\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578144; batch adversarial loss: 0.627587\n",
      "epoch 7; iter: 0; batch classifier loss: 0.450198; batch adversarial loss: 0.606590\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513714; batch adversarial loss: 0.585384\n",
      "epoch 9; iter: 0; batch classifier loss: 0.555021; batch adversarial loss: 0.564516\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568325; batch adversarial loss: 0.562660\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507220; batch adversarial loss: 0.561568\n",
      "epoch 12; iter: 0; batch classifier loss: 0.466789; batch adversarial loss: 0.570944\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498488; batch adversarial loss: 0.548279\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530366; batch adversarial loss: 0.560878\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555454; batch adversarial loss: 0.611687\n",
      "epoch 16; iter: 0; batch classifier loss: 0.563168; batch adversarial loss: 0.586092\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487641; batch adversarial loss: 0.588701\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501269; batch adversarial loss: 0.535799\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530996; batch adversarial loss: 0.549192\n",
      "epoch 20; iter: 0; batch classifier loss: 0.467718; batch adversarial loss: 0.617657\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469716; batch adversarial loss: 0.572423\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470044; batch adversarial loss: 0.613110\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461574; batch adversarial loss: 0.598216\n",
      "epoch 24; iter: 0; batch classifier loss: 0.417868; batch adversarial loss: 0.498656\n",
      "epoch 25; iter: 0; batch classifier loss: 0.427884; batch adversarial loss: 0.516766\n",
      "epoch 26; iter: 0; batch classifier loss: 0.405098; batch adversarial loss: 0.560654\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455482; batch adversarial loss: 0.603138\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490956; batch adversarial loss: 0.466040\n",
      "epoch 29; iter: 0; batch classifier loss: 0.427755; batch adversarial loss: 0.481879\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533470; batch adversarial loss: 0.532276\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475976; batch adversarial loss: 0.571171\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467750; batch adversarial loss: 0.501503\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463409; batch adversarial loss: 0.574353\n",
      "epoch 34; iter: 0; batch classifier loss: 0.505901; batch adversarial loss: 0.605896\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400266; batch adversarial loss: 0.473953\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441998; batch adversarial loss: 0.462154\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469879; batch adversarial loss: 0.527971\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457849; batch adversarial loss: 0.546543\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478121; batch adversarial loss: 0.479911\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455409; batch adversarial loss: 0.502555\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448123; batch adversarial loss: 0.568162\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439202; batch adversarial loss: 0.472779\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401447; batch adversarial loss: 0.549154\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468127; batch adversarial loss: 0.533835\n",
      "epoch 45; iter: 0; batch classifier loss: 0.496762; batch adversarial loss: 0.518934\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409480; batch adversarial loss: 0.578797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.450718; batch adversarial loss: 0.558805\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445380; batch adversarial loss: 0.552879\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406108; batch adversarial loss: 0.536207\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418791; batch adversarial loss: 0.545466\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416792; batch adversarial loss: 0.484356\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445732; batch adversarial loss: 0.561885\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414860; batch adversarial loss: 0.545956\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463969; batch adversarial loss: 0.508724\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398867; batch adversarial loss: 0.597139\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433363; batch adversarial loss: 0.598631\n",
      "epoch 57; iter: 0; batch classifier loss: 0.381262; batch adversarial loss: 0.535749\n",
      "epoch 58; iter: 0; batch classifier loss: 0.476081; batch adversarial loss: 0.544334\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421764; batch adversarial loss: 0.491483\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376822; batch adversarial loss: 0.588109\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385803; batch adversarial loss: 0.607013\n",
      "epoch 62; iter: 0; batch classifier loss: 0.339943; batch adversarial loss: 0.580039\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377338; batch adversarial loss: 0.577079\n",
      "epoch 64; iter: 0; batch classifier loss: 0.402619; batch adversarial loss: 0.624374\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408266; batch adversarial loss: 0.553194\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447882; batch adversarial loss: 0.535569\n",
      "epoch 67; iter: 0; batch classifier loss: 0.437670; batch adversarial loss: 0.475048\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404305; batch adversarial loss: 0.570461\n",
      "epoch 69; iter: 0; batch classifier loss: 0.303936; batch adversarial loss: 0.572926\n",
      "epoch 70; iter: 0; batch classifier loss: 0.484793; batch adversarial loss: 0.552085\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391695; batch adversarial loss: 0.545825\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386132; batch adversarial loss: 0.606439\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372595; batch adversarial loss: 0.509860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413654; batch adversarial loss: 0.572659\n",
      "epoch 75; iter: 0; batch classifier loss: 0.351760; batch adversarial loss: 0.484002\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390147; batch adversarial loss: 0.581978\n",
      "epoch 77; iter: 0; batch classifier loss: 0.373119; batch adversarial loss: 0.519716\n",
      "epoch 78; iter: 0; batch classifier loss: 0.374879; batch adversarial loss: 0.547265\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382254; batch adversarial loss: 0.502146\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358334; batch adversarial loss: 0.501913\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423117; batch adversarial loss: 0.657797\n",
      "epoch 82; iter: 0; batch classifier loss: 0.351042; batch adversarial loss: 0.484041\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372235; batch adversarial loss: 0.492546\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403919; batch adversarial loss: 0.501653\n",
      "epoch 85; iter: 0; batch classifier loss: 0.386224; batch adversarial loss: 0.474968\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406811; batch adversarial loss: 0.509267\n",
      "epoch 87; iter: 0; batch classifier loss: 0.409581; batch adversarial loss: 0.527096\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369223; batch adversarial loss: 0.500899\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358329; batch adversarial loss: 0.562468\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395364; batch adversarial loss: 0.536085\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363614; batch adversarial loss: 0.518512\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432427; batch adversarial loss: 0.624336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.322487; batch adversarial loss: 0.500782\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396535; batch adversarial loss: 0.517068\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387961; batch adversarial loss: 0.617402\n",
      "epoch 96; iter: 0; batch classifier loss: 0.363265; batch adversarial loss: 0.528264\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390134; batch adversarial loss: 0.570255\n",
      "epoch 98; iter: 0; batch classifier loss: 0.340937; batch adversarial loss: 0.508918\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377547; batch adversarial loss: 0.553838\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408248; batch adversarial loss: 0.553713\n",
      "epoch 101; iter: 0; batch classifier loss: 0.447113; batch adversarial loss: 0.475020\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416428; batch adversarial loss: 0.649285\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401025; batch adversarial loss: 0.561875\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434580; batch adversarial loss: 0.535962\n",
      "epoch 105; iter: 0; batch classifier loss: 0.447985; batch adversarial loss: 0.588913\n",
      "epoch 106; iter: 0; batch classifier loss: 0.349983; batch adversarial loss: 0.588950\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319289; batch adversarial loss: 0.624319\n",
      "epoch 108; iter: 0; batch classifier loss: 0.439781; batch adversarial loss: 0.483018\n",
      "epoch 109; iter: 0; batch classifier loss: 0.398286; batch adversarial loss: 0.465384\n",
      "epoch 110; iter: 0; batch classifier loss: 0.425952; batch adversarial loss: 0.553397\n",
      "epoch 111; iter: 0; batch classifier loss: 0.404114; batch adversarial loss: 0.554001\n",
      "epoch 112; iter: 0; batch classifier loss: 0.345163; batch adversarial loss: 0.553895\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373303; batch adversarial loss: 0.509944\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378194; batch adversarial loss: 0.553214\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364146; batch adversarial loss: 0.508855\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385493; batch adversarial loss: 0.596935\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351936; batch adversarial loss: 0.553425\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385271; batch adversarial loss: 0.526659\n",
      "epoch 119; iter: 0; batch classifier loss: 0.407544; batch adversarial loss: 0.508895\n",
      "epoch 120; iter: 0; batch classifier loss: 0.393550; batch adversarial loss: 0.553969\n",
      "epoch 121; iter: 0; batch classifier loss: 0.325804; batch adversarial loss: 0.544596\n",
      "epoch 122; iter: 0; batch classifier loss: 0.336566; batch adversarial loss: 0.536109\n",
      "epoch 123; iter: 0; batch classifier loss: 0.270156; batch adversarial loss: 0.553687\n",
      "epoch 124; iter: 0; batch classifier loss: 0.280238; batch adversarial loss: 0.527607\n",
      "epoch 125; iter: 0; batch classifier loss: 0.427184; batch adversarial loss: 0.528451\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392148; batch adversarial loss: 0.534821\n",
      "epoch 127; iter: 0; batch classifier loss: 0.323057; batch adversarial loss: 0.554072\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362823; batch adversarial loss: 0.580536\n",
      "epoch 129; iter: 0; batch classifier loss: 0.411782; batch adversarial loss: 0.542549\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340737; batch adversarial loss: 0.526847\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384674; batch adversarial loss: 0.544626\n",
      "epoch 132; iter: 0; batch classifier loss: 0.271226; batch adversarial loss: 0.517345\n",
      "epoch 133; iter: 0; batch classifier loss: 0.384852; batch adversarial loss: 0.508603\n",
      "epoch 134; iter: 0; batch classifier loss: 0.348893; batch adversarial loss: 0.563072\n",
      "epoch 135; iter: 0; batch classifier loss: 0.391669; batch adversarial loss: 0.492433\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361743; batch adversarial loss: 0.561273\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385080; batch adversarial loss: 0.572231\n",
      "epoch 138; iter: 0; batch classifier loss: 0.312821; batch adversarial loss: 0.544283\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357748; batch adversarial loss: 0.517351\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365587; batch adversarial loss: 0.562712\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434084; batch adversarial loss: 0.623948\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389928; batch adversarial loss: 0.588421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.287854; batch adversarial loss: 0.561164\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371582; batch adversarial loss: 0.568939\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358141; batch adversarial loss: 0.613244\n",
      "epoch 146; iter: 0; batch classifier loss: 0.437265; batch adversarial loss: 0.534490\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376512; batch adversarial loss: 0.578114\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363536; batch adversarial loss: 0.594031\n",
      "epoch 149; iter: 0; batch classifier loss: 0.348305; batch adversarial loss: 0.499472\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388829; batch adversarial loss: 0.569271\n",
      "epoch 151; iter: 0; batch classifier loss: 0.288875; batch adversarial loss: 0.572247\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394897; batch adversarial loss: 0.560938\n",
      "epoch 153; iter: 0; batch classifier loss: 0.332596; batch adversarial loss: 0.553596\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352382; batch adversarial loss: 0.570961\n",
      "epoch 155; iter: 0; batch classifier loss: 0.368356; batch adversarial loss: 0.554230\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403085; batch adversarial loss: 0.615088\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373264; batch adversarial loss: 0.617543\n",
      "epoch 158; iter: 0; batch classifier loss: 0.332905; batch adversarial loss: 0.508620\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361757; batch adversarial loss: 0.571217\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349531; batch adversarial loss: 0.510459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.396222; batch adversarial loss: 0.572157\n",
      "epoch 162; iter: 0; batch classifier loss: 0.345787; batch adversarial loss: 0.571329\n",
      "epoch 163; iter: 0; batch classifier loss: 0.470181; batch adversarial loss: 0.589961\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386428; batch adversarial loss: 0.519958\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389608; batch adversarial loss: 0.535555\n",
      "epoch 166; iter: 0; batch classifier loss: 0.291944; batch adversarial loss: 0.552988\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380646; batch adversarial loss: 0.544590\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320821; batch adversarial loss: 0.499125\n",
      "epoch 169; iter: 0; batch classifier loss: 0.419840; batch adversarial loss: 0.580706\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339717; batch adversarial loss: 0.556259\n",
      "epoch 171; iter: 0; batch classifier loss: 0.490935; batch adversarial loss: 0.598428\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328120; batch adversarial loss: 0.630731\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340534; batch adversarial loss: 0.491032\n",
      "epoch 174; iter: 0; batch classifier loss: 0.330122; batch adversarial loss: 0.580704\n",
      "epoch 175; iter: 0; batch classifier loss: 0.494165; batch adversarial loss: 0.546312\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369805; batch adversarial loss: 0.519543\n",
      "epoch 177; iter: 0; batch classifier loss: 0.394946; batch adversarial loss: 0.456577\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372571; batch adversarial loss: 0.474209\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368726; batch adversarial loss: 0.554599\n",
      "epoch 180; iter: 0; batch classifier loss: 0.317561; batch adversarial loss: 0.579266\n",
      "epoch 181; iter: 0; batch classifier loss: 0.269118; batch adversarial loss: 0.552901\n",
      "epoch 182; iter: 0; batch classifier loss: 0.417269; batch adversarial loss: 0.519691\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315993; batch adversarial loss: 0.562052\n",
      "epoch 184; iter: 0; batch classifier loss: 0.450577; batch adversarial loss: 0.553777\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393158; batch adversarial loss: 0.580847\n",
      "epoch 186; iter: 0; batch classifier loss: 0.374032; batch adversarial loss: 0.571061\n",
      "epoch 187; iter: 0; batch classifier loss: 0.347563; batch adversarial loss: 0.613956\n",
      "epoch 188; iter: 0; batch classifier loss: 0.260949; batch adversarial loss: 0.553745\n",
      "epoch 189; iter: 0; batch classifier loss: 0.299414; batch adversarial loss: 0.560531\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331442; batch adversarial loss: 0.605978\n",
      "epoch 191; iter: 0; batch classifier loss: 0.358283; batch adversarial loss: 0.526664\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326047; batch adversarial loss: 0.589111\n",
      "epoch 193; iter: 0; batch classifier loss: 0.311128; batch adversarial loss: 0.510976\n",
      "epoch 194; iter: 0; batch classifier loss: 0.361813; batch adversarial loss: 0.519054\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381516; batch adversarial loss: 0.536218\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332794; batch adversarial loss: 0.518695\n",
      "epoch 197; iter: 0; batch classifier loss: 0.401277; batch adversarial loss: 0.660134\n",
      "epoch 198; iter: 0; batch classifier loss: 0.439968; batch adversarial loss: 0.535259\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314607; batch adversarial loss: 0.580963\n",
      "epoch 0; iter: 0; batch classifier loss: 0.813732; batch adversarial loss: 0.758585\n",
      "epoch 1; iter: 0; batch classifier loss: 0.531432; batch adversarial loss: 0.701159\n",
      "epoch 2; iter: 0; batch classifier loss: 0.654992; batch adversarial loss: 0.692609\n",
      "epoch 3; iter: 0; batch classifier loss: 0.552021; batch adversarial loss: 0.661606\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543642; batch adversarial loss: 0.651906\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577343; batch adversarial loss: 0.648680\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560425; batch adversarial loss: 0.597592\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568557; batch adversarial loss: 0.590792\n",
      "epoch 8; iter: 0; batch classifier loss: 0.605906; batch adversarial loss: 0.570652\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598008; batch adversarial loss: 0.605172\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557173; batch adversarial loss: 0.548160\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532243; batch adversarial loss: 0.567813\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553560; batch adversarial loss: 0.520200\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511256; batch adversarial loss: 0.533860\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529288; batch adversarial loss: 0.555075\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468954; batch adversarial loss: 0.564132\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460399; batch adversarial loss: 0.575229\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491430; batch adversarial loss: 0.528945\n",
      "epoch 18; iter: 0; batch classifier loss: 0.563535; batch adversarial loss: 0.506464\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550962; batch adversarial loss: 0.652838\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523321; batch adversarial loss: 0.581538\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490742; batch adversarial loss: 0.583596\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490286; batch adversarial loss: 0.533500\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497605; batch adversarial loss: 0.563683\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492670; batch adversarial loss: 0.570752\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481699; batch adversarial loss: 0.549736\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439095; batch adversarial loss: 0.518683\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481110; batch adversarial loss: 0.540560\n",
      "epoch 28; iter: 0; batch classifier loss: 0.541479; batch adversarial loss: 0.636743\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413076; batch adversarial loss: 0.538393\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448150; batch adversarial loss: 0.554736\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466443; batch adversarial loss: 0.605114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.441366; batch adversarial loss: 0.640100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.396575; batch adversarial loss: 0.571364\n",
      "epoch 34; iter: 0; batch classifier loss: 0.522238; batch adversarial loss: 0.571448\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402712; batch adversarial loss: 0.536135\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492599; batch adversarial loss: 0.553493\n",
      "epoch 37; iter: 0; batch classifier loss: 0.405652; batch adversarial loss: 0.562688\n",
      "epoch 38; iter: 0; batch classifier loss: 0.505195; batch adversarial loss: 0.544653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.430537; batch adversarial loss: 0.535687\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459323; batch adversarial loss: 0.597892\n",
      "epoch 41; iter: 0; batch classifier loss: 0.497514; batch adversarial loss: 0.607609\n",
      "epoch 42; iter: 0; batch classifier loss: 0.401714; batch adversarial loss: 0.453474\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455757; batch adversarial loss: 0.499228\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407326; batch adversarial loss: 0.507984\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404755; batch adversarial loss: 0.526129\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471215; batch adversarial loss: 0.581383\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444482; batch adversarial loss: 0.600502\n",
      "epoch 48; iter: 0; batch classifier loss: 0.499438; batch adversarial loss: 0.544647\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429940; batch adversarial loss: 0.591391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418817; batch adversarial loss: 0.563151\n",
      "epoch 51; iter: 0; batch classifier loss: 0.393785; batch adversarial loss: 0.629480\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432142; batch adversarial loss: 0.553997\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401804; batch adversarial loss: 0.497400\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448571; batch adversarial loss: 0.591577\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446322; batch adversarial loss: 0.535059\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432184; batch adversarial loss: 0.581826\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427839; batch adversarial loss: 0.487819\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443949; batch adversarial loss: 0.591775\n",
      "epoch 59; iter: 0; batch classifier loss: 0.356821; batch adversarial loss: 0.525864\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420490; batch adversarial loss: 0.507053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399731; batch adversarial loss: 0.459383\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409029; batch adversarial loss: 0.582103\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396236; batch adversarial loss: 0.600921\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424163; batch adversarial loss: 0.507267\n",
      "epoch 65; iter: 0; batch classifier loss: 0.512976; batch adversarial loss: 0.534990\n",
      "epoch 66; iter: 0; batch classifier loss: 0.476866; batch adversarial loss: 0.534650\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420859; batch adversarial loss: 0.572715\n",
      "epoch 68; iter: 0; batch classifier loss: 0.450816; batch adversarial loss: 0.516908\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436569; batch adversarial loss: 0.488487\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383002; batch adversarial loss: 0.479163\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438181; batch adversarial loss: 0.516890\n",
      "epoch 72; iter: 0; batch classifier loss: 0.459946; batch adversarial loss: 0.535273\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400389; batch adversarial loss: 0.516245\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418364; batch adversarial loss: 0.572691\n",
      "epoch 75; iter: 0; batch classifier loss: 0.498074; batch adversarial loss: 0.487950\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395717; batch adversarial loss: 0.554245\n",
      "epoch 77; iter: 0; batch classifier loss: 0.347136; batch adversarial loss: 0.487861\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397178; batch adversarial loss: 0.497167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366241; batch adversarial loss: 0.517406\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470050; batch adversarial loss: 0.554006\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443001; batch adversarial loss: 0.516135\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374508; batch adversarial loss: 0.601120\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441349; batch adversarial loss: 0.543929\n",
      "epoch 84; iter: 0; batch classifier loss: 0.332209; batch adversarial loss: 0.572995\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427264; batch adversarial loss: 0.468580\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395482; batch adversarial loss: 0.562765\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410153; batch adversarial loss: 0.535169\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375549; batch adversarial loss: 0.525168\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385719; batch adversarial loss: 0.497476\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425184; batch adversarial loss: 0.534736\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408239; batch adversarial loss: 0.534542\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382883; batch adversarial loss: 0.544454\n",
      "epoch 93; iter: 0; batch classifier loss: 0.388019; batch adversarial loss: 0.572563\n",
      "epoch 94; iter: 0; batch classifier loss: 0.344910; batch adversarial loss: 0.564021\n",
      "epoch 95; iter: 0; batch classifier loss: 0.456665; batch adversarial loss: 0.563737\n",
      "epoch 96; iter: 0; batch classifier loss: 0.306732; batch adversarial loss: 0.526976\n",
      "epoch 97; iter: 0; batch classifier loss: 0.438737; batch adversarial loss: 0.506656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406182; batch adversarial loss: 0.600560\n",
      "epoch 99; iter: 0; batch classifier loss: 0.300441; batch adversarial loss: 0.572683\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400563; batch adversarial loss: 0.544927\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367495; batch adversarial loss: 0.554577\n",
      "epoch 102; iter: 0; batch classifier loss: 0.442905; batch adversarial loss: 0.609891\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356674; batch adversarial loss: 0.516634\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341368; batch adversarial loss: 0.562509\n",
      "epoch 105; iter: 0; batch classifier loss: 0.336902; batch adversarial loss: 0.591284\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359314; batch adversarial loss: 0.544235\n",
      "epoch 107; iter: 0; batch classifier loss: 0.345570; batch adversarial loss: 0.497005\n",
      "epoch 108; iter: 0; batch classifier loss: 0.443332; batch adversarial loss: 0.564338\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410837; batch adversarial loss: 0.553923\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350747; batch adversarial loss: 0.553448\n",
      "epoch 111; iter: 0; batch classifier loss: 0.370707; batch adversarial loss: 0.516764\n",
      "epoch 112; iter: 0; batch classifier loss: 0.433942; batch adversarial loss: 0.535422\n",
      "epoch 113; iter: 0; batch classifier loss: 0.465794; batch adversarial loss: 0.487913\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367559; batch adversarial loss: 0.422680\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364627; batch adversarial loss: 0.600867\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379935; batch adversarial loss: 0.563509\n",
      "epoch 117; iter: 0; batch classifier loss: 0.359268; batch adversarial loss: 0.506830\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389319; batch adversarial loss: 0.572027\n",
      "epoch 119; iter: 0; batch classifier loss: 0.421139; batch adversarial loss: 0.609946\n",
      "epoch 120; iter: 0; batch classifier loss: 0.409467; batch adversarial loss: 0.442616\n",
      "epoch 121; iter: 0; batch classifier loss: 0.446484; batch adversarial loss: 0.534440\n",
      "epoch 122; iter: 0; batch classifier loss: 0.328146; batch adversarial loss: 0.506751\n",
      "epoch 123; iter: 0; batch classifier loss: 0.338009; batch adversarial loss: 0.535725\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381040; batch adversarial loss: 0.507402\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382224; batch adversarial loss: 0.564455\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359695; batch adversarial loss: 0.497832\n",
      "epoch 127; iter: 0; batch classifier loss: 0.423864; batch adversarial loss: 0.518072\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402536; batch adversarial loss: 0.543556\n",
      "epoch 129; iter: 0; batch classifier loss: 0.424811; batch adversarial loss: 0.479598\n",
      "epoch 130; iter: 0; batch classifier loss: 0.434574; batch adversarial loss: 0.515939\n",
      "epoch 131; iter: 0; batch classifier loss: 0.439636; batch adversarial loss: 0.487003\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421888; batch adversarial loss: 0.610013\n",
      "epoch 133; iter: 0; batch classifier loss: 0.431322; batch adversarial loss: 0.590047\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386834; batch adversarial loss: 0.506171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.442206; batch adversarial loss: 0.572100\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392971; batch adversarial loss: 0.553231\n",
      "epoch 137; iter: 0; batch classifier loss: 0.428921; batch adversarial loss: 0.544160\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342207; batch adversarial loss: 0.554298\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388282; batch adversarial loss: 0.562381\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389475; batch adversarial loss: 0.525503\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325335; batch adversarial loss: 0.498448\n",
      "epoch 142; iter: 0; batch classifier loss: 0.343165; batch adversarial loss: 0.488239\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361044; batch adversarial loss: 0.507128\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337938; batch adversarial loss: 0.478553\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340841; batch adversarial loss: 0.506900\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395672; batch adversarial loss: 0.516401\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338680; batch adversarial loss: 0.590920\n",
      "epoch 148; iter: 0; batch classifier loss: 0.429603; batch adversarial loss: 0.533535\n",
      "epoch 149; iter: 0; batch classifier loss: 0.404527; batch adversarial loss: 0.563280\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341455; batch adversarial loss: 0.506461\n",
      "epoch 151; iter: 0; batch classifier loss: 0.342729; batch adversarial loss: 0.647445\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365124; batch adversarial loss: 0.554366\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346783; batch adversarial loss: 0.479142\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395808; batch adversarial loss: 0.572126\n",
      "epoch 155; iter: 0; batch classifier loss: 0.459633; batch adversarial loss: 0.515755\n",
      "epoch 156; iter: 0; batch classifier loss: 0.382130; batch adversarial loss: 0.591274\n",
      "epoch 157; iter: 0; batch classifier loss: 0.398861; batch adversarial loss: 0.461347\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356169; batch adversarial loss: 0.526096\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356179; batch adversarial loss: 0.564184\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342133; batch adversarial loss: 0.469999\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378063; batch adversarial loss: 0.496339\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311282; batch adversarial loss: 0.517066\n",
      "epoch 163; iter: 0; batch classifier loss: 0.357060; batch adversarial loss: 0.497626\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371526; batch adversarial loss: 0.646972\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394044; batch adversarial loss: 0.542986\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364532; batch adversarial loss: 0.563500\n",
      "epoch 167; iter: 0; batch classifier loss: 0.419193; batch adversarial loss: 0.525245\n",
      "epoch 168; iter: 0; batch classifier loss: 0.294139; batch adversarial loss: 0.489698\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356592; batch adversarial loss: 0.526997\n",
      "epoch 170; iter: 0; batch classifier loss: 0.279572; batch adversarial loss: 0.601595\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344486; batch adversarial loss: 0.619795\n",
      "epoch 172; iter: 0; batch classifier loss: 0.416173; batch adversarial loss: 0.543670\n",
      "epoch 173; iter: 0; batch classifier loss: 0.399029; batch adversarial loss: 0.610039\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365712; batch adversarial loss: 0.506228\n",
      "epoch 175; iter: 0; batch classifier loss: 0.387892; batch adversarial loss: 0.619492\n",
      "epoch 176; iter: 0; batch classifier loss: 0.456261; batch adversarial loss: 0.553323\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378587; batch adversarial loss: 0.601331\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387386; batch adversarial loss: 0.553867\n",
      "epoch 179; iter: 0; batch classifier loss: 0.307271; batch adversarial loss: 0.554740\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387793; batch adversarial loss: 0.544336\n",
      "epoch 181; iter: 0; batch classifier loss: 0.381627; batch adversarial loss: 0.479652\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340172; batch adversarial loss: 0.563318\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315843; batch adversarial loss: 0.571296\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371727; batch adversarial loss: 0.479338\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357063; batch adversarial loss: 0.535329\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355801; batch adversarial loss: 0.609718\n",
      "epoch 187; iter: 0; batch classifier loss: 0.331395; batch adversarial loss: 0.619293\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381759; batch adversarial loss: 0.554330\n",
      "epoch 189; iter: 0; batch classifier loss: 0.407941; batch adversarial loss: 0.545018\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341344; batch adversarial loss: 0.535700\n",
      "epoch 191; iter: 0; batch classifier loss: 0.469417; batch adversarial loss: 0.507309\n",
      "epoch 192; iter: 0; batch classifier loss: 0.289587; batch adversarial loss: 0.553644\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327471; batch adversarial loss: 0.572698\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397315; batch adversarial loss: 0.517041\n",
      "epoch 195; iter: 0; batch classifier loss: 0.340088; batch adversarial loss: 0.591283\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309611; batch adversarial loss: 0.563087\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318201; batch adversarial loss: 0.506618\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331662; batch adversarial loss: 0.534113\n",
      "epoch 199; iter: 0; batch classifier loss: 0.383948; batch adversarial loss: 0.488531\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691345; batch adversarial loss: 0.647729\n",
      "epoch 1; iter: 0; batch classifier loss: 0.566468; batch adversarial loss: 0.662181\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604029; batch adversarial loss: 0.625297\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593817; batch adversarial loss: 0.617330\n",
      "epoch 4; iter: 0; batch classifier loss: 0.644452; batch adversarial loss: 0.650041\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598439; batch adversarial loss: 0.658364\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575659; batch adversarial loss: 0.627331\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574666; batch adversarial loss: 0.615070\n",
      "epoch 8; iter: 0; batch classifier loss: 0.640350; batch adversarial loss: 0.637152\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584117; batch adversarial loss: 0.545242\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567832; batch adversarial loss: 0.608551\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593064; batch adversarial loss: 0.591672\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517504; batch adversarial loss: 0.619019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495348; batch adversarial loss: 0.647854\n",
      "epoch 14; iter: 0; batch classifier loss: 0.594189; batch adversarial loss: 0.530446\n",
      "epoch 15; iter: 0; batch classifier loss: 0.405676; batch adversarial loss: 0.622223\n",
      "epoch 16; iter: 0; batch classifier loss: 0.549975; batch adversarial loss: 0.566029\n",
      "epoch 17; iter: 0; batch classifier loss: 0.579013; batch adversarial loss: 0.549316\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490968; batch adversarial loss: 0.553196\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491061; batch adversarial loss: 0.543777\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510973; batch adversarial loss: 0.616434\n",
      "epoch 21; iter: 0; batch classifier loss: 0.533513; batch adversarial loss: 0.618279\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463981; batch adversarial loss: 0.475464\n",
      "epoch 23; iter: 0; batch classifier loss: 0.419809; batch adversarial loss: 0.482202\n",
      "epoch 24; iter: 0; batch classifier loss: 0.630187; batch adversarial loss: 0.595761\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479376; batch adversarial loss: 0.562969\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435232; batch adversarial loss: 0.521976\n",
      "epoch 27; iter: 0; batch classifier loss: 0.523507; batch adversarial loss: 0.598207\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512162; batch adversarial loss: 0.552588\n",
      "epoch 29; iter: 0; batch classifier loss: 0.553963; batch adversarial loss: 0.535447\n",
      "epoch 30; iter: 0; batch classifier loss: 0.512105; batch adversarial loss: 0.595414\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484191; batch adversarial loss: 0.553597\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403192; batch adversarial loss: 0.543919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.416863; batch adversarial loss: 0.600578\n",
      "epoch 34; iter: 0; batch classifier loss: 0.520241; batch adversarial loss: 0.579373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496013; batch adversarial loss: 0.484522\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436174; batch adversarial loss: 0.590555\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424540; batch adversarial loss: 0.597567\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468579; batch adversarial loss: 0.510474\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501396; batch adversarial loss: 0.483440\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470537; batch adversarial loss: 0.536519\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475738; batch adversarial loss: 0.562092\n",
      "epoch 42; iter: 0; batch classifier loss: 0.508917; batch adversarial loss: 0.579960\n",
      "epoch 43; iter: 0; batch classifier loss: 0.544073; batch adversarial loss: 0.481798\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485760; batch adversarial loss: 0.517468\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440248; batch adversarial loss: 0.508237\n",
      "epoch 46; iter: 0; batch classifier loss: 0.510309; batch adversarial loss: 0.499919\n",
      "epoch 47; iter: 0; batch classifier loss: 0.458415; batch adversarial loss: 0.616906\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468923; batch adversarial loss: 0.607394\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429750; batch adversarial loss: 0.508894\n",
      "epoch 50; iter: 0; batch classifier loss: 0.454807; batch adversarial loss: 0.543862\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444274; batch adversarial loss: 0.633839\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420424; batch adversarial loss: 0.517304\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408223; batch adversarial loss: 0.571325\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420971; batch adversarial loss: 0.535349\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409402; batch adversarial loss: 0.499541\n",
      "epoch 56; iter: 0; batch classifier loss: 0.474446; batch adversarial loss: 0.589384\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396636; batch adversarial loss: 0.580698\n",
      "epoch 58; iter: 0; batch classifier loss: 0.495862; batch adversarial loss: 0.589920\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411975; batch adversarial loss: 0.571396\n",
      "epoch 60; iter: 0; batch classifier loss: 0.494687; batch adversarial loss: 0.562862\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438369; batch adversarial loss: 0.472230\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441979; batch adversarial loss: 0.562880\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423809; batch adversarial loss: 0.580711\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390136; batch adversarial loss: 0.563192\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424289; batch adversarial loss: 0.525786\n",
      "epoch 66; iter: 0; batch classifier loss: 0.361624; batch adversarial loss: 0.626875\n",
      "epoch 67; iter: 0; batch classifier loss: 0.365322; batch adversarial loss: 0.553281\n",
      "epoch 68; iter: 0; batch classifier loss: 0.451159; batch adversarial loss: 0.552639\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447520; batch adversarial loss: 0.554684\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459658; batch adversarial loss: 0.526191\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416896; batch adversarial loss: 0.602075\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387055; batch adversarial loss: 0.543946\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427160; batch adversarial loss: 0.481481\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410318; batch adversarial loss: 0.526994\n",
      "epoch 75; iter: 0; batch classifier loss: 0.530567; batch adversarial loss: 0.526178\n",
      "epoch 76; iter: 0; batch classifier loss: 0.434630; batch adversarial loss: 0.581240\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434722; batch adversarial loss: 0.562199\n",
      "epoch 78; iter: 0; batch classifier loss: 0.452710; batch adversarial loss: 0.544747\n",
      "epoch 79; iter: 0; batch classifier loss: 0.471245; batch adversarial loss: 0.507946\n",
      "epoch 80; iter: 0; batch classifier loss: 0.348545; batch adversarial loss: 0.545002\n",
      "epoch 81; iter: 0; batch classifier loss: 0.438247; batch adversarial loss: 0.508675\n",
      "epoch 82; iter: 0; batch classifier loss: 0.391870; batch adversarial loss: 0.517621\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412526; batch adversarial loss: 0.562332\n",
      "epoch 84; iter: 0; batch classifier loss: 0.511281; batch adversarial loss: 0.536162\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407993; batch adversarial loss: 0.633902\n",
      "epoch 86; iter: 0; batch classifier loss: 0.463219; batch adversarial loss: 0.562532\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390318; batch adversarial loss: 0.599020\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379541; batch adversarial loss: 0.572573\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358910; batch adversarial loss: 0.560645\n",
      "epoch 90; iter: 0; batch classifier loss: 0.429844; batch adversarial loss: 0.546014\n",
      "epoch 91; iter: 0; batch classifier loss: 0.429174; batch adversarial loss: 0.562785\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407345; batch adversarial loss: 0.534068\n",
      "epoch 93; iter: 0; batch classifier loss: 0.506794; batch adversarial loss: 0.546469\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387051; batch adversarial loss: 0.564284\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431209; batch adversarial loss: 0.553279\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355793; batch adversarial loss: 0.589549\n",
      "epoch 97; iter: 0; batch classifier loss: 0.450345; batch adversarial loss: 0.660867\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389614; batch adversarial loss: 0.608826\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456532; batch adversarial loss: 0.527285\n",
      "epoch 100; iter: 0; batch classifier loss: 0.447050; batch adversarial loss: 0.571756\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401573; batch adversarial loss: 0.519530\n",
      "epoch 102; iter: 0; batch classifier loss: 0.464086; batch adversarial loss: 0.589444\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377879; batch adversarial loss: 0.607662\n",
      "epoch 104; iter: 0; batch classifier loss: 0.448545; batch adversarial loss: 0.544403\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432063; batch adversarial loss: 0.554038\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381416; batch adversarial loss: 0.607304\n",
      "epoch 107; iter: 0; batch classifier loss: 0.341429; batch adversarial loss: 0.580633\n",
      "epoch 108; iter: 0; batch classifier loss: 0.315485; batch adversarial loss: 0.544782\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364736; batch adversarial loss: 0.652340\n",
      "epoch 110; iter: 0; batch classifier loss: 0.446241; batch adversarial loss: 0.499595\n",
      "epoch 111; iter: 0; batch classifier loss: 0.421108; batch adversarial loss: 0.616681\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415246; batch adversarial loss: 0.562415\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399158; batch adversarial loss: 0.571283\n",
      "epoch 114; iter: 0; batch classifier loss: 0.544340; batch adversarial loss: 0.562047\n",
      "epoch 115; iter: 0; batch classifier loss: 0.450831; batch adversarial loss: 0.572531\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413059; batch adversarial loss: 0.516658\n",
      "epoch 117; iter: 0; batch classifier loss: 0.432327; batch adversarial loss: 0.489332\n",
      "epoch 118; iter: 0; batch classifier loss: 0.440345; batch adversarial loss: 0.526058\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377653; batch adversarial loss: 0.535529\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381148; batch adversarial loss: 0.517034\n",
      "epoch 121; iter: 0; batch classifier loss: 0.447234; batch adversarial loss: 0.490433\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386211; batch adversarial loss: 0.491789\n",
      "epoch 123; iter: 0; batch classifier loss: 0.411696; batch adversarial loss: 0.581846\n",
      "epoch 124; iter: 0; batch classifier loss: 0.431328; batch adversarial loss: 0.546097\n",
      "epoch 125; iter: 0; batch classifier loss: 0.385480; batch adversarial loss: 0.571418\n",
      "epoch 126; iter: 0; batch classifier loss: 0.378512; batch adversarial loss: 0.572703\n",
      "epoch 127; iter: 0; batch classifier loss: 0.437679; batch adversarial loss: 0.525831\n",
      "epoch 128; iter: 0; batch classifier loss: 0.326697; batch adversarial loss: 0.517027\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397641; batch adversarial loss: 0.581277\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390098; batch adversarial loss: 0.499042\n",
      "epoch 131; iter: 0; batch classifier loss: 0.484169; batch adversarial loss: 0.590151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.356166; batch adversarial loss: 0.563052\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402872; batch adversarial loss: 0.616763\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364868; batch adversarial loss: 0.517409\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349167; batch adversarial loss: 0.462967\n",
      "epoch 136; iter: 0; batch classifier loss: 0.453035; batch adversarial loss: 0.580931\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385468; batch adversarial loss: 0.499294\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358274; batch adversarial loss: 0.571490\n",
      "epoch 139; iter: 0; batch classifier loss: 0.473751; batch adversarial loss: 0.526783\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328792; batch adversarial loss: 0.526561\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383373; batch adversarial loss: 0.508519\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408609; batch adversarial loss: 0.535589\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399556; batch adversarial loss: 0.526396\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369992; batch adversarial loss: 0.517148\n",
      "epoch 145; iter: 0; batch classifier loss: 0.413496; batch adversarial loss: 0.553287\n",
      "epoch 146; iter: 0; batch classifier loss: 0.398033; batch adversarial loss: 0.544390\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372421; batch adversarial loss: 0.553269\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389359; batch adversarial loss: 0.517445\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400551; batch adversarial loss: 0.490760\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349656; batch adversarial loss: 0.544606\n",
      "epoch 151; iter: 0; batch classifier loss: 0.366617; batch adversarial loss: 0.499619\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394102; batch adversarial loss: 0.607890\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344984; batch adversarial loss: 0.562302\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340747; batch adversarial loss: 0.553705\n",
      "epoch 155; iter: 0; batch classifier loss: 0.402915; batch adversarial loss: 0.598810\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387217; batch adversarial loss: 0.463497\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375692; batch adversarial loss: 0.598756\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378441; batch adversarial loss: 0.580917\n",
      "epoch 159; iter: 0; batch classifier loss: 0.331981; batch adversarial loss: 0.589812\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358493; batch adversarial loss: 0.598967\n",
      "epoch 161; iter: 0; batch classifier loss: 0.309857; batch adversarial loss: 0.562054\n",
      "epoch 162; iter: 0; batch classifier loss: 0.407057; batch adversarial loss: 0.571252\n",
      "epoch 163; iter: 0; batch classifier loss: 0.322804; batch adversarial loss: 0.535311\n",
      "epoch 164; iter: 0; batch classifier loss: 0.388133; batch adversarial loss: 0.552936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377144; batch adversarial loss: 0.579026\n",
      "epoch 166; iter: 0; batch classifier loss: 0.437910; batch adversarial loss: 0.514359\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371139; batch adversarial loss: 0.572165\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349632; batch adversarial loss: 0.526635\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369359; batch adversarial loss: 0.606197\n",
      "epoch 170; iter: 0; batch classifier loss: 0.314105; batch adversarial loss: 0.482450\n",
      "epoch 171; iter: 0; batch classifier loss: 0.447924; batch adversarial loss: 0.573034\n",
      "epoch 172; iter: 0; batch classifier loss: 0.350962; batch adversarial loss: 0.564318\n",
      "epoch 173; iter: 0; batch classifier loss: 0.413286; batch adversarial loss: 0.536544\n",
      "epoch 174; iter: 0; batch classifier loss: 0.425472; batch adversarial loss: 0.536412\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344300; batch adversarial loss: 0.554219\n",
      "epoch 176; iter: 0; batch classifier loss: 0.311661; batch adversarial loss: 0.508453\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345634; batch adversarial loss: 0.570582\n",
      "epoch 178; iter: 0; batch classifier loss: 0.464094; batch adversarial loss: 0.499854\n",
      "epoch 179; iter: 0; batch classifier loss: 0.316852; batch adversarial loss: 0.489858\n",
      "epoch 180; iter: 0; batch classifier loss: 0.308020; batch adversarial loss: 0.562559\n",
      "epoch 181; iter: 0; batch classifier loss: 0.304670; batch adversarial loss: 0.597929\n",
      "epoch 182; iter: 0; batch classifier loss: 0.274357; batch adversarial loss: 0.590821\n",
      "epoch 183; iter: 0; batch classifier loss: 0.399455; batch adversarial loss: 0.489965\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416406; batch adversarial loss: 0.633961\n",
      "epoch 185; iter: 0; batch classifier loss: 0.478243; batch adversarial loss: 0.572107\n",
      "epoch 186; iter: 0; batch classifier loss: 0.369487; batch adversarial loss: 0.535169\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388173; batch adversarial loss: 0.544680\n",
      "epoch 188; iter: 0; batch classifier loss: 0.388322; batch adversarial loss: 0.590958\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384977; batch adversarial loss: 0.517635\n",
      "epoch 190; iter: 0; batch classifier loss: 0.414725; batch adversarial loss: 0.544058\n",
      "epoch 191; iter: 0; batch classifier loss: 0.387835; batch adversarial loss: 0.453177\n",
      "epoch 192; iter: 0; batch classifier loss: 0.392806; batch adversarial loss: 0.597887\n",
      "epoch 193; iter: 0; batch classifier loss: 0.458353; batch adversarial loss: 0.544190\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397191; batch adversarial loss: 0.499558\n",
      "epoch 195; iter: 0; batch classifier loss: 0.288211; batch adversarial loss: 0.470594\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400327; batch adversarial loss: 0.598076\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341710; batch adversarial loss: 0.517730\n",
      "epoch 198; iter: 0; batch classifier loss: 0.379169; batch adversarial loss: 0.500839\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308477; batch adversarial loss: 0.519426\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718350; batch adversarial loss: 1.032001\n",
      "epoch 1; iter: 0; batch classifier loss: 0.831259; batch adversarial loss: 1.289490\n",
      "epoch 2; iter: 0; batch classifier loss: 1.073585; batch adversarial loss: 1.287310\n",
      "epoch 3; iter: 0; batch classifier loss: 1.120207; batch adversarial loss: 1.172529\n",
      "epoch 4; iter: 0; batch classifier loss: 1.059804; batch adversarial loss: 1.065628\n",
      "epoch 5; iter: 0; batch classifier loss: 1.036619; batch adversarial loss: 0.990500\n",
      "epoch 6; iter: 0; batch classifier loss: 1.200911; batch adversarial loss: 0.917550\n",
      "epoch 7; iter: 0; batch classifier loss: 1.159916; batch adversarial loss: 0.841134\n",
      "epoch 8; iter: 0; batch classifier loss: 1.068719; batch adversarial loss: 0.778659\n",
      "epoch 9; iter: 0; batch classifier loss: 0.958088; batch adversarial loss: 0.733198\n",
      "epoch 10; iter: 0; batch classifier loss: 0.993785; batch adversarial loss: 0.697312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.866464; batch adversarial loss: 0.646911\n",
      "epoch 12; iter: 0; batch classifier loss: 0.868469; batch adversarial loss: 0.601573\n",
      "epoch 13; iter: 0; batch classifier loss: 0.703989; batch adversarial loss: 0.620422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.661002; batch adversarial loss: 0.593556\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552085; batch adversarial loss: 0.577154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532662; batch adversarial loss: 0.543969\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471044; batch adversarial loss: 0.557762\n",
      "epoch 18; iter: 0; batch classifier loss: 0.441755; batch adversarial loss: 0.543687\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515447; batch adversarial loss: 0.546777\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449873; batch adversarial loss: 0.539196\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538243; batch adversarial loss: 0.581501\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472931; batch adversarial loss: 0.552625\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486407; batch adversarial loss: 0.605561\n",
      "epoch 24; iter: 0; batch classifier loss: 0.563079; batch adversarial loss: 0.567162\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497141; batch adversarial loss: 0.551577\n",
      "epoch 26; iter: 0; batch classifier loss: 0.532355; batch adversarial loss: 0.589803\n",
      "epoch 27; iter: 0; batch classifier loss: 0.522951; batch adversarial loss: 0.473805\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473772; batch adversarial loss: 0.501928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.454770; batch adversarial loss: 0.521670\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506043; batch adversarial loss: 0.587475\n",
      "epoch 31; iter: 0; batch classifier loss: 0.408914; batch adversarial loss: 0.572239\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403633; batch adversarial loss: 0.561098\n",
      "epoch 33; iter: 0; batch classifier loss: 0.454343; batch adversarial loss: 0.487170\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390237; batch adversarial loss: 0.515438\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474023; batch adversarial loss: 0.557018\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436152; batch adversarial loss: 0.533566\n",
      "epoch 37; iter: 0; batch classifier loss: 0.496204; batch adversarial loss: 0.554862\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476065; batch adversarial loss: 0.609344\n",
      "epoch 39; iter: 0; batch classifier loss: 0.385803; batch adversarial loss: 0.625943\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425730; batch adversarial loss: 0.545477\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483945; batch adversarial loss: 0.528504\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457414; batch adversarial loss: 0.555699\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391726; batch adversarial loss: 0.521631\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441103; batch adversarial loss: 0.538622\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433060; batch adversarial loss: 0.554828\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479764; batch adversarial loss: 0.575011\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477486; batch adversarial loss: 0.625203\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407564; batch adversarial loss: 0.510926\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396941; batch adversarial loss: 0.588216\n",
      "epoch 50; iter: 0; batch classifier loss: 0.404480; batch adversarial loss: 0.579970\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425454; batch adversarial loss: 0.526364\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433386; batch adversarial loss: 0.500220\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461882; batch adversarial loss: 0.578392\n",
      "epoch 54; iter: 0; batch classifier loss: 0.390737; batch adversarial loss: 0.536797\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377323; batch adversarial loss: 0.543146\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423965; batch adversarial loss: 0.597773\n",
      "epoch 57; iter: 0; batch classifier loss: 0.378875; batch adversarial loss: 0.607512\n",
      "epoch 58; iter: 0; batch classifier loss: 0.377475; batch adversarial loss: 0.501466\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427492; batch adversarial loss: 0.512218\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405033; batch adversarial loss: 0.519354\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427271; batch adversarial loss: 0.516648\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445768; batch adversarial loss: 0.463120\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392292; batch adversarial loss: 0.528732\n",
      "epoch 64; iter: 0; batch classifier loss: 0.389785; batch adversarial loss: 0.525485\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429335; batch adversarial loss: 0.543414\n",
      "epoch 66; iter: 0; batch classifier loss: 0.327242; batch adversarial loss: 0.554219\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387198; batch adversarial loss: 0.581075\n",
      "epoch 68; iter: 0; batch classifier loss: 0.358876; batch adversarial loss: 0.542662\n",
      "epoch 69; iter: 0; batch classifier loss: 0.468106; batch adversarial loss: 0.557858\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434479; batch adversarial loss: 0.540286\n",
      "epoch 71; iter: 0; batch classifier loss: 0.347849; batch adversarial loss: 0.534172\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386290; batch adversarial loss: 0.606553\n",
      "epoch 73; iter: 0; batch classifier loss: 0.497889; batch adversarial loss: 0.559195\n",
      "epoch 74; iter: 0; batch classifier loss: 0.330823; batch adversarial loss: 0.609252\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403834; batch adversarial loss: 0.555944\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395137; batch adversarial loss: 0.597601\n",
      "epoch 77; iter: 0; batch classifier loss: 0.478187; batch adversarial loss: 0.527736\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389978; batch adversarial loss: 0.569769\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407799; batch adversarial loss: 0.527651\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385804; batch adversarial loss: 0.563448\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392786; batch adversarial loss: 0.587909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.316521; batch adversarial loss: 0.571330\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385404; batch adversarial loss: 0.582744\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416685; batch adversarial loss: 0.643672\n",
      "epoch 85; iter: 0; batch classifier loss: 0.386784; batch adversarial loss: 0.552948\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387253; batch adversarial loss: 0.571428\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384663; batch adversarial loss: 0.561903\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378226; batch adversarial loss: 0.490352\n",
      "epoch 89; iter: 0; batch classifier loss: 0.305629; batch adversarial loss: 0.587246\n",
      "epoch 90; iter: 0; batch classifier loss: 0.337311; batch adversarial loss: 0.517805\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345447; batch adversarial loss: 0.545198\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421263; batch adversarial loss: 0.507905\n",
      "epoch 93; iter: 0; batch classifier loss: 0.471074; batch adversarial loss: 0.518140\n",
      "epoch 94; iter: 0; batch classifier loss: 0.366923; batch adversarial loss: 0.523475\n",
      "epoch 95; iter: 0; batch classifier loss: 0.437051; batch adversarial loss: 0.536443\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443908; batch adversarial loss: 0.652721\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391787; batch adversarial loss: 0.671194\n",
      "epoch 98; iter: 0; batch classifier loss: 0.429894; batch adversarial loss: 0.499537\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360837; batch adversarial loss: 0.517363\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396509; batch adversarial loss: 0.641705\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335723; batch adversarial loss: 0.579213\n",
      "epoch 102; iter: 0; batch classifier loss: 0.413978; batch adversarial loss: 0.516061\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412786; batch adversarial loss: 0.579509\n",
      "epoch 104; iter: 0; batch classifier loss: 0.309838; batch adversarial loss: 0.531283\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364075; batch adversarial loss: 0.582081\n",
      "epoch 106; iter: 0; batch classifier loss: 0.306889; batch adversarial loss: 0.617995\n",
      "epoch 107; iter: 0; batch classifier loss: 0.275536; batch adversarial loss: 0.525611\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397448; batch adversarial loss: 0.482062\n",
      "epoch 109; iter: 0; batch classifier loss: 0.314464; batch adversarial loss: 0.571172\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403803; batch adversarial loss: 0.517221\n",
      "epoch 111; iter: 0; batch classifier loss: 0.549477; batch adversarial loss: 0.572360\n",
      "epoch 112; iter: 0; batch classifier loss: 0.344641; batch adversarial loss: 0.582152\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413236; batch adversarial loss: 0.591947\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367051; batch adversarial loss: 0.533869\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326280; batch adversarial loss: 0.573205\n",
      "epoch 116; iter: 0; batch classifier loss: 0.322664; batch adversarial loss: 0.597343\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346960; batch adversarial loss: 0.527865\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392531; batch adversarial loss: 0.608232\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368774; batch adversarial loss: 0.560949\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413649; batch adversarial loss: 0.534591\n",
      "epoch 121; iter: 0; batch classifier loss: 0.318475; batch adversarial loss: 0.524734\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356010; batch adversarial loss: 0.580624\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357811; batch adversarial loss: 0.508986\n",
      "epoch 124; iter: 0; batch classifier loss: 0.323241; batch adversarial loss: 0.516876\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413483; batch adversarial loss: 0.544079\n",
      "epoch 126; iter: 0; batch classifier loss: 0.342317; batch adversarial loss: 0.696402\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415866; batch adversarial loss: 0.509475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.309725; batch adversarial loss: 0.573883\n",
      "epoch 129; iter: 0; batch classifier loss: 0.409271; batch adversarial loss: 0.517823\n",
      "epoch 130; iter: 0; batch classifier loss: 0.293480; batch adversarial loss: 0.642228\n",
      "epoch 131; iter: 0; batch classifier loss: 0.377505; batch adversarial loss: 0.606520\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351166; batch adversarial loss: 0.553422\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334866; batch adversarial loss: 0.574288\n",
      "epoch 134; iter: 0; batch classifier loss: 0.359373; batch adversarial loss: 0.623620\n",
      "epoch 135; iter: 0; batch classifier loss: 0.306789; batch adversarial loss: 0.536941\n",
      "epoch 136; iter: 0; batch classifier loss: 0.390856; batch adversarial loss: 0.597374\n",
      "epoch 137; iter: 0; batch classifier loss: 0.333716; batch adversarial loss: 0.554521\n",
      "epoch 138; iter: 0; batch classifier loss: 0.343011; batch adversarial loss: 0.510580\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397680; batch adversarial loss: 0.535342\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338613; batch adversarial loss: 0.598754\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357103; batch adversarial loss: 0.608646\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338654; batch adversarial loss: 0.527586\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369040; batch adversarial loss: 0.553621\n",
      "epoch 144; iter: 0; batch classifier loss: 0.285086; batch adversarial loss: 0.649768\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390146; batch adversarial loss: 0.582778\n",
      "epoch 146; iter: 0; batch classifier loss: 0.401247; batch adversarial loss: 0.474006\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377513; batch adversarial loss: 0.563160\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310153; batch adversarial loss: 0.535528\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376539; batch adversarial loss: 0.562225\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325935; batch adversarial loss: 0.543318\n",
      "epoch 151; iter: 0; batch classifier loss: 0.301721; batch adversarial loss: 0.606770\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378500; batch adversarial loss: 0.616472\n",
      "epoch 153; iter: 0; batch classifier loss: 0.423858; batch adversarial loss: 0.455489\n",
      "epoch 154; iter: 0; batch classifier loss: 0.328917; batch adversarial loss: 0.517366\n",
      "epoch 155; iter: 0; batch classifier loss: 0.298903; batch adversarial loss: 0.497890\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314219; batch adversarial loss: 0.527029\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356664; batch adversarial loss: 0.530269\n",
      "epoch 158; iter: 0; batch classifier loss: 0.301768; batch adversarial loss: 0.613506\n",
      "epoch 159; iter: 0; batch classifier loss: 0.299917; batch adversarial loss: 0.544290\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406032; batch adversarial loss: 0.509565\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387246; batch adversarial loss: 0.624602\n",
      "epoch 162; iter: 0; batch classifier loss: 0.337895; batch adversarial loss: 0.608304\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334235; batch adversarial loss: 0.562810\n",
      "epoch 164; iter: 0; batch classifier loss: 0.262091; batch adversarial loss: 0.563694\n",
      "epoch 165; iter: 0; batch classifier loss: 0.290699; batch adversarial loss: 0.507028\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388295; batch adversarial loss: 0.484072\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336953; batch adversarial loss: 0.633245\n",
      "epoch 168; iter: 0; batch classifier loss: 0.300782; batch adversarial loss: 0.526462\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390970; batch adversarial loss: 0.597094\n",
      "epoch 170; iter: 0; batch classifier loss: 0.279683; batch adversarial loss: 0.507715\n",
      "epoch 171; iter: 0; batch classifier loss: 0.300952; batch adversarial loss: 0.590635\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328044; batch adversarial loss: 0.564924\n",
      "epoch 173; iter: 0; batch classifier loss: 0.427362; batch adversarial loss: 0.535010\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384873; batch adversarial loss: 0.629314\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330184; batch adversarial loss: 0.516246\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343678; batch adversarial loss: 0.517758\n",
      "epoch 177; iter: 0; batch classifier loss: 0.302631; batch adversarial loss: 0.575816\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316850; batch adversarial loss: 0.534641\n",
      "epoch 179; iter: 0; batch classifier loss: 0.317549; batch adversarial loss: 0.590607\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352044; batch adversarial loss: 0.466295\n",
      "epoch 181; iter: 0; batch classifier loss: 0.312434; batch adversarial loss: 0.497610\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320051; batch adversarial loss: 0.573356\n",
      "epoch 183; iter: 0; batch classifier loss: 0.328307; batch adversarial loss: 0.623767\n",
      "epoch 184; iter: 0; batch classifier loss: 0.291899; batch adversarial loss: 0.536548\n",
      "epoch 185; iter: 0; batch classifier loss: 0.313627; batch adversarial loss: 0.545716\n",
      "epoch 186; iter: 0; batch classifier loss: 0.311917; batch adversarial loss: 0.558053\n",
      "epoch 187; iter: 0; batch classifier loss: 0.282541; batch adversarial loss: 0.536469\n",
      "epoch 188; iter: 0; batch classifier loss: 0.264954; batch adversarial loss: 0.561224\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338480; batch adversarial loss: 0.570596\n",
      "epoch 190; iter: 0; batch classifier loss: 0.287604; batch adversarial loss: 0.541104\n",
      "epoch 191; iter: 0; batch classifier loss: 0.237807; batch adversarial loss: 0.489619\n",
      "epoch 192; iter: 0; batch classifier loss: 0.311166; batch adversarial loss: 0.617977\n",
      "epoch 193; iter: 0; batch classifier loss: 0.264897; batch adversarial loss: 0.471341\n",
      "epoch 194; iter: 0; batch classifier loss: 0.288747; batch adversarial loss: 0.507895\n",
      "epoch 195; iter: 0; batch classifier loss: 0.325718; batch adversarial loss: 0.471637\n",
      "epoch 196; iter: 0; batch classifier loss: 0.253803; batch adversarial loss: 0.651465\n",
      "epoch 197; iter: 0; batch classifier loss: 0.419989; batch adversarial loss: 0.593214\n",
      "epoch 198; iter: 0; batch classifier loss: 0.314584; batch adversarial loss: 0.553177\n",
      "epoch 199; iter: 0; batch classifier loss: 0.264695; batch adversarial loss: 0.510497\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685320; batch adversarial loss: 0.848378\n",
      "epoch 1; iter: 0; batch classifier loss: 0.705770; batch adversarial loss: 0.997750\n",
      "epoch 2; iter: 0; batch classifier loss: 0.750419; batch adversarial loss: 0.883663\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576407; batch adversarial loss: 0.819840\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565458; batch adversarial loss: 0.746561\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596433; batch adversarial loss: 0.693251\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606054; batch adversarial loss: 0.640963\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548682; batch adversarial loss: 0.648829\n",
      "epoch 8; iter: 0; batch classifier loss: 0.584267; batch adversarial loss: 0.656599\n",
      "epoch 9; iter: 0; batch classifier loss: 0.649413; batch adversarial loss: 0.582261\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539673; batch adversarial loss: 0.613983\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512419; batch adversarial loss: 0.580876\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552270; batch adversarial loss: 0.556768\n",
      "epoch 13; iter: 0; batch classifier loss: 0.441522; batch adversarial loss: 0.597579\n",
      "epoch 14; iter: 0; batch classifier loss: 0.586884; batch adversarial loss: 0.566254\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463620; batch adversarial loss: 0.567492\n",
      "epoch 16; iter: 0; batch classifier loss: 0.549678; batch adversarial loss: 0.552171\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543234; batch adversarial loss: 0.608407\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500530; batch adversarial loss: 0.562002\n",
      "epoch 19; iter: 0; batch classifier loss: 0.479572; batch adversarial loss: 0.546568\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480014; batch adversarial loss: 0.527663\n",
      "epoch 21; iter: 0; batch classifier loss: 0.580663; batch adversarial loss: 0.560255\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480930; batch adversarial loss: 0.588229\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458145; batch adversarial loss: 0.566866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.533525; batch adversarial loss: 0.509363\n",
      "epoch 25; iter: 0; batch classifier loss: 0.444241; batch adversarial loss: 0.465913\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519368; batch adversarial loss: 0.547915\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453764; batch adversarial loss: 0.506047\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433919; batch adversarial loss: 0.536280\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509577; batch adversarial loss: 0.494087\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480130; batch adversarial loss: 0.481980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490085; batch adversarial loss: 0.527897\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466947; batch adversarial loss: 0.530287\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463551; batch adversarial loss: 0.600484\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478880; batch adversarial loss: 0.532233\n",
      "epoch 35; iter: 0; batch classifier loss: 0.512819; batch adversarial loss: 0.553417\n",
      "epoch 36; iter: 0; batch classifier loss: 0.486063; batch adversarial loss: 0.506761\n",
      "epoch 37; iter: 0; batch classifier loss: 0.523818; batch adversarial loss: 0.543474\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451784; batch adversarial loss: 0.523539\n",
      "epoch 39; iter: 0; batch classifier loss: 0.536330; batch adversarial loss: 0.524542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455874; batch adversarial loss: 0.548327\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486975; batch adversarial loss: 0.556153\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393404; batch adversarial loss: 0.552765\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492280; batch adversarial loss: 0.523791\n",
      "epoch 44; iter: 0; batch classifier loss: 0.413349; batch adversarial loss: 0.627117\n",
      "epoch 45; iter: 0; batch classifier loss: 0.536617; batch adversarial loss: 0.549364\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444267; batch adversarial loss: 0.583195\n",
      "epoch 47; iter: 0; batch classifier loss: 0.498577; batch adversarial loss: 0.588607\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426119; batch adversarial loss: 0.507001\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431511; batch adversarial loss: 0.469886\n",
      "epoch 50; iter: 0; batch classifier loss: 0.487699; batch adversarial loss: 0.561855\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436202; batch adversarial loss: 0.489396\n",
      "epoch 52; iter: 0; batch classifier loss: 0.495523; batch adversarial loss: 0.490005\n",
      "epoch 53; iter: 0; batch classifier loss: 0.491013; batch adversarial loss: 0.571705\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445907; batch adversarial loss: 0.561682\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439462; batch adversarial loss: 0.610908\n",
      "epoch 56; iter: 0; batch classifier loss: 0.387460; batch adversarial loss: 0.618095\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471144; batch adversarial loss: 0.504687\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442436; batch adversarial loss: 0.601741\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441859; batch adversarial loss: 0.591869\n",
      "epoch 60; iter: 0; batch classifier loss: 0.400881; batch adversarial loss: 0.507256\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440366; batch adversarial loss: 0.575013\n",
      "epoch 62; iter: 0; batch classifier loss: 0.456673; batch adversarial loss: 0.563119\n",
      "epoch 63; iter: 0; batch classifier loss: 0.464765; batch adversarial loss: 0.571692\n",
      "epoch 64; iter: 0; batch classifier loss: 0.479187; batch adversarial loss: 0.563197\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407650; batch adversarial loss: 0.479708\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439566; batch adversarial loss: 0.665741\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426462; batch adversarial loss: 0.484761\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390442; batch adversarial loss: 0.449336\n",
      "epoch 69; iter: 0; batch classifier loss: 0.399703; batch adversarial loss: 0.599041\n",
      "epoch 70; iter: 0; batch classifier loss: 0.400117; batch adversarial loss: 0.517608\n",
      "epoch 71; iter: 0; batch classifier loss: 0.516334; batch adversarial loss: 0.498037\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466207; batch adversarial loss: 0.600533\n",
      "epoch 73; iter: 0; batch classifier loss: 0.444966; batch adversarial loss: 0.549371\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417427; batch adversarial loss: 0.557917\n",
      "epoch 75; iter: 0; batch classifier loss: 0.464109; batch adversarial loss: 0.527003\n",
      "epoch 76; iter: 0; batch classifier loss: 0.455604; batch adversarial loss: 0.576609\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378580; batch adversarial loss: 0.551451\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379927; batch adversarial loss: 0.608772\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419683; batch adversarial loss: 0.564050\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437196; batch adversarial loss: 0.551208\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384499; batch adversarial loss: 0.530773\n",
      "epoch 82; iter: 0; batch classifier loss: 0.439945; batch adversarial loss: 0.508779\n",
      "epoch 83; iter: 0; batch classifier loss: 0.458654; batch adversarial loss: 0.498369\n",
      "epoch 84; iter: 0; batch classifier loss: 0.482145; batch adversarial loss: 0.575976\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425511; batch adversarial loss: 0.535064\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382492; batch adversarial loss: 0.525150\n",
      "epoch 87; iter: 0; batch classifier loss: 0.462917; batch adversarial loss: 0.533594\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396426; batch adversarial loss: 0.495731\n",
      "epoch 89; iter: 0; batch classifier loss: 0.440143; batch adversarial loss: 0.563016\n",
      "epoch 90; iter: 0; batch classifier loss: 0.464660; batch adversarial loss: 0.500414\n",
      "epoch 91; iter: 0; batch classifier loss: 0.480147; batch adversarial loss: 0.468606\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395254; batch adversarial loss: 0.526792\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404028; batch adversarial loss: 0.486729\n",
      "epoch 94; iter: 0; batch classifier loss: 0.460895; batch adversarial loss: 0.592513\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442981; batch adversarial loss: 0.525409\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443213; batch adversarial loss: 0.554690\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371319; batch adversarial loss: 0.535209\n",
      "epoch 98; iter: 0; batch classifier loss: 0.341790; batch adversarial loss: 0.667263\n",
      "epoch 99; iter: 0; batch classifier loss: 0.465437; batch adversarial loss: 0.545893\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374805; batch adversarial loss: 0.516518\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400714; batch adversarial loss: 0.526708\n",
      "epoch 102; iter: 0; batch classifier loss: 0.492610; batch adversarial loss: 0.510971\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376084; batch adversarial loss: 0.513770\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400911; batch adversarial loss: 0.556927\n",
      "epoch 105; iter: 0; batch classifier loss: 0.461917; batch adversarial loss: 0.458464\n",
      "epoch 106; iter: 0; batch classifier loss: 0.401329; batch adversarial loss: 0.600581\n",
      "epoch 107; iter: 0; batch classifier loss: 0.370715; batch adversarial loss: 0.562990\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385595; batch adversarial loss: 0.536279\n",
      "epoch 109; iter: 0; batch classifier loss: 0.420175; batch adversarial loss: 0.566885\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375536; batch adversarial loss: 0.581289\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375809; batch adversarial loss: 0.468371\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376457; batch adversarial loss: 0.479201\n",
      "epoch 113; iter: 0; batch classifier loss: 0.460086; batch adversarial loss: 0.544777\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372962; batch adversarial loss: 0.509710\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374883; batch adversarial loss: 0.536426\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380321; batch adversarial loss: 0.562019\n",
      "epoch 117; iter: 0; batch classifier loss: 0.426897; batch adversarial loss: 0.466097\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397671; batch adversarial loss: 0.542709\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387404; batch adversarial loss: 0.562519\n",
      "epoch 120; iter: 0; batch classifier loss: 0.345704; batch adversarial loss: 0.469311\n",
      "epoch 121; iter: 0; batch classifier loss: 0.437880; batch adversarial loss: 0.577325\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406196; batch adversarial loss: 0.613313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.408794; batch adversarial loss: 0.515065\n",
      "epoch 124; iter: 0; batch classifier loss: 0.454662; batch adversarial loss: 0.566218\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389167; batch adversarial loss: 0.553140\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368973; batch adversarial loss: 0.572332\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396246; batch adversarial loss: 0.542721\n",
      "epoch 128; iter: 0; batch classifier loss: 0.374688; batch adversarial loss: 0.536009\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356314; batch adversarial loss: 0.568810\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402114; batch adversarial loss: 0.546793\n",
      "epoch 131; iter: 0; batch classifier loss: 0.450403; batch adversarial loss: 0.533910\n",
      "epoch 132; iter: 0; batch classifier loss: 0.444858; batch adversarial loss: 0.514119\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392000; batch adversarial loss: 0.498215\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402057; batch adversarial loss: 0.536929\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354493; batch adversarial loss: 0.555458\n",
      "epoch 136; iter: 0; batch classifier loss: 0.434948; batch adversarial loss: 0.583040\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366040; batch adversarial loss: 0.523451\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375282; batch adversarial loss: 0.536437\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366938; batch adversarial loss: 0.568633\n",
      "epoch 140; iter: 0; batch classifier loss: 0.410252; batch adversarial loss: 0.542391\n",
      "epoch 141; iter: 0; batch classifier loss: 0.485069; batch adversarial loss: 0.504558\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386108; batch adversarial loss: 0.601060\n",
      "epoch 143; iter: 0; batch classifier loss: 0.362549; batch adversarial loss: 0.509383\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396275; batch adversarial loss: 0.497839\n",
      "epoch 145; iter: 0; batch classifier loss: 0.301607; batch adversarial loss: 0.507341\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377381; batch adversarial loss: 0.528122\n",
      "epoch 147; iter: 0; batch classifier loss: 0.420170; batch adversarial loss: 0.534324\n",
      "epoch 148; iter: 0; batch classifier loss: 0.372713; batch adversarial loss: 0.552866\n",
      "epoch 149; iter: 0; batch classifier loss: 0.300962; batch adversarial loss: 0.563090\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338944; batch adversarial loss: 0.525207\n",
      "epoch 151; iter: 0; batch classifier loss: 0.318546; batch adversarial loss: 0.496510\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340664; batch adversarial loss: 0.563188\n",
      "epoch 153; iter: 0; batch classifier loss: 0.462240; batch adversarial loss: 0.516147\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343606; batch adversarial loss: 0.564007\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364145; batch adversarial loss: 0.552781\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363415; batch adversarial loss: 0.505860\n",
      "epoch 157; iter: 0; batch classifier loss: 0.414383; batch adversarial loss: 0.524292\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388916; batch adversarial loss: 0.479185\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371945; batch adversarial loss: 0.497206\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406529; batch adversarial loss: 0.484956\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397135; batch adversarial loss: 0.537882\n",
      "epoch 162; iter: 0; batch classifier loss: 0.469776; batch adversarial loss: 0.563648\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388686; batch adversarial loss: 0.590619\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368638; batch adversarial loss: 0.535367\n",
      "epoch 165; iter: 0; batch classifier loss: 0.445757; batch adversarial loss: 0.525373\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351910; batch adversarial loss: 0.533348\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360861; batch adversarial loss: 0.600903\n",
      "epoch 168; iter: 0; batch classifier loss: 0.284840; batch adversarial loss: 0.577426\n",
      "epoch 169; iter: 0; batch classifier loss: 0.428570; batch adversarial loss: 0.559731\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342972; batch adversarial loss: 0.573572\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326216; batch adversarial loss: 0.563966\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381007; batch adversarial loss: 0.542018\n",
      "epoch 173; iter: 0; batch classifier loss: 0.397932; batch adversarial loss: 0.549824\n",
      "epoch 174; iter: 0; batch classifier loss: 0.289654; batch adversarial loss: 0.603074\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322272; batch adversarial loss: 0.554664\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410875; batch adversarial loss: 0.469615\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369780; batch adversarial loss: 0.535417\n",
      "epoch 178; iter: 0; batch classifier loss: 0.407495; batch adversarial loss: 0.572085\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279643; batch adversarial loss: 0.605817\n",
      "epoch 180; iter: 0; batch classifier loss: 0.408031; batch adversarial loss: 0.541402\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325564; batch adversarial loss: 0.543341\n",
      "epoch 182; iter: 0; batch classifier loss: 0.301888; batch adversarial loss: 0.449953\n",
      "epoch 183; iter: 0; batch classifier loss: 0.421149; batch adversarial loss: 0.513978\n",
      "epoch 184; iter: 0; batch classifier loss: 0.433053; batch adversarial loss: 0.562609\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384304; batch adversarial loss: 0.498589\n",
      "epoch 186; iter: 0; batch classifier loss: 0.471591; batch adversarial loss: 0.512265\n",
      "epoch 187; iter: 0; batch classifier loss: 0.399243; batch adversarial loss: 0.555658\n",
      "epoch 188; iter: 0; batch classifier loss: 0.397923; batch adversarial loss: 0.580169\n",
      "epoch 189; iter: 0; batch classifier loss: 0.392720; batch adversarial loss: 0.581157\n",
      "epoch 190; iter: 0; batch classifier loss: 0.418066; batch adversarial loss: 0.606388\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344431; batch adversarial loss: 0.548344\n",
      "epoch 192; iter: 0; batch classifier loss: 0.300472; batch adversarial loss: 0.535304\n",
      "epoch 193; iter: 0; batch classifier loss: 0.379780; batch adversarial loss: 0.561548\n",
      "epoch 194; iter: 0; batch classifier loss: 0.440213; batch adversarial loss: 0.533351\n",
      "epoch 195; iter: 0; batch classifier loss: 0.367388; batch adversarial loss: 0.479345\n",
      "epoch 196; iter: 0; batch classifier loss: 0.453665; batch adversarial loss: 0.588547\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347988; batch adversarial loss: 0.538125\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321876; batch adversarial loss: 0.483197\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397075; batch adversarial loss: 0.475706\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712359; batch adversarial loss: 0.624852\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629482; batch adversarial loss: 0.657651\n",
      "epoch 2; iter: 0; batch classifier loss: 0.612182; batch adversarial loss: 0.672838\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623151; batch adversarial loss: 0.667038\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568279; batch adversarial loss: 0.640695\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555042; batch adversarial loss: 0.638875\n",
      "epoch 6; iter: 0; batch classifier loss: 0.651382; batch adversarial loss: 0.678510\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550290; batch adversarial loss: 0.650312\n",
      "epoch 8; iter: 0; batch classifier loss: 0.699354; batch adversarial loss: 0.611635\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526840; batch adversarial loss: 0.594319\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580689; batch adversarial loss: 0.593322\n",
      "epoch 11; iter: 0; batch classifier loss: 0.500679; batch adversarial loss: 0.610119\n",
      "epoch 12; iter: 0; batch classifier loss: 0.508675; batch adversarial loss: 0.560917\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517299; batch adversarial loss: 0.585253\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542958; batch adversarial loss: 0.601234\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558117; batch adversarial loss: 0.563263\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482093; batch adversarial loss: 0.577649\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477034; batch adversarial loss: 0.554461\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478129; batch adversarial loss: 0.577035\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385129; batch adversarial loss: 0.552137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.524943; batch adversarial loss: 0.584483\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521103; batch adversarial loss: 0.589183\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433061; batch adversarial loss: 0.495920\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460528; batch adversarial loss: 0.494828\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491428; batch adversarial loss: 0.550341\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455101; batch adversarial loss: 0.564786\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510385; batch adversarial loss: 0.491176\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493574; batch adversarial loss: 0.586761\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429545; batch adversarial loss: 0.533715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492155; batch adversarial loss: 0.504755\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488504; batch adversarial loss: 0.580598\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444046; batch adversarial loss: 0.503449\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469776; batch adversarial loss: 0.454010\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400566; batch adversarial loss: 0.531051\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475659; batch adversarial loss: 0.512738\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447654; batch adversarial loss: 0.512504\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406233; batch adversarial loss: 0.529632\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422544; batch adversarial loss: 0.557827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440043; batch adversarial loss: 0.498847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470683; batch adversarial loss: 0.504757\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476281; batch adversarial loss: 0.543545\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411849; batch adversarial loss: 0.600406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.401007; batch adversarial loss: 0.568631\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454451; batch adversarial loss: 0.526031\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386951; batch adversarial loss: 0.533570\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424882; batch adversarial loss: 0.562947\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430672; batch adversarial loss: 0.581377\n",
      "epoch 47; iter: 0; batch classifier loss: 0.394252; batch adversarial loss: 0.536687\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460826; batch adversarial loss: 0.546466\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487092; batch adversarial loss: 0.457357\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424054; batch adversarial loss: 0.546650\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384217; batch adversarial loss: 0.435039\n",
      "epoch 52; iter: 0; batch classifier loss: 0.497539; batch adversarial loss: 0.573819\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422272; batch adversarial loss: 0.645670\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415471; batch adversarial loss: 0.570610\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416070; batch adversarial loss: 0.525251\n",
      "epoch 56; iter: 0; batch classifier loss: 0.356584; batch adversarial loss: 0.489365\n",
      "epoch 57; iter: 0; batch classifier loss: 0.385702; batch adversarial loss: 0.533831\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447785; batch adversarial loss: 0.507290\n",
      "epoch 59; iter: 0; batch classifier loss: 0.437528; batch adversarial loss: 0.527265\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434455; batch adversarial loss: 0.516483\n",
      "epoch 61; iter: 0; batch classifier loss: 0.394165; batch adversarial loss: 0.542654\n",
      "epoch 62; iter: 0; batch classifier loss: 0.354334; batch adversarial loss: 0.577594\n",
      "epoch 63; iter: 0; batch classifier loss: 0.483665; batch adversarial loss: 0.576856\n",
      "epoch 64; iter: 0; batch classifier loss: 0.383532; batch adversarial loss: 0.459869\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431673; batch adversarial loss: 0.552760\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417820; batch adversarial loss: 0.486568\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429961; batch adversarial loss: 0.554863\n",
      "epoch 68; iter: 0; batch classifier loss: 0.367339; batch adversarial loss: 0.504905\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401021; batch adversarial loss: 0.544396\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419187; batch adversarial loss: 0.574154\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386872; batch adversarial loss: 0.638705\n",
      "epoch 72; iter: 0; batch classifier loss: 0.426185; batch adversarial loss: 0.439123\n",
      "epoch 73; iter: 0; batch classifier loss: 0.466502; batch adversarial loss: 0.524643\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401760; batch adversarial loss: 0.573471\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352496; batch adversarial loss: 0.498422\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405783; batch adversarial loss: 0.610520\n",
      "epoch 77; iter: 0; batch classifier loss: 0.431321; batch adversarial loss: 0.563566\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398403; batch adversarial loss: 0.515945\n",
      "epoch 79; iter: 0; batch classifier loss: 0.427652; batch adversarial loss: 0.495021\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402387; batch adversarial loss: 0.524752\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351314; batch adversarial loss: 0.634218\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366972; batch adversarial loss: 0.613392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.433065; batch adversarial loss: 0.535344\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403264; batch adversarial loss: 0.536145\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392333; batch adversarial loss: 0.600704\n",
      "epoch 86; iter: 0; batch classifier loss: 0.469671; batch adversarial loss: 0.572439\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428207; batch adversarial loss: 0.590510\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340773; batch adversarial loss: 0.601831\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362666; batch adversarial loss: 0.592872\n",
      "epoch 90; iter: 0; batch classifier loss: 0.436522; batch adversarial loss: 0.602535\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362763; batch adversarial loss: 0.534935\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402056; batch adversarial loss: 0.554272\n",
      "epoch 93; iter: 0; batch classifier loss: 0.428567; batch adversarial loss: 0.542395\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406240; batch adversarial loss: 0.572147\n",
      "epoch 95; iter: 0; batch classifier loss: 0.476703; batch adversarial loss: 0.584166\n",
      "epoch 96; iter: 0; batch classifier loss: 0.406260; batch adversarial loss: 0.535196\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376506; batch adversarial loss: 0.563176\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377714; batch adversarial loss: 0.534473\n",
      "epoch 99; iter: 0; batch classifier loss: 0.345105; batch adversarial loss: 0.526310\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388378; batch adversarial loss: 0.478547\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415287; batch adversarial loss: 0.468971\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374122; batch adversarial loss: 0.526112\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350121; batch adversarial loss: 0.581378\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358730; batch adversarial loss: 0.544547\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372772; batch adversarial loss: 0.583450\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385393; batch adversarial loss: 0.572310\n",
      "epoch 107; iter: 0; batch classifier loss: 0.328500; batch adversarial loss: 0.554056\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351170; batch adversarial loss: 0.496860\n",
      "epoch 109; iter: 0; batch classifier loss: 0.432004; batch adversarial loss: 0.515258\n",
      "epoch 110; iter: 0; batch classifier loss: 0.387479; batch adversarial loss: 0.554651\n",
      "epoch 111; iter: 0; batch classifier loss: 0.399482; batch adversarial loss: 0.447888\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364347; batch adversarial loss: 0.545057\n",
      "epoch 113; iter: 0; batch classifier loss: 0.478941; batch adversarial loss: 0.506104\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365573; batch adversarial loss: 0.495640\n",
      "epoch 115; iter: 0; batch classifier loss: 0.322913; batch adversarial loss: 0.573208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.309316; batch adversarial loss: 0.524855\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365230; batch adversarial loss: 0.554742\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361828; batch adversarial loss: 0.525515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.383103; batch adversarial loss: 0.564336\n",
      "epoch 120; iter: 0; batch classifier loss: 0.307431; batch adversarial loss: 0.571360\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395576; batch adversarial loss: 0.516672\n",
      "epoch 122; iter: 0; batch classifier loss: 0.413804; batch adversarial loss: 0.547033\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359242; batch adversarial loss: 0.546292\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379712; batch adversarial loss: 0.573661\n",
      "epoch 125; iter: 0; batch classifier loss: 0.308613; batch adversarial loss: 0.543914\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358650; batch adversarial loss: 0.612266\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374294; batch adversarial loss: 0.514611\n",
      "epoch 128; iter: 0; batch classifier loss: 0.442217; batch adversarial loss: 0.553694\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394008; batch adversarial loss: 0.484760\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380295; batch adversarial loss: 0.533431\n",
      "epoch 131; iter: 0; batch classifier loss: 0.441652; batch adversarial loss: 0.558279\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394840; batch adversarial loss: 0.591906\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399270; batch adversarial loss: 0.638746\n",
      "epoch 134; iter: 0; batch classifier loss: 0.422953; batch adversarial loss: 0.469125\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408166; batch adversarial loss: 0.553516\n",
      "epoch 136; iter: 0; batch classifier loss: 0.501329; batch adversarial loss: 0.503867\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374002; batch adversarial loss: 0.553383\n",
      "epoch 138; iter: 0; batch classifier loss: 0.322218; batch adversarial loss: 0.534801\n",
      "epoch 139; iter: 0; batch classifier loss: 0.318132; batch adversarial loss: 0.564721\n",
      "epoch 140; iter: 0; batch classifier loss: 0.420999; batch adversarial loss: 0.473835\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350393; batch adversarial loss: 0.504118\n",
      "epoch 142; iter: 0; batch classifier loss: 0.270247; batch adversarial loss: 0.522355\n",
      "epoch 143; iter: 0; batch classifier loss: 0.375662; batch adversarial loss: 0.515455\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354954; batch adversarial loss: 0.527422\n",
      "epoch 145; iter: 0; batch classifier loss: 0.322776; batch adversarial loss: 0.566544\n",
      "epoch 146; iter: 0; batch classifier loss: 0.394575; batch adversarial loss: 0.649997\n",
      "epoch 147; iter: 0; batch classifier loss: 0.423102; batch adversarial loss: 0.554240\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353297; batch adversarial loss: 0.526477\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359525; batch adversarial loss: 0.572345\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368567; batch adversarial loss: 0.562749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417718; batch adversarial loss: 0.525774\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385448; batch adversarial loss: 0.572470\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351598; batch adversarial loss: 0.478149\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346637; batch adversarial loss: 0.525552\n",
      "epoch 155; iter: 0; batch classifier loss: 0.432367; batch adversarial loss: 0.487936\n",
      "epoch 156; iter: 0; batch classifier loss: 0.284216; batch adversarial loss: 0.496428\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399223; batch adversarial loss: 0.582785\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364862; batch adversarial loss: 0.449286\n",
      "epoch 159; iter: 0; batch classifier loss: 0.438703; batch adversarial loss: 0.544266\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390838; batch adversarial loss: 0.584148\n",
      "epoch 161; iter: 0; batch classifier loss: 0.328260; batch adversarial loss: 0.543846\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360093; batch adversarial loss: 0.538165\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366390; batch adversarial loss: 0.477361\n",
      "epoch 164; iter: 0; batch classifier loss: 0.427806; batch adversarial loss: 0.554443\n",
      "epoch 165; iter: 0; batch classifier loss: 0.381069; batch adversarial loss: 0.563959\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350228; batch adversarial loss: 0.507715\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362826; batch adversarial loss: 0.525801\n",
      "epoch 168; iter: 0; batch classifier loss: 0.393224; batch adversarial loss: 0.514741\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369046; batch adversarial loss: 0.507079\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344617; batch adversarial loss: 0.485776\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366674; batch adversarial loss: 0.496652\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336822; batch adversarial loss: 0.447051\n",
      "epoch 173; iter: 0; batch classifier loss: 0.282967; batch adversarial loss: 0.515705\n",
      "epoch 174; iter: 0; batch classifier loss: 0.354064; batch adversarial loss: 0.486876\n",
      "epoch 175; iter: 0; batch classifier loss: 0.387172; batch adversarial loss: 0.497757\n",
      "epoch 176; iter: 0; batch classifier loss: 0.412341; batch adversarial loss: 0.534984\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362026; batch adversarial loss: 0.629074\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351570; batch adversarial loss: 0.562056\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379391; batch adversarial loss: 0.571412\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354467; batch adversarial loss: 0.429761\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387326; batch adversarial loss: 0.505188\n",
      "epoch 182; iter: 0; batch classifier loss: 0.417270; batch adversarial loss: 0.553463\n",
      "epoch 183; iter: 0; batch classifier loss: 0.425265; batch adversarial loss: 0.564809\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347938; batch adversarial loss: 0.589803\n",
      "epoch 185; iter: 0; batch classifier loss: 0.427805; batch adversarial loss: 0.554138\n",
      "epoch 186; iter: 0; batch classifier loss: 0.431334; batch adversarial loss: 0.468390\n",
      "epoch 187; iter: 0; batch classifier loss: 0.410434; batch adversarial loss: 0.593715\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355445; batch adversarial loss: 0.544299\n",
      "epoch 189; iter: 0; batch classifier loss: 0.317254; batch adversarial loss: 0.582859\n",
      "epoch 190; iter: 0; batch classifier loss: 0.413510; batch adversarial loss: 0.604959\n",
      "epoch 191; iter: 0; batch classifier loss: 0.406845; batch adversarial loss: 0.611300\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343454; batch adversarial loss: 0.601779\n",
      "epoch 193; iter: 0; batch classifier loss: 0.404099; batch adversarial loss: 0.508028\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318873; batch adversarial loss: 0.496781\n",
      "epoch 195; iter: 0; batch classifier loss: 0.371388; batch adversarial loss: 0.515915\n",
      "epoch 196; iter: 0; batch classifier loss: 0.417135; batch adversarial loss: 0.584003\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339668; batch adversarial loss: 0.479120\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360130; batch adversarial loss: 0.516197\n",
      "epoch 199; iter: 0; batch classifier loss: 0.428269; batch adversarial loss: 0.554467\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716202; batch adversarial loss: 0.697663\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632059; batch adversarial loss: 0.668453\n",
      "epoch 2; iter: 0; batch classifier loss: 0.500722; batch adversarial loss: 0.646581\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542844; batch adversarial loss: 0.660903\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562896; batch adversarial loss: 0.628198\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612466; batch adversarial loss: 0.609326\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542500; batch adversarial loss: 0.583328\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546358; batch adversarial loss: 0.602567\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539297; batch adversarial loss: 0.597971\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554106; batch adversarial loss: 0.601860\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610376; batch adversarial loss: 0.535002\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545858; batch adversarial loss: 0.590244\n",
      "epoch 12; iter: 0; batch classifier loss: 0.606999; batch adversarial loss: 0.588760\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540320; batch adversarial loss: 0.622966\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548738; batch adversarial loss: 0.597225\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475725; batch adversarial loss: 0.519019\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543314; batch adversarial loss: 0.506927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.549428; batch adversarial loss: 0.507278\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548674; batch adversarial loss: 0.584934\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527242; batch adversarial loss: 0.570499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502951; batch adversarial loss: 0.553666\n",
      "epoch 21; iter: 0; batch classifier loss: 0.571884; batch adversarial loss: 0.615708\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494138; batch adversarial loss: 0.629112\n",
      "epoch 23; iter: 0; batch classifier loss: 0.428052; batch adversarial loss: 0.594396\n",
      "epoch 24; iter: 0; batch classifier loss: 0.523438; batch adversarial loss: 0.532763\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492075; batch adversarial loss: 0.454420\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465502; batch adversarial loss: 0.530953\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463269; batch adversarial loss: 0.514189\n",
      "epoch 28; iter: 0; batch classifier loss: 0.575859; batch adversarial loss: 0.481509\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461460; batch adversarial loss: 0.502552\n",
      "epoch 30; iter: 0; batch classifier loss: 0.522352; batch adversarial loss: 0.556518\n",
      "epoch 31; iter: 0; batch classifier loss: 0.512641; batch adversarial loss: 0.615604\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434885; batch adversarial loss: 0.545611\n",
      "epoch 33; iter: 0; batch classifier loss: 0.428438; batch adversarial loss: 0.571062\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418239; batch adversarial loss: 0.572276\n",
      "epoch 35; iter: 0; batch classifier loss: 0.508056; batch adversarial loss: 0.519166\n",
      "epoch 36; iter: 0; batch classifier loss: 0.365340; batch adversarial loss: 0.589872\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469378; batch adversarial loss: 0.544857\n",
      "epoch 38; iter: 0; batch classifier loss: 0.526844; batch adversarial loss: 0.508408\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471601; batch adversarial loss: 0.572372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466881; batch adversarial loss: 0.543462\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487526; batch adversarial loss: 0.491282\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422964; batch adversarial loss: 0.499579\n",
      "epoch 43; iter: 0; batch classifier loss: 0.529483; batch adversarial loss: 0.480882\n",
      "epoch 44; iter: 0; batch classifier loss: 0.413698; batch adversarial loss: 0.517468\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411409; batch adversarial loss: 0.545052\n",
      "epoch 46; iter: 0; batch classifier loss: 0.535559; batch adversarial loss: 0.535521\n",
      "epoch 47; iter: 0; batch classifier loss: 0.540435; batch adversarial loss: 0.526534\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425442; batch adversarial loss: 0.507670\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418650; batch adversarial loss: 0.544508\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386900; batch adversarial loss: 0.563298\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443541; batch adversarial loss: 0.526197\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461426; batch adversarial loss: 0.563034\n",
      "epoch 53; iter: 0; batch classifier loss: 0.575536; batch adversarial loss: 0.535205\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450559; batch adversarial loss: 0.563080\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376330; batch adversarial loss: 0.488952\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389757; batch adversarial loss: 0.498809\n",
      "epoch 57; iter: 0; batch classifier loss: 0.475698; batch adversarial loss: 0.516974\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438140; batch adversarial loss: 0.516222\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468695; batch adversarial loss: 0.553777\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445915; batch adversarial loss: 0.591189\n",
      "epoch 61; iter: 0; batch classifier loss: 0.405265; batch adversarial loss: 0.533856\n",
      "epoch 62; iter: 0; batch classifier loss: 0.483171; batch adversarial loss: 0.450285\n",
      "epoch 63; iter: 0; batch classifier loss: 0.455057; batch adversarial loss: 0.571897\n",
      "epoch 64; iter: 0; batch classifier loss: 0.459820; batch adversarial loss: 0.599721\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453988; batch adversarial loss: 0.507618\n",
      "epoch 66; iter: 0; batch classifier loss: 0.467307; batch adversarial loss: 0.554072\n",
      "epoch 67; iter: 0; batch classifier loss: 0.459372; batch adversarial loss: 0.462198\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380097; batch adversarial loss: 0.553619\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388172; batch adversarial loss: 0.544421\n",
      "epoch 70; iter: 0; batch classifier loss: 0.439370; batch adversarial loss: 0.571917\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378093; batch adversarial loss: 0.599661\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417383; batch adversarial loss: 0.553019\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395460; batch adversarial loss: 0.607751\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392891; batch adversarial loss: 0.599125\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424682; batch adversarial loss: 0.497106\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412964; batch adversarial loss: 0.498592\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400990; batch adversarial loss: 0.523701\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444365; batch adversarial loss: 0.532536\n",
      "epoch 79; iter: 0; batch classifier loss: 0.530495; batch adversarial loss: 0.590546\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476758; batch adversarial loss: 0.489615\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360249; batch adversarial loss: 0.563063\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407259; batch adversarial loss: 0.535207\n",
      "epoch 83; iter: 0; batch classifier loss: 0.355302; batch adversarial loss: 0.507779\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393742; batch adversarial loss: 0.643052\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413807; batch adversarial loss: 0.516314\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424648; batch adversarial loss: 0.563891\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377853; batch adversarial loss: 0.554557\n",
      "epoch 88; iter: 0; batch classifier loss: 0.419813; batch adversarial loss: 0.592696\n",
      "epoch 89; iter: 0; batch classifier loss: 0.426936; batch adversarial loss: 0.582903\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413743; batch adversarial loss: 0.535244\n",
      "epoch 91; iter: 0; batch classifier loss: 0.498578; batch adversarial loss: 0.507146\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364591; batch adversarial loss: 0.544144\n",
      "epoch 93; iter: 0; batch classifier loss: 0.323321; batch adversarial loss: 0.497552\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452280; batch adversarial loss: 0.526062\n",
      "epoch 95; iter: 0; batch classifier loss: 0.475555; batch adversarial loss: 0.525472\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392030; batch adversarial loss: 0.600105\n",
      "epoch 97; iter: 0; batch classifier loss: 0.451579; batch adversarial loss: 0.516318\n",
      "epoch 98; iter: 0; batch classifier loss: 0.353115; batch adversarial loss: 0.495451\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429544; batch adversarial loss: 0.562725\n",
      "epoch 100; iter: 0; batch classifier loss: 0.436186; batch adversarial loss: 0.544611\n",
      "epoch 101; iter: 0; batch classifier loss: 0.416156; batch adversarial loss: 0.628200\n",
      "epoch 102; iter: 0; batch classifier loss: 0.405054; batch adversarial loss: 0.554425\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391343; batch adversarial loss: 0.525286\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393831; batch adversarial loss: 0.563615\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398517; batch adversarial loss: 0.563877\n",
      "epoch 106; iter: 0; batch classifier loss: 0.319854; batch adversarial loss: 0.564253\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403870; batch adversarial loss: 0.571514\n",
      "epoch 108; iter: 0; batch classifier loss: 0.389064; batch adversarial loss: 0.552999\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415135; batch adversarial loss: 0.544568\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384609; batch adversarial loss: 0.572522\n",
      "epoch 111; iter: 0; batch classifier loss: 0.410613; batch adversarial loss: 0.526270\n",
      "epoch 112; iter: 0; batch classifier loss: 0.441744; batch adversarial loss: 0.470953\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389441; batch adversarial loss: 0.590213\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327738; batch adversarial loss: 0.536469\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371664; batch adversarial loss: 0.508232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.358696; batch adversarial loss: 0.516754\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408951; batch adversarial loss: 0.618114\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385622; batch adversarial loss: 0.608235\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414668; batch adversarial loss: 0.601027\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420249; batch adversarial loss: 0.525399\n",
      "epoch 121; iter: 0; batch classifier loss: 0.477061; batch adversarial loss: 0.497495\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343796; batch adversarial loss: 0.552755\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388324; batch adversarial loss: 0.644980\n",
      "epoch 124; iter: 0; batch classifier loss: 0.463325; batch adversarial loss: 0.544138\n",
      "epoch 125; iter: 0; batch classifier loss: 0.414904; batch adversarial loss: 0.479159\n",
      "epoch 126; iter: 0; batch classifier loss: 0.378388; batch adversarial loss: 0.498218\n",
      "epoch 127; iter: 0; batch classifier loss: 0.337160; batch adversarial loss: 0.507531\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355733; batch adversarial loss: 0.451930\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399038; batch adversarial loss: 0.508003\n",
      "epoch 130; iter: 0; batch classifier loss: 0.344796; batch adversarial loss: 0.470229\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373688; batch adversarial loss: 0.526803\n",
      "epoch 132; iter: 0; batch classifier loss: 0.424997; batch adversarial loss: 0.628296\n",
      "epoch 133; iter: 0; batch classifier loss: 0.359055; batch adversarial loss: 0.461053\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387884; batch adversarial loss: 0.552992\n",
      "epoch 135; iter: 0; batch classifier loss: 0.414310; batch adversarial loss: 0.507150\n",
      "epoch 136; iter: 0; batch classifier loss: 0.433102; batch adversarial loss: 0.608857\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400200; batch adversarial loss: 0.525141\n",
      "epoch 138; iter: 0; batch classifier loss: 0.436865; batch adversarial loss: 0.572432\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347171; batch adversarial loss: 0.580957\n",
      "epoch 140; iter: 0; batch classifier loss: 0.419658; batch adversarial loss: 0.506905\n",
      "epoch 141; iter: 0; batch classifier loss: 0.426332; batch adversarial loss: 0.498164\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347111; batch adversarial loss: 0.480016\n",
      "epoch 143; iter: 0; batch classifier loss: 0.417864; batch adversarial loss: 0.562625\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312710; batch adversarial loss: 0.581387\n",
      "epoch 145; iter: 0; batch classifier loss: 0.432909; batch adversarial loss: 0.516307\n",
      "epoch 146; iter: 0; batch classifier loss: 0.324104; batch adversarial loss: 0.526067\n",
      "epoch 147; iter: 0; batch classifier loss: 0.412400; batch adversarial loss: 0.553710\n",
      "epoch 148; iter: 0; batch classifier loss: 0.384631; batch adversarial loss: 0.637732\n",
      "epoch 149; iter: 0; batch classifier loss: 0.443511; batch adversarial loss: 0.517004\n",
      "epoch 150; iter: 0; batch classifier loss: 0.393827; batch adversarial loss: 0.637455\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372321; batch adversarial loss: 0.609628\n",
      "epoch 152; iter: 0; batch classifier loss: 0.381469; batch adversarial loss: 0.581709\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351834; batch adversarial loss: 0.554023\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337477; batch adversarial loss: 0.526450\n",
      "epoch 155; iter: 0; batch classifier loss: 0.396679; batch adversarial loss: 0.526323\n",
      "epoch 156; iter: 0; batch classifier loss: 0.393326; batch adversarial loss: 0.516436\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404076; batch adversarial loss: 0.544797\n",
      "epoch 158; iter: 0; batch classifier loss: 0.413103; batch adversarial loss: 0.544400\n",
      "epoch 159; iter: 0; batch classifier loss: 0.401580; batch adversarial loss: 0.516245\n",
      "epoch 160; iter: 0; batch classifier loss: 0.427687; batch adversarial loss: 0.572877\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330826; batch adversarial loss: 0.451737\n",
      "epoch 162; iter: 0; batch classifier loss: 0.395600; batch adversarial loss: 0.497359\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334832; batch adversarial loss: 0.600918\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372514; batch adversarial loss: 0.516314\n",
      "epoch 165; iter: 0; batch classifier loss: 0.408531; batch adversarial loss: 0.543138\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334614; batch adversarial loss: 0.581502\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395992; batch adversarial loss: 0.506876\n",
      "epoch 168; iter: 0; batch classifier loss: 0.403891; batch adversarial loss: 0.516207\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379399; batch adversarial loss: 0.535186\n",
      "epoch 170; iter: 0; batch classifier loss: 0.293373; batch adversarial loss: 0.535581\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344779; batch adversarial loss: 0.516636\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379367; batch adversarial loss: 0.555196\n",
      "epoch 173; iter: 0; batch classifier loss: 0.418451; batch adversarial loss: 0.479837\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334228; batch adversarial loss: 0.498264\n",
      "epoch 175; iter: 0; batch classifier loss: 0.341145; batch adversarial loss: 0.599057\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367174; batch adversarial loss: 0.534869\n",
      "epoch 177; iter: 0; batch classifier loss: 0.482090; batch adversarial loss: 0.518152\n",
      "epoch 178; iter: 0; batch classifier loss: 0.407298; batch adversarial loss: 0.545258\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362371; batch adversarial loss: 0.570309\n",
      "epoch 180; iter: 0; batch classifier loss: 0.451009; batch adversarial loss: 0.590228\n",
      "epoch 181; iter: 0; batch classifier loss: 0.394387; batch adversarial loss: 0.525943\n",
      "epoch 182; iter: 0; batch classifier loss: 0.388866; batch adversarial loss: 0.554883\n",
      "epoch 183; iter: 0; batch classifier loss: 0.422408; batch adversarial loss: 0.561873\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328950; batch adversarial loss: 0.580848\n",
      "epoch 185; iter: 0; batch classifier loss: 0.410379; batch adversarial loss: 0.525714\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414991; batch adversarial loss: 0.562585\n",
      "epoch 187; iter: 0; batch classifier loss: 0.335783; batch adversarial loss: 0.628413\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330256; batch adversarial loss: 0.554695\n",
      "epoch 189; iter: 0; batch classifier loss: 0.405526; batch adversarial loss: 0.581024\n",
      "epoch 190; iter: 0; batch classifier loss: 0.441541; batch adversarial loss: 0.620122\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403132; batch adversarial loss: 0.526139\n",
      "epoch 192; iter: 0; batch classifier loss: 0.426796; batch adversarial loss: 0.563268\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373499; batch adversarial loss: 0.488863\n",
      "epoch 194; iter: 0; batch classifier loss: 0.460152; batch adversarial loss: 0.554054\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321542; batch adversarial loss: 0.563167\n",
      "epoch 196; iter: 0; batch classifier loss: 0.409965; batch adversarial loss: 0.553977\n",
      "epoch 197; iter: 0; batch classifier loss: 0.408988; batch adversarial loss: 0.498254\n",
      "epoch 198; iter: 0; batch classifier loss: 0.427520; batch adversarial loss: 0.534413\n",
      "epoch 199; iter: 0; batch classifier loss: 0.500910; batch adversarial loss: 0.600671\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700565; batch adversarial loss: 0.897044\n",
      "epoch 1; iter: 0; batch classifier loss: 0.798108; batch adversarial loss: 1.062860\n",
      "epoch 2; iter: 0; batch classifier loss: 1.045204; batch adversarial loss: 1.034466\n",
      "epoch 3; iter: 0; batch classifier loss: 1.024440; batch adversarial loss: 0.932936\n",
      "epoch 4; iter: 0; batch classifier loss: 1.073091; batch adversarial loss: 0.856383\n",
      "epoch 5; iter: 0; batch classifier loss: 1.131780; batch adversarial loss: 0.803234\n",
      "epoch 6; iter: 0; batch classifier loss: 1.265324; batch adversarial loss: 0.735512\n",
      "epoch 7; iter: 0; batch classifier loss: 1.110532; batch adversarial loss: 0.679020\n",
      "epoch 8; iter: 0; batch classifier loss: 1.041610; batch adversarial loss: 0.636641\n",
      "epoch 9; iter: 0; batch classifier loss: 0.645829; batch adversarial loss: 0.616476\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612069; batch adversarial loss: 0.568495\n",
      "epoch 11; iter: 0; batch classifier loss: 0.449730; batch adversarial loss: 0.533346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.558451; batch adversarial loss: 0.611053\n",
      "epoch 13; iter: 0; batch classifier loss: 0.531160; batch adversarial loss: 0.547308\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513224; batch adversarial loss: 0.584355\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531738; batch adversarial loss: 0.549092\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519943; batch adversarial loss: 0.511639\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525828; batch adversarial loss: 0.611133\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502465; batch adversarial loss: 0.496061\n",
      "epoch 19; iter: 0; batch classifier loss: 0.580236; batch adversarial loss: 0.483571\n",
      "epoch 20; iter: 0; batch classifier loss: 0.501706; batch adversarial loss: 0.564067\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539848; batch adversarial loss: 0.555647\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515999; batch adversarial loss: 0.555576\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521942; batch adversarial loss: 0.541827\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501892; batch adversarial loss: 0.540146\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431124; batch adversarial loss: 0.511905\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502470; batch adversarial loss: 0.571260\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511644; batch adversarial loss: 0.588046\n",
      "epoch 28; iter: 0; batch classifier loss: 0.505158; batch adversarial loss: 0.508796\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505415; batch adversarial loss: 0.552434\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463717; batch adversarial loss: 0.541493\n",
      "epoch 31; iter: 0; batch classifier loss: 0.534025; batch adversarial loss: 0.528143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422343; batch adversarial loss: 0.582574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440714; batch adversarial loss: 0.515480\n",
      "epoch 34; iter: 0; batch classifier loss: 0.395837; batch adversarial loss: 0.518415\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445780; batch adversarial loss: 0.555503\n",
      "epoch 36; iter: 0; batch classifier loss: 0.409008; batch adversarial loss: 0.554653\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463574; batch adversarial loss: 0.584756\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512426; batch adversarial loss: 0.532017\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401815; batch adversarial loss: 0.565147\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430998; batch adversarial loss: 0.565086\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477891; batch adversarial loss: 0.501629\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440179; batch adversarial loss: 0.509703\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424653; batch adversarial loss: 0.529431\n",
      "epoch 44; iter: 0; batch classifier loss: 0.399854; batch adversarial loss: 0.553539\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461593; batch adversarial loss: 0.568337\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458145; batch adversarial loss: 0.543905\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431802; batch adversarial loss: 0.521157\n",
      "epoch 48; iter: 0; batch classifier loss: 0.527990; batch adversarial loss: 0.615202\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474059; batch adversarial loss: 0.545241\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460645; batch adversarial loss: 0.523064\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450120; batch adversarial loss: 0.453890\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391046; batch adversarial loss: 0.555090\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405107; batch adversarial loss: 0.538112\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440701; batch adversarial loss: 0.535805\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386685; batch adversarial loss: 0.528517\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473139; batch adversarial loss: 0.605356\n",
      "epoch 57; iter: 0; batch classifier loss: 0.449859; batch adversarial loss: 0.588384\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410268; batch adversarial loss: 0.582624\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420642; batch adversarial loss: 0.543202\n",
      "epoch 60; iter: 0; batch classifier loss: 0.380643; batch adversarial loss: 0.535180\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399366; batch adversarial loss: 0.516745\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398425; batch adversarial loss: 0.511313\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434743; batch adversarial loss: 0.585718\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387420; batch adversarial loss: 0.604839\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388294; batch adversarial loss: 0.564164\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419616; batch adversarial loss: 0.541396\n",
      "epoch 67; iter: 0; batch classifier loss: 0.427918; batch adversarial loss: 0.485875\n",
      "epoch 68; iter: 0; batch classifier loss: 0.320984; batch adversarial loss: 0.518209\n",
      "epoch 69; iter: 0; batch classifier loss: 0.483751; batch adversarial loss: 0.579959\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391541; batch adversarial loss: 0.523987\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419532; batch adversarial loss: 0.561949\n",
      "epoch 72; iter: 0; batch classifier loss: 0.351419; batch adversarial loss: 0.556370\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414357; batch adversarial loss: 0.543993\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391883; batch adversarial loss: 0.525555\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415011; batch adversarial loss: 0.554133\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406413; batch adversarial loss: 0.574879\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412291; batch adversarial loss: 0.542179\n",
      "epoch 78; iter: 0; batch classifier loss: 0.342069; batch adversarial loss: 0.525121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400692; batch adversarial loss: 0.527911\n",
      "epoch 80; iter: 0; batch classifier loss: 0.391650; batch adversarial loss: 0.609837\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391693; batch adversarial loss: 0.572261\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386291; batch adversarial loss: 0.535881\n",
      "epoch 83; iter: 0; batch classifier loss: 0.399621; batch adversarial loss: 0.572776\n",
      "epoch 84; iter: 0; batch classifier loss: 0.330751; batch adversarial loss: 0.626068\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412851; batch adversarial loss: 0.580985\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419759; batch adversarial loss: 0.553884\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405721; batch adversarial loss: 0.617250\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356622; batch adversarial loss: 0.598869\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403266; batch adversarial loss: 0.536189\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364794; batch adversarial loss: 0.590322\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439505; batch adversarial loss: 0.563742\n",
      "epoch 92; iter: 0; batch classifier loss: 0.433829; batch adversarial loss: 0.487507\n",
      "epoch 93; iter: 0; batch classifier loss: 0.396197; batch adversarial loss: 0.542051\n",
      "epoch 94; iter: 0; batch classifier loss: 0.333075; batch adversarial loss: 0.590058\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422352; batch adversarial loss: 0.562030\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384838; batch adversarial loss: 0.498940\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375038; batch adversarial loss: 0.535152\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375441; batch adversarial loss: 0.631630\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358037; batch adversarial loss: 0.527203\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375832; batch adversarial loss: 0.574407\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414939; batch adversarial loss: 0.535217\n",
      "epoch 102; iter: 0; batch classifier loss: 0.383117; batch adversarial loss: 0.589967\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382284; batch adversarial loss: 0.543289\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393073; batch adversarial loss: 0.508007\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395818; batch adversarial loss: 0.570533\n",
      "epoch 106; iter: 0; batch classifier loss: 0.436608; batch adversarial loss: 0.527516\n",
      "epoch 107; iter: 0; batch classifier loss: 0.438814; batch adversarial loss: 0.598388\n",
      "epoch 108; iter: 0; batch classifier loss: 0.332336; batch adversarial loss: 0.516681\n",
      "epoch 109; iter: 0; batch classifier loss: 0.382468; batch adversarial loss: 0.535104\n",
      "epoch 110; iter: 0; batch classifier loss: 0.322878; batch adversarial loss: 0.608961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.369975; batch adversarial loss: 0.562311\n",
      "epoch 112; iter: 0; batch classifier loss: 0.330479; batch adversarial loss: 0.626704\n",
      "epoch 113; iter: 0; batch classifier loss: 0.393572; batch adversarial loss: 0.598583\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360986; batch adversarial loss: 0.516378\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358910; batch adversarial loss: 0.517466\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382800; batch adversarial loss: 0.497745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363319; batch adversarial loss: 0.590590\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410488; batch adversarial loss: 0.534757\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394937; batch adversarial loss: 0.563809\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330467; batch adversarial loss: 0.508146\n",
      "epoch 121; iter: 0; batch classifier loss: 0.430630; batch adversarial loss: 0.588952\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326901; batch adversarial loss: 0.543287\n",
      "epoch 123; iter: 0; batch classifier loss: 0.292608; batch adversarial loss: 0.507000\n",
      "epoch 124; iter: 0; batch classifier loss: 0.349962; batch adversarial loss: 0.553927\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382990; batch adversarial loss: 0.553769\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314492; batch adversarial loss: 0.560655\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395152; batch adversarial loss: 0.561799\n",
      "epoch 128; iter: 0; batch classifier loss: 0.300746; batch adversarial loss: 0.563205\n",
      "epoch 129; iter: 0; batch classifier loss: 0.290357; batch adversarial loss: 0.471642\n",
      "epoch 130; iter: 0; batch classifier loss: 0.297182; batch adversarial loss: 0.506918\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328438; batch adversarial loss: 0.554400\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431655; batch adversarial loss: 0.608163\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361246; batch adversarial loss: 0.581419\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340479; batch adversarial loss: 0.634256\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347574; batch adversarial loss: 0.589839\n",
      "epoch 136; iter: 0; batch classifier loss: 0.311400; batch adversarial loss: 0.617143\n",
      "epoch 137; iter: 0; batch classifier loss: 0.309439; batch adversarial loss: 0.598007\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362293; batch adversarial loss: 0.543272\n",
      "epoch 139; iter: 0; batch classifier loss: 0.364536; batch adversarial loss: 0.536648\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347360; batch adversarial loss: 0.471752\n",
      "epoch 141; iter: 0; batch classifier loss: 0.335280; batch adversarial loss: 0.589981\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347135; batch adversarial loss: 0.580251\n",
      "epoch 143; iter: 0; batch classifier loss: 0.435793; batch adversarial loss: 0.563152\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361783; batch adversarial loss: 0.553025\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358606; batch adversarial loss: 0.487926\n",
      "epoch 146; iter: 0; batch classifier loss: 0.372290; batch adversarial loss: 0.526561\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334427; batch adversarial loss: 0.499705\n",
      "epoch 148; iter: 0; batch classifier loss: 0.359019; batch adversarial loss: 0.499968\n",
      "epoch 149; iter: 0; batch classifier loss: 0.383056; batch adversarial loss: 0.598467\n",
      "epoch 150; iter: 0; batch classifier loss: 0.310427; batch adversarial loss: 0.580857\n",
      "epoch 151; iter: 0; batch classifier loss: 0.324680; batch adversarial loss: 0.616892\n",
      "epoch 152; iter: 0; batch classifier loss: 0.296038; batch adversarial loss: 0.490763\n",
      "epoch 153; iter: 0; batch classifier loss: 0.416520; batch adversarial loss: 0.472451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372577; batch adversarial loss: 0.544260\n",
      "epoch 155; iter: 0; batch classifier loss: 0.361555; batch adversarial loss: 0.617359\n",
      "epoch 156; iter: 0; batch classifier loss: 0.329482; batch adversarial loss: 0.635468\n",
      "epoch 157; iter: 0; batch classifier loss: 0.289377; batch adversarial loss: 0.544630\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345283; batch adversarial loss: 0.499204\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388701; batch adversarial loss: 0.516856\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364456; batch adversarial loss: 0.561803\n",
      "epoch 161; iter: 0; batch classifier loss: 0.317811; batch adversarial loss: 0.471749\n",
      "epoch 162; iter: 0; batch classifier loss: 0.414975; batch adversarial loss: 0.625510\n",
      "epoch 163; iter: 0; batch classifier loss: 0.316863; batch adversarial loss: 0.507281\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368523; batch adversarial loss: 0.536551\n",
      "epoch 165; iter: 0; batch classifier loss: 0.430800; batch adversarial loss: 0.561600\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354281; batch adversarial loss: 0.580806\n",
      "epoch 167; iter: 0; batch classifier loss: 0.326919; batch adversarial loss: 0.497847\n",
      "epoch 168; iter: 0; batch classifier loss: 0.429066; batch adversarial loss: 0.507416\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384050; batch adversarial loss: 0.499560\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398551; batch adversarial loss: 0.527293\n",
      "epoch 171; iter: 0; batch classifier loss: 0.405460; batch adversarial loss: 0.554794\n",
      "epoch 172; iter: 0; batch classifier loss: 0.289558; batch adversarial loss: 0.546225\n",
      "epoch 173; iter: 0; batch classifier loss: 0.307869; batch adversarial loss: 0.636509\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311302; batch adversarial loss: 0.608237\n",
      "epoch 175; iter: 0; batch classifier loss: 0.310327; batch adversarial loss: 0.487199\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316953; batch adversarial loss: 0.636274\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417541; batch adversarial loss: 0.573249\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367147; batch adversarial loss: 0.551114\n",
      "epoch 179; iter: 0; batch classifier loss: 0.328876; batch adversarial loss: 0.590788\n",
      "epoch 180; iter: 0; batch classifier loss: 0.349142; batch adversarial loss: 0.584325\n",
      "epoch 181; iter: 0; batch classifier loss: 0.284346; batch adversarial loss: 0.490008\n",
      "epoch 182; iter: 0; batch classifier loss: 0.294780; batch adversarial loss: 0.536446\n",
      "epoch 183; iter: 0; batch classifier loss: 0.415843; batch adversarial loss: 0.580761\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342313; batch adversarial loss: 0.573488\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303725; batch adversarial loss: 0.545200\n",
      "epoch 186; iter: 0; batch classifier loss: 0.372525; batch adversarial loss: 0.537349\n",
      "epoch 187; iter: 0; batch classifier loss: 0.289249; batch adversarial loss: 0.553694\n",
      "epoch 188; iter: 0; batch classifier loss: 0.300748; batch adversarial loss: 0.608952\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346385; batch adversarial loss: 0.510466\n",
      "epoch 190; iter: 0; batch classifier loss: 0.370913; batch adversarial loss: 0.617053\n",
      "epoch 191; iter: 0; batch classifier loss: 0.303594; batch adversarial loss: 0.508823\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394076; batch adversarial loss: 0.626252\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361471; batch adversarial loss: 0.499123\n",
      "epoch 194; iter: 0; batch classifier loss: 0.317215; batch adversarial loss: 0.671828\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319981; batch adversarial loss: 0.644220\n",
      "epoch 196; iter: 0; batch classifier loss: 0.291488; batch adversarial loss: 0.517595\n",
      "epoch 197; iter: 0; batch classifier loss: 0.410135; batch adversarial loss: 0.643983\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353649; batch adversarial loss: 0.552858\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334333; batch adversarial loss: 0.499668\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772050; batch adversarial loss: 0.838646\n",
      "epoch 1; iter: 0; batch classifier loss: 0.713647; batch adversarial loss: 0.852276\n",
      "epoch 2; iter: 0; batch classifier loss: 0.886915; batch adversarial loss: 0.812188\n",
      "epoch 3; iter: 0; batch classifier loss: 0.860714; batch adversarial loss: 0.741215\n",
      "epoch 4; iter: 0; batch classifier loss: 0.994632; batch adversarial loss: 0.677052\n",
      "epoch 5; iter: 0; batch classifier loss: 0.797016; batch adversarial loss: 0.643270\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549000; batch adversarial loss: 0.604124\n",
      "epoch 7; iter: 0; batch classifier loss: 0.613240; batch adversarial loss: 0.614981\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578165; batch adversarial loss: 0.602009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.544642; batch adversarial loss: 0.611425\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535915; batch adversarial loss: 0.578401\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521437; batch adversarial loss: 0.568347\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550887; batch adversarial loss: 0.575985\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511148; batch adversarial loss: 0.569605\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530439; batch adversarial loss: 0.635245\n",
      "epoch 15; iter: 0; batch classifier loss: 0.568213; batch adversarial loss: 0.606762\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491487; batch adversarial loss: 0.586849\n",
      "epoch 17; iter: 0; batch classifier loss: 0.566553; batch adversarial loss: 0.563262\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473942; batch adversarial loss: 0.529730\n",
      "epoch 19; iter: 0; batch classifier loss: 0.580041; batch adversarial loss: 0.504089\n",
      "epoch 20; iter: 0; batch classifier loss: 0.600126; batch adversarial loss: 0.575541\n",
      "epoch 21; iter: 0; batch classifier loss: 0.562428; batch adversarial loss: 0.503086\n",
      "epoch 22; iter: 0; batch classifier loss: 0.556026; batch adversarial loss: 0.536605\n",
      "epoch 23; iter: 0; batch classifier loss: 0.542612; batch adversarial loss: 0.475227\n",
      "epoch 24; iter: 0; batch classifier loss: 0.545635; batch adversarial loss: 0.524043\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510084; batch adversarial loss: 0.565218\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487680; batch adversarial loss: 0.526427\n",
      "epoch 27; iter: 0; batch classifier loss: 0.555197; batch adversarial loss: 0.580169\n",
      "epoch 28; iter: 0; batch classifier loss: 0.449899; batch adversarial loss: 0.506262\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485596; batch adversarial loss: 0.511832\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452321; batch adversarial loss: 0.578217\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440597; batch adversarial loss: 0.495190\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506851; batch adversarial loss: 0.531424\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465335; batch adversarial loss: 0.491603\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477102; batch adversarial loss: 0.574897\n",
      "epoch 35; iter: 0; batch classifier loss: 0.508504; batch adversarial loss: 0.572120\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441796; batch adversarial loss: 0.573951\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423652; batch adversarial loss: 0.510272\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439960; batch adversarial loss: 0.524054\n",
      "epoch 39; iter: 0; batch classifier loss: 0.368158; batch adversarial loss: 0.520514\n",
      "epoch 40; iter: 0; batch classifier loss: 0.372232; batch adversarial loss: 0.500414\n",
      "epoch 41; iter: 0; batch classifier loss: 0.393575; batch adversarial loss: 0.479310\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451920; batch adversarial loss: 0.576814\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449915; batch adversarial loss: 0.431872\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501478; batch adversarial loss: 0.583705\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400359; batch adversarial loss: 0.558287\n",
      "epoch 46; iter: 0; batch classifier loss: 0.369997; batch adversarial loss: 0.503723\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417097; batch adversarial loss: 0.555202\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419583; batch adversarial loss: 0.558539\n",
      "epoch 49; iter: 0; batch classifier loss: 0.332080; batch adversarial loss: 0.469850\n",
      "epoch 50; iter: 0; batch classifier loss: 0.358776; batch adversarial loss: 0.572738\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404959; batch adversarial loss: 0.554692\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418241; batch adversarial loss: 0.534197\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454615; batch adversarial loss: 0.569796\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443696; batch adversarial loss: 0.544221\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416487; batch adversarial loss: 0.486339\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463964; batch adversarial loss: 0.507525\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428946; batch adversarial loss: 0.608330\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429316; batch adversarial loss: 0.560908\n",
      "epoch 59; iter: 0; batch classifier loss: 0.367090; batch adversarial loss: 0.516052\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427945; batch adversarial loss: 0.497542\n",
      "epoch 61; iter: 0; batch classifier loss: 0.358115; batch adversarial loss: 0.599153\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395190; batch adversarial loss: 0.507470\n",
      "epoch 63; iter: 0; batch classifier loss: 0.373597; batch adversarial loss: 0.533814\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382728; batch adversarial loss: 0.505975\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380609; batch adversarial loss: 0.571821\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386077; batch adversarial loss: 0.525843\n",
      "epoch 67; iter: 0; batch classifier loss: 0.378632; batch adversarial loss: 0.508184\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428825; batch adversarial loss: 0.552477\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389645; batch adversarial loss: 0.507835\n",
      "epoch 70; iter: 0; batch classifier loss: 0.348448; batch adversarial loss: 0.634599\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358978; batch adversarial loss: 0.544915\n",
      "epoch 72; iter: 0; batch classifier loss: 0.337094; batch adversarial loss: 0.525110\n",
      "epoch 73; iter: 0; batch classifier loss: 0.343194; batch adversarial loss: 0.583485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465191; batch adversarial loss: 0.470879\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426509; batch adversarial loss: 0.523274\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366644; batch adversarial loss: 0.555944\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404632; batch adversarial loss: 0.561888\n",
      "epoch 78; iter: 0; batch classifier loss: 0.340743; batch adversarial loss: 0.527633\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418606; batch adversarial loss: 0.553510\n",
      "epoch 80; iter: 0; batch classifier loss: 0.465372; batch adversarial loss: 0.627429\n",
      "epoch 81; iter: 0; batch classifier loss: 0.380271; batch adversarial loss: 0.598770\n",
      "epoch 82; iter: 0; batch classifier loss: 0.332840; batch adversarial loss: 0.507761\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409631; batch adversarial loss: 0.561852\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371609; batch adversarial loss: 0.551883\n",
      "epoch 85; iter: 0; batch classifier loss: 0.444354; batch adversarial loss: 0.498320\n",
      "epoch 86; iter: 0; batch classifier loss: 0.341979; batch adversarial loss: 0.564233\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350976; batch adversarial loss: 0.514836\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395785; batch adversarial loss: 0.592923\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410742; batch adversarial loss: 0.589432\n",
      "epoch 90; iter: 0; batch classifier loss: 0.361733; batch adversarial loss: 0.527878\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356825; batch adversarial loss: 0.600195\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407935; batch adversarial loss: 0.485944\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398809; batch adversarial loss: 0.538560\n",
      "epoch 94; iter: 0; batch classifier loss: 0.350226; batch adversarial loss: 0.515891\n",
      "epoch 95; iter: 0; batch classifier loss: 0.282826; batch adversarial loss: 0.581309\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332545; batch adversarial loss: 0.493216\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378069; batch adversarial loss: 0.576068\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396789; batch adversarial loss: 0.596457\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356225; batch adversarial loss: 0.587012\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361745; batch adversarial loss: 0.489745\n",
      "epoch 101; iter: 0; batch classifier loss: 0.430111; batch adversarial loss: 0.548966\n",
      "epoch 102; iter: 0; batch classifier loss: 0.420617; batch adversarial loss: 0.551824\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374094; batch adversarial loss: 0.482590\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389088; batch adversarial loss: 0.580275\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359641; batch adversarial loss: 0.581361\n",
      "epoch 106; iter: 0; batch classifier loss: 0.309810; batch adversarial loss: 0.571592\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380713; batch adversarial loss: 0.554024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.337232; batch adversarial loss: 0.581520\n",
      "epoch 109; iter: 0; batch classifier loss: 0.353558; batch adversarial loss: 0.544896\n",
      "epoch 110; iter: 0; batch classifier loss: 0.290894; batch adversarial loss: 0.506121\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348470; batch adversarial loss: 0.563352\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349155; batch adversarial loss: 0.590735\n",
      "epoch 113; iter: 0; batch classifier loss: 0.376048; batch adversarial loss: 0.534324\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347960; batch adversarial loss: 0.544423\n",
      "epoch 115; iter: 0; batch classifier loss: 0.349865; batch adversarial loss: 0.534772\n",
      "epoch 116; iter: 0; batch classifier loss: 0.399527; batch adversarial loss: 0.517534\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411433; batch adversarial loss: 0.544594\n",
      "epoch 118; iter: 0; batch classifier loss: 0.400961; batch adversarial loss: 0.618958\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387515; batch adversarial loss: 0.571605\n",
      "epoch 120; iter: 0; batch classifier loss: 0.335697; batch adversarial loss: 0.525239\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391992; batch adversarial loss: 0.572994\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356922; batch adversarial loss: 0.534880\n",
      "epoch 123; iter: 0; batch classifier loss: 0.246017; batch adversarial loss: 0.563924\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402245; batch adversarial loss: 0.599776\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408098; batch adversarial loss: 0.450935\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386609; batch adversarial loss: 0.543135\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333212; batch adversarial loss: 0.497670\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322677; batch adversarial loss: 0.537060\n",
      "epoch 129; iter: 0; batch classifier loss: 0.316342; batch adversarial loss: 0.462268\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352556; batch adversarial loss: 0.507290\n",
      "epoch 131; iter: 0; batch classifier loss: 0.312287; batch adversarial loss: 0.554685\n",
      "epoch 132; iter: 0; batch classifier loss: 0.365944; batch adversarial loss: 0.563150\n",
      "epoch 133; iter: 0; batch classifier loss: 0.339517; batch adversarial loss: 0.552637\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354360; batch adversarial loss: 0.403473\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378606; batch adversarial loss: 0.543670\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378100; batch adversarial loss: 0.563714\n",
      "epoch 137; iter: 0; batch classifier loss: 0.411198; batch adversarial loss: 0.545272\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359027; batch adversarial loss: 0.481100\n",
      "epoch 139; iter: 0; batch classifier loss: 0.348032; batch adversarial loss: 0.562545\n",
      "epoch 140; iter: 0; batch classifier loss: 0.372240; batch adversarial loss: 0.580768\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390814; batch adversarial loss: 0.554143\n",
      "epoch 142; iter: 0; batch classifier loss: 0.319926; batch adversarial loss: 0.582198\n",
      "epoch 143; iter: 0; batch classifier loss: 0.304965; batch adversarial loss: 0.526465\n",
      "epoch 144; iter: 0; batch classifier loss: 0.306397; batch adversarial loss: 0.554289\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353608; batch adversarial loss: 0.452446\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317670; batch adversarial loss: 0.608816\n",
      "epoch 147; iter: 0; batch classifier loss: 0.403676; batch adversarial loss: 0.535820\n",
      "epoch 148; iter: 0; batch classifier loss: 0.355760; batch adversarial loss: 0.571835\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320236; batch adversarial loss: 0.581056\n",
      "epoch 150; iter: 0; batch classifier loss: 0.295721; batch adversarial loss: 0.589587\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368300; batch adversarial loss: 0.647129\n",
      "epoch 152; iter: 0; batch classifier loss: 0.322504; batch adversarial loss: 0.544385\n",
      "epoch 153; iter: 0; batch classifier loss: 0.382518; batch adversarial loss: 0.535006\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298732; batch adversarial loss: 0.590713\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356784; batch adversarial loss: 0.552928\n",
      "epoch 156; iter: 0; batch classifier loss: 0.293908; batch adversarial loss: 0.507902\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368062; batch adversarial loss: 0.489428\n",
      "epoch 158; iter: 0; batch classifier loss: 0.317679; batch adversarial loss: 0.498632\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342882; batch adversarial loss: 0.507942\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352506; batch adversarial loss: 0.544540\n",
      "epoch 161; iter: 0; batch classifier loss: 0.283232; batch adversarial loss: 0.581183\n",
      "epoch 162; iter: 0; batch classifier loss: 0.319614; batch adversarial loss: 0.572158\n",
      "epoch 163; iter: 0; batch classifier loss: 0.314034; batch adversarial loss: 0.469918\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356241; batch adversarial loss: 0.563166\n",
      "epoch 165; iter: 0; batch classifier loss: 0.406279; batch adversarial loss: 0.497941\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395715; batch adversarial loss: 0.544069\n",
      "epoch 167; iter: 0; batch classifier loss: 0.368329; batch adversarial loss: 0.535202\n",
      "epoch 168; iter: 0; batch classifier loss: 0.299425; batch adversarial loss: 0.563172\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339595; batch adversarial loss: 0.507029\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354271; batch adversarial loss: 0.553694\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295766; batch adversarial loss: 0.534768\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374010; batch adversarial loss: 0.488091\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342300; batch adversarial loss: 0.581732\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363312; batch adversarial loss: 0.554442\n",
      "epoch 175; iter: 0; batch classifier loss: 0.321306; batch adversarial loss: 0.570989\n",
      "epoch 176; iter: 0; batch classifier loss: 0.327747; batch adversarial loss: 0.498956\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372265; batch adversarial loss: 0.545655\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389364; batch adversarial loss: 0.517290\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322545; batch adversarial loss: 0.618808\n",
      "epoch 180; iter: 0; batch classifier loss: 0.247262; batch adversarial loss: 0.488036\n",
      "epoch 181; iter: 0; batch classifier loss: 0.274898; batch adversarial loss: 0.517441\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368078; batch adversarial loss: 0.535032\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341661; batch adversarial loss: 0.526096\n",
      "epoch 184; iter: 0; batch classifier loss: 0.402990; batch adversarial loss: 0.572249\n",
      "epoch 185; iter: 0; batch classifier loss: 0.312454; batch adversarial loss: 0.591211\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359389; batch adversarial loss: 0.571912\n",
      "epoch 187; iter: 0; batch classifier loss: 0.432957; batch adversarial loss: 0.534848\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311610; batch adversarial loss: 0.518039\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323180; batch adversarial loss: 0.451034\n",
      "epoch 190; iter: 0; batch classifier loss: 0.314589; batch adversarial loss: 0.535626\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344168; batch adversarial loss: 0.608221\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349985; batch adversarial loss: 0.442804\n",
      "epoch 193; iter: 0; batch classifier loss: 0.306223; batch adversarial loss: 0.563400\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368842; batch adversarial loss: 0.488632\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341859; batch adversarial loss: 0.617707\n",
      "epoch 196; iter: 0; batch classifier loss: 0.270317; batch adversarial loss: 0.536850\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339698; batch adversarial loss: 0.591454\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336775; batch adversarial loss: 0.563175\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385816; batch adversarial loss: 0.545722\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723812; batch adversarial loss: 0.703654\n",
      "epoch 1; iter: 0; batch classifier loss: 0.684889; batch adversarial loss: 0.673465\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558867; batch adversarial loss: 0.645537\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598829; batch adversarial loss: 0.640493\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541366; batch adversarial loss: 0.602934\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564177; batch adversarial loss: 0.612554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.541600; batch adversarial loss: 0.615116\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522321; batch adversarial loss: 0.581566\n",
      "epoch 8; iter: 0; batch classifier loss: 0.493868; batch adversarial loss: 0.587283\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518782; batch adversarial loss: 0.568474\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506612; batch adversarial loss: 0.565694\n",
      "epoch 11; iter: 0; batch classifier loss: 0.477930; batch adversarial loss: 0.594024\n",
      "epoch 12; iter: 0; batch classifier loss: 0.474863; batch adversarial loss: 0.575694\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506899; batch adversarial loss: 0.575434\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438654; batch adversarial loss: 0.540659\n",
      "epoch 15; iter: 0; batch classifier loss: 0.619824; batch adversarial loss: 0.612941\n",
      "epoch 16; iter: 0; batch classifier loss: 0.548548; batch adversarial loss: 0.626388\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530050; batch adversarial loss: 0.583038\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501140; batch adversarial loss: 0.575685\n",
      "epoch 19; iter: 0; batch classifier loss: 0.568918; batch adversarial loss: 0.616023\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508136; batch adversarial loss: 0.533732\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487984; batch adversarial loss: 0.571219\n",
      "epoch 22; iter: 0; batch classifier loss: 0.444998; batch adversarial loss: 0.480976\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439170; batch adversarial loss: 0.560086\n",
      "epoch 24; iter: 0; batch classifier loss: 0.545413; batch adversarial loss: 0.487963\n",
      "epoch 25; iter: 0; batch classifier loss: 0.544080; batch adversarial loss: 0.516744\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513106; batch adversarial loss: 0.492835\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485881; batch adversarial loss: 0.559109\n",
      "epoch 28; iter: 0; batch classifier loss: 0.428782; batch adversarial loss: 0.555128\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488649; batch adversarial loss: 0.536261\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406288; batch adversarial loss: 0.560347\n",
      "epoch 31; iter: 0; batch classifier loss: 0.478357; batch adversarial loss: 0.562267\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468393; batch adversarial loss: 0.552061\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430911; batch adversarial loss: 0.465670\n",
      "epoch 34; iter: 0; batch classifier loss: 0.506952; batch adversarial loss: 0.474544\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411828; batch adversarial loss: 0.552539\n",
      "epoch 36; iter: 0; batch classifier loss: 0.393636; batch adversarial loss: 0.607088\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486431; batch adversarial loss: 0.472649\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458208; batch adversarial loss: 0.493200\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420423; batch adversarial loss: 0.554338\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413302; batch adversarial loss: 0.536465\n",
      "epoch 41; iter: 0; batch classifier loss: 0.529414; batch adversarial loss: 0.438007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422316; batch adversarial loss: 0.534985\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445901; batch adversarial loss: 0.580182\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461358; batch adversarial loss: 0.508901\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441022; batch adversarial loss: 0.507135\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508134; batch adversarial loss: 0.480017\n",
      "epoch 47; iter: 0; batch classifier loss: 0.394388; batch adversarial loss: 0.517290\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445445; batch adversarial loss: 0.516320\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458368; batch adversarial loss: 0.588612\n",
      "epoch 50; iter: 0; batch classifier loss: 0.464350; batch adversarial loss: 0.536590\n",
      "epoch 51; iter: 0; batch classifier loss: 0.347182; batch adversarial loss: 0.453482\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390645; batch adversarial loss: 0.562713\n",
      "epoch 53; iter: 0; batch classifier loss: 0.483360; batch adversarial loss: 0.571932\n",
      "epoch 54; iter: 0; batch classifier loss: 0.547125; batch adversarial loss: 0.469062\n",
      "epoch 55; iter: 0; batch classifier loss: 0.507188; batch adversarial loss: 0.533841\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467936; batch adversarial loss: 0.562226\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404691; batch adversarial loss: 0.479372\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421535; batch adversarial loss: 0.626983\n",
      "epoch 59; iter: 0; batch classifier loss: 0.493680; batch adversarial loss: 0.589117\n",
      "epoch 60; iter: 0; batch classifier loss: 0.429507; batch adversarial loss: 0.564199\n",
      "epoch 61; iter: 0; batch classifier loss: 0.443589; batch adversarial loss: 0.590335\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393913; batch adversarial loss: 0.637677\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447923; batch adversarial loss: 0.503002\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376754; batch adversarial loss: 0.527020\n",
      "epoch 65; iter: 0; batch classifier loss: 0.336625; batch adversarial loss: 0.544553\n",
      "epoch 66; iter: 0; batch classifier loss: 0.383639; batch adversarial loss: 0.520475\n",
      "epoch 67; iter: 0; batch classifier loss: 0.336264; batch adversarial loss: 0.553118\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427694; batch adversarial loss: 0.554153\n",
      "epoch 69; iter: 0; batch classifier loss: 0.346330; batch adversarial loss: 0.526875\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462350; batch adversarial loss: 0.581732\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448340; batch adversarial loss: 0.518809\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397202; batch adversarial loss: 0.597337\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403571; batch adversarial loss: 0.437371\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387855; batch adversarial loss: 0.499323\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438930; batch adversarial loss: 0.644297\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386264; batch adversarial loss: 0.581212\n",
      "epoch 77; iter: 0; batch classifier loss: 0.466020; batch adversarial loss: 0.561822\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394406; batch adversarial loss: 0.517345\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420574; batch adversarial loss: 0.525913\n",
      "epoch 80; iter: 0; batch classifier loss: 0.373100; batch adversarial loss: 0.534927\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415850; batch adversarial loss: 0.581745\n",
      "epoch 82; iter: 0; batch classifier loss: 0.468760; batch adversarial loss: 0.581490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.480795; batch adversarial loss: 0.470758\n",
      "epoch 84; iter: 0; batch classifier loss: 0.461674; batch adversarial loss: 0.580668\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378334; batch adversarial loss: 0.517232\n",
      "epoch 86; iter: 0; batch classifier loss: 0.453911; batch adversarial loss: 0.663668\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352315; batch adversarial loss: 0.544043\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365023; batch adversarial loss: 0.517874\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379973; batch adversarial loss: 0.617534\n",
      "epoch 90; iter: 0; batch classifier loss: 0.406746; batch adversarial loss: 0.571523\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387645; batch adversarial loss: 0.618141\n",
      "epoch 92; iter: 0; batch classifier loss: 0.337097; batch adversarial loss: 0.516803\n",
      "epoch 93; iter: 0; batch classifier loss: 0.324348; batch adversarial loss: 0.471784\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424999; batch adversarial loss: 0.544913\n",
      "epoch 95; iter: 0; batch classifier loss: 0.354239; batch adversarial loss: 0.553879\n",
      "epoch 96; iter: 0; batch classifier loss: 0.455789; batch adversarial loss: 0.608869\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404384; batch adversarial loss: 0.544050\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397680; batch adversarial loss: 0.526071\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359500; batch adversarial loss: 0.563052\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382099; batch adversarial loss: 0.489259\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398188; batch adversarial loss: 0.563301\n",
      "epoch 102; iter: 0; batch classifier loss: 0.348968; batch adversarial loss: 0.489645\n",
      "epoch 103; iter: 0; batch classifier loss: 0.425210; batch adversarial loss: 0.590519\n",
      "epoch 104; iter: 0; batch classifier loss: 0.320438; batch adversarial loss: 0.544504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.376290; batch adversarial loss: 0.544216\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409295; batch adversarial loss: 0.553689\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362652; batch adversarial loss: 0.581324\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420569; batch adversarial loss: 0.535325\n",
      "epoch 109; iter: 0; batch classifier loss: 0.433289; batch adversarial loss: 0.554107\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375117; batch adversarial loss: 0.553426\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381355; batch adversarial loss: 0.581245\n",
      "epoch 112; iter: 0; batch classifier loss: 0.463972; batch adversarial loss: 0.626714\n",
      "epoch 113; iter: 0; batch classifier loss: 0.480274; batch adversarial loss: 0.452959\n",
      "epoch 114; iter: 0; batch classifier loss: 0.336255; batch adversarial loss: 0.590679\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348687; batch adversarial loss: 0.553366\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343873; batch adversarial loss: 0.608524\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342772; batch adversarial loss: 0.580865\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382701; batch adversarial loss: 0.525685\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334267; batch adversarial loss: 0.544982\n",
      "epoch 120; iter: 0; batch classifier loss: 0.477613; batch adversarial loss: 0.499228\n",
      "epoch 121; iter: 0; batch classifier loss: 0.399908; batch adversarial loss: 0.526644\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353239; batch adversarial loss: 0.554727\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425486; batch adversarial loss: 0.508141\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407100; batch adversarial loss: 0.600220\n",
      "epoch 125; iter: 0; batch classifier loss: 0.455131; batch adversarial loss: 0.582488\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354224; batch adversarial loss: 0.588964\n",
      "epoch 127; iter: 0; batch classifier loss: 0.460698; batch adversarial loss: 0.598548\n",
      "epoch 128; iter: 0; batch classifier loss: 0.467587; batch adversarial loss: 0.507882\n",
      "epoch 129; iter: 0; batch classifier loss: 0.425562; batch adversarial loss: 0.498732\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348365; batch adversarial loss: 0.534866\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394532; batch adversarial loss: 0.533969\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341732; batch adversarial loss: 0.563482\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371745; batch adversarial loss: 0.434742\n",
      "epoch 134; iter: 0; batch classifier loss: 0.324274; batch adversarial loss: 0.621124\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338680; batch adversarial loss: 0.619688\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385882; batch adversarial loss: 0.572381\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359694; batch adversarial loss: 0.572567\n",
      "epoch 138; iter: 0; batch classifier loss: 0.442193; batch adversarial loss: 0.488958\n",
      "epoch 139; iter: 0; batch classifier loss: 0.275489; batch adversarial loss: 0.609523\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325390; batch adversarial loss: 0.534845\n",
      "epoch 141; iter: 0; batch classifier loss: 0.292450; batch adversarial loss: 0.526120\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405780; batch adversarial loss: 0.608653\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378898; batch adversarial loss: 0.526660\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360239; batch adversarial loss: 0.553360\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375188; batch adversarial loss: 0.552462\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367511; batch adversarial loss: 0.490085\n",
      "epoch 147; iter: 0; batch classifier loss: 0.419581; batch adversarial loss: 0.489925\n",
      "epoch 148; iter: 0; batch classifier loss: 0.317355; batch adversarial loss: 0.527546\n",
      "epoch 149; iter: 0; batch classifier loss: 0.446765; batch adversarial loss: 0.525710\n",
      "epoch 150; iter: 0; batch classifier loss: 0.303859; batch adversarial loss: 0.525703\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376870; batch adversarial loss: 0.570114\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339836; batch adversarial loss: 0.507771\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339390; batch adversarial loss: 0.627184\n",
      "epoch 154; iter: 0; batch classifier loss: 0.371014; batch adversarial loss: 0.519055\n",
      "epoch 155; iter: 0; batch classifier loss: 0.329004; batch adversarial loss: 0.590472\n",
      "epoch 156; iter: 0; batch classifier loss: 0.420010; batch adversarial loss: 0.609335\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349664; batch adversarial loss: 0.498230\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395068; batch adversarial loss: 0.600121\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400702; batch adversarial loss: 0.563271\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356816; batch adversarial loss: 0.581807\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341932; batch adversarial loss: 0.516656\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347393; batch adversarial loss: 0.507788\n",
      "epoch 163; iter: 0; batch classifier loss: 0.370681; batch adversarial loss: 0.654591\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402594; batch adversarial loss: 0.517444\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372264; batch adversarial loss: 0.526130\n",
      "epoch 166; iter: 0; batch classifier loss: 0.280105; batch adversarial loss: 0.580521\n",
      "epoch 167; iter: 0; batch classifier loss: 0.396191; batch adversarial loss: 0.498998\n",
      "epoch 168; iter: 0; batch classifier loss: 0.440147; batch adversarial loss: 0.524002\n",
      "epoch 169; iter: 0; batch classifier loss: 0.421736; batch adversarial loss: 0.599084\n",
      "epoch 170; iter: 0; batch classifier loss: 0.401154; batch adversarial loss: 0.517192\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362517; batch adversarial loss: 0.570814\n",
      "epoch 172; iter: 0; batch classifier loss: 0.324481; batch adversarial loss: 0.480269\n",
      "epoch 173; iter: 0; batch classifier loss: 0.428627; batch adversarial loss: 0.572339\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376575; batch adversarial loss: 0.489058\n",
      "epoch 175; iter: 0; batch classifier loss: 0.412396; batch adversarial loss: 0.617695\n",
      "epoch 176; iter: 0; batch classifier loss: 0.303544; batch adversarial loss: 0.543883\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375522; batch adversarial loss: 0.544492\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387262; batch adversarial loss: 0.608615\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318427; batch adversarial loss: 0.516640\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389767; batch adversarial loss: 0.608948\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339486; batch adversarial loss: 0.552878\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367183; batch adversarial loss: 0.572606\n",
      "epoch 183; iter: 0; batch classifier loss: 0.492871; batch adversarial loss: 0.562873\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329269; batch adversarial loss: 0.543656\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328481; batch adversarial loss: 0.564680\n",
      "epoch 186; iter: 0; batch classifier loss: 0.409007; batch adversarial loss: 0.554197\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334511; batch adversarial loss: 0.553246\n",
      "epoch 188; iter: 0; batch classifier loss: 0.390496; batch adversarial loss: 0.581978\n",
      "epoch 189; iter: 0; batch classifier loss: 0.283560; batch adversarial loss: 0.496650\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327676; batch adversarial loss: 0.490837\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386582; batch adversarial loss: 0.581712\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308754; batch adversarial loss: 0.563654\n",
      "epoch 193; iter: 0; batch classifier loss: 0.451843; batch adversarial loss: 0.516316\n",
      "epoch 194; iter: 0; batch classifier loss: 0.310795; batch adversarial loss: 0.552138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.425978; batch adversarial loss: 0.563860\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306052; batch adversarial loss: 0.554930\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312598; batch adversarial loss: 0.599948\n",
      "epoch 198; iter: 0; batch classifier loss: 0.419609; batch adversarial loss: 0.563841\n",
      "epoch 199; iter: 0; batch classifier loss: 0.474443; batch adversarial loss: 0.599183\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664716; batch adversarial loss: 0.705384\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627659; batch adversarial loss: 0.671300\n",
      "epoch 2; iter: 0; batch classifier loss: 0.526228; batch adversarial loss: 0.657852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.560287; batch adversarial loss: 0.653372\n",
      "epoch 4; iter: 0; batch classifier loss: 0.636861; batch adversarial loss: 0.607640\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633721; batch adversarial loss: 0.615969\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554883; batch adversarial loss: 0.597324\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485589; batch adversarial loss: 0.598517\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519037; batch adversarial loss: 0.611950\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518177; batch adversarial loss: 0.597890\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481688; batch adversarial loss: 0.562216\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580140; batch adversarial loss: 0.554700\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542660; batch adversarial loss: 0.588053\n",
      "epoch 13; iter: 0; batch classifier loss: 0.470872; batch adversarial loss: 0.540860\n",
      "epoch 14; iter: 0; batch classifier loss: 0.568717; batch adversarial loss: 0.563781\n",
      "epoch 15; iter: 0; batch classifier loss: 0.479631; batch adversarial loss: 0.619448\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506715; batch adversarial loss: 0.609385\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466240; batch adversarial loss: 0.539042\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536312; batch adversarial loss: 0.586580\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512830; batch adversarial loss: 0.505764\n",
      "epoch 20; iter: 0; batch classifier loss: 0.452989; batch adversarial loss: 0.549971\n",
      "epoch 21; iter: 0; batch classifier loss: 0.366900; batch adversarial loss: 0.547464\n",
      "epoch 22; iter: 0; batch classifier loss: 0.535217; batch adversarial loss: 0.514046\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465619; batch adversarial loss: 0.532018\n",
      "epoch 24; iter: 0; batch classifier loss: 0.577705; batch adversarial loss: 0.551840\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490714; batch adversarial loss: 0.527685\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495139; batch adversarial loss: 0.514629\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507210; batch adversarial loss: 0.564191\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429821; batch adversarial loss: 0.574004\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428905; batch adversarial loss: 0.588214\n",
      "epoch 30; iter: 0; batch classifier loss: 0.460159; batch adversarial loss: 0.536765\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475667; batch adversarial loss: 0.639834\n",
      "epoch 32; iter: 0; batch classifier loss: 0.463625; batch adversarial loss: 0.547763\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444670; batch adversarial loss: 0.569779\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453650; batch adversarial loss: 0.547736\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444362; batch adversarial loss: 0.529581\n",
      "epoch 36; iter: 0; batch classifier loss: 0.372374; batch adversarial loss: 0.510490\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438816; batch adversarial loss: 0.484917\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455686; batch adversarial loss: 0.579186\n",
      "epoch 39; iter: 0; batch classifier loss: 0.488460; batch adversarial loss: 0.563133\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404894; batch adversarial loss: 0.606564\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414713; batch adversarial loss: 0.519053\n",
      "epoch 42; iter: 0; batch classifier loss: 0.341323; batch adversarial loss: 0.553823\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486016; batch adversarial loss: 0.527724\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485691; batch adversarial loss: 0.579967\n",
      "epoch 45; iter: 0; batch classifier loss: 0.468279; batch adversarial loss: 0.518850\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471249; batch adversarial loss: 0.579847\n",
      "epoch 47; iter: 0; batch classifier loss: 0.495309; batch adversarial loss: 0.518395\n",
      "epoch 48; iter: 0; batch classifier loss: 0.497109; batch adversarial loss: 0.570877\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406764; batch adversarial loss: 0.500725\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388521; batch adversarial loss: 0.500467\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448706; batch adversarial loss: 0.571408\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405548; batch adversarial loss: 0.561978\n",
      "epoch 53; iter: 0; batch classifier loss: 0.489004; batch adversarial loss: 0.580411\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450359; batch adversarial loss: 0.544832\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396131; batch adversarial loss: 0.562327\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446213; batch adversarial loss: 0.553593\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429804; batch adversarial loss: 0.491382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442865; batch adversarial loss: 0.580268\n",
      "epoch 59; iter: 0; batch classifier loss: 0.386081; batch adversarial loss: 0.580083\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414035; batch adversarial loss: 0.562265\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404961; batch adversarial loss: 0.580273\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439089; batch adversarial loss: 0.526834\n",
      "epoch 63; iter: 0; batch classifier loss: 0.373384; batch adversarial loss: 0.571373\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440913; batch adversarial loss: 0.544836\n",
      "epoch 65; iter: 0; batch classifier loss: 0.491171; batch adversarial loss: 0.607322\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421437; batch adversarial loss: 0.607358\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460576; batch adversarial loss: 0.526927\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412845; batch adversarial loss: 0.553287\n",
      "epoch 69; iter: 0; batch classifier loss: 0.339388; batch adversarial loss: 0.624712\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410362; batch adversarial loss: 0.535278\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438255; batch adversarial loss: 0.499862\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403752; batch adversarial loss: 0.616144\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409710; batch adversarial loss: 0.535653\n",
      "epoch 74; iter: 0; batch classifier loss: 0.375441; batch adversarial loss: 0.545190\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367992; batch adversarial loss: 0.544665\n",
      "epoch 76; iter: 0; batch classifier loss: 0.336642; batch adversarial loss: 0.508991\n",
      "epoch 77; iter: 0; batch classifier loss: 0.370072; batch adversarial loss: 0.589467\n",
      "epoch 78; iter: 0; batch classifier loss: 0.443281; batch adversarial loss: 0.598284\n",
      "epoch 79; iter: 0; batch classifier loss: 0.312674; batch adversarial loss: 0.553332\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406569; batch adversarial loss: 0.589069\n",
      "epoch 81; iter: 0; batch classifier loss: 0.457021; batch adversarial loss: 0.535623\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381854; batch adversarial loss: 0.536148\n",
      "epoch 83; iter: 0; batch classifier loss: 0.390653; batch adversarial loss: 0.563218\n",
      "epoch 84; iter: 0; batch classifier loss: 0.432677; batch adversarial loss: 0.526714\n",
      "epoch 85; iter: 0; batch classifier loss: 0.348459; batch adversarial loss: 0.616180\n",
      "epoch 86; iter: 0; batch classifier loss: 0.439415; batch adversarial loss: 0.544374\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398086; batch adversarial loss: 0.562948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375861; batch adversarial loss: 0.535769\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370092; batch adversarial loss: 0.535011\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391282; batch adversarial loss: 0.562211\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385087; batch adversarial loss: 0.509150\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372838; batch adversarial loss: 0.598131\n",
      "epoch 93; iter: 0; batch classifier loss: 0.373623; batch adversarial loss: 0.580594\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407224; batch adversarial loss: 0.509087\n",
      "epoch 95; iter: 0; batch classifier loss: 0.479141; batch adversarial loss: 0.535917\n",
      "epoch 96; iter: 0; batch classifier loss: 0.303650; batch adversarial loss: 0.598355\n",
      "epoch 97; iter: 0; batch classifier loss: 0.311722; batch adversarial loss: 0.642383\n",
      "epoch 98; iter: 0; batch classifier loss: 0.326619; batch adversarial loss: 0.518123\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401680; batch adversarial loss: 0.526133\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400960; batch adversarial loss: 0.571523\n",
      "epoch 101; iter: 0; batch classifier loss: 0.337045; batch adversarial loss: 0.518152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.328331; batch adversarial loss: 0.571470\n",
      "epoch 103; iter: 0; batch classifier loss: 0.456579; batch adversarial loss: 0.562313\n",
      "epoch 104; iter: 0; batch classifier loss: 0.455589; batch adversarial loss: 0.544565\n",
      "epoch 105; iter: 0; batch classifier loss: 0.338912; batch adversarial loss: 0.571500\n",
      "epoch 106; iter: 0; batch classifier loss: 0.447575; batch adversarial loss: 0.536358\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358987; batch adversarial loss: 0.482887\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388714; batch adversarial loss: 0.554318\n",
      "epoch 109; iter: 0; batch classifier loss: 0.439246; batch adversarial loss: 0.501198\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411727; batch adversarial loss: 0.526757\n",
      "epoch 111; iter: 0; batch classifier loss: 0.337475; batch adversarial loss: 0.606811\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383127; batch adversarial loss: 0.598077\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375900; batch adversarial loss: 0.472580\n",
      "epoch 114; iter: 0; batch classifier loss: 0.370211; batch adversarial loss: 0.580202\n",
      "epoch 115; iter: 0; batch classifier loss: 0.330855; batch adversarial loss: 0.509097\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413086; batch adversarial loss: 0.536879\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402788; batch adversarial loss: 0.482756\n",
      "epoch 118; iter: 0; batch classifier loss: 0.301143; batch adversarial loss: 0.544803\n",
      "epoch 119; iter: 0; batch classifier loss: 0.320171; batch adversarial loss: 0.518355\n",
      "epoch 120; iter: 0; batch classifier loss: 0.469684; batch adversarial loss: 0.482484\n",
      "epoch 121; iter: 0; batch classifier loss: 0.426810; batch adversarial loss: 0.534781\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377175; batch adversarial loss: 0.607376\n",
      "epoch 123; iter: 0; batch classifier loss: 0.304007; batch adversarial loss: 0.526751\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376616; batch adversarial loss: 0.545004\n",
      "epoch 125; iter: 0; batch classifier loss: 0.336836; batch adversarial loss: 0.588874\n",
      "epoch 126; iter: 0; batch classifier loss: 0.398545; batch adversarial loss: 0.499582\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377220; batch adversarial loss: 0.562392\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332026; batch adversarial loss: 0.545384\n",
      "epoch 129; iter: 0; batch classifier loss: 0.464334; batch adversarial loss: 0.545691\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359630; batch adversarial loss: 0.482662\n",
      "epoch 131; iter: 0; batch classifier loss: 0.323745; batch adversarial loss: 0.552755\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395052; batch adversarial loss: 0.598287\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397505; batch adversarial loss: 0.596793\n",
      "epoch 134; iter: 0; batch classifier loss: 0.304987; batch adversarial loss: 0.544463\n",
      "epoch 135; iter: 0; batch classifier loss: 0.416957; batch adversarial loss: 0.553824\n",
      "epoch 136; iter: 0; batch classifier loss: 0.309632; batch adversarial loss: 0.517906\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383121; batch adversarial loss: 0.544379\n",
      "epoch 138; iter: 0; batch classifier loss: 0.431406; batch adversarial loss: 0.553100\n",
      "epoch 139; iter: 0; batch classifier loss: 0.370262; batch adversarial loss: 0.544665\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346454; batch adversarial loss: 0.615715\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350850; batch adversarial loss: 0.536303\n",
      "epoch 142; iter: 0; batch classifier loss: 0.426298; batch adversarial loss: 0.544666\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385083; batch adversarial loss: 0.607312\n",
      "epoch 144; iter: 0; batch classifier loss: 0.333322; batch adversarial loss: 0.580459\n",
      "epoch 145; iter: 0; batch classifier loss: 0.354384; batch adversarial loss: 0.517124\n",
      "epoch 146; iter: 0; batch classifier loss: 0.338552; batch adversarial loss: 0.580387\n",
      "epoch 147; iter: 0; batch classifier loss: 0.333826; batch adversarial loss: 0.481362\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335732; batch adversarial loss: 0.455436\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384488; batch adversarial loss: 0.499826\n",
      "epoch 150; iter: 0; batch classifier loss: 0.412608; batch adversarial loss: 0.508640\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356369; batch adversarial loss: 0.571454\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377212; batch adversarial loss: 0.553922\n",
      "epoch 153; iter: 0; batch classifier loss: 0.403512; batch adversarial loss: 0.588651\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335987; batch adversarial loss: 0.509361\n",
      "epoch 155; iter: 0; batch classifier loss: 0.331956; batch adversarial loss: 0.509093\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357471; batch adversarial loss: 0.508926\n",
      "epoch 157; iter: 0; batch classifier loss: 0.330744; batch adversarial loss: 0.543840\n",
      "epoch 158; iter: 0; batch classifier loss: 0.418413; batch adversarial loss: 0.517777\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371286; batch adversarial loss: 0.580071\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377928; batch adversarial loss: 0.482443\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399448; batch adversarial loss: 0.544932\n",
      "epoch 162; iter: 0; batch classifier loss: 0.324916; batch adversarial loss: 0.527269\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374837; batch adversarial loss: 0.571694\n",
      "epoch 164; iter: 0; batch classifier loss: 0.364621; batch adversarial loss: 0.553685\n",
      "epoch 165; iter: 0; batch classifier loss: 0.306466; batch adversarial loss: 0.527366\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354158; batch adversarial loss: 0.499425\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369656; batch adversarial loss: 0.606684\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320855; batch adversarial loss: 0.473044\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349773; batch adversarial loss: 0.552561\n",
      "epoch 170; iter: 0; batch classifier loss: 0.388643; batch adversarial loss: 0.544824\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389219; batch adversarial loss: 0.563139\n",
      "epoch 172; iter: 0; batch classifier loss: 0.339480; batch adversarial loss: 0.508667\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330141; batch adversarial loss: 0.482384\n",
      "epoch 174; iter: 0; batch classifier loss: 0.422652; batch adversarial loss: 0.597035\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351278; batch adversarial loss: 0.571000\n",
      "epoch 176; iter: 0; batch classifier loss: 0.434297; batch adversarial loss: 0.553800\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303154; batch adversarial loss: 0.490434\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345105; batch adversarial loss: 0.606973\n",
      "epoch 179; iter: 0; batch classifier loss: 0.401870; batch adversarial loss: 0.499994\n",
      "epoch 180; iter: 0; batch classifier loss: 0.383626; batch adversarial loss: 0.606075\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343670; batch adversarial loss: 0.525962\n",
      "epoch 182; iter: 0; batch classifier loss: 0.350412; batch adversarial loss: 0.536004\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342037; batch adversarial loss: 0.535700\n",
      "epoch 184; iter: 0; batch classifier loss: 0.405523; batch adversarial loss: 0.590641\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303478; batch adversarial loss: 0.597876\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343986; batch adversarial loss: 0.581334\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327162; batch adversarial loss: 0.525636\n",
      "epoch 188; iter: 0; batch classifier loss: 0.349251; batch adversarial loss: 0.499879\n",
      "epoch 189; iter: 0; batch classifier loss: 0.442743; batch adversarial loss: 0.562942\n",
      "epoch 190; iter: 0; batch classifier loss: 0.286404; batch adversarial loss: 0.562084\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346375; batch adversarial loss: 0.536901\n",
      "epoch 192; iter: 0; batch classifier loss: 0.369745; batch adversarial loss: 0.562835\n",
      "epoch 193; iter: 0; batch classifier loss: 0.292157; batch adversarial loss: 0.535746\n",
      "epoch 194; iter: 0; batch classifier loss: 0.346918; batch adversarial loss: 0.639968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327270; batch adversarial loss: 0.563563\n",
      "epoch 196; iter: 0; batch classifier loss: 0.318568; batch adversarial loss: 0.579542\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396891; batch adversarial loss: 0.552438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.324316; batch adversarial loss: 0.545164\n",
      "epoch 199; iter: 0; batch classifier loss: 0.307142; batch adversarial loss: 0.544976\n",
      "epoch 0; iter: 0; batch classifier loss: 0.799067; batch adversarial loss: 0.760482\n",
      "epoch 1; iter: 0; batch classifier loss: 0.742047; batch adversarial loss: 0.739884\n",
      "epoch 2; iter: 0; batch classifier loss: 0.737548; batch adversarial loss: 0.686433\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575896; batch adversarial loss: 0.653596\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590924; batch adversarial loss: 0.645058\n",
      "epoch 5; iter: 0; batch classifier loss: 0.584896; batch adversarial loss: 0.595774\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527413; batch adversarial loss: 0.585322\n",
      "epoch 7; iter: 0; batch classifier loss: 0.484365; batch adversarial loss: 0.591041\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542695; batch adversarial loss: 0.606322\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494039; batch adversarial loss: 0.579149\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505688; batch adversarial loss: 0.533757\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593445; batch adversarial loss: 0.589880\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533736; batch adversarial loss: 0.541199\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534288; batch adversarial loss: 0.563867\n",
      "epoch 14; iter: 0; batch classifier loss: 0.494127; batch adversarial loss: 0.541495\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552313; batch adversarial loss: 0.536293\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501126; batch adversarial loss: 0.586468\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498481; batch adversarial loss: 0.494021\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518862; batch adversarial loss: 0.546082\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444459; batch adversarial loss: 0.605178\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456268; batch adversarial loss: 0.556377\n",
      "epoch 21; iter: 0; batch classifier loss: 0.437266; batch adversarial loss: 0.591294\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573267; batch adversarial loss: 0.574297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478435; batch adversarial loss: 0.499170\n",
      "epoch 24; iter: 0; batch classifier loss: 0.520377; batch adversarial loss: 0.515390\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473929; batch adversarial loss: 0.556325\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543094; batch adversarial loss: 0.502387\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472890; batch adversarial loss: 0.546935\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538808; batch adversarial loss: 0.509446\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445280; batch adversarial loss: 0.516241\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454796; batch adversarial loss: 0.500210\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505120; batch adversarial loss: 0.571553\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410196; batch adversarial loss: 0.563872\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429962; batch adversarial loss: 0.550463\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483503; batch adversarial loss: 0.494617\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438145; batch adversarial loss: 0.524597\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478311; batch adversarial loss: 0.521308\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446842; batch adversarial loss: 0.606743\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463598; batch adversarial loss: 0.554399\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404479; batch adversarial loss: 0.528332\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480014; batch adversarial loss: 0.510427\n",
      "epoch 41; iter: 0; batch classifier loss: 0.423348; batch adversarial loss: 0.528092\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436987; batch adversarial loss: 0.562610\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407251; batch adversarial loss: 0.535859\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420891; batch adversarial loss: 0.571458\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460670; batch adversarial loss: 0.509336\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445320; batch adversarial loss: 0.580175\n",
      "epoch 47; iter: 0; batch classifier loss: 0.351762; batch adversarial loss: 0.562414\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444537; batch adversarial loss: 0.571643\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462607; batch adversarial loss: 0.553447\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390531; batch adversarial loss: 0.535426\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405369; batch adversarial loss: 0.490417\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423300; batch adversarial loss: 0.552209\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446161; batch adversarial loss: 0.598703\n",
      "epoch 54; iter: 0; batch classifier loss: 0.380093; batch adversarial loss: 0.506804\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388768; batch adversarial loss: 0.562559\n",
      "epoch 56; iter: 0; batch classifier loss: 0.462652; batch adversarial loss: 0.554419\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379546; batch adversarial loss: 0.581838\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378458; batch adversarial loss: 0.508674\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382638; batch adversarial loss: 0.590580\n",
      "epoch 60; iter: 0; batch classifier loss: 0.510816; batch adversarial loss: 0.489356\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407603; batch adversarial loss: 0.607411\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393982; batch adversarial loss: 0.462496\n",
      "epoch 63; iter: 0; batch classifier loss: 0.393457; batch adversarial loss: 0.579828\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380386; batch adversarial loss: 0.552150\n",
      "epoch 65; iter: 0; batch classifier loss: 0.393439; batch adversarial loss: 0.581440\n",
      "epoch 66; iter: 0; batch classifier loss: 0.349167; batch adversarial loss: 0.561798\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366277; batch adversarial loss: 0.528201\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412759; batch adversarial loss: 0.581457\n",
      "epoch 69; iter: 0; batch classifier loss: 0.349100; batch adversarial loss: 0.545602\n",
      "epoch 70; iter: 0; batch classifier loss: 0.394344; batch adversarial loss: 0.542719\n",
      "epoch 71; iter: 0; batch classifier loss: 0.350286; batch adversarial loss: 0.510073\n",
      "epoch 72; iter: 0; batch classifier loss: 0.452821; batch adversarial loss: 0.481761\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415368; batch adversarial loss: 0.501485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393406; batch adversarial loss: 0.429205\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430927; batch adversarial loss: 0.544460\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395323; batch adversarial loss: 0.580804\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425300; batch adversarial loss: 0.508810\n",
      "epoch 78; iter: 0; batch classifier loss: 0.338848; batch adversarial loss: 0.572242\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366548; batch adversarial loss: 0.590512\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360549; batch adversarial loss: 0.598203\n",
      "epoch 81; iter: 0; batch classifier loss: 0.463978; batch adversarial loss: 0.587984\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380559; batch adversarial loss: 0.562997\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371310; batch adversarial loss: 0.597243\n",
      "epoch 84; iter: 0; batch classifier loss: 0.329349; batch adversarial loss: 0.553589\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407371; batch adversarial loss: 0.500274\n",
      "epoch 86; iter: 0; batch classifier loss: 0.429705; batch adversarial loss: 0.528200\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356738; batch adversarial loss: 0.597572\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400023; batch adversarial loss: 0.527520\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422260; batch adversarial loss: 0.561792\n",
      "epoch 90; iter: 0; batch classifier loss: 0.360752; batch adversarial loss: 0.570298\n",
      "epoch 91; iter: 0; batch classifier loss: 0.336598; batch adversarial loss: 0.591314\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428361; batch adversarial loss: 0.544370\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389548; batch adversarial loss: 0.563182\n",
      "epoch 94; iter: 0; batch classifier loss: 0.437942; batch adversarial loss: 0.644851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.390533; batch adversarial loss: 0.472034\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384782; batch adversarial loss: 0.589896\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386808; batch adversarial loss: 0.526906\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391730; batch adversarial loss: 0.606185\n",
      "epoch 99; iter: 0; batch classifier loss: 0.334543; batch adversarial loss: 0.498289\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365799; batch adversarial loss: 0.563264\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403145; batch adversarial loss: 0.571840\n",
      "epoch 102; iter: 0; batch classifier loss: 0.395885; batch adversarial loss: 0.542559\n",
      "epoch 103; iter: 0; batch classifier loss: 0.370417; batch adversarial loss: 0.537449\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368352; batch adversarial loss: 0.571979\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359877; batch adversarial loss: 0.553917\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398511; batch adversarial loss: 0.552851\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406460; batch adversarial loss: 0.525779\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355658; batch adversarial loss: 0.489815\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384942; batch adversarial loss: 0.571391\n",
      "epoch 110; iter: 0; batch classifier loss: 0.376509; batch adversarial loss: 0.490587\n",
      "epoch 111; iter: 0; batch classifier loss: 0.519739; batch adversarial loss: 0.563463\n",
      "epoch 112; iter: 0; batch classifier loss: 0.340829; batch adversarial loss: 0.588975\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382812; batch adversarial loss: 0.542266\n",
      "epoch 114; iter: 0; batch classifier loss: 0.467556; batch adversarial loss: 0.553119\n",
      "epoch 115; iter: 0; batch classifier loss: 0.333662; batch adversarial loss: 0.580637\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372422; batch adversarial loss: 0.553296\n",
      "epoch 117; iter: 0; batch classifier loss: 0.343391; batch adversarial loss: 0.579601\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402504; batch adversarial loss: 0.588247\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374684; batch adversarial loss: 0.554623\n",
      "epoch 120; iter: 0; batch classifier loss: 0.402008; batch adversarial loss: 0.598681\n",
      "epoch 121; iter: 0; batch classifier loss: 0.354845; batch adversarial loss: 0.599909\n",
      "epoch 122; iter: 0; batch classifier loss: 0.295752; batch adversarial loss: 0.527314\n",
      "epoch 123; iter: 0; batch classifier loss: 0.374245; batch adversarial loss: 0.516859\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403098; batch adversarial loss: 0.526517\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334056; batch adversarial loss: 0.571501\n",
      "epoch 126; iter: 0; batch classifier loss: 0.430026; batch adversarial loss: 0.537030\n",
      "epoch 127; iter: 0; batch classifier loss: 0.400807; batch adversarial loss: 0.551718\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403883; batch adversarial loss: 0.499101\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394336; batch adversarial loss: 0.572915\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380116; batch adversarial loss: 0.527155\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348660; batch adversarial loss: 0.561942\n",
      "epoch 132; iter: 0; batch classifier loss: 0.309125; batch adversarial loss: 0.600408\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372357; batch adversarial loss: 0.555609\n",
      "epoch 134; iter: 0; batch classifier loss: 0.451531; batch adversarial loss: 0.570745\n",
      "epoch 135; iter: 0; batch classifier loss: 0.383842; batch adversarial loss: 0.553659\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385579; batch adversarial loss: 0.652116\n",
      "epoch 137; iter: 0; batch classifier loss: 0.388374; batch adversarial loss: 0.534915\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411616; batch adversarial loss: 0.571630\n",
      "epoch 139; iter: 0; batch classifier loss: 0.307621; batch adversarial loss: 0.607189\n",
      "epoch 140; iter: 0; batch classifier loss: 0.301131; batch adversarial loss: 0.508186\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332187; batch adversarial loss: 0.589868\n",
      "epoch 142; iter: 0; batch classifier loss: 0.311029; batch adversarial loss: 0.598724\n",
      "epoch 143; iter: 0; batch classifier loss: 0.257059; batch adversarial loss: 0.588787\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312309; batch adversarial loss: 0.571313\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348740; batch adversarial loss: 0.543051\n",
      "epoch 146; iter: 0; batch classifier loss: 0.459909; batch adversarial loss: 0.589506\n",
      "epoch 147; iter: 0; batch classifier loss: 0.486805; batch adversarial loss: 0.520190\n",
      "epoch 148; iter: 0; batch classifier loss: 0.430490; batch adversarial loss: 0.590476\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343778; batch adversarial loss: 0.578916\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373965; batch adversarial loss: 0.471662\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325383; batch adversarial loss: 0.563111\n",
      "epoch 152; iter: 0; batch classifier loss: 0.310301; batch adversarial loss: 0.534663\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358058; batch adversarial loss: 0.518366\n",
      "epoch 154; iter: 0; batch classifier loss: 0.327866; batch adversarial loss: 0.535373\n",
      "epoch 155; iter: 0; batch classifier loss: 0.460398; batch adversarial loss: 0.527921\n",
      "epoch 156; iter: 0; batch classifier loss: 0.331224; batch adversarial loss: 0.569588\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376442; batch adversarial loss: 0.625451\n",
      "epoch 158; iter: 0; batch classifier loss: 0.264736; batch adversarial loss: 0.625388\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342890; batch adversarial loss: 0.578655\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382645; batch adversarial loss: 0.526601\n",
      "epoch 161; iter: 0; batch classifier loss: 0.284622; batch adversarial loss: 0.625824\n",
      "epoch 162; iter: 0; batch classifier loss: 0.459874; batch adversarial loss: 0.560724\n",
      "epoch 163; iter: 0; batch classifier loss: 0.260635; batch adversarial loss: 0.535448\n",
      "epoch 164; iter: 0; batch classifier loss: 0.401956; batch adversarial loss: 0.517523\n",
      "epoch 165; iter: 0; batch classifier loss: 0.454024; batch adversarial loss: 0.482526\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322433; batch adversarial loss: 0.590657\n",
      "epoch 167; iter: 0; batch classifier loss: 0.315882; batch adversarial loss: 0.554604\n",
      "epoch 168; iter: 0; batch classifier loss: 0.393331; batch adversarial loss: 0.525957\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356896; batch adversarial loss: 0.525870\n",
      "epoch 170; iter: 0; batch classifier loss: 0.384984; batch adversarial loss: 0.580931\n",
      "epoch 171; iter: 0; batch classifier loss: 0.441084; batch adversarial loss: 0.580652\n",
      "epoch 172; iter: 0; batch classifier loss: 0.338431; batch adversarial loss: 0.573547\n",
      "epoch 173; iter: 0; batch classifier loss: 0.443549; batch adversarial loss: 0.554682\n",
      "epoch 174; iter: 0; batch classifier loss: 0.382205; batch adversarial loss: 0.544601\n",
      "epoch 175; iter: 0; batch classifier loss: 0.301511; batch adversarial loss: 0.536320\n",
      "epoch 176; iter: 0; batch classifier loss: 0.402409; batch adversarial loss: 0.589689\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347166; batch adversarial loss: 0.570402\n",
      "epoch 178; iter: 0; batch classifier loss: 0.397250; batch adversarial loss: 0.625542\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372043; batch adversarial loss: 0.508880\n",
      "epoch 180; iter: 0; batch classifier loss: 0.381860; batch adversarial loss: 0.544883\n",
      "epoch 181; iter: 0; batch classifier loss: 0.317986; batch adversarial loss: 0.491235\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370002; batch adversarial loss: 0.492034\n",
      "epoch 183; iter: 0; batch classifier loss: 0.417241; batch adversarial loss: 0.653842\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313596; batch adversarial loss: 0.526821\n",
      "epoch 185; iter: 0; batch classifier loss: 0.241292; batch adversarial loss: 0.553431\n",
      "epoch 186; iter: 0; batch classifier loss: 0.311767; batch adversarial loss: 0.589009\n",
      "epoch 187; iter: 0; batch classifier loss: 0.408875; batch adversarial loss: 0.563417\n",
      "epoch 188; iter: 0; batch classifier loss: 0.317607; batch adversarial loss: 0.489581\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311466; batch adversarial loss: 0.590022\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333556; batch adversarial loss: 0.624252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.334905; batch adversarial loss: 0.543129\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347365; batch adversarial loss: 0.500962\n",
      "epoch 193; iter: 0; batch classifier loss: 0.285974; batch adversarial loss: 0.596761\n",
      "epoch 194; iter: 0; batch classifier loss: 0.296446; batch adversarial loss: 0.518543\n",
      "epoch 195; iter: 0; batch classifier loss: 0.333718; batch adversarial loss: 0.581437\n",
      "epoch 196; iter: 0; batch classifier loss: 0.410310; batch adversarial loss: 0.516553\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357871; batch adversarial loss: 0.571977\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370047; batch adversarial loss: 0.614832\n",
      "epoch 199; iter: 0; batch classifier loss: 0.301851; batch adversarial loss: 0.543820\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735985; batch adversarial loss: 1.041090\n",
      "epoch 1; iter: 0; batch classifier loss: 0.831900; batch adversarial loss: 1.204918\n",
      "epoch 2; iter: 0; batch classifier loss: 0.991753; batch adversarial loss: 1.207248\n",
      "epoch 3; iter: 0; batch classifier loss: 1.157801; batch adversarial loss: 1.113886\n",
      "epoch 4; iter: 0; batch classifier loss: 1.167346; batch adversarial loss: 1.027984\n",
      "epoch 5; iter: 0; batch classifier loss: 1.324032; batch adversarial loss: 0.982089\n",
      "epoch 6; iter: 0; batch classifier loss: 1.080421; batch adversarial loss: 0.888651\n",
      "epoch 7; iter: 0; batch classifier loss: 1.021080; batch adversarial loss: 0.783108\n",
      "epoch 8; iter: 0; batch classifier loss: 0.782022; batch adversarial loss: 0.707092\n",
      "epoch 9; iter: 0; batch classifier loss: 0.858531; batch adversarial loss: 0.727446\n",
      "epoch 10; iter: 0; batch classifier loss: 0.681769; batch adversarial loss: 0.650371\n",
      "epoch 11; iter: 0; batch classifier loss: 0.672074; batch adversarial loss: 0.609634\n",
      "epoch 12; iter: 0; batch classifier loss: 0.606168; batch adversarial loss: 0.584233\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575155; batch adversarial loss: 0.576126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511970; batch adversarial loss: 0.605829\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542638; batch adversarial loss: 0.541172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493222; batch adversarial loss: 0.603674\n",
      "epoch 17; iter: 0; batch classifier loss: 0.623076; batch adversarial loss: 0.569202\n",
      "epoch 18; iter: 0; batch classifier loss: 0.575623; batch adversarial loss: 0.532462\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534682; batch adversarial loss: 0.538555\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496133; batch adversarial loss: 0.609404\n",
      "epoch 21; iter: 0; batch classifier loss: 0.552289; batch adversarial loss: 0.563134\n",
      "epoch 22; iter: 0; batch classifier loss: 0.591371; batch adversarial loss: 0.641943\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467763; batch adversarial loss: 0.551430\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503869; batch adversarial loss: 0.534896\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526553; batch adversarial loss: 0.568055\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461056; batch adversarial loss: 0.552451\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469651; batch adversarial loss: 0.604997\n",
      "epoch 28; iter: 0; batch classifier loss: 0.576023; batch adversarial loss: 0.565980\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504236; batch adversarial loss: 0.539456\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481917; batch adversarial loss: 0.542226\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466872; batch adversarial loss: 0.630888\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485651; batch adversarial loss: 0.593619\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465162; batch adversarial loss: 0.584504\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470285; batch adversarial loss: 0.556033\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488854; batch adversarial loss: 0.523317\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424922; batch adversarial loss: 0.518921\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483232; batch adversarial loss: 0.533834\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486047; batch adversarial loss: 0.527113\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501390; batch adversarial loss: 0.576220\n",
      "epoch 40; iter: 0; batch classifier loss: 0.438509; batch adversarial loss: 0.578710\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450661; batch adversarial loss: 0.515313\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409493; batch adversarial loss: 0.597792\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401836; batch adversarial loss: 0.485001\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477331; batch adversarial loss: 0.585651\n",
      "epoch 45; iter: 0; batch classifier loss: 0.447505; batch adversarial loss: 0.565913\n",
      "epoch 46; iter: 0; batch classifier loss: 0.510648; batch adversarial loss: 0.443762\n",
      "epoch 47; iter: 0; batch classifier loss: 0.419051; batch adversarial loss: 0.517301\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424866; batch adversarial loss: 0.517685\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476208; batch adversarial loss: 0.551763\n",
      "epoch 50; iter: 0; batch classifier loss: 0.482844; batch adversarial loss: 0.487071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.458741; batch adversarial loss: 0.541268\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475413; batch adversarial loss: 0.572299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.469159; batch adversarial loss: 0.561441\n",
      "epoch 54; iter: 0; batch classifier loss: 0.471785; batch adversarial loss: 0.531446\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447375; batch adversarial loss: 0.542125\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456082; batch adversarial loss: 0.539775\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426439; batch adversarial loss: 0.552205\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445909; batch adversarial loss: 0.533906\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421323; batch adversarial loss: 0.554845\n",
      "epoch 60; iter: 0; batch classifier loss: 0.502183; batch adversarial loss: 0.631019\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439447; batch adversarial loss: 0.506684\n",
      "epoch 62; iter: 0; batch classifier loss: 0.370482; batch adversarial loss: 0.546267\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441395; batch adversarial loss: 0.538484\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425777; batch adversarial loss: 0.530197\n",
      "epoch 65; iter: 0; batch classifier loss: 0.326907; batch adversarial loss: 0.514658\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437659; batch adversarial loss: 0.583682\n",
      "epoch 67; iter: 0; batch classifier loss: 0.461939; batch adversarial loss: 0.646132\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413898; batch adversarial loss: 0.517043\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386043; batch adversarial loss: 0.596869\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417166; batch adversarial loss: 0.499078\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395931; batch adversarial loss: 0.458276\n",
      "epoch 72; iter: 0; batch classifier loss: 0.420360; batch adversarial loss: 0.610473\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380029; batch adversarial loss: 0.595589\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432956; batch adversarial loss: 0.563264\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388220; batch adversarial loss: 0.581551\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388426; batch adversarial loss: 0.561071\n",
      "epoch 77; iter: 0; batch classifier loss: 0.330966; batch adversarial loss: 0.499434\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369308; batch adversarial loss: 0.570189\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411708; batch adversarial loss: 0.482661\n",
      "epoch 80; iter: 0; batch classifier loss: 0.461194; batch adversarial loss: 0.526181\n",
      "epoch 81; iter: 0; batch classifier loss: 0.328188; batch adversarial loss: 0.578397\n",
      "epoch 82; iter: 0; batch classifier loss: 0.328781; batch adversarial loss: 0.589111\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387104; batch adversarial loss: 0.579254\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404548; batch adversarial loss: 0.527698\n",
      "epoch 85; iter: 0; batch classifier loss: 0.450647; batch adversarial loss: 0.571276\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373070; batch adversarial loss: 0.542884\n",
      "epoch 87; iter: 0; batch classifier loss: 0.381839; batch adversarial loss: 0.598004\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423655; batch adversarial loss: 0.526190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.406634; batch adversarial loss: 0.562952\n",
      "epoch 90; iter: 0; batch classifier loss: 0.361942; batch adversarial loss: 0.482508\n",
      "epoch 91; iter: 0; batch classifier loss: 0.355581; batch adversarial loss: 0.579945\n",
      "epoch 92; iter: 0; batch classifier loss: 0.493252; batch adversarial loss: 0.605186\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441679; batch adversarial loss: 0.536977\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354324; batch adversarial loss: 0.588531\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345009; batch adversarial loss: 0.527382\n",
      "epoch 96; iter: 0; batch classifier loss: 0.423391; batch adversarial loss: 0.563763\n",
      "epoch 97; iter: 0; batch classifier loss: 0.444258; batch adversarial loss: 0.659907\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379923; batch adversarial loss: 0.536114\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405147; batch adversarial loss: 0.527226\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411788; batch adversarial loss: 0.588608\n",
      "epoch 101; iter: 0; batch classifier loss: 0.416425; batch adversarial loss: 0.563041\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376127; batch adversarial loss: 0.589251\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396899; batch adversarial loss: 0.616824\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376713; batch adversarial loss: 0.563284\n",
      "epoch 105; iter: 0; batch classifier loss: 0.354661; batch adversarial loss: 0.482406\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397114; batch adversarial loss: 0.535228\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377332; batch adversarial loss: 0.535624\n",
      "epoch 108; iter: 0; batch classifier loss: 0.368692; batch adversarial loss: 0.517812\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370725; batch adversarial loss: 0.606655\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408924; batch adversarial loss: 0.642517\n",
      "epoch 111; iter: 0; batch classifier loss: 0.458530; batch adversarial loss: 0.616449\n",
      "epoch 112; iter: 0; batch classifier loss: 0.443890; batch adversarial loss: 0.526964\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373979; batch adversarial loss: 0.544835\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377934; batch adversarial loss: 0.562614\n",
      "epoch 115; iter: 0; batch classifier loss: 0.435956; batch adversarial loss: 0.535824\n",
      "epoch 116; iter: 0; batch classifier loss: 0.476130; batch adversarial loss: 0.606733\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375206; batch adversarial loss: 0.694888\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384203; batch adversarial loss: 0.491867\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370750; batch adversarial loss: 0.492537\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369928; batch adversarial loss: 0.572129\n",
      "epoch 121; iter: 0; batch classifier loss: 0.433333; batch adversarial loss: 0.526760\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343835; batch adversarial loss: 0.490840\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341950; batch adversarial loss: 0.500141\n",
      "epoch 124; iter: 0; batch classifier loss: 0.493931; batch adversarial loss: 0.526685\n",
      "epoch 125; iter: 0; batch classifier loss: 0.237554; batch adversarial loss: 0.598257\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368978; batch adversarial loss: 0.544585\n",
      "epoch 127; iter: 0; batch classifier loss: 0.342080; batch adversarial loss: 0.499762\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350442; batch adversarial loss: 0.543439\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391899; batch adversarial loss: 0.524512\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373870; batch adversarial loss: 0.481094\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361036; batch adversarial loss: 0.507977\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359608; batch adversarial loss: 0.478985\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326312; batch adversarial loss: 0.525103\n",
      "epoch 134; iter: 0; batch classifier loss: 0.323155; batch adversarial loss: 0.455582\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350659; batch adversarial loss: 0.599707\n",
      "epoch 136; iter: 0; batch classifier loss: 0.413316; batch adversarial loss: 0.528461\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329172; batch adversarial loss: 0.617938\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411375; batch adversarial loss: 0.448095\n",
      "epoch 139; iter: 0; batch classifier loss: 0.423663; batch adversarial loss: 0.527619\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378440; batch adversarial loss: 0.516664\n",
      "epoch 141; iter: 0; batch classifier loss: 0.361897; batch adversarial loss: 0.535901\n",
      "epoch 142; iter: 0; batch classifier loss: 0.343304; batch adversarial loss: 0.547890\n",
      "epoch 143; iter: 0; batch classifier loss: 0.294224; batch adversarial loss: 0.509588\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390336; batch adversarial loss: 0.501025\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341971; batch adversarial loss: 0.563072\n",
      "epoch 146; iter: 0; batch classifier loss: 0.342586; batch adversarial loss: 0.544470\n",
      "epoch 147; iter: 0; batch classifier loss: 0.320912; batch adversarial loss: 0.623375\n",
      "epoch 148; iter: 0; batch classifier loss: 0.387533; batch adversarial loss: 0.571094\n",
      "epoch 149; iter: 0; batch classifier loss: 0.393798; batch adversarial loss: 0.545453\n",
      "epoch 150; iter: 0; batch classifier loss: 0.335105; batch adversarial loss: 0.509994\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391913; batch adversarial loss: 0.544800\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376626; batch adversarial loss: 0.632031\n",
      "epoch 153; iter: 0; batch classifier loss: 0.317577; batch adversarial loss: 0.561621\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353137; batch adversarial loss: 0.615030\n",
      "epoch 155; iter: 0; batch classifier loss: 0.297789; batch adversarial loss: 0.615560\n",
      "epoch 156; iter: 0; batch classifier loss: 0.305728; batch adversarial loss: 0.553513\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376076; batch adversarial loss: 0.562740\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334823; batch adversarial loss: 0.562529\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277046; batch adversarial loss: 0.500484\n",
      "epoch 160; iter: 0; batch classifier loss: 0.410065; batch adversarial loss: 0.589133\n",
      "epoch 161; iter: 0; batch classifier loss: 0.315969; batch adversarial loss: 0.482709\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334266; batch adversarial loss: 0.571188\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351661; batch adversarial loss: 0.597660\n",
      "epoch 164; iter: 0; batch classifier loss: 0.388156; batch adversarial loss: 0.483075\n",
      "epoch 165; iter: 0; batch classifier loss: 0.270608; batch adversarial loss: 0.570837\n",
      "epoch 166; iter: 0; batch classifier loss: 0.268758; batch adversarial loss: 0.589506\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367261; batch adversarial loss: 0.508910\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327765; batch adversarial loss: 0.544547\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339321; batch adversarial loss: 0.535202\n",
      "epoch 170; iter: 0; batch classifier loss: 0.372382; batch adversarial loss: 0.580223\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323928; batch adversarial loss: 0.500548\n",
      "epoch 172; iter: 0; batch classifier loss: 0.371246; batch adversarial loss: 0.554564\n",
      "epoch 173; iter: 0; batch classifier loss: 0.279253; batch adversarial loss: 0.527496\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334616; batch adversarial loss: 0.570714\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360798; batch adversarial loss: 0.518096\n",
      "epoch 176; iter: 0; batch classifier loss: 0.352356; batch adversarial loss: 0.527217\n",
      "epoch 177; iter: 0; batch classifier loss: 0.308196; batch adversarial loss: 0.615132\n",
      "epoch 178; iter: 0; batch classifier loss: 0.313438; batch adversarial loss: 0.588639\n",
      "epoch 179; iter: 0; batch classifier loss: 0.375563; batch adversarial loss: 0.518030\n",
      "epoch 180; iter: 0; batch classifier loss: 0.314078; batch adversarial loss: 0.517746\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323089; batch adversarial loss: 0.500106\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322115; batch adversarial loss: 0.515603\n",
      "epoch 183; iter: 0; batch classifier loss: 0.322987; batch adversarial loss: 0.515664\n",
      "epoch 184; iter: 0; batch classifier loss: 0.320206; batch adversarial loss: 0.551919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.277922; batch adversarial loss: 0.563172\n",
      "epoch 186; iter: 0; batch classifier loss: 0.335660; batch adversarial loss: 0.491513\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329592; batch adversarial loss: 0.499368\n",
      "epoch 188; iter: 0; batch classifier loss: 0.291187; batch adversarial loss: 0.564599\n",
      "epoch 189; iter: 0; batch classifier loss: 0.331698; batch adversarial loss: 0.575706\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368264; batch adversarial loss: 0.489029\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339845; batch adversarial loss: 0.546150\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330204; batch adversarial loss: 0.490791\n",
      "epoch 193; iter: 0; batch classifier loss: 0.292204; batch adversarial loss: 0.581121\n",
      "epoch 194; iter: 0; batch classifier loss: 0.249365; batch adversarial loss: 0.546112\n",
      "epoch 195; iter: 0; batch classifier loss: 0.295850; batch adversarial loss: 0.557808\n",
      "epoch 196; iter: 0; batch classifier loss: 0.299714; batch adversarial loss: 0.510736\n",
      "epoch 197; iter: 0; batch classifier loss: 0.275368; batch adversarial loss: 0.528187\n",
      "epoch 198; iter: 0; batch classifier loss: 0.260913; batch adversarial loss: 0.542482\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319839; batch adversarial loss: 0.552734\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697049; batch adversarial loss: 0.598443\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593396; batch adversarial loss: 0.648285\n",
      "epoch 2; iter: 0; batch classifier loss: 0.622479; batch adversarial loss: 0.616722\n",
      "epoch 3; iter: 0; batch classifier loss: 0.497731; batch adversarial loss: 0.617048\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575451; batch adversarial loss: 0.627220\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546178; batch adversarial loss: 0.609011\n",
      "epoch 6; iter: 0; batch classifier loss: 0.603479; batch adversarial loss: 0.618930\n",
      "epoch 7; iter: 0; batch classifier loss: 0.540883; batch adversarial loss: 0.612275\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523162; batch adversarial loss: 0.579516\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565001; batch adversarial loss: 0.608897\n",
      "epoch 10; iter: 0; batch classifier loss: 0.454524; batch adversarial loss: 0.608978\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504046; batch adversarial loss: 0.635134\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534637; batch adversarial loss: 0.601954\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488028; batch adversarial loss: 0.553659\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512216; batch adversarial loss: 0.560677\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538803; batch adversarial loss: 0.560857\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503778; batch adversarial loss: 0.557472\n",
      "epoch 17; iter: 0; batch classifier loss: 0.475433; batch adversarial loss: 0.573676\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419134; batch adversarial loss: 0.571708\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501861; batch adversarial loss: 0.520635\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516858; batch adversarial loss: 0.596193\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511204; batch adversarial loss: 0.516484\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473163; batch adversarial loss: 0.539019\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486938; batch adversarial loss: 0.559318\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446745; batch adversarial loss: 0.579324\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476099; batch adversarial loss: 0.546859\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489566; batch adversarial loss: 0.597273\n",
      "epoch 27; iter: 0; batch classifier loss: 0.452133; batch adversarial loss: 0.605499\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438791; batch adversarial loss: 0.520693\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464618; batch adversarial loss: 0.528623\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421813; batch adversarial loss: 0.476485\n",
      "epoch 31; iter: 0; batch classifier loss: 0.369923; batch adversarial loss: 0.570905\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445471; batch adversarial loss: 0.588851\n",
      "epoch 33; iter: 0; batch classifier loss: 0.417020; batch adversarial loss: 0.536081\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469333; batch adversarial loss: 0.500366\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437320; batch adversarial loss: 0.580922\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397233; batch adversarial loss: 0.562735\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394637; batch adversarial loss: 0.545712\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430904; batch adversarial loss: 0.588929\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429502; batch adversarial loss: 0.580676\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398147; batch adversarial loss: 0.544503\n",
      "epoch 41; iter: 0; batch classifier loss: 0.505860; batch adversarial loss: 0.545890\n",
      "epoch 42; iter: 0; batch classifier loss: 0.524834; batch adversarial loss: 0.564024\n",
      "epoch 43; iter: 0; batch classifier loss: 0.371718; batch adversarial loss: 0.488597\n",
      "epoch 44; iter: 0; batch classifier loss: 0.475315; batch adversarial loss: 0.615748\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398544; batch adversarial loss: 0.564429\n",
      "epoch 46; iter: 0; batch classifier loss: 0.395273; batch adversarial loss: 0.563405\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462226; batch adversarial loss: 0.562710\n",
      "epoch 48; iter: 0; batch classifier loss: 0.398285; batch adversarial loss: 0.545692\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424823; batch adversarial loss: 0.544170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.488374; batch adversarial loss: 0.490402\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450216; batch adversarial loss: 0.519434\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433698; batch adversarial loss: 0.543912\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429494; batch adversarial loss: 0.552615\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433648; batch adversarial loss: 0.596455\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434793; batch adversarial loss: 0.569741\n",
      "epoch 56; iter: 0; batch classifier loss: 0.400482; batch adversarial loss: 0.568821\n",
      "epoch 57; iter: 0; batch classifier loss: 0.365570; batch adversarial loss: 0.570371\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378026; batch adversarial loss: 0.463624\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435247; batch adversarial loss: 0.570551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388479; batch adversarial loss: 0.630684\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395602; batch adversarial loss: 0.535803\n",
      "epoch 62; iter: 0; batch classifier loss: 0.477403; batch adversarial loss: 0.567814\n",
      "epoch 63; iter: 0; batch classifier loss: 0.437488; batch adversarial loss: 0.566713\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423087; batch adversarial loss: 0.552837\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394505; batch adversarial loss: 0.643834\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420119; batch adversarial loss: 0.582535\n",
      "epoch 67; iter: 0; batch classifier loss: 0.365122; batch adversarial loss: 0.453768\n",
      "epoch 68; iter: 0; batch classifier loss: 0.366458; batch adversarial loss: 0.641346\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401732; batch adversarial loss: 0.554708\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444050; batch adversarial loss: 0.535482\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426894; batch adversarial loss: 0.489386\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394424; batch adversarial loss: 0.507075\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419392; batch adversarial loss: 0.547887\n",
      "epoch 74; iter: 0; batch classifier loss: 0.438103; batch adversarial loss: 0.515213\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427631; batch adversarial loss: 0.598510\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359966; batch adversarial loss: 0.570608\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389048; batch adversarial loss: 0.568394\n",
      "epoch 78; iter: 0; batch classifier loss: 0.425225; batch adversarial loss: 0.586849\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439417; batch adversarial loss: 0.553986\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426882; batch adversarial loss: 0.561693\n",
      "epoch 81; iter: 0; batch classifier loss: 0.416562; batch adversarial loss: 0.528763\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435800; batch adversarial loss: 0.507754\n",
      "epoch 83; iter: 0; batch classifier loss: 0.353853; batch adversarial loss: 0.580618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.407940; batch adversarial loss: 0.573924\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378232; batch adversarial loss: 0.601047\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357579; batch adversarial loss: 0.584047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398972; batch adversarial loss: 0.538058\n",
      "epoch 88; iter: 0; batch classifier loss: 0.505778; batch adversarial loss: 0.572916\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370657; batch adversarial loss: 0.619387\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432449; batch adversarial loss: 0.534182\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399054; batch adversarial loss: 0.587467\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411325; batch adversarial loss: 0.526859\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363652; batch adversarial loss: 0.449275\n",
      "epoch 94; iter: 0; batch classifier loss: 0.448238; batch adversarial loss: 0.554445\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384464; batch adversarial loss: 0.531204\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420153; batch adversarial loss: 0.563266\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376558; batch adversarial loss: 0.634512\n",
      "epoch 98; iter: 0; batch classifier loss: 0.414524; batch adversarial loss: 0.534519\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460623; batch adversarial loss: 0.492110\n",
      "epoch 100; iter: 0; batch classifier loss: 0.427288; batch adversarial loss: 0.536919\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379738; batch adversarial loss: 0.525789\n",
      "epoch 102; iter: 0; batch classifier loss: 0.343516; batch adversarial loss: 0.680686\n",
      "epoch 103; iter: 0; batch classifier loss: 0.432394; batch adversarial loss: 0.524275\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420373; batch adversarial loss: 0.560598\n",
      "epoch 105; iter: 0; batch classifier loss: 0.444549; batch adversarial loss: 0.596385\n",
      "epoch 106; iter: 0; batch classifier loss: 0.446323; batch adversarial loss: 0.499572\n",
      "epoch 107; iter: 0; batch classifier loss: 0.475405; batch adversarial loss: 0.561041\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401408; batch adversarial loss: 0.532330\n",
      "epoch 109; iter: 0; batch classifier loss: 0.390421; batch adversarial loss: 0.500061\n",
      "epoch 110; iter: 0; batch classifier loss: 0.332786; batch adversarial loss: 0.543862\n",
      "epoch 111; iter: 0; batch classifier loss: 0.413111; batch adversarial loss: 0.508807\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360521; batch adversarial loss: 0.576922\n",
      "epoch 113; iter: 0; batch classifier loss: 0.313694; batch adversarial loss: 0.533554\n",
      "epoch 114; iter: 0; batch classifier loss: 0.333817; batch adversarial loss: 0.602776\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419551; batch adversarial loss: 0.525500\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364571; batch adversarial loss: 0.506949\n",
      "epoch 117; iter: 0; batch classifier loss: 0.404610; batch adversarial loss: 0.534241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387181; batch adversarial loss: 0.570106\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410071; batch adversarial loss: 0.624085\n",
      "epoch 120; iter: 0; batch classifier loss: 0.345121; batch adversarial loss: 0.498316\n",
      "epoch 121; iter: 0; batch classifier loss: 0.449946; batch adversarial loss: 0.470056\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388381; batch adversarial loss: 0.607986\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356541; batch adversarial loss: 0.568584\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403233; batch adversarial loss: 0.594740\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377162; batch adversarial loss: 0.544901\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382076; batch adversarial loss: 0.487924\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379141; batch adversarial loss: 0.516712\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362308; batch adversarial loss: 0.596823\n",
      "epoch 129; iter: 0; batch classifier loss: 0.318449; batch adversarial loss: 0.504936\n",
      "epoch 130; iter: 0; batch classifier loss: 0.337404; batch adversarial loss: 0.572816\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388946; batch adversarial loss: 0.539765\n",
      "epoch 132; iter: 0; batch classifier loss: 0.367438; batch adversarial loss: 0.562761\n",
      "epoch 133; iter: 0; batch classifier loss: 0.380678; batch adversarial loss: 0.463420\n",
      "epoch 134; iter: 0; batch classifier loss: 0.360902; batch adversarial loss: 0.541567\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370231; batch adversarial loss: 0.512520\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346039; batch adversarial loss: 0.524977\n",
      "epoch 137; iter: 0; batch classifier loss: 0.429116; batch adversarial loss: 0.598148\n",
      "epoch 138; iter: 0; batch classifier loss: 0.311407; batch adversarial loss: 0.546991\n",
      "epoch 139; iter: 0; batch classifier loss: 0.409531; batch adversarial loss: 0.557891\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343547; batch adversarial loss: 0.593294\n",
      "epoch 141; iter: 0; batch classifier loss: 0.480184; batch adversarial loss: 0.525574\n",
      "epoch 142; iter: 0; batch classifier loss: 0.303235; batch adversarial loss: 0.557747\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371398; batch adversarial loss: 0.515463\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372916; batch adversarial loss: 0.604354\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379251; batch adversarial loss: 0.502593\n",
      "epoch 146; iter: 0; batch classifier loss: 0.431318; batch adversarial loss: 0.480213\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383540; batch adversarial loss: 0.517088\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350044; batch adversarial loss: 0.551553\n",
      "epoch 149; iter: 0; batch classifier loss: 0.325913; batch adversarial loss: 0.522901\n",
      "epoch 150; iter: 0; batch classifier loss: 0.386984; batch adversarial loss: 0.500610\n",
      "epoch 151; iter: 0; batch classifier loss: 0.277031; batch adversarial loss: 0.520035\n",
      "epoch 152; iter: 0; batch classifier loss: 0.441328; batch adversarial loss: 0.573017\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357521; batch adversarial loss: 0.590352\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370571; batch adversarial loss: 0.576064\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307897; batch adversarial loss: 0.498983\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336318; batch adversarial loss: 0.516436\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360077; batch adversarial loss: 0.568678\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334830; batch adversarial loss: 0.526102\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359079; batch adversarial loss: 0.525659\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400751; batch adversarial loss: 0.534953\n",
      "epoch 161; iter: 0; batch classifier loss: 0.302804; batch adversarial loss: 0.521885\n",
      "epoch 162; iter: 0; batch classifier loss: 0.424845; batch adversarial loss: 0.590608\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359562; batch adversarial loss: 0.534587\n",
      "epoch 164; iter: 0; batch classifier loss: 0.326484; batch adversarial loss: 0.524500\n",
      "epoch 165; iter: 0; batch classifier loss: 0.340883; batch adversarial loss: 0.545829\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374786; batch adversarial loss: 0.481076\n",
      "epoch 167; iter: 0; batch classifier loss: 0.306243; batch adversarial loss: 0.552045\n",
      "epoch 168; iter: 0; batch classifier loss: 0.325370; batch adversarial loss: 0.489590\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362371; batch adversarial loss: 0.542475\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329805; batch adversarial loss: 0.607233\n",
      "epoch 171; iter: 0; batch classifier loss: 0.386942; batch adversarial loss: 0.607265\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341369; batch adversarial loss: 0.538029\n",
      "epoch 173; iter: 0; batch classifier loss: 0.400857; batch adversarial loss: 0.549124\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378340; batch adversarial loss: 0.486435\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352438; batch adversarial loss: 0.509460\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367882; batch adversarial loss: 0.497291\n",
      "epoch 177; iter: 0; batch classifier loss: 0.255691; batch adversarial loss: 0.525331\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351552; batch adversarial loss: 0.543048\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318648; batch adversarial loss: 0.551737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.362633; batch adversarial loss: 0.563074\n",
      "epoch 181; iter: 0; batch classifier loss: 0.287824; batch adversarial loss: 0.580290\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314458; batch adversarial loss: 0.638152\n",
      "epoch 183; iter: 0; batch classifier loss: 0.311622; batch adversarial loss: 0.532933\n",
      "epoch 184; iter: 0; batch classifier loss: 0.314830; batch adversarial loss: 0.582396\n",
      "epoch 185; iter: 0; batch classifier loss: 0.443404; batch adversarial loss: 0.555725\n",
      "epoch 186; iter: 0; batch classifier loss: 0.335286; batch adversarial loss: 0.553631\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338765; batch adversarial loss: 0.544162\n",
      "epoch 188; iter: 0; batch classifier loss: 0.298085; batch adversarial loss: 0.536149\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345586; batch adversarial loss: 0.485288\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368868; batch adversarial loss: 0.453943\n",
      "epoch 191; iter: 0; batch classifier loss: 0.305584; batch adversarial loss: 0.536152\n",
      "epoch 192; iter: 0; batch classifier loss: 0.296354; batch adversarial loss: 0.534998\n",
      "epoch 193; iter: 0; batch classifier loss: 0.295041; batch adversarial loss: 0.571880\n",
      "epoch 194; iter: 0; batch classifier loss: 0.440668; batch adversarial loss: 0.554363\n",
      "epoch 195; iter: 0; batch classifier loss: 0.463840; batch adversarial loss: 0.574443\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376930; batch adversarial loss: 0.592756\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315278; batch adversarial loss: 0.497216\n",
      "epoch 198; iter: 0; batch classifier loss: 0.270185; batch adversarial loss: 0.538014\n",
      "epoch 199; iter: 0; batch classifier loss: 0.391873; batch adversarial loss: 0.563508\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687843; batch adversarial loss: 0.680508\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622525; batch adversarial loss: 0.666442\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562467; batch adversarial loss: 0.644410\n",
      "epoch 3; iter: 0; batch classifier loss: 0.527148; batch adversarial loss: 0.644905\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545725; batch adversarial loss: 0.640280\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521222; batch adversarial loss: 0.579446\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592901; batch adversarial loss: 0.609691\n",
      "epoch 7; iter: 0; batch classifier loss: 0.600019; batch adversarial loss: 0.608538\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543983; batch adversarial loss: 0.592396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573662; batch adversarial loss: 0.569958\n",
      "epoch 10; iter: 0; batch classifier loss: 0.617085; batch adversarial loss: 0.569490\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590153; batch adversarial loss: 0.538930\n",
      "epoch 12; iter: 0; batch classifier loss: 0.611812; batch adversarial loss: 0.563176\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539407; batch adversarial loss: 0.606763\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512893; batch adversarial loss: 0.561662\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542177; batch adversarial loss: 0.555660\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522968; batch adversarial loss: 0.527939\n",
      "epoch 17; iter: 0; batch classifier loss: 0.452784; batch adversarial loss: 0.564025\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508824; batch adversarial loss: 0.537182\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437131; batch adversarial loss: 0.576761\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475386; batch adversarial loss: 0.515229\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543428; batch adversarial loss: 0.575706\n",
      "epoch 22; iter: 0; batch classifier loss: 0.544133; batch adversarial loss: 0.527417\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473167; batch adversarial loss: 0.547883\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440127; batch adversarial loss: 0.589728\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479720; batch adversarial loss: 0.446491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.514838; batch adversarial loss: 0.452622\n",
      "epoch 27; iter: 0; batch classifier loss: 0.559547; batch adversarial loss: 0.485168\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442331; batch adversarial loss: 0.532145\n",
      "epoch 29; iter: 0; batch classifier loss: 0.535301; batch adversarial loss: 0.594057\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478758; batch adversarial loss: 0.545465\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484142; batch adversarial loss: 0.478853\n",
      "epoch 32; iter: 0; batch classifier loss: 0.542724; batch adversarial loss: 0.580695\n",
      "epoch 33; iter: 0; batch classifier loss: 0.454730; batch adversarial loss: 0.508953\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484614; batch adversarial loss: 0.603135\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438436; batch adversarial loss: 0.564102\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447003; batch adversarial loss: 0.546559\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383145; batch adversarial loss: 0.536851\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469061; batch adversarial loss: 0.486393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451485; batch adversarial loss: 0.578447\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439149; batch adversarial loss: 0.561756\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471495; batch adversarial loss: 0.554156\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448927; batch adversarial loss: 0.597660\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460773; batch adversarial loss: 0.556509\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410526; batch adversarial loss: 0.543387\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412897; batch adversarial loss: 0.534975\n",
      "epoch 46; iter: 0; batch classifier loss: 0.376701; batch adversarial loss: 0.562307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425601; batch adversarial loss: 0.509552\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408839; batch adversarial loss: 0.527291\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401608; batch adversarial loss: 0.573031\n",
      "epoch 50; iter: 0; batch classifier loss: 0.452426; batch adversarial loss: 0.590012\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443833; batch adversarial loss: 0.527048\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440349; batch adversarial loss: 0.517283\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423085; batch adversarial loss: 0.527207\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379570; batch adversarial loss: 0.562363\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449000; batch adversarial loss: 0.508561\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426986; batch adversarial loss: 0.544361\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445609; batch adversarial loss: 0.526836\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450474; batch adversarial loss: 0.562859\n",
      "epoch 59; iter: 0; batch classifier loss: 0.484976; batch adversarial loss: 0.580420\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442523; batch adversarial loss: 0.607006\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432455; batch adversarial loss: 0.516766\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387008; batch adversarial loss: 0.580916\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421501; batch adversarial loss: 0.554625\n",
      "epoch 64; iter: 0; batch classifier loss: 0.364533; batch adversarial loss: 0.571894\n",
      "epoch 65; iter: 0; batch classifier loss: 0.469367; batch adversarial loss: 0.581487\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384263; batch adversarial loss: 0.588369\n",
      "epoch 67; iter: 0; batch classifier loss: 0.341901; batch adversarial loss: 0.607433\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426735; batch adversarial loss: 0.588857\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451760; batch adversarial loss: 0.554073\n",
      "epoch 70; iter: 0; batch classifier loss: 0.376773; batch adversarial loss: 0.526868\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376264; batch adversarial loss: 0.572024\n",
      "epoch 72; iter: 0; batch classifier loss: 0.362205; batch adversarial loss: 0.499821\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419858; batch adversarial loss: 0.553660\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380431; batch adversarial loss: 0.481297\n",
      "epoch 75; iter: 0; batch classifier loss: 0.428742; batch adversarial loss: 0.472571\n",
      "epoch 76; iter: 0; batch classifier loss: 0.347590; batch adversarial loss: 0.453690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.394948; batch adversarial loss: 0.490936\n",
      "epoch 78; iter: 0; batch classifier loss: 0.463998; batch adversarial loss: 0.589431\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417573; batch adversarial loss: 0.508524\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395050; batch adversarial loss: 0.581462\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365645; batch adversarial loss: 0.526694\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387463; batch adversarial loss: 0.481392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.453950; batch adversarial loss: 0.535604\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402875; batch adversarial loss: 0.589661\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344016; batch adversarial loss: 0.490633\n",
      "epoch 86; iter: 0; batch classifier loss: 0.386981; batch adversarial loss: 0.598541\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365006; batch adversarial loss: 0.526831\n",
      "epoch 88; iter: 0; batch classifier loss: 0.314378; batch adversarial loss: 0.499483\n",
      "epoch 89; iter: 0; batch classifier loss: 0.448549; batch adversarial loss: 0.516906\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435679; batch adversarial loss: 0.590014\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400910; batch adversarial loss: 0.571689\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400303; batch adversarial loss: 0.535226\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374840; batch adversarial loss: 0.607577\n",
      "epoch 94; iter: 0; batch classifier loss: 0.344094; batch adversarial loss: 0.580460\n",
      "epoch 95; iter: 0; batch classifier loss: 0.355249; batch adversarial loss: 0.490063\n",
      "epoch 96; iter: 0; batch classifier loss: 0.351832; batch adversarial loss: 0.526457\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363998; batch adversarial loss: 0.544414\n",
      "epoch 98; iter: 0; batch classifier loss: 0.334925; batch adversarial loss: 0.607548\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417918; batch adversarial loss: 0.454916\n",
      "epoch 100; iter: 0; batch classifier loss: 0.508453; batch adversarial loss: 0.544655\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336893; batch adversarial loss: 0.499817\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388505; batch adversarial loss: 0.571671\n",
      "epoch 103; iter: 0; batch classifier loss: 0.332599; batch adversarial loss: 0.544681\n",
      "epoch 104; iter: 0; batch classifier loss: 0.313941; batch adversarial loss: 0.562520\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414963; batch adversarial loss: 0.526531\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377091; batch adversarial loss: 0.517086\n",
      "epoch 107; iter: 0; batch classifier loss: 0.356431; batch adversarial loss: 0.472564\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351478; batch adversarial loss: 0.463729\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413227; batch adversarial loss: 0.535726\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388831; batch adversarial loss: 0.679348\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375833; batch adversarial loss: 0.544598\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357764; batch adversarial loss: 0.598420\n",
      "epoch 113; iter: 0; batch classifier loss: 0.509173; batch adversarial loss: 0.598569\n",
      "epoch 114; iter: 0; batch classifier loss: 0.414641; batch adversarial loss: 0.526263\n",
      "epoch 115; iter: 0; batch classifier loss: 0.429011; batch adversarial loss: 0.553139\n",
      "epoch 116; iter: 0; batch classifier loss: 0.395653; batch adversarial loss: 0.589228\n",
      "epoch 117; iter: 0; batch classifier loss: 0.401574; batch adversarial loss: 0.581338\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404464; batch adversarial loss: 0.544768\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366370; batch adversarial loss: 0.526412\n",
      "epoch 120; iter: 0; batch classifier loss: 0.327904; batch adversarial loss: 0.581168\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339396; batch adversarial loss: 0.553810\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398674; batch adversarial loss: 0.589868\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375386; batch adversarial loss: 0.562666\n",
      "epoch 124; iter: 0; batch classifier loss: 0.311324; batch adversarial loss: 0.508149\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412263; batch adversarial loss: 0.544564\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380934; batch adversarial loss: 0.607722\n",
      "epoch 127; iter: 0; batch classifier loss: 0.363114; batch adversarial loss: 0.626095\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375550; batch adversarial loss: 0.508070\n",
      "epoch 129; iter: 0; batch classifier loss: 0.293171; batch adversarial loss: 0.525969\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370604; batch adversarial loss: 0.534511\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326691; batch adversarial loss: 0.535157\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400078; batch adversarial loss: 0.534315\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410730; batch adversarial loss: 0.517068\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354961; batch adversarial loss: 0.589331\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380131; batch adversarial loss: 0.541801\n",
      "epoch 136; iter: 0; batch classifier loss: 0.423405; batch adversarial loss: 0.602842\n",
      "epoch 137; iter: 0; batch classifier loss: 0.428555; batch adversarial loss: 0.637281\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320029; batch adversarial loss: 0.536805\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379107; batch adversarial loss: 0.562834\n",
      "epoch 140; iter: 0; batch classifier loss: 0.287587; batch adversarial loss: 0.580043\n",
      "epoch 141; iter: 0; batch classifier loss: 0.394254; batch adversarial loss: 0.473057\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384148; batch adversarial loss: 0.499899\n",
      "epoch 143; iter: 0; batch classifier loss: 0.421319; batch adversarial loss: 0.633789\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406146; batch adversarial loss: 0.544839\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355320; batch adversarial loss: 0.597748\n",
      "epoch 146; iter: 0; batch classifier loss: 0.386952; batch adversarial loss: 0.606724\n",
      "epoch 147; iter: 0; batch classifier loss: 0.425810; batch adversarial loss: 0.571348\n",
      "epoch 148; iter: 0; batch classifier loss: 0.287818; batch adversarial loss: 0.526066\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359971; batch adversarial loss: 0.653259\n",
      "epoch 150; iter: 0; batch classifier loss: 0.401996; batch adversarial loss: 0.561912\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350746; batch adversarial loss: 0.597999\n",
      "epoch 152; iter: 0; batch classifier loss: 0.396709; batch adversarial loss: 0.488118\n",
      "epoch 153; iter: 0; batch classifier loss: 0.417952; batch adversarial loss: 0.643389\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381993; batch adversarial loss: 0.607778\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346782; batch adversarial loss: 0.523561\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352942; batch adversarial loss: 0.535137\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373288; batch adversarial loss: 0.518415\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321112; batch adversarial loss: 0.626714\n",
      "epoch 159; iter: 0; batch classifier loss: 0.379644; batch adversarial loss: 0.534410\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363465; batch adversarial loss: 0.580238\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334516; batch adversarial loss: 0.561834\n",
      "epoch 162; iter: 0; batch classifier loss: 0.354040; batch adversarial loss: 0.589557\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339278; batch adversarial loss: 0.571737\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362685; batch adversarial loss: 0.580232\n",
      "epoch 165; iter: 0; batch classifier loss: 0.383267; batch adversarial loss: 0.615759\n",
      "epoch 166; iter: 0; batch classifier loss: 0.352120; batch adversarial loss: 0.554125\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323007; batch adversarial loss: 0.544359\n",
      "epoch 168; iter: 0; batch classifier loss: 0.307271; batch adversarial loss: 0.553853\n",
      "epoch 169; iter: 0; batch classifier loss: 0.420716; batch adversarial loss: 0.482155\n",
      "epoch 170; iter: 0; batch classifier loss: 0.314942; batch adversarial loss: 0.581005\n",
      "epoch 171; iter: 0; batch classifier loss: 0.395772; batch adversarial loss: 0.662602\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379100; batch adversarial loss: 0.606352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.387472; batch adversarial loss: 0.517226\n",
      "epoch 174; iter: 0; batch classifier loss: 0.398304; batch adversarial loss: 0.571946\n",
      "epoch 175; iter: 0; batch classifier loss: 0.277044; batch adversarial loss: 0.508886\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370077; batch adversarial loss: 0.517145\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374566; batch adversarial loss: 0.536503\n",
      "epoch 178; iter: 0; batch classifier loss: 0.378324; batch adversarial loss: 0.616530\n",
      "epoch 179; iter: 0; batch classifier loss: 0.403442; batch adversarial loss: 0.616941\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360287; batch adversarial loss: 0.481842\n",
      "epoch 181; iter: 0; batch classifier loss: 0.440843; batch adversarial loss: 0.535633\n",
      "epoch 182; iter: 0; batch classifier loss: 0.356961; batch adversarial loss: 0.562416\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347280; batch adversarial loss: 0.617560\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377026; batch adversarial loss: 0.472893\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376315; batch adversarial loss: 0.509035\n",
      "epoch 186; iter: 0; batch classifier loss: 0.395553; batch adversarial loss: 0.436951\n",
      "epoch 187; iter: 0; batch classifier loss: 0.315040; batch adversarial loss: 0.544693\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358060; batch adversarial loss: 0.589309\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309423; batch adversarial loss: 0.589431\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344416; batch adversarial loss: 0.562791\n",
      "epoch 191; iter: 0; batch classifier loss: 0.369264; batch adversarial loss: 0.499517\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384998; batch adversarial loss: 0.553743\n",
      "epoch 193; iter: 0; batch classifier loss: 0.420094; batch adversarial loss: 0.553417\n",
      "epoch 194; iter: 0; batch classifier loss: 0.479127; batch adversarial loss: 0.562763\n",
      "epoch 195; iter: 0; batch classifier loss: 0.373907; batch adversarial loss: 0.608178\n",
      "epoch 196; iter: 0; batch classifier loss: 0.417803; batch adversarial loss: 0.590414\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347432; batch adversarial loss: 0.615831\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356700; batch adversarial loss: 0.471139\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388999; batch adversarial loss: 0.517459\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717139; batch adversarial loss: 0.831678\n",
      "epoch 1; iter: 0; batch classifier loss: 0.764093; batch adversarial loss: 0.789746\n",
      "epoch 2; iter: 0; batch classifier loss: 0.774730; batch adversarial loss: 0.775084\n",
      "epoch 3; iter: 0; batch classifier loss: 0.707142; batch adversarial loss: 0.738214\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607664; batch adversarial loss: 0.670239\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515332; batch adversarial loss: 0.591747\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592515; batch adversarial loss: 0.609832\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561267; batch adversarial loss: 0.607030\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588312; batch adversarial loss: 0.594209\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576078; batch adversarial loss: 0.638015\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498533; batch adversarial loss: 0.570578\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567240; batch adversarial loss: 0.617350\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518467; batch adversarial loss: 0.552096\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569998; batch adversarial loss: 0.586476\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524322; batch adversarial loss: 0.548217\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519347; batch adversarial loss: 0.604973\n",
      "epoch 16; iter: 0; batch classifier loss: 0.443115; batch adversarial loss: 0.544279\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499318; batch adversarial loss: 0.536284\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462625; batch adversarial loss: 0.545890\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545241; batch adversarial loss: 0.612052\n",
      "epoch 20; iter: 0; batch classifier loss: 0.571374; batch adversarial loss: 0.508818\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510579; batch adversarial loss: 0.531714\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477970; batch adversarial loss: 0.613462\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487668; batch adversarial loss: 0.519037\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512079; batch adversarial loss: 0.555146\n",
      "epoch 25; iter: 0; batch classifier loss: 0.450772; batch adversarial loss: 0.539229\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413686; batch adversarial loss: 0.600553\n",
      "epoch 27; iter: 0; batch classifier loss: 0.410819; batch adversarial loss: 0.548173\n",
      "epoch 28; iter: 0; batch classifier loss: 0.501379; batch adversarial loss: 0.561985\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486327; batch adversarial loss: 0.582235\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456130; batch adversarial loss: 0.621191\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445317; batch adversarial loss: 0.527358\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432560; batch adversarial loss: 0.621298\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421915; batch adversarial loss: 0.572782\n",
      "epoch 34; iter: 0; batch classifier loss: 0.373043; batch adversarial loss: 0.497723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434940; batch adversarial loss: 0.447736\n",
      "epoch 36; iter: 0; batch classifier loss: 0.514235; batch adversarial loss: 0.500616\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421133; batch adversarial loss: 0.596974\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468701; batch adversarial loss: 0.507295\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480202; batch adversarial loss: 0.493891\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457453; batch adversarial loss: 0.571000\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426288; batch adversarial loss: 0.507586\n",
      "epoch 42; iter: 0; batch classifier loss: 0.412135; batch adversarial loss: 0.499705\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410357; batch adversarial loss: 0.518361\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415901; batch adversarial loss: 0.515644\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443167; batch adversarial loss: 0.505251\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447779; batch adversarial loss: 0.535587\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432494; batch adversarial loss: 0.497767\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457708; batch adversarial loss: 0.546112\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472744; batch adversarial loss: 0.591344\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414901; batch adversarial loss: 0.572428\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414137; batch adversarial loss: 0.525699\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442712; batch adversarial loss: 0.544183\n",
      "epoch 53; iter: 0; batch classifier loss: 0.433327; batch adversarial loss: 0.517029\n",
      "epoch 54; iter: 0; batch classifier loss: 0.483639; batch adversarial loss: 0.525805\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448545; batch adversarial loss: 0.574373\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404493; batch adversarial loss: 0.544206\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459376; batch adversarial loss: 0.525428\n",
      "epoch 58; iter: 0; batch classifier loss: 0.324918; batch adversarial loss: 0.581131\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420758; batch adversarial loss: 0.497794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431427; batch adversarial loss: 0.581837\n",
      "epoch 61; iter: 0; batch classifier loss: 0.368641; batch adversarial loss: 0.553940\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383557; batch adversarial loss: 0.533568\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418111; batch adversarial loss: 0.561985\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489519; batch adversarial loss: 0.601544\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365657; batch adversarial loss: 0.545107\n",
      "epoch 66; iter: 0; batch classifier loss: 0.368794; batch adversarial loss: 0.524628\n",
      "epoch 67; iter: 0; batch classifier loss: 0.489011; batch adversarial loss: 0.524180\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434407; batch adversarial loss: 0.555810\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400110; batch adversarial loss: 0.564080\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391786; batch adversarial loss: 0.439940\n",
      "epoch 71; iter: 0; batch classifier loss: 0.456248; batch adversarial loss: 0.564847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.364787; batch adversarial loss: 0.544432\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386330; batch adversarial loss: 0.536412\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464371; batch adversarial loss: 0.462794\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402332; batch adversarial loss: 0.580869\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404619; batch adversarial loss: 0.508948\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388741; batch adversarial loss: 0.495717\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401418; batch adversarial loss: 0.498179\n",
      "epoch 79; iter: 0; batch classifier loss: 0.346011; batch adversarial loss: 0.569571\n",
      "epoch 80; iter: 0; batch classifier loss: 0.362602; batch adversarial loss: 0.464842\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387340; batch adversarial loss: 0.511510\n",
      "epoch 82; iter: 0; batch classifier loss: 0.459764; batch adversarial loss: 0.493888\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364772; batch adversarial loss: 0.566107\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418640; batch adversarial loss: 0.465636\n",
      "epoch 85; iter: 0; batch classifier loss: 0.351713; batch adversarial loss: 0.487714\n",
      "epoch 86; iter: 0; batch classifier loss: 0.447544; batch adversarial loss: 0.538082\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380936; batch adversarial loss: 0.533717\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405217; batch adversarial loss: 0.604293\n",
      "epoch 89; iter: 0; batch classifier loss: 0.340667; batch adversarial loss: 0.607839\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398343; batch adversarial loss: 0.540477\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381624; batch adversarial loss: 0.564304\n",
      "epoch 92; iter: 0; batch classifier loss: 0.547326; batch adversarial loss: 0.562403\n",
      "epoch 93; iter: 0; batch classifier loss: 0.453910; batch adversarial loss: 0.570572\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381684; batch adversarial loss: 0.572254\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401592; batch adversarial loss: 0.429352\n",
      "epoch 96; iter: 0; batch classifier loss: 0.486054; batch adversarial loss: 0.522564\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346337; batch adversarial loss: 0.514920\n",
      "epoch 98; iter: 0; batch classifier loss: 0.323624; batch adversarial loss: 0.525629\n",
      "epoch 99; iter: 0; batch classifier loss: 0.335267; batch adversarial loss: 0.532563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421636; batch adversarial loss: 0.560837\n",
      "epoch 101; iter: 0; batch classifier loss: 0.325414; batch adversarial loss: 0.536394\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386045; batch adversarial loss: 0.495948\n",
      "epoch 103; iter: 0; batch classifier loss: 0.475796; batch adversarial loss: 0.576336\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361790; batch adversarial loss: 0.552212\n",
      "epoch 105; iter: 0; batch classifier loss: 0.403396; batch adversarial loss: 0.539011\n",
      "epoch 106; iter: 0; batch classifier loss: 0.464588; batch adversarial loss: 0.486134\n",
      "epoch 107; iter: 0; batch classifier loss: 0.300352; batch adversarial loss: 0.431016\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377739; batch adversarial loss: 0.465718\n",
      "epoch 109; iter: 0; batch classifier loss: 0.324090; batch adversarial loss: 0.557207\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366724; batch adversarial loss: 0.469961\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369008; batch adversarial loss: 0.610955\n",
      "epoch 112; iter: 0; batch classifier loss: 0.377852; batch adversarial loss: 0.585078\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350379; batch adversarial loss: 0.531915\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402549; batch adversarial loss: 0.518417\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379402; batch adversarial loss: 0.544934\n",
      "epoch 116; iter: 0; batch classifier loss: 0.501505; batch adversarial loss: 0.624704\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360202; batch adversarial loss: 0.537513\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366659; batch adversarial loss: 0.583307\n",
      "epoch 119; iter: 0; batch classifier loss: 0.440058; batch adversarial loss: 0.627825\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350069; batch adversarial loss: 0.570375\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346911; batch adversarial loss: 0.552102\n",
      "epoch 122; iter: 0; batch classifier loss: 0.318032; batch adversarial loss: 0.499207\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356368; batch adversarial loss: 0.552596\n",
      "epoch 124; iter: 0; batch classifier loss: 0.355125; batch adversarial loss: 0.501245\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401560; batch adversarial loss: 0.581269\n",
      "epoch 126; iter: 0; batch classifier loss: 0.424574; batch adversarial loss: 0.484441\n",
      "epoch 127; iter: 0; batch classifier loss: 0.405525; batch adversarial loss: 0.569406\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367564; batch adversarial loss: 0.605711\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368224; batch adversarial loss: 0.582677\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370260; batch adversarial loss: 0.500978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.304396; batch adversarial loss: 0.563958\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373555; batch adversarial loss: 0.486779\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364037; batch adversarial loss: 0.438834\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381261; batch adversarial loss: 0.472006\n",
      "epoch 135; iter: 0; batch classifier loss: 0.309549; batch adversarial loss: 0.597525\n",
      "epoch 136; iter: 0; batch classifier loss: 0.380075; batch adversarial loss: 0.598485\n",
      "epoch 137; iter: 0; batch classifier loss: 0.426515; batch adversarial loss: 0.478862\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377998; batch adversarial loss: 0.484897\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366002; batch adversarial loss: 0.497191\n",
      "epoch 140; iter: 0; batch classifier loss: 0.424994; batch adversarial loss: 0.573441\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383006; batch adversarial loss: 0.509334\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346874; batch adversarial loss: 0.475107\n",
      "epoch 143; iter: 0; batch classifier loss: 0.433893; batch adversarial loss: 0.527594\n",
      "epoch 144; iter: 0; batch classifier loss: 0.318664; batch adversarial loss: 0.545048\n",
      "epoch 145; iter: 0; batch classifier loss: 0.458476; batch adversarial loss: 0.602192\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404954; batch adversarial loss: 0.570522\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339689; batch adversarial loss: 0.515796\n",
      "epoch 148; iter: 0; batch classifier loss: 0.306040; batch adversarial loss: 0.538650\n",
      "epoch 149; iter: 0; batch classifier loss: 0.348953; batch adversarial loss: 0.571479\n",
      "epoch 150; iter: 0; batch classifier loss: 0.321366; batch adversarial loss: 0.556287\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364414; batch adversarial loss: 0.601439\n",
      "epoch 152; iter: 0; batch classifier loss: 0.282917; batch adversarial loss: 0.589313\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339957; batch adversarial loss: 0.528944\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342623; batch adversarial loss: 0.628452\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364450; batch adversarial loss: 0.496400\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403667; batch adversarial loss: 0.517214\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319459; batch adversarial loss: 0.414252\n",
      "epoch 158; iter: 0; batch classifier loss: 0.435428; batch adversarial loss: 0.564638\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385217; batch adversarial loss: 0.488044\n",
      "epoch 160; iter: 0; batch classifier loss: 0.433943; batch adversarial loss: 0.517496\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370092; batch adversarial loss: 0.527018\n",
      "epoch 162; iter: 0; batch classifier loss: 0.270915; batch adversarial loss: 0.590981\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354562; batch adversarial loss: 0.526671\n",
      "epoch 164; iter: 0; batch classifier loss: 0.331186; batch adversarial loss: 0.601801\n",
      "epoch 165; iter: 0; batch classifier loss: 0.400579; batch adversarial loss: 0.555341\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378604; batch adversarial loss: 0.571872\n",
      "epoch 167; iter: 0; batch classifier loss: 0.392741; batch adversarial loss: 0.573369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.284146; batch adversarial loss: 0.569311\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366869; batch adversarial loss: 0.561548\n",
      "epoch 170; iter: 0; batch classifier loss: 0.408462; batch adversarial loss: 0.563872\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411864; batch adversarial loss: 0.583983\n",
      "epoch 172; iter: 0; batch classifier loss: 0.300359; batch adversarial loss: 0.545158\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351137; batch adversarial loss: 0.619549\n",
      "epoch 174; iter: 0; batch classifier loss: 0.330504; batch adversarial loss: 0.461615\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357982; batch adversarial loss: 0.497327\n",
      "epoch 176; iter: 0; batch classifier loss: 0.390888; batch adversarial loss: 0.547171\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374333; batch adversarial loss: 0.543099\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333838; batch adversarial loss: 0.508206\n",
      "epoch 179; iter: 0; batch classifier loss: 0.465624; batch adversarial loss: 0.569821\n",
      "epoch 180; iter: 0; batch classifier loss: 0.404527; batch adversarial loss: 0.544269\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314303; batch adversarial loss: 0.549132\n",
      "epoch 182; iter: 0; batch classifier loss: 0.361048; batch adversarial loss: 0.601584\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356617; batch adversarial loss: 0.521910\n",
      "epoch 184; iter: 0; batch classifier loss: 0.446487; batch adversarial loss: 0.553871\n",
      "epoch 185; iter: 0; batch classifier loss: 0.451181; batch adversarial loss: 0.567484\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324306; batch adversarial loss: 0.518551\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356082; batch adversarial loss: 0.467809\n",
      "epoch 188; iter: 0; batch classifier loss: 0.308272; batch adversarial loss: 0.513417\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368222; batch adversarial loss: 0.497448\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379914; batch adversarial loss: 0.489226\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357097; batch adversarial loss: 0.502930\n",
      "epoch 192; iter: 0; batch classifier loss: 0.429209; batch adversarial loss: 0.558232\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349504; batch adversarial loss: 0.495557\n",
      "epoch 194; iter: 0; batch classifier loss: 0.392682; batch adversarial loss: 0.602258\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381034; batch adversarial loss: 0.535387\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349975; batch adversarial loss: 0.609173\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361150; batch adversarial loss: 0.581710\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378641; batch adversarial loss: 0.495940\n",
      "epoch 199; iter: 0; batch classifier loss: 0.372390; batch adversarial loss: 0.649563\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694068; batch adversarial loss: 0.649002\n",
      "epoch 1; iter: 0; batch classifier loss: 0.568210; batch adversarial loss: 0.682762\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572006; batch adversarial loss: 0.678370\n",
      "epoch 3; iter: 0; batch classifier loss: 0.640991; batch adversarial loss: 0.609437\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558664; batch adversarial loss: 0.626983\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599476; batch adversarial loss: 0.635519\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527596; batch adversarial loss: 0.619245\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565489; batch adversarial loss: 0.625757\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555844; batch adversarial loss: 0.596936\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521576; batch adversarial loss: 0.557869\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514028; batch adversarial loss: 0.655771\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506562; batch adversarial loss: 0.561292\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518367; batch adversarial loss: 0.635074\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535778; batch adversarial loss: 0.553563\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507978; batch adversarial loss: 0.634982\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487716; batch adversarial loss: 0.579915\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505414; batch adversarial loss: 0.627299\n",
      "epoch 17; iter: 0; batch classifier loss: 0.449741; batch adversarial loss: 0.593969\n",
      "epoch 18; iter: 0; batch classifier loss: 0.570685; batch adversarial loss: 0.517378\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530331; batch adversarial loss: 0.567004\n",
      "epoch 20; iter: 0; batch classifier loss: 0.535101; batch adversarial loss: 0.618994\n",
      "epoch 21; iter: 0; batch classifier loss: 0.446421; batch adversarial loss: 0.535119\n",
      "epoch 22; iter: 0; batch classifier loss: 0.520195; batch adversarial loss: 0.579129\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467604; batch adversarial loss: 0.496240\n",
      "epoch 24; iter: 0; batch classifier loss: 0.438781; batch adversarial loss: 0.596210\n",
      "epoch 25; iter: 0; batch classifier loss: 0.402421; batch adversarial loss: 0.555825\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506483; batch adversarial loss: 0.555073\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454450; batch adversarial loss: 0.529033\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468154; batch adversarial loss: 0.583055\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460181; batch adversarial loss: 0.624780\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421169; batch adversarial loss: 0.538096\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494137; batch adversarial loss: 0.620647\n",
      "epoch 32; iter: 0; batch classifier loss: 0.544646; batch adversarial loss: 0.524217\n",
      "epoch 33; iter: 0; batch classifier loss: 0.512521; batch adversarial loss: 0.536374\n",
      "epoch 34; iter: 0; batch classifier loss: 0.504640; batch adversarial loss: 0.505475\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452877; batch adversarial loss: 0.545604\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451301; batch adversarial loss: 0.529202\n",
      "epoch 37; iter: 0; batch classifier loss: 0.482738; batch adversarial loss: 0.485481\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470552; batch adversarial loss: 0.561840\n",
      "epoch 39; iter: 0; batch classifier loss: 0.472515; batch adversarial loss: 0.579403\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420512; batch adversarial loss: 0.571262\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459051; batch adversarial loss: 0.509033\n",
      "epoch 42; iter: 0; batch classifier loss: 0.561768; batch adversarial loss: 0.544608\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431892; batch adversarial loss: 0.525948\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450779; batch adversarial loss: 0.535897\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424017; batch adversarial loss: 0.517004\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424145; batch adversarial loss: 0.488860\n",
      "epoch 47; iter: 0; batch classifier loss: 0.509813; batch adversarial loss: 0.517379\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383019; batch adversarial loss: 0.518558\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468318; batch adversarial loss: 0.500360\n",
      "epoch 50; iter: 0; batch classifier loss: 0.445023; batch adversarial loss: 0.588561\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481261; batch adversarial loss: 0.525437\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407209; batch adversarial loss: 0.533664\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406993; batch adversarial loss: 0.498408\n",
      "epoch 54; iter: 0; batch classifier loss: 0.458168; batch adversarial loss: 0.616857\n",
      "epoch 55; iter: 0; batch classifier loss: 0.494466; batch adversarial loss: 0.553084\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440773; batch adversarial loss: 0.616455\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424545; batch adversarial loss: 0.603515\n",
      "epoch 58; iter: 0; batch classifier loss: 0.416838; batch adversarial loss: 0.500618\n",
      "epoch 59; iter: 0; batch classifier loss: 0.453644; batch adversarial loss: 0.524629\n",
      "epoch 60; iter: 0; batch classifier loss: 0.337646; batch adversarial loss: 0.571419\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420424; batch adversarial loss: 0.533881\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424115; batch adversarial loss: 0.500347\n",
      "epoch 63; iter: 0; batch classifier loss: 0.470141; batch adversarial loss: 0.500368\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420829; batch adversarial loss: 0.613853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.453810; batch adversarial loss: 0.619893\n",
      "epoch 66; iter: 0; batch classifier loss: 0.438309; batch adversarial loss: 0.610603\n",
      "epoch 67; iter: 0; batch classifier loss: 0.303883; batch adversarial loss: 0.446002\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404425; batch adversarial loss: 0.548863\n",
      "epoch 69; iter: 0; batch classifier loss: 0.494083; batch adversarial loss: 0.543958\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428157; batch adversarial loss: 0.558769\n",
      "epoch 71; iter: 0; batch classifier loss: 0.500765; batch adversarial loss: 0.556510\n",
      "epoch 72; iter: 0; batch classifier loss: 0.508896; batch adversarial loss: 0.487237\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391947; batch adversarial loss: 0.479215\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418180; batch adversarial loss: 0.506649\n",
      "epoch 75; iter: 0; batch classifier loss: 0.286392; batch adversarial loss: 0.525121\n",
      "epoch 76; iter: 0; batch classifier loss: 0.481764; batch adversarial loss: 0.543304\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429042; batch adversarial loss: 0.607808\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402175; batch adversarial loss: 0.637024\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396643; batch adversarial loss: 0.496967\n",
      "epoch 80; iter: 0; batch classifier loss: 0.456124; batch adversarial loss: 0.534820\n",
      "epoch 81; iter: 0; batch classifier loss: 0.479404; batch adversarial loss: 0.545106\n",
      "epoch 82; iter: 0; batch classifier loss: 0.370261; batch adversarial loss: 0.575205\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386840; batch adversarial loss: 0.512324\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446298; batch adversarial loss: 0.515155\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377490; batch adversarial loss: 0.452354\n",
      "epoch 86; iter: 0; batch classifier loss: 0.352380; batch adversarial loss: 0.533616\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413298; batch adversarial loss: 0.619429\n",
      "epoch 88; iter: 0; batch classifier loss: 0.319389; batch adversarial loss: 0.608747\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339231; batch adversarial loss: 0.584322\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367426; batch adversarial loss: 0.544028\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460320; batch adversarial loss: 0.607969\n",
      "epoch 92; iter: 0; batch classifier loss: 0.430871; batch adversarial loss: 0.536490\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363462; batch adversarial loss: 0.510428\n",
      "epoch 94; iter: 0; batch classifier loss: 0.389162; batch adversarial loss: 0.482507\n",
      "epoch 95; iter: 0; batch classifier loss: 0.404517; batch adversarial loss: 0.583841\n",
      "epoch 96; iter: 0; batch classifier loss: 0.340211; batch adversarial loss: 0.509151\n",
      "epoch 97; iter: 0; batch classifier loss: 0.434286; batch adversarial loss: 0.561956\n",
      "epoch 98; iter: 0; batch classifier loss: 0.363359; batch adversarial loss: 0.646103\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384069; batch adversarial loss: 0.563640\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433876; batch adversarial loss: 0.489019\n",
      "epoch 101; iter: 0; batch classifier loss: 0.373588; batch adversarial loss: 0.504819\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398096; batch adversarial loss: 0.535784\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388278; batch adversarial loss: 0.524965\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395259; batch adversarial loss: 0.552045\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385993; batch adversarial loss: 0.555972\n",
      "epoch 106; iter: 0; batch classifier loss: 0.298325; batch adversarial loss: 0.477683\n",
      "epoch 107; iter: 0; batch classifier loss: 0.385532; batch adversarial loss: 0.515234\n",
      "epoch 108; iter: 0; batch classifier loss: 0.468875; batch adversarial loss: 0.489333\n",
      "epoch 109; iter: 0; batch classifier loss: 0.366007; batch adversarial loss: 0.572139\n",
      "epoch 110; iter: 0; batch classifier loss: 0.404626; batch adversarial loss: 0.590303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.399641; batch adversarial loss: 0.525333\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387314; batch adversarial loss: 0.567718\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352452; batch adversarial loss: 0.514184\n",
      "epoch 114; iter: 0; batch classifier loss: 0.438258; batch adversarial loss: 0.532677\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412122; batch adversarial loss: 0.562226\n",
      "epoch 116; iter: 0; batch classifier loss: 0.397775; batch adversarial loss: 0.552956\n",
      "epoch 117; iter: 0; batch classifier loss: 0.401342; batch adversarial loss: 0.569295\n",
      "epoch 118; iter: 0; batch classifier loss: 0.424676; batch adversarial loss: 0.582790\n",
      "epoch 119; iter: 0; batch classifier loss: 0.357967; batch adversarial loss: 0.506560\n",
      "epoch 120; iter: 0; batch classifier loss: 0.432486; batch adversarial loss: 0.533720\n",
      "epoch 121; iter: 0; batch classifier loss: 0.457202; batch adversarial loss: 0.461563\n",
      "epoch 122; iter: 0; batch classifier loss: 0.320003; batch adversarial loss: 0.557242\n",
      "epoch 123; iter: 0; batch classifier loss: 0.487920; batch adversarial loss: 0.553915\n",
      "epoch 124; iter: 0; batch classifier loss: 0.415066; batch adversarial loss: 0.559813\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386435; batch adversarial loss: 0.563610\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386292; batch adversarial loss: 0.444808\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379524; batch adversarial loss: 0.477978\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419415; batch adversarial loss: 0.543401\n",
      "epoch 129; iter: 0; batch classifier loss: 0.333532; batch adversarial loss: 0.550729\n",
      "epoch 130; iter: 0; batch classifier loss: 0.443392; batch adversarial loss: 0.488435\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414530; batch adversarial loss: 0.527125\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354233; batch adversarial loss: 0.507779\n",
      "epoch 133; iter: 0; batch classifier loss: 0.342887; batch adversarial loss: 0.541683\n",
      "epoch 134; iter: 0; batch classifier loss: 0.420691; batch adversarial loss: 0.478051\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362749; batch adversarial loss: 0.528481\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396877; batch adversarial loss: 0.472789\n",
      "epoch 137; iter: 0; batch classifier loss: 0.326076; batch adversarial loss: 0.491318\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404890; batch adversarial loss: 0.548313\n",
      "epoch 139; iter: 0; batch classifier loss: 0.398918; batch adversarial loss: 0.535910\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352832; batch adversarial loss: 0.568703\n",
      "epoch 141; iter: 0; batch classifier loss: 0.424667; batch adversarial loss: 0.570587\n",
      "epoch 142; iter: 0; batch classifier loss: 0.390722; batch adversarial loss: 0.537080\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371696; batch adversarial loss: 0.561344\n",
      "epoch 144; iter: 0; batch classifier loss: 0.462120; batch adversarial loss: 0.502355\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381189; batch adversarial loss: 0.509312\n",
      "epoch 146; iter: 0; batch classifier loss: 0.336857; batch adversarial loss: 0.612542\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353621; batch adversarial loss: 0.595107\n",
      "epoch 148; iter: 0; batch classifier loss: 0.418611; batch adversarial loss: 0.523620\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331312; batch adversarial loss: 0.469851\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339482; batch adversarial loss: 0.572711\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370931; batch adversarial loss: 0.611791\n",
      "epoch 152; iter: 0; batch classifier loss: 0.454509; batch adversarial loss: 0.563122\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342837; batch adversarial loss: 0.553914\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379518; batch adversarial loss: 0.596852\n",
      "epoch 155; iter: 0; batch classifier loss: 0.297693; batch adversarial loss: 0.490137\n",
      "epoch 156; iter: 0; batch classifier loss: 0.319597; batch adversarial loss: 0.597647\n",
      "epoch 157; iter: 0; batch classifier loss: 0.357932; batch adversarial loss: 0.435493\n",
      "epoch 158; iter: 0; batch classifier loss: 0.303110; batch adversarial loss: 0.542872\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329220; batch adversarial loss: 0.517059\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341859; batch adversarial loss: 0.477618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.441373; batch adversarial loss: 0.586346\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386113; batch adversarial loss: 0.601099\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382369; batch adversarial loss: 0.526941\n",
      "epoch 164; iter: 0; batch classifier loss: 0.431820; batch adversarial loss: 0.517480\n",
      "epoch 165; iter: 0; batch classifier loss: 0.459559; batch adversarial loss: 0.568100\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364141; batch adversarial loss: 0.578650\n",
      "epoch 167; iter: 0; batch classifier loss: 0.400133; batch adversarial loss: 0.589308\n",
      "epoch 168; iter: 0; batch classifier loss: 0.311747; batch adversarial loss: 0.470858\n",
      "epoch 169; iter: 0; batch classifier loss: 0.345816; batch adversarial loss: 0.536182\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360310; batch adversarial loss: 0.544411\n",
      "epoch 171; iter: 0; batch classifier loss: 0.393146; batch adversarial loss: 0.486832\n",
      "epoch 172; iter: 0; batch classifier loss: 0.343653; batch adversarial loss: 0.543360\n",
      "epoch 173; iter: 0; batch classifier loss: 0.398003; batch adversarial loss: 0.470820\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326918; batch adversarial loss: 0.551488\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335306; batch adversarial loss: 0.524112\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341939; batch adversarial loss: 0.506524\n",
      "epoch 177; iter: 0; batch classifier loss: 0.327899; batch adversarial loss: 0.574944\n",
      "epoch 178; iter: 0; batch classifier loss: 0.365747; batch adversarial loss: 0.582555\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330050; batch adversarial loss: 0.571927\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387843; batch adversarial loss: 0.543471\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370218; batch adversarial loss: 0.564328\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370158; batch adversarial loss: 0.470840\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337549; batch adversarial loss: 0.511108\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344378; batch adversarial loss: 0.491090\n",
      "epoch 185; iter: 0; batch classifier loss: 0.429715; batch adversarial loss: 0.568024\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368233; batch adversarial loss: 0.526893\n",
      "epoch 187; iter: 0; batch classifier loss: 0.379073; batch adversarial loss: 0.463397\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336447; batch adversarial loss: 0.587633\n",
      "epoch 189; iter: 0; batch classifier loss: 0.449425; batch adversarial loss: 0.554537\n",
      "epoch 190; iter: 0; batch classifier loss: 0.401388; batch adversarial loss: 0.557164\n",
      "epoch 191; iter: 0; batch classifier loss: 0.471374; batch adversarial loss: 0.479277\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387358; batch adversarial loss: 0.535065\n",
      "epoch 193; iter: 0; batch classifier loss: 0.425016; batch adversarial loss: 0.516525\n",
      "epoch 194; iter: 0; batch classifier loss: 0.386219; batch adversarial loss: 0.526670\n",
      "epoch 195; iter: 0; batch classifier loss: 0.424573; batch adversarial loss: 0.514493\n",
      "epoch 196; iter: 0; batch classifier loss: 0.302530; batch adversarial loss: 0.533802\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318859; batch adversarial loss: 0.497522\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355801; batch adversarial loss: 0.551394\n",
      "epoch 199; iter: 0; batch classifier loss: 0.401112; batch adversarial loss: 0.608810\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736542; batch adversarial loss: 0.631490\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537534; batch adversarial loss: 0.645878\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600354; batch adversarial loss: 0.648706\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582414; batch adversarial loss: 0.666514\n",
      "epoch 4; iter: 0; batch classifier loss: 0.488963; batch adversarial loss: 0.645165\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561029; batch adversarial loss: 0.608476\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537442; batch adversarial loss: 0.593329\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559735; batch adversarial loss: 0.572811\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505263; batch adversarial loss: 0.617746\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552798; batch adversarial loss: 0.587397\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544934; batch adversarial loss: 0.585190\n",
      "epoch 11; iter: 0; batch classifier loss: 0.597065; batch adversarial loss: 0.545772\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499686; batch adversarial loss: 0.583639\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540178; batch adversarial loss: 0.548277\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473134; batch adversarial loss: 0.572383\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500458; batch adversarial loss: 0.510807\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528583; batch adversarial loss: 0.519331\n",
      "epoch 17; iter: 0; batch classifier loss: 0.450457; batch adversarial loss: 0.527496\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487984; batch adversarial loss: 0.602100\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545286; batch adversarial loss: 0.503431\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489475; batch adversarial loss: 0.550719\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491038; batch adversarial loss: 0.446752\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474213; batch adversarial loss: 0.557177\n",
      "epoch 23; iter: 0; batch classifier loss: 0.500660; batch adversarial loss: 0.622929\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491464; batch adversarial loss: 0.581317\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495276; batch adversarial loss: 0.527488\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475358; batch adversarial loss: 0.564632\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509290; batch adversarial loss: 0.587733\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468592; batch adversarial loss: 0.491682\n",
      "epoch 29; iter: 0; batch classifier loss: 0.399150; batch adversarial loss: 0.565507\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431030; batch adversarial loss: 0.557383\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432146; batch adversarial loss: 0.530767\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500709; batch adversarial loss: 0.579338\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420963; batch adversarial loss: 0.546125\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416035; batch adversarial loss: 0.534546\n",
      "epoch 35; iter: 0; batch classifier loss: 0.409907; batch adversarial loss: 0.573210\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451252; batch adversarial loss: 0.497994\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438874; batch adversarial loss: 0.517705\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498384; batch adversarial loss: 0.553622\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449853; batch adversarial loss: 0.535359\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462731; batch adversarial loss: 0.526817\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438486; batch adversarial loss: 0.580221\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436617; batch adversarial loss: 0.610247\n",
      "epoch 43; iter: 0; batch classifier loss: 0.543260; batch adversarial loss: 0.489321\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433727; batch adversarial loss: 0.524991\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448303; batch adversarial loss: 0.535008\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377054; batch adversarial loss: 0.516960\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443791; batch adversarial loss: 0.638233\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403280; batch adversarial loss: 0.572942\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384281; batch adversarial loss: 0.553634\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472418; batch adversarial loss: 0.609935\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432190; batch adversarial loss: 0.488413\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391587; batch adversarial loss: 0.488516\n",
      "epoch 53; iter: 0; batch classifier loss: 0.541159; batch adversarial loss: 0.611179\n",
      "epoch 54; iter: 0; batch classifier loss: 0.334841; batch adversarial loss: 0.555011\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439130; batch adversarial loss: 0.516781\n",
      "epoch 56; iter: 0; batch classifier loss: 0.500493; batch adversarial loss: 0.535730\n",
      "epoch 57; iter: 0; batch classifier loss: 0.509730; batch adversarial loss: 0.474769\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448102; batch adversarial loss: 0.526731\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401160; batch adversarial loss: 0.515902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.393441; batch adversarial loss: 0.561813\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410871; batch adversarial loss: 0.497464\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393572; batch adversarial loss: 0.592391\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435255; batch adversarial loss: 0.480053\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438313; batch adversarial loss: 0.528194\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397992; batch adversarial loss: 0.580263\n",
      "epoch 66; iter: 0; batch classifier loss: 0.359276; batch adversarial loss: 0.495505\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360777; batch adversarial loss: 0.513718\n",
      "epoch 68; iter: 0; batch classifier loss: 0.458858; batch adversarial loss: 0.582248\n",
      "epoch 69; iter: 0; batch classifier loss: 0.408501; batch adversarial loss: 0.538197\n",
      "epoch 70; iter: 0; batch classifier loss: 0.361374; batch adversarial loss: 0.612083\n",
      "epoch 71; iter: 0; batch classifier loss: 0.401172; batch adversarial loss: 0.573217\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386509; batch adversarial loss: 0.498061\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400374; batch adversarial loss: 0.507716\n",
      "epoch 74; iter: 0; batch classifier loss: 0.409258; batch adversarial loss: 0.525403\n",
      "epoch 75; iter: 0; batch classifier loss: 0.488319; batch adversarial loss: 0.545132\n",
      "epoch 76; iter: 0; batch classifier loss: 0.456742; batch adversarial loss: 0.544606\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458243; batch adversarial loss: 0.525899\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393702; batch adversarial loss: 0.553049\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358615; batch adversarial loss: 0.497745\n",
      "epoch 80; iter: 0; batch classifier loss: 0.433244; batch adversarial loss: 0.572687\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370817; batch adversarial loss: 0.525674\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416186; batch adversarial loss: 0.488061\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371467; batch adversarial loss: 0.515987\n",
      "epoch 84; iter: 0; batch classifier loss: 0.344999; batch adversarial loss: 0.621269\n",
      "epoch 85; iter: 0; batch classifier loss: 0.354211; batch adversarial loss: 0.468853\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353741; batch adversarial loss: 0.571908\n",
      "epoch 87; iter: 0; batch classifier loss: 0.337810; batch adversarial loss: 0.544506\n",
      "epoch 88; iter: 0; batch classifier loss: 0.452456; batch adversarial loss: 0.612027\n",
      "epoch 89; iter: 0; batch classifier loss: 0.315050; batch adversarial loss: 0.610606\n",
      "epoch 90; iter: 0; batch classifier loss: 0.406533; batch adversarial loss: 0.534228\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385611; batch adversarial loss: 0.458411\n",
      "epoch 92; iter: 0; batch classifier loss: 0.473564; batch adversarial loss: 0.612203\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340059; batch adversarial loss: 0.497033\n",
      "epoch 94; iter: 0; batch classifier loss: 0.308330; batch adversarial loss: 0.459893\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347753; batch adversarial loss: 0.583218\n",
      "epoch 96; iter: 0; batch classifier loss: 0.357323; batch adversarial loss: 0.524983\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367413; batch adversarial loss: 0.535725\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370517; batch adversarial loss: 0.527444\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402287; batch adversarial loss: 0.498354\n",
      "epoch 100; iter: 0; batch classifier loss: 0.344266; batch adversarial loss: 0.571578\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390854; batch adversarial loss: 0.582417\n",
      "epoch 102; iter: 0; batch classifier loss: 0.440380; batch adversarial loss: 0.507134\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379197; batch adversarial loss: 0.497101\n",
      "epoch 104; iter: 0; batch classifier loss: 0.321055; batch adversarial loss: 0.544283\n",
      "epoch 105; iter: 0; batch classifier loss: 0.328828; batch adversarial loss: 0.506673\n",
      "epoch 106; iter: 0; batch classifier loss: 0.351713; batch adversarial loss: 0.563068\n",
      "epoch 107; iter: 0; batch classifier loss: 0.401325; batch adversarial loss: 0.572679\n",
      "epoch 108; iter: 0; batch classifier loss: 0.475859; batch adversarial loss: 0.553774\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365624; batch adversarial loss: 0.545454\n",
      "epoch 110; iter: 0; batch classifier loss: 0.332916; batch adversarial loss: 0.535729\n",
      "epoch 111; iter: 0; batch classifier loss: 0.499714; batch adversarial loss: 0.572419\n",
      "epoch 112; iter: 0; batch classifier loss: 0.277436; batch adversarial loss: 0.469099\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374632; batch adversarial loss: 0.610682\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372406; batch adversarial loss: 0.535706\n",
      "epoch 115; iter: 0; batch classifier loss: 0.369027; batch adversarial loss: 0.553846\n",
      "epoch 116; iter: 0; batch classifier loss: 0.315180; batch adversarial loss: 0.506870\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357723; batch adversarial loss: 0.506282\n",
      "epoch 118; iter: 0; batch classifier loss: 0.448412; batch adversarial loss: 0.515771\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352184; batch adversarial loss: 0.534875\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383259; batch adversarial loss: 0.507446\n",
      "epoch 121; iter: 0; batch classifier loss: 0.421065; batch adversarial loss: 0.582811\n",
      "epoch 122; iter: 0; batch classifier loss: 0.313116; batch adversarial loss: 0.583095\n",
      "epoch 123; iter: 0; batch classifier loss: 0.328158; batch adversarial loss: 0.497662\n",
      "epoch 124; iter: 0; batch classifier loss: 0.424393; batch adversarial loss: 0.553322\n",
      "epoch 125; iter: 0; batch classifier loss: 0.433452; batch adversarial loss: 0.535176\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372942; batch adversarial loss: 0.582809\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356303; batch adversarial loss: 0.478070\n",
      "epoch 128; iter: 0; batch classifier loss: 0.384892; batch adversarial loss: 0.563279\n",
      "epoch 129; iter: 0; batch classifier loss: 0.412690; batch adversarial loss: 0.590372\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393869; batch adversarial loss: 0.553828\n",
      "epoch 131; iter: 0; batch classifier loss: 0.305022; batch adversarial loss: 0.449223\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364033; batch adversarial loss: 0.516860\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347189; batch adversarial loss: 0.563616\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366443; batch adversarial loss: 0.507346\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380382; batch adversarial loss: 0.554535\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387036; batch adversarial loss: 0.610614\n",
      "epoch 137; iter: 0; batch classifier loss: 0.323967; batch adversarial loss: 0.544513\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414192; batch adversarial loss: 0.563869\n",
      "epoch 139; iter: 0; batch classifier loss: 0.375771; batch adversarial loss: 0.525389\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397094; batch adversarial loss: 0.449963\n",
      "epoch 141; iter: 0; batch classifier loss: 0.362797; batch adversarial loss: 0.535442\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367287; batch adversarial loss: 0.535295\n",
      "epoch 143; iter: 0; batch classifier loss: 0.393635; batch adversarial loss: 0.563710\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377416; batch adversarial loss: 0.496771\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349131; batch adversarial loss: 0.526104\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395382; batch adversarial loss: 0.516721\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393126; batch adversarial loss: 0.488633\n",
      "epoch 148; iter: 0; batch classifier loss: 0.422781; batch adversarial loss: 0.449930\n",
      "epoch 149; iter: 0; batch classifier loss: 0.454394; batch adversarial loss: 0.487704\n",
      "epoch 150; iter: 0; batch classifier loss: 0.332728; batch adversarial loss: 0.563511\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356341; batch adversarial loss: 0.506447\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326931; batch adversarial loss: 0.516345\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391395; batch adversarial loss: 0.553305\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298409; batch adversarial loss: 0.610966\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337494; batch adversarial loss: 0.497382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.400650; batch adversarial loss: 0.487538\n",
      "epoch 157; iter: 0; batch classifier loss: 0.323590; batch adversarial loss: 0.440477\n",
      "epoch 158; iter: 0; batch classifier loss: 0.467325; batch adversarial loss: 0.563039\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349853; batch adversarial loss: 0.591601\n",
      "epoch 160; iter: 0; batch classifier loss: 0.317102; batch adversarial loss: 0.525061\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391406; batch adversarial loss: 0.563191\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397186; batch adversarial loss: 0.555221\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330123; batch adversarial loss: 0.630080\n",
      "epoch 164; iter: 0; batch classifier loss: 0.276399; batch adversarial loss: 0.535324\n",
      "epoch 165; iter: 0; batch classifier loss: 0.312458; batch adversarial loss: 0.459217\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351839; batch adversarial loss: 0.535095\n",
      "epoch 167; iter: 0; batch classifier loss: 0.502259; batch adversarial loss: 0.553087\n",
      "epoch 168; iter: 0; batch classifier loss: 0.290798; batch adversarial loss: 0.554104\n",
      "epoch 169; iter: 0; batch classifier loss: 0.383414; batch adversarial loss: 0.544466\n",
      "epoch 170; iter: 0; batch classifier loss: 0.288654; batch adversarial loss: 0.601348\n",
      "epoch 171; iter: 0; batch classifier loss: 0.325818; batch adversarial loss: 0.506787\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394986; batch adversarial loss: 0.553587\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333604; batch adversarial loss: 0.543638\n",
      "epoch 174; iter: 0; batch classifier loss: 0.445391; batch adversarial loss: 0.638413\n",
      "epoch 175; iter: 0; batch classifier loss: 0.421020; batch adversarial loss: 0.525718\n",
      "epoch 176; iter: 0; batch classifier loss: 0.352043; batch adversarial loss: 0.610319\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417673; batch adversarial loss: 0.544270\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376168; batch adversarial loss: 0.572819\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366034; batch adversarial loss: 0.563487\n",
      "epoch 180; iter: 0; batch classifier loss: 0.312243; batch adversarial loss: 0.554390\n",
      "epoch 181; iter: 0; batch classifier loss: 0.315373; batch adversarial loss: 0.553709\n",
      "epoch 182; iter: 0; batch classifier loss: 0.386266; batch adversarial loss: 0.563431\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344591; batch adversarial loss: 0.496971\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363193; batch adversarial loss: 0.506900\n",
      "epoch 185; iter: 0; batch classifier loss: 0.410526; batch adversarial loss: 0.536071\n",
      "epoch 186; iter: 0; batch classifier loss: 0.322079; batch adversarial loss: 0.535280\n",
      "epoch 187; iter: 0; batch classifier loss: 0.398416; batch adversarial loss: 0.525810\n",
      "epoch 188; iter: 0; batch classifier loss: 0.292217; batch adversarial loss: 0.647994\n",
      "epoch 189; iter: 0; batch classifier loss: 0.456328; batch adversarial loss: 0.525827\n",
      "epoch 190; iter: 0; batch classifier loss: 0.272305; batch adversarial loss: 0.544768\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373995; batch adversarial loss: 0.544755\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359900; batch adversarial loss: 0.620484\n",
      "epoch 193; iter: 0; batch classifier loss: 0.281887; batch adversarial loss: 0.507040\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366403; batch adversarial loss: 0.535190\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334268; batch adversarial loss: 0.573077\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383280; batch adversarial loss: 0.610753\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355395; batch adversarial loss: 0.478156\n",
      "epoch 198; iter: 0; batch classifier loss: 0.314470; batch adversarial loss: 0.525858\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359012; batch adversarial loss: 0.505994\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658627; batch adversarial loss: 0.791043\n",
      "epoch 1; iter: 0; batch classifier loss: 0.798436; batch adversarial loss: 0.994958\n",
      "epoch 2; iter: 0; batch classifier loss: 0.924984; batch adversarial loss: 0.964274\n",
      "epoch 3; iter: 0; batch classifier loss: 0.907562; batch adversarial loss: 0.892523\n",
      "epoch 4; iter: 0; batch classifier loss: 0.786607; batch adversarial loss: 0.797676\n",
      "epoch 5; iter: 0; batch classifier loss: 0.703394; batch adversarial loss: 0.708797\n",
      "epoch 6; iter: 0; batch classifier loss: 0.637399; batch adversarial loss: 0.672531\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559745; batch adversarial loss: 0.629933\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578145; batch adversarial loss: 0.639026\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534208; batch adversarial loss: 0.603043\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510707; batch adversarial loss: 0.588210\n",
      "epoch 11; iter: 0; batch classifier loss: 0.594347; batch adversarial loss: 0.584745\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575161; batch adversarial loss: 0.595627\n",
      "epoch 13; iter: 0; batch classifier loss: 0.438484; batch adversarial loss: 0.605934\n",
      "epoch 14; iter: 0; batch classifier loss: 0.496216; batch adversarial loss: 0.597962\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538292; batch adversarial loss: 0.563087\n",
      "epoch 16; iter: 0; batch classifier loss: 0.559316; batch adversarial loss: 0.590410\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508416; batch adversarial loss: 0.586357\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534709; batch adversarial loss: 0.555004\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472729; batch adversarial loss: 0.558598\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484097; batch adversarial loss: 0.567456\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494714; batch adversarial loss: 0.503337\n",
      "epoch 22; iter: 0; batch classifier loss: 0.412897; batch adversarial loss: 0.641397\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480016; batch adversarial loss: 0.565930\n",
      "epoch 24; iter: 0; batch classifier loss: 0.530085; batch adversarial loss: 0.504475\n",
      "epoch 25; iter: 0; batch classifier loss: 0.544654; batch adversarial loss: 0.564097\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461827; batch adversarial loss: 0.556937\n",
      "epoch 27; iter: 0; batch classifier loss: 0.399277; batch adversarial loss: 0.456098\n",
      "epoch 28; iter: 0; batch classifier loss: 0.502658; batch adversarial loss: 0.563823\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490410; batch adversarial loss: 0.555808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503495; batch adversarial loss: 0.552430\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476705; batch adversarial loss: 0.502842\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425905; batch adversarial loss: 0.493258\n",
      "epoch 33; iter: 0; batch classifier loss: 0.411290; batch adversarial loss: 0.528100\n",
      "epoch 34; iter: 0; batch classifier loss: 0.548766; batch adversarial loss: 0.587759\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469957; batch adversarial loss: 0.580353\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428489; batch adversarial loss: 0.562037\n",
      "epoch 37; iter: 0; batch classifier loss: 0.521438; batch adversarial loss: 0.459244\n",
      "epoch 38; iter: 0; batch classifier loss: 0.500227; batch adversarial loss: 0.448125\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470322; batch adversarial loss: 0.581264\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454672; batch adversarial loss: 0.491517\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477016; batch adversarial loss: 0.527697\n",
      "epoch 42; iter: 0; batch classifier loss: 0.363738; batch adversarial loss: 0.527191\n",
      "epoch 43; iter: 0; batch classifier loss: 0.472304; batch adversarial loss: 0.554888\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414357; batch adversarial loss: 0.535005\n",
      "epoch 45; iter: 0; batch classifier loss: 0.379079; batch adversarial loss: 0.535076\n",
      "epoch 46; iter: 0; batch classifier loss: 0.435418; batch adversarial loss: 0.546393\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461652; batch adversarial loss: 0.597946\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450855; batch adversarial loss: 0.581393\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465575; batch adversarial loss: 0.564586\n",
      "epoch 50; iter: 0; batch classifier loss: 0.381117; batch adversarial loss: 0.543686\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446482; batch adversarial loss: 0.571649\n",
      "epoch 52; iter: 0; batch classifier loss: 0.503334; batch adversarial loss: 0.616865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.432748; batch adversarial loss: 0.580353\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430333; batch adversarial loss: 0.525905\n",
      "epoch 55; iter: 0; batch classifier loss: 0.514898; batch adversarial loss: 0.499535\n",
      "epoch 56; iter: 0; batch classifier loss: 0.480301; batch adversarial loss: 0.599242\n",
      "epoch 57; iter: 0; batch classifier loss: 0.480072; batch adversarial loss: 0.553929\n",
      "epoch 58; iter: 0; batch classifier loss: 0.331815; batch adversarial loss: 0.573270\n",
      "epoch 59; iter: 0; batch classifier loss: 0.526557; batch adversarial loss: 0.624001\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383336; batch adversarial loss: 0.508242\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381733; batch adversarial loss: 0.577354\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440313; batch adversarial loss: 0.549833\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418152; batch adversarial loss: 0.576108\n",
      "epoch 64; iter: 0; batch classifier loss: 0.312618; batch adversarial loss: 0.481404\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428285; batch adversarial loss: 0.480720\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381413; batch adversarial loss: 0.480491\n",
      "epoch 67; iter: 0; batch classifier loss: 0.503462; batch adversarial loss: 0.473836\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418020; batch adversarial loss: 0.545042\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405116; batch adversarial loss: 0.510736\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377783; batch adversarial loss: 0.565187\n",
      "epoch 71; iter: 0; batch classifier loss: 0.452948; batch adversarial loss: 0.533863\n",
      "epoch 72; iter: 0; batch classifier loss: 0.341024; batch adversarial loss: 0.467289\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437560; batch adversarial loss: 0.572827\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386638; batch adversarial loss: 0.536422\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407999; batch adversarial loss: 0.573020\n",
      "epoch 76; iter: 0; batch classifier loss: 0.362712; batch adversarial loss: 0.451809\n",
      "epoch 77; iter: 0; batch classifier loss: 0.373213; batch adversarial loss: 0.553329\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427101; batch adversarial loss: 0.554414\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377008; batch adversarial loss: 0.497731\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381293; batch adversarial loss: 0.618554\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378116; batch adversarial loss: 0.543423\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422914; batch adversarial loss: 0.508973\n",
      "epoch 83; iter: 0; batch classifier loss: 0.350817; batch adversarial loss: 0.655761\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391579; batch adversarial loss: 0.552959\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419019; batch adversarial loss: 0.535544\n",
      "epoch 86; iter: 0; batch classifier loss: 0.465449; batch adversarial loss: 0.545157\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384069; batch adversarial loss: 0.534611\n",
      "epoch 88; iter: 0; batch classifier loss: 0.341662; batch adversarial loss: 0.674080\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429602; batch adversarial loss: 0.571098\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402636; batch adversarial loss: 0.543344\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399092; batch adversarial loss: 0.497534\n",
      "epoch 92; iter: 0; batch classifier loss: 0.423803; batch adversarial loss: 0.525640\n",
      "epoch 93; iter: 0; batch classifier loss: 0.348394; batch adversarial loss: 0.544480\n",
      "epoch 94; iter: 0; batch classifier loss: 0.487168; batch adversarial loss: 0.498761\n",
      "epoch 95; iter: 0; batch classifier loss: 0.341019; batch adversarial loss: 0.471047\n",
      "epoch 96; iter: 0; batch classifier loss: 0.490877; batch adversarial loss: 0.553817\n",
      "epoch 97; iter: 0; batch classifier loss: 0.431992; batch adversarial loss: 0.551883\n",
      "epoch 98; iter: 0; batch classifier loss: 0.355793; batch adversarial loss: 0.563498\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312680; batch adversarial loss: 0.497200\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382939; batch adversarial loss: 0.508653\n",
      "epoch 101; iter: 0; batch classifier loss: 0.304165; batch adversarial loss: 0.508150\n",
      "epoch 102; iter: 0; batch classifier loss: 0.364867; batch adversarial loss: 0.551608\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352205; batch adversarial loss: 0.526620\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416001; batch adversarial loss: 0.564737\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368300; batch adversarial loss: 0.571320\n",
      "epoch 106; iter: 0; batch classifier loss: 0.463088; batch adversarial loss: 0.553782\n",
      "epoch 107; iter: 0; batch classifier loss: 0.409897; batch adversarial loss: 0.662556\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373909; batch adversarial loss: 0.554148\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386090; batch adversarial loss: 0.508509\n",
      "epoch 110; iter: 0; batch classifier loss: 0.376841; batch adversarial loss: 0.552548\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375869; batch adversarial loss: 0.535712\n",
      "epoch 112; iter: 0; batch classifier loss: 0.416547; batch adversarial loss: 0.499076\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366663; batch adversarial loss: 0.635885\n",
      "epoch 114; iter: 0; batch classifier loss: 0.308230; batch adversarial loss: 0.644955\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404850; batch adversarial loss: 0.562958\n",
      "epoch 116; iter: 0; batch classifier loss: 0.442517; batch adversarial loss: 0.581280\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367249; batch adversarial loss: 0.627621\n",
      "epoch 118; iter: 0; batch classifier loss: 0.399240; batch adversarial loss: 0.517328\n",
      "epoch 119; iter: 0; batch classifier loss: 0.333662; batch adversarial loss: 0.600410\n",
      "epoch 120; iter: 0; batch classifier loss: 0.268587; batch adversarial loss: 0.471243\n",
      "epoch 121; iter: 0; batch classifier loss: 0.386947; batch adversarial loss: 0.516451\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352647; batch adversarial loss: 0.599090\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380150; batch adversarial loss: 0.451257\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398808; batch adversarial loss: 0.572245\n",
      "epoch 125; iter: 0; batch classifier loss: 0.318496; batch adversarial loss: 0.451361\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353750; batch adversarial loss: 0.490387\n",
      "epoch 127; iter: 0; batch classifier loss: 0.486699; batch adversarial loss: 0.516316\n",
      "epoch 128; iter: 0; batch classifier loss: 0.374344; batch adversarial loss: 0.618955\n",
      "epoch 129; iter: 0; batch classifier loss: 0.453199; batch adversarial loss: 0.587839\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360913; batch adversarial loss: 0.499251\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335541; batch adversarial loss: 0.462774\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388871; batch adversarial loss: 0.541125\n",
      "epoch 133; iter: 0; batch classifier loss: 0.456986; batch adversarial loss: 0.637021\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357392; batch adversarial loss: 0.554316\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413736; batch adversarial loss: 0.499917\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372543; batch adversarial loss: 0.498633\n",
      "epoch 137; iter: 0; batch classifier loss: 0.309393; batch adversarial loss: 0.508763\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348745; batch adversarial loss: 0.562889\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335143; batch adversarial loss: 0.518101\n",
      "epoch 140; iter: 0; batch classifier loss: 0.350683; batch adversarial loss: 0.562946\n",
      "epoch 141; iter: 0; batch classifier loss: 0.316807; batch adversarial loss: 0.508933\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359264; batch adversarial loss: 0.571360\n",
      "epoch 143; iter: 0; batch classifier loss: 0.320115; batch adversarial loss: 0.544086\n",
      "epoch 144; iter: 0; batch classifier loss: 0.294537; batch adversarial loss: 0.582037\n",
      "epoch 145; iter: 0; batch classifier loss: 0.344815; batch adversarial loss: 0.609077\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379995; batch adversarial loss: 0.627114\n",
      "epoch 147; iter: 0; batch classifier loss: 0.341433; batch adversarial loss: 0.617892\n",
      "epoch 148; iter: 0; batch classifier loss: 0.361921; batch adversarial loss: 0.538234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.315838; batch adversarial loss: 0.599597\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373653; batch adversarial loss: 0.537415\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370421; batch adversarial loss: 0.562274\n",
      "epoch 152; iter: 0; batch classifier loss: 0.310156; batch adversarial loss: 0.461892\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342273; batch adversarial loss: 0.563624\n",
      "epoch 154; iter: 0; batch classifier loss: 0.281838; batch adversarial loss: 0.572861\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412011; batch adversarial loss: 0.590866\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348846; batch adversarial loss: 0.507683\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377329; batch adversarial loss: 0.525614\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354109; batch adversarial loss: 0.507681\n",
      "epoch 159; iter: 0; batch classifier loss: 0.262437; batch adversarial loss: 0.480303\n",
      "epoch 160; iter: 0; batch classifier loss: 0.279634; batch adversarial loss: 0.553994\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316770; batch adversarial loss: 0.543761\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358429; batch adversarial loss: 0.535414\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319022; batch adversarial loss: 0.518062\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350037; batch adversarial loss: 0.570280\n",
      "epoch 165; iter: 0; batch classifier loss: 0.303093; batch adversarial loss: 0.583450\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322824; batch adversarial loss: 0.535939\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379944; batch adversarial loss: 0.572637\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378475; batch adversarial loss: 0.479420\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327168; batch adversarial loss: 0.434137\n",
      "epoch 170; iter: 0; batch classifier loss: 0.287610; batch adversarial loss: 0.545365\n",
      "epoch 171; iter: 0; batch classifier loss: 0.331104; batch adversarial loss: 0.598561\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362091; batch adversarial loss: 0.516974\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339119; batch adversarial loss: 0.517323\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345303; batch adversarial loss: 0.507895\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360897; batch adversarial loss: 0.533706\n",
      "epoch 176; iter: 0; batch classifier loss: 0.261538; batch adversarial loss: 0.552284\n",
      "epoch 177; iter: 0; batch classifier loss: 0.368776; batch adversarial loss: 0.551876\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389230; batch adversarial loss: 0.498033\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333244; batch adversarial loss: 0.587332\n",
      "epoch 180; iter: 0; batch classifier loss: 0.426989; batch adversarial loss: 0.453201\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322483; batch adversarial loss: 0.543297\n",
      "epoch 182; iter: 0; batch classifier loss: 0.369799; batch adversarial loss: 0.509435\n",
      "epoch 183; iter: 0; batch classifier loss: 0.360260; batch adversarial loss: 0.617987\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376983; batch adversarial loss: 0.507988\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352976; batch adversarial loss: 0.552415\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399628; batch adversarial loss: 0.553719\n",
      "epoch 187; iter: 0; batch classifier loss: 0.437891; batch adversarial loss: 0.549879\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365096; batch adversarial loss: 0.537518\n",
      "epoch 189; iter: 0; batch classifier loss: 0.317934; batch adversarial loss: 0.516779\n",
      "epoch 190; iter: 0; batch classifier loss: 0.356358; batch adversarial loss: 0.609946\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366857; batch adversarial loss: 0.481792\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371282; batch adversarial loss: 0.563042\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376147; batch adversarial loss: 0.590305\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316636; batch adversarial loss: 0.517398\n",
      "epoch 195; iter: 0; batch classifier loss: 0.409249; batch adversarial loss: 0.480229\n",
      "epoch 196; iter: 0; batch classifier loss: 0.308389; batch adversarial loss: 0.563305\n",
      "epoch 197; iter: 0; batch classifier loss: 0.275277; batch adversarial loss: 0.592068\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321093; batch adversarial loss: 0.480769\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379801; batch adversarial loss: 0.553810\n",
      "epoch 0; iter: 0; batch classifier loss: 0.804673; batch adversarial loss: 1.251250\n",
      "epoch 1; iter: 0; batch classifier loss: 0.963593; batch adversarial loss: 1.440192\n",
      "epoch 2; iter: 0; batch classifier loss: 1.133423; batch adversarial loss: 1.420194\n",
      "epoch 3; iter: 0; batch classifier loss: 1.116153; batch adversarial loss: 1.380769\n",
      "epoch 4; iter: 0; batch classifier loss: 1.062425; batch adversarial loss: 1.263444\n",
      "epoch 5; iter: 0; batch classifier loss: 1.082557; batch adversarial loss: 1.161654\n",
      "epoch 6; iter: 0; batch classifier loss: 1.182102; batch adversarial loss: 1.060359\n",
      "epoch 7; iter: 0; batch classifier loss: 1.283810; batch adversarial loss: 0.964397\n",
      "epoch 8; iter: 0; batch classifier loss: 1.047769; batch adversarial loss: 0.906576\n",
      "epoch 9; iter: 0; batch classifier loss: 1.049259; batch adversarial loss: 0.848175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.973550; batch adversarial loss: 0.809727\n",
      "epoch 11; iter: 0; batch classifier loss: 0.908718; batch adversarial loss: 0.755171\n",
      "epoch 12; iter: 0; batch classifier loss: 0.850289; batch adversarial loss: 0.675636\n",
      "epoch 13; iter: 0; batch classifier loss: 0.780811; batch adversarial loss: 0.697027\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579518; batch adversarial loss: 0.636041\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543969; batch adversarial loss: 0.615118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522906; batch adversarial loss: 0.573030\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533419; batch adversarial loss: 0.597427\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502952; batch adversarial loss: 0.590167\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525454; batch adversarial loss: 0.563137\n",
      "epoch 20; iter: 0; batch classifier loss: 0.558245; batch adversarial loss: 0.574630\n",
      "epoch 21; iter: 0; batch classifier loss: 0.529322; batch adversarial loss: 0.550968\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515379; batch adversarial loss: 0.555458\n",
      "epoch 23; iter: 0; batch classifier loss: 0.546971; batch adversarial loss: 0.554580\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508833; batch adversarial loss: 0.503535\n",
      "epoch 25; iter: 0; batch classifier loss: 0.545412; batch adversarial loss: 0.493810\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445231; batch adversarial loss: 0.529410\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494889; batch adversarial loss: 0.571752\n",
      "epoch 28; iter: 0; batch classifier loss: 0.521259; batch adversarial loss: 0.554973\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456922; batch adversarial loss: 0.552910\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481178; batch adversarial loss: 0.582034\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465582; batch adversarial loss: 0.544962\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479074; batch adversarial loss: 0.485019\n",
      "epoch 33; iter: 0; batch classifier loss: 0.534964; batch adversarial loss: 0.529613\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462611; batch adversarial loss: 0.521470\n",
      "epoch 35; iter: 0; batch classifier loss: 0.532205; batch adversarial loss: 0.554001\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471258; batch adversarial loss: 0.575822\n",
      "epoch 37; iter: 0; batch classifier loss: 0.397859; batch adversarial loss: 0.589937\n",
      "epoch 38; iter: 0; batch classifier loss: 0.564251; batch adversarial loss: 0.476215\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464357; batch adversarial loss: 0.611986\n",
      "epoch 40; iter: 0; batch classifier loss: 0.494347; batch adversarial loss: 0.539647\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443437; batch adversarial loss: 0.476051\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402182; batch adversarial loss: 0.564040\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469106; batch adversarial loss: 0.551026\n",
      "epoch 44; iter: 0; batch classifier loss: 0.425291; batch adversarial loss: 0.501905\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397922; batch adversarial loss: 0.535777\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495260; batch adversarial loss: 0.549032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.389351; batch adversarial loss: 0.543810\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427946; batch adversarial loss: 0.525997\n",
      "epoch 49; iter: 0; batch classifier loss: 0.381499; batch adversarial loss: 0.544572\n",
      "epoch 50; iter: 0; batch classifier loss: 0.387898; batch adversarial loss: 0.478708\n",
      "epoch 51; iter: 0; batch classifier loss: 0.457857; batch adversarial loss: 0.516318\n",
      "epoch 52; iter: 0; batch classifier loss: 0.490989; batch adversarial loss: 0.617549\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461574; batch adversarial loss: 0.573257\n",
      "epoch 54; iter: 0; batch classifier loss: 0.353674; batch adversarial loss: 0.547281\n",
      "epoch 55; iter: 0; batch classifier loss: 0.535613; batch adversarial loss: 0.555206\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412618; batch adversarial loss: 0.524714\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426726; batch adversarial loss: 0.545169\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465656; batch adversarial loss: 0.570896\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468214; batch adversarial loss: 0.508195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427756; batch adversarial loss: 0.591539\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397969; batch adversarial loss: 0.554191\n",
      "epoch 62; iter: 0; batch classifier loss: 0.473669; batch adversarial loss: 0.526404\n",
      "epoch 63; iter: 0; batch classifier loss: 0.357270; batch adversarial loss: 0.628757\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418440; batch adversarial loss: 0.628497\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438619; batch adversarial loss: 0.507569\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427981; batch adversarial loss: 0.572617\n",
      "epoch 67; iter: 0; batch classifier loss: 0.345931; batch adversarial loss: 0.526940\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460715; batch adversarial loss: 0.563189\n",
      "epoch 69; iter: 0; batch classifier loss: 0.472964; batch adversarial loss: 0.451153\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413653; batch adversarial loss: 0.563215\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390213; batch adversarial loss: 0.572992\n",
      "epoch 72; iter: 0; batch classifier loss: 0.453070; batch adversarial loss: 0.619443\n",
      "epoch 73; iter: 0; batch classifier loss: 0.359185; batch adversarial loss: 0.619112\n",
      "epoch 74; iter: 0; batch classifier loss: 0.351555; batch adversarial loss: 0.572606\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443052; batch adversarial loss: 0.546043\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359821; batch adversarial loss: 0.582637\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436744; batch adversarial loss: 0.563367\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405294; batch adversarial loss: 0.470194\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359567; batch adversarial loss: 0.610713\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411687; batch adversarial loss: 0.534645\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394000; batch adversarial loss: 0.496978\n",
      "epoch 82; iter: 0; batch classifier loss: 0.327318; batch adversarial loss: 0.609185\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387512; batch adversarial loss: 0.526750\n",
      "epoch 84; iter: 0; batch classifier loss: 0.465635; batch adversarial loss: 0.554230\n",
      "epoch 85; iter: 0; batch classifier loss: 0.368901; batch adversarial loss: 0.553558\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400420; batch adversarial loss: 0.562781\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411433; batch adversarial loss: 0.582335\n",
      "epoch 88; iter: 0; batch classifier loss: 0.409166; batch adversarial loss: 0.525825\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355251; batch adversarial loss: 0.601268\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368845; batch adversarial loss: 0.618992\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411768; batch adversarial loss: 0.487964\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383809; batch adversarial loss: 0.534625\n",
      "epoch 93; iter: 0; batch classifier loss: 0.408528; batch adversarial loss: 0.609023\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411546; batch adversarial loss: 0.535881\n",
      "epoch 95; iter: 0; batch classifier loss: 0.459754; batch adversarial loss: 0.468960\n",
      "epoch 96; iter: 0; batch classifier loss: 0.411370; batch adversarial loss: 0.608660\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436464; batch adversarial loss: 0.535244\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385484; batch adversarial loss: 0.506897\n",
      "epoch 99; iter: 0; batch classifier loss: 0.389843; batch adversarial loss: 0.563364\n",
      "epoch 100; iter: 0; batch classifier loss: 0.335064; batch adversarial loss: 0.516051\n",
      "epoch 101; iter: 0; batch classifier loss: 0.304252; batch adversarial loss: 0.497347\n",
      "epoch 102; iter: 0; batch classifier loss: 0.338845; batch adversarial loss: 0.561764\n",
      "epoch 103; iter: 0; batch classifier loss: 0.321281; batch adversarial loss: 0.636537\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402638; batch adversarial loss: 0.589344\n",
      "epoch 105; iter: 0; batch classifier loss: 0.403747; batch adversarial loss: 0.545208\n",
      "epoch 106; iter: 0; batch classifier loss: 0.318214; batch adversarial loss: 0.580473\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413702; batch adversarial loss: 0.517323\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355145; batch adversarial loss: 0.517283\n",
      "epoch 109; iter: 0; batch classifier loss: 0.328819; batch adversarial loss: 0.554665\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359006; batch adversarial loss: 0.590676\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405360; batch adversarial loss: 0.424154\n",
      "epoch 112; iter: 0; batch classifier loss: 0.358313; batch adversarial loss: 0.591529\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352614; batch adversarial loss: 0.608734\n",
      "epoch 114; iter: 0; batch classifier loss: 0.352022; batch adversarial loss: 0.525789\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380081; batch adversarial loss: 0.562673\n",
      "epoch 116; iter: 0; batch classifier loss: 0.476775; batch adversarial loss: 0.601495\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363111; batch adversarial loss: 0.517627\n",
      "epoch 118; iter: 0; batch classifier loss: 0.346558; batch adversarial loss: 0.582279\n",
      "epoch 119; iter: 0; batch classifier loss: 0.355810; batch adversarial loss: 0.545402\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361969; batch adversarial loss: 0.517253\n",
      "epoch 121; iter: 0; batch classifier loss: 0.266939; batch adversarial loss: 0.628949\n",
      "epoch 122; iter: 0; batch classifier loss: 0.320998; batch adversarial loss: 0.582038\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384787; batch adversarial loss: 0.498549\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337162; batch adversarial loss: 0.525376\n",
      "epoch 125; iter: 0; batch classifier loss: 0.407183; batch adversarial loss: 0.525173\n",
      "epoch 126; iter: 0; batch classifier loss: 0.284796; batch adversarial loss: 0.597653\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344161; batch adversarial loss: 0.545936\n",
      "epoch 128; iter: 0; batch classifier loss: 0.341006; batch adversarial loss: 0.505962\n",
      "epoch 129; iter: 0; batch classifier loss: 0.363607; batch adversarial loss: 0.517678\n",
      "epoch 130; iter: 0; batch classifier loss: 0.412089; batch adversarial loss: 0.526843\n",
      "epoch 131; iter: 0; batch classifier loss: 0.418663; batch adversarial loss: 0.489018\n",
      "epoch 132; iter: 0; batch classifier loss: 0.299607; batch adversarial loss: 0.480432\n",
      "epoch 133; iter: 0; batch classifier loss: 0.273852; batch adversarial loss: 0.469420\n",
      "epoch 134; iter: 0; batch classifier loss: 0.331507; batch adversarial loss: 0.556710\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338267; batch adversarial loss: 0.608020\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339532; batch adversarial loss: 0.552897\n",
      "epoch 137; iter: 0; batch classifier loss: 0.336167; batch adversarial loss: 0.554004\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317575; batch adversarial loss: 0.545888\n",
      "epoch 139; iter: 0; batch classifier loss: 0.370444; batch adversarial loss: 0.536302\n",
      "epoch 140; iter: 0; batch classifier loss: 0.416350; batch adversarial loss: 0.526465\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342175; batch adversarial loss: 0.489543\n",
      "epoch 142; iter: 0; batch classifier loss: 0.278208; batch adversarial loss: 0.564472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.442329; batch adversarial loss: 0.489074\n",
      "epoch 144; iter: 0; batch classifier loss: 0.414790; batch adversarial loss: 0.497532\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363766; batch adversarial loss: 0.562472\n",
      "epoch 146; iter: 0; batch classifier loss: 0.309332; batch adversarial loss: 0.562916\n",
      "epoch 147; iter: 0; batch classifier loss: 0.341629; batch adversarial loss: 0.517264\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356175; batch adversarial loss: 0.581689\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369852; batch adversarial loss: 0.544985\n",
      "epoch 150; iter: 0; batch classifier loss: 0.274705; batch adversarial loss: 0.555381\n",
      "epoch 151; iter: 0; batch classifier loss: 0.301441; batch adversarial loss: 0.516873\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376835; batch adversarial loss: 0.562039\n",
      "epoch 153; iter: 0; batch classifier loss: 0.326581; batch adversarial loss: 0.610386\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340841; batch adversarial loss: 0.600910\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324271; batch adversarial loss: 0.620257\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396608; batch adversarial loss: 0.591195\n",
      "epoch 157; iter: 0; batch classifier loss: 0.296080; batch adversarial loss: 0.535702\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334637; batch adversarial loss: 0.573874\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290853; batch adversarial loss: 0.505089\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337933; batch adversarial loss: 0.479080\n",
      "epoch 161; iter: 0; batch classifier loss: 0.432326; batch adversarial loss: 0.554269\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329358; batch adversarial loss: 0.508491\n",
      "epoch 163; iter: 0; batch classifier loss: 0.452390; batch adversarial loss: 0.582276\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360968; batch adversarial loss: 0.543048\n",
      "epoch 165; iter: 0; batch classifier loss: 0.391208; batch adversarial loss: 0.603175\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395797; batch adversarial loss: 0.534588\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334324; batch adversarial loss: 0.527044\n",
      "epoch 168; iter: 0; batch classifier loss: 0.334367; batch adversarial loss: 0.572407\n",
      "epoch 169; iter: 0; batch classifier loss: 0.378835; batch adversarial loss: 0.562237\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397715; batch adversarial loss: 0.535809\n",
      "epoch 171; iter: 0; batch classifier loss: 0.298831; batch adversarial loss: 0.507971\n",
      "epoch 172; iter: 0; batch classifier loss: 0.380841; batch adversarial loss: 0.526545\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349009; batch adversarial loss: 0.535153\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363966; batch adversarial loss: 0.581582\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388235; batch adversarial loss: 0.590910\n",
      "epoch 176; iter: 0; batch classifier loss: 0.415225; batch adversarial loss: 0.469730\n",
      "epoch 177; iter: 0; batch classifier loss: 0.429418; batch adversarial loss: 0.573217\n",
      "epoch 178; iter: 0; batch classifier loss: 0.318569; batch adversarial loss: 0.498700\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358341; batch adversarial loss: 0.544010\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329650; batch adversarial loss: 0.545502\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377059; batch adversarial loss: 0.601997\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318121; batch adversarial loss: 0.516528\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373604; batch adversarial loss: 0.524746\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377076; batch adversarial loss: 0.555330\n",
      "epoch 185; iter: 0; batch classifier loss: 0.292804; batch adversarial loss: 0.555082\n",
      "epoch 186; iter: 0; batch classifier loss: 0.316433; batch adversarial loss: 0.535012\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352629; batch adversarial loss: 0.561837\n",
      "epoch 188; iter: 0; batch classifier loss: 0.303288; batch adversarial loss: 0.588954\n",
      "epoch 189; iter: 0; batch classifier loss: 0.376259; batch adversarial loss: 0.554917\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322425; batch adversarial loss: 0.664706\n",
      "epoch 191; iter: 0; batch classifier loss: 0.412639; batch adversarial loss: 0.564005\n",
      "epoch 192; iter: 0; batch classifier loss: 0.291447; batch adversarial loss: 0.636614\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308337; batch adversarial loss: 0.508093\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315915; batch adversarial loss: 0.525747\n",
      "epoch 195; iter: 0; batch classifier loss: 0.394301; batch adversarial loss: 0.582362\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364183; batch adversarial loss: 0.506408\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358909; batch adversarial loss: 0.478823\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382005; batch adversarial loss: 0.546127\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340688; batch adversarial loss: 0.395854\n",
      "epoch 0; iter: 0; batch classifier loss: 0.761639; batch adversarial loss: 0.715318\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559694; batch adversarial loss: 0.634500\n",
      "epoch 2; iter: 0; batch classifier loss: 0.503367; batch adversarial loss: 0.651169\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538927; batch adversarial loss: 0.662174\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621011; batch adversarial loss: 0.629209\n",
      "epoch 5; iter: 0; batch classifier loss: 0.522199; batch adversarial loss: 0.598528\n",
      "epoch 6; iter: 0; batch classifier loss: 0.600917; batch adversarial loss: 0.611223\n",
      "epoch 7; iter: 0; batch classifier loss: 0.540227; batch adversarial loss: 0.532406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511178; batch adversarial loss: 0.523798\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552533; batch adversarial loss: 0.561895\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498986; batch adversarial loss: 0.684800\n",
      "epoch 11; iter: 0; batch classifier loss: 0.499172; batch adversarial loss: 0.642237\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547005; batch adversarial loss: 0.484301\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541935; batch adversarial loss: 0.585633\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511900; batch adversarial loss: 0.556244\n",
      "epoch 15; iter: 0; batch classifier loss: 0.412493; batch adversarial loss: 0.609772\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492008; batch adversarial loss: 0.582011\n",
      "epoch 17; iter: 0; batch classifier loss: 0.461919; batch adversarial loss: 0.526011\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446113; batch adversarial loss: 0.563784\n",
      "epoch 19; iter: 0; batch classifier loss: 0.477914; batch adversarial loss: 0.587820\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507156; batch adversarial loss: 0.521496\n",
      "epoch 21; iter: 0; batch classifier loss: 0.465289; batch adversarial loss: 0.557489\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517334; batch adversarial loss: 0.566789\n",
      "epoch 23; iter: 0; batch classifier loss: 0.405555; batch adversarial loss: 0.523061\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453891; batch adversarial loss: 0.570847\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433365; batch adversarial loss: 0.484969\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460799; batch adversarial loss: 0.555674\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466724; batch adversarial loss: 0.580933\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455300; batch adversarial loss: 0.534100\n",
      "epoch 29; iter: 0; batch classifier loss: 0.577074; batch adversarial loss: 0.594874\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472221; batch adversarial loss: 0.565553\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498300; batch adversarial loss: 0.547734\n",
      "epoch 32; iter: 0; batch classifier loss: 0.568711; batch adversarial loss: 0.520653\n",
      "epoch 33; iter: 0; batch classifier loss: 0.411525; batch adversarial loss: 0.552911\n",
      "epoch 34; iter: 0; batch classifier loss: 0.409901; batch adversarial loss: 0.515672\n",
      "epoch 35; iter: 0; batch classifier loss: 0.533314; batch adversarial loss: 0.638365\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503372; batch adversarial loss: 0.529543\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447989; batch adversarial loss: 0.466550\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473204; batch adversarial loss: 0.496040\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451627; batch adversarial loss: 0.579817\n",
      "epoch 40; iter: 0; batch classifier loss: 0.402018; batch adversarial loss: 0.542641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.352608; batch adversarial loss: 0.539553\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419673; batch adversarial loss: 0.589847\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442304; batch adversarial loss: 0.595380\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397183; batch adversarial loss: 0.554961\n",
      "epoch 45; iter: 0; batch classifier loss: 0.497285; batch adversarial loss: 0.532854\n",
      "epoch 46; iter: 0; batch classifier loss: 0.413180; batch adversarial loss: 0.449616\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452500; batch adversarial loss: 0.542912\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432931; batch adversarial loss: 0.487163\n",
      "epoch 49; iter: 0; batch classifier loss: 0.362566; batch adversarial loss: 0.555796\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403090; batch adversarial loss: 0.485229\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470383; batch adversarial loss: 0.514954\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460283; batch adversarial loss: 0.545184\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417314; batch adversarial loss: 0.513101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445612; batch adversarial loss: 0.574129\n",
      "epoch 55; iter: 0; batch classifier loss: 0.373362; batch adversarial loss: 0.665225\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445788; batch adversarial loss: 0.517408\n",
      "epoch 57; iter: 0; batch classifier loss: 0.373211; batch adversarial loss: 0.580461\n",
      "epoch 58; iter: 0; batch classifier loss: 0.457250; batch adversarial loss: 0.526475\n",
      "epoch 59; iter: 0; batch classifier loss: 0.348442; batch adversarial loss: 0.568604\n",
      "epoch 60; iter: 0; batch classifier loss: 0.475839; batch adversarial loss: 0.532412\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426672; batch adversarial loss: 0.555207\n",
      "epoch 62; iter: 0; batch classifier loss: 0.375208; batch adversarial loss: 0.634196\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412243; batch adversarial loss: 0.592675\n",
      "epoch 64; iter: 0; batch classifier loss: 0.481046; batch adversarial loss: 0.582394\n",
      "epoch 65; iter: 0; batch classifier loss: 0.378233; batch adversarial loss: 0.530332\n",
      "epoch 66; iter: 0; batch classifier loss: 0.462522; batch adversarial loss: 0.561943\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428790; batch adversarial loss: 0.587260\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392765; batch adversarial loss: 0.545159\n",
      "epoch 69; iter: 0; batch classifier loss: 0.312779; batch adversarial loss: 0.614925\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407791; batch adversarial loss: 0.599365\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405304; batch adversarial loss: 0.590201\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411917; batch adversarial loss: 0.607355\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377470; batch adversarial loss: 0.545239\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384407; batch adversarial loss: 0.605997\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423010; batch adversarial loss: 0.553923\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424491; batch adversarial loss: 0.527251\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406256; batch adversarial loss: 0.561790\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376544; batch adversarial loss: 0.588606\n",
      "epoch 79; iter: 0; batch classifier loss: 0.506588; batch adversarial loss: 0.510413\n",
      "epoch 80; iter: 0; batch classifier loss: 0.342119; batch adversarial loss: 0.529103\n",
      "epoch 81; iter: 0; batch classifier loss: 0.345203; batch adversarial loss: 0.600343\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418322; batch adversarial loss: 0.609216\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411488; batch adversarial loss: 0.544214\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412672; batch adversarial loss: 0.592494\n",
      "epoch 85; iter: 0; batch classifier loss: 0.308717; batch adversarial loss: 0.571514\n",
      "epoch 86; iter: 0; batch classifier loss: 0.456990; batch adversarial loss: 0.508044\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369511; batch adversarial loss: 0.537528\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399594; batch adversarial loss: 0.537205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384466; batch adversarial loss: 0.546673\n",
      "epoch 90; iter: 0; batch classifier loss: 0.487577; batch adversarial loss: 0.534195\n",
      "epoch 91; iter: 0; batch classifier loss: 0.496628; batch adversarial loss: 0.555029\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348415; batch adversarial loss: 0.580565\n",
      "epoch 93; iter: 0; batch classifier loss: 0.334207; batch adversarial loss: 0.552558\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387664; batch adversarial loss: 0.634718\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414861; batch adversarial loss: 0.526842\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371348; batch adversarial loss: 0.578608\n",
      "epoch 97; iter: 0; batch classifier loss: 0.450057; batch adversarial loss: 0.592761\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382891; batch adversarial loss: 0.506585\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424065; batch adversarial loss: 0.546702\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404394; batch adversarial loss: 0.471583\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383859; batch adversarial loss: 0.582083\n",
      "epoch 102; iter: 0; batch classifier loss: 0.427635; batch adversarial loss: 0.570157\n",
      "epoch 103; iter: 0; batch classifier loss: 0.422965; batch adversarial loss: 0.601466\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392848; batch adversarial loss: 0.544240\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369390; batch adversarial loss: 0.505472\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382308; batch adversarial loss: 0.561193\n",
      "epoch 107; iter: 0; batch classifier loss: 0.370765; batch adversarial loss: 0.537366\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362367; batch adversarial loss: 0.564454\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385405; batch adversarial loss: 0.590068\n",
      "epoch 110; iter: 0; batch classifier loss: 0.317159; batch adversarial loss: 0.542306\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336303; batch adversarial loss: 0.561665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.316962; batch adversarial loss: 0.553425\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370659; batch adversarial loss: 0.579215\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346541; batch adversarial loss: 0.561401\n",
      "epoch 115; iter: 0; batch classifier loss: 0.460728; batch adversarial loss: 0.480415\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325225; batch adversarial loss: 0.556557\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408051; batch adversarial loss: 0.528301\n",
      "epoch 118; iter: 0; batch classifier loss: 0.518703; batch adversarial loss: 0.525591\n",
      "epoch 119; iter: 0; batch classifier loss: 0.341046; batch adversarial loss: 0.517050\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420130; batch adversarial loss: 0.599012\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398991; batch adversarial loss: 0.593390\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388933; batch adversarial loss: 0.525670\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387904; batch adversarial loss: 0.569622\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392483; batch adversarial loss: 0.482229\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326411; batch adversarial loss: 0.497128\n",
      "epoch 126; iter: 0; batch classifier loss: 0.327888; batch adversarial loss: 0.516146\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346909; batch adversarial loss: 0.554102\n",
      "epoch 128; iter: 0; batch classifier loss: 0.473332; batch adversarial loss: 0.528427\n",
      "epoch 129; iter: 0; batch classifier loss: 0.407611; batch adversarial loss: 0.435814\n",
      "epoch 130; iter: 0; batch classifier loss: 0.412561; batch adversarial loss: 0.505999\n",
      "epoch 131; iter: 0; batch classifier loss: 0.471528; batch adversarial loss: 0.609173\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376546; batch adversarial loss: 0.545021\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395276; batch adversarial loss: 0.525061\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355349; batch adversarial loss: 0.496253\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341964; batch adversarial loss: 0.462297\n",
      "epoch 136; iter: 0; batch classifier loss: 0.261417; batch adversarial loss: 0.516246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.405177; batch adversarial loss: 0.510375\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341680; batch adversarial loss: 0.518504\n",
      "epoch 139; iter: 0; batch classifier loss: 0.443208; batch adversarial loss: 0.470920\n",
      "epoch 140; iter: 0; batch classifier loss: 0.452842; batch adversarial loss: 0.505721\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337260; batch adversarial loss: 0.626499\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380240; batch adversarial loss: 0.578911\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368279; batch adversarial loss: 0.608094\n",
      "epoch 144; iter: 0; batch classifier loss: 0.426557; batch adversarial loss: 0.500004\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372466; batch adversarial loss: 0.644128\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360880; batch adversarial loss: 0.555542\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361723; batch adversarial loss: 0.535560\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346580; batch adversarial loss: 0.570577\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392236; batch adversarial loss: 0.554874\n",
      "epoch 150; iter: 0; batch classifier loss: 0.272178; batch adversarial loss: 0.559761\n",
      "epoch 151; iter: 0; batch classifier loss: 0.320965; batch adversarial loss: 0.578839\n",
      "epoch 152; iter: 0; batch classifier loss: 0.415235; batch adversarial loss: 0.518057\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324534; batch adversarial loss: 0.562932\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342443; batch adversarial loss: 0.533816\n",
      "epoch 155; iter: 0; batch classifier loss: 0.353494; batch adversarial loss: 0.597797\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401581; batch adversarial loss: 0.481459\n",
      "epoch 157; iter: 0; batch classifier loss: 0.386070; batch adversarial loss: 0.654381\n",
      "epoch 158; iter: 0; batch classifier loss: 0.402797; batch adversarial loss: 0.480573\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349437; batch adversarial loss: 0.518194\n",
      "epoch 160; iter: 0; batch classifier loss: 0.315070; batch adversarial loss: 0.563473\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410707; batch adversarial loss: 0.610198\n",
      "epoch 162; iter: 0; batch classifier loss: 0.307499; batch adversarial loss: 0.498285\n",
      "epoch 163; iter: 0; batch classifier loss: 0.423372; batch adversarial loss: 0.482750\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361754; batch adversarial loss: 0.645107\n",
      "epoch 165; iter: 0; batch classifier loss: 0.381800; batch adversarial loss: 0.589301\n",
      "epoch 166; iter: 0; batch classifier loss: 0.250877; batch adversarial loss: 0.571440\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345765; batch adversarial loss: 0.633964\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318684; batch adversarial loss: 0.436358\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392410; batch adversarial loss: 0.587521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.404606; batch adversarial loss: 0.555272\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394342; batch adversarial loss: 0.488270\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322912; batch adversarial loss: 0.554983\n",
      "epoch 173; iter: 0; batch classifier loss: 0.379923; batch adversarial loss: 0.534180\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361022; batch adversarial loss: 0.562678\n",
      "epoch 175; iter: 0; batch classifier loss: 0.411886; batch adversarial loss: 0.646139\n",
      "epoch 176; iter: 0; batch classifier loss: 0.416675; batch adversarial loss: 0.650590\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383218; batch adversarial loss: 0.561965\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383409; batch adversarial loss: 0.508869\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349334; batch adversarial loss: 0.608933\n",
      "epoch 180; iter: 0; batch classifier loss: 0.364717; batch adversarial loss: 0.581412\n",
      "epoch 181; iter: 0; batch classifier loss: 0.405438; batch adversarial loss: 0.553405\n",
      "epoch 182; iter: 0; batch classifier loss: 0.412614; batch adversarial loss: 0.507665\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396250; batch adversarial loss: 0.553909\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337933; batch adversarial loss: 0.596628\n",
      "epoch 185; iter: 0; batch classifier loss: 0.491246; batch adversarial loss: 0.506312\n",
      "epoch 186; iter: 0; batch classifier loss: 0.391645; batch adversarial loss: 0.575173\n",
      "epoch 187; iter: 0; batch classifier loss: 0.383059; batch adversarial loss: 0.499277\n",
      "epoch 188; iter: 0; batch classifier loss: 0.322275; batch adversarial loss: 0.506634\n",
      "epoch 189; iter: 0; batch classifier loss: 0.366747; batch adversarial loss: 0.526951\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329131; batch adversarial loss: 0.508512\n",
      "epoch 191; iter: 0; batch classifier loss: 0.458659; batch adversarial loss: 0.625298\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394418; batch adversarial loss: 0.520667\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348036; batch adversarial loss: 0.525901\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342757; batch adversarial loss: 0.552562\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323838; batch adversarial loss: 0.570434\n",
      "epoch 196; iter: 0; batch classifier loss: 0.377229; batch adversarial loss: 0.527572\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321173; batch adversarial loss: 0.553311\n",
      "epoch 198; iter: 0; batch classifier loss: 0.396371; batch adversarial loss: 0.564011\n",
      "epoch 199; iter: 0; batch classifier loss: 0.459233; batch adversarial loss: 0.626053\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709027; batch adversarial loss: 0.728590\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594302; batch adversarial loss: 0.690514\n",
      "epoch 2; iter: 0; batch classifier loss: 0.499009; batch adversarial loss: 0.663089\n",
      "epoch 3; iter: 0; batch classifier loss: 0.596573; batch adversarial loss: 0.642223\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552068; batch adversarial loss: 0.630824\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532299; batch adversarial loss: 0.590104\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545169; batch adversarial loss: 0.596183\n",
      "epoch 7; iter: 0; batch classifier loss: 0.473652; batch adversarial loss: 0.560484\n",
      "epoch 8; iter: 0; batch classifier loss: 0.510793; batch adversarial loss: 0.555258\n",
      "epoch 9; iter: 0; batch classifier loss: 0.457897; batch adversarial loss: 0.592981\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518630; batch adversarial loss: 0.582913\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535615; batch adversarial loss: 0.555057\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542268; batch adversarial loss: 0.580184\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563613; batch adversarial loss: 0.553934\n",
      "epoch 14; iter: 0; batch classifier loss: 0.536557; batch adversarial loss: 0.572385\n",
      "epoch 15; iter: 0; batch classifier loss: 0.559375; batch adversarial loss: 0.574468\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501135; batch adversarial loss: 0.561721\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488585; batch adversarial loss: 0.516426\n",
      "epoch 18; iter: 0; batch classifier loss: 0.554282; batch adversarial loss: 0.551463\n",
      "epoch 19; iter: 0; batch classifier loss: 0.533569; batch adversarial loss: 0.550644\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454329; batch adversarial loss: 0.592157\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507672; batch adversarial loss: 0.535753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.542832; batch adversarial loss: 0.555038\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461981; batch adversarial loss: 0.600048\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445275; batch adversarial loss: 0.565920\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484560; batch adversarial loss: 0.558802\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424530; batch adversarial loss: 0.541002\n",
      "epoch 27; iter: 0; batch classifier loss: 0.578909; batch adversarial loss: 0.546338\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439390; batch adversarial loss: 0.523165\n",
      "epoch 29; iter: 0; batch classifier loss: 0.418991; batch adversarial loss: 0.580884\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476129; batch adversarial loss: 0.564188\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431139; batch adversarial loss: 0.469084\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423557; batch adversarial loss: 0.571280\n",
      "epoch 33; iter: 0; batch classifier loss: 0.419260; batch adversarial loss: 0.572529\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469730; batch adversarial loss: 0.499403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.358813; batch adversarial loss: 0.581176\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450305; batch adversarial loss: 0.598759\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399102; batch adversarial loss: 0.519166\n",
      "epoch 38; iter: 0; batch classifier loss: 0.426430; batch adversarial loss: 0.632553\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449705; batch adversarial loss: 0.606010\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405221; batch adversarial loss: 0.581377\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433855; batch adversarial loss: 0.554032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400015; batch adversarial loss: 0.625858\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463537; batch adversarial loss: 0.580747\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445388; batch adversarial loss: 0.481141\n",
      "epoch 45; iter: 0; batch classifier loss: 0.391877; batch adversarial loss: 0.517504\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385180; batch adversarial loss: 0.616915\n",
      "epoch 47; iter: 0; batch classifier loss: 0.470471; batch adversarial loss: 0.481043\n",
      "epoch 48; iter: 0; batch classifier loss: 0.479291; batch adversarial loss: 0.599018\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390377; batch adversarial loss: 0.572420\n",
      "epoch 50; iter: 0; batch classifier loss: 0.404602; batch adversarial loss: 0.544293\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414510; batch adversarial loss: 0.517521\n",
      "epoch 52; iter: 0; batch classifier loss: 0.447862; batch adversarial loss: 0.553697\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403551; batch adversarial loss: 0.482025\n",
      "epoch 54; iter: 0; batch classifier loss: 0.369285; batch adversarial loss: 0.525210\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409830; batch adversarial loss: 0.580599\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408017; batch adversarial loss: 0.634150\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392970; batch adversarial loss: 0.564480\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466011; batch adversarial loss: 0.609039\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407365; batch adversarial loss: 0.525699\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434774; batch adversarial loss: 0.535194\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391383; batch adversarial loss: 0.562953\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430010; batch adversarial loss: 0.535624\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441504; batch adversarial loss: 0.488979\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376935; batch adversarial loss: 0.580363\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370045; batch adversarial loss: 0.525201\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412815; batch adversarial loss: 0.572437\n",
      "epoch 67; iter: 0; batch classifier loss: 0.456694; batch adversarial loss: 0.533624\n",
      "epoch 68; iter: 0; batch classifier loss: 0.374500; batch adversarial loss: 0.505942\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388406; batch adversarial loss: 0.562170\n",
      "epoch 70; iter: 0; batch classifier loss: 0.487957; batch adversarial loss: 0.543225\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399626; batch adversarial loss: 0.545349\n",
      "epoch 72; iter: 0; batch classifier loss: 0.308182; batch adversarial loss: 0.490122\n",
      "epoch 73; iter: 0; batch classifier loss: 0.471208; batch adversarial loss: 0.563096\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414110; batch adversarial loss: 0.590665\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425335; batch adversarial loss: 0.536771\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419230; batch adversarial loss: 0.582942\n",
      "epoch 77; iter: 0; batch classifier loss: 0.420768; batch adversarial loss: 0.637401\n",
      "epoch 78; iter: 0; batch classifier loss: 0.336245; batch adversarial loss: 0.628753\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378326; batch adversarial loss: 0.544629\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381639; batch adversarial loss: 0.590606\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358786; batch adversarial loss: 0.525700\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342418; batch adversarial loss: 0.563246\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375161; batch adversarial loss: 0.589542\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354515; batch adversarial loss: 0.572464\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390038; batch adversarial loss: 0.479601\n",
      "epoch 86; iter: 0; batch classifier loss: 0.441154; batch adversarial loss: 0.581319\n",
      "epoch 87; iter: 0; batch classifier loss: 0.303308; batch adversarial loss: 0.507515\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417861; batch adversarial loss: 0.599336\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373450; batch adversarial loss: 0.479888\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387159; batch adversarial loss: 0.581347\n",
      "epoch 91; iter: 0; batch classifier loss: 0.451625; batch adversarial loss: 0.525792\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399590; batch adversarial loss: 0.570991\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399254; batch adversarial loss: 0.526212\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378571; batch adversarial loss: 0.572320\n",
      "epoch 95; iter: 0; batch classifier loss: 0.406430; batch adversarial loss: 0.579511\n",
      "epoch 96; iter: 0; batch classifier loss: 0.293407; batch adversarial loss: 0.543583\n",
      "epoch 97; iter: 0; batch classifier loss: 0.326860; batch adversarial loss: 0.526904\n",
      "epoch 98; iter: 0; batch classifier loss: 0.436208; batch adversarial loss: 0.578855\n",
      "epoch 99; iter: 0; batch classifier loss: 0.298995; batch adversarial loss: 0.632975\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399381; batch adversarial loss: 0.599522\n",
      "epoch 101; iter: 0; batch classifier loss: 0.498405; batch adversarial loss: 0.547111\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350148; batch adversarial loss: 0.469665\n",
      "epoch 103; iter: 0; batch classifier loss: 0.335376; batch adversarial loss: 0.518157\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372955; batch adversarial loss: 0.505180\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401264; batch adversarial loss: 0.536207\n",
      "epoch 106; iter: 0; batch classifier loss: 0.450035; batch adversarial loss: 0.461791\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393112; batch adversarial loss: 0.526794\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385886; batch adversarial loss: 0.563129\n",
      "epoch 109; iter: 0; batch classifier loss: 0.353842; batch adversarial loss: 0.609736\n",
      "epoch 110; iter: 0; batch classifier loss: 0.338925; batch adversarial loss: 0.516229\n",
      "epoch 111; iter: 0; batch classifier loss: 0.322228; batch adversarial loss: 0.544348\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376740; batch adversarial loss: 0.470390\n",
      "epoch 113; iter: 0; batch classifier loss: 0.284062; batch adversarial loss: 0.581562\n",
      "epoch 114; iter: 0; batch classifier loss: 0.331223; batch adversarial loss: 0.572446\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373575; batch adversarial loss: 0.553592\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323432; batch adversarial loss: 0.535240\n",
      "epoch 117; iter: 0; batch classifier loss: 0.303745; batch adversarial loss: 0.534912\n",
      "epoch 118; iter: 0; batch classifier loss: 0.446588; batch adversarial loss: 0.470415\n",
      "epoch 119; iter: 0; batch classifier loss: 0.450847; batch adversarial loss: 0.545366\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373415; batch adversarial loss: 0.453671\n",
      "epoch 121; iter: 0; batch classifier loss: 0.384436; batch adversarial loss: 0.561184\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368630; batch adversarial loss: 0.436722\n",
      "epoch 123; iter: 0; batch classifier loss: 0.424985; batch adversarial loss: 0.508275\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401661; batch adversarial loss: 0.443798\n",
      "epoch 125; iter: 0; batch classifier loss: 0.303960; batch adversarial loss: 0.600832\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351907; batch adversarial loss: 0.526053\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348337; batch adversarial loss: 0.554154\n",
      "epoch 128; iter: 0; batch classifier loss: 0.413500; batch adversarial loss: 0.552412\n",
      "epoch 129; iter: 0; batch classifier loss: 0.363903; batch adversarial loss: 0.599915\n",
      "epoch 130; iter: 0; batch classifier loss: 0.467811; batch adversarial loss: 0.543907\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347823; batch adversarial loss: 0.555189\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352666; batch adversarial loss: 0.648473\n",
      "epoch 133; iter: 0; batch classifier loss: 0.338191; batch adversarial loss: 0.618945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.330793; batch adversarial loss: 0.554145\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363226; batch adversarial loss: 0.497520\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395404; batch adversarial loss: 0.572861\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403080; batch adversarial loss: 0.544772\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392880; batch adversarial loss: 0.488595\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352945; batch adversarial loss: 0.562749\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359479; batch adversarial loss: 0.600040\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325033; batch adversarial loss: 0.498921\n",
      "epoch 142; iter: 0; batch classifier loss: 0.306981; batch adversarial loss: 0.470737\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364968; batch adversarial loss: 0.563253\n",
      "epoch 144; iter: 0; batch classifier loss: 0.370705; batch adversarial loss: 0.588884\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323044; batch adversarial loss: 0.544001\n",
      "epoch 146; iter: 0; batch classifier loss: 0.336394; batch adversarial loss: 0.609038\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307335; batch adversarial loss: 0.561617\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358578; batch adversarial loss: 0.523582\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410993; batch adversarial loss: 0.546040\n",
      "epoch 150; iter: 0; batch classifier loss: 0.348455; batch adversarial loss: 0.553234\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341385; batch adversarial loss: 0.535000\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333057; batch adversarial loss: 0.553226\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381508; batch adversarial loss: 0.601400\n",
      "epoch 154; iter: 0; batch classifier loss: 0.454876; batch adversarial loss: 0.535879\n",
      "epoch 155; iter: 0; batch classifier loss: 0.437814; batch adversarial loss: 0.507341\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376603; batch adversarial loss: 0.480133\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333394; batch adversarial loss: 0.544049\n",
      "epoch 158; iter: 0; batch classifier loss: 0.281094; batch adversarial loss: 0.533622\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370829; batch adversarial loss: 0.489713\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382032; batch adversarial loss: 0.617707\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319627; batch adversarial loss: 0.664859\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360097; batch adversarial loss: 0.562083\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373490; batch adversarial loss: 0.564012\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337469; batch adversarial loss: 0.545325\n",
      "epoch 165; iter: 0; batch classifier loss: 0.296717; batch adversarial loss: 0.545672\n",
      "epoch 166; iter: 0; batch classifier loss: 0.405556; batch adversarial loss: 0.591012\n",
      "epoch 167; iter: 0; batch classifier loss: 0.398246; batch adversarial loss: 0.506879\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363073; batch adversarial loss: 0.602119\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366266; batch adversarial loss: 0.544935\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393108; batch adversarial loss: 0.534622\n",
      "epoch 171; iter: 0; batch classifier loss: 0.456657; batch adversarial loss: 0.479457\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318626; batch adversarial loss: 0.526211\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404550; batch adversarial loss: 0.516748\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350236; batch adversarial loss: 0.563648\n",
      "epoch 175; iter: 0; batch classifier loss: 0.385914; batch adversarial loss: 0.516760\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365953; batch adversarial loss: 0.562416\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343199; batch adversarial loss: 0.517276\n",
      "epoch 178; iter: 0; batch classifier loss: 0.399529; batch adversarial loss: 0.572812\n",
      "epoch 179; iter: 0; batch classifier loss: 0.284550; batch adversarial loss: 0.525767\n",
      "epoch 180; iter: 0; batch classifier loss: 0.421246; batch adversarial loss: 0.507585\n",
      "epoch 181; iter: 0; batch classifier loss: 0.268679; batch adversarial loss: 0.619096\n",
      "epoch 182; iter: 0; batch classifier loss: 0.403710; batch adversarial loss: 0.553901\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375278; batch adversarial loss: 0.591295\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339262; batch adversarial loss: 0.507850\n",
      "epoch 185; iter: 0; batch classifier loss: 0.286352; batch adversarial loss: 0.616194\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348373; batch adversarial loss: 0.508080\n",
      "epoch 187; iter: 0; batch classifier loss: 0.411576; batch adversarial loss: 0.469602\n",
      "epoch 188; iter: 0; batch classifier loss: 0.325702; batch adversarial loss: 0.561571\n",
      "epoch 189; iter: 0; batch classifier loss: 0.244536; batch adversarial loss: 0.479253\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367969; batch adversarial loss: 0.591451\n",
      "epoch 191; iter: 0; batch classifier loss: 0.405348; batch adversarial loss: 0.509492\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328497; batch adversarial loss: 0.490586\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395920; batch adversarial loss: 0.543001\n",
      "epoch 194; iter: 0; batch classifier loss: 0.367709; batch adversarial loss: 0.579911\n",
      "epoch 195; iter: 0; batch classifier loss: 0.440128; batch adversarial loss: 0.517468\n",
      "epoch 196; iter: 0; batch classifier loss: 0.304462; batch adversarial loss: 0.544094\n",
      "epoch 197; iter: 0; batch classifier loss: 0.285000; batch adversarial loss: 0.562950\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347202; batch adversarial loss: 0.553810\n",
      "epoch 199; iter: 0; batch classifier loss: 0.426267; batch adversarial loss: 0.536399\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701555; batch adversarial loss: 0.525440\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618244; batch adversarial loss: 0.626978\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599139; batch adversarial loss: 0.614027\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569793; batch adversarial loss: 0.654782\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591910; batch adversarial loss: 0.692458\n",
      "epoch 5; iter: 0; batch classifier loss: 0.610634; batch adversarial loss: 0.643151\n",
      "epoch 6; iter: 0; batch classifier loss: 0.687476; batch adversarial loss: 0.672582\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601474; batch adversarial loss: 0.605283\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475005; batch adversarial loss: 0.593209\n",
      "epoch 9; iter: 0; batch classifier loss: 0.592852; batch adversarial loss: 0.582624\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560481; batch adversarial loss: 0.590795\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576268; batch adversarial loss: 0.610515\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533746; batch adversarial loss: 0.589450\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579074; batch adversarial loss: 0.534798\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466885; batch adversarial loss: 0.516931\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468972; batch adversarial loss: 0.561026\n",
      "epoch 16; iter: 0; batch classifier loss: 0.551007; batch adversarial loss: 0.563975\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524786; batch adversarial loss: 0.572106\n",
      "epoch 18; iter: 0; batch classifier loss: 0.594454; batch adversarial loss: 0.581326\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458817; batch adversarial loss: 0.593409\n",
      "epoch 20; iter: 0; batch classifier loss: 0.464424; batch adversarial loss: 0.473945\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543718; batch adversarial loss: 0.580990\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471106; batch adversarial loss: 0.547106\n",
      "epoch 23; iter: 0; batch classifier loss: 0.429545; batch adversarial loss: 0.552517\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515111; batch adversarial loss: 0.562360\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498992; batch adversarial loss: 0.545229\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387031; batch adversarial loss: 0.547168\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468014; batch adversarial loss: 0.538407\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513322; batch adversarial loss: 0.579125\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448126; batch adversarial loss: 0.532786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.435365; batch adversarial loss: 0.635425\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429500; batch adversarial loss: 0.525063\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438533; batch adversarial loss: 0.581215\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461695; batch adversarial loss: 0.456474\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501902; batch adversarial loss: 0.562170\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475788; batch adversarial loss: 0.481933\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426095; batch adversarial loss: 0.487590\n",
      "epoch 37; iter: 0; batch classifier loss: 0.484198; batch adversarial loss: 0.589534\n",
      "epoch 38; iter: 0; batch classifier loss: 0.506751; batch adversarial loss: 0.550479\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498707; batch adversarial loss: 0.485594\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412786; batch adversarial loss: 0.514539\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475241; batch adversarial loss: 0.611797\n",
      "epoch 42; iter: 0; batch classifier loss: 0.473888; batch adversarial loss: 0.519777\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442549; batch adversarial loss: 0.536759\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358070; batch adversarial loss: 0.565074\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458394; batch adversarial loss: 0.553279\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388445; batch adversarial loss: 0.508891\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411526; batch adversarial loss: 0.464069\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432492; batch adversarial loss: 0.479530\n",
      "epoch 49; iter: 0; batch classifier loss: 0.395440; batch adversarial loss: 0.543045\n",
      "epoch 50; iter: 0; batch classifier loss: 0.474633; batch adversarial loss: 0.554183\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418619; batch adversarial loss: 0.494963\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466107; batch adversarial loss: 0.544679\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389136; batch adversarial loss: 0.534273\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439678; batch adversarial loss: 0.607792\n",
      "epoch 55; iter: 0; batch classifier loss: 0.463056; batch adversarial loss: 0.572841\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453192; batch adversarial loss: 0.490114\n",
      "epoch 57; iter: 0; batch classifier loss: 0.496180; batch adversarial loss: 0.506687\n",
      "epoch 58; iter: 0; batch classifier loss: 0.379773; batch adversarial loss: 0.562854\n",
      "epoch 59; iter: 0; batch classifier loss: 0.478178; batch adversarial loss: 0.578266\n",
      "epoch 60; iter: 0; batch classifier loss: 0.358364; batch adversarial loss: 0.574239\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451386; batch adversarial loss: 0.581412\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386700; batch adversarial loss: 0.596230\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396012; batch adversarial loss: 0.564812\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365907; batch adversarial loss: 0.535442\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448485; batch adversarial loss: 0.565352\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384052; batch adversarial loss: 0.573028\n",
      "epoch 67; iter: 0; batch classifier loss: 0.438510; batch adversarial loss: 0.488401\n",
      "epoch 68; iter: 0; batch classifier loss: 0.431551; batch adversarial loss: 0.599259\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412909; batch adversarial loss: 0.517501\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396972; batch adversarial loss: 0.535244\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423178; batch adversarial loss: 0.527451\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416794; batch adversarial loss: 0.527043\n",
      "epoch 73; iter: 0; batch classifier loss: 0.356300; batch adversarial loss: 0.555163\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394165; batch adversarial loss: 0.515719\n",
      "epoch 75; iter: 0; batch classifier loss: 0.406049; batch adversarial loss: 0.507857\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393041; batch adversarial loss: 0.563405\n",
      "epoch 77; iter: 0; batch classifier loss: 0.448536; batch adversarial loss: 0.606518\n",
      "epoch 78; iter: 0; batch classifier loss: 0.451813; batch adversarial loss: 0.543696\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433371; batch adversarial loss: 0.516558\n",
      "epoch 80; iter: 0; batch classifier loss: 0.463329; batch adversarial loss: 0.478717\n",
      "epoch 81; iter: 0; batch classifier loss: 0.341115; batch adversarial loss: 0.645849\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412555; batch adversarial loss: 0.552410\n",
      "epoch 83; iter: 0; batch classifier loss: 0.445773; batch adversarial loss: 0.534670\n",
      "epoch 84; iter: 0; batch classifier loss: 0.350295; batch adversarial loss: 0.561629\n",
      "epoch 85; iter: 0; batch classifier loss: 0.421673; batch adversarial loss: 0.562394\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377750; batch adversarial loss: 0.516393\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418936; batch adversarial loss: 0.525427\n",
      "epoch 88; iter: 0; batch classifier loss: 0.407531; batch adversarial loss: 0.553855\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375070; batch adversarial loss: 0.629821\n",
      "epoch 90; iter: 0; batch classifier loss: 0.424644; batch adversarial loss: 0.572482\n",
      "epoch 91; iter: 0; batch classifier loss: 0.341228; batch adversarial loss: 0.527097\n",
      "epoch 92; iter: 0; batch classifier loss: 0.342092; batch adversarial loss: 0.609391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.465978; batch adversarial loss: 0.498977\n",
      "epoch 94; iter: 0; batch classifier loss: 0.330989; batch adversarial loss: 0.451758\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365739; batch adversarial loss: 0.489785\n",
      "epoch 96; iter: 0; batch classifier loss: 0.413235; batch adversarial loss: 0.563140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.332233; batch adversarial loss: 0.516230\n",
      "epoch 98; iter: 0; batch classifier loss: 0.334551; batch adversarial loss: 0.591363\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355296; batch adversarial loss: 0.581880\n",
      "epoch 100; iter: 0; batch classifier loss: 0.337291; batch adversarial loss: 0.459789\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394266; batch adversarial loss: 0.479378\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355183; batch adversarial loss: 0.525864\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373484; batch adversarial loss: 0.536630\n",
      "epoch 104; iter: 0; batch classifier loss: 0.340775; batch adversarial loss: 0.526627\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360429; batch adversarial loss: 0.552175\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374518; batch adversarial loss: 0.555266\n",
      "epoch 107; iter: 0; batch classifier loss: 0.340158; batch adversarial loss: 0.508323\n",
      "epoch 108; iter: 0; batch classifier loss: 0.389028; batch adversarial loss: 0.506441\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415639; batch adversarial loss: 0.591173\n",
      "epoch 110; iter: 0; batch classifier loss: 0.469428; batch adversarial loss: 0.636092\n",
      "epoch 111; iter: 0; batch classifier loss: 0.402506; batch adversarial loss: 0.571036\n",
      "epoch 112; iter: 0; batch classifier loss: 0.406249; batch adversarial loss: 0.572865\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375331; batch adversarial loss: 0.488388\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357410; batch adversarial loss: 0.581355\n",
      "epoch 115; iter: 0; batch classifier loss: 0.399805; batch adversarial loss: 0.552220\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410900; batch adversarial loss: 0.657374\n",
      "epoch 117; iter: 0; batch classifier loss: 0.353120; batch adversarial loss: 0.515908\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410485; batch adversarial loss: 0.600560\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347890; batch adversarial loss: 0.516635\n",
      "epoch 120; iter: 0; batch classifier loss: 0.404697; batch adversarial loss: 0.508651\n",
      "epoch 121; iter: 0; batch classifier loss: 0.462842; batch adversarial loss: 0.535595\n",
      "epoch 122; iter: 0; batch classifier loss: 0.396632; batch adversarial loss: 0.580646\n",
      "epoch 123; iter: 0; batch classifier loss: 0.422309; batch adversarial loss: 0.573270\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347851; batch adversarial loss: 0.582363\n",
      "epoch 125; iter: 0; batch classifier loss: 0.422340; batch adversarial loss: 0.507379\n",
      "epoch 126; iter: 0; batch classifier loss: 0.455606; batch adversarial loss: 0.581213\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344022; batch adversarial loss: 0.489135\n",
      "epoch 128; iter: 0; batch classifier loss: 0.420598; batch adversarial loss: 0.562656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.429259; batch adversarial loss: 0.544832\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385564; batch adversarial loss: 0.589342\n",
      "epoch 131; iter: 0; batch classifier loss: 0.377063; batch adversarial loss: 0.582555\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377248; batch adversarial loss: 0.489018\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370461; batch adversarial loss: 0.497326\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374535; batch adversarial loss: 0.488731\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413899; batch adversarial loss: 0.609507\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372192; batch adversarial loss: 0.508379\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349468; batch adversarial loss: 0.517189\n",
      "epoch 138; iter: 0; batch classifier loss: 0.281988; batch adversarial loss: 0.526326\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332929; batch adversarial loss: 0.553587\n",
      "epoch 140; iter: 0; batch classifier loss: 0.353755; batch adversarial loss: 0.498595\n",
      "epoch 141; iter: 0; batch classifier loss: 0.425664; batch adversarial loss: 0.526117\n",
      "epoch 142; iter: 0; batch classifier loss: 0.352128; batch adversarial loss: 0.571903\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389499; batch adversarial loss: 0.571964\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437443; batch adversarial loss: 0.589896\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342872; batch adversarial loss: 0.562433\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369334; batch adversarial loss: 0.619083\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342279; batch adversarial loss: 0.535016\n",
      "epoch 148; iter: 0; batch classifier loss: 0.401529; batch adversarial loss: 0.479364\n",
      "epoch 149; iter: 0; batch classifier loss: 0.371601; batch adversarial loss: 0.525460\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359455; batch adversarial loss: 0.544336\n",
      "epoch 151; iter: 0; batch classifier loss: 0.397024; batch adversarial loss: 0.610531\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355872; batch adversarial loss: 0.506631\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316352; batch adversarial loss: 0.536873\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376991; batch adversarial loss: 0.564521\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349243; batch adversarial loss: 0.479385\n",
      "epoch 156; iter: 0; batch classifier loss: 0.320454; batch adversarial loss: 0.562386\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376223; batch adversarial loss: 0.488639\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383004; batch adversarial loss: 0.498329\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361746; batch adversarial loss: 0.516847\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390299; batch adversarial loss: 0.525612\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372405; batch adversarial loss: 0.554013\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326776; batch adversarial loss: 0.591386\n",
      "epoch 163; iter: 0; batch classifier loss: 0.400983; batch adversarial loss: 0.573642\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334500; batch adversarial loss: 0.532229\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358517; batch adversarial loss: 0.535973\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373404; batch adversarial loss: 0.601375\n",
      "epoch 167; iter: 0; batch classifier loss: 0.418246; batch adversarial loss: 0.516640\n",
      "epoch 168; iter: 0; batch classifier loss: 0.309251; batch adversarial loss: 0.552133\n",
      "epoch 169; iter: 0; batch classifier loss: 0.346300; batch adversarial loss: 0.477985\n",
      "epoch 170; iter: 0; batch classifier loss: 0.434220; batch adversarial loss: 0.507251\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295210; batch adversarial loss: 0.526051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.380280; batch adversarial loss: 0.545230\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346002; batch adversarial loss: 0.535287\n",
      "epoch 174; iter: 0; batch classifier loss: 0.403840; batch adversarial loss: 0.489868\n",
      "epoch 175; iter: 0; batch classifier loss: 0.404932; batch adversarial loss: 0.498996\n",
      "epoch 176; iter: 0; batch classifier loss: 0.390482; batch adversarial loss: 0.480601\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354135; batch adversarial loss: 0.562471\n",
      "epoch 178; iter: 0; batch classifier loss: 0.276459; batch adversarial loss: 0.507910\n",
      "epoch 179; iter: 0; batch classifier loss: 0.335124; batch adversarial loss: 0.544390\n",
      "epoch 180; iter: 0; batch classifier loss: 0.410983; batch adversarial loss: 0.451095\n",
      "epoch 181; iter: 0; batch classifier loss: 0.424359; batch adversarial loss: 0.480014\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380010; batch adversarial loss: 0.451894\n",
      "epoch 183; iter: 0; batch classifier loss: 0.398133; batch adversarial loss: 0.554101\n",
      "epoch 184; iter: 0; batch classifier loss: 0.395745; batch adversarial loss: 0.544159\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319408; batch adversarial loss: 0.590555\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367588; batch adversarial loss: 0.572699\n",
      "epoch 187; iter: 0; batch classifier loss: 0.344993; batch adversarial loss: 0.581496\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365238; batch adversarial loss: 0.562807\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323517; batch adversarial loss: 0.582056\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328981; batch adversarial loss: 0.489103\n",
      "epoch 191; iter: 0; batch classifier loss: 0.397854; batch adversarial loss: 0.535823\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356437; batch adversarial loss: 0.628839\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325848; batch adversarial loss: 0.571954\n",
      "epoch 194; iter: 0; batch classifier loss: 0.361486; batch adversarial loss: 0.628302\n",
      "epoch 195; iter: 0; batch classifier loss: 0.372971; batch adversarial loss: 0.610439\n",
      "epoch 196; iter: 0; batch classifier loss: 0.333061; batch adversarial loss: 0.544753\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345459; batch adversarial loss: 0.498324\n",
      "epoch 198; iter: 0; batch classifier loss: 0.449187; batch adversarial loss: 0.516956\n",
      "epoch 199; iter: 0; batch classifier loss: 0.389672; batch adversarial loss: 0.526263\n",
      "epoch 0; iter: 0; batch classifier loss: 0.777027; batch adversarial loss: 0.765121\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608103; batch adversarial loss: 0.696785\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594204; batch adversarial loss: 0.678730\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566237; batch adversarial loss: 0.647900\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559725; batch adversarial loss: 0.619863\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564448; batch adversarial loss: 0.615479\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557429; batch adversarial loss: 0.627736\n",
      "epoch 7; iter: 0; batch classifier loss: 0.500314; batch adversarial loss: 0.565787\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520388; batch adversarial loss: 0.579440\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512708; batch adversarial loss: 0.572612\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554573; batch adversarial loss: 0.574834\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586969; batch adversarial loss: 0.613161\n",
      "epoch 12; iter: 0; batch classifier loss: 0.592784; batch adversarial loss: 0.627439\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501313; batch adversarial loss: 0.628107\n",
      "epoch 14; iter: 0; batch classifier loss: 0.567791; batch adversarial loss: 0.613607\n",
      "epoch 15; iter: 0; batch classifier loss: 0.586158; batch adversarial loss: 0.578595\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493104; batch adversarial loss: 0.648434\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507522; batch adversarial loss: 0.538023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530382; batch adversarial loss: 0.608635\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525950; batch adversarial loss: 0.629861\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525435; batch adversarial loss: 0.650192\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522019; batch adversarial loss: 0.593155\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491641; batch adversarial loss: 0.552188\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505052; batch adversarial loss: 0.601265\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517474; batch adversarial loss: 0.610228\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476432; batch adversarial loss: 0.544818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.492664; batch adversarial loss: 0.639164\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495991; batch adversarial loss: 0.550841\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429506; batch adversarial loss: 0.550649\n",
      "epoch 29; iter: 0; batch classifier loss: 0.426602; batch adversarial loss: 0.557397\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487755; batch adversarial loss: 0.619969\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432195; batch adversarial loss: 0.651978\n",
      "epoch 32; iter: 0; batch classifier loss: 0.505330; batch adversarial loss: 0.525272\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475003; batch adversarial loss: 0.489746\n",
      "epoch 34; iter: 0; batch classifier loss: 0.503813; batch adversarial loss: 0.603667\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434445; batch adversarial loss: 0.579392\n",
      "epoch 36; iter: 0; batch classifier loss: 0.522999; batch adversarial loss: 0.554182\n",
      "epoch 37; iter: 0; batch classifier loss: 0.419415; batch adversarial loss: 0.570814\n",
      "epoch 38; iter: 0; batch classifier loss: 0.516379; batch adversarial loss: 0.553865\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435611; batch adversarial loss: 0.469127\n",
      "epoch 40; iter: 0; batch classifier loss: 0.528287; batch adversarial loss: 0.604771\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461708; batch adversarial loss: 0.587753\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469894; batch adversarial loss: 0.509987\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454806; batch adversarial loss: 0.684465\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424481; batch adversarial loss: 0.536197\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454665; batch adversarial loss: 0.526480\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454681; batch adversarial loss: 0.544664\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443826; batch adversarial loss: 0.545018\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417097; batch adversarial loss: 0.606187\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419557; batch adversarial loss: 0.519149\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391698; batch adversarial loss: 0.527339\n",
      "epoch 51; iter: 0; batch classifier loss: 0.338085; batch adversarial loss: 0.606786\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430290; batch adversarial loss: 0.639674\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401456; batch adversarial loss: 0.561856\n",
      "epoch 54; iter: 0; batch classifier loss: 0.364576; batch adversarial loss: 0.596434\n",
      "epoch 55; iter: 0; batch classifier loss: 0.455570; batch adversarial loss: 0.492965\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413196; batch adversarial loss: 0.589223\n",
      "epoch 57; iter: 0; batch classifier loss: 0.503052; batch adversarial loss: 0.552593\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360312; batch adversarial loss: 0.536860\n",
      "epoch 59; iter: 0; batch classifier loss: 0.491576; batch adversarial loss: 0.570951\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398408; batch adversarial loss: 0.623709\n",
      "epoch 61; iter: 0; batch classifier loss: 0.471059; batch adversarial loss: 0.509642\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378734; batch adversarial loss: 0.570912\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400026; batch adversarial loss: 0.509828\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440757; batch adversarial loss: 0.492784\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423219; batch adversarial loss: 0.536183\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387612; batch adversarial loss: 0.475014\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380856; batch adversarial loss: 0.492849\n",
      "epoch 68; iter: 0; batch classifier loss: 0.458086; batch adversarial loss: 0.492628\n",
      "epoch 69; iter: 0; batch classifier loss: 0.476031; batch adversarial loss: 0.562259\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353499; batch adversarial loss: 0.727589\n",
      "epoch 71; iter: 0; batch classifier loss: 0.459501; batch adversarial loss: 0.500912\n",
      "epoch 72; iter: 0; batch classifier loss: 0.424630; batch adversarial loss: 0.701409\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409634; batch adversarial loss: 0.562573\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416532; batch adversarial loss: 0.510049\n",
      "epoch 75; iter: 0; batch classifier loss: 0.455914; batch adversarial loss: 0.562706\n",
      "epoch 76; iter: 0; batch classifier loss: 0.437829; batch adversarial loss: 0.492274\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386980; batch adversarial loss: 0.579679\n",
      "epoch 78; iter: 0; batch classifier loss: 0.385226; batch adversarial loss: 0.589378\n",
      "epoch 79; iter: 0; batch classifier loss: 0.434598; batch adversarial loss: 0.569038\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371812; batch adversarial loss: 0.643440\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400451; batch adversarial loss: 0.568487\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376573; batch adversarial loss: 0.650199\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400019; batch adversarial loss: 0.676991\n",
      "epoch 84; iter: 0; batch classifier loss: 0.379235; batch adversarial loss: 0.563241\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456642; batch adversarial loss: 0.535612\n",
      "epoch 86; iter: 0; batch classifier loss: 0.423849; batch adversarial loss: 0.597863\n",
      "epoch 87; iter: 0; batch classifier loss: 0.518463; batch adversarial loss: 0.571067\n",
      "epoch 88; iter: 0; batch classifier loss: 0.439116; batch adversarial loss: 0.579849\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358253; batch adversarial loss: 0.631237\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368702; batch adversarial loss: 0.528412\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399018; batch adversarial loss: 0.545370\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386567; batch adversarial loss: 0.493969\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439347; batch adversarial loss: 0.570678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381995; batch adversarial loss: 0.562296\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384209; batch adversarial loss: 0.527724\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425591; batch adversarial loss: 0.536091\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364257; batch adversarial loss: 0.492904\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411634; batch adversarial loss: 0.519048\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413683; batch adversarial loss: 0.579651\n",
      "epoch 100; iter: 0; batch classifier loss: 0.409854; batch adversarial loss: 0.518605\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382255; batch adversarial loss: 0.544838\n",
      "epoch 102; iter: 0; batch classifier loss: 0.327466; batch adversarial loss: 0.579805\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426101; batch adversarial loss: 0.544941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397135; batch adversarial loss: 0.518633\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365193; batch adversarial loss: 0.527632\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383767; batch adversarial loss: 0.579866\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421879; batch adversarial loss: 0.632108\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378787; batch adversarial loss: 0.553647\n",
      "epoch 109; iter: 0; batch classifier loss: 0.311640; batch adversarial loss: 0.562396\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388519; batch adversarial loss: 0.448851\n",
      "epoch 111; iter: 0; batch classifier loss: 0.295284; batch adversarial loss: 0.553743\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371701; batch adversarial loss: 0.588637\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355722; batch adversarial loss: 0.518067\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350073; batch adversarial loss: 0.518234\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394333; batch adversarial loss: 0.632736\n",
      "epoch 116; iter: 0; batch classifier loss: 0.399487; batch adversarial loss: 0.509658\n",
      "epoch 117; iter: 0; batch classifier loss: 0.455943; batch adversarial loss: 0.606730\n",
      "epoch 118; iter: 0; batch classifier loss: 0.359116; batch adversarial loss: 0.669389\n",
      "epoch 119; iter: 0; batch classifier loss: 0.346926; batch adversarial loss: 0.553766\n",
      "epoch 120; iter: 0; batch classifier loss: 0.464678; batch adversarial loss: 0.639831\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383761; batch adversarial loss: 0.554005\n",
      "epoch 122; iter: 0; batch classifier loss: 0.341932; batch adversarial loss: 0.510360\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366196; batch adversarial loss: 0.605536\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359468; batch adversarial loss: 0.536435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.387428; batch adversarial loss: 0.536355\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379540; batch adversarial loss: 0.597513\n",
      "epoch 127; iter: 0; batch classifier loss: 0.548258; batch adversarial loss: 0.519008\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381388; batch adversarial loss: 0.510195\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385237; batch adversarial loss: 0.588562\n",
      "epoch 130; iter: 0; batch classifier loss: 0.399131; batch adversarial loss: 0.554055\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388992; batch adversarial loss: 0.501389\n",
      "epoch 132; iter: 0; batch classifier loss: 0.397780; batch adversarial loss: 0.509395\n",
      "epoch 133; iter: 0; batch classifier loss: 0.325107; batch adversarial loss: 0.544649\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337476; batch adversarial loss: 0.562332\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360857; batch adversarial loss: 0.545045\n",
      "epoch 136; iter: 0; batch classifier loss: 0.405243; batch adversarial loss: 0.649156\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349249; batch adversarial loss: 0.588486\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383256; batch adversarial loss: 0.562403\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372673; batch adversarial loss: 0.606206\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361151; batch adversarial loss: 0.492243\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379919; batch adversarial loss: 0.526856\n",
      "epoch 142; iter: 0; batch classifier loss: 0.385506; batch adversarial loss: 0.571443\n",
      "epoch 143; iter: 0; batch classifier loss: 0.424718; batch adversarial loss: 0.570742\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337143; batch adversarial loss: 0.509933\n",
      "epoch 145; iter: 0; batch classifier loss: 0.437185; batch adversarial loss: 0.552574\n",
      "epoch 146; iter: 0; batch classifier loss: 0.420126; batch adversarial loss: 0.597140\n",
      "epoch 147; iter: 0; batch classifier loss: 0.417005; batch adversarial loss: 0.589735\n",
      "epoch 148; iter: 0; batch classifier loss: 0.311716; batch adversarial loss: 0.587481\n",
      "epoch 149; iter: 0; batch classifier loss: 0.429857; batch adversarial loss: 0.525346\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364865; batch adversarial loss: 0.517555\n",
      "epoch 151; iter: 0; batch classifier loss: 0.412169; batch adversarial loss: 0.528041\n",
      "epoch 152; iter: 0; batch classifier loss: 0.313779; batch adversarial loss: 0.625765\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368524; batch adversarial loss: 0.582863\n",
      "epoch 154; iter: 0; batch classifier loss: 0.287319; batch adversarial loss: 0.562263\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389501; batch adversarial loss: 0.580309\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337259; batch adversarial loss: 0.555031\n",
      "epoch 157; iter: 0; batch classifier loss: 0.486824; batch adversarial loss: 0.467160\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382784; batch adversarial loss: 0.578996\n",
      "epoch 159; iter: 0; batch classifier loss: 0.392355; batch adversarial loss: 0.493518\n",
      "epoch 160; iter: 0; batch classifier loss: 0.286314; batch adversarial loss: 0.595929\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335396; batch adversarial loss: 0.561608\n",
      "epoch 162; iter: 0; batch classifier loss: 0.378948; batch adversarial loss: 0.552997\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391782; batch adversarial loss: 0.613391\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368143; batch adversarial loss: 0.546147\n",
      "epoch 165; iter: 0; batch classifier loss: 0.412513; batch adversarial loss: 0.544553\n",
      "epoch 166; iter: 0; batch classifier loss: 0.404797; batch adversarial loss: 0.597061\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353166; batch adversarial loss: 0.458671\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359176; batch adversarial loss: 0.597517\n",
      "epoch 169; iter: 0; batch classifier loss: 0.411767; batch adversarial loss: 0.458709\n",
      "epoch 170; iter: 0; batch classifier loss: 0.291260; batch adversarial loss: 0.536284\n",
      "epoch 171; iter: 0; batch classifier loss: 0.379726; batch adversarial loss: 0.571069\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358408; batch adversarial loss: 0.545025\n",
      "epoch 173; iter: 0; batch classifier loss: 0.352641; batch adversarial loss: 0.605790\n",
      "epoch 174; iter: 0; batch classifier loss: 0.337609; batch adversarial loss: 0.536152\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365495; batch adversarial loss: 0.501371\n",
      "epoch 176; iter: 0; batch classifier loss: 0.300419; batch adversarial loss: 0.606165\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352881; batch adversarial loss: 0.545026\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320118; batch adversarial loss: 0.561717\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384208; batch adversarial loss: 0.562701\n",
      "epoch 180; iter: 0; batch classifier loss: 0.342172; batch adversarial loss: 0.597181\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338393; batch adversarial loss: 0.562414\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402796; batch adversarial loss: 0.606165\n",
      "epoch 183; iter: 0; batch classifier loss: 0.383075; batch adversarial loss: 0.490339\n",
      "epoch 184; iter: 0; batch classifier loss: 0.417622; batch adversarial loss: 0.500374\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371370; batch adversarial loss: 0.517755\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347026; batch adversarial loss: 0.507702\n",
      "epoch 187; iter: 0; batch classifier loss: 0.452413; batch adversarial loss: 0.651168\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313076; batch adversarial loss: 0.595705\n",
      "epoch 189; iter: 0; batch classifier loss: 0.326127; batch adversarial loss: 0.659378\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345983; batch adversarial loss: 0.660494\n",
      "epoch 191; iter: 0; batch classifier loss: 0.388204; batch adversarial loss: 0.589073\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384792; batch adversarial loss: 0.543980\n",
      "epoch 193; iter: 0; batch classifier loss: 0.443958; batch adversarial loss: 0.581204\n",
      "epoch 194; iter: 0; batch classifier loss: 0.298374; batch adversarial loss: 0.509156\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350274; batch adversarial loss: 0.623223\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341275; batch adversarial loss: 0.564627\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349280; batch adversarial loss: 0.509957\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352858; batch adversarial loss: 0.578983\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362450; batch adversarial loss: 0.597220\n",
      "epoch 0; iter: 0; batch classifier loss: 0.749524; batch adversarial loss: 0.683742\n",
      "epoch 1; iter: 0; batch classifier loss: 0.645126; batch adversarial loss: 0.664672\n",
      "epoch 2; iter: 0; batch classifier loss: 0.592198; batch adversarial loss: 0.634822\n",
      "epoch 3; iter: 0; batch classifier loss: 0.532516; batch adversarial loss: 0.643869\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539302; batch adversarial loss: 0.611280\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512312; batch adversarial loss: 0.601076\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520664; batch adversarial loss: 0.589216\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556825; batch adversarial loss: 0.591084\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525338; batch adversarial loss: 0.536636\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496742; batch adversarial loss: 0.594420\n",
      "epoch 10; iter: 0; batch classifier loss: 0.599504; batch adversarial loss: 0.542997\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579565; batch adversarial loss: 0.605687\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518900; batch adversarial loss: 0.586760\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516365; batch adversarial loss: 0.574274\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503387; batch adversarial loss: 0.598364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.608537; batch adversarial loss: 0.585565\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497218; batch adversarial loss: 0.541983\n",
      "epoch 17; iter: 0; batch classifier loss: 0.562237; batch adversarial loss: 0.576699\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521459; batch adversarial loss: 0.569301\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519257; batch adversarial loss: 0.546692\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478337; batch adversarial loss: 0.596768\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494842; batch adversarial loss: 0.619504\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432530; batch adversarial loss: 0.517489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.440922; batch adversarial loss: 0.517818\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456166; batch adversarial loss: 0.523347\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497362; batch adversarial loss: 0.546093\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476217; batch adversarial loss: 0.544565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442022; batch adversarial loss: 0.538577\n",
      "epoch 28; iter: 0; batch classifier loss: 0.547598; batch adversarial loss: 0.562582\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466416; batch adversarial loss: 0.536309\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510567; batch adversarial loss: 0.450310\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449340; batch adversarial loss: 0.598784\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496131; batch adversarial loss: 0.580353\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450953; batch adversarial loss: 0.544743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.409948; batch adversarial loss: 0.580046\n",
      "epoch 35; iter: 0; batch classifier loss: 0.357511; batch adversarial loss: 0.553710\n",
      "epoch 36; iter: 0; batch classifier loss: 0.408874; batch adversarial loss: 0.473267\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424991; batch adversarial loss: 0.615796\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420257; batch adversarial loss: 0.473139\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466395; batch adversarial loss: 0.560259\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432665; batch adversarial loss: 0.499159\n",
      "epoch 41; iter: 0; batch classifier loss: 0.379965; batch adversarial loss: 0.504814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423214; batch adversarial loss: 0.518288\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455685; batch adversarial loss: 0.447953\n",
      "epoch 44; iter: 0; batch classifier loss: 0.452932; batch adversarial loss: 0.527862\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464007; batch adversarial loss: 0.528045\n",
      "epoch 46; iter: 0; batch classifier loss: 0.468778; batch adversarial loss: 0.545420\n",
      "epoch 47; iter: 0; batch classifier loss: 0.539351; batch adversarial loss: 0.526130\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486887; batch adversarial loss: 0.611200\n",
      "epoch 49; iter: 0; batch classifier loss: 0.363666; batch adversarial loss: 0.497240\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423877; batch adversarial loss: 0.544177\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411664; batch adversarial loss: 0.488714\n",
      "epoch 52; iter: 0; batch classifier loss: 0.468642; batch adversarial loss: 0.535670\n",
      "epoch 53; iter: 0; batch classifier loss: 0.476740; batch adversarial loss: 0.506963\n",
      "epoch 54; iter: 0; batch classifier loss: 0.545055; batch adversarial loss: 0.545115\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422316; batch adversarial loss: 0.554423\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457269; batch adversarial loss: 0.620185\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415059; batch adversarial loss: 0.572633\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458346; batch adversarial loss: 0.573489\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439243; batch adversarial loss: 0.544660\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391713; batch adversarial loss: 0.580282\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408373; batch adversarial loss: 0.479366\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426032; batch adversarial loss: 0.553490\n",
      "epoch 63; iter: 0; batch classifier loss: 0.428964; batch adversarial loss: 0.469892\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466955; batch adversarial loss: 0.488758\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413752; batch adversarial loss: 0.514481\n",
      "epoch 66; iter: 0; batch classifier loss: 0.370570; batch adversarial loss: 0.516026\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392269; batch adversarial loss: 0.573101\n",
      "epoch 68; iter: 0; batch classifier loss: 0.396319; batch adversarial loss: 0.553950\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389281; batch adversarial loss: 0.532715\n",
      "epoch 70; iter: 0; batch classifier loss: 0.450092; batch adversarial loss: 0.544333\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399850; batch adversarial loss: 0.553216\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457600; batch adversarial loss: 0.498450\n",
      "epoch 73; iter: 0; batch classifier loss: 0.413805; batch adversarial loss: 0.570373\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411111; batch adversarial loss: 0.518119\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384783; batch adversarial loss: 0.559651\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424202; batch adversarial loss: 0.524589\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407177; batch adversarial loss: 0.561646\n",
      "epoch 78; iter: 0; batch classifier loss: 0.492409; batch adversarial loss: 0.634820\n",
      "epoch 79; iter: 0; batch classifier loss: 0.346523; batch adversarial loss: 0.546761\n",
      "epoch 80; iter: 0; batch classifier loss: 0.415976; batch adversarial loss: 0.589040\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388738; batch adversarial loss: 0.572165\n",
      "epoch 82; iter: 0; batch classifier loss: 0.347353; batch adversarial loss: 0.518198\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411790; batch adversarial loss: 0.537463\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404623; batch adversarial loss: 0.596632\n",
      "epoch 85; iter: 0; batch classifier loss: 0.422051; batch adversarial loss: 0.541202\n",
      "epoch 86; iter: 0; batch classifier loss: 0.337470; batch adversarial loss: 0.554898\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440201; batch adversarial loss: 0.526445\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358296; batch adversarial loss: 0.578602\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385833; batch adversarial loss: 0.572488\n",
      "epoch 90; iter: 0; batch classifier loss: 0.389684; batch adversarial loss: 0.579793\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365961; batch adversarial loss: 0.513609\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376343; batch adversarial loss: 0.540808\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398101; batch adversarial loss: 0.534712\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380998; batch adversarial loss: 0.525743\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413583; batch adversarial loss: 0.548775\n",
      "epoch 96; iter: 0; batch classifier loss: 0.325801; batch adversarial loss: 0.575306\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388630; batch adversarial loss: 0.568402\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369218; batch adversarial loss: 0.583270\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425453; batch adversarial loss: 0.545573\n",
      "epoch 100; iter: 0; batch classifier loss: 0.324292; batch adversarial loss: 0.620747\n",
      "epoch 101; iter: 0; batch classifier loss: 0.444004; batch adversarial loss: 0.546077\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391923; batch adversarial loss: 0.563354\n",
      "epoch 103; iter: 0; batch classifier loss: 0.459449; batch adversarial loss: 0.543494\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392224; batch adversarial loss: 0.572358\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417951; batch adversarial loss: 0.573394\n",
      "epoch 106; iter: 0; batch classifier loss: 0.439698; batch adversarial loss: 0.535226\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403273; batch adversarial loss: 0.543163\n",
      "epoch 108; iter: 0; batch classifier loss: 0.317212; batch adversarial loss: 0.581816\n",
      "epoch 109; iter: 0; batch classifier loss: 0.399137; batch adversarial loss: 0.516162\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386416; batch adversarial loss: 0.534669\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395353; batch adversarial loss: 0.513867\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364805; batch adversarial loss: 0.551881\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383340; batch adversarial loss: 0.523943\n",
      "epoch 114; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.516991\n",
      "epoch 115; iter: 0; batch classifier loss: 0.376719; batch adversarial loss: 0.525265\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406508; batch adversarial loss: 0.546752\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325644; batch adversarial loss: 0.506989\n",
      "epoch 118; iter: 0; batch classifier loss: 0.448471; batch adversarial loss: 0.655026\n",
      "epoch 119; iter: 0; batch classifier loss: 0.420917; batch adversarial loss: 0.532911\n",
      "epoch 120; iter: 0; batch classifier loss: 0.473300; batch adversarial loss: 0.636015\n",
      "epoch 121; iter: 0; batch classifier loss: 0.359544; batch adversarial loss: 0.562284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.416507; batch adversarial loss: 0.608152\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366519; batch adversarial loss: 0.526791\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348132; batch adversarial loss: 0.552932\n",
      "epoch 125; iter: 0; batch classifier loss: 0.358981; batch adversarial loss: 0.636513\n",
      "epoch 126; iter: 0; batch classifier loss: 0.414324; batch adversarial loss: 0.515734\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374275; batch adversarial loss: 0.570768\n",
      "epoch 128; iter: 0; batch classifier loss: 0.306273; batch adversarial loss: 0.479440\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364447; batch adversarial loss: 0.563734\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413498; batch adversarial loss: 0.506167\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351111; batch adversarial loss: 0.580471\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390319; batch adversarial loss: 0.511476\n",
      "epoch 133; iter: 0; batch classifier loss: 0.321816; batch adversarial loss: 0.599315\n",
      "epoch 134; iter: 0; batch classifier loss: 0.441418; batch adversarial loss: 0.570116\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377585; batch adversarial loss: 0.589249\n",
      "epoch 136; iter: 0; batch classifier loss: 0.295561; batch adversarial loss: 0.534828\n",
      "epoch 137; iter: 0; batch classifier loss: 0.279343; batch adversarial loss: 0.556230\n",
      "epoch 138; iter: 0; batch classifier loss: 0.367026; batch adversarial loss: 0.564922\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393654; batch adversarial loss: 0.505933\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399202; batch adversarial loss: 0.484903\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349174; batch adversarial loss: 0.620126\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335317; batch adversarial loss: 0.487548\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401616; batch adversarial loss: 0.465284\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380105; batch adversarial loss: 0.444156\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377185; batch adversarial loss: 0.623960\n",
      "epoch 146; iter: 0; batch classifier loss: 0.456535; batch adversarial loss: 0.561867\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369258; batch adversarial loss: 0.519839\n",
      "epoch 148; iter: 0; batch classifier loss: 0.424072; batch adversarial loss: 0.496251\n",
      "epoch 149; iter: 0; batch classifier loss: 0.311106; batch adversarial loss: 0.538175\n",
      "epoch 150; iter: 0; batch classifier loss: 0.331319; batch adversarial loss: 0.567814\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353245; batch adversarial loss: 0.511752\n",
      "epoch 152; iter: 0; batch classifier loss: 0.440934; batch adversarial loss: 0.518962\n",
      "epoch 153; iter: 0; batch classifier loss: 0.397588; batch adversarial loss: 0.508600\n",
      "epoch 154; iter: 0; batch classifier loss: 0.454688; batch adversarial loss: 0.563920\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371112; batch adversarial loss: 0.505617\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363516; batch adversarial loss: 0.563264\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371162; batch adversarial loss: 0.621692\n",
      "epoch 158; iter: 0; batch classifier loss: 0.302882; batch adversarial loss: 0.533511\n",
      "epoch 159; iter: 0; batch classifier loss: 0.421652; batch adversarial loss: 0.545745\n",
      "epoch 160; iter: 0; batch classifier loss: 0.295657; batch adversarial loss: 0.630621\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330153; batch adversarial loss: 0.487307\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328184; batch adversarial loss: 0.516153\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338186; batch adversarial loss: 0.525140\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337769; batch adversarial loss: 0.469316\n",
      "epoch 165; iter: 0; batch classifier loss: 0.429154; batch adversarial loss: 0.535369\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331990; batch adversarial loss: 0.545559\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383852; batch adversarial loss: 0.543368\n",
      "epoch 168; iter: 0; batch classifier loss: 0.381086; batch adversarial loss: 0.577403\n",
      "epoch 169; iter: 0; batch classifier loss: 0.305217; batch adversarial loss: 0.452952\n",
      "epoch 170; iter: 0; batch classifier loss: 0.300430; batch adversarial loss: 0.506283\n",
      "epoch 171; iter: 0; batch classifier loss: 0.423449; batch adversarial loss: 0.515269\n",
      "epoch 172; iter: 0; batch classifier loss: 0.308030; batch adversarial loss: 0.525761\n",
      "epoch 173; iter: 0; batch classifier loss: 0.391656; batch adversarial loss: 0.525447\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302066; batch adversarial loss: 0.600899\n",
      "epoch 175; iter: 0; batch classifier loss: 0.317173; batch adversarial loss: 0.569355\n",
      "epoch 176; iter: 0; batch classifier loss: 0.405031; batch adversarial loss: 0.518979\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387245; batch adversarial loss: 0.555173\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360428; batch adversarial loss: 0.512546\n",
      "epoch 179; iter: 0; batch classifier loss: 0.421005; batch adversarial loss: 0.476544\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389110; batch adversarial loss: 0.589671\n",
      "epoch 181; iter: 0; batch classifier loss: 0.335056; batch adversarial loss: 0.504350\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383345; batch adversarial loss: 0.504323\n",
      "epoch 183; iter: 0; batch classifier loss: 0.488689; batch adversarial loss: 0.592445\n",
      "epoch 184; iter: 0; batch classifier loss: 0.388263; batch adversarial loss: 0.634196\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392332; batch adversarial loss: 0.514173\n",
      "epoch 186; iter: 0; batch classifier loss: 0.426688; batch adversarial loss: 0.589815\n",
      "epoch 187; iter: 0; batch classifier loss: 0.401937; batch adversarial loss: 0.440448\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374223; batch adversarial loss: 0.533563\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341283; batch adversarial loss: 0.670208\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357354; batch adversarial loss: 0.564248\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389439; batch adversarial loss: 0.594946\n",
      "epoch 192; iter: 0; batch classifier loss: 0.414188; batch adversarial loss: 0.477592\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351890; batch adversarial loss: 0.583049\n",
      "epoch 194; iter: 0; batch classifier loss: 0.378331; batch adversarial loss: 0.601388\n",
      "epoch 195; iter: 0; batch classifier loss: 0.439285; batch adversarial loss: 0.507839\n",
      "epoch 196; iter: 0; batch classifier loss: 0.424077; batch adversarial loss: 0.545630\n",
      "epoch 197; iter: 0; batch classifier loss: 0.376297; batch adversarial loss: 0.563460\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366135; batch adversarial loss: 0.560880\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339387; batch adversarial loss: 0.470351\n",
      "epoch 0; iter: 0; batch classifier loss: 0.870893; batch adversarial loss: 0.843471\n",
      "epoch 1; iter: 0; batch classifier loss: 0.720866; batch adversarial loss: 0.826245\n",
      "epoch 2; iter: 0; batch classifier loss: 0.680716; batch adversarial loss: 0.768184\n",
      "epoch 3; iter: 0; batch classifier loss: 0.676725; batch adversarial loss: 0.715001\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619180; batch adversarial loss: 0.661918\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557726; batch adversarial loss: 0.615857\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567461; batch adversarial loss: 0.617773\n",
      "epoch 7; iter: 0; batch classifier loss: 0.521132; batch adversarial loss: 0.611794\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577044; batch adversarial loss: 0.596985\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525702; batch adversarial loss: 0.574829\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564843; batch adversarial loss: 0.572978\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529384; batch adversarial loss: 0.594135\n",
      "epoch 12; iter: 0; batch classifier loss: 0.444002; batch adversarial loss: 0.530635\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518456; batch adversarial loss: 0.592729\n",
      "epoch 14; iter: 0; batch classifier loss: 0.496516; batch adversarial loss: 0.615404\n",
      "epoch 15; iter: 0; batch classifier loss: 0.460312; batch adversarial loss: 0.556146\n",
      "epoch 16; iter: 0; batch classifier loss: 0.444440; batch adversarial loss: 0.556172\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543262; batch adversarial loss: 0.580724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.469229; batch adversarial loss: 0.589284\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550820; batch adversarial loss: 0.534512\n",
      "epoch 20; iter: 0; batch classifier loss: 0.438578; batch adversarial loss: 0.552959\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514298; batch adversarial loss: 0.510359\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478482; batch adversarial loss: 0.527173\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508316; batch adversarial loss: 0.507893\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485919; batch adversarial loss: 0.541588\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515988; batch adversarial loss: 0.631367\n",
      "epoch 26; iter: 0; batch classifier loss: 0.398145; batch adversarial loss: 0.564019\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462789; batch adversarial loss: 0.630337\n",
      "epoch 28; iter: 0; batch classifier loss: 0.553349; batch adversarial loss: 0.565771\n",
      "epoch 29; iter: 0; batch classifier loss: 0.539941; batch adversarial loss: 0.649671\n",
      "epoch 30; iter: 0; batch classifier loss: 0.522979; batch adversarial loss: 0.505031\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473363; batch adversarial loss: 0.550151\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400827; batch adversarial loss: 0.467002\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514743; batch adversarial loss: 0.615448\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480674; batch adversarial loss: 0.547059\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396389; batch adversarial loss: 0.554453\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472389; batch adversarial loss: 0.537249\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471962; batch adversarial loss: 0.562149\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398038; batch adversarial loss: 0.527544\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483623; batch adversarial loss: 0.561847\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404385; batch adversarial loss: 0.561607\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471848; batch adversarial loss: 0.550928\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438552; batch adversarial loss: 0.518151\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447914; batch adversarial loss: 0.544784\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410307; batch adversarial loss: 0.491722\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459420; batch adversarial loss: 0.606676\n",
      "epoch 46; iter: 0; batch classifier loss: 0.449294; batch adversarial loss: 0.562377\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468219; batch adversarial loss: 0.608419\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407194; batch adversarial loss: 0.518382\n",
      "epoch 49; iter: 0; batch classifier loss: 0.363322; batch adversarial loss: 0.526370\n",
      "epoch 50; iter: 0; batch classifier loss: 0.419240; batch adversarial loss: 0.609329\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416335; batch adversarial loss: 0.553612\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449058; batch adversarial loss: 0.553021\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442600; batch adversarial loss: 0.581512\n",
      "epoch 54; iter: 0; batch classifier loss: 0.461052; batch adversarial loss: 0.553818\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389262; batch adversarial loss: 0.517230\n",
      "epoch 56; iter: 0; batch classifier loss: 0.402882; batch adversarial loss: 0.507632\n",
      "epoch 57; iter: 0; batch classifier loss: 0.361513; batch adversarial loss: 0.563071\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423460; batch adversarial loss: 0.719130\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428364; batch adversarial loss: 0.581324\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423516; batch adversarial loss: 0.572146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.485908; batch adversarial loss: 0.553072\n",
      "epoch 62; iter: 0; batch classifier loss: 0.361920; batch adversarial loss: 0.553308\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450196; batch adversarial loss: 0.535523\n",
      "epoch 64; iter: 0; batch classifier loss: 0.468596; batch adversarial loss: 0.508391\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457523; batch adversarial loss: 0.580476\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400574; batch adversarial loss: 0.462877\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416934; batch adversarial loss: 0.553930\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376708; batch adversarial loss: 0.590981\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371574; batch adversarial loss: 0.553547\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401307; batch adversarial loss: 0.516895\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394613; batch adversarial loss: 0.544079\n",
      "epoch 72; iter: 0; batch classifier loss: 0.384889; batch adversarial loss: 0.627257\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369964; batch adversarial loss: 0.479824\n",
      "epoch 74; iter: 0; batch classifier loss: 0.501020; batch adversarial loss: 0.553887\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395911; batch adversarial loss: 0.572203\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383344; batch adversarial loss: 0.453068\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395072; batch adversarial loss: 0.672410\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378424; batch adversarial loss: 0.489942\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354855; batch adversarial loss: 0.553461\n",
      "epoch 80; iter: 0; batch classifier loss: 0.459232; batch adversarial loss: 0.562360\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391235; batch adversarial loss: 0.544318\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407214; batch adversarial loss: 0.497150\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391894; batch adversarial loss: 0.487645\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426533; batch adversarial loss: 0.517611\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387794; batch adversarial loss: 0.478797\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421150; batch adversarial loss: 0.572340\n",
      "epoch 87; iter: 0; batch classifier loss: 0.349843; batch adversarial loss: 0.543500\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369139; batch adversarial loss: 0.570968\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358432; batch adversarial loss: 0.588197\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373091; batch adversarial loss: 0.629170\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396424; batch adversarial loss: 0.507733\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371050; batch adversarial loss: 0.588208\n",
      "epoch 93; iter: 0; batch classifier loss: 0.334230; batch adversarial loss: 0.602270\n",
      "epoch 94; iter: 0; batch classifier loss: 0.432730; batch adversarial loss: 0.562983\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430338; batch adversarial loss: 0.546310\n",
      "epoch 96; iter: 0; batch classifier loss: 0.473143; batch adversarial loss: 0.625198\n",
      "epoch 97; iter: 0; batch classifier loss: 0.406727; batch adversarial loss: 0.545655\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392110; batch adversarial loss: 0.535498\n",
      "epoch 99; iter: 0; batch classifier loss: 0.347864; batch adversarial loss: 0.463855\n",
      "epoch 100; iter: 0; batch classifier loss: 0.334467; batch adversarial loss: 0.536618\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406066; batch adversarial loss: 0.588824\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323734; batch adversarial loss: 0.536595\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346403; batch adversarial loss: 0.534579\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369928; batch adversarial loss: 0.580671\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371712; batch adversarial loss: 0.517946\n",
      "epoch 106; iter: 0; batch classifier loss: 0.469379; batch adversarial loss: 0.481616\n",
      "epoch 107; iter: 0; batch classifier loss: 0.415878; batch adversarial loss: 0.554792\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364629; batch adversarial loss: 0.516415\n",
      "epoch 109; iter: 0; batch classifier loss: 0.319366; batch adversarial loss: 0.489454\n",
      "epoch 110; iter: 0; batch classifier loss: 0.438996; batch adversarial loss: 0.499532\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347596; batch adversarial loss: 0.499567\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411555; batch adversarial loss: 0.544136\n",
      "epoch 113; iter: 0; batch classifier loss: 0.326142; batch adversarial loss: 0.599988\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412786; batch adversarial loss: 0.534350\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379086; batch adversarial loss: 0.544385\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372323; batch adversarial loss: 0.480351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.349966; batch adversarial loss: 0.452593\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340272; batch adversarial loss: 0.462072\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371331; batch adversarial loss: 0.526481\n",
      "epoch 120; iter: 0; batch classifier loss: 0.434241; batch adversarial loss: 0.572360\n",
      "epoch 121; iter: 0; batch classifier loss: 0.426567; batch adversarial loss: 0.588844\n",
      "epoch 122; iter: 0; batch classifier loss: 0.336378; batch adversarial loss: 0.489810\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339949; batch adversarial loss: 0.562077\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336569; batch adversarial loss: 0.535786\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387034; batch adversarial loss: 0.470443\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358689; batch adversarial loss: 0.545004\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367180; batch adversarial loss: 0.590580\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373453; batch adversarial loss: 0.554406\n",
      "epoch 129; iter: 0; batch classifier loss: 0.345837; batch adversarial loss: 0.498463\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360213; batch adversarial loss: 0.543742\n",
      "epoch 131; iter: 0; batch classifier loss: 0.317372; batch adversarial loss: 0.479330\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350812; batch adversarial loss: 0.553230\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395220; batch adversarial loss: 0.572599\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386872; batch adversarial loss: 0.517884\n",
      "epoch 135; iter: 0; batch classifier loss: 0.427366; batch adversarial loss: 0.555263\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363453; batch adversarial loss: 0.516893\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372173; batch adversarial loss: 0.536208\n",
      "epoch 138; iter: 0; batch classifier loss: 0.321727; batch adversarial loss: 0.590346\n",
      "epoch 139; iter: 0; batch classifier loss: 0.321586; batch adversarial loss: 0.509341\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409774; batch adversarial loss: 0.581369\n",
      "epoch 141; iter: 0; batch classifier loss: 0.397295; batch adversarial loss: 0.562370\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339190; batch adversarial loss: 0.582487\n",
      "epoch 143; iter: 0; batch classifier loss: 0.340324; batch adversarial loss: 0.507319\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366182; batch adversarial loss: 0.573488\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369175; batch adversarial loss: 0.581601\n",
      "epoch 146; iter: 0; batch classifier loss: 0.372999; batch adversarial loss: 0.625090\n",
      "epoch 147; iter: 0; batch classifier loss: 0.375794; batch adversarial loss: 0.580329\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337421; batch adversarial loss: 0.607548\n",
      "epoch 149; iter: 0; batch classifier loss: 0.397009; batch adversarial loss: 0.452177\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388353; batch adversarial loss: 0.618310\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374117; batch adversarial loss: 0.507136\n",
      "epoch 152; iter: 0; batch classifier loss: 0.433578; batch adversarial loss: 0.535323\n",
      "epoch 153; iter: 0; batch classifier loss: 0.318443; batch adversarial loss: 0.580756\n",
      "epoch 154; iter: 0; batch classifier loss: 0.331597; batch adversarial loss: 0.492348\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367053; batch adversarial loss: 0.490641\n",
      "epoch 156; iter: 0; batch classifier loss: 0.309603; batch adversarial loss: 0.516805\n",
      "epoch 157; iter: 0; batch classifier loss: 0.413485; batch adversarial loss: 0.571208\n",
      "epoch 158; iter: 0; batch classifier loss: 0.271089; batch adversarial loss: 0.525806\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290747; batch adversarial loss: 0.634519\n",
      "epoch 160; iter: 0; batch classifier loss: 0.303188; batch adversarial loss: 0.526390\n",
      "epoch 161; iter: 0; batch classifier loss: 0.297313; batch adversarial loss: 0.525397\n",
      "epoch 162; iter: 0; batch classifier loss: 0.342957; batch adversarial loss: 0.598369\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339781; batch adversarial loss: 0.554059\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369596; batch adversarial loss: 0.571473\n",
      "epoch 165; iter: 0; batch classifier loss: 0.298736; batch adversarial loss: 0.517143\n",
      "epoch 166; iter: 0; batch classifier loss: 0.310998; batch adversarial loss: 0.590778\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349671; batch adversarial loss: 0.581983\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354985; batch adversarial loss: 0.580781\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372997; batch adversarial loss: 0.517564\n",
      "epoch 170; iter: 0; batch classifier loss: 0.288931; batch adversarial loss: 0.526827\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384721; batch adversarial loss: 0.525977\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391665; batch adversarial loss: 0.535699\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321583; batch adversarial loss: 0.507681\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396236; batch adversarial loss: 0.480586\n",
      "epoch 175; iter: 0; batch classifier loss: 0.319324; batch adversarial loss: 0.515881\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343061; batch adversarial loss: 0.544144\n",
      "epoch 177; iter: 0; batch classifier loss: 0.349207; batch adversarial loss: 0.489603\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361583; batch adversarial loss: 0.490682\n",
      "epoch 179; iter: 0; batch classifier loss: 0.306617; batch adversarial loss: 0.525040\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316463; batch adversarial loss: 0.652864\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382553; batch adversarial loss: 0.544433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387283; batch adversarial loss: 0.526159\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387639; batch adversarial loss: 0.488841\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343235; batch adversarial loss: 0.506901\n",
      "epoch 185; iter: 0; batch classifier loss: 0.422253; batch adversarial loss: 0.470387\n",
      "epoch 186; iter: 0; batch classifier loss: 0.317717; batch adversarial loss: 0.580563\n",
      "epoch 187; iter: 0; batch classifier loss: 0.347226; batch adversarial loss: 0.589146\n",
      "epoch 188; iter: 0; batch classifier loss: 0.302793; batch adversarial loss: 0.635779\n",
      "epoch 189; iter: 0; batch classifier loss: 0.316374; batch adversarial loss: 0.516690\n",
      "epoch 190; iter: 0; batch classifier loss: 0.305253; batch adversarial loss: 0.534990\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321785; batch adversarial loss: 0.646959\n",
      "epoch 192; iter: 0; batch classifier loss: 0.407655; batch adversarial loss: 0.507382\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333557; batch adversarial loss: 0.598886\n",
      "epoch 194; iter: 0; batch classifier loss: 0.352710; batch adversarial loss: 0.590031\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310969; batch adversarial loss: 0.563057\n",
      "epoch 196; iter: 0; batch classifier loss: 0.368826; batch adversarial loss: 0.526756\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352625; batch adversarial loss: 0.461260\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349170; batch adversarial loss: 0.533462\n",
      "epoch 199; iter: 0; batch classifier loss: 0.403595; batch adversarial loss: 0.546186\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704035; batch adversarial loss: 0.718730\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606820; batch adversarial loss: 0.694774\n",
      "epoch 2; iter: 0; batch classifier loss: 0.598429; batch adversarial loss: 0.638700\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605746; batch adversarial loss: 0.635283\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575211; batch adversarial loss: 0.581962\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568206; batch adversarial loss: 0.575764\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560140; batch adversarial loss: 0.605983\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495823; batch adversarial loss: 0.592441\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523838; batch adversarial loss: 0.626140\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506057; batch adversarial loss: 0.612930\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528210; batch adversarial loss: 0.558350\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516677; batch adversarial loss: 0.568635\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571423; batch adversarial loss: 0.570484\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482424; batch adversarial loss: 0.654768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.513642; batch adversarial loss: 0.549529\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487403; batch adversarial loss: 0.593989\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534632; batch adversarial loss: 0.601288\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518341; batch adversarial loss: 0.535046\n",
      "epoch 18; iter: 0; batch classifier loss: 0.565558; batch adversarial loss: 0.640109\n",
      "epoch 19; iter: 0; batch classifier loss: 0.453513; batch adversarial loss: 0.585647\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473949; batch adversarial loss: 0.568688\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510281; batch adversarial loss: 0.638719\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457842; batch adversarial loss: 0.565212\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528902; batch adversarial loss: 0.497657\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464789; batch adversarial loss: 0.622917\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479589; batch adversarial loss: 0.572434\n",
      "epoch 26; iter: 0; batch classifier loss: 0.507613; batch adversarial loss: 0.592458\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507147; batch adversarial loss: 0.517268\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532433; batch adversarial loss: 0.582147\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465006; batch adversarial loss: 0.502000\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390682; batch adversarial loss: 0.478932\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439615; batch adversarial loss: 0.583030\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487743; batch adversarial loss: 0.570963\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452232; batch adversarial loss: 0.589927\n",
      "epoch 34; iter: 0; batch classifier loss: 0.373252; batch adversarial loss: 0.546857\n",
      "epoch 35; iter: 0; batch classifier loss: 0.536133; batch adversarial loss: 0.519103\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481013; batch adversarial loss: 0.500251\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473421; batch adversarial loss: 0.572317\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405310; batch adversarial loss: 0.581376\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435237; batch adversarial loss: 0.535228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474903; batch adversarial loss: 0.490024\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458172; batch adversarial loss: 0.552901\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429811; batch adversarial loss: 0.481282\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480698; batch adversarial loss: 0.535297\n",
      "epoch 44; iter: 0; batch classifier loss: 0.387422; batch adversarial loss: 0.508631\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465331; batch adversarial loss: 0.517109\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432673; batch adversarial loss: 0.553494\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437069; batch adversarial loss: 0.526156\n",
      "epoch 48; iter: 0; batch classifier loss: 0.384912; batch adversarial loss: 0.581261\n",
      "epoch 49; iter: 0; batch classifier loss: 0.338261; batch adversarial loss: 0.580901\n",
      "epoch 50; iter: 0; batch classifier loss: 0.387007; batch adversarial loss: 0.600159\n",
      "epoch 51; iter: 0; batch classifier loss: 0.361972; batch adversarial loss: 0.507262\n",
      "epoch 52; iter: 0; batch classifier loss: 0.479286; batch adversarial loss: 0.572271\n",
      "epoch 53; iter: 0; batch classifier loss: 0.477881; batch adversarial loss: 0.612442\n",
      "epoch 54; iter: 0; batch classifier loss: 0.365626; batch adversarial loss: 0.522751\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425741; batch adversarial loss: 0.563054\n",
      "epoch 56; iter: 0; batch classifier loss: 0.330174; batch adversarial loss: 0.508378\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426895; batch adversarial loss: 0.499175\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378925; batch adversarial loss: 0.517724\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392395; batch adversarial loss: 0.579638\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439672; batch adversarial loss: 0.564044\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379259; batch adversarial loss: 0.517765\n",
      "epoch 62; iter: 0; batch classifier loss: 0.344172; batch adversarial loss: 0.517733\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416791; batch adversarial loss: 0.453634\n",
      "epoch 64; iter: 0; batch classifier loss: 0.272265; batch adversarial loss: 0.580881\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416800; batch adversarial loss: 0.655132\n",
      "epoch 66; iter: 0; batch classifier loss: 0.360164; batch adversarial loss: 0.544525\n",
      "epoch 67; iter: 0; batch classifier loss: 0.456618; batch adversarial loss: 0.618419\n",
      "epoch 68; iter: 0; batch classifier loss: 0.436163; batch adversarial loss: 0.563122\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437133; batch adversarial loss: 0.600292\n",
      "epoch 70; iter: 0; batch classifier loss: 0.342497; batch adversarial loss: 0.525701\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451100; batch adversarial loss: 0.564339\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411332; batch adversarial loss: 0.525859\n",
      "epoch 73; iter: 0; batch classifier loss: 0.416782; batch adversarial loss: 0.555525\n",
      "epoch 74; iter: 0; batch classifier loss: 0.484775; batch adversarial loss: 0.544535\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412747; batch adversarial loss: 0.564193\n",
      "epoch 76; iter: 0; batch classifier loss: 0.439090; batch adversarial loss: 0.507894\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376360; batch adversarial loss: 0.554108\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400241; batch adversarial loss: 0.554480\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396761; batch adversarial loss: 0.471243\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408175; batch adversarial loss: 0.562747\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408729; batch adversarial loss: 0.590658\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356863; batch adversarial loss: 0.507833\n",
      "epoch 83; iter: 0; batch classifier loss: 0.446755; batch adversarial loss: 0.535427\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370186; batch adversarial loss: 0.498353\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405695; batch adversarial loss: 0.553740\n",
      "epoch 86; iter: 0; batch classifier loss: 0.461510; batch adversarial loss: 0.461856\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377734; batch adversarial loss: 0.590374\n",
      "epoch 88; iter: 0; batch classifier loss: 0.434387; batch adversarial loss: 0.554266\n",
      "epoch 89; iter: 0; batch classifier loss: 0.450972; batch adversarial loss: 0.488662\n",
      "epoch 90; iter: 0; batch classifier loss: 0.294921; batch adversarial loss: 0.600876\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379066; batch adversarial loss: 0.591491\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367587; batch adversarial loss: 0.563182\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399090; batch adversarial loss: 0.544472\n",
      "epoch 94; iter: 0; batch classifier loss: 0.458587; batch adversarial loss: 0.638326\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361610; batch adversarial loss: 0.516194\n",
      "epoch 96; iter: 0; batch classifier loss: 0.451941; batch adversarial loss: 0.562915\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390307; batch adversarial loss: 0.515235\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415865; batch adversarial loss: 0.572630\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390613; batch adversarial loss: 0.497656\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400874; batch adversarial loss: 0.460479\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394740; batch adversarial loss: 0.488359\n",
      "epoch 102; iter: 0; batch classifier loss: 0.344255; batch adversarial loss: 0.544602\n",
      "epoch 103; iter: 0; batch classifier loss: 0.335762; batch adversarial loss: 0.562991\n",
      "epoch 104; iter: 0; batch classifier loss: 0.462479; batch adversarial loss: 0.488865\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398060; batch adversarial loss: 0.608968\n",
      "epoch 106; iter: 0; batch classifier loss: 0.477924; batch adversarial loss: 0.516912\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392148; batch adversarial loss: 0.451878\n",
      "epoch 108; iter: 0; batch classifier loss: 0.471145; batch adversarial loss: 0.572724\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331000; batch adversarial loss: 0.544577\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378474; batch adversarial loss: 0.525928\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354619; batch adversarial loss: 0.535502\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396088; batch adversarial loss: 0.507573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.340591; batch adversarial loss: 0.525789\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369389; batch adversarial loss: 0.563236\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354396; batch adversarial loss: 0.479328\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413382; batch adversarial loss: 0.581907\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360414; batch adversarial loss: 0.498400\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394290; batch adversarial loss: 0.488879\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386295; batch adversarial loss: 0.590967\n",
      "epoch 120; iter: 0; batch classifier loss: 0.481689; batch adversarial loss: 0.498367\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341027; batch adversarial loss: 0.544573\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378436; batch adversarial loss: 0.488771\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380691; batch adversarial loss: 0.553793\n",
      "epoch 124; iter: 0; batch classifier loss: 0.344481; batch adversarial loss: 0.553271\n",
      "epoch 125; iter: 0; batch classifier loss: 0.307331; batch adversarial loss: 0.599729\n",
      "epoch 126; iter: 0; batch classifier loss: 0.324851; batch adversarial loss: 0.497087\n",
      "epoch 127; iter: 0; batch classifier loss: 0.399528; batch adversarial loss: 0.560393\n",
      "epoch 128; iter: 0; batch classifier loss: 0.371658; batch adversarial loss: 0.536301\n",
      "epoch 129; iter: 0; batch classifier loss: 0.412176; batch adversarial loss: 0.517617\n",
      "epoch 130; iter: 0; batch classifier loss: 0.429184; batch adversarial loss: 0.508902\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392327; batch adversarial loss: 0.413905\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414344; batch adversarial loss: 0.598592\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375886; batch adversarial loss: 0.470714\n",
      "epoch 134; iter: 0; batch classifier loss: 0.326024; batch adversarial loss: 0.573662\n",
      "epoch 135; iter: 0; batch classifier loss: 0.432573; batch adversarial loss: 0.591329\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385172; batch adversarial loss: 0.497842\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329489; batch adversarial loss: 0.497413\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377680; batch adversarial loss: 0.478509\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371795; batch adversarial loss: 0.516074\n",
      "epoch 140; iter: 0; batch classifier loss: 0.480894; batch adversarial loss: 0.544618\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325364; batch adversarial loss: 0.601403\n",
      "epoch 142; iter: 0; batch classifier loss: 0.382785; batch adversarial loss: 0.477086\n",
      "epoch 143; iter: 0; batch classifier loss: 0.339319; batch adversarial loss: 0.562353\n",
      "epoch 144; iter: 0; batch classifier loss: 0.309654; batch adversarial loss: 0.553766\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352740; batch adversarial loss: 0.532885\n",
      "epoch 146; iter: 0; batch classifier loss: 0.469150; batch adversarial loss: 0.543751\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353308; batch adversarial loss: 0.563524\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417791; batch adversarial loss: 0.497462\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341572; batch adversarial loss: 0.469670\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365433; batch adversarial loss: 0.599318\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384923; batch adversarial loss: 0.516789\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368809; batch adversarial loss: 0.582155\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360001; batch adversarial loss: 0.572910\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350382; batch adversarial loss: 0.434624\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358507; batch adversarial loss: 0.507249\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381922; batch adversarial loss: 0.610102\n",
      "epoch 157; iter: 0; batch classifier loss: 0.330939; batch adversarial loss: 0.442476\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343480; batch adversarial loss: 0.562596\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352055; batch adversarial loss: 0.479807\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400216; batch adversarial loss: 0.563396\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374952; batch adversarial loss: 0.489558\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348594; batch adversarial loss: 0.544695\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338864; batch adversarial loss: 0.526077\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342852; batch adversarial loss: 0.545233\n",
      "epoch 165; iter: 0; batch classifier loss: 0.317458; batch adversarial loss: 0.562378\n",
      "epoch 166; iter: 0; batch classifier loss: 0.410477; batch adversarial loss: 0.581284\n",
      "epoch 167; iter: 0; batch classifier loss: 0.406761; batch adversarial loss: 0.470059\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370067; batch adversarial loss: 0.535072\n",
      "epoch 169; iter: 0; batch classifier loss: 0.286297; batch adversarial loss: 0.545122\n",
      "epoch 170; iter: 0; batch classifier loss: 0.388845; batch adversarial loss: 0.433690\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357571; batch adversarial loss: 0.581173\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392376; batch adversarial loss: 0.618286\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345310; batch adversarial loss: 0.656101\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325721; batch adversarial loss: 0.563082\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340440; batch adversarial loss: 0.572426\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340972; batch adversarial loss: 0.526016\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343099; batch adversarial loss: 0.600371\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351787; batch adversarial loss: 0.590619\n",
      "epoch 179; iter: 0; batch classifier loss: 0.382746; batch adversarial loss: 0.600698\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340477; batch adversarial loss: 0.525801\n",
      "epoch 181; iter: 0; batch classifier loss: 0.388145; batch adversarial loss: 0.525925\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373153; batch adversarial loss: 0.516864\n",
      "epoch 183; iter: 0; batch classifier loss: 0.380074; batch adversarial loss: 0.572575\n",
      "epoch 184; iter: 0; batch classifier loss: 0.398425; batch adversarial loss: 0.497822\n",
      "epoch 185; iter: 0; batch classifier loss: 0.375668; batch adversarial loss: 0.563208\n",
      "epoch 186; iter: 0; batch classifier loss: 0.418877; batch adversarial loss: 0.553964\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374526; batch adversarial loss: 0.526066\n",
      "epoch 188; iter: 0; batch classifier loss: 0.290485; batch adversarial loss: 0.618460\n",
      "epoch 189; iter: 0; batch classifier loss: 0.337195; batch adversarial loss: 0.590755\n",
      "epoch 190; iter: 0; batch classifier loss: 0.440164; batch adversarial loss: 0.534727\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359091; batch adversarial loss: 0.562281\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368510; batch adversarial loss: 0.462104\n",
      "epoch 193; iter: 0; batch classifier loss: 0.312267; batch adversarial loss: 0.461825\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376061; batch adversarial loss: 0.590725\n",
      "epoch 195; iter: 0; batch classifier loss: 0.372054; batch adversarial loss: 0.452198\n",
      "epoch 196; iter: 0; batch classifier loss: 0.363246; batch adversarial loss: 0.535885\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373281; batch adversarial loss: 0.582696\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348792; batch adversarial loss: 0.563559\n",
      "epoch 199; iter: 0; batch classifier loss: 0.417187; batch adversarial loss: 0.535166\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694316; batch adversarial loss: 0.635904\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628422; batch adversarial loss: 0.643734\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582736; batch adversarial loss: 0.648391\n",
      "epoch 3; iter: 0; batch classifier loss: 0.622972; batch adversarial loss: 0.622630\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529761; batch adversarial loss: 0.650185\n",
      "epoch 5; iter: 0; batch classifier loss: 0.617788; batch adversarial loss: 0.626320\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569157; batch adversarial loss: 0.627566\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503177; batch adversarial loss: 0.570614\n",
      "epoch 8; iter: 0; batch classifier loss: 0.567949; batch adversarial loss: 0.608763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.591220; batch adversarial loss: 0.585015\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515463; batch adversarial loss: 0.575268\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559721; batch adversarial loss: 0.555471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.602455; batch adversarial loss: 0.617403\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532771; batch adversarial loss: 0.524194\n",
      "epoch 14; iter: 0; batch classifier loss: 0.443665; batch adversarial loss: 0.563640\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454422; batch adversarial loss: 0.547377\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475138; batch adversarial loss: 0.544696\n",
      "epoch 17; iter: 0; batch classifier loss: 0.493172; batch adversarial loss: 0.573508\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531779; batch adversarial loss: 0.573005\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536250; batch adversarial loss: 0.597284\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543460; batch adversarial loss: 0.580105\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484514; batch adversarial loss: 0.503275\n",
      "epoch 22; iter: 0; batch classifier loss: 0.532119; batch adversarial loss: 0.516874\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456757; batch adversarial loss: 0.547913\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485717; batch adversarial loss: 0.650347\n",
      "epoch 25; iter: 0; batch classifier loss: 0.550587; batch adversarial loss: 0.605296\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506199; batch adversarial loss: 0.522872\n",
      "epoch 27; iter: 0; batch classifier loss: 0.503804; batch adversarial loss: 0.579497\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475859; batch adversarial loss: 0.488476\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527205; batch adversarial loss: 0.519961\n",
      "epoch 30; iter: 0; batch classifier loss: 0.549648; batch adversarial loss: 0.536947\n",
      "epoch 31; iter: 0; batch classifier loss: 0.460774; batch adversarial loss: 0.580059\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466143; batch adversarial loss: 0.596408\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442335; batch adversarial loss: 0.519356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.531444; batch adversarial loss: 0.519477\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392735; batch adversarial loss: 0.596498\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458298; batch adversarial loss: 0.484430\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457419; batch adversarial loss: 0.605273\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458576; batch adversarial loss: 0.518317\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478076; batch adversarial loss: 0.517460\n",
      "epoch 40; iter: 0; batch classifier loss: 0.438071; batch adversarial loss: 0.545844\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408557; batch adversarial loss: 0.595062\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450092; batch adversarial loss: 0.598656\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473682; batch adversarial loss: 0.527557\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441809; batch adversarial loss: 0.616217\n",
      "epoch 45; iter: 0; batch classifier loss: 0.538056; batch adversarial loss: 0.588106\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439366; batch adversarial loss: 0.532495\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370624; batch adversarial loss: 0.543007\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382480; batch adversarial loss: 0.587730\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433942; batch adversarial loss: 0.578556\n",
      "epoch 50; iter: 0; batch classifier loss: 0.513772; batch adversarial loss: 0.591875\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447328; batch adversarial loss: 0.503036\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461950; batch adversarial loss: 0.585301\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441197; batch adversarial loss: 0.568101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442897; batch adversarial loss: 0.508596\n",
      "epoch 55; iter: 0; batch classifier loss: 0.399204; batch adversarial loss: 0.541225\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451674; batch adversarial loss: 0.585457\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415481; batch adversarial loss: 0.485369\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419506; batch adversarial loss: 0.510086\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431070; batch adversarial loss: 0.576304\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409971; batch adversarial loss: 0.564587\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413598; batch adversarial loss: 0.525237\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440217; batch adversarial loss: 0.519953\n",
      "epoch 63; iter: 0; batch classifier loss: 0.462758; batch adversarial loss: 0.498695\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437294; batch adversarial loss: 0.553417\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417117; batch adversarial loss: 0.595786\n",
      "epoch 66; iter: 0; batch classifier loss: 0.353831; batch adversarial loss: 0.552106\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426725; batch adversarial loss: 0.635493\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404172; batch adversarial loss: 0.571176\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410094; batch adversarial loss: 0.545443\n",
      "epoch 70; iter: 0; batch classifier loss: 0.456275; batch adversarial loss: 0.591029\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403576; batch adversarial loss: 0.586989\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381017; batch adversarial loss: 0.592461\n",
      "epoch 73; iter: 0; batch classifier loss: 0.450018; batch adversarial loss: 0.589532\n",
      "epoch 74; iter: 0; batch classifier loss: 0.379249; batch adversarial loss: 0.551152\n",
      "epoch 75; iter: 0; batch classifier loss: 0.383210; batch adversarial loss: 0.527882\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385252; batch adversarial loss: 0.563379\n",
      "epoch 77; iter: 0; batch classifier loss: 0.445707; batch adversarial loss: 0.528616\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396598; batch adversarial loss: 0.571149\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343008; batch adversarial loss: 0.573260\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406927; batch adversarial loss: 0.510269\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399043; batch adversarial loss: 0.516888\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447301; batch adversarial loss: 0.517334\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406632; batch adversarial loss: 0.544291\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400835; batch adversarial loss: 0.553598\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400412; batch adversarial loss: 0.535526\n",
      "epoch 86; iter: 0; batch classifier loss: 0.376762; batch adversarial loss: 0.579472\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366542; batch adversarial loss: 0.588948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.430039; batch adversarial loss: 0.544469\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342732; batch adversarial loss: 0.607124\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452501; batch adversarial loss: 0.517516\n",
      "epoch 91; iter: 0; batch classifier loss: 0.436415; batch adversarial loss: 0.606610\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391095; batch adversarial loss: 0.491520\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383355; batch adversarial loss: 0.570934\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380620; batch adversarial loss: 0.473507\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407365; batch adversarial loss: 0.563535\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373756; batch adversarial loss: 0.552709\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420005; batch adversarial loss: 0.616497\n",
      "epoch 98; iter: 0; batch classifier loss: 0.445944; batch adversarial loss: 0.517412\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404269; batch adversarial loss: 0.553440\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410337; batch adversarial loss: 0.561061\n",
      "epoch 101; iter: 0; batch classifier loss: 0.416302; batch adversarial loss: 0.482802\n",
      "epoch 102; iter: 0; batch classifier loss: 0.422938; batch adversarial loss: 0.526942\n",
      "epoch 103; iter: 0; batch classifier loss: 0.344047; batch adversarial loss: 0.544661\n",
      "epoch 104; iter: 0; batch classifier loss: 0.442286; batch adversarial loss: 0.614929\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408853; batch adversarial loss: 0.482796\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434805; batch adversarial loss: 0.572116\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402784; batch adversarial loss: 0.526823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.356026; batch adversarial loss: 0.579185\n",
      "epoch 109; iter: 0; batch classifier loss: 0.431449; batch adversarial loss: 0.651102\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401241; batch adversarial loss: 0.491671\n",
      "epoch 111; iter: 0; batch classifier loss: 0.417170; batch adversarial loss: 0.544372\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409798; batch adversarial loss: 0.570069\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390494; batch adversarial loss: 0.625445\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405015; batch adversarial loss: 0.579678\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405629; batch adversarial loss: 0.571275\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400559; batch adversarial loss: 0.535933\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402109; batch adversarial loss: 0.590101\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406192; batch adversarial loss: 0.624791\n",
      "epoch 119; iter: 0; batch classifier loss: 0.435357; batch adversarial loss: 0.544353\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328530; batch adversarial loss: 0.553153\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388954; batch adversarial loss: 0.527180\n",
      "epoch 122; iter: 0; batch classifier loss: 0.436258; batch adversarial loss: 0.553029\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365240; batch adversarial loss: 0.544714\n",
      "epoch 124; iter: 0; batch classifier loss: 0.436926; batch adversarial loss: 0.535697\n",
      "epoch 125; iter: 0; batch classifier loss: 0.422840; batch adversarial loss: 0.588423\n",
      "epoch 126; iter: 0; batch classifier loss: 0.449507; batch adversarial loss: 0.516183\n",
      "epoch 127; iter: 0; batch classifier loss: 0.402584; batch adversarial loss: 0.536536\n",
      "epoch 128; iter: 0; batch classifier loss: 0.371446; batch adversarial loss: 0.509891\n",
      "epoch 129; iter: 0; batch classifier loss: 0.320248; batch adversarial loss: 0.491156\n",
      "epoch 130; iter: 0; batch classifier loss: 0.327625; batch adversarial loss: 0.579614\n",
      "epoch 131; iter: 0; batch classifier loss: 0.397941; batch adversarial loss: 0.589825\n",
      "epoch 132; iter: 0; batch classifier loss: 0.419730; batch adversarial loss: 0.660123\n",
      "epoch 133; iter: 0; batch classifier loss: 0.305167; batch adversarial loss: 0.561428\n",
      "epoch 134; iter: 0; batch classifier loss: 0.380921; batch adversarial loss: 0.510016\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338203; batch adversarial loss: 0.569884\n",
      "epoch 136; iter: 0; batch classifier loss: 0.440955; batch adversarial loss: 0.514017\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359084; batch adversarial loss: 0.534991\n",
      "epoch 138; iter: 0; batch classifier loss: 0.440355; batch adversarial loss: 0.544088\n",
      "epoch 139; iter: 0; batch classifier loss: 0.394630; batch adversarial loss: 0.518280\n",
      "epoch 140; iter: 0; batch classifier loss: 0.372129; batch adversarial loss: 0.591018\n",
      "epoch 141; iter: 0; batch classifier loss: 0.444113; batch adversarial loss: 0.562453\n",
      "epoch 142; iter: 0; batch classifier loss: 0.404687; batch adversarial loss: 0.525028\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367415; batch adversarial loss: 0.588996\n",
      "epoch 144; iter: 0; batch classifier loss: 0.386871; batch adversarial loss: 0.436167\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340541; batch adversarial loss: 0.528805\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367417; batch adversarial loss: 0.594550\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326659; batch adversarial loss: 0.587824\n",
      "epoch 148; iter: 0; batch classifier loss: 0.467707; batch adversarial loss: 0.560521\n",
      "epoch 149; iter: 0; batch classifier loss: 0.442070; batch adversarial loss: 0.540935\n",
      "epoch 150; iter: 0; batch classifier loss: 0.417598; batch adversarial loss: 0.529925\n",
      "epoch 151; iter: 0; batch classifier loss: 0.424294; batch adversarial loss: 0.597658\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333457; batch adversarial loss: 0.534382\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356411; batch adversarial loss: 0.529175\n",
      "epoch 154; iter: 0; batch classifier loss: 0.414576; batch adversarial loss: 0.574935\n",
      "epoch 155; iter: 0; batch classifier loss: 0.400953; batch adversarial loss: 0.507674\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314584; batch adversarial loss: 0.575129\n",
      "epoch 157; iter: 0; batch classifier loss: 0.309669; batch adversarial loss: 0.529030\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327433; batch adversarial loss: 0.554483\n",
      "epoch 159; iter: 0; batch classifier loss: 0.384090; batch adversarial loss: 0.580038\n",
      "epoch 160; iter: 0; batch classifier loss: 0.424741; batch adversarial loss: 0.543402\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397156; batch adversarial loss: 0.588883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.316791; batch adversarial loss: 0.553672\n",
      "epoch 163; iter: 0; batch classifier loss: 0.417392; batch adversarial loss: 0.508949\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376567; batch adversarial loss: 0.518961\n",
      "epoch 165; iter: 0; batch classifier loss: 0.421625; batch adversarial loss: 0.563769\n",
      "epoch 166; iter: 0; batch classifier loss: 0.454258; batch adversarial loss: 0.516230\n",
      "epoch 167; iter: 0; batch classifier loss: 0.391734; batch adversarial loss: 0.553914\n",
      "epoch 168; iter: 0; batch classifier loss: 0.391721; batch adversarial loss: 0.507637\n",
      "epoch 169; iter: 0; batch classifier loss: 0.419110; batch adversarial loss: 0.553231\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364035; batch adversarial loss: 0.517143\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341558; batch adversarial loss: 0.551911\n",
      "epoch 172; iter: 0; batch classifier loss: 0.425225; batch adversarial loss: 0.586515\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375164; batch adversarial loss: 0.554484\n",
      "epoch 174; iter: 0; batch classifier loss: 0.401125; batch adversarial loss: 0.537073\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383301; batch adversarial loss: 0.523083\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346181; batch adversarial loss: 0.551084\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384514; batch adversarial loss: 0.534113\n",
      "epoch 178; iter: 0; batch classifier loss: 0.306279; batch adversarial loss: 0.616500\n",
      "epoch 179; iter: 0; batch classifier loss: 0.421028; batch adversarial loss: 0.583057\n",
      "epoch 180; iter: 0; batch classifier loss: 0.445553; batch adversarial loss: 0.670909\n",
      "epoch 181; iter: 0; batch classifier loss: 0.352575; batch adversarial loss: 0.564572\n",
      "epoch 182; iter: 0; batch classifier loss: 0.288703; batch adversarial loss: 0.575281\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367892; batch adversarial loss: 0.561224\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381220; batch adversarial loss: 0.583047\n",
      "epoch 185; iter: 0; batch classifier loss: 0.353426; batch adversarial loss: 0.616706\n",
      "epoch 186; iter: 0; batch classifier loss: 0.288235; batch adversarial loss: 0.587678\n",
      "epoch 187; iter: 0; batch classifier loss: 0.411079; batch adversarial loss: 0.587977\n",
      "epoch 188; iter: 0; batch classifier loss: 0.407563; batch adversarial loss: 0.654313\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295735; batch adversarial loss: 0.572308\n",
      "epoch 190; iter: 0; batch classifier loss: 0.286299; batch adversarial loss: 0.536504\n",
      "epoch 191; iter: 0; batch classifier loss: 0.396837; batch adversarial loss: 0.544278\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365874; batch adversarial loss: 0.605359\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338983; batch adversarial loss: 0.613847\n",
      "epoch 194; iter: 0; batch classifier loss: 0.469652; batch adversarial loss: 0.593333\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323282; batch adversarial loss: 0.579904\n",
      "epoch 196; iter: 0; batch classifier loss: 0.432395; batch adversarial loss: 0.572412\n",
      "epoch 197; iter: 0; batch classifier loss: 0.402009; batch adversarial loss: 0.576606\n",
      "epoch 198; iter: 0; batch classifier loss: 0.395704; batch adversarial loss: 0.563052\n",
      "epoch 199; iter: 0; batch classifier loss: 0.443756; batch adversarial loss: 0.569374\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717020; batch adversarial loss: 0.752107\n",
      "epoch 1; iter: 0; batch classifier loss: 0.639475; batch adversarial loss: 0.700557\n",
      "epoch 2; iter: 0; batch classifier loss: 0.618739; batch adversarial loss: 0.667476\n",
      "epoch 3; iter: 0; batch classifier loss: 0.621354; batch adversarial loss: 0.637963\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545308; batch adversarial loss: 0.618109\n",
      "epoch 5; iter: 0; batch classifier loss: 0.631311; batch adversarial loss: 0.598645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.544780; batch adversarial loss: 0.586399\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588119; batch adversarial loss: 0.572146\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573204; batch adversarial loss: 0.624207\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584575; batch adversarial loss: 0.585894\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508685; batch adversarial loss: 0.556044\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590840; batch adversarial loss: 0.583219\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537241; batch adversarial loss: 0.616486\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457330; batch adversarial loss: 0.536762\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530610; batch adversarial loss: 0.537469\n",
      "epoch 15; iter: 0; batch classifier loss: 0.418501; batch adversarial loss: 0.553310\n",
      "epoch 16; iter: 0; batch classifier loss: 0.438838; batch adversarial loss: 0.597469\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451556; batch adversarial loss: 0.527777\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509274; batch adversarial loss: 0.591792\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491109; batch adversarial loss: 0.545436\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506777; batch adversarial loss: 0.565887\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520959; batch adversarial loss: 0.521862\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487599; batch adversarial loss: 0.507408\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484815; batch adversarial loss: 0.501683\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515376; batch adversarial loss: 0.496601\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502522; batch adversarial loss: 0.513382\n",
      "epoch 26; iter: 0; batch classifier loss: 0.589877; batch adversarial loss: 0.531705\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466024; batch adversarial loss: 0.526109\n",
      "epoch 28; iter: 0; batch classifier loss: 0.540169; batch adversarial loss: 0.564287\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510003; batch adversarial loss: 0.564189\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508948; batch adversarial loss: 0.550372\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442150; batch adversarial loss: 0.592368\n",
      "epoch 32; iter: 0; batch classifier loss: 0.519921; batch adversarial loss: 0.573467\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478326; batch adversarial loss: 0.495967\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468477; batch adversarial loss: 0.590323\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406153; batch adversarial loss: 0.581006\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451772; batch adversarial loss: 0.590361\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493992; batch adversarial loss: 0.617371\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440612; batch adversarial loss: 0.587786\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436314; batch adversarial loss: 0.535393\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404285; batch adversarial loss: 0.536017\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429108; batch adversarial loss: 0.517628\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443943; batch adversarial loss: 0.589391\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438085; batch adversarial loss: 0.570382\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406578; batch adversarial loss: 0.525491\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374801; batch adversarial loss: 0.516160\n",
      "epoch 46; iter: 0; batch classifier loss: 0.415449; batch adversarial loss: 0.498722\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446550; batch adversarial loss: 0.561433\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391876; batch adversarial loss: 0.526440\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465597; batch adversarial loss: 0.507673\n",
      "epoch 50; iter: 0; batch classifier loss: 0.419855; batch adversarial loss: 0.554216\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483248; batch adversarial loss: 0.542959\n",
      "epoch 52; iter: 0; batch classifier loss: 0.465449; batch adversarial loss: 0.635418\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408349; batch adversarial loss: 0.481423\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424510; batch adversarial loss: 0.545429\n",
      "epoch 55; iter: 0; batch classifier loss: 0.369911; batch adversarial loss: 0.582165\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468671; batch adversarial loss: 0.546232\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450805; batch adversarial loss: 0.515875\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445344; batch adversarial loss: 0.489013\n",
      "epoch 59; iter: 0; batch classifier loss: 0.575644; batch adversarial loss: 0.608304\n",
      "epoch 60; iter: 0; batch classifier loss: 0.497845; batch adversarial loss: 0.634760\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439296; batch adversarial loss: 0.517768\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403400; batch adversarial loss: 0.544748\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449920; batch adversarial loss: 0.533775\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358388; batch adversarial loss: 0.537826\n",
      "epoch 65; iter: 0; batch classifier loss: 0.334646; batch adversarial loss: 0.563174\n",
      "epoch 66; iter: 0; batch classifier loss: 0.390444; batch adversarial loss: 0.553310\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445898; batch adversarial loss: 0.607924\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432717; batch adversarial loss: 0.543273\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438371; batch adversarial loss: 0.536036\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465939; batch adversarial loss: 0.634575\n",
      "epoch 71; iter: 0; batch classifier loss: 0.475379; batch adversarial loss: 0.535091\n",
      "epoch 72; iter: 0; batch classifier loss: 0.437651; batch adversarial loss: 0.507719\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409392; batch adversarial loss: 0.554780\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436081; batch adversarial loss: 0.536850\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391806; batch adversarial loss: 0.600921\n",
      "epoch 76; iter: 0; batch classifier loss: 0.360099; batch adversarial loss: 0.534833\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375819; batch adversarial loss: 0.563469\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354219; batch adversarial loss: 0.536573\n",
      "epoch 79; iter: 0; batch classifier loss: 0.345741; batch adversarial loss: 0.516405\n",
      "epoch 80; iter: 0; batch classifier loss: 0.328157; batch adversarial loss: 0.454502\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387311; batch adversarial loss: 0.553285\n",
      "epoch 82; iter: 0; batch classifier loss: 0.310568; batch adversarial loss: 0.636224\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371076; batch adversarial loss: 0.506757\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409084; batch adversarial loss: 0.407903\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383702; batch adversarial loss: 0.524104\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403267; batch adversarial loss: 0.535022\n",
      "epoch 87; iter: 0; batch classifier loss: 0.335273; batch adversarial loss: 0.397535\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384751; batch adversarial loss: 0.527588\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424962; batch adversarial loss: 0.496715\n",
      "epoch 90; iter: 0; batch classifier loss: 0.389985; batch adversarial loss: 0.655519\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398036; batch adversarial loss: 0.616269\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396584; batch adversarial loss: 0.545011\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427823; batch adversarial loss: 0.584121\n",
      "epoch 94; iter: 0; batch classifier loss: 0.453862; batch adversarial loss: 0.526320\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412307; batch adversarial loss: 0.570975\n",
      "epoch 96; iter: 0; batch classifier loss: 0.517992; batch adversarial loss: 0.580787\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440628; batch adversarial loss: 0.571529\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400474; batch adversarial loss: 0.582293\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398268; batch adversarial loss: 0.526708\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385656; batch adversarial loss: 0.525093\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426537; batch adversarial loss: 0.442511\n",
      "epoch 102; iter: 0; batch classifier loss: 0.356094; batch adversarial loss: 0.546495\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413489; batch adversarial loss: 0.563278\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434981; batch adversarial loss: 0.536192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.412091; batch adversarial loss: 0.553724\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394737; batch adversarial loss: 0.518094\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397023; batch adversarial loss: 0.593251\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385481; batch adversarial loss: 0.571279\n",
      "epoch 109; iter: 0; batch classifier loss: 0.338885; batch adversarial loss: 0.562390\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362173; batch adversarial loss: 0.562303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353729; batch adversarial loss: 0.444727\n",
      "epoch 112; iter: 0; batch classifier loss: 0.451784; batch adversarial loss: 0.563460\n",
      "epoch 113; iter: 0; batch classifier loss: 0.320427; batch adversarial loss: 0.626154\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350598; batch adversarial loss: 0.581388\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404240; batch adversarial loss: 0.508281\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356909; batch adversarial loss: 0.478556\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345969; batch adversarial loss: 0.607369\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383137; batch adversarial loss: 0.571528\n",
      "epoch 119; iter: 0; batch classifier loss: 0.327367; batch adversarial loss: 0.480041\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378729; batch adversarial loss: 0.610092\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355335; batch adversarial loss: 0.629605\n",
      "epoch 122; iter: 0; batch classifier loss: 0.336801; batch adversarial loss: 0.564191\n",
      "epoch 123; iter: 0; batch classifier loss: 0.276393; batch adversarial loss: 0.552005\n",
      "epoch 124; iter: 0; batch classifier loss: 0.454720; batch adversarial loss: 0.637194\n",
      "epoch 125; iter: 0; batch classifier loss: 0.347804; batch adversarial loss: 0.599790\n",
      "epoch 126; iter: 0; batch classifier loss: 0.422688; batch adversarial loss: 0.524762\n",
      "epoch 127; iter: 0; batch classifier loss: 0.310567; batch adversarial loss: 0.646594\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390031; batch adversarial loss: 0.481192\n",
      "epoch 129; iter: 0; batch classifier loss: 0.390454; batch adversarial loss: 0.545246\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387723; batch adversarial loss: 0.545860\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382928; batch adversarial loss: 0.600092\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329921; batch adversarial loss: 0.592399\n",
      "epoch 133; iter: 0; batch classifier loss: 0.382300; batch adversarial loss: 0.571556\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379565; batch adversarial loss: 0.508162\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325424; batch adversarial loss: 0.581913\n",
      "epoch 136; iter: 0; batch classifier loss: 0.345896; batch adversarial loss: 0.544586\n",
      "epoch 137; iter: 0; batch classifier loss: 0.339368; batch adversarial loss: 0.553347\n",
      "epoch 138; iter: 0; batch classifier loss: 0.422625; batch adversarial loss: 0.617700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.333126; batch adversarial loss: 0.460156\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359870; batch adversarial loss: 0.480089\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323880; batch adversarial loss: 0.471362\n",
      "epoch 142; iter: 0; batch classifier loss: 0.329599; batch adversarial loss: 0.472926\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352484; batch adversarial loss: 0.589293\n",
      "epoch 144; iter: 0; batch classifier loss: 0.400296; batch adversarial loss: 0.507255\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358231; batch adversarial loss: 0.564705\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349251; batch adversarial loss: 0.544377\n",
      "epoch 147; iter: 0; batch classifier loss: 0.440695; batch adversarial loss: 0.525696\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371577; batch adversarial loss: 0.516751\n",
      "epoch 149; iter: 0; batch classifier loss: 0.394417; batch adversarial loss: 0.634503\n",
      "epoch 150; iter: 0; batch classifier loss: 0.357417; batch adversarial loss: 0.582295\n",
      "epoch 151; iter: 0; batch classifier loss: 0.412085; batch adversarial loss: 0.580598\n",
      "epoch 152; iter: 0; batch classifier loss: 0.418113; batch adversarial loss: 0.518420\n",
      "epoch 153; iter: 0; batch classifier loss: 0.410747; batch adversarial loss: 0.545764\n",
      "epoch 154; iter: 0; batch classifier loss: 0.440924; batch adversarial loss: 0.559953\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406727; batch adversarial loss: 0.535254\n",
      "epoch 156; iter: 0; batch classifier loss: 0.393260; batch adversarial loss: 0.506087\n",
      "epoch 157; iter: 0; batch classifier loss: 0.386420; batch adversarial loss: 0.516832\n",
      "epoch 158; iter: 0; batch classifier loss: 0.328254; batch adversarial loss: 0.555447\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390420; batch adversarial loss: 0.563414\n",
      "epoch 160; iter: 0; batch classifier loss: 0.410165; batch adversarial loss: 0.545674\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341631; batch adversarial loss: 0.556768\n",
      "epoch 162; iter: 0; batch classifier loss: 0.336764; batch adversarial loss: 0.598875\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359641; batch adversarial loss: 0.537793\n",
      "epoch 164; iter: 0; batch classifier loss: 0.382694; batch adversarial loss: 0.558499\n",
      "epoch 165; iter: 0; batch classifier loss: 0.347028; batch adversarial loss: 0.515971\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339174; batch adversarial loss: 0.570721\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335457; batch adversarial loss: 0.517667\n",
      "epoch 168; iter: 0; batch classifier loss: 0.433807; batch adversarial loss: 0.507779\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369587; batch adversarial loss: 0.527188\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395695; batch adversarial loss: 0.506798\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409447; batch adversarial loss: 0.598726\n",
      "epoch 172; iter: 0; batch classifier loss: 0.304745; batch adversarial loss: 0.500201\n",
      "epoch 173; iter: 0; batch classifier loss: 0.312608; batch adversarial loss: 0.539205\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357545; batch adversarial loss: 0.542861\n",
      "epoch 175; iter: 0; batch classifier loss: 0.398180; batch adversarial loss: 0.534292\n",
      "epoch 176; iter: 0; batch classifier loss: 0.337850; batch adversarial loss: 0.526191\n",
      "epoch 177; iter: 0; batch classifier loss: 0.441391; batch adversarial loss: 0.582652\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383007; batch adversarial loss: 0.597843\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348949; batch adversarial loss: 0.482348\n",
      "epoch 180; iter: 0; batch classifier loss: 0.423223; batch adversarial loss: 0.516609\n",
      "epoch 181; iter: 0; batch classifier loss: 0.432738; batch adversarial loss: 0.591353\n",
      "epoch 182; iter: 0; batch classifier loss: 0.413330; batch adversarial loss: 0.554139\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355994; batch adversarial loss: 0.526967\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366420; batch adversarial loss: 0.570230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352634; batch adversarial loss: 0.580859\n",
      "epoch 186; iter: 0; batch classifier loss: 0.419755; batch adversarial loss: 0.499400\n",
      "epoch 187; iter: 0; batch classifier loss: 0.318839; batch adversarial loss: 0.542251\n",
      "epoch 188; iter: 0; batch classifier loss: 0.398612; batch adversarial loss: 0.573604\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371213; batch adversarial loss: 0.490692\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329228; batch adversarial loss: 0.572499\n",
      "epoch 191; iter: 0; batch classifier loss: 0.411829; batch adversarial loss: 0.492501\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334898; batch adversarial loss: 0.574392\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395297; batch adversarial loss: 0.637570\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393672; batch adversarial loss: 0.518519\n",
      "epoch 195; iter: 0; batch classifier loss: 0.250756; batch adversarial loss: 0.519020\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357134; batch adversarial loss: 0.561526\n",
      "epoch 197; iter: 0; batch classifier loss: 0.281651; batch adversarial loss: 0.607303\n",
      "epoch 198; iter: 0; batch classifier loss: 0.408655; batch adversarial loss: 0.470897\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342039; batch adversarial loss: 0.590535\n",
      "epoch 0; iter: 0; batch classifier loss: 0.656904; batch adversarial loss: 0.688246\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556087; batch adversarial loss: 0.664770\n",
      "epoch 2; iter: 0; batch classifier loss: 0.617844; batch adversarial loss: 0.650779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.628430; batch adversarial loss: 0.596630\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596729; batch adversarial loss: 0.606401\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524956; batch adversarial loss: 0.576588\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587405; batch adversarial loss: 0.554343\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539941; batch adversarial loss: 0.540433\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576594; batch adversarial loss: 0.590308\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573719; batch adversarial loss: 0.604732\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525502; batch adversarial loss: 0.563032\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525813; batch adversarial loss: 0.591999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525094; batch adversarial loss: 0.586328\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556574; batch adversarial loss: 0.561616\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526685; batch adversarial loss: 0.603505\n",
      "epoch 15; iter: 0; batch classifier loss: 0.572800; batch adversarial loss: 0.578585\n",
      "epoch 16; iter: 0; batch classifier loss: 0.560816; batch adversarial loss: 0.586010\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499541; batch adversarial loss: 0.579951\n",
      "epoch 18; iter: 0; batch classifier loss: 0.423032; batch adversarial loss: 0.578967\n",
      "epoch 19; iter: 0; batch classifier loss: 0.557478; batch adversarial loss: 0.560965\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508147; batch adversarial loss: 0.508629\n",
      "epoch 21; iter: 0; batch classifier loss: 0.554701; batch adversarial loss: 0.592306\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474532; batch adversarial loss: 0.602761\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539292; batch adversarial loss: 0.554564\n",
      "epoch 24; iter: 0; batch classifier loss: 0.447235; batch adversarial loss: 0.499436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.405606; batch adversarial loss: 0.463491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499466; batch adversarial loss: 0.514699\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529227; batch adversarial loss: 0.582643\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515222; batch adversarial loss: 0.552645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527716; batch adversarial loss: 0.558875\n",
      "epoch 30; iter: 0; batch classifier loss: 0.525191; batch adversarial loss: 0.488080\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443444; batch adversarial loss: 0.512087\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479762; batch adversarial loss: 0.634676\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472176; batch adversarial loss: 0.545626\n",
      "epoch 34; iter: 0; batch classifier loss: 0.517505; batch adversarial loss: 0.544336\n",
      "epoch 35; iter: 0; batch classifier loss: 0.546515; batch adversarial loss: 0.490820\n",
      "epoch 36; iter: 0; batch classifier loss: 0.374756; batch adversarial loss: 0.572518\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431705; batch adversarial loss: 0.599630\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439036; batch adversarial loss: 0.590080\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442784; batch adversarial loss: 0.545057\n",
      "epoch 40; iter: 0; batch classifier loss: 0.506441; batch adversarial loss: 0.628962\n",
      "epoch 41; iter: 0; batch classifier loss: 0.480119; batch adversarial loss: 0.508264\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498989; batch adversarial loss: 0.544748\n",
      "epoch 43; iter: 0; batch classifier loss: 0.530119; batch adversarial loss: 0.487145\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435414; batch adversarial loss: 0.487679\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421180; batch adversarial loss: 0.545077\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451338; batch adversarial loss: 0.554994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.419336; batch adversarial loss: 0.546009\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428748; batch adversarial loss: 0.515095\n",
      "epoch 49; iter: 0; batch classifier loss: 0.486482; batch adversarial loss: 0.544471\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421741; batch adversarial loss: 0.544416\n",
      "epoch 51; iter: 0; batch classifier loss: 0.420854; batch adversarial loss: 0.488708\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438140; batch adversarial loss: 0.457004\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443004; batch adversarial loss: 0.504742\n",
      "epoch 54; iter: 0; batch classifier loss: 0.436167; batch adversarial loss: 0.593347\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485538; batch adversarial loss: 0.506146\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442691; batch adversarial loss: 0.486659\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389732; batch adversarial loss: 0.487601\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398131; batch adversarial loss: 0.544600\n",
      "epoch 59; iter: 0; batch classifier loss: 0.397621; batch adversarial loss: 0.487630\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406171; batch adversarial loss: 0.526946\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401998; batch adversarial loss: 0.554353\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421960; batch adversarial loss: 0.573992\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413543; batch adversarial loss: 0.469263\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428526; batch adversarial loss: 0.555950\n",
      "epoch 65; iter: 0; batch classifier loss: 0.330483; batch adversarial loss: 0.536360\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445916; batch adversarial loss: 0.466647\n",
      "epoch 67; iter: 0; batch classifier loss: 0.464439; batch adversarial loss: 0.603510\n",
      "epoch 68; iter: 0; batch classifier loss: 0.366325; batch adversarial loss: 0.523881\n",
      "epoch 69; iter: 0; batch classifier loss: 0.329769; batch adversarial loss: 0.535349\n",
      "epoch 70; iter: 0; batch classifier loss: 0.349795; batch adversarial loss: 0.553342\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390722; batch adversarial loss: 0.573922\n",
      "epoch 72; iter: 0; batch classifier loss: 0.406669; batch adversarial loss: 0.506625\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425272; batch adversarial loss: 0.516034\n",
      "epoch 74; iter: 0; batch classifier loss: 0.435241; batch adversarial loss: 0.436573\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416655; batch adversarial loss: 0.496734\n",
      "epoch 76; iter: 0; batch classifier loss: 0.342345; batch adversarial loss: 0.543726\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406981; batch adversarial loss: 0.497383\n",
      "epoch 78; iter: 0; batch classifier loss: 0.488045; batch adversarial loss: 0.631723\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426381; batch adversarial loss: 0.524986\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423825; batch adversarial loss: 0.562919\n",
      "epoch 81; iter: 0; batch classifier loss: 0.441959; batch adversarial loss: 0.465938\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363530; batch adversarial loss: 0.506053\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368416; batch adversarial loss: 0.650700\n",
      "epoch 84; iter: 0; batch classifier loss: 0.394719; batch adversarial loss: 0.525334\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405782; batch adversarial loss: 0.458735\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430562; batch adversarial loss: 0.517186\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422380; batch adversarial loss: 0.534617\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401593; batch adversarial loss: 0.575964\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399101; batch adversarial loss: 0.438130\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383001; batch adversarial loss: 0.583900\n",
      "epoch 91; iter: 0; batch classifier loss: 0.325883; batch adversarial loss: 0.524854\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364343; batch adversarial loss: 0.653240\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437462; batch adversarial loss: 0.593650\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424948; batch adversarial loss: 0.496466\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387486; batch adversarial loss: 0.555008\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419149; batch adversarial loss: 0.525345\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367867; batch adversarial loss: 0.506711\n",
      "epoch 98; iter: 0; batch classifier loss: 0.464661; batch adversarial loss: 0.555184\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382561; batch adversarial loss: 0.582067\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384842; batch adversarial loss: 0.555694\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407010; batch adversarial loss: 0.623457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.326256; batch adversarial loss: 0.486901\n",
      "epoch 103; iter: 0; batch classifier loss: 0.392318; batch adversarial loss: 0.543960\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409200; batch adversarial loss: 0.544404\n",
      "epoch 105; iter: 0; batch classifier loss: 0.336421; batch adversarial loss: 0.525522\n",
      "epoch 106; iter: 0; batch classifier loss: 0.337254; batch adversarial loss: 0.506444\n",
      "epoch 107; iter: 0; batch classifier loss: 0.440954; batch adversarial loss: 0.478662\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398686; batch adversarial loss: 0.497514\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379077; batch adversarial loss: 0.565396\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389382; batch adversarial loss: 0.562670\n",
      "epoch 111; iter: 0; batch classifier loss: 0.432655; batch adversarial loss: 0.534037\n",
      "epoch 112; iter: 0; batch classifier loss: 0.333533; batch adversarial loss: 0.573672\n",
      "epoch 113; iter: 0; batch classifier loss: 0.313645; batch adversarial loss: 0.526445\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375864; batch adversarial loss: 0.526008\n",
      "epoch 115; iter: 0; batch classifier loss: 0.474824; batch adversarial loss: 0.563351\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396294; batch adversarial loss: 0.534804\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386871; batch adversarial loss: 0.525662\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375966; batch adversarial loss: 0.506550\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390455; batch adversarial loss: 0.486863\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388881; batch adversarial loss: 0.514884\n",
      "epoch 121; iter: 0; batch classifier loss: 0.408659; batch adversarial loss: 0.525724\n",
      "epoch 122; iter: 0; batch classifier loss: 0.288109; batch adversarial loss: 0.573216\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394476; batch adversarial loss: 0.486801\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386700; batch adversarial loss: 0.544875\n",
      "epoch 125; iter: 0; batch classifier loss: 0.431645; batch adversarial loss: 0.555509\n",
      "epoch 126; iter: 0; batch classifier loss: 0.433195; batch adversarial loss: 0.526378\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374408; batch adversarial loss: 0.536259\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373917; batch adversarial loss: 0.552090\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370242; batch adversarial loss: 0.485557\n",
      "epoch 130; iter: 0; batch classifier loss: 0.426577; batch adversarial loss: 0.648584\n",
      "epoch 131; iter: 0; batch classifier loss: 0.443567; batch adversarial loss: 0.533936\n",
      "epoch 132; iter: 0; batch classifier loss: 0.425103; batch adversarial loss: 0.570750\n",
      "epoch 133; iter: 0; batch classifier loss: 0.426039; batch adversarial loss: 0.658790\n",
      "epoch 134; iter: 0; batch classifier loss: 0.440770; batch adversarial loss: 0.575625\n",
      "epoch 135; iter: 0; batch classifier loss: 0.401349; batch adversarial loss: 0.515928\n",
      "epoch 136; iter: 0; batch classifier loss: 0.367432; batch adversarial loss: 0.545004\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424949; batch adversarial loss: 0.585226\n",
      "epoch 138; iter: 0; batch classifier loss: 0.430268; batch adversarial loss: 0.564365\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402060; batch adversarial loss: 0.544945\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333207; batch adversarial loss: 0.593171\n",
      "epoch 141; iter: 0; batch classifier loss: 0.293469; batch adversarial loss: 0.573122\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374556; batch adversarial loss: 0.544745\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401072; batch adversarial loss: 0.485489\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377126; batch adversarial loss: 0.459508\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384269; batch adversarial loss: 0.593473\n",
      "epoch 146; iter: 0; batch classifier loss: 0.538623; batch adversarial loss: 0.534641\n",
      "epoch 147; iter: 0; batch classifier loss: 0.412555; batch adversarial loss: 0.496183\n",
      "epoch 148; iter: 0; batch classifier loss: 0.449207; batch adversarial loss: 0.534935\n",
      "epoch 149; iter: 0; batch classifier loss: 0.436379; batch adversarial loss: 0.495281\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368748; batch adversarial loss: 0.476300\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352772; batch adversarial loss: 0.594234\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365250; batch adversarial loss: 0.565902\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329938; batch adversarial loss: 0.564080\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382482; batch adversarial loss: 0.485902\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355577; batch adversarial loss: 0.622230\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368850; batch adversarial loss: 0.545820\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385761; batch adversarial loss: 0.495590\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381501; batch adversarial loss: 0.438126\n",
      "epoch 159; iter: 0; batch classifier loss: 0.397482; batch adversarial loss: 0.534287\n",
      "epoch 160; iter: 0; batch classifier loss: 0.409431; batch adversarial loss: 0.591046\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414436; batch adversarial loss: 0.457845\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390167; batch adversarial loss: 0.600817\n",
      "epoch 163; iter: 0; batch classifier loss: 0.470840; batch adversarial loss: 0.603448\n",
      "epoch 164; iter: 0; batch classifier loss: 0.439411; batch adversarial loss: 0.486879\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334061; batch adversarial loss: 0.515332\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384514; batch adversarial loss: 0.594459\n",
      "epoch 167; iter: 0; batch classifier loss: 0.354550; batch adversarial loss: 0.525518\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327150; batch adversarial loss: 0.495398\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367970; batch adversarial loss: 0.554357\n",
      "epoch 170; iter: 0; batch classifier loss: 0.444919; batch adversarial loss: 0.448847\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355394; batch adversarial loss: 0.488203\n",
      "epoch 172; iter: 0; batch classifier loss: 0.408135; batch adversarial loss: 0.467398\n",
      "epoch 173; iter: 0; batch classifier loss: 0.454580; batch adversarial loss: 0.573158\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392120; batch adversarial loss: 0.487424\n",
      "epoch 175; iter: 0; batch classifier loss: 0.289927; batch adversarial loss: 0.554855\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358983; batch adversarial loss: 0.439134\n",
      "epoch 177; iter: 0; batch classifier loss: 0.393261; batch adversarial loss: 0.631217\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350675; batch adversarial loss: 0.507339\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303508; batch adversarial loss: 0.602624\n",
      "epoch 180; iter: 0; batch classifier loss: 0.317950; batch adversarial loss: 0.601862\n",
      "epoch 181; iter: 0; batch classifier loss: 0.463990; batch adversarial loss: 0.524699\n",
      "epoch 182; iter: 0; batch classifier loss: 0.327045; batch adversarial loss: 0.554503\n",
      "epoch 183; iter: 0; batch classifier loss: 0.340921; batch adversarial loss: 0.448087\n",
      "epoch 184; iter: 0; batch classifier loss: 0.369875; batch adversarial loss: 0.447606\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384876; batch adversarial loss: 0.563141\n",
      "epoch 186; iter: 0; batch classifier loss: 0.362778; batch adversarial loss: 0.582465\n",
      "epoch 187; iter: 0; batch classifier loss: 0.445615; batch adversarial loss: 0.592223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.344625; batch adversarial loss: 0.496101\n",
      "epoch 189; iter: 0; batch classifier loss: 0.372586; batch adversarial loss: 0.517141\n",
      "epoch 190; iter: 0; batch classifier loss: 0.354253; batch adversarial loss: 0.573178\n",
      "epoch 191; iter: 0; batch classifier loss: 0.413217; batch adversarial loss: 0.516130\n",
      "epoch 192; iter: 0; batch classifier loss: 0.432398; batch adversarial loss: 0.564634\n",
      "epoch 193; iter: 0; batch classifier loss: 0.374867; batch adversarial loss: 0.601264\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350381; batch adversarial loss: 0.516101\n",
      "epoch 195; iter: 0; batch classifier loss: 0.414396; batch adversarial loss: 0.485326\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332604; batch adversarial loss: 0.506095\n",
      "epoch 197; iter: 0; batch classifier loss: 0.380799; batch adversarial loss: 0.524556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.326736; batch adversarial loss: 0.619654\n",
      "epoch 199; iter: 0; batch classifier loss: 0.486390; batch adversarial loss: 0.544264\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741199; batch adversarial loss: 0.627221\n",
      "epoch 1; iter: 0; batch classifier loss: 0.558870; batch adversarial loss: 0.664370\n",
      "epoch 2; iter: 0; batch classifier loss: 0.531082; batch adversarial loss: 0.657727\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582959; batch adversarial loss: 0.610928\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569958; batch adversarial loss: 0.631860\n",
      "epoch 5; iter: 0; batch classifier loss: 0.513960; batch adversarial loss: 0.603755\n",
      "epoch 6; iter: 0; batch classifier loss: 0.613218; batch adversarial loss: 0.618209\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573090; batch adversarial loss: 0.618470\n",
      "epoch 8; iter: 0; batch classifier loss: 0.593380; batch adversarial loss: 0.623437\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604664; batch adversarial loss: 0.532653\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508123; batch adversarial loss: 0.577843\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569174; batch adversarial loss: 0.585946\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497418; batch adversarial loss: 0.584798\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488138; batch adversarial loss: 0.600090\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501124; batch adversarial loss: 0.561920\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541538; batch adversarial loss: 0.529422\n",
      "epoch 16; iter: 0; batch classifier loss: 0.546798; batch adversarial loss: 0.539305\n",
      "epoch 17; iter: 0; batch classifier loss: 0.404405; batch adversarial loss: 0.563294\n",
      "epoch 18; iter: 0; batch classifier loss: 0.451727; batch adversarial loss: 0.597934\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512710; batch adversarial loss: 0.577545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495769; batch adversarial loss: 0.501568\n",
      "epoch 21; iter: 0; batch classifier loss: 0.566057; batch adversarial loss: 0.512981\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433912; batch adversarial loss: 0.585158\n",
      "epoch 23; iter: 0; batch classifier loss: 0.440356; batch adversarial loss: 0.543719\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506375; batch adversarial loss: 0.521174\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440483; batch adversarial loss: 0.545755\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470489; batch adversarial loss: 0.539381\n",
      "epoch 27; iter: 0; batch classifier loss: 0.420242; batch adversarial loss: 0.571346\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439534; batch adversarial loss: 0.451718\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463957; batch adversarial loss: 0.518473\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466066; batch adversarial loss: 0.482096\n",
      "epoch 31; iter: 0; batch classifier loss: 0.493187; batch adversarial loss: 0.509954\n",
      "epoch 32; iter: 0; batch classifier loss: 0.427192; batch adversarial loss: 0.607887\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388613; batch adversarial loss: 0.590225\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439637; batch adversarial loss: 0.509462\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426820; batch adversarial loss: 0.463926\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441842; batch adversarial loss: 0.535618\n",
      "epoch 37; iter: 0; batch classifier loss: 0.419694; batch adversarial loss: 0.508612\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398369; batch adversarial loss: 0.427297\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452114; batch adversarial loss: 0.480680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.384750; batch adversarial loss: 0.544462\n",
      "epoch 41; iter: 0; batch classifier loss: 0.520395; batch adversarial loss: 0.535421\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462272; batch adversarial loss: 0.608789\n",
      "epoch 43; iter: 0; batch classifier loss: 0.498376; batch adversarial loss: 0.572013\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476992; batch adversarial loss: 0.471853\n",
      "epoch 45; iter: 0; batch classifier loss: 0.501110; batch adversarial loss: 0.571851\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495960; batch adversarial loss: 0.516687\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433509; batch adversarial loss: 0.562867\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460409; batch adversarial loss: 0.628233\n",
      "epoch 49; iter: 0; batch classifier loss: 0.364149; batch adversarial loss: 0.544633\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451044; batch adversarial loss: 0.535700\n",
      "epoch 51; iter: 0; batch classifier loss: 0.410794; batch adversarial loss: 0.506943\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413872; batch adversarial loss: 0.516328\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384727; batch adversarial loss: 0.515741\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432472; batch adversarial loss: 0.509101\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405520; batch adversarial loss: 0.561939\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395628; batch adversarial loss: 0.543385\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424763; batch adversarial loss: 0.543423\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409124; batch adversarial loss: 0.560901\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384799; batch adversarial loss: 0.544412\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376932; batch adversarial loss: 0.523203\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381309; batch adversarial loss: 0.499992\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433402; batch adversarial loss: 0.534865\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422344; batch adversarial loss: 0.628150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442837; batch adversarial loss: 0.554586\n",
      "epoch 65; iter: 0; batch classifier loss: 0.372270; batch adversarial loss: 0.544672\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408597; batch adversarial loss: 0.590140\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386054; batch adversarial loss: 0.516362\n",
      "epoch 68; iter: 0; batch classifier loss: 0.449944; batch adversarial loss: 0.591275\n",
      "epoch 69; iter: 0; batch classifier loss: 0.516054; batch adversarial loss: 0.487535\n",
      "epoch 70; iter: 0; batch classifier loss: 0.448590; batch adversarial loss: 0.506564\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390057; batch adversarial loss: 0.544614\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418005; batch adversarial loss: 0.555081\n",
      "epoch 73; iter: 0; batch classifier loss: 0.352603; batch adversarial loss: 0.592397\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359606; batch adversarial loss: 0.534399\n",
      "epoch 75; iter: 0; batch classifier loss: 0.338187; batch adversarial loss: 0.562638\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405672; batch adversarial loss: 0.479449\n",
      "epoch 77; iter: 0; batch classifier loss: 0.473542; batch adversarial loss: 0.524467\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376084; batch adversarial loss: 0.591309\n",
      "epoch 79; iter: 0; batch classifier loss: 0.454459; batch adversarial loss: 0.553420\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406052; batch adversarial loss: 0.602141\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387218; batch adversarial loss: 0.590664\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380000; batch adversarial loss: 0.525815\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345515; batch adversarial loss: 0.535630\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364944; batch adversarial loss: 0.572228\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382243; batch adversarial loss: 0.588559\n",
      "epoch 86; iter: 0; batch classifier loss: 0.317753; batch adversarial loss: 0.498325\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384475; batch adversarial loss: 0.561907\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358961; batch adversarial loss: 0.481510\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380391; batch adversarial loss: 0.535283\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359270; batch adversarial loss: 0.590038\n",
      "epoch 91; iter: 0; batch classifier loss: 0.328202; batch adversarial loss: 0.563640\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434657; batch adversarial loss: 0.477985\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385686; batch adversarial loss: 0.600250\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431418; batch adversarial loss: 0.591018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.389674; batch adversarial loss: 0.528945\n",
      "epoch 96; iter: 0; batch classifier loss: 0.406218; batch adversarial loss: 0.497590\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379580; batch adversarial loss: 0.496598\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390742; batch adversarial loss: 0.516082\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375141; batch adversarial loss: 0.505433\n",
      "epoch 100; iter: 0; batch classifier loss: 0.315155; batch adversarial loss: 0.479956\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360566; batch adversarial loss: 0.563043\n",
      "epoch 102; iter: 0; batch classifier loss: 0.408227; batch adversarial loss: 0.551703\n",
      "epoch 103; iter: 0; batch classifier loss: 0.357144; batch adversarial loss: 0.541202\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373178; batch adversarial loss: 0.524434\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365836; batch adversarial loss: 0.555811\n",
      "epoch 106; iter: 0; batch classifier loss: 0.337954; batch adversarial loss: 0.468642\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361799; batch adversarial loss: 0.573994\n",
      "epoch 108; iter: 0; batch classifier loss: 0.425792; batch adversarial loss: 0.571638\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347596; batch adversarial loss: 0.580533\n",
      "epoch 110; iter: 0; batch classifier loss: 0.456902; batch adversarial loss: 0.564820\n",
      "epoch 111; iter: 0; batch classifier loss: 0.305106; batch adversarial loss: 0.563580\n",
      "epoch 112; iter: 0; batch classifier loss: 0.300845; batch adversarial loss: 0.553633\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401470; batch adversarial loss: 0.618498\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374352; batch adversarial loss: 0.460373\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352176; batch adversarial loss: 0.545582\n",
      "epoch 116; iter: 0; batch classifier loss: 0.428723; batch adversarial loss: 0.552628\n",
      "epoch 117; iter: 0; batch classifier loss: 0.428676; batch adversarial loss: 0.461002\n",
      "epoch 118; iter: 0; batch classifier loss: 0.449503; batch adversarial loss: 0.589831\n",
      "epoch 119; iter: 0; batch classifier loss: 0.335505; batch adversarial loss: 0.518458\n",
      "epoch 120; iter: 0; batch classifier loss: 0.331140; batch adversarial loss: 0.515714\n",
      "epoch 121; iter: 0; batch classifier loss: 0.331043; batch adversarial loss: 0.554573\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364898; batch adversarial loss: 0.618937\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372492; batch adversarial loss: 0.515343\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382191; batch adversarial loss: 0.524940\n",
      "epoch 125; iter: 0; batch classifier loss: 0.424265; batch adversarial loss: 0.543904\n",
      "epoch 126; iter: 0; batch classifier loss: 0.457626; batch adversarial loss: 0.556229\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352541; batch adversarial loss: 0.515496\n",
      "epoch 128; iter: 0; batch classifier loss: 0.423458; batch adversarial loss: 0.519252\n",
      "epoch 129; iter: 0; batch classifier loss: 0.427538; batch adversarial loss: 0.496848\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397570; batch adversarial loss: 0.683237\n",
      "epoch 131; iter: 0; batch classifier loss: 0.358528; batch adversarial loss: 0.519734\n",
      "epoch 132; iter: 0; batch classifier loss: 0.383582; batch adversarial loss: 0.517911\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355992; batch adversarial loss: 0.530181\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351884; batch adversarial loss: 0.525596\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369519; batch adversarial loss: 0.565687\n",
      "epoch 136; iter: 0; batch classifier loss: 0.356398; batch adversarial loss: 0.536967\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369296; batch adversarial loss: 0.534072\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318883; batch adversarial loss: 0.526940\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374213; batch adversarial loss: 0.496931\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377831; batch adversarial loss: 0.515742\n",
      "epoch 141; iter: 0; batch classifier loss: 0.396605; batch adversarial loss: 0.553851\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386588; batch adversarial loss: 0.507485\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337492; batch adversarial loss: 0.469115\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401119; batch adversarial loss: 0.546900\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418327; batch adversarial loss: 0.533868\n",
      "epoch 146; iter: 0; batch classifier loss: 0.422135; batch adversarial loss: 0.582309\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342886; batch adversarial loss: 0.516744\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331067; batch adversarial loss: 0.600559\n",
      "epoch 149; iter: 0; batch classifier loss: 0.389599; batch adversarial loss: 0.590821\n",
      "epoch 150; iter: 0; batch classifier loss: 0.315158; batch adversarial loss: 0.600768\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375629; batch adversarial loss: 0.533190\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390349; batch adversarial loss: 0.554641\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380420; batch adversarial loss: 0.516662\n",
      "epoch 154; iter: 0; batch classifier loss: 0.415909; batch adversarial loss: 0.469676\n",
      "epoch 155; iter: 0; batch classifier loss: 0.326903; batch adversarial loss: 0.543505\n",
      "epoch 156; iter: 0; batch classifier loss: 0.235296; batch adversarial loss: 0.479781\n",
      "epoch 157; iter: 0; batch classifier loss: 0.388131; batch adversarial loss: 0.545225\n",
      "epoch 158; iter: 0; batch classifier loss: 0.316655; batch adversarial loss: 0.615586\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398527; batch adversarial loss: 0.636299\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352791; batch adversarial loss: 0.535757\n",
      "epoch 161; iter: 0; batch classifier loss: 0.289250; batch adversarial loss: 0.553519\n",
      "epoch 162; iter: 0; batch classifier loss: 0.423971; batch adversarial loss: 0.572032\n",
      "epoch 163; iter: 0; batch classifier loss: 0.412269; batch adversarial loss: 0.648598\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362291; batch adversarial loss: 0.595879\n",
      "epoch 165; iter: 0; batch classifier loss: 0.432601; batch adversarial loss: 0.554528\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369537; batch adversarial loss: 0.589746\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301105; batch adversarial loss: 0.555865\n",
      "epoch 168; iter: 0; batch classifier loss: 0.428678; batch adversarial loss: 0.541548\n",
      "epoch 169; iter: 0; batch classifier loss: 0.383031; batch adversarial loss: 0.511781\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315201; batch adversarial loss: 0.517955\n",
      "epoch 171; iter: 0; batch classifier loss: 0.434522; batch adversarial loss: 0.517142\n",
      "epoch 172; iter: 0; batch classifier loss: 0.320537; batch adversarial loss: 0.516946\n",
      "epoch 173; iter: 0; batch classifier loss: 0.427460; batch adversarial loss: 0.469514\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362877; batch adversarial loss: 0.467728\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342929; batch adversarial loss: 0.545416\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365861; batch adversarial loss: 0.629928\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352332; batch adversarial loss: 0.545118\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371814; batch adversarial loss: 0.543642\n",
      "epoch 179; iter: 0; batch classifier loss: 0.319447; batch adversarial loss: 0.599393\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372099; batch adversarial loss: 0.545833\n",
      "epoch 181; iter: 0; batch classifier loss: 0.389510; batch adversarial loss: 0.563555\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375202; batch adversarial loss: 0.528173\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354985; batch adversarial loss: 0.592648\n",
      "epoch 184; iter: 0; batch classifier loss: 0.414987; batch adversarial loss: 0.508386\n",
      "epoch 185; iter: 0; batch classifier loss: 0.310593; batch adversarial loss: 0.458522\n",
      "epoch 186; iter: 0; batch classifier loss: 0.437001; batch adversarial loss: 0.564264\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329113; batch adversarial loss: 0.581340\n",
      "epoch 188; iter: 0; batch classifier loss: 0.327168; batch adversarial loss: 0.580310\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377430; batch adversarial loss: 0.581339\n",
      "epoch 190; iter: 0; batch classifier loss: 0.397606; batch adversarial loss: 0.508666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.335634; batch adversarial loss: 0.516368\n",
      "epoch 192; iter: 0; batch classifier loss: 0.295170; batch adversarial loss: 0.544052\n",
      "epoch 193; iter: 0; batch classifier loss: 0.414965; batch adversarial loss: 0.582436\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362748; batch adversarial loss: 0.497077\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290212; batch adversarial loss: 0.487349\n",
      "epoch 196; iter: 0; batch classifier loss: 0.300060; batch adversarial loss: 0.598938\n",
      "epoch 197; iter: 0; batch classifier loss: 0.424394; batch adversarial loss: 0.555068\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309608; batch adversarial loss: 0.537346\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308241; batch adversarial loss: 0.526824\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728233; batch adversarial loss: 0.552326\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588628; batch adversarial loss: 0.617038\n",
      "epoch 2; iter: 0; batch classifier loss: 0.592379; batch adversarial loss: 0.745429\n",
      "epoch 3; iter: 0; batch classifier loss: 0.630290; batch adversarial loss: 0.743336\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614808; batch adversarial loss: 0.670510\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587300; batch adversarial loss: 0.698635\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607472; batch adversarial loss: 0.637042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.716476; batch adversarial loss: 0.649074\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602477; batch adversarial loss: 0.621183\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616723; batch adversarial loss: 0.574551\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543181; batch adversarial loss: 0.604527\n",
      "epoch 11; iter: 0; batch classifier loss: 0.611181; batch adversarial loss: 0.578192\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519425; batch adversarial loss: 0.644723\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546674; batch adversarial loss: 0.567857\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552305; batch adversarial loss: 0.585890\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486101; batch adversarial loss: 0.573872\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538024; batch adversarial loss: 0.588123\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528612; batch adversarial loss: 0.576416\n",
      "epoch 18; iter: 0; batch classifier loss: 0.594460; batch adversarial loss: 0.522711\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492791; batch adversarial loss: 0.593383\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512028; batch adversarial loss: 0.600541\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527734; batch adversarial loss: 0.477774\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515743; batch adversarial loss: 0.492552\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505011; batch adversarial loss: 0.528808\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493989; batch adversarial loss: 0.542395\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485342; batch adversarial loss: 0.463279\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442214; batch adversarial loss: 0.514764\n",
      "epoch 27; iter: 0; batch classifier loss: 0.521168; batch adversarial loss: 0.483409\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450722; batch adversarial loss: 0.586697\n",
      "epoch 29; iter: 0; batch classifier loss: 0.554716; batch adversarial loss: 0.530793\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455048; batch adversarial loss: 0.573468\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488424; batch adversarial loss: 0.519585\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452707; batch adversarial loss: 0.489958\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522507; batch adversarial loss: 0.564690\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496451; batch adversarial loss: 0.653881\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476641; batch adversarial loss: 0.543790\n",
      "epoch 36; iter: 0; batch classifier loss: 0.391123; batch adversarial loss: 0.526478\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450623; batch adversarial loss: 0.545862\n",
      "epoch 38; iter: 0; batch classifier loss: 0.505480; batch adversarial loss: 0.553919\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424084; batch adversarial loss: 0.581851\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408104; batch adversarial loss: 0.624564\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462459; batch adversarial loss: 0.526913\n",
      "epoch 42; iter: 0; batch classifier loss: 0.565198; batch adversarial loss: 0.579971\n",
      "epoch 43; iter: 0; batch classifier loss: 0.496706; batch adversarial loss: 0.580738\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456349; batch adversarial loss: 0.566542\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397182; batch adversarial loss: 0.470538\n",
      "epoch 46; iter: 0; batch classifier loss: 0.421129; batch adversarial loss: 0.562275\n",
      "epoch 47; iter: 0; batch classifier loss: 0.486124; batch adversarial loss: 0.598550\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382591; batch adversarial loss: 0.536241\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371576; batch adversarial loss: 0.533463\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503342; batch adversarial loss: 0.583439\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469824; batch adversarial loss: 0.490453\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409497; batch adversarial loss: 0.525385\n",
      "epoch 53; iter: 0; batch classifier loss: 0.358359; batch adversarial loss: 0.525868\n",
      "epoch 54; iter: 0; batch classifier loss: 0.367887; batch adversarial loss: 0.489583\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444966; batch adversarial loss: 0.553711\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412463; batch adversarial loss: 0.526138\n",
      "epoch 57; iter: 0; batch classifier loss: 0.462245; batch adversarial loss: 0.634163\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360332; batch adversarial loss: 0.516820\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476310; batch adversarial loss: 0.553151\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418725; batch adversarial loss: 0.454788\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446279; batch adversarial loss: 0.606802\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428496; batch adversarial loss: 0.572713\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418392; batch adversarial loss: 0.526628\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437112; batch adversarial loss: 0.546157\n",
      "epoch 65; iter: 0; batch classifier loss: 0.472875; batch adversarial loss: 0.536162\n",
      "epoch 66; iter: 0; batch classifier loss: 0.494826; batch adversarial loss: 0.573380\n",
      "epoch 67; iter: 0; batch classifier loss: 0.458990; batch adversarial loss: 0.489532\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376330; batch adversarial loss: 0.498982\n",
      "epoch 69; iter: 0; batch classifier loss: 0.343488; batch adversarial loss: 0.536771\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423128; batch adversarial loss: 0.526460\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365032; batch adversarial loss: 0.553665\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444411; batch adversarial loss: 0.562828\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390102; batch adversarial loss: 0.528204\n",
      "epoch 74; iter: 0; batch classifier loss: 0.296518; batch adversarial loss: 0.545341\n",
      "epoch 75; iter: 0; batch classifier loss: 0.496663; batch adversarial loss: 0.516652\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386631; batch adversarial loss: 0.573294\n",
      "epoch 77; iter: 0; batch classifier loss: 0.403630; batch adversarial loss: 0.534871\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441207; batch adversarial loss: 0.536766\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392193; batch adversarial loss: 0.489811\n",
      "epoch 80; iter: 0; batch classifier loss: 0.372960; batch adversarial loss: 0.553650\n",
      "epoch 81; iter: 0; batch classifier loss: 0.323787; batch adversarial loss: 0.553997\n",
      "epoch 82; iter: 0; batch classifier loss: 0.322546; batch adversarial loss: 0.607657\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420272; batch adversarial loss: 0.563129\n",
      "epoch 84; iter: 0; batch classifier loss: 0.332180; batch adversarial loss: 0.562866\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435196; batch adversarial loss: 0.526109\n",
      "epoch 86; iter: 0; batch classifier loss: 0.363703; batch adversarial loss: 0.600016\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380754; batch adversarial loss: 0.508113\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399602; batch adversarial loss: 0.526732\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379307; batch adversarial loss: 0.553483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.434387; batch adversarial loss: 0.517831\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373136; batch adversarial loss: 0.535775\n",
      "epoch 92; iter: 0; batch classifier loss: 0.437973; batch adversarial loss: 0.581400\n",
      "epoch 93; iter: 0; batch classifier loss: 0.444215; batch adversarial loss: 0.461927\n",
      "epoch 94; iter: 0; batch classifier loss: 0.364357; batch adversarial loss: 0.508308\n",
      "epoch 95; iter: 0; batch classifier loss: 0.436492; batch adversarial loss: 0.590693\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429069; batch adversarial loss: 0.617240\n",
      "epoch 97; iter: 0; batch classifier loss: 0.398031; batch adversarial loss: 0.571838\n",
      "epoch 98; iter: 0; batch classifier loss: 0.431070; batch adversarial loss: 0.608593\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380392; batch adversarial loss: 0.599442\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386544; batch adversarial loss: 0.553314\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355126; batch adversarial loss: 0.572315\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386581; batch adversarial loss: 0.563553\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403212; batch adversarial loss: 0.544165\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421596; batch adversarial loss: 0.608825\n",
      "epoch 105; iter: 0; batch classifier loss: 0.387383; batch adversarial loss: 0.572142\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377229; batch adversarial loss: 0.517056\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375242; batch adversarial loss: 0.608767\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381487; batch adversarial loss: 0.517169\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379467; batch adversarial loss: 0.526130\n",
      "epoch 110; iter: 0; batch classifier loss: 0.269778; batch adversarial loss: 0.508282\n",
      "epoch 111; iter: 0; batch classifier loss: 0.465095; batch adversarial loss: 0.553685\n",
      "epoch 112; iter: 0; batch classifier loss: 0.307287; batch adversarial loss: 0.516979\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390330; batch adversarial loss: 0.616731\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374931; batch adversarial loss: 0.580762\n",
      "epoch 115; iter: 0; batch classifier loss: 0.424899; batch adversarial loss: 0.498943\n",
      "epoch 116; iter: 0; batch classifier loss: 0.329910; batch adversarial loss: 0.526054\n",
      "epoch 117; iter: 0; batch classifier loss: 0.380386; batch adversarial loss: 0.544328\n",
      "epoch 118; iter: 0; batch classifier loss: 0.359239; batch adversarial loss: 0.562856\n",
      "epoch 119; iter: 0; batch classifier loss: 0.362322; batch adversarial loss: 0.498934\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341541; batch adversarial loss: 0.562648\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391581; batch adversarial loss: 0.544574\n",
      "epoch 122; iter: 0; batch classifier loss: 0.433002; batch adversarial loss: 0.471738\n",
      "epoch 123; iter: 0; batch classifier loss: 0.419764; batch adversarial loss: 0.590112\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379560; batch adversarial loss: 0.608476\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418415; batch adversarial loss: 0.590011\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357442; batch adversarial loss: 0.435381\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333711; batch adversarial loss: 0.480641\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348763; batch adversarial loss: 0.526271\n",
      "epoch 129; iter: 0; batch classifier loss: 0.412894; batch adversarial loss: 0.508335\n",
      "epoch 130; iter: 0; batch classifier loss: 0.378986; batch adversarial loss: 0.490147\n",
      "epoch 131; iter: 0; batch classifier loss: 0.451298; batch adversarial loss: 0.535372\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317286; batch adversarial loss: 0.490058\n",
      "epoch 133; iter: 0; batch classifier loss: 0.524808; batch adversarial loss: 0.526988\n",
      "epoch 134; iter: 0; batch classifier loss: 0.392425; batch adversarial loss: 0.553473\n",
      "epoch 135; iter: 0; batch classifier loss: 0.384958; batch adversarial loss: 0.572194\n",
      "epoch 136; iter: 0; batch classifier loss: 0.326235; batch adversarial loss: 0.571932\n",
      "epoch 137; iter: 0; batch classifier loss: 0.479770; batch adversarial loss: 0.581183\n",
      "epoch 138; iter: 0; batch classifier loss: 0.347051; batch adversarial loss: 0.552503\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393588; batch adversarial loss: 0.598631\n",
      "epoch 140; iter: 0; batch classifier loss: 0.421781; batch adversarial loss: 0.536029\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325389; batch adversarial loss: 0.516944\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391149; batch adversarial loss: 0.580918\n",
      "epoch 143; iter: 0; batch classifier loss: 0.447660; batch adversarial loss: 0.544333\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381347; batch adversarial loss: 0.562911\n",
      "epoch 145; iter: 0; batch classifier loss: 0.410783; batch adversarial loss: 0.507841\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380751; batch adversarial loss: 0.589368\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400166; batch adversarial loss: 0.588745\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360344; batch adversarial loss: 0.544588\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342957; batch adversarial loss: 0.535748\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379141; batch adversarial loss: 0.519420\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367533; batch adversarial loss: 0.554519\n",
      "epoch 152; iter: 0; batch classifier loss: 0.471622; batch adversarial loss: 0.551930\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391465; batch adversarial loss: 0.581033\n",
      "epoch 154; iter: 0; batch classifier loss: 0.439390; batch adversarial loss: 0.498981\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344786; batch adversarial loss: 0.544619\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362844; batch adversarial loss: 0.526274\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324823; batch adversarial loss: 0.581437\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388010; batch adversarial loss: 0.544393\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322714; batch adversarial loss: 0.544714\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404231; batch adversarial loss: 0.507959\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316618; batch adversarial loss: 0.526187\n",
      "epoch 162; iter: 0; batch classifier loss: 0.475366; batch adversarial loss: 0.507858\n",
      "epoch 163; iter: 0; batch classifier loss: 0.352236; batch adversarial loss: 0.618027\n",
      "epoch 164; iter: 0; batch classifier loss: 0.298891; batch adversarial loss: 0.535405\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388027; batch adversarial loss: 0.553567\n",
      "epoch 166; iter: 0; batch classifier loss: 0.391750; batch adversarial loss: 0.471562\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352209; batch adversarial loss: 0.516844\n",
      "epoch 168; iter: 0; batch classifier loss: 0.307658; batch adversarial loss: 0.553619\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371925; batch adversarial loss: 0.516957\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368811; batch adversarial loss: 0.572010\n",
      "epoch 171; iter: 0; batch classifier loss: 0.413494; batch adversarial loss: 0.627807\n",
      "epoch 172; iter: 0; batch classifier loss: 0.427886; batch adversarial loss: 0.598477\n",
      "epoch 173; iter: 0; batch classifier loss: 0.415036; batch adversarial loss: 0.553323\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396023; batch adversarial loss: 0.508586\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395743; batch adversarial loss: 0.589964\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395267; batch adversarial loss: 0.590652\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354457; batch adversarial loss: 0.598521\n",
      "epoch 178; iter: 0; batch classifier loss: 0.379325; batch adversarial loss: 0.598724\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354956; batch adversarial loss: 0.562893\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316545; batch adversarial loss: 0.580341\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319231; batch adversarial loss: 0.616758\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339702; batch adversarial loss: 0.571958\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354995; batch adversarial loss: 0.581107\n",
      "epoch 184; iter: 0; batch classifier loss: 0.308515; batch adversarial loss: 0.553136\n",
      "epoch 185; iter: 0; batch classifier loss: 0.399428; batch adversarial loss: 0.481269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.330868; batch adversarial loss: 0.526924\n",
      "epoch 187; iter: 0; batch classifier loss: 0.412127; batch adversarial loss: 0.498960\n",
      "epoch 188; iter: 0; batch classifier loss: 0.252882; batch adversarial loss: 0.543984\n",
      "epoch 189; iter: 0; batch classifier loss: 0.299957; batch adversarial loss: 0.518031\n",
      "epoch 190; iter: 0; batch classifier loss: 0.295170; batch adversarial loss: 0.508167\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403091; batch adversarial loss: 0.489735\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387572; batch adversarial loss: 0.507841\n",
      "epoch 193; iter: 0; batch classifier loss: 0.412835; batch adversarial loss: 0.516827\n",
      "epoch 194; iter: 0; batch classifier loss: 0.449063; batch adversarial loss: 0.581134\n",
      "epoch 195; iter: 0; batch classifier loss: 0.418341; batch adversarial loss: 0.553206\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316064; batch adversarial loss: 0.535710\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353364; batch adversarial loss: 0.562927\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342304; batch adversarial loss: 0.599685\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381377; batch adversarial loss: 0.489463\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724799; batch adversarial loss: 0.710801\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609326; batch adversarial loss: 0.671716\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603887; batch adversarial loss: 0.646111\n",
      "epoch 3; iter: 0; batch classifier loss: 0.596014; batch adversarial loss: 0.637501\n",
      "epoch 4; iter: 0; batch classifier loss: 0.515163; batch adversarial loss: 0.612408\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579006; batch adversarial loss: 0.574184\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578087; batch adversarial loss: 0.588367\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532164; batch adversarial loss: 0.581808\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530875; batch adversarial loss: 0.568641\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551514; batch adversarial loss: 0.550072\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489634; batch adversarial loss: 0.590216\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577723; batch adversarial loss: 0.581199\n",
      "epoch 12; iter: 0; batch classifier loss: 0.627120; batch adversarial loss: 0.590580\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497033; batch adversarial loss: 0.567247\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522800; batch adversarial loss: 0.568318\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562496; batch adversarial loss: 0.604212\n",
      "epoch 16; iter: 0; batch classifier loss: 0.439247; batch adversarial loss: 0.583618\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488172; batch adversarial loss: 0.575619\n",
      "epoch 18; iter: 0; batch classifier loss: 0.552512; batch adversarial loss: 0.628755\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483210; batch adversarial loss: 0.586802\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524711; batch adversarial loss: 0.588364\n",
      "epoch 21; iter: 0; batch classifier loss: 0.627505; batch adversarial loss: 0.651345\n",
      "epoch 22; iter: 0; batch classifier loss: 0.604205; batch adversarial loss: 0.609222\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507711; batch adversarial loss: 0.589169\n",
      "epoch 24; iter: 0; batch classifier loss: 0.522498; batch adversarial loss: 0.496509\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484458; batch adversarial loss: 0.484822\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498251; batch adversarial loss: 0.665703\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481130; batch adversarial loss: 0.645559\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439835; batch adversarial loss: 0.586377\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485921; batch adversarial loss: 0.524196\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454217; batch adversarial loss: 0.583352\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505940; batch adversarial loss: 0.497406\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450857; batch adversarial loss: 0.547395\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480807; batch adversarial loss: 0.521515\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464312; batch adversarial loss: 0.529298\n",
      "epoch 35; iter: 0; batch classifier loss: 0.510158; batch adversarial loss: 0.535132\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487508; batch adversarial loss: 0.598878\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460908; batch adversarial loss: 0.500281\n",
      "epoch 38; iter: 0; batch classifier loss: 0.563882; batch adversarial loss: 0.517636\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471450; batch adversarial loss: 0.599197\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450737; batch adversarial loss: 0.544574\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410796; batch adversarial loss: 0.553851\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402080; batch adversarial loss: 0.526187\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449615; batch adversarial loss: 0.553602\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481634; batch adversarial loss: 0.581537\n",
      "epoch 45; iter: 0; batch classifier loss: 0.474467; batch adversarial loss: 0.563029\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394305; batch adversarial loss: 0.581873\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409379; batch adversarial loss: 0.553732\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484472; batch adversarial loss: 0.571209\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423029; batch adversarial loss: 0.655866\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432457; batch adversarial loss: 0.470764\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468606; batch adversarial loss: 0.515171\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389128; batch adversarial loss: 0.610291\n",
      "epoch 53; iter: 0; batch classifier loss: 0.330139; batch adversarial loss: 0.544858\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469701; batch adversarial loss: 0.525711\n",
      "epoch 55; iter: 0; batch classifier loss: 0.458685; batch adversarial loss: 0.525512\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443331; batch adversarial loss: 0.526605\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414633; batch adversarial loss: 0.599457\n",
      "epoch 58; iter: 0; batch classifier loss: 0.362996; batch adversarial loss: 0.599859\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456757; batch adversarial loss: 0.516795\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473123; batch adversarial loss: 0.469647\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429623; batch adversarial loss: 0.536702\n",
      "epoch 62; iter: 0; batch classifier loss: 0.404820; batch adversarial loss: 0.570362\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442712; batch adversarial loss: 0.599653\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403461; batch adversarial loss: 0.479172\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367569; batch adversarial loss: 0.599611\n",
      "epoch 66; iter: 0; batch classifier loss: 0.369849; batch adversarial loss: 0.583449\n",
      "epoch 67; iter: 0; batch classifier loss: 0.356372; batch adversarial loss: 0.420538\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401888; batch adversarial loss: 0.536568\n",
      "epoch 69; iter: 0; batch classifier loss: 0.446761; batch adversarial loss: 0.553675\n",
      "epoch 70; iter: 0; batch classifier loss: 0.469023; batch adversarial loss: 0.533921\n",
      "epoch 71; iter: 0; batch classifier loss: 0.339774; batch adversarial loss: 0.554883\n",
      "epoch 72; iter: 0; batch classifier loss: 0.345100; batch adversarial loss: 0.601445\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409338; batch adversarial loss: 0.517411\n",
      "epoch 74; iter: 0; batch classifier loss: 0.334988; batch adversarial loss: 0.505236\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417473; batch adversarial loss: 0.464941\n",
      "epoch 76; iter: 0; batch classifier loss: 0.403762; batch adversarial loss: 0.527817\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435847; batch adversarial loss: 0.555131\n",
      "epoch 78; iter: 0; batch classifier loss: 0.434822; batch adversarial loss: 0.486657\n",
      "epoch 79; iter: 0; batch classifier loss: 0.465602; batch adversarial loss: 0.535270\n",
      "epoch 80; iter: 0; batch classifier loss: 0.362122; batch adversarial loss: 0.553211\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407749; batch adversarial loss: 0.544907\n",
      "epoch 82; iter: 0; batch classifier loss: 0.405531; batch adversarial loss: 0.526265\n",
      "epoch 83; iter: 0; batch classifier loss: 0.440168; batch adversarial loss: 0.589958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.490654; batch adversarial loss: 0.628657\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402680; batch adversarial loss: 0.543974\n",
      "epoch 86; iter: 0; batch classifier loss: 0.483023; batch adversarial loss: 0.610365\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399774; batch adversarial loss: 0.489746\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376120; batch adversarial loss: 0.449860\n",
      "epoch 89; iter: 0; batch classifier loss: 0.351658; batch adversarial loss: 0.544381\n",
      "epoch 90; iter: 0; batch classifier loss: 0.360152; batch adversarial loss: 0.543809\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413357; batch adversarial loss: 0.572605\n",
      "epoch 92; iter: 0; batch classifier loss: 0.361945; batch adversarial loss: 0.581675\n",
      "epoch 93; iter: 0; batch classifier loss: 0.354203; batch adversarial loss: 0.611515\n",
      "epoch 94; iter: 0; batch classifier loss: 0.429946; batch adversarial loss: 0.535660\n",
      "epoch 95; iter: 0; batch classifier loss: 0.380638; batch adversarial loss: 0.599866\n",
      "epoch 96; iter: 0; batch classifier loss: 0.495279; batch adversarial loss: 0.591259\n",
      "epoch 97; iter: 0; batch classifier loss: 0.380909; batch adversarial loss: 0.517190\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398115; batch adversarial loss: 0.562824\n",
      "epoch 99; iter: 0; batch classifier loss: 0.431885; batch adversarial loss: 0.553084\n",
      "epoch 100; iter: 0; batch classifier loss: 0.480469; batch adversarial loss: 0.563256\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384276; batch adversarial loss: 0.516016\n",
      "epoch 102; iter: 0; batch classifier loss: 0.339146; batch adversarial loss: 0.516146\n",
      "epoch 103; iter: 0; batch classifier loss: 0.353823; batch adversarial loss: 0.600487\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375676; batch adversarial loss: 0.545483\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383529; batch adversarial loss: 0.469857\n",
      "epoch 106; iter: 0; batch classifier loss: 0.448322; batch adversarial loss: 0.487899\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350160; batch adversarial loss: 0.515342\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351020; batch adversarial loss: 0.563979\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387926; batch adversarial loss: 0.582747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.418561; batch adversarial loss: 0.629039\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401896; batch adversarial loss: 0.637512\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384781; batch adversarial loss: 0.516632\n",
      "epoch 113; iter: 0; batch classifier loss: 0.403068; batch adversarial loss: 0.553241\n",
      "epoch 114; iter: 0; batch classifier loss: 0.305372; batch adversarial loss: 0.506721\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394362; batch adversarial loss: 0.525628\n",
      "epoch 116; iter: 0; batch classifier loss: 0.362739; batch adversarial loss: 0.469080\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386538; batch adversarial loss: 0.553718\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402704; batch adversarial loss: 0.601074\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349982; batch adversarial loss: 0.507170\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408363; batch adversarial loss: 0.525207\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420734; batch adversarial loss: 0.543628\n",
      "epoch 122; iter: 0; batch classifier loss: 0.390208; batch adversarial loss: 0.572874\n",
      "epoch 123; iter: 0; batch classifier loss: 0.421551; batch adversarial loss: 0.610463\n",
      "epoch 124; iter: 0; batch classifier loss: 0.436599; batch adversarial loss: 0.637841\n",
      "epoch 125; iter: 0; batch classifier loss: 0.419894; batch adversarial loss: 0.507000\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368215; batch adversarial loss: 0.506055\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370343; batch adversarial loss: 0.524873\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409659; batch adversarial loss: 0.571457\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347698; batch adversarial loss: 0.507532\n",
      "epoch 130; iter: 0; batch classifier loss: 0.378431; batch adversarial loss: 0.629672\n",
      "epoch 131; iter: 0; batch classifier loss: 0.334292; batch adversarial loss: 0.610633\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335973; batch adversarial loss: 0.543500\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408713; batch adversarial loss: 0.590842\n",
      "epoch 134; iter: 0; batch classifier loss: 0.468767; batch adversarial loss: 0.429841\n",
      "epoch 135; iter: 0; batch classifier loss: 0.342055; batch adversarial loss: 0.573194\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387234; batch adversarial loss: 0.573795\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374746; batch adversarial loss: 0.535285\n",
      "epoch 138; iter: 0; batch classifier loss: 0.324746; batch adversarial loss: 0.562678\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415703; batch adversarial loss: 0.582404\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355358; batch adversarial loss: 0.524327\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357121; batch adversarial loss: 0.591531\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400227; batch adversarial loss: 0.534667\n",
      "epoch 143; iter: 0; batch classifier loss: 0.427094; batch adversarial loss: 0.535463\n",
      "epoch 144; iter: 0; batch classifier loss: 0.418013; batch adversarial loss: 0.487165\n",
      "epoch 145; iter: 0; batch classifier loss: 0.445783; batch adversarial loss: 0.515614\n",
      "epoch 146; iter: 0; batch classifier loss: 0.289175; batch adversarial loss: 0.459773\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388089; batch adversarial loss: 0.564829\n",
      "epoch 148; iter: 0; batch classifier loss: 0.430592; batch adversarial loss: 0.656834\n",
      "epoch 149; iter: 0; batch classifier loss: 0.291497; batch adversarial loss: 0.506326\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355298; batch adversarial loss: 0.544400\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370048; batch adversarial loss: 0.581014\n",
      "epoch 152; iter: 0; batch classifier loss: 0.412941; batch adversarial loss: 0.526039\n",
      "epoch 153; iter: 0; batch classifier loss: 0.436179; batch adversarial loss: 0.516783\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320440; batch adversarial loss: 0.478620\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362437; batch adversarial loss: 0.535482\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380209; batch adversarial loss: 0.600759\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366581; batch adversarial loss: 0.487082\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384350; batch adversarial loss: 0.478444\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361404; batch adversarial loss: 0.516071\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379805; batch adversarial loss: 0.440580\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329758; batch adversarial loss: 0.450048\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369355; batch adversarial loss: 0.582520\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374722; batch adversarial loss: 0.534896\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369632; batch adversarial loss: 0.553051\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344846; batch adversarial loss: 0.507597\n",
      "epoch 166; iter: 0; batch classifier loss: 0.297279; batch adversarial loss: 0.525557\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372104; batch adversarial loss: 0.554773\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359558; batch adversarial loss: 0.516119\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384776; batch adversarial loss: 0.488521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.461844; batch adversarial loss: 0.544089\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326317; batch adversarial loss: 0.544442\n",
      "epoch 172; iter: 0; batch classifier loss: 0.321793; batch adversarial loss: 0.459399\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380724; batch adversarial loss: 0.535607\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368713; batch adversarial loss: 0.515933\n",
      "epoch 175; iter: 0; batch classifier loss: 0.371788; batch adversarial loss: 0.488436\n",
      "epoch 176; iter: 0; batch classifier loss: 0.326492; batch adversarial loss: 0.562807\n",
      "epoch 177; iter: 0; batch classifier loss: 0.394890; batch adversarial loss: 0.515661\n",
      "epoch 178; iter: 0; batch classifier loss: 0.365474; batch adversarial loss: 0.610037\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367939; batch adversarial loss: 0.544261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.371707; batch adversarial loss: 0.554835\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345120; batch adversarial loss: 0.545443\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341250; batch adversarial loss: 0.516697\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343210; batch adversarial loss: 0.562588\n",
      "epoch 184; iter: 0; batch classifier loss: 0.408378; batch adversarial loss: 0.517503\n",
      "epoch 185; iter: 0; batch classifier loss: 0.466681; batch adversarial loss: 0.506434\n",
      "epoch 186; iter: 0; batch classifier loss: 0.481705; batch adversarial loss: 0.591074\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310075; batch adversarial loss: 0.478752\n",
      "epoch 188; iter: 0; batch classifier loss: 0.415786; batch adversarial loss: 0.468768\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333717; batch adversarial loss: 0.602115\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358058; batch adversarial loss: 0.545030\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341142; batch adversarial loss: 0.430562\n",
      "epoch 192; iter: 0; batch classifier loss: 0.311725; batch adversarial loss: 0.506348\n",
      "epoch 193; iter: 0; batch classifier loss: 0.315355; batch adversarial loss: 0.553017\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347392; batch adversarial loss: 0.601247\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362757; batch adversarial loss: 0.554104\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309753; batch adversarial loss: 0.496433\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349075; batch adversarial loss: 0.488234\n",
      "epoch 198; iter: 0; batch classifier loss: 0.392008; batch adversarial loss: 0.552688\n",
      "epoch 199; iter: 0; batch classifier loss: 0.392021; batch adversarial loss: 0.619228\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714588; batch adversarial loss: 0.799521\n",
      "epoch 1; iter: 0; batch classifier loss: 0.830281; batch adversarial loss: 0.906079\n",
      "epoch 2; iter: 0; batch classifier loss: 0.907272; batch adversarial loss: 0.851586\n",
      "epoch 3; iter: 0; batch classifier loss: 0.693392; batch adversarial loss: 0.707187\n",
      "epoch 4; iter: 0; batch classifier loss: 0.688368; batch adversarial loss: 0.678184\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600493; batch adversarial loss: 0.633543\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563498; batch adversarial loss: 0.630617\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582379; batch adversarial loss: 0.644627\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602196; batch adversarial loss: 0.614855\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567929; batch adversarial loss: 0.619757\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542182; batch adversarial loss: 0.593880\n",
      "epoch 11; iter: 0; batch classifier loss: 0.561590; batch adversarial loss: 0.671855\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570605; batch adversarial loss: 0.617145\n",
      "epoch 13; iter: 0; batch classifier loss: 0.620098; batch adversarial loss: 0.545916\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509321; batch adversarial loss: 0.636388\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521075; batch adversarial loss: 0.571820\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505396; batch adversarial loss: 0.557499\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519249; batch adversarial loss: 0.580607\n",
      "epoch 18; iter: 0; batch classifier loss: 0.470646; batch adversarial loss: 0.567171\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471479; batch adversarial loss: 0.585410\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500547; batch adversarial loss: 0.573566\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455212; batch adversarial loss: 0.565587\n",
      "epoch 22; iter: 0; batch classifier loss: 0.455489; batch adversarial loss: 0.559258\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462866; batch adversarial loss: 0.530504\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471166; batch adversarial loss: 0.591223\n",
      "epoch 25; iter: 0; batch classifier loss: 0.423867; batch adversarial loss: 0.527023\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497961; batch adversarial loss: 0.586664\n",
      "epoch 27; iter: 0; batch classifier loss: 0.498961; batch adversarial loss: 0.541949\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514583; batch adversarial loss: 0.546027\n",
      "epoch 29; iter: 0; batch classifier loss: 0.442133; batch adversarial loss: 0.498901\n",
      "epoch 30; iter: 0; batch classifier loss: 0.528573; batch adversarial loss: 0.619280\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471949; batch adversarial loss: 0.557430\n",
      "epoch 32; iter: 0; batch classifier loss: 0.451378; batch adversarial loss: 0.564160\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477579; batch adversarial loss: 0.559184\n",
      "epoch 34; iter: 0; batch classifier loss: 0.489909; batch adversarial loss: 0.681100\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475397; batch adversarial loss: 0.581311\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460559; batch adversarial loss: 0.611872\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440605; batch adversarial loss: 0.578391\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492398; batch adversarial loss: 0.485464\n",
      "epoch 39; iter: 0; batch classifier loss: 0.486991; batch adversarial loss: 0.439567\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439488; batch adversarial loss: 0.557483\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448116; batch adversarial loss: 0.561456\n",
      "epoch 42; iter: 0; batch classifier loss: 0.458632; batch adversarial loss: 0.536617\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437419; batch adversarial loss: 0.523631\n",
      "epoch 44; iter: 0; batch classifier loss: 0.504491; batch adversarial loss: 0.564272\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414320; batch adversarial loss: 0.530948\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443894; batch adversarial loss: 0.517168\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438988; batch adversarial loss: 0.525955\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388271; batch adversarial loss: 0.565149\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475161; batch adversarial loss: 0.526804\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395073; batch adversarial loss: 0.480643\n",
      "epoch 51; iter: 0; batch classifier loss: 0.504185; batch adversarial loss: 0.526961\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380745; batch adversarial loss: 0.609400\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454309; batch adversarial loss: 0.618273\n",
      "epoch 54; iter: 0; batch classifier loss: 0.359966; batch adversarial loss: 0.497248\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441386; batch adversarial loss: 0.609206\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404470; batch adversarial loss: 0.526003\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471073; batch adversarial loss: 0.526373\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427183; batch adversarial loss: 0.563602\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416230; batch adversarial loss: 0.542749\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437815; batch adversarial loss: 0.572105\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386833; batch adversarial loss: 0.560949\n",
      "epoch 62; iter: 0; batch classifier loss: 0.512410; batch adversarial loss: 0.499253\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441801; batch adversarial loss: 0.526927\n",
      "epoch 64; iter: 0; batch classifier loss: 0.443217; batch adversarial loss: 0.572624\n",
      "epoch 65; iter: 0; batch classifier loss: 0.391522; batch adversarial loss: 0.609517\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432311; batch adversarial loss: 0.577307\n",
      "epoch 67; iter: 0; batch classifier loss: 0.443921; batch adversarial loss: 0.515153\n",
      "epoch 68; iter: 0; batch classifier loss: 0.538426; batch adversarial loss: 0.550091\n",
      "epoch 69; iter: 0; batch classifier loss: 0.573401; batch adversarial loss: 0.531925\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406860; batch adversarial loss: 0.461166\n",
      "epoch 71; iter: 0; batch classifier loss: 0.388602; batch adversarial loss: 0.480096\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381332; batch adversarial loss: 0.497595\n",
      "epoch 73; iter: 0; batch classifier loss: 0.357835; batch adversarial loss: 0.529637\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430243; batch adversarial loss: 0.589710\n",
      "epoch 75; iter: 0; batch classifier loss: 0.446094; batch adversarial loss: 0.476650\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441307; batch adversarial loss: 0.479470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.437862; batch adversarial loss: 0.462172\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417802; batch adversarial loss: 0.490151\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406140; batch adversarial loss: 0.581893\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441880; batch adversarial loss: 0.598852\n",
      "epoch 81; iter: 0; batch classifier loss: 0.431399; batch adversarial loss: 0.514884\n",
      "epoch 82; iter: 0; batch classifier loss: 0.432556; batch adversarial loss: 0.524467\n",
      "epoch 83; iter: 0; batch classifier loss: 0.408713; batch adversarial loss: 0.553734\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362367; batch adversarial loss: 0.544148\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390084; batch adversarial loss: 0.568930\n",
      "epoch 86; iter: 0; batch classifier loss: 0.476174; batch adversarial loss: 0.574751\n",
      "epoch 87; iter: 0; batch classifier loss: 0.409469; batch adversarial loss: 0.552262\n",
      "epoch 88; iter: 0; batch classifier loss: 0.431970; batch adversarial loss: 0.524831\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422394; batch adversarial loss: 0.459197\n",
      "epoch 90; iter: 0; batch classifier loss: 0.329014; batch adversarial loss: 0.528178\n",
      "epoch 91; iter: 0; batch classifier loss: 0.308809; batch adversarial loss: 0.505530\n",
      "epoch 92; iter: 0; batch classifier loss: 0.343143; batch adversarial loss: 0.592758\n",
      "epoch 93; iter: 0; batch classifier loss: 0.373267; batch adversarial loss: 0.541177\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348871; batch adversarial loss: 0.560280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387655; batch adversarial loss: 0.555194\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428204; batch adversarial loss: 0.611886\n",
      "epoch 97; iter: 0; batch classifier loss: 0.319221; batch adversarial loss: 0.533879\n",
      "epoch 98; iter: 0; batch classifier loss: 0.426763; batch adversarial loss: 0.579978\n",
      "epoch 99; iter: 0; batch classifier loss: 0.331033; batch adversarial loss: 0.593398\n",
      "epoch 100; iter: 0; batch classifier loss: 0.325465; batch adversarial loss: 0.563432\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394642; batch adversarial loss: 0.582392\n",
      "epoch 102; iter: 0; batch classifier loss: 0.390164; batch adversarial loss: 0.591320\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406478; batch adversarial loss: 0.583185\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384486; batch adversarial loss: 0.551303\n",
      "epoch 105; iter: 0; batch classifier loss: 0.438221; batch adversarial loss: 0.583070\n",
      "epoch 106; iter: 0; batch classifier loss: 0.403568; batch adversarial loss: 0.569254\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339225; batch adversarial loss: 0.542576\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388169; batch adversarial loss: 0.413173\n",
      "epoch 109; iter: 0; batch classifier loss: 0.354460; batch adversarial loss: 0.508193\n",
      "epoch 110; iter: 0; batch classifier loss: 0.439815; batch adversarial loss: 0.528684\n",
      "epoch 111; iter: 0; batch classifier loss: 0.495261; batch adversarial loss: 0.545496\n",
      "epoch 112; iter: 0; batch classifier loss: 0.328153; batch adversarial loss: 0.507466\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394076; batch adversarial loss: 0.588467\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382496; batch adversarial loss: 0.427585\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380336; batch adversarial loss: 0.513364\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353154; batch adversarial loss: 0.573688\n",
      "epoch 117; iter: 0; batch classifier loss: 0.423686; batch adversarial loss: 0.479815\n",
      "epoch 118; iter: 0; batch classifier loss: 0.413526; batch adversarial loss: 0.534922\n",
      "epoch 119; iter: 0; batch classifier loss: 0.331252; batch adversarial loss: 0.526218\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413975; batch adversarial loss: 0.468509\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346625; batch adversarial loss: 0.592707\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359164; batch adversarial loss: 0.544013\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353337; batch adversarial loss: 0.563686\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408343; batch adversarial loss: 0.553687\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386752; batch adversarial loss: 0.543885\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377129; batch adversarial loss: 0.525091\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401795; batch adversarial loss: 0.498326\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369172; batch adversarial loss: 0.579672\n",
      "epoch 129; iter: 0; batch classifier loss: 0.392108; batch adversarial loss: 0.506516\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384599; batch adversarial loss: 0.627255\n",
      "epoch 131; iter: 0; batch classifier loss: 0.357121; batch adversarial loss: 0.598794\n",
      "epoch 132; iter: 0; batch classifier loss: 0.314579; batch adversarial loss: 0.525228\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397836; batch adversarial loss: 0.580564\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363521; batch adversarial loss: 0.549364\n",
      "epoch 135; iter: 0; batch classifier loss: 0.404176; batch adversarial loss: 0.510129\n",
      "epoch 136; iter: 0; batch classifier loss: 0.412180; batch adversarial loss: 0.552153\n",
      "epoch 137; iter: 0; batch classifier loss: 0.434852; batch adversarial loss: 0.589725\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358849; batch adversarial loss: 0.562725\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378744; batch adversarial loss: 0.594157\n",
      "epoch 140; iter: 0; batch classifier loss: 0.414049; batch adversarial loss: 0.546305\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343311; batch adversarial loss: 0.604705\n",
      "epoch 142; iter: 0; batch classifier loss: 0.444267; batch adversarial loss: 0.600612\n",
      "epoch 143; iter: 0; batch classifier loss: 0.332880; batch adversarial loss: 0.627125\n",
      "epoch 144; iter: 0; batch classifier loss: 0.412781; batch adversarial loss: 0.563958\n",
      "epoch 145; iter: 0; batch classifier loss: 0.406463; batch adversarial loss: 0.610003\n",
      "epoch 146; iter: 0; batch classifier loss: 0.450337; batch adversarial loss: 0.553648\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355813; batch adversarial loss: 0.513821\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331881; batch adversarial loss: 0.533064\n",
      "epoch 149; iter: 0; batch classifier loss: 0.398122; batch adversarial loss: 0.441976\n",
      "epoch 150; iter: 0; batch classifier loss: 0.308141; batch adversarial loss: 0.597541\n",
      "epoch 151; iter: 0; batch classifier loss: 0.424203; batch adversarial loss: 0.536283\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403177; batch adversarial loss: 0.508258\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361883; batch adversarial loss: 0.471064\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340246; batch adversarial loss: 0.458895\n",
      "epoch 155; iter: 0; batch classifier loss: 0.426197; batch adversarial loss: 0.508180\n",
      "epoch 156; iter: 0; batch classifier loss: 0.382435; batch adversarial loss: 0.563711\n",
      "epoch 157; iter: 0; batch classifier loss: 0.323933; batch adversarial loss: 0.562683\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366576; batch adversarial loss: 0.524171\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376129; batch adversarial loss: 0.561378\n",
      "epoch 160; iter: 0; batch classifier loss: 0.287840; batch adversarial loss: 0.564268\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319524; batch adversarial loss: 0.615595\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363986; batch adversarial loss: 0.555287\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351810; batch adversarial loss: 0.562492\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375679; batch adversarial loss: 0.439865\n",
      "epoch 165; iter: 0; batch classifier loss: 0.312396; batch adversarial loss: 0.517247\n",
      "epoch 166; iter: 0; batch classifier loss: 0.371183; batch adversarial loss: 0.535058\n",
      "epoch 167; iter: 0; batch classifier loss: 0.413989; batch adversarial loss: 0.543693\n",
      "epoch 168; iter: 0; batch classifier loss: 0.403937; batch adversarial loss: 0.572044\n",
      "epoch 169; iter: 0; batch classifier loss: 0.401538; batch adversarial loss: 0.506902\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336063; batch adversarial loss: 0.580670\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375745; batch adversarial loss: 0.449255\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351766; batch adversarial loss: 0.527445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.426167; batch adversarial loss: 0.564366\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375420; batch adversarial loss: 0.617660\n",
      "epoch 175; iter: 0; batch classifier loss: 0.410800; batch adversarial loss: 0.543823\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393740; batch adversarial loss: 0.513306\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306959; batch adversarial loss: 0.553776\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381987; batch adversarial loss: 0.599725\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399494; batch adversarial loss: 0.600768\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322629; batch adversarial loss: 0.553882\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371401; batch adversarial loss: 0.554280\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375035; batch adversarial loss: 0.649619\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369938; batch adversarial loss: 0.581433\n",
      "epoch 184; iter: 0; batch classifier loss: 0.369406; batch adversarial loss: 0.535468\n",
      "epoch 185; iter: 0; batch classifier loss: 0.394871; batch adversarial loss: 0.543863\n",
      "epoch 186; iter: 0; batch classifier loss: 0.405094; batch adversarial loss: 0.618930\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393207; batch adversarial loss: 0.592841\n",
      "epoch 188; iter: 0; batch classifier loss: 0.344122; batch adversarial loss: 0.544541\n",
      "epoch 189; iter: 0; batch classifier loss: 0.319071; batch adversarial loss: 0.488105\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333088; batch adversarial loss: 0.498014\n",
      "epoch 191; iter: 0; batch classifier loss: 0.367775; batch adversarial loss: 0.467390\n",
      "epoch 192; iter: 0; batch classifier loss: 0.406205; batch adversarial loss: 0.563285\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344863; batch adversarial loss: 0.635368\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318087; batch adversarial loss: 0.534369\n",
      "epoch 195; iter: 0; batch classifier loss: 0.296683; batch adversarial loss: 0.497763\n",
      "epoch 196; iter: 0; batch classifier loss: 0.389206; batch adversarial loss: 0.618250\n",
      "epoch 197; iter: 0; batch classifier loss: 0.415055; batch adversarial loss: 0.582940\n",
      "epoch 198; iter: 0; batch classifier loss: 0.425439; batch adversarial loss: 0.536509\n",
      "epoch 199; iter: 0; batch classifier loss: 0.313480; batch adversarial loss: 0.600946\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704169; batch adversarial loss: 0.772075\n",
      "epoch 1; iter: 0; batch classifier loss: 0.779260; batch adversarial loss: 0.857484\n",
      "epoch 2; iter: 0; batch classifier loss: 0.771963; batch adversarial loss: 0.776185\n",
      "epoch 3; iter: 0; batch classifier loss: 0.695167; batch adversarial loss: 0.679413\n",
      "epoch 4; iter: 0; batch classifier loss: 0.613420; batch adversarial loss: 0.692932\n",
      "epoch 5; iter: 0; batch classifier loss: 0.525247; batch adversarial loss: 0.634428\n",
      "epoch 6; iter: 0; batch classifier loss: 0.649593; batch adversarial loss: 0.612002\n",
      "epoch 7; iter: 0; batch classifier loss: 0.506365; batch adversarial loss: 0.628342\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558639; batch adversarial loss: 0.621062\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600758; batch adversarial loss: 0.590618\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546557; batch adversarial loss: 0.586638\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549323; batch adversarial loss: 0.569758\n",
      "epoch 12; iter: 0; batch classifier loss: 0.478748; batch adversarial loss: 0.559237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476587; batch adversarial loss: 0.585031\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543340; batch adversarial loss: 0.575587\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562279; batch adversarial loss: 0.572847\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519171; batch adversarial loss: 0.595596\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466972; batch adversarial loss: 0.613781\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483143; batch adversarial loss: 0.566954\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463489; batch adversarial loss: 0.546242\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513222; batch adversarial loss: 0.656609\n",
      "epoch 21; iter: 0; batch classifier loss: 0.446612; batch adversarial loss: 0.552699\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525027; batch adversarial loss: 0.567640\n",
      "epoch 23; iter: 0; batch classifier loss: 0.448281; batch adversarial loss: 0.524002\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387614; batch adversarial loss: 0.561013\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520608; batch adversarial loss: 0.480105\n",
      "epoch 26; iter: 0; batch classifier loss: 0.488558; batch adversarial loss: 0.485685\n",
      "epoch 27; iter: 0; batch classifier loss: 0.396738; batch adversarial loss: 0.541458\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421767; batch adversarial loss: 0.607124\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497206; batch adversarial loss: 0.489469\n",
      "epoch 30; iter: 0; batch classifier loss: 0.526386; batch adversarial loss: 0.488428\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449068; batch adversarial loss: 0.638903\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430495; batch adversarial loss: 0.518308\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446075; batch adversarial loss: 0.492236\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499714; batch adversarial loss: 0.574338\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459778; batch adversarial loss: 0.625289\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450989; batch adversarial loss: 0.512886\n",
      "epoch 37; iter: 0; batch classifier loss: 0.398036; batch adversarial loss: 0.588858\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436168; batch adversarial loss: 0.527649\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415435; batch adversarial loss: 0.573569\n",
      "epoch 40; iter: 0; batch classifier loss: 0.534253; batch adversarial loss: 0.542410\n",
      "epoch 41; iter: 0; batch classifier loss: 0.514087; batch adversarial loss: 0.605111\n",
      "epoch 42; iter: 0; batch classifier loss: 0.494257; batch adversarial loss: 0.514455\n",
      "epoch 43; iter: 0; batch classifier loss: 0.516322; batch adversarial loss: 0.553628\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492721; batch adversarial loss: 0.521537\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473290; batch adversarial loss: 0.636293\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464228; batch adversarial loss: 0.635027\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467442; batch adversarial loss: 0.486570\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443623; batch adversarial loss: 0.525088\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433946; batch adversarial loss: 0.462154\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426683; batch adversarial loss: 0.549491\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454334; batch adversarial loss: 0.481074\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425344; batch adversarial loss: 0.525850\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410360; batch adversarial loss: 0.468031\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413178; batch adversarial loss: 0.489365\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404705; batch adversarial loss: 0.614403\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383465; batch adversarial loss: 0.535092\n",
      "epoch 57; iter: 0; batch classifier loss: 0.376674; batch adversarial loss: 0.579707\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441976; batch adversarial loss: 0.461962\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392244; batch adversarial loss: 0.545342\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422164; batch adversarial loss: 0.506123\n",
      "epoch 61; iter: 0; batch classifier loss: 0.477146; batch adversarial loss: 0.581261\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408294; batch adversarial loss: 0.581843\n",
      "epoch 63; iter: 0; batch classifier loss: 0.334033; batch adversarial loss: 0.560991\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418609; batch adversarial loss: 0.479142\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411986; batch adversarial loss: 0.528949\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425482; batch adversarial loss: 0.479486\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379212; batch adversarial loss: 0.628618\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364223; batch adversarial loss: 0.619526\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400536; batch adversarial loss: 0.518433\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425440; batch adversarial loss: 0.477769\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425702; batch adversarial loss: 0.544412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.374043; batch adversarial loss: 0.619277\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376014; batch adversarial loss: 0.553982\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404338; batch adversarial loss: 0.580489\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395512; batch adversarial loss: 0.581947\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404104; batch adversarial loss: 0.507263\n",
      "epoch 77; iter: 0; batch classifier loss: 0.366804; batch adversarial loss: 0.614325\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402933; batch adversarial loss: 0.563937\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428071; batch adversarial loss: 0.506613\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375905; batch adversarial loss: 0.602386\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395787; batch adversarial loss: 0.599022\n",
      "epoch 82; iter: 0; batch classifier loss: 0.453607; batch adversarial loss: 0.608329\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398434; batch adversarial loss: 0.626475\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388197; batch adversarial loss: 0.589626\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433533; batch adversarial loss: 0.460751\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389453; batch adversarial loss: 0.533562\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429760; batch adversarial loss: 0.488867\n",
      "epoch 88; iter: 0; batch classifier loss: 0.474745; batch adversarial loss: 0.537039\n",
      "epoch 89; iter: 0; batch classifier loss: 0.359970; batch adversarial loss: 0.517685\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393928; batch adversarial loss: 0.515769\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362991; batch adversarial loss: 0.505003\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393514; batch adversarial loss: 0.515701\n",
      "epoch 93; iter: 0; batch classifier loss: 0.279278; batch adversarial loss: 0.553667\n",
      "epoch 94; iter: 0; batch classifier loss: 0.302713; batch adversarial loss: 0.563611\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424767; batch adversarial loss: 0.570140\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396403; batch adversarial loss: 0.588946\n",
      "epoch 97; iter: 0; batch classifier loss: 0.317067; batch adversarial loss: 0.554458\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398703; batch adversarial loss: 0.578644\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366908; batch adversarial loss: 0.610597\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361909; batch adversarial loss: 0.508029\n",
      "epoch 101; iter: 0; batch classifier loss: 0.373764; batch adversarial loss: 0.543493\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416640; batch adversarial loss: 0.503755\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407145; batch adversarial loss: 0.608080\n",
      "epoch 104; iter: 0; batch classifier loss: 0.426382; batch adversarial loss: 0.526196\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388393; batch adversarial loss: 0.568929\n",
      "epoch 106; iter: 0; batch classifier loss: 0.357253; batch adversarial loss: 0.526313\n",
      "epoch 107; iter: 0; batch classifier loss: 0.447869; batch adversarial loss: 0.579389\n",
      "epoch 108; iter: 0; batch classifier loss: 0.358755; batch adversarial loss: 0.599101\n",
      "epoch 109; iter: 0; batch classifier loss: 0.336767; batch adversarial loss: 0.597515\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369141; batch adversarial loss: 0.525371\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412863; batch adversarial loss: 0.441650\n",
      "epoch 112; iter: 0; batch classifier loss: 0.322148; batch adversarial loss: 0.546045\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418072; batch adversarial loss: 0.497566\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350579; batch adversarial loss: 0.497152\n",
      "epoch 115; iter: 0; batch classifier loss: 0.377499; batch adversarial loss: 0.600972\n",
      "epoch 116; iter: 0; batch classifier loss: 0.324602; batch adversarial loss: 0.508698\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350922; batch adversarial loss: 0.581160\n",
      "epoch 118; iter: 0; batch classifier loss: 0.332700; batch adversarial loss: 0.517011\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367552; batch adversarial loss: 0.561971\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375963; batch adversarial loss: 0.524928\n",
      "epoch 121; iter: 0; batch classifier loss: 0.426368; batch adversarial loss: 0.546112\n",
      "epoch 122; iter: 0; batch classifier loss: 0.444882; batch adversarial loss: 0.553366\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360173; batch adversarial loss: 0.550943\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374910; batch adversarial loss: 0.494585\n",
      "epoch 125; iter: 0; batch classifier loss: 0.317914; batch adversarial loss: 0.488368\n",
      "epoch 126; iter: 0; batch classifier loss: 0.431305; batch adversarial loss: 0.463429\n",
      "epoch 127; iter: 0; batch classifier loss: 0.305416; batch adversarial loss: 0.476601\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313071; batch adversarial loss: 0.526226\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377711; batch adversarial loss: 0.608483\n",
      "epoch 130; iter: 0; batch classifier loss: 0.446672; batch adversarial loss: 0.517645\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371156; batch adversarial loss: 0.619729\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421391; batch adversarial loss: 0.562611\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326878; batch adversarial loss: 0.584889\n",
      "epoch 134; iter: 0; batch classifier loss: 0.413458; batch adversarial loss: 0.471137\n",
      "epoch 135; iter: 0; batch classifier loss: 0.470556; batch adversarial loss: 0.496962\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393996; batch adversarial loss: 0.508041\n",
      "epoch 137; iter: 0; batch classifier loss: 0.339723; batch adversarial loss: 0.642016\n",
      "epoch 138; iter: 0; batch classifier loss: 0.459820; batch adversarial loss: 0.568701\n",
      "epoch 139; iter: 0; batch classifier loss: 0.439408; batch adversarial loss: 0.577622\n",
      "epoch 140; iter: 0; batch classifier loss: 0.353995; batch adversarial loss: 0.473050\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344164; batch adversarial loss: 0.509155\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383335; batch adversarial loss: 0.578683\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368703; batch adversarial loss: 0.551866\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396836; batch adversarial loss: 0.540853\n",
      "epoch 145; iter: 0; batch classifier loss: 0.304540; batch adversarial loss: 0.479532\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368006; batch adversarial loss: 0.527686\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391636; batch adversarial loss: 0.570814\n",
      "epoch 148; iter: 0; batch classifier loss: 0.369488; batch adversarial loss: 0.510589\n",
      "epoch 149; iter: 0; batch classifier loss: 0.318971; batch adversarial loss: 0.563337\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364177; batch adversarial loss: 0.509585\n",
      "epoch 151; iter: 0; batch classifier loss: 0.311005; batch adversarial loss: 0.498616\n",
      "epoch 152; iter: 0; batch classifier loss: 0.407389; batch adversarial loss: 0.510018\n",
      "epoch 153; iter: 0; batch classifier loss: 0.460797; batch adversarial loss: 0.499743\n",
      "epoch 154; iter: 0; batch classifier loss: 0.322890; batch adversarial loss: 0.514395\n",
      "epoch 155; iter: 0; batch classifier loss: 0.403002; batch adversarial loss: 0.603031\n",
      "epoch 156; iter: 0; batch classifier loss: 0.342416; batch adversarial loss: 0.558879\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326565; batch adversarial loss: 0.562338\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337512; batch adversarial loss: 0.547698\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415311; batch adversarial loss: 0.560310\n",
      "epoch 160; iter: 0; batch classifier loss: 0.334937; batch adversarial loss: 0.478794\n",
      "epoch 161; iter: 0; batch classifier loss: 0.360583; batch adversarial loss: 0.508749\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382409; batch adversarial loss: 0.480392\n",
      "epoch 163; iter: 0; batch classifier loss: 0.370080; batch adversarial loss: 0.559244\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362153; batch adversarial loss: 0.536699\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344259; batch adversarial loss: 0.538179\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374359; batch adversarial loss: 0.496702\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363381; batch adversarial loss: 0.564424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.346104; batch adversarial loss: 0.478663\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341412; batch adversarial loss: 0.513630\n",
      "epoch 170; iter: 0; batch classifier loss: 0.348370; batch adversarial loss: 0.589075\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382485; batch adversarial loss: 0.574171\n",
      "epoch 172; iter: 0; batch classifier loss: 0.297648; batch adversarial loss: 0.541473\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342011; batch adversarial loss: 0.562646\n",
      "epoch 174; iter: 0; batch classifier loss: 0.386427; batch adversarial loss: 0.541493\n",
      "epoch 175; iter: 0; batch classifier loss: 0.404697; batch adversarial loss: 0.534602\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328949; batch adversarial loss: 0.568936\n",
      "epoch 177; iter: 0; batch classifier loss: 0.353524; batch adversarial loss: 0.533720\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368075; batch adversarial loss: 0.589617\n",
      "epoch 179; iter: 0; batch classifier loss: 0.280373; batch adversarial loss: 0.497770\n",
      "epoch 180; iter: 0; batch classifier loss: 0.273607; batch adversarial loss: 0.657608\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370364; batch adversarial loss: 0.525093\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341024; batch adversarial loss: 0.532184\n",
      "epoch 183; iter: 0; batch classifier loss: 0.414767; batch adversarial loss: 0.570721\n",
      "epoch 184; iter: 0; batch classifier loss: 0.368858; batch adversarial loss: 0.543748\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320579; batch adversarial loss: 0.536682\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389826; batch adversarial loss: 0.481012\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357881; batch adversarial loss: 0.542767\n",
      "epoch 188; iter: 0; batch classifier loss: 0.303587; batch adversarial loss: 0.584615\n",
      "epoch 189; iter: 0; batch classifier loss: 0.329108; batch adversarial loss: 0.478123\n",
      "epoch 190; iter: 0; batch classifier loss: 0.279510; batch adversarial loss: 0.555170\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336172; batch adversarial loss: 0.553779\n",
      "epoch 192; iter: 0; batch classifier loss: 0.269898; batch adversarial loss: 0.589059\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316947; batch adversarial loss: 0.506100\n",
      "epoch 194; iter: 0; batch classifier loss: 0.288030; batch adversarial loss: 0.543543\n",
      "epoch 195; iter: 0; batch classifier loss: 0.364965; batch adversarial loss: 0.554732\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327413; batch adversarial loss: 0.536379\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320938; batch adversarial loss: 0.579309\n",
      "epoch 198; iter: 0; batch classifier loss: 0.364956; batch adversarial loss: 0.628610\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345050; batch adversarial loss: 0.509180\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670345; batch adversarial loss: 0.828729\n",
      "epoch 1; iter: 0; batch classifier loss: 0.856225; batch adversarial loss: 0.876703\n",
      "epoch 2; iter: 0; batch classifier loss: 0.923801; batch adversarial loss: 0.823375\n",
      "epoch 3; iter: 0; batch classifier loss: 1.001998; batch adversarial loss: 0.760729\n",
      "epoch 4; iter: 0; batch classifier loss: 0.816622; batch adversarial loss: 0.687807\n",
      "epoch 5; iter: 0; batch classifier loss: 0.659496; batch adversarial loss: 0.641119\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605589; batch adversarial loss: 0.598572\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563021; batch adversarial loss: 0.604091\n",
      "epoch 8; iter: 0; batch classifier loss: 0.591650; batch adversarial loss: 0.599270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524247; batch adversarial loss: 0.594872\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537111; batch adversarial loss: 0.581844\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563366; batch adversarial loss: 0.611600\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542219; batch adversarial loss: 0.575176\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554094; batch adversarial loss: 0.564414\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545403; batch adversarial loss: 0.560035\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524162; batch adversarial loss: 0.536284\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519598; batch adversarial loss: 0.565700\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495226; batch adversarial loss: 0.567077\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509473; batch adversarial loss: 0.565547\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480898; batch adversarial loss: 0.529602\n",
      "epoch 20; iter: 0; batch classifier loss: 0.481212; batch adversarial loss: 0.553514\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452186; batch adversarial loss: 0.536214\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473754; batch adversarial loss: 0.598967\n",
      "epoch 23; iter: 0; batch classifier loss: 0.410375; batch adversarial loss: 0.607442\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471634; batch adversarial loss: 0.538543\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451212; batch adversarial loss: 0.546740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472194; batch adversarial loss: 0.588801\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484379; batch adversarial loss: 0.600574\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421753; batch adversarial loss: 0.567947\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534519; batch adversarial loss: 0.549897\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441394; batch adversarial loss: 0.583384\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439186; batch adversarial loss: 0.548489\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472218; batch adversarial loss: 0.532603\n",
      "epoch 33; iter: 0; batch classifier loss: 0.418537; batch adversarial loss: 0.476261\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443992; batch adversarial loss: 0.552127\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468306; batch adversarial loss: 0.531448\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422262; batch adversarial loss: 0.519905\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456420; batch adversarial loss: 0.527237\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454065; batch adversarial loss: 0.554131\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497770; batch adversarial loss: 0.538261\n",
      "epoch 40; iter: 0; batch classifier loss: 0.414022; batch adversarial loss: 0.544527\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449329; batch adversarial loss: 0.532774\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444318; batch adversarial loss: 0.505310\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426830; batch adversarial loss: 0.566751\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441179; batch adversarial loss: 0.594711\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429389; batch adversarial loss: 0.600188\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423254; batch adversarial loss: 0.599981\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466330; batch adversarial loss: 0.585953\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412534; batch adversarial loss: 0.560458\n",
      "epoch 49; iter: 0; batch classifier loss: 0.492857; batch adversarial loss: 0.506900\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431847; batch adversarial loss: 0.514604\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449059; batch adversarial loss: 0.543292\n",
      "epoch 52; iter: 0; batch classifier loss: 0.366251; batch adversarial loss: 0.552468\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402986; batch adversarial loss: 0.554863\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427907; batch adversarial loss: 0.491110\n",
      "epoch 55; iter: 0; batch classifier loss: 0.438355; batch adversarial loss: 0.562593\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389485; batch adversarial loss: 0.526780\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414295; batch adversarial loss: 0.544644\n",
      "epoch 58; iter: 0; batch classifier loss: 0.519341; batch adversarial loss: 0.563698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419339; batch adversarial loss: 0.489456\n",
      "epoch 60; iter: 0; batch classifier loss: 0.413028; batch adversarial loss: 0.627883\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420128; batch adversarial loss: 0.600354\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415103; batch adversarial loss: 0.535801\n",
      "epoch 63; iter: 0; batch classifier loss: 0.366054; batch adversarial loss: 0.516671\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386853; batch adversarial loss: 0.507868\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451936; batch adversarial loss: 0.507855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.390311; batch adversarial loss: 0.516905\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411412; batch adversarial loss: 0.562877\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392279; batch adversarial loss: 0.581894\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387582; batch adversarial loss: 0.498123\n",
      "epoch 70; iter: 0; batch classifier loss: 0.457048; batch adversarial loss: 0.516672\n",
      "epoch 71; iter: 0; batch classifier loss: 0.350679; batch adversarial loss: 0.535575\n",
      "epoch 72; iter: 0; batch classifier loss: 0.369676; batch adversarial loss: 0.460596\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410868; batch adversarial loss: 0.516503\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378664; batch adversarial loss: 0.535016\n",
      "epoch 75; iter: 0; batch classifier loss: 0.332074; batch adversarial loss: 0.571852\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371549; batch adversarial loss: 0.591449\n",
      "epoch 77; iter: 0; batch classifier loss: 0.357374; batch adversarial loss: 0.572334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391115; batch adversarial loss: 0.544814\n",
      "epoch 79; iter: 0; batch classifier loss: 0.441273; batch adversarial loss: 0.535956\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369163; batch adversarial loss: 0.572563\n",
      "epoch 81; iter: 0; batch classifier loss: 0.353033; batch adversarial loss: 0.536405\n",
      "epoch 82; iter: 0; batch classifier loss: 0.460989; batch adversarial loss: 0.591031\n",
      "epoch 83; iter: 0; batch classifier loss: 0.348300; batch adversarial loss: 0.544238\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409644; batch adversarial loss: 0.526007\n",
      "epoch 85; iter: 0; batch classifier loss: 0.312105; batch adversarial loss: 0.544451\n",
      "epoch 86; iter: 0; batch classifier loss: 0.305515; batch adversarial loss: 0.507373\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347182; batch adversarial loss: 0.535197\n",
      "epoch 88; iter: 0; batch classifier loss: 0.303615; batch adversarial loss: 0.525964\n",
      "epoch 89; iter: 0; batch classifier loss: 0.316109; batch adversarial loss: 0.516349\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412038; batch adversarial loss: 0.497403\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375136; batch adversarial loss: 0.525407\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389247; batch adversarial loss: 0.591474\n",
      "epoch 93; iter: 0; batch classifier loss: 0.428060; batch adversarial loss: 0.535684\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374351; batch adversarial loss: 0.534790\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381064; batch adversarial loss: 0.544558\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349250; batch adversarial loss: 0.554104\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379043; batch adversarial loss: 0.545443\n",
      "epoch 98; iter: 0; batch classifier loss: 0.430541; batch adversarial loss: 0.488032\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395205; batch adversarial loss: 0.553361\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346385; batch adversarial loss: 0.581895\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402474; batch adversarial loss: 0.470371\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331572; batch adversarial loss: 0.507133\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358675; batch adversarial loss: 0.545609\n",
      "epoch 104; iter: 0; batch classifier loss: 0.316249; batch adversarial loss: 0.487199\n",
      "epoch 105; iter: 0; batch classifier loss: 0.353149; batch adversarial loss: 0.535729\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409442; batch adversarial loss: 0.488517\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363709; batch adversarial loss: 0.497231\n",
      "epoch 108; iter: 0; batch classifier loss: 0.360130; batch adversarial loss: 0.536459\n",
      "epoch 109; iter: 0; batch classifier loss: 0.327754; batch adversarial loss: 0.572901\n",
      "epoch 110; iter: 0; batch classifier loss: 0.428367; batch adversarial loss: 0.516926\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386881; batch adversarial loss: 0.487774\n",
      "epoch 112; iter: 0; batch classifier loss: 0.305087; batch adversarial loss: 0.565036\n",
      "epoch 113; iter: 0; batch classifier loss: 0.408821; batch adversarial loss: 0.508479\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359514; batch adversarial loss: 0.478594\n",
      "epoch 115; iter: 0; batch classifier loss: 0.321192; batch adversarial loss: 0.543450\n",
      "epoch 116; iter: 0; batch classifier loss: 0.378662; batch adversarial loss: 0.536439\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370258; batch adversarial loss: 0.527417\n",
      "epoch 118; iter: 0; batch classifier loss: 0.306740; batch adversarial loss: 0.515938\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353586; batch adversarial loss: 0.535603\n",
      "epoch 120; iter: 0; batch classifier loss: 0.327546; batch adversarial loss: 0.525796\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355453; batch adversarial loss: 0.534048\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368959; batch adversarial loss: 0.553677\n",
      "epoch 123; iter: 0; batch classifier loss: 0.330246; batch adversarial loss: 0.515940\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340607; batch adversarial loss: 0.533228\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409543; batch adversarial loss: 0.582673\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406852; batch adversarial loss: 0.562620\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374141; batch adversarial loss: 0.591447\n",
      "epoch 128; iter: 0; batch classifier loss: 0.386256; batch adversarial loss: 0.544480\n",
      "epoch 129; iter: 0; batch classifier loss: 0.417263; batch adversarial loss: 0.469642\n",
      "epoch 130; iter: 0; batch classifier loss: 0.267690; batch adversarial loss: 0.589943\n",
      "epoch 131; iter: 0; batch classifier loss: 0.369100; batch adversarial loss: 0.471007\n",
      "epoch 132; iter: 0; batch classifier loss: 0.322242; batch adversarial loss: 0.619375\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334746; batch adversarial loss: 0.507508\n",
      "epoch 134; iter: 0; batch classifier loss: 0.409524; batch adversarial loss: 0.534221\n",
      "epoch 135; iter: 0; batch classifier loss: 0.453339; batch adversarial loss: 0.536278\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395400; batch adversarial loss: 0.525971\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359188; batch adversarial loss: 0.543946\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348509; batch adversarial loss: 0.544213\n",
      "epoch 139; iter: 0; batch classifier loss: 0.394711; batch adversarial loss: 0.526761\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391811; batch adversarial loss: 0.460754\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350335; batch adversarial loss: 0.487783\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326249; batch adversarial loss: 0.431643\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383683; batch adversarial loss: 0.571008\n",
      "epoch 144; iter: 0; batch classifier loss: 0.436883; batch adversarial loss: 0.516160\n",
      "epoch 145; iter: 0; batch classifier loss: 0.389347; batch adversarial loss: 0.581426\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380494; batch adversarial loss: 0.545505\n",
      "epoch 147; iter: 0; batch classifier loss: 0.395133; batch adversarial loss: 0.572236\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328816; batch adversarial loss: 0.618702\n",
      "epoch 149; iter: 0; batch classifier loss: 0.306097; batch adversarial loss: 0.525250\n",
      "epoch 150; iter: 0; batch classifier loss: 0.406179; batch adversarial loss: 0.525246\n",
      "epoch 151; iter: 0; batch classifier loss: 0.419019; batch adversarial loss: 0.629198\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397915; batch adversarial loss: 0.608952\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356769; batch adversarial loss: 0.526276\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372375; batch adversarial loss: 0.488638\n",
      "epoch 155; iter: 0; batch classifier loss: 0.333535; batch adversarial loss: 0.563433\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349640; batch adversarial loss: 0.496774\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333710; batch adversarial loss: 0.545521\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380711; batch adversarial loss: 0.535380\n",
      "epoch 159; iter: 0; batch classifier loss: 0.364646; batch adversarial loss: 0.562448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.313480; batch adversarial loss: 0.534909\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329390; batch adversarial loss: 0.573082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.330108; batch adversarial loss: 0.590417\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350358; batch adversarial loss: 0.460189\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356404; batch adversarial loss: 0.582700\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345958; batch adversarial loss: 0.563408\n",
      "epoch 166; iter: 0; batch classifier loss: 0.329730; batch adversarial loss: 0.582421\n",
      "epoch 167; iter: 0; batch classifier loss: 0.305368; batch adversarial loss: 0.507742\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395544; batch adversarial loss: 0.470612\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367041; batch adversarial loss: 0.506383\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342323; batch adversarial loss: 0.564823\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396552; batch adversarial loss: 0.564597\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381732; batch adversarial loss: 0.544099\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301875; batch adversarial loss: 0.619032\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381824; batch adversarial loss: 0.591602\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395725; batch adversarial loss: 0.545618\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362032; batch adversarial loss: 0.506475\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387350; batch adversarial loss: 0.478792\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372628; batch adversarial loss: 0.543697\n",
      "epoch 179; iter: 0; batch classifier loss: 0.304137; batch adversarial loss: 0.506655\n",
      "epoch 180; iter: 0; batch classifier loss: 0.384791; batch adversarial loss: 0.582273\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362194; batch adversarial loss: 0.507165\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371843; batch adversarial loss: 0.534944\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371548; batch adversarial loss: 0.639167\n",
      "epoch 184; iter: 0; batch classifier loss: 0.419554; batch adversarial loss: 0.610396\n",
      "epoch 185; iter: 0; batch classifier loss: 0.343295; batch adversarial loss: 0.545283\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326546; batch adversarial loss: 0.582532\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373864; batch adversarial loss: 0.535235\n",
      "epoch 188; iter: 0; batch classifier loss: 0.303612; batch adversarial loss: 0.525807\n",
      "epoch 189; iter: 0; batch classifier loss: 0.376275; batch adversarial loss: 0.527511\n",
      "epoch 190; iter: 0; batch classifier loss: 0.320578; batch adversarial loss: 0.506730\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331304; batch adversarial loss: 0.553452\n",
      "epoch 192; iter: 0; batch classifier loss: 0.292741; batch adversarial loss: 0.545366\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300168; batch adversarial loss: 0.564130\n",
      "epoch 194; iter: 0; batch classifier loss: 0.283012; batch adversarial loss: 0.545291\n",
      "epoch 195; iter: 0; batch classifier loss: 0.369964; batch adversarial loss: 0.506115\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332617; batch adversarial loss: 0.546014\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367737; batch adversarial loss: 0.544474\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333400; batch adversarial loss: 0.516253\n",
      "epoch 199; iter: 0; batch classifier loss: 0.428753; batch adversarial loss: 0.544187\n",
      "epoch 0; iter: 0; batch classifier loss: 0.653297; batch adversarial loss: 0.740211\n",
      "epoch 1; iter: 0; batch classifier loss: 0.706870; batch adversarial loss: 0.746235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.675665; batch adversarial loss: 0.688400\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579166; batch adversarial loss: 0.647960\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565224; batch adversarial loss: 0.645335\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571512; batch adversarial loss: 0.627519\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571534; batch adversarial loss: 0.640038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541910; batch adversarial loss: 0.623402\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553865; batch adversarial loss: 0.620835\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529200; batch adversarial loss: 0.615493\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502060; batch adversarial loss: 0.555356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529496; batch adversarial loss: 0.533664\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526696; batch adversarial loss: 0.605340\n",
      "epoch 13; iter: 0; batch classifier loss: 0.442565; batch adversarial loss: 0.584294\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466396; batch adversarial loss: 0.559416\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555650; batch adversarial loss: 0.564371\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450280; batch adversarial loss: 0.511188\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516335; batch adversarial loss: 0.546473\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530933; batch adversarial loss: 0.611426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465712; batch adversarial loss: 0.590581\n",
      "epoch 20; iter: 0; batch classifier loss: 0.566970; batch adversarial loss: 0.622345\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530112; batch adversarial loss: 0.488427\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526217; batch adversarial loss: 0.603149\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493679; batch adversarial loss: 0.589810\n",
      "epoch 24; iter: 0; batch classifier loss: 0.539121; batch adversarial loss: 0.505498\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472109; batch adversarial loss: 0.559075\n",
      "epoch 26; iter: 0; batch classifier loss: 0.423465; batch adversarial loss: 0.489476\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518080; batch adversarial loss: 0.561456\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477476; batch adversarial loss: 0.578156\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510346; batch adversarial loss: 0.498875\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430346; batch adversarial loss: 0.521274\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495796; batch adversarial loss: 0.487212\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443909; batch adversarial loss: 0.608351\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474974; batch adversarial loss: 0.528569\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480107; batch adversarial loss: 0.618386\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511020; batch adversarial loss: 0.528397\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492437; batch adversarial loss: 0.484786\n",
      "epoch 37; iter: 0; batch classifier loss: 0.514158; batch adversarial loss: 0.438350\n",
      "epoch 38; iter: 0; batch classifier loss: 0.489234; batch adversarial loss: 0.547869\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405013; batch adversarial loss: 0.580239\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477843; batch adversarial loss: 0.534449\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419344; batch adversarial loss: 0.525618\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433220; batch adversarial loss: 0.588506\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427002; batch adversarial loss: 0.517785\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419126; batch adversarial loss: 0.493025\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478256; batch adversarial loss: 0.544416\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400262; batch adversarial loss: 0.615343\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471293; batch adversarial loss: 0.580235\n",
      "epoch 48; iter: 0; batch classifier loss: 0.527520; batch adversarial loss: 0.669204\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384234; batch adversarial loss: 0.553235\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449767; batch adversarial loss: 0.526599\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440628; batch adversarial loss: 0.491577\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466660; batch adversarial loss: 0.589047\n",
      "epoch 53; iter: 0; batch classifier loss: 0.368840; batch adversarial loss: 0.607697\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420505; batch adversarial loss: 0.571708\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397883; batch adversarial loss: 0.625977\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423063; batch adversarial loss: 0.517471\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437516; batch adversarial loss: 0.517317\n",
      "epoch 58; iter: 0; batch classifier loss: 0.369696; batch adversarial loss: 0.590496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.397374; batch adversarial loss: 0.544431\n",
      "epoch 60; iter: 0; batch classifier loss: 0.399568; batch adversarial loss: 0.526158\n",
      "epoch 61; iter: 0; batch classifier loss: 0.374825; batch adversarial loss: 0.598016\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451860; batch adversarial loss: 0.562651\n",
      "epoch 63; iter: 0; batch classifier loss: 0.366801; batch adversarial loss: 0.571705\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361368; batch adversarial loss: 0.624206\n",
      "epoch 65; iter: 0; batch classifier loss: 0.465845; batch adversarial loss: 0.464974\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406052; batch adversarial loss: 0.562997\n",
      "epoch 67; iter: 0; batch classifier loss: 0.480494; batch adversarial loss: 0.560736\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411038; batch adversarial loss: 0.598559\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415682; batch adversarial loss: 0.589605\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343111; batch adversarial loss: 0.516941\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394175; batch adversarial loss: 0.527374\n",
      "epoch 72; iter: 0; batch classifier loss: 0.460249; batch adversarial loss: 0.545045\n",
      "epoch 73; iter: 0; batch classifier loss: 0.521775; batch adversarial loss: 0.490075\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396161; batch adversarial loss: 0.507829\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441280; batch adversarial loss: 0.544500\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414030; batch adversarial loss: 0.508994\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385594; batch adversarial loss: 0.589822\n",
      "epoch 78; iter: 0; batch classifier loss: 0.516423; batch adversarial loss: 0.545312\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373693; batch adversarial loss: 0.472103\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389986; batch adversarial loss: 0.617269\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382350; batch adversarial loss: 0.562074\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414708; batch adversarial loss: 0.489945\n",
      "epoch 83; iter: 0; batch classifier loss: 0.431260; batch adversarial loss: 0.571376\n",
      "epoch 84; iter: 0; batch classifier loss: 0.424394; batch adversarial loss: 0.588089\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346592; batch adversarial loss: 0.472494\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407074; batch adversarial loss: 0.588448\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368544; batch adversarial loss: 0.463572\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363478; batch adversarial loss: 0.614923\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411604; batch adversarial loss: 0.499196\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393577; batch adversarial loss: 0.525970\n",
      "epoch 91; iter: 0; batch classifier loss: 0.378844; batch adversarial loss: 0.526099\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432133; batch adversarial loss: 0.491034\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384928; batch adversarial loss: 0.437322\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402214; batch adversarial loss: 0.481519\n",
      "epoch 95; iter: 0; batch classifier loss: 0.494207; batch adversarial loss: 0.562061\n",
      "epoch 96; iter: 0; batch classifier loss: 0.515973; batch adversarial loss: 0.553356\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390998; batch adversarial loss: 0.572097\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409860; batch adversarial loss: 0.508072\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356381; batch adversarial loss: 0.553840\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357267; batch adversarial loss: 0.561968\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352195; batch adversarial loss: 0.651254\n",
      "epoch 102; iter: 0; batch classifier loss: 0.313729; batch adversarial loss: 0.571263\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382480; batch adversarial loss: 0.561317\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368295; batch adversarial loss: 0.599814\n",
      "epoch 105; iter: 0; batch classifier loss: 0.422570; batch adversarial loss: 0.589824\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434521; batch adversarial loss: 0.562589\n",
      "epoch 107; iter: 0; batch classifier loss: 0.290005; batch adversarial loss: 0.571320\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357376; batch adversarial loss: 0.598705\n",
      "epoch 109; iter: 0; batch classifier loss: 0.466163; batch adversarial loss: 0.616650\n",
      "epoch 110; iter: 0; batch classifier loss: 0.355335; batch adversarial loss: 0.535979\n",
      "epoch 111; iter: 0; batch classifier loss: 0.434418; batch adversarial loss: 0.589542\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387962; batch adversarial loss: 0.508810\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400557; batch adversarial loss: 0.590168\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357182; batch adversarial loss: 0.562928\n",
      "epoch 115; iter: 0; batch classifier loss: 0.400204; batch adversarial loss: 0.562817\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417759; batch adversarial loss: 0.527475\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382790; batch adversarial loss: 0.472911\n",
      "epoch 118; iter: 0; batch classifier loss: 0.359874; batch adversarial loss: 0.508555\n",
      "epoch 119; iter: 0; batch classifier loss: 0.422903; batch adversarial loss: 0.544664\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372425; batch adversarial loss: 0.544219\n",
      "epoch 121; iter: 0; batch classifier loss: 0.450447; batch adversarial loss: 0.490572\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391841; batch adversarial loss: 0.516929\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367149; batch adversarial loss: 0.508720\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371871; batch adversarial loss: 0.562938\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342244; batch adversarial loss: 0.499550\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387701; batch adversarial loss: 0.563343\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365427; batch adversarial loss: 0.580984\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357360; batch adversarial loss: 0.526539\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364840; batch adversarial loss: 0.599390\n",
      "epoch 130; iter: 0; batch classifier loss: 0.450493; batch adversarial loss: 0.507680\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363004; batch adversarial loss: 0.544793\n",
      "epoch 132; iter: 0; batch classifier loss: 0.393955; batch adversarial loss: 0.509007\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350374; batch adversarial loss: 0.526815\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357300; batch adversarial loss: 0.527281\n",
      "epoch 135; iter: 0; batch classifier loss: 0.312348; batch adversarial loss: 0.543934\n",
      "epoch 136; iter: 0; batch classifier loss: 0.422051; batch adversarial loss: 0.527153\n",
      "epoch 137; iter: 0; batch classifier loss: 0.355725; batch adversarial loss: 0.545346\n",
      "epoch 138; iter: 0; batch classifier loss: 0.390155; batch adversarial loss: 0.517442\n",
      "epoch 139; iter: 0; batch classifier loss: 0.327376; batch adversarial loss: 0.445572\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376161; batch adversarial loss: 0.490305\n",
      "epoch 141; iter: 0; batch classifier loss: 0.432696; batch adversarial loss: 0.571730\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369439; batch adversarial loss: 0.480844\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363364; batch adversarial loss: 0.481547\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350012; batch adversarial loss: 0.572004\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377495; batch adversarial loss: 0.552586\n",
      "epoch 146; iter: 0; batch classifier loss: 0.424097; batch adversarial loss: 0.571807\n",
      "epoch 147; iter: 0; batch classifier loss: 0.380349; batch adversarial loss: 0.571052\n",
      "epoch 148; iter: 0; batch classifier loss: 0.416994; batch adversarial loss: 0.553867\n",
      "epoch 149; iter: 0; batch classifier loss: 0.442097; batch adversarial loss: 0.580125\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350756; batch adversarial loss: 0.544556\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408398; batch adversarial loss: 0.563125\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383898; batch adversarial loss: 0.508651\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383118; batch adversarial loss: 0.552299\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349337; batch adversarial loss: 0.635285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.420686; batch adversarial loss: 0.572146\n",
      "epoch 156; iter: 0; batch classifier loss: 0.414162; batch adversarial loss: 0.553549\n",
      "epoch 157; iter: 0; batch classifier loss: 0.414330; batch adversarial loss: 0.580548\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382736; batch adversarial loss: 0.499986\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369559; batch adversarial loss: 0.517751\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375350; batch adversarial loss: 0.572394\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375296; batch adversarial loss: 0.481454\n",
      "epoch 162; iter: 0; batch classifier loss: 0.303080; batch adversarial loss: 0.616767\n",
      "epoch 163; iter: 0; batch classifier loss: 0.275522; batch adversarial loss: 0.553979\n",
      "epoch 164; iter: 0; batch classifier loss: 0.443149; batch adversarial loss: 0.562027\n",
      "epoch 165; iter: 0; batch classifier loss: 0.317012; batch adversarial loss: 0.570798\n",
      "epoch 166; iter: 0; batch classifier loss: 0.400386; batch adversarial loss: 0.544687\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334213; batch adversarial loss: 0.633732\n",
      "epoch 168; iter: 0; batch classifier loss: 0.428853; batch adversarial loss: 0.598465\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370454; batch adversarial loss: 0.517900\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349926; batch adversarial loss: 0.607200\n",
      "epoch 171; iter: 0; batch classifier loss: 0.386404; batch adversarial loss: 0.634810\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372996; batch adversarial loss: 0.625014\n",
      "epoch 173; iter: 0; batch classifier loss: 0.389033; batch adversarial loss: 0.462795\n",
      "epoch 174; iter: 0; batch classifier loss: 0.367841; batch adversarial loss: 0.518009\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322194; batch adversarial loss: 0.516707\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378616; batch adversarial loss: 0.462773\n",
      "epoch 177; iter: 0; batch classifier loss: 0.415772; batch adversarial loss: 0.527253\n",
      "epoch 178; iter: 0; batch classifier loss: 0.435894; batch adversarial loss: 0.580369\n",
      "epoch 179; iter: 0; batch classifier loss: 0.331701; batch adversarial loss: 0.599202\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389412; batch adversarial loss: 0.607673\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361130; batch adversarial loss: 0.581557\n",
      "epoch 182; iter: 0; batch classifier loss: 0.401867; batch adversarial loss: 0.580968\n",
      "epoch 183; iter: 0; batch classifier loss: 0.390351; batch adversarial loss: 0.526743\n",
      "epoch 184; iter: 0; batch classifier loss: 0.436429; batch adversarial loss: 0.527023\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326329; batch adversarial loss: 0.606090\n",
      "epoch 186; iter: 0; batch classifier loss: 0.415209; batch adversarial loss: 0.553697\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374744; batch adversarial loss: 0.544510\n",
      "epoch 188; iter: 0; batch classifier loss: 0.444246; batch adversarial loss: 0.580128\n",
      "epoch 189; iter: 0; batch classifier loss: 0.321010; batch adversarial loss: 0.527526\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391588; batch adversarial loss: 0.472649\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320081; batch adversarial loss: 0.527173\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358918; batch adversarial loss: 0.517928\n",
      "epoch 193; iter: 0; batch classifier loss: 0.354429; batch adversarial loss: 0.562649\n",
      "epoch 194; iter: 0; batch classifier loss: 0.410399; batch adversarial loss: 0.427396\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397221; batch adversarial loss: 0.589415\n",
      "epoch 196; iter: 0; batch classifier loss: 0.401103; batch adversarial loss: 0.589683\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372988; batch adversarial loss: 0.589431\n",
      "epoch 198; iter: 0; batch classifier loss: 0.315081; batch adversarial loss: 0.571534\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323961; batch adversarial loss: 0.571381\n",
      "epoch 0; iter: 0; batch classifier loss: 0.743454; batch adversarial loss: 0.774773\n",
      "epoch 1; iter: 0; batch classifier loss: 0.708027; batch adversarial loss: 0.733283\n",
      "epoch 2; iter: 0; batch classifier loss: 0.726850; batch adversarial loss: 0.688868\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579396; batch adversarial loss: 0.652163\n",
      "epoch 4; iter: 0; batch classifier loss: 0.611000; batch adversarial loss: 0.631567\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552011; batch adversarial loss: 0.642576\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519453; batch adversarial loss: 0.606961\n",
      "epoch 7; iter: 0; batch classifier loss: 0.628591; batch adversarial loss: 0.610635\n",
      "epoch 8; iter: 0; batch classifier loss: 0.492450; batch adversarial loss: 0.600893\n",
      "epoch 9; iter: 0; batch classifier loss: 0.606468; batch adversarial loss: 0.577312\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502644; batch adversarial loss: 0.557342\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508004; batch adversarial loss: 0.579220\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540872; batch adversarial loss: 0.559954\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497845; batch adversarial loss: 0.594552\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524491; batch adversarial loss: 0.559774\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541111; batch adversarial loss: 0.576130\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511416; batch adversarial loss: 0.527938\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487720; batch adversarial loss: 0.591645\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488151; batch adversarial loss: 0.502077\n",
      "epoch 19; iter: 0; batch classifier loss: 0.431910; batch adversarial loss: 0.577050\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449230; batch adversarial loss: 0.547490\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476200; batch adversarial loss: 0.544654\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464115; batch adversarial loss: 0.528674\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481788; batch adversarial loss: 0.474592\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484847; batch adversarial loss: 0.603741\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526695; batch adversarial loss: 0.612462\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458317; batch adversarial loss: 0.588369\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425522; batch adversarial loss: 0.523476\n",
      "epoch 28; iter: 0; batch classifier loss: 0.501649; batch adversarial loss: 0.480310\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480875; batch adversarial loss: 0.572490\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470054; batch adversarial loss: 0.577804\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483773; batch adversarial loss: 0.581072\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529061; batch adversarial loss: 0.587763\n",
      "epoch 33; iter: 0; batch classifier loss: 0.538411; batch adversarial loss: 0.605256\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451667; batch adversarial loss: 0.605043\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432976; batch adversarial loss: 0.605240\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497104; batch adversarial loss: 0.519713\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455037; batch adversarial loss: 0.476325\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455539; batch adversarial loss: 0.588373\n",
      "epoch 39; iter: 0; batch classifier loss: 0.524632; batch adversarial loss: 0.597228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.382116; batch adversarial loss: 0.492932\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408542; batch adversarial loss: 0.571421\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489047; batch adversarial loss: 0.597487\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398052; batch adversarial loss: 0.579970\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493020; batch adversarial loss: 0.545393\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467876; batch adversarial loss: 0.491392\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443943; batch adversarial loss: 0.562164\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465761; batch adversarial loss: 0.561383\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465636; batch adversarial loss: 0.554114\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432607; batch adversarial loss: 0.578886\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416590; batch adversarial loss: 0.587705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.408201; batch adversarial loss: 0.507175\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429579; batch adversarial loss: 0.569225\n",
      "epoch 53; iter: 0; batch classifier loss: 0.504603; batch adversarial loss: 0.553953\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404037; batch adversarial loss: 0.532482\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423795; batch adversarial loss: 0.585102\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440719; batch adversarial loss: 0.518642\n",
      "epoch 57; iter: 0; batch classifier loss: 0.430651; batch adversarial loss: 0.534058\n",
      "epoch 58; iter: 0; batch classifier loss: 0.449710; batch adversarial loss: 0.522593\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425302; batch adversarial loss: 0.534783\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426123; batch adversarial loss: 0.517015\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444823; batch adversarial loss: 0.615115\n",
      "epoch 62; iter: 0; batch classifier loss: 0.372592; batch adversarial loss: 0.612614\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419059; batch adversarial loss: 0.592535\n",
      "epoch 64; iter: 0; batch classifier loss: 0.473976; batch adversarial loss: 0.562487\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374134; batch adversarial loss: 0.569199\n",
      "epoch 66; iter: 0; batch classifier loss: 0.391757; batch adversarial loss: 0.494600\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444341; batch adversarial loss: 0.517974\n",
      "epoch 68; iter: 0; batch classifier loss: 0.493700; batch adversarial loss: 0.556437\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420017; batch adversarial loss: 0.600031\n",
      "epoch 70; iter: 0; batch classifier loss: 0.378218; batch adversarial loss: 0.508147\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429215; batch adversarial loss: 0.589125\n",
      "epoch 72; iter: 0; batch classifier loss: 0.485875; batch adversarial loss: 0.578380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402080; batch adversarial loss: 0.571285\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356872; batch adversarial loss: 0.545433\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408572; batch adversarial loss: 0.533814\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359639; batch adversarial loss: 0.520120\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374562; batch adversarial loss: 0.591333\n",
      "epoch 78; iter: 0; batch classifier loss: 0.361849; batch adversarial loss: 0.526895\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425481; batch adversarial loss: 0.552024\n",
      "epoch 80; iter: 0; batch classifier loss: 0.405729; batch adversarial loss: 0.517144\n",
      "epoch 81; iter: 0; batch classifier loss: 0.472228; batch adversarial loss: 0.544531\n",
      "epoch 82; iter: 0; batch classifier loss: 0.445811; batch adversarial loss: 0.589744\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371076; batch adversarial loss: 0.553246\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356751; batch adversarial loss: 0.570676\n",
      "epoch 85; iter: 0; batch classifier loss: 0.352395; batch adversarial loss: 0.571699\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403537; batch adversarial loss: 0.607263\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417691; batch adversarial loss: 0.617188\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426243; batch adversarial loss: 0.571467\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369636; batch adversarial loss: 0.555298\n",
      "epoch 90; iter: 0; batch classifier loss: 0.442296; batch adversarial loss: 0.542879\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360939; batch adversarial loss: 0.597008\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374134; batch adversarial loss: 0.471214\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353567; batch adversarial loss: 0.546845\n",
      "epoch 94; iter: 0; batch classifier loss: 0.455128; batch adversarial loss: 0.448174\n",
      "epoch 95; iter: 0; batch classifier loss: 0.370200; batch adversarial loss: 0.555748\n",
      "epoch 96; iter: 0; batch classifier loss: 0.505771; batch adversarial loss: 0.584654\n",
      "epoch 97; iter: 0; batch classifier loss: 0.339103; batch adversarial loss: 0.541742\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376949; batch adversarial loss: 0.431388\n",
      "epoch 99; iter: 0; batch classifier loss: 0.346122; batch adversarial loss: 0.569214\n",
      "epoch 100; iter: 0; batch classifier loss: 0.474297; batch adversarial loss: 0.579082\n",
      "epoch 101; iter: 0; batch classifier loss: 0.313837; batch adversarial loss: 0.538000\n",
      "epoch 102; iter: 0; batch classifier loss: 0.389873; batch adversarial loss: 0.635086\n",
      "epoch 103; iter: 0; batch classifier loss: 0.461560; batch adversarial loss: 0.569127\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363807; batch adversarial loss: 0.599321\n",
      "epoch 105; iter: 0; batch classifier loss: 0.327373; batch adversarial loss: 0.513645\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378022; batch adversarial loss: 0.608348\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363337; batch adversarial loss: 0.559882\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386936; batch adversarial loss: 0.508397\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331767; batch adversarial loss: 0.547194\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373363; batch adversarial loss: 0.555168\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353109; batch adversarial loss: 0.526372\n",
      "epoch 112; iter: 0; batch classifier loss: 0.424269; batch adversarial loss: 0.545021\n",
      "epoch 113; iter: 0; batch classifier loss: 0.339144; batch adversarial loss: 0.580772\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405636; batch adversarial loss: 0.489711\n",
      "epoch 115; iter: 0; batch classifier loss: 0.392430; batch adversarial loss: 0.589717\n",
      "epoch 116; iter: 0; batch classifier loss: 0.408387; batch adversarial loss: 0.580860\n",
      "epoch 117; iter: 0; batch classifier loss: 0.409797; batch adversarial loss: 0.579286\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351430; batch adversarial loss: 0.620391\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350599; batch adversarial loss: 0.543519\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428934; batch adversarial loss: 0.554170\n",
      "epoch 121; iter: 0; batch classifier loss: 0.384550; batch adversarial loss: 0.445400\n",
      "epoch 122; iter: 0; batch classifier loss: 0.329305; batch adversarial loss: 0.571507\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331755; batch adversarial loss: 0.587986\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336478; batch adversarial loss: 0.580610\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394366; batch adversarial loss: 0.587444\n",
      "epoch 126; iter: 0; batch classifier loss: 0.286476; batch adversarial loss: 0.555745\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395029; batch adversarial loss: 0.551204\n",
      "epoch 128; iter: 0; batch classifier loss: 0.384486; batch adversarial loss: 0.554519\n",
      "epoch 129; iter: 0; batch classifier loss: 0.298338; batch adversarial loss: 0.546653\n",
      "epoch 130; iter: 0; batch classifier loss: 0.435439; batch adversarial loss: 0.548371\n",
      "epoch 131; iter: 0; batch classifier loss: 0.429160; batch adversarial loss: 0.543067\n",
      "epoch 132; iter: 0; batch classifier loss: 0.316282; batch adversarial loss: 0.592482\n",
      "epoch 133; iter: 0; batch classifier loss: 0.480487; batch adversarial loss: 0.607594\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343783; batch adversarial loss: 0.542749\n",
      "epoch 135; iter: 0; batch classifier loss: 0.438623; batch adversarial loss: 0.535523\n",
      "epoch 136; iter: 0; batch classifier loss: 0.325670; batch adversarial loss: 0.610792\n",
      "epoch 137; iter: 0; batch classifier loss: 0.300487; batch adversarial loss: 0.537892\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405730; batch adversarial loss: 0.516242\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371395; batch adversarial loss: 0.517670\n",
      "epoch 140; iter: 0; batch classifier loss: 0.380513; batch adversarial loss: 0.510634\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344882; batch adversarial loss: 0.632372\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360989; batch adversarial loss: 0.545335\n",
      "epoch 143; iter: 0; batch classifier loss: 0.273102; batch adversarial loss: 0.589277\n",
      "epoch 144; iter: 0; batch classifier loss: 0.311954; batch adversarial loss: 0.662527\n",
      "epoch 145; iter: 0; batch classifier loss: 0.279627; batch adversarial loss: 0.533162\n",
      "epoch 146; iter: 0; batch classifier loss: 0.464706; batch adversarial loss: 0.578913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.384641; batch adversarial loss: 0.632242\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331730; batch adversarial loss: 0.581471\n",
      "epoch 149; iter: 0; batch classifier loss: 0.301403; batch adversarial loss: 0.500250\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361448; batch adversarial loss: 0.563240\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417188; batch adversarial loss: 0.557232\n",
      "epoch 152; iter: 0; batch classifier loss: 0.301056; batch adversarial loss: 0.449700\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357249; batch adversarial loss: 0.616745\n",
      "epoch 154; iter: 0; batch classifier loss: 0.405775; batch adversarial loss: 0.491989\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357867; batch adversarial loss: 0.604606\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398492; batch adversarial loss: 0.545579\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363843; batch adversarial loss: 0.580999\n",
      "epoch 158; iter: 0; batch classifier loss: 0.314210; batch adversarial loss: 0.542875\n",
      "epoch 159; iter: 0; batch classifier loss: 0.302047; batch adversarial loss: 0.554400\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340282; batch adversarial loss: 0.590437\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362308; batch adversarial loss: 0.508693\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371974; batch adversarial loss: 0.534561\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353828; batch adversarial loss: 0.640853\n",
      "epoch 164; iter: 0; batch classifier loss: 0.405795; batch adversarial loss: 0.551962\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399949; batch adversarial loss: 0.482547\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378642; batch adversarial loss: 0.482237\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332845; batch adversarial loss: 0.511614\n",
      "epoch 168; iter: 0; batch classifier loss: 0.430763; batch adversarial loss: 0.544174\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332247; batch adversarial loss: 0.552331\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383027; batch adversarial loss: 0.553021\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385296; batch adversarial loss: 0.511294\n",
      "epoch 172; iter: 0; batch classifier loss: 0.436362; batch adversarial loss: 0.543099\n",
      "epoch 173; iter: 0; batch classifier loss: 0.454589; batch adversarial loss: 0.572044\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340370; batch adversarial loss: 0.654638\n",
      "epoch 175; iter: 0; batch classifier loss: 0.348776; batch adversarial loss: 0.583679\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361702; batch adversarial loss: 0.625931\n",
      "epoch 177; iter: 0; batch classifier loss: 0.359753; batch adversarial loss: 0.588432\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391500; batch adversarial loss: 0.569238\n",
      "epoch 179; iter: 0; batch classifier loss: 0.316373; batch adversarial loss: 0.571259\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323223; batch adversarial loss: 0.584393\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373001; batch adversarial loss: 0.464689\n",
      "epoch 182; iter: 0; batch classifier loss: 0.307851; batch adversarial loss: 0.573434\n",
      "epoch 183; iter: 0; batch classifier loss: 0.281199; batch adversarial loss: 0.602567\n",
      "epoch 184; iter: 0; batch classifier loss: 0.321236; batch adversarial loss: 0.544705\n",
      "epoch 185; iter: 0; batch classifier loss: 0.287598; batch adversarial loss: 0.580553\n",
      "epoch 186; iter: 0; batch classifier loss: 0.279388; batch adversarial loss: 0.654005\n",
      "epoch 187; iter: 0; batch classifier loss: 0.417190; batch adversarial loss: 0.519912\n",
      "epoch 188; iter: 0; batch classifier loss: 0.331383; batch adversarial loss: 0.586367\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345684; batch adversarial loss: 0.494936\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345394; batch adversarial loss: 0.542212\n",
      "epoch 191; iter: 0; batch classifier loss: 0.387575; batch adversarial loss: 0.492004\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337199; batch adversarial loss: 0.543912\n",
      "epoch 193; iter: 0; batch classifier loss: 0.418108; batch adversarial loss: 0.590525\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419564; batch adversarial loss: 0.553308\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321092; batch adversarial loss: 0.592812\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376556; batch adversarial loss: 0.489087\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340023; batch adversarial loss: 0.536540\n",
      "epoch 198; iter: 0; batch classifier loss: 0.397564; batch adversarial loss: 0.587169\n",
      "epoch 199; iter: 0; batch classifier loss: 0.415521; batch adversarial loss: 0.507294\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678130; batch adversarial loss: 0.659996\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588417; batch adversarial loss: 0.681567\n",
      "epoch 2; iter: 0; batch classifier loss: 0.570159; batch adversarial loss: 0.613310\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598395; batch adversarial loss: 0.645940\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565054; batch adversarial loss: 0.607399\n",
      "epoch 5; iter: 0; batch classifier loss: 0.490048; batch adversarial loss: 0.666256\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521935; batch adversarial loss: 0.557577\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516970; batch adversarial loss: 0.630170\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555282; batch adversarial loss: 0.547206\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532613; batch adversarial loss: 0.519960\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556250; batch adversarial loss: 0.616554\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553911; batch adversarial loss: 0.556338\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540747; batch adversarial loss: 0.536386\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488258; batch adversarial loss: 0.613918\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504520; batch adversarial loss: 0.556021\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530502; batch adversarial loss: 0.513160\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528283; batch adversarial loss: 0.601891\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511807; batch adversarial loss: 0.593767\n",
      "epoch 18; iter: 0; batch classifier loss: 0.563214; batch adversarial loss: 0.498518\n",
      "epoch 19; iter: 0; batch classifier loss: 0.418172; batch adversarial loss: 0.575322\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496815; batch adversarial loss: 0.521481\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496102; batch adversarial loss: 0.524151\n",
      "epoch 22; iter: 0; batch classifier loss: 0.499985; batch adversarial loss: 0.532455\n",
      "epoch 23; iter: 0; batch classifier loss: 0.649578; batch adversarial loss: 0.532628\n",
      "epoch 24; iter: 0; batch classifier loss: 0.548165; batch adversarial loss: 0.548447\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491660; batch adversarial loss: 0.623529\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439631; batch adversarial loss: 0.621647\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427279; batch adversarial loss: 0.565037\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433904; batch adversarial loss: 0.565278\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465902; batch adversarial loss: 0.539291\n",
      "epoch 30; iter: 0; batch classifier loss: 0.590443; batch adversarial loss: 0.501160\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438718; batch adversarial loss: 0.554498\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461947; batch adversarial loss: 0.508405\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461366; batch adversarial loss: 0.609926\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462276; batch adversarial loss: 0.562062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.549914; batch adversarial loss: 0.570985\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478590; batch adversarial loss: 0.542551\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452483; batch adversarial loss: 0.583810\n",
      "epoch 38; iter: 0; batch classifier loss: 0.388133; batch adversarial loss: 0.592059\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410930; batch adversarial loss: 0.563180\n",
      "epoch 40; iter: 0; batch classifier loss: 0.380317; batch adversarial loss: 0.527099\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451193; batch adversarial loss: 0.570953\n",
      "epoch 42; iter: 0; batch classifier loss: 0.373314; batch adversarial loss: 0.534820\n",
      "epoch 43; iter: 0; batch classifier loss: 0.551061; batch adversarial loss: 0.525511\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430450; batch adversarial loss: 0.525781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.461963; batch adversarial loss: 0.581780\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491548; batch adversarial loss: 0.469638\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423137; batch adversarial loss: 0.468885\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389882; batch adversarial loss: 0.544662\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470514; batch adversarial loss: 0.535131\n",
      "epoch 50; iter: 0; batch classifier loss: 0.489369; batch adversarial loss: 0.554000\n",
      "epoch 51; iter: 0; batch classifier loss: 0.382691; batch adversarial loss: 0.488605\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410582; batch adversarial loss: 0.535029\n",
      "epoch 53; iter: 0; batch classifier loss: 0.372052; batch adversarial loss: 0.525775\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400189; batch adversarial loss: 0.516345\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393776; batch adversarial loss: 0.563318\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405478; batch adversarial loss: 0.553798\n",
      "epoch 57; iter: 0; batch classifier loss: 0.378440; batch adversarial loss: 0.544652\n",
      "epoch 58; iter: 0; batch classifier loss: 0.373742; batch adversarial loss: 0.525626\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466530; batch adversarial loss: 0.553765\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391968; batch adversarial loss: 0.591664\n",
      "epoch 61; iter: 0; batch classifier loss: 0.475772; batch adversarial loss: 0.544547\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453711; batch adversarial loss: 0.516723\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411906; batch adversarial loss: 0.554294\n",
      "epoch 64; iter: 0; batch classifier loss: 0.455718; batch adversarial loss: 0.573234\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427101; batch adversarial loss: 0.563426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446722; batch adversarial loss: 0.544571\n",
      "epoch 67; iter: 0; batch classifier loss: 0.349576; batch adversarial loss: 0.582186\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430956; batch adversarial loss: 0.535320\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366088; batch adversarial loss: 0.573071\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384831; batch adversarial loss: 0.469561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402799; batch adversarial loss: 0.516355\n",
      "epoch 72; iter: 0; batch classifier loss: 0.424666; batch adversarial loss: 0.563412\n",
      "epoch 73; iter: 0; batch classifier loss: 0.346240; batch adversarial loss: 0.554029\n",
      "epoch 74; iter: 0; batch classifier loss: 0.498355; batch adversarial loss: 0.497534\n",
      "epoch 75; iter: 0; batch classifier loss: 0.450811; batch adversarial loss: 0.525930\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410495; batch adversarial loss: 0.497351\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402037; batch adversarial loss: 0.534965\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381988; batch adversarial loss: 0.591897\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399114; batch adversarial loss: 0.573117\n",
      "epoch 80; iter: 0; batch classifier loss: 0.434552; batch adversarial loss: 0.534554\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422776; batch adversarial loss: 0.592071\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423260; batch adversarial loss: 0.450563\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360324; batch adversarial loss: 0.563702\n",
      "epoch 84; iter: 0; batch classifier loss: 0.345007; batch adversarial loss: 0.506599\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377846; batch adversarial loss: 0.497861\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428304; batch adversarial loss: 0.582547\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410882; batch adversarial loss: 0.507053\n",
      "epoch 88; iter: 0; batch classifier loss: 0.419553; batch adversarial loss: 0.516199\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355432; batch adversarial loss: 0.515783\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397465; batch adversarial loss: 0.563703\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389975; batch adversarial loss: 0.544719\n",
      "epoch 92; iter: 0; batch classifier loss: 0.440617; batch adversarial loss: 0.506712\n",
      "epoch 93; iter: 0; batch classifier loss: 0.474208; batch adversarial loss: 0.544348\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370175; batch adversarial loss: 0.515795\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348500; batch adversarial loss: 0.525863\n",
      "epoch 96; iter: 0; batch classifier loss: 0.291674; batch adversarial loss: 0.525451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.354633; batch adversarial loss: 0.554303\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375908; batch adversarial loss: 0.534944\n",
      "epoch 99; iter: 0; batch classifier loss: 0.466239; batch adversarial loss: 0.591778\n",
      "epoch 100; iter: 0; batch classifier loss: 0.440547; batch adversarial loss: 0.516138\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421789; batch adversarial loss: 0.449752\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388705; batch adversarial loss: 0.591412\n",
      "epoch 103; iter: 0; batch classifier loss: 0.421215; batch adversarial loss: 0.600740\n",
      "epoch 104; iter: 0; batch classifier loss: 0.347125; batch adversarial loss: 0.497267\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417544; batch adversarial loss: 0.497952\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394809; batch adversarial loss: 0.525834\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366638; batch adversarial loss: 0.554092\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388513; batch adversarial loss: 0.535311\n",
      "epoch 109; iter: 0; batch classifier loss: 0.320472; batch adversarial loss: 0.535115\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373820; batch adversarial loss: 0.488083\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362677; batch adversarial loss: 0.554026\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435179; batch adversarial loss: 0.506983\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350959; batch adversarial loss: 0.468976\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405388; batch adversarial loss: 0.562999\n",
      "epoch 115; iter: 0; batch classifier loss: 0.368461; batch adversarial loss: 0.544522\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353371; batch adversarial loss: 0.610498\n",
      "epoch 117; iter: 0; batch classifier loss: 0.319254; batch adversarial loss: 0.563260\n",
      "epoch 118; iter: 0; batch classifier loss: 0.336359; batch adversarial loss: 0.468806\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382388; batch adversarial loss: 0.544572\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375860; batch adversarial loss: 0.534854\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378885; batch adversarial loss: 0.535124\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385474; batch adversarial loss: 0.619876\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388521; batch adversarial loss: 0.488313\n",
      "epoch 124; iter: 0; batch classifier loss: 0.291263; batch adversarial loss: 0.553936\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379423; batch adversarial loss: 0.543984\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413409; batch adversarial loss: 0.412136\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417186; batch adversarial loss: 0.487741\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356420; batch adversarial loss: 0.534740\n",
      "epoch 129; iter: 0; batch classifier loss: 0.313468; batch adversarial loss: 0.515839\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363596; batch adversarial loss: 0.524945\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339757; batch adversarial loss: 0.516131\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352619; batch adversarial loss: 0.554273\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392658; batch adversarial loss: 0.516150\n",
      "epoch 134; iter: 0; batch classifier loss: 0.314158; batch adversarial loss: 0.497278\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340405; batch adversarial loss: 0.488170\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348373; batch adversarial loss: 0.468600\n",
      "epoch 137; iter: 0; batch classifier loss: 0.320812; batch adversarial loss: 0.535133\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338865; batch adversarial loss: 0.525753\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345596; batch adversarial loss: 0.573184\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383921; batch adversarial loss: 0.478408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.394538; batch adversarial loss: 0.516910\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345611; batch adversarial loss: 0.562908\n",
      "epoch 143; iter: 0; batch classifier loss: 0.276847; batch adversarial loss: 0.572826\n",
      "epoch 144; iter: 0; batch classifier loss: 0.402008; batch adversarial loss: 0.534718\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334018; batch adversarial loss: 0.497546\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343247; batch adversarial loss: 0.572856\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345596; batch adversarial loss: 0.525851\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330193; batch adversarial loss: 0.506992\n",
      "epoch 149; iter: 0; batch classifier loss: 0.386741; batch adversarial loss: 0.544791\n",
      "epoch 150; iter: 0; batch classifier loss: 0.437046; batch adversarial loss: 0.582169\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376531; batch adversarial loss: 0.506581\n",
      "epoch 152; iter: 0; batch classifier loss: 0.286663; batch adversarial loss: 0.440788\n",
      "epoch 153; iter: 0; batch classifier loss: 0.455303; batch adversarial loss: 0.516031\n",
      "epoch 154; iter: 0; batch classifier loss: 0.289655; batch adversarial loss: 0.563235\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354617; batch adversarial loss: 0.516285\n",
      "epoch 156; iter: 0; batch classifier loss: 0.432189; batch adversarial loss: 0.544606\n",
      "epoch 157; iter: 0; batch classifier loss: 0.338457; batch adversarial loss: 0.469379\n",
      "epoch 158; iter: 0; batch classifier loss: 0.349399; batch adversarial loss: 0.563200\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361706; batch adversarial loss: 0.488046\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314958; batch adversarial loss: 0.506840\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387936; batch adversarial loss: 0.553560\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387280; batch adversarial loss: 0.544492\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339768; batch adversarial loss: 0.610256\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337420; batch adversarial loss: 0.573253\n",
      "epoch 165; iter: 0; batch classifier loss: 0.432532; batch adversarial loss: 0.553843\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364954; batch adversarial loss: 0.553912\n",
      "epoch 167; iter: 0; batch classifier loss: 0.464895; batch adversarial loss: 0.497184\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354474; batch adversarial loss: 0.591989\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343253; batch adversarial loss: 0.535150\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346956; batch adversarial loss: 0.506725\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353649; batch adversarial loss: 0.600734\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407472; batch adversarial loss: 0.581749\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369786; batch adversarial loss: 0.525624\n",
      "epoch 174; iter: 0; batch classifier loss: 0.438794; batch adversarial loss: 0.619825\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325921; batch adversarial loss: 0.496768\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310503; batch adversarial loss: 0.496782\n",
      "epoch 177; iter: 0; batch classifier loss: 0.269860; batch adversarial loss: 0.553491\n",
      "epoch 178; iter: 0; batch classifier loss: 0.366072; batch adversarial loss: 0.629894\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384453; batch adversarial loss: 0.459999\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368935; batch adversarial loss: 0.478264\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338240; batch adversarial loss: 0.534737\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354728; batch adversarial loss: 0.517024\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369072; batch adversarial loss: 0.506729\n",
      "epoch 184; iter: 0; batch classifier loss: 0.253932; batch adversarial loss: 0.572672\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358642; batch adversarial loss: 0.610747\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356066; batch adversarial loss: 0.506582\n",
      "epoch 187; iter: 0; batch classifier loss: 0.480497; batch adversarial loss: 0.582399\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392889; batch adversarial loss: 0.544488\n",
      "epoch 189; iter: 0; batch classifier loss: 0.342064; batch adversarial loss: 0.478606\n",
      "epoch 190; iter: 0; batch classifier loss: 0.369296; batch adversarial loss: 0.544493\n",
      "epoch 191; iter: 0; batch classifier loss: 0.367250; batch adversarial loss: 0.563385\n",
      "epoch 192; iter: 0; batch classifier loss: 0.282861; batch adversarial loss: 0.525389\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333034; batch adversarial loss: 0.544431\n",
      "epoch 194; iter: 0; batch classifier loss: 0.401862; batch adversarial loss: 0.488175\n",
      "epoch 195; iter: 0; batch classifier loss: 0.368338; batch adversarial loss: 0.554077\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334128; batch adversarial loss: 0.573217\n",
      "epoch 197; iter: 0; batch classifier loss: 0.419367; batch adversarial loss: 0.554025\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332906; batch adversarial loss: 0.525870\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339681; batch adversarial loss: 0.554307\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696495; batch adversarial loss: 0.643295\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613108; batch adversarial loss: 0.623768\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583509; batch adversarial loss: 0.634886\n",
      "epoch 3; iter: 0; batch classifier loss: 0.604110; batch adversarial loss: 0.597340\n",
      "epoch 4; iter: 0; batch classifier loss: 0.608482; batch adversarial loss: 0.670314\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585931; batch adversarial loss: 0.613842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518820; batch adversarial loss: 0.583073\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570726; batch adversarial loss: 0.572560\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536047; batch adversarial loss: 0.566068\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553563; batch adversarial loss: 0.538747\n",
      "epoch 10; iter: 0; batch classifier loss: 0.497938; batch adversarial loss: 0.614092\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503042; batch adversarial loss: 0.632535\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514877; batch adversarial loss: 0.587392\n",
      "epoch 13; iter: 0; batch classifier loss: 0.531255; batch adversarial loss: 0.572891\n",
      "epoch 14; iter: 0; batch classifier loss: 0.570154; batch adversarial loss: 0.535535\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527666; batch adversarial loss: 0.555210\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561654; batch adversarial loss: 0.603053\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488208; batch adversarial loss: 0.569251\n",
      "epoch 18; iter: 0; batch classifier loss: 0.475627; batch adversarial loss: 0.518445\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437745; batch adversarial loss: 0.538996\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534785; batch adversarial loss: 0.521277\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468082; batch adversarial loss: 0.488741\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482656; batch adversarial loss: 0.575605\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461094; batch adversarial loss: 0.552071\n",
      "epoch 24; iter: 0; batch classifier loss: 0.413952; batch adversarial loss: 0.507097\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431253; batch adversarial loss: 0.547521\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489538; batch adversarial loss: 0.505473\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441710; batch adversarial loss: 0.564687\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421940; batch adversarial loss: 0.633936\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439250; batch adversarial loss: 0.494027\n",
      "epoch 30; iter: 0; batch classifier loss: 0.556151; batch adversarial loss: 0.563745\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480126; batch adversarial loss: 0.527438\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513193; batch adversarial loss: 0.526571\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455252; batch adversarial loss: 0.641919\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471675; batch adversarial loss: 0.571710\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468106; batch adversarial loss: 0.562584\n",
      "epoch 36; iter: 0; batch classifier loss: 0.517200; batch adversarial loss: 0.516906\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409435; batch adversarial loss: 0.562015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.452553; batch adversarial loss: 0.645852\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437717; batch adversarial loss: 0.553939\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470524; batch adversarial loss: 0.517886\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436819; batch adversarial loss: 0.563541\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407900; batch adversarial loss: 0.543915\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479668; batch adversarial loss: 0.443226\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468671; batch adversarial loss: 0.553582\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432564; batch adversarial loss: 0.526218\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396509; batch adversarial loss: 0.564513\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443463; batch adversarial loss: 0.544933\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450782; batch adversarial loss: 0.543931\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456731; batch adversarial loss: 0.581764\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432928; batch adversarial loss: 0.544915\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447056; batch adversarial loss: 0.553862\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436671; batch adversarial loss: 0.431805\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480422; batch adversarial loss: 0.544537\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417735; batch adversarial loss: 0.573461\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482451; batch adversarial loss: 0.601816\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439522; batch adversarial loss: 0.468792\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416671; batch adversarial loss: 0.544362\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440426; batch adversarial loss: 0.600775\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384131; batch adversarial loss: 0.535310\n",
      "epoch 60; iter: 0; batch classifier loss: 0.408414; batch adversarial loss: 0.516938\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395341; batch adversarial loss: 0.423168\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383366; batch adversarial loss: 0.544884\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383276; batch adversarial loss: 0.469078\n",
      "epoch 64; iter: 0; batch classifier loss: 0.510135; batch adversarial loss: 0.479573\n",
      "epoch 65; iter: 0; batch classifier loss: 0.489916; batch adversarial loss: 0.548862\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431712; batch adversarial loss: 0.562385\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411012; batch adversarial loss: 0.591880\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376013; batch adversarial loss: 0.543676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390948; batch adversarial loss: 0.534872\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397157; batch adversarial loss: 0.552771\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369200; batch adversarial loss: 0.525478\n",
      "epoch 72; iter: 0; batch classifier loss: 0.508970; batch adversarial loss: 0.667040\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402877; batch adversarial loss: 0.496659\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394928; batch adversarial loss: 0.664793\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422371; batch adversarial loss: 0.516352\n",
      "epoch 76; iter: 0; batch classifier loss: 0.444256; batch adversarial loss: 0.500358\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404238; batch adversarial loss: 0.612911\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392944; batch adversarial loss: 0.536047\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409765; batch adversarial loss: 0.632690\n",
      "epoch 80; iter: 0; batch classifier loss: 0.482294; batch adversarial loss: 0.622333\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373717; batch adversarial loss: 0.458196\n",
      "epoch 82; iter: 0; batch classifier loss: 0.462186; batch adversarial loss: 0.525189\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378044; batch adversarial loss: 0.573111\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382328; batch adversarial loss: 0.497245\n",
      "epoch 85; iter: 0; batch classifier loss: 0.386942; batch adversarial loss: 0.507179\n",
      "epoch 86; iter: 0; batch classifier loss: 0.385188; batch adversarial loss: 0.488962\n",
      "epoch 87; iter: 0; batch classifier loss: 0.480221; batch adversarial loss: 0.572906\n",
      "epoch 88; iter: 0; batch classifier loss: 0.534721; batch adversarial loss: 0.544183\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407409; batch adversarial loss: 0.555231\n",
      "epoch 90; iter: 0; batch classifier loss: 0.431726; batch adversarial loss: 0.573008\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427760; batch adversarial loss: 0.553160\n",
      "epoch 92; iter: 0; batch classifier loss: 0.504941; batch adversarial loss: 0.554276\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439100; batch adversarial loss: 0.545350\n",
      "epoch 94; iter: 0; batch classifier loss: 0.447722; batch adversarial loss: 0.535135\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427675; batch adversarial loss: 0.487400\n",
      "epoch 96; iter: 0; batch classifier loss: 0.444632; batch adversarial loss: 0.477635\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400373; batch adversarial loss: 0.611564\n",
      "epoch 98; iter: 0; batch classifier loss: 0.332905; batch adversarial loss: 0.553810\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342382; batch adversarial loss: 0.487210\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345092; batch adversarial loss: 0.515749\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411061; batch adversarial loss: 0.534975\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350524; batch adversarial loss: 0.592446\n",
      "epoch 103; iter: 0; batch classifier loss: 0.380448; batch adversarial loss: 0.555044\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365567; batch adversarial loss: 0.516139\n",
      "epoch 105; iter: 0; batch classifier loss: 0.354520; batch adversarial loss: 0.553340\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417210; batch adversarial loss: 0.544156\n",
      "epoch 107; iter: 0; batch classifier loss: 0.314733; batch adversarial loss: 0.525577\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403198; batch adversarial loss: 0.479007\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412821; batch adversarial loss: 0.517513\n",
      "epoch 110; iter: 0; batch classifier loss: 0.327407; batch adversarial loss: 0.423187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.311901; batch adversarial loss: 0.545013\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394060; batch adversarial loss: 0.572612\n",
      "epoch 113; iter: 0; batch classifier loss: 0.453812; batch adversarial loss: 0.536170\n",
      "epoch 114; iter: 0; batch classifier loss: 0.474312; batch adversarial loss: 0.507441\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336340; batch adversarial loss: 0.553034\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405717; batch adversarial loss: 0.554277\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345165; batch adversarial loss: 0.582833\n",
      "epoch 118; iter: 0; batch classifier loss: 0.441937; batch adversarial loss: 0.478210\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414624; batch adversarial loss: 0.609867\n",
      "epoch 120; iter: 0; batch classifier loss: 0.456912; batch adversarial loss: 0.506628\n",
      "epoch 121; iter: 0; batch classifier loss: 0.421306; batch adversarial loss: 0.535961\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363313; batch adversarial loss: 0.553832\n",
      "epoch 123; iter: 0; batch classifier loss: 0.393204; batch adversarial loss: 0.524937\n",
      "epoch 124; iter: 0; batch classifier loss: 0.355948; batch adversarial loss: 0.469977\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402229; batch adversarial loss: 0.542833\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377995; batch adversarial loss: 0.535666\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358439; batch adversarial loss: 0.460412\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348905; batch adversarial loss: 0.563797\n",
      "epoch 129; iter: 0; batch classifier loss: 0.353344; batch adversarial loss: 0.526515\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408947; batch adversarial loss: 0.666954\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388647; batch adversarial loss: 0.517283\n",
      "epoch 132; iter: 0; batch classifier loss: 0.444351; batch adversarial loss: 0.572901\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361476; batch adversarial loss: 0.601322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.362551; batch adversarial loss: 0.543731\n",
      "epoch 135; iter: 0; batch classifier loss: 0.393849; batch adversarial loss: 0.592481\n",
      "epoch 136; iter: 0; batch classifier loss: 0.268116; batch adversarial loss: 0.553583\n",
      "epoch 137; iter: 0; batch classifier loss: 0.312656; batch adversarial loss: 0.515884\n",
      "epoch 138; iter: 0; batch classifier loss: 0.399137; batch adversarial loss: 0.506786\n",
      "epoch 139; iter: 0; batch classifier loss: 0.353154; batch adversarial loss: 0.572251\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365381; batch adversarial loss: 0.582478\n",
      "epoch 141; iter: 0; batch classifier loss: 0.423849; batch adversarial loss: 0.507560\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355198; batch adversarial loss: 0.459357\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386264; batch adversarial loss: 0.554716\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338355; batch adversarial loss: 0.544229\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381251; batch adversarial loss: 0.544292\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400255; batch adversarial loss: 0.507273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353707; batch adversarial loss: 0.515586\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378127; batch adversarial loss: 0.552591\n",
      "epoch 149; iter: 0; batch classifier loss: 0.404785; batch adversarial loss: 0.498263\n",
      "epoch 150; iter: 0; batch classifier loss: 0.317461; batch adversarial loss: 0.450810\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330557; batch adversarial loss: 0.619281\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376380; batch adversarial loss: 0.562089\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376684; batch adversarial loss: 0.451052\n",
      "epoch 154; iter: 0; batch classifier loss: 0.408502; batch adversarial loss: 0.479398\n",
      "epoch 155; iter: 0; batch classifier loss: 0.433791; batch adversarial loss: 0.551452\n",
      "epoch 156; iter: 0; batch classifier loss: 0.498884; batch adversarial loss: 0.526602\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370274; batch adversarial loss: 0.534440\n",
      "epoch 158; iter: 0; batch classifier loss: 0.295475; batch adversarial loss: 0.563303\n",
      "epoch 159; iter: 0; batch classifier loss: 0.336334; batch adversarial loss: 0.632650\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400949; batch adversarial loss: 0.572313\n",
      "epoch 161; iter: 0; batch classifier loss: 0.390886; batch adversarial loss: 0.583724\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355051; batch adversarial loss: 0.564017\n",
      "epoch 163; iter: 0; batch classifier loss: 0.417274; batch adversarial loss: 0.573875\n",
      "epoch 164; iter: 0; batch classifier loss: 0.365493; batch adversarial loss: 0.591038\n",
      "epoch 165; iter: 0; batch classifier loss: 0.400255; batch adversarial loss: 0.581404\n",
      "epoch 166; iter: 0; batch classifier loss: 0.399344; batch adversarial loss: 0.507369\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346779; batch adversarial loss: 0.478100\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395369; batch adversarial loss: 0.563509\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355494; batch adversarial loss: 0.515918\n",
      "epoch 170; iter: 0; batch classifier loss: 0.400240; batch adversarial loss: 0.517544\n",
      "epoch 171; iter: 0; batch classifier loss: 0.328833; batch adversarial loss: 0.583838\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365870; batch adversarial loss: 0.507543\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349454; batch adversarial loss: 0.526877\n",
      "epoch 174; iter: 0; batch classifier loss: 0.310157; batch adversarial loss: 0.598018\n",
      "epoch 175; iter: 0; batch classifier loss: 0.379274; batch adversarial loss: 0.516614\n",
      "epoch 176; iter: 0; batch classifier loss: 0.331306; batch adversarial loss: 0.543711\n",
      "epoch 177; iter: 0; batch classifier loss: 0.367472; batch adversarial loss: 0.571963\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363411; batch adversarial loss: 0.523399\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340809; batch adversarial loss: 0.552728\n",
      "epoch 180; iter: 0; batch classifier loss: 0.393561; batch adversarial loss: 0.477431\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360157; batch adversarial loss: 0.608606\n",
      "epoch 182; iter: 0; batch classifier loss: 0.401361; batch adversarial loss: 0.534061\n",
      "epoch 183; iter: 0; batch classifier loss: 0.439886; batch adversarial loss: 0.525833\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358731; batch adversarial loss: 0.458816\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333303; batch adversarial loss: 0.542210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382344; batch adversarial loss: 0.553921\n",
      "epoch 187; iter: 0; batch classifier loss: 0.392975; batch adversarial loss: 0.515944\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373553; batch adversarial loss: 0.498060\n",
      "epoch 189; iter: 0; batch classifier loss: 0.318712; batch adversarial loss: 0.470407\n",
      "epoch 190; iter: 0; batch classifier loss: 0.437428; batch adversarial loss: 0.542767\n",
      "epoch 191; iter: 0; batch classifier loss: 0.297795; batch adversarial loss: 0.572779\n",
      "epoch 192; iter: 0; batch classifier loss: 0.417481; batch adversarial loss: 0.582358\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378115; batch adversarial loss: 0.546655\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357788; batch adversarial loss: 0.527119\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387897; batch adversarial loss: 0.579506\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355893; batch adversarial loss: 0.612887\n",
      "epoch 197; iter: 0; batch classifier loss: 0.384081; batch adversarial loss: 0.460084\n",
      "epoch 198; iter: 0; batch classifier loss: 0.420909; batch adversarial loss: 0.543194\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396378; batch adversarial loss: 0.535467\n",
      "epoch 0; iter: 0; batch classifier loss: 0.790484; batch adversarial loss: 1.027481\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597195; batch adversarial loss: 0.911747\n",
      "epoch 2; iter: 0; batch classifier loss: 0.519570; batch adversarial loss: 0.782523\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547489; batch adversarial loss: 0.728652\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544545; batch adversarial loss: 0.785622\n",
      "epoch 5; iter: 0; batch classifier loss: 0.545000; batch adversarial loss: 0.670433\n",
      "epoch 6; iter: 0; batch classifier loss: 0.576579; batch adversarial loss: 0.683132\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598720; batch adversarial loss: 0.661311\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528611; batch adversarial loss: 0.622858\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471823; batch adversarial loss: 0.631556\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561873; batch adversarial loss: 0.653119\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562614; batch adversarial loss: 0.635721\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547296; batch adversarial loss: 0.590111\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498878; batch adversarial loss: 0.565288\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518376; batch adversarial loss: 0.610077\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482022; batch adversarial loss: 0.596525\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519955; batch adversarial loss: 0.525251\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474420; batch adversarial loss: 0.536031\n",
      "epoch 18; iter: 0; batch classifier loss: 0.461417; batch adversarial loss: 0.580904\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484968; batch adversarial loss: 0.585891\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440149; batch adversarial loss: 0.543004\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546614; batch adversarial loss: 0.512565\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481829; batch adversarial loss: 0.482549\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513311; batch adversarial loss: 0.576250\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445178; batch adversarial loss: 0.563017\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457616; batch adversarial loss: 0.555797\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445460; batch adversarial loss: 0.559727\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471235; batch adversarial loss: 0.483309\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499393; batch adversarial loss: 0.531955\n",
      "epoch 29; iter: 0; batch classifier loss: 0.410588; batch adversarial loss: 0.604247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.470849; batch adversarial loss: 0.585784\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439286; batch adversarial loss: 0.587989\n",
      "epoch 32; iter: 0; batch classifier loss: 0.575261; batch adversarial loss: 0.577048\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518311; batch adversarial loss: 0.577227\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462925; batch adversarial loss: 0.607816\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402292; batch adversarial loss: 0.513373\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484556; batch adversarial loss: 0.574828\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439344; batch adversarial loss: 0.465878\n",
      "epoch 38; iter: 0; batch classifier loss: 0.507176; batch adversarial loss: 0.544747\n",
      "epoch 39; iter: 0; batch classifier loss: 0.472449; batch adversarial loss: 0.520421\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451596; batch adversarial loss: 0.571947\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435672; batch adversarial loss: 0.576803\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472396; batch adversarial loss: 0.561458\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424230; batch adversarial loss: 0.632945\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464931; batch adversarial loss: 0.485229\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471510; batch adversarial loss: 0.539510\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420221; batch adversarial loss: 0.448698\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464145; batch adversarial loss: 0.506309\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407980; batch adversarial loss: 0.592319\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476548; batch adversarial loss: 0.553935\n",
      "epoch 50; iter: 0; batch classifier loss: 0.370387; batch adversarial loss: 0.444565\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455229; batch adversarial loss: 0.629809\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414874; batch adversarial loss: 0.536626\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390910; batch adversarial loss: 0.517229\n",
      "epoch 54; iter: 0; batch classifier loss: 0.321009; batch adversarial loss: 0.553414\n",
      "epoch 55; iter: 0; batch classifier loss: 0.443375; batch adversarial loss: 0.525975\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415879; batch adversarial loss: 0.509357\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440449; batch adversarial loss: 0.469982\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390491; batch adversarial loss: 0.573560\n",
      "epoch 59; iter: 0; batch classifier loss: 0.502862; batch adversarial loss: 0.608727\n",
      "epoch 60; iter: 0; batch classifier loss: 0.489620; batch adversarial loss: 0.489112\n",
      "epoch 61; iter: 0; batch classifier loss: 0.462394; batch adversarial loss: 0.507720\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416389; batch adversarial loss: 0.536172\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394332; batch adversarial loss: 0.508630\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401488; batch adversarial loss: 0.516611\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389813; batch adversarial loss: 0.487925\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441873; batch adversarial loss: 0.554758\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395848; batch adversarial loss: 0.563503\n",
      "epoch 68; iter: 0; batch classifier loss: 0.469420; batch adversarial loss: 0.536018\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447734; batch adversarial loss: 0.544161\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447287; batch adversarial loss: 0.508505\n",
      "epoch 71; iter: 0; batch classifier loss: 0.485728; batch adversarial loss: 0.497264\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413022; batch adversarial loss: 0.516585\n",
      "epoch 73; iter: 0; batch classifier loss: 0.469265; batch adversarial loss: 0.543660\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404756; batch adversarial loss: 0.506880\n",
      "epoch 75; iter: 0; batch classifier loss: 0.414778; batch adversarial loss: 0.515995\n",
      "epoch 76; iter: 0; batch classifier loss: 0.417578; batch adversarial loss: 0.574757\n",
      "epoch 77; iter: 0; batch classifier loss: 0.352823; batch adversarial loss: 0.610415\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438145; batch adversarial loss: 0.563666\n",
      "epoch 79; iter: 0; batch classifier loss: 0.355354; batch adversarial loss: 0.554684\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378099; batch adversarial loss: 0.622124\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396937; batch adversarial loss: 0.516775\n",
      "epoch 82; iter: 0; batch classifier loss: 0.442341; batch adversarial loss: 0.626471\n",
      "epoch 83; iter: 0; batch classifier loss: 0.361564; batch adversarial loss: 0.554706\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390584; batch adversarial loss: 0.589691\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395651; batch adversarial loss: 0.515335\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379550; batch adversarial loss: 0.480418\n",
      "epoch 87; iter: 0; batch classifier loss: 0.469610; batch adversarial loss: 0.534019\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417418; batch adversarial loss: 0.599208\n",
      "epoch 89; iter: 0; batch classifier loss: 0.476087; batch adversarial loss: 0.544565\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434801; batch adversarial loss: 0.524478\n",
      "epoch 91; iter: 0; batch classifier loss: 0.454111; batch adversarial loss: 0.563237\n",
      "epoch 92; iter: 0; batch classifier loss: 0.452854; batch adversarial loss: 0.592281\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374436; batch adversarial loss: 0.543334\n",
      "epoch 94; iter: 0; batch classifier loss: 0.346235; batch adversarial loss: 0.488715\n",
      "epoch 95; iter: 0; batch classifier loss: 0.328302; batch adversarial loss: 0.460470\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367800; batch adversarial loss: 0.460626\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365684; batch adversarial loss: 0.618772\n",
      "epoch 98; iter: 0; batch classifier loss: 0.424503; batch adversarial loss: 0.600646\n",
      "epoch 99; iter: 0; batch classifier loss: 0.420224; batch adversarial loss: 0.535744\n",
      "epoch 100; iter: 0; batch classifier loss: 0.425312; batch adversarial loss: 0.544423\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352740; batch adversarial loss: 0.592344\n",
      "epoch 102; iter: 0; batch classifier loss: 0.384239; batch adversarial loss: 0.519249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381333; batch adversarial loss: 0.546060\n",
      "epoch 104; iter: 0; batch classifier loss: 0.449910; batch adversarial loss: 0.468716\n",
      "epoch 105; iter: 0; batch classifier loss: 0.332640; batch adversarial loss: 0.592341\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408618; batch adversarial loss: 0.555821\n",
      "epoch 107; iter: 0; batch classifier loss: 0.446206; batch adversarial loss: 0.579813\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353863; batch adversarial loss: 0.503832\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370095; batch adversarial loss: 0.583321\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379548; batch adversarial loss: 0.610212\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376850; batch adversarial loss: 0.468379\n",
      "epoch 112; iter: 0; batch classifier loss: 0.433307; batch adversarial loss: 0.538715\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395145; batch adversarial loss: 0.534698\n",
      "epoch 114; iter: 0; batch classifier loss: 0.301248; batch adversarial loss: 0.529211\n",
      "epoch 115; iter: 0; batch classifier loss: 0.399749; batch adversarial loss: 0.535290\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384304; batch adversarial loss: 0.609892\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373486; batch adversarial loss: 0.549399\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352847; batch adversarial loss: 0.519714\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378121; batch adversarial loss: 0.579385\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400197; batch adversarial loss: 0.619671\n",
      "epoch 121; iter: 0; batch classifier loss: 0.342757; batch adversarial loss: 0.548782\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385685; batch adversarial loss: 0.628435\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385843; batch adversarial loss: 0.509580\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376906; batch adversarial loss: 0.518499\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349243; batch adversarial loss: 0.563264\n",
      "epoch 126; iter: 0; batch classifier loss: 0.310333; batch adversarial loss: 0.591002\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443402; batch adversarial loss: 0.537193\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313388; batch adversarial loss: 0.537184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.322572; batch adversarial loss: 0.598418\n",
      "epoch 130; iter: 0; batch classifier loss: 0.433848; batch adversarial loss: 0.506516\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380151; batch adversarial loss: 0.553519\n",
      "epoch 132; iter: 0; batch classifier loss: 0.422263; batch adversarial loss: 0.469503\n",
      "epoch 133; iter: 0; batch classifier loss: 0.321373; batch adversarial loss: 0.562934\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395791; batch adversarial loss: 0.572352\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337944; batch adversarial loss: 0.535647\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393737; batch adversarial loss: 0.591519\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366391; batch adversarial loss: 0.504075\n",
      "epoch 138; iter: 0; batch classifier loss: 0.306647; batch adversarial loss: 0.565440\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359187; batch adversarial loss: 0.515422\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361766; batch adversarial loss: 0.562365\n",
      "epoch 141; iter: 0; batch classifier loss: 0.444529; batch adversarial loss: 0.589052\n",
      "epoch 142; iter: 0; batch classifier loss: 0.390353; batch adversarial loss: 0.525852\n",
      "epoch 143; iter: 0; batch classifier loss: 0.335204; batch adversarial loss: 0.517830\n",
      "epoch 144; iter: 0; batch classifier loss: 0.375373; batch adversarial loss: 0.535468\n",
      "epoch 145; iter: 0; batch classifier loss: 0.326282; batch adversarial loss: 0.582707\n",
      "epoch 146; iter: 0; batch classifier loss: 0.428674; batch adversarial loss: 0.425564\n",
      "epoch 147; iter: 0; batch classifier loss: 0.302336; batch adversarial loss: 0.534977\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343055; batch adversarial loss: 0.480249\n",
      "epoch 149; iter: 0; batch classifier loss: 0.372667; batch adversarial loss: 0.552986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392986; batch adversarial loss: 0.489151\n",
      "epoch 151; iter: 0; batch classifier loss: 0.406837; batch adversarial loss: 0.498032\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323171; batch adversarial loss: 0.619644\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344212; batch adversarial loss: 0.600772\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390680; batch adversarial loss: 0.543735\n",
      "epoch 155; iter: 0; batch classifier loss: 0.424317; batch adversarial loss: 0.610513\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349805; batch adversarial loss: 0.553104\n",
      "epoch 157; iter: 0; batch classifier loss: 0.413082; batch adversarial loss: 0.543850\n",
      "epoch 158; iter: 0; batch classifier loss: 0.408813; batch adversarial loss: 0.553363\n",
      "epoch 159; iter: 0; batch classifier loss: 0.406271; batch adversarial loss: 0.544772\n",
      "epoch 160; iter: 0; batch classifier loss: 0.441791; batch adversarial loss: 0.527050\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376304; batch adversarial loss: 0.544883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.309780; batch adversarial loss: 0.591122\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362703; batch adversarial loss: 0.544769\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363377; batch adversarial loss: 0.582536\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379069; batch adversarial loss: 0.553929\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312802; batch adversarial loss: 0.488510\n",
      "epoch 167; iter: 0; batch classifier loss: 0.388573; batch adversarial loss: 0.525165\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388511; batch adversarial loss: 0.627835\n",
      "epoch 169; iter: 0; batch classifier loss: 0.400932; batch adversarial loss: 0.591580\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369798; batch adversarial loss: 0.525964\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363709; batch adversarial loss: 0.609306\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385748; batch adversarial loss: 0.572229\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343721; batch adversarial loss: 0.573405\n",
      "epoch 174; iter: 0; batch classifier loss: 0.328872; batch adversarial loss: 0.591174\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340598; batch adversarial loss: 0.497076\n",
      "epoch 176; iter: 0; batch classifier loss: 0.284674; batch adversarial loss: 0.451053\n",
      "epoch 177; iter: 0; batch classifier loss: 0.364600; batch adversarial loss: 0.544583\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316897; batch adversarial loss: 0.554318\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279569; batch adversarial loss: 0.460692\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324408; batch adversarial loss: 0.600480\n",
      "epoch 181; iter: 0; batch classifier loss: 0.326659; batch adversarial loss: 0.572882\n",
      "epoch 182; iter: 0; batch classifier loss: 0.395659; batch adversarial loss: 0.498630\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348734; batch adversarial loss: 0.573854\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338845; batch adversarial loss: 0.572320\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330163; batch adversarial loss: 0.507905\n",
      "epoch 186; iter: 0; batch classifier loss: 0.293404; batch adversarial loss: 0.479478\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376607; batch adversarial loss: 0.543877\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378791; batch adversarial loss: 0.554191\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383948; batch adversarial loss: 0.517446\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347192; batch adversarial loss: 0.489379\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403772; batch adversarial loss: 0.599849\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365997; batch adversarial loss: 0.479035\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335143; batch adversarial loss: 0.582132\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364297; batch adversarial loss: 0.608394\n",
      "epoch 195; iter: 0; batch classifier loss: 0.369121; batch adversarial loss: 0.525981\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312977; batch adversarial loss: 0.571891\n",
      "epoch 197; iter: 0; batch classifier loss: 0.439645; batch adversarial loss: 0.553684\n",
      "epoch 198; iter: 0; batch classifier loss: 0.418018; batch adversarial loss: 0.553855\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388794; batch adversarial loss: 0.507236\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723246; batch adversarial loss: 0.630884\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581769; batch adversarial loss: 0.618010\n",
      "epoch 2; iter: 0; batch classifier loss: 0.519279; batch adversarial loss: 0.634655\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614786; batch adversarial loss: 0.595836\n",
      "epoch 4; iter: 0; batch classifier loss: 0.510243; batch adversarial loss: 0.578736\n",
      "epoch 5; iter: 0; batch classifier loss: 0.504066; batch adversarial loss: 0.610944\n",
      "epoch 6; iter: 0; batch classifier loss: 0.531004; batch adversarial loss: 0.637532\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537950; batch adversarial loss: 0.608152\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601156; batch adversarial loss: 0.617482\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530454; batch adversarial loss: 0.584350\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543763; batch adversarial loss: 0.603203\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547293; batch adversarial loss: 0.593776\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558809; batch adversarial loss: 0.611019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477952; batch adversarial loss: 0.600346\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526168; batch adversarial loss: 0.583535\n",
      "epoch 15; iter: 0; batch classifier loss: 0.586097; batch adversarial loss: 0.643886\n",
      "epoch 16; iter: 0; batch classifier loss: 0.530597; batch adversarial loss: 0.630530\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560684; batch adversarial loss: 0.640293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511853; batch adversarial loss: 0.572077\n",
      "epoch 19; iter: 0; batch classifier loss: 0.562938; batch adversarial loss: 0.549917\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469498; batch adversarial loss: 0.515363\n",
      "epoch 21; iter: 0; batch classifier loss: 0.459819; batch adversarial loss: 0.519603\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464312; batch adversarial loss: 0.539603\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471890; batch adversarial loss: 0.533719\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463150; batch adversarial loss: 0.597337\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494285; batch adversarial loss: 0.507167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.378709; batch adversarial loss: 0.572937\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470732; batch adversarial loss: 0.554338\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419963; batch adversarial loss: 0.502807\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447392; batch adversarial loss: 0.615405\n",
      "epoch 30; iter: 0; batch classifier loss: 0.546011; batch adversarial loss: 0.499990\n",
      "epoch 31; iter: 0; batch classifier loss: 0.508159; batch adversarial loss: 0.609931\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460156; batch adversarial loss: 0.581405\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442659; batch adversarial loss: 0.501165\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464889; batch adversarial loss: 0.580957\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511003; batch adversarial loss: 0.504232\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444539; batch adversarial loss: 0.581598\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404299; batch adversarial loss: 0.480584\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483643; batch adversarial loss: 0.509400\n",
      "epoch 39; iter: 0; batch classifier loss: 0.499693; batch adversarial loss: 0.495178\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462492; batch adversarial loss: 0.477098\n",
      "epoch 41; iter: 0; batch classifier loss: 0.485349; batch adversarial loss: 0.537631\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481396; batch adversarial loss: 0.517771\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421489; batch adversarial loss: 0.523372\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392322; batch adversarial loss: 0.532885\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481209; batch adversarial loss: 0.536317\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469351; batch adversarial loss: 0.479173\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473250; batch adversarial loss: 0.442023\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414249; batch adversarial loss: 0.486642\n",
      "epoch 49; iter: 0; batch classifier loss: 0.387600; batch adversarial loss: 0.536386\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417093; batch adversarial loss: 0.507913\n",
      "epoch 51; iter: 0; batch classifier loss: 0.456613; batch adversarial loss: 0.575756\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433632; batch adversarial loss: 0.461000\n",
      "epoch 53; iter: 0; batch classifier loss: 0.488177; batch adversarial loss: 0.551456\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420239; batch adversarial loss: 0.561412\n",
      "epoch 55; iter: 0; batch classifier loss: 0.418474; batch adversarial loss: 0.573020\n",
      "epoch 56; iter: 0; batch classifier loss: 0.478361; batch adversarial loss: 0.506976\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441067; batch adversarial loss: 0.475468\n",
      "epoch 58; iter: 0; batch classifier loss: 0.484326; batch adversarial loss: 0.509113\n",
      "epoch 59; iter: 0; batch classifier loss: 0.379150; batch adversarial loss: 0.459857\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402801; batch adversarial loss: 0.526958\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427135; batch adversarial loss: 0.573584\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396243; batch adversarial loss: 0.563069\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378594; batch adversarial loss: 0.468376\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436367; batch adversarial loss: 0.525553\n",
      "epoch 65; iter: 0; batch classifier loss: 0.454617; batch adversarial loss: 0.459682\n",
      "epoch 66; iter: 0; batch classifier loss: 0.375969; batch adversarial loss: 0.497106\n",
      "epoch 67; iter: 0; batch classifier loss: 0.516899; batch adversarial loss: 0.487834\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455377; batch adversarial loss: 0.580639\n",
      "epoch 69; iter: 0; batch classifier loss: 0.369677; batch adversarial loss: 0.525656\n",
      "epoch 70; iter: 0; batch classifier loss: 0.450995; batch adversarial loss: 0.562574\n",
      "epoch 71; iter: 0; batch classifier loss: 0.361748; batch adversarial loss: 0.506179\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392833; batch adversarial loss: 0.488350\n",
      "epoch 73; iter: 0; batch classifier loss: 0.358370; batch adversarial loss: 0.524006\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388138; batch adversarial loss: 0.553144\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393092; batch adversarial loss: 0.533986\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388635; batch adversarial loss: 0.517552\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387533; batch adversarial loss: 0.592526\n",
      "epoch 78; iter: 0; batch classifier loss: 0.432231; batch adversarial loss: 0.434591\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390186; batch adversarial loss: 0.495836\n",
      "epoch 80; iter: 0; batch classifier loss: 0.355745; batch adversarial loss: 0.714366\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390139; batch adversarial loss: 0.488257\n",
      "epoch 82; iter: 0; batch classifier loss: 0.331482; batch adversarial loss: 0.459177\n",
      "epoch 83; iter: 0; batch classifier loss: 0.335361; batch adversarial loss: 0.562416\n",
      "epoch 84; iter: 0; batch classifier loss: 0.434719; batch adversarial loss: 0.516380\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456283; batch adversarial loss: 0.525226\n",
      "epoch 86; iter: 0; batch classifier loss: 0.348216; batch adversarial loss: 0.496289\n",
      "epoch 87; iter: 0; batch classifier loss: 0.319266; batch adversarial loss: 0.479680\n",
      "epoch 88; iter: 0; batch classifier loss: 0.456309; batch adversarial loss: 0.497280\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374376; batch adversarial loss: 0.479570\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362178; batch adversarial loss: 0.562757\n",
      "epoch 91; iter: 0; batch classifier loss: 0.317290; batch adversarial loss: 0.637753\n",
      "epoch 92; iter: 0; batch classifier loss: 0.337731; batch adversarial loss: 0.547331\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367037; batch adversarial loss: 0.497411\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303631; batch adversarial loss: 0.536406\n",
      "epoch 95; iter: 0; batch classifier loss: 0.471107; batch adversarial loss: 0.592136\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390557; batch adversarial loss: 0.516159\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436004; batch adversarial loss: 0.543794\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397102; batch adversarial loss: 0.523954\n",
      "epoch 99; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.562509\n",
      "epoch 100; iter: 0; batch classifier loss: 0.482215; batch adversarial loss: 0.496068\n",
      "epoch 101; iter: 0; batch classifier loss: 0.378959; batch adversarial loss: 0.580747\n",
      "epoch 102; iter: 0; batch classifier loss: 0.463751; batch adversarial loss: 0.525845\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365535; batch adversarial loss: 0.554004\n",
      "epoch 104; iter: 0; batch classifier loss: 0.453104; batch adversarial loss: 0.487624\n",
      "epoch 105; iter: 0; batch classifier loss: 0.436299; batch adversarial loss: 0.468767\n",
      "epoch 106; iter: 0; batch classifier loss: 0.498447; batch adversarial loss: 0.497862\n",
      "epoch 107; iter: 0; batch classifier loss: 0.335224; batch adversarial loss: 0.515964\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385785; batch adversarial loss: 0.535564\n",
      "epoch 109; iter: 0; batch classifier loss: 0.304076; batch adversarial loss: 0.582788\n",
      "epoch 110; iter: 0; batch classifier loss: 0.413330; batch adversarial loss: 0.533344\n",
      "epoch 111; iter: 0; batch classifier loss: 0.383040; batch adversarial loss: 0.498267\n",
      "epoch 112; iter: 0; batch classifier loss: 0.441528; batch adversarial loss: 0.506710\n",
      "epoch 113; iter: 0; batch classifier loss: 0.465714; batch adversarial loss: 0.562727\n",
      "epoch 114; iter: 0; batch classifier loss: 0.314060; batch adversarial loss: 0.516546\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380960; batch adversarial loss: 0.542581\n",
      "epoch 116; iter: 0; batch classifier loss: 0.404749; batch adversarial loss: 0.545947\n",
      "epoch 117; iter: 0; batch classifier loss: 0.320482; batch adversarial loss: 0.451010\n",
      "epoch 118; iter: 0; batch classifier loss: 0.353129; batch adversarial loss: 0.534967\n",
      "epoch 119; iter: 0; batch classifier loss: 0.292284; batch adversarial loss: 0.564933\n",
      "epoch 120; iter: 0; batch classifier loss: 0.395973; batch adversarial loss: 0.630470\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370065; batch adversarial loss: 0.563476\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350098; batch adversarial loss: 0.612580\n",
      "epoch 123; iter: 0; batch classifier loss: 0.439384; batch adversarial loss: 0.544475\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404484; batch adversarial loss: 0.450178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.471628; batch adversarial loss: 0.593405\n",
      "epoch 126; iter: 0; batch classifier loss: 0.340286; batch adversarial loss: 0.591167\n",
      "epoch 127; iter: 0; batch classifier loss: 0.446197; batch adversarial loss: 0.592533\n",
      "epoch 128; iter: 0; batch classifier loss: 0.445917; batch adversarial loss: 0.533554\n",
      "epoch 129; iter: 0; batch classifier loss: 0.431351; batch adversarial loss: 0.451124\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363046; batch adversarial loss: 0.553109\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381028; batch adversarial loss: 0.524753\n",
      "epoch 132; iter: 0; batch classifier loss: 0.338925; batch adversarial loss: 0.534301\n",
      "epoch 133; iter: 0; batch classifier loss: 0.420204; batch adversarial loss: 0.613927\n",
      "epoch 134; iter: 0; batch classifier loss: 0.345735; batch adversarial loss: 0.616081\n",
      "epoch 135; iter: 0; batch classifier loss: 0.288746; batch adversarial loss: 0.518073\n",
      "epoch 136; iter: 0; batch classifier loss: 0.325937; batch adversarial loss: 0.603523\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371275; batch adversarial loss: 0.494525\n",
      "epoch 138; iter: 0; batch classifier loss: 0.422832; batch adversarial loss: 0.478320\n",
      "epoch 139; iter: 0; batch classifier loss: 0.422711; batch adversarial loss: 0.559789\n",
      "epoch 140; iter: 0; batch classifier loss: 0.419498; batch adversarial loss: 0.524853\n",
      "epoch 141; iter: 0; batch classifier loss: 0.416211; batch adversarial loss: 0.553291\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386690; batch adversarial loss: 0.566506\n",
      "epoch 143; iter: 0; batch classifier loss: 0.312499; batch adversarial loss: 0.576330\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339977; batch adversarial loss: 0.601529\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385135; batch adversarial loss: 0.554694\n",
      "epoch 146; iter: 0; batch classifier loss: 0.348026; batch adversarial loss: 0.592716\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365331; batch adversarial loss: 0.533988\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412416; batch adversarial loss: 0.524084\n",
      "epoch 149; iter: 0; batch classifier loss: 0.394520; batch adversarial loss: 0.487563\n",
      "epoch 150; iter: 0; batch classifier loss: 0.312320; batch adversarial loss: 0.479243\n",
      "epoch 151; iter: 0; batch classifier loss: 0.457092; batch adversarial loss: 0.612725\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395014; batch adversarial loss: 0.545599\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333513; batch adversarial loss: 0.488728\n",
      "epoch 154; iter: 0; batch classifier loss: 0.322916; batch adversarial loss: 0.507291\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314998; batch adversarial loss: 0.526527\n",
      "epoch 156; iter: 0; batch classifier loss: 0.386282; batch adversarial loss: 0.609049\n",
      "epoch 157; iter: 0; batch classifier loss: 0.354565; batch adversarial loss: 0.562758\n",
      "epoch 158; iter: 0; batch classifier loss: 0.417909; batch adversarial loss: 0.525363\n",
      "epoch 159; iter: 0; batch classifier loss: 0.355420; batch adversarial loss: 0.515043\n",
      "epoch 160; iter: 0; batch classifier loss: 0.397170; batch adversarial loss: 0.488563\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356654; batch adversarial loss: 0.610625\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326319; batch adversarial loss: 0.487031\n",
      "epoch 163; iter: 0; batch classifier loss: 0.454914; batch adversarial loss: 0.563040\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387053; batch adversarial loss: 0.544341\n",
      "epoch 165; iter: 0; batch classifier loss: 0.331400; batch adversarial loss: 0.460394\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374051; batch adversarial loss: 0.563488\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329855; batch adversarial loss: 0.600542\n",
      "epoch 168; iter: 0; batch classifier loss: 0.386168; batch adversarial loss: 0.477672\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341558; batch adversarial loss: 0.600830\n",
      "epoch 170; iter: 0; batch classifier loss: 0.377714; batch adversarial loss: 0.553047\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340257; batch adversarial loss: 0.573593\n",
      "epoch 172; iter: 0; batch classifier loss: 0.418021; batch adversarial loss: 0.638051\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383821; batch adversarial loss: 0.515092\n",
      "epoch 174; iter: 0; batch classifier loss: 0.414534; batch adversarial loss: 0.524334\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368736; batch adversarial loss: 0.591079\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382194; batch adversarial loss: 0.506522\n",
      "epoch 177; iter: 0; batch classifier loss: 0.457652; batch adversarial loss: 0.534697\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382980; batch adversarial loss: 0.515788\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384266; batch adversarial loss: 0.657715\n",
      "epoch 180; iter: 0; batch classifier loss: 0.380899; batch adversarial loss: 0.554292\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423572; batch adversarial loss: 0.592166\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348660; batch adversarial loss: 0.545043\n",
      "epoch 183; iter: 0; batch classifier loss: 0.334841; batch adversarial loss: 0.582949\n",
      "epoch 184; iter: 0; batch classifier loss: 0.295618; batch adversarial loss: 0.544350\n",
      "epoch 185; iter: 0; batch classifier loss: 0.423690; batch adversarial loss: 0.534736\n",
      "epoch 186; iter: 0; batch classifier loss: 0.413216; batch adversarial loss: 0.590609\n",
      "epoch 187; iter: 0; batch classifier loss: 0.405533; batch adversarial loss: 0.554110\n",
      "epoch 188; iter: 0; batch classifier loss: 0.342318; batch adversarial loss: 0.553437\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364398; batch adversarial loss: 0.581494\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345298; batch adversarial loss: 0.563437\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338811; batch adversarial loss: 0.535255\n",
      "epoch 192; iter: 0; batch classifier loss: 0.310780; batch adversarial loss: 0.544501\n",
      "epoch 193; iter: 0; batch classifier loss: 0.301228; batch adversarial loss: 0.459215\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318416; batch adversarial loss: 0.496947\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332649; batch adversarial loss: 0.535490\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374661; batch adversarial loss: 0.535519\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364174; batch adversarial loss: 0.525927\n",
      "epoch 198; iter: 0; batch classifier loss: 0.442622; batch adversarial loss: 0.525854\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351573; batch adversarial loss: 0.658393\n",
      "epoch 0; iter: 0; batch classifier loss: 0.760285; batch adversarial loss: 0.617031\n",
      "epoch 1; iter: 0; batch classifier loss: 0.664495; batch adversarial loss: 0.670118\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542454; batch adversarial loss: 0.681031\n",
      "epoch 3; iter: 0; batch classifier loss: 0.528527; batch adversarial loss: 0.627810\n",
      "epoch 4; iter: 0; batch classifier loss: 0.675111; batch adversarial loss: 0.634694\n",
      "epoch 5; iter: 0; batch classifier loss: 0.535601; batch adversarial loss: 0.595674\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548561; batch adversarial loss: 0.689129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556011; batch adversarial loss: 0.580065\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498839; batch adversarial loss: 0.623423\n",
      "epoch 9; iter: 0; batch classifier loss: 0.611551; batch adversarial loss: 0.670223\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541946; batch adversarial loss: 0.570600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535223; batch adversarial loss: 0.637588\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586476; batch adversarial loss: 0.620115\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549278; batch adversarial loss: 0.534861\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413628; batch adversarial loss: 0.575660\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550535; batch adversarial loss: 0.558748\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527782; batch adversarial loss: 0.626130\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516974; batch adversarial loss: 0.545174\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456714; batch adversarial loss: 0.590546\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508512; batch adversarial loss: 0.551479\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378676; batch adversarial loss: 0.563335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.460174; batch adversarial loss: 0.617921\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513137; batch adversarial loss: 0.548043\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472697; batch adversarial loss: 0.502690\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477936; batch adversarial loss: 0.528934\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489564; batch adversarial loss: 0.479275\n",
      "epoch 26; iter: 0; batch classifier loss: 0.555729; batch adversarial loss: 0.622317\n",
      "epoch 27; iter: 0; batch classifier loss: 0.392757; batch adversarial loss: 0.544645\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515443; batch adversarial loss: 0.547791\n",
      "epoch 29; iter: 0; batch classifier loss: 0.522201; batch adversarial loss: 0.611804\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457220; batch adversarial loss: 0.528265\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452891; batch adversarial loss: 0.616493\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500761; batch adversarial loss: 0.517747\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475486; batch adversarial loss: 0.518253\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435447; batch adversarial loss: 0.491629\n",
      "epoch 35; iter: 0; batch classifier loss: 0.386710; batch adversarial loss: 0.491975\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421419; batch adversarial loss: 0.491868\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412806; batch adversarial loss: 0.526970\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425170; batch adversarial loss: 0.517694\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449899; batch adversarial loss: 0.544419\n",
      "epoch 40; iter: 0; batch classifier loss: 0.433024; batch adversarial loss: 0.509541\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466897; batch adversarial loss: 0.517582\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429236; batch adversarial loss: 0.570482\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483475; batch adversarial loss: 0.589720\n",
      "epoch 44; iter: 0; batch classifier loss: 0.486899; batch adversarial loss: 0.553260\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400887; batch adversarial loss: 0.590629\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454167; batch adversarial loss: 0.508909\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471403; batch adversarial loss: 0.535688\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447298; batch adversarial loss: 0.588595\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408686; batch adversarial loss: 0.508446\n",
      "epoch 50; iter: 0; batch classifier loss: 0.362121; batch adversarial loss: 0.553532\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440394; batch adversarial loss: 0.489243\n",
      "epoch 52; iter: 0; batch classifier loss: 0.503884; batch adversarial loss: 0.662990\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414795; batch adversarial loss: 0.562243\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417259; batch adversarial loss: 0.524867\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410434; batch adversarial loss: 0.563250\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390719; batch adversarial loss: 0.507516\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403952; batch adversarial loss: 0.635858\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417017; batch adversarial loss: 0.528221\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449601; batch adversarial loss: 0.572329\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428668; batch adversarial loss: 0.606738\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423865; batch adversarial loss: 0.579407\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396429; batch adversarial loss: 0.608082\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421632; batch adversarial loss: 0.602597\n",
      "epoch 64; iter: 0; batch classifier loss: 0.446906; batch adversarial loss: 0.563396\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401406; batch adversarial loss: 0.571423\n",
      "epoch 66; iter: 0; batch classifier loss: 0.489222; batch adversarial loss: 0.535406\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430390; batch adversarial loss: 0.497191\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442867; batch adversarial loss: 0.534631\n",
      "epoch 69; iter: 0; batch classifier loss: 0.452274; batch adversarial loss: 0.627167\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434777; batch adversarial loss: 0.534691\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394746; batch adversarial loss: 0.507712\n",
      "epoch 72; iter: 0; batch classifier loss: 0.395217; batch adversarial loss: 0.480835\n",
      "epoch 73; iter: 0; batch classifier loss: 0.452997; batch adversarial loss: 0.644689\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394129; batch adversarial loss: 0.526997\n",
      "epoch 75; iter: 0; batch classifier loss: 0.482933; batch adversarial loss: 0.525714\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383285; batch adversarial loss: 0.583007\n",
      "epoch 77; iter: 0; batch classifier loss: 0.370867; batch adversarial loss: 0.553996\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387619; batch adversarial loss: 0.562774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.438183; batch adversarial loss: 0.563107\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414562; batch adversarial loss: 0.516800\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365657; batch adversarial loss: 0.643800\n",
      "epoch 82; iter: 0; batch classifier loss: 0.470403; batch adversarial loss: 0.562949\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396597; batch adversarial loss: 0.526267\n",
      "epoch 84; iter: 0; batch classifier loss: 0.358309; batch adversarial loss: 0.508294\n",
      "epoch 85; iter: 0; batch classifier loss: 0.388037; batch adversarial loss: 0.536563\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435184; batch adversarial loss: 0.479869\n",
      "epoch 87; iter: 0; batch classifier loss: 0.403867; batch adversarial loss: 0.498391\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405170; batch adversarial loss: 0.525419\n",
      "epoch 89; iter: 0; batch classifier loss: 0.351009; batch adversarial loss: 0.480730\n",
      "epoch 90; iter: 0; batch classifier loss: 0.357538; batch adversarial loss: 0.599167\n",
      "epoch 91; iter: 0; batch classifier loss: 0.341436; batch adversarial loss: 0.489428\n",
      "epoch 92; iter: 0; batch classifier loss: 0.477105; batch adversarial loss: 0.498242\n",
      "epoch 93; iter: 0; batch classifier loss: 0.350516; batch adversarial loss: 0.571091\n",
      "epoch 94; iter: 0; batch classifier loss: 0.347043; batch adversarial loss: 0.543902\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391845; batch adversarial loss: 0.562120\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349918; batch adversarial loss: 0.461517\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381196; batch adversarial loss: 0.561742\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351741; batch adversarial loss: 0.581102\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414395; batch adversarial loss: 0.507348\n",
      "epoch 100; iter: 0; batch classifier loss: 0.479202; batch adversarial loss: 0.488519\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387706; batch adversarial loss: 0.498607\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330569; batch adversarial loss: 0.470751\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402626; batch adversarial loss: 0.507480\n",
      "epoch 104; iter: 0; batch classifier loss: 0.431056; batch adversarial loss: 0.555551\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391274; batch adversarial loss: 0.498666\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398597; batch adversarial loss: 0.581122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.367706; batch adversarial loss: 0.608166\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385476; batch adversarial loss: 0.535770\n",
      "epoch 109; iter: 0; batch classifier loss: 0.350619; batch adversarial loss: 0.491107\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343022; batch adversarial loss: 0.616406\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354439; batch adversarial loss: 0.472456\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386796; batch adversarial loss: 0.508381\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356215; batch adversarial loss: 0.517557\n",
      "epoch 114; iter: 0; batch classifier loss: 0.274459; batch adversarial loss: 0.536130\n",
      "epoch 115; iter: 0; batch classifier loss: 0.493326; batch adversarial loss: 0.607283\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387482; batch adversarial loss: 0.634895\n",
      "epoch 117; iter: 0; batch classifier loss: 0.397589; batch adversarial loss: 0.616970\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394696; batch adversarial loss: 0.507936\n",
      "epoch 119; iter: 0; batch classifier loss: 0.406798; batch adversarial loss: 0.553563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.383267; batch adversarial loss: 0.663092\n",
      "epoch 121; iter: 0; batch classifier loss: 0.448811; batch adversarial loss: 0.498604\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379435; batch adversarial loss: 0.544296\n",
      "epoch 123; iter: 0; batch classifier loss: 0.393580; batch adversarial loss: 0.608185\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418360; batch adversarial loss: 0.544815\n",
      "epoch 125; iter: 0; batch classifier loss: 0.354569; batch adversarial loss: 0.553645\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394156; batch adversarial loss: 0.572230\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372704; batch adversarial loss: 0.553695\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379949; batch adversarial loss: 0.572411\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379451; batch adversarial loss: 0.552227\n",
      "epoch 130; iter: 0; batch classifier loss: 0.401900; batch adversarial loss: 0.544656\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336614; batch adversarial loss: 0.526231\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415740; batch adversarial loss: 0.525809\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397916; batch adversarial loss: 0.554683\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416797; batch adversarial loss: 0.554911\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372453; batch adversarial loss: 0.543055\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366579; batch adversarial loss: 0.462605\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359018; batch adversarial loss: 0.561673\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346617; batch adversarial loss: 0.461899\n",
      "epoch 139; iter: 0; batch classifier loss: 0.290847; batch adversarial loss: 0.544470\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377158; batch adversarial loss: 0.489844\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375746; batch adversarial loss: 0.553031\n",
      "epoch 142; iter: 0; batch classifier loss: 0.365944; batch adversarial loss: 0.597856\n",
      "epoch 143; iter: 0; batch classifier loss: 0.333434; batch adversarial loss: 0.635858\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357031; batch adversarial loss: 0.590924\n",
      "epoch 145; iter: 0; batch classifier loss: 0.450304; batch adversarial loss: 0.580401\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332866; batch adversarial loss: 0.526837\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358916; batch adversarial loss: 0.525540\n",
      "epoch 148; iter: 0; batch classifier loss: 0.476928; batch adversarial loss: 0.472088\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367286; batch adversarial loss: 0.592235\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339722; batch adversarial loss: 0.472619\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356886; batch adversarial loss: 0.599527\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342858; batch adversarial loss: 0.518116\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356962; batch adversarial loss: 0.471481\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393445; batch adversarial loss: 0.636442\n",
      "epoch 155; iter: 0; batch classifier loss: 0.319493; batch adversarial loss: 0.572107\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390707; batch adversarial loss: 0.489976\n",
      "epoch 157; iter: 0; batch classifier loss: 0.428450; batch adversarial loss: 0.637245\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346180; batch adversarial loss: 0.627630\n",
      "epoch 159; iter: 0; batch classifier loss: 0.320284; batch adversarial loss: 0.527010\n",
      "epoch 160; iter: 0; batch classifier loss: 0.334081; batch adversarial loss: 0.515710\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363135; batch adversarial loss: 0.517422\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364005; batch adversarial loss: 0.562056\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366896; batch adversarial loss: 0.471233\n",
      "epoch 164; iter: 0; batch classifier loss: 0.290643; batch adversarial loss: 0.543575\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361884; batch adversarial loss: 0.534562\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340827; batch adversarial loss: 0.653332\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401322; batch adversarial loss: 0.545262\n",
      "epoch 168; iter: 0; batch classifier loss: 0.360565; batch adversarial loss: 0.553560\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371428; batch adversarial loss: 0.588985\n",
      "epoch 170; iter: 0; batch classifier loss: 0.468759; batch adversarial loss: 0.545016\n",
      "epoch 171; iter: 0; batch classifier loss: 0.289818; batch adversarial loss: 0.518150\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377773; batch adversarial loss: 0.599755\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345597; batch adversarial loss: 0.499773\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364562; batch adversarial loss: 0.462294\n",
      "epoch 175; iter: 0; batch classifier loss: 0.379781; batch adversarial loss: 0.561709\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329640; batch adversarial loss: 0.507882\n",
      "epoch 177; iter: 0; batch classifier loss: 0.428946; batch adversarial loss: 0.607810\n",
      "epoch 178; iter: 0; batch classifier loss: 0.405239; batch adversarial loss: 0.499129\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352061; batch adversarial loss: 0.572814\n",
      "epoch 180; iter: 0; batch classifier loss: 0.308515; batch adversarial loss: 0.581733\n",
      "epoch 181; iter: 0; batch classifier loss: 0.484201; batch adversarial loss: 0.507042\n",
      "epoch 182; iter: 0; batch classifier loss: 0.283492; batch adversarial loss: 0.535555\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355551; batch adversarial loss: 0.599480\n",
      "epoch 184; iter: 0; batch classifier loss: 0.405307; batch adversarial loss: 0.608132\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383449; batch adversarial loss: 0.490682\n",
      "epoch 186; iter: 0; batch classifier loss: 0.423454; batch adversarial loss: 0.589349\n",
      "epoch 187; iter: 0; batch classifier loss: 0.272352; batch adversarial loss: 0.526100\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381911; batch adversarial loss: 0.497870\n",
      "epoch 189; iter: 0; batch classifier loss: 0.434530; batch adversarial loss: 0.652667\n",
      "epoch 190; iter: 0; batch classifier loss: 0.394164; batch adversarial loss: 0.680422\n",
      "epoch 191; iter: 0; batch classifier loss: 0.460013; batch adversarial loss: 0.570119\n",
      "epoch 192; iter: 0; batch classifier loss: 0.395773; batch adversarial loss: 0.589597\n",
      "epoch 193; iter: 0; batch classifier loss: 0.411063; batch adversarial loss: 0.543158\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315981; batch adversarial loss: 0.616576\n",
      "epoch 195; iter: 0; batch classifier loss: 0.287480; batch adversarial loss: 0.536428\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327072; batch adversarial loss: 0.544117\n",
      "epoch 197; iter: 0; batch classifier loss: 0.379969; batch adversarial loss: 0.524756\n",
      "epoch 198; iter: 0; batch classifier loss: 0.399777; batch adversarial loss: 0.552673\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366147; batch adversarial loss: 0.544941\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661546; batch adversarial loss: 0.650537\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609754; batch adversarial loss: 0.669353\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581985; batch adversarial loss: 0.634787\n",
      "epoch 3; iter: 0; batch classifier loss: 0.514271; batch adversarial loss: 0.629794\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580836; batch adversarial loss: 0.639099\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635488; batch adversarial loss: 0.653373\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492854; batch adversarial loss: 0.613355\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598152; batch adversarial loss: 0.625261\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578672; batch adversarial loss: 0.654719\n",
      "epoch 9; iter: 0; batch classifier loss: 0.628416; batch adversarial loss: 0.581829\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545374; batch adversarial loss: 0.606169\n",
      "epoch 11; iter: 0; batch classifier loss: 0.587348; batch adversarial loss: 0.563785\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549056; batch adversarial loss: 0.522186\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600470; batch adversarial loss: 0.581304\n",
      "epoch 14; iter: 0; batch classifier loss: 0.584110; batch adversarial loss: 0.554965\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562324; batch adversarial loss: 0.525970\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467808; batch adversarial loss: 0.535160\n",
      "epoch 17; iter: 0; batch classifier loss: 0.555475; batch adversarial loss: 0.530672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.460184; batch adversarial loss: 0.582017\n",
      "epoch 19; iter: 0; batch classifier loss: 0.547144; batch adversarial loss: 0.565526\n",
      "epoch 20; iter: 0; batch classifier loss: 0.599075; batch adversarial loss: 0.605333\n",
      "epoch 21; iter: 0; batch classifier loss: 0.430034; batch adversarial loss: 0.526988\n",
      "epoch 22; iter: 0; batch classifier loss: 0.518661; batch adversarial loss: 0.550545\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420992; batch adversarial loss: 0.553768\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448571; batch adversarial loss: 0.499399\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505593; batch adversarial loss: 0.512926\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440730; batch adversarial loss: 0.585854\n",
      "epoch 27; iter: 0; batch classifier loss: 0.588120; batch adversarial loss: 0.553750\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460155; batch adversarial loss: 0.509484\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424030; batch adversarial loss: 0.507679\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464785; batch adversarial loss: 0.576899\n",
      "epoch 31; iter: 0; batch classifier loss: 0.413741; batch adversarial loss: 0.523179\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443009; batch adversarial loss: 0.649664\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441881; batch adversarial loss: 0.514301\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461580; batch adversarial loss: 0.517778\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451328; batch adversarial loss: 0.471391\n",
      "epoch 36; iter: 0; batch classifier loss: 0.373962; batch adversarial loss: 0.605335\n",
      "epoch 37; iter: 0; batch classifier loss: 0.395801; batch adversarial loss: 0.541269\n",
      "epoch 38; iter: 0; batch classifier loss: 0.391270; batch adversarial loss: 0.539308\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427202; batch adversarial loss: 0.542029\n",
      "epoch 40; iter: 0; batch classifier loss: 0.489643; batch adversarial loss: 0.620756\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459672; batch adversarial loss: 0.594000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.515049; batch adversarial loss: 0.534202\n",
      "epoch 43; iter: 0; batch classifier loss: 0.514481; batch adversarial loss: 0.666337\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382576; batch adversarial loss: 0.595382\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443895; batch adversarial loss: 0.453329\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410582; batch adversarial loss: 0.528647\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444997; batch adversarial loss: 0.534674\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420026; batch adversarial loss: 0.486520\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435569; batch adversarial loss: 0.467431\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411370; batch adversarial loss: 0.617386\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397743; batch adversarial loss: 0.561390\n",
      "epoch 52; iter: 0; batch classifier loss: 0.507859; batch adversarial loss: 0.562755\n",
      "epoch 53; iter: 0; batch classifier loss: 0.448773; batch adversarial loss: 0.544437\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404942; batch adversarial loss: 0.568893\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417154; batch adversarial loss: 0.480860\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390265; batch adversarial loss: 0.608041\n",
      "epoch 57; iter: 0; batch classifier loss: 0.418265; batch adversarial loss: 0.601100\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430439; batch adversarial loss: 0.516684\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435838; batch adversarial loss: 0.630434\n",
      "epoch 60; iter: 0; batch classifier loss: 0.460474; batch adversarial loss: 0.560336\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416691; batch adversarial loss: 0.590592\n",
      "epoch 62; iter: 0; batch classifier loss: 0.372325; batch adversarial loss: 0.584084\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408905; batch adversarial loss: 0.496606\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405257; batch adversarial loss: 0.624320\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445305; batch adversarial loss: 0.567926\n",
      "epoch 66; iter: 0; batch classifier loss: 0.344637; batch adversarial loss: 0.541918\n",
      "epoch 67; iter: 0; batch classifier loss: 0.323635; batch adversarial loss: 0.533966\n",
      "epoch 68; iter: 0; batch classifier loss: 0.367078; batch adversarial loss: 0.488966\n",
      "epoch 69; iter: 0; batch classifier loss: 0.312048; batch adversarial loss: 0.525726\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369542; batch adversarial loss: 0.583174\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419396; batch adversarial loss: 0.470842\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429265; batch adversarial loss: 0.582770\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431666; batch adversarial loss: 0.512796\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441683; batch adversarial loss: 0.504079\n",
      "epoch 75; iter: 0; batch classifier loss: 0.349989; batch adversarial loss: 0.553162\n",
      "epoch 76; iter: 0; batch classifier loss: 0.345111; batch adversarial loss: 0.535759\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398895; batch adversarial loss: 0.536119\n",
      "epoch 78; iter: 0; batch classifier loss: 0.442478; batch adversarial loss: 0.471321\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395507; batch adversarial loss: 0.588395\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347269; batch adversarial loss: 0.561198\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398839; batch adversarial loss: 0.511625\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406363; batch adversarial loss: 0.479425\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404936; batch adversarial loss: 0.505371\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397945; batch adversarial loss: 0.591327\n",
      "epoch 85; iter: 0; batch classifier loss: 0.338619; batch adversarial loss: 0.525136\n",
      "epoch 86; iter: 0; batch classifier loss: 0.489248; batch adversarial loss: 0.568918\n",
      "epoch 87; iter: 0; batch classifier loss: 0.357722; batch adversarial loss: 0.543603\n",
      "epoch 88; iter: 0; batch classifier loss: 0.437226; batch adversarial loss: 0.585000\n",
      "epoch 89; iter: 0; batch classifier loss: 0.444282; batch adversarial loss: 0.571112\n",
      "epoch 90; iter: 0; batch classifier loss: 0.379730; batch adversarial loss: 0.485644\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432232; batch adversarial loss: 0.479349\n",
      "epoch 92; iter: 0; batch classifier loss: 0.463398; batch adversarial loss: 0.618042\n",
      "epoch 93; iter: 0; batch classifier loss: 0.464918; batch adversarial loss: 0.505550\n",
      "epoch 94; iter: 0; batch classifier loss: 0.429082; batch adversarial loss: 0.545481\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382086; batch adversarial loss: 0.528291\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376939; batch adversarial loss: 0.514640\n",
      "epoch 97; iter: 0; batch classifier loss: 0.460397; batch adversarial loss: 0.527109\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372142; batch adversarial loss: 0.544202\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402729; batch adversarial loss: 0.514284\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349042; batch adversarial loss: 0.479300\n",
      "epoch 101; iter: 0; batch classifier loss: 0.331682; batch adversarial loss: 0.518413\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323379; batch adversarial loss: 0.524388\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440254; batch adversarial loss: 0.580669\n",
      "epoch 104; iter: 0; batch classifier loss: 0.314175; batch adversarial loss: 0.480831\n",
      "epoch 105; iter: 0; batch classifier loss: 0.313855; batch adversarial loss: 0.666048\n",
      "epoch 106; iter: 0; batch classifier loss: 0.324476; batch adversarial loss: 0.527387\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386435; batch adversarial loss: 0.487011\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363918; batch adversarial loss: 0.581059\n",
      "epoch 109; iter: 0; batch classifier loss: 0.296595; batch adversarial loss: 0.496206\n",
      "epoch 110; iter: 0; batch classifier loss: 0.296902; batch adversarial loss: 0.522893\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336058; batch adversarial loss: 0.506403\n",
      "epoch 112; iter: 0; batch classifier loss: 0.400076; batch adversarial loss: 0.545726\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421350; batch adversarial loss: 0.501169\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363788; batch adversarial loss: 0.562619\n",
      "epoch 115; iter: 0; batch classifier loss: 0.305707; batch adversarial loss: 0.505931\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376167; batch adversarial loss: 0.581025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.404247; batch adversarial loss: 0.599580\n",
      "epoch 118; iter: 0; batch classifier loss: 0.441153; batch adversarial loss: 0.514169\n",
      "epoch 119; iter: 0; batch classifier loss: 0.434902; batch adversarial loss: 0.526608\n",
      "epoch 120; iter: 0; batch classifier loss: 0.317227; batch adversarial loss: 0.544666\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366811; batch adversarial loss: 0.562758\n",
      "epoch 122; iter: 0; batch classifier loss: 0.370336; batch adversarial loss: 0.520582\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372165; batch adversarial loss: 0.527340\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367109; batch adversarial loss: 0.563781\n",
      "epoch 125; iter: 0; batch classifier loss: 0.414679; batch adversarial loss: 0.498181\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395959; batch adversarial loss: 0.547997\n",
      "epoch 127; iter: 0; batch classifier loss: 0.432277; batch adversarial loss: 0.570781\n",
      "epoch 128; iter: 0; batch classifier loss: 0.434716; batch adversarial loss: 0.536374\n",
      "epoch 129; iter: 0; batch classifier loss: 0.349011; batch adversarial loss: 0.535004\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396474; batch adversarial loss: 0.573169\n",
      "epoch 131; iter: 0; batch classifier loss: 0.465294; batch adversarial loss: 0.508932\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319178; batch adversarial loss: 0.565387\n",
      "epoch 133; iter: 0; batch classifier loss: 0.298353; batch adversarial loss: 0.535757\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378606; batch adversarial loss: 0.504707\n",
      "epoch 135; iter: 0; batch classifier loss: 0.419669; batch adversarial loss: 0.601111\n",
      "epoch 136; iter: 0; batch classifier loss: 0.275756; batch adversarial loss: 0.441473\n",
      "epoch 137; iter: 0; batch classifier loss: 0.325649; batch adversarial loss: 0.605870\n",
      "epoch 138; iter: 0; batch classifier loss: 0.372041; batch adversarial loss: 0.612742\n",
      "epoch 139; iter: 0; batch classifier loss: 0.382643; batch adversarial loss: 0.467222\n",
      "epoch 140; iter: 0; batch classifier loss: 0.326470; batch adversarial loss: 0.496461\n",
      "epoch 141; iter: 0; batch classifier loss: 0.438598; batch adversarial loss: 0.529136\n",
      "epoch 142; iter: 0; batch classifier loss: 0.295583; batch adversarial loss: 0.537763\n",
      "epoch 143; iter: 0; batch classifier loss: 0.327013; batch adversarial loss: 0.560815\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312431; batch adversarial loss: 0.553636\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412729; batch adversarial loss: 0.563152\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347794; batch adversarial loss: 0.542993\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376822; batch adversarial loss: 0.506318\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312991; batch adversarial loss: 0.546776\n",
      "epoch 149; iter: 0; batch classifier loss: 0.435894; batch adversarial loss: 0.523971\n",
      "epoch 150; iter: 0; batch classifier loss: 0.404100; batch adversarial loss: 0.562390\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348326; batch adversarial loss: 0.516570\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353990; batch adversarial loss: 0.600481\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379515; batch adversarial loss: 0.567941\n",
      "epoch 154; iter: 0; batch classifier loss: 0.449002; batch adversarial loss: 0.459292\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419589; batch adversarial loss: 0.523881\n",
      "epoch 156; iter: 0; batch classifier loss: 0.271218; batch adversarial loss: 0.545512\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350342; batch adversarial loss: 0.616207\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376553; batch adversarial loss: 0.535230\n",
      "epoch 159; iter: 0; batch classifier loss: 0.419401; batch adversarial loss: 0.479190\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377132; batch adversarial loss: 0.505657\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345049; batch adversarial loss: 0.545432\n",
      "epoch 162; iter: 0; batch classifier loss: 0.346140; batch adversarial loss: 0.599764\n",
      "epoch 163; iter: 0; batch classifier loss: 0.452387; batch adversarial loss: 0.506965\n",
      "epoch 164; iter: 0; batch classifier loss: 0.357487; batch adversarial loss: 0.536593\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418532; batch adversarial loss: 0.508608\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319965; batch adversarial loss: 0.514745\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347663; batch adversarial loss: 0.480334\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392180; batch adversarial loss: 0.527076\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355799; batch adversarial loss: 0.503600\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335727; batch adversarial loss: 0.507692\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326669; batch adversarial loss: 0.506571\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381666; batch adversarial loss: 0.535404\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382849; batch adversarial loss: 0.497418\n",
      "epoch 174; iter: 0; batch classifier loss: 0.410994; batch adversarial loss: 0.527488\n",
      "epoch 175; iter: 0; batch classifier loss: 0.307868; batch adversarial loss: 0.429628\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376850; batch adversarial loss: 0.552961\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378939; batch adversarial loss: 0.505542\n",
      "epoch 178; iter: 0; batch classifier loss: 0.430683; batch adversarial loss: 0.503328\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384958; batch adversarial loss: 0.619686\n",
      "epoch 180; iter: 0; batch classifier loss: 0.420316; batch adversarial loss: 0.500881\n",
      "epoch 181; iter: 0; batch classifier loss: 0.366965; batch adversarial loss: 0.583973\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389621; batch adversarial loss: 0.503251\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332487; batch adversarial loss: 0.496287\n",
      "epoch 184; iter: 0; batch classifier loss: 0.349672; batch adversarial loss: 0.508357\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320146; batch adversarial loss: 0.591617\n",
      "epoch 186; iter: 0; batch classifier loss: 0.435526; batch adversarial loss: 0.609061\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353670; batch adversarial loss: 0.541575\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404464; batch adversarial loss: 0.555687\n",
      "epoch 189; iter: 0; batch classifier loss: 0.304293; batch adversarial loss: 0.469553\n",
      "epoch 190; iter: 0; batch classifier loss: 0.432244; batch adversarial loss: 0.518002\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372175; batch adversarial loss: 0.646979\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355088; batch adversarial loss: 0.510379\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343648; batch adversarial loss: 0.517322\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368337; batch adversarial loss: 0.518046\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336670; batch adversarial loss: 0.519589\n",
      "epoch 196; iter: 0; batch classifier loss: 0.297040; batch adversarial loss: 0.563214\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322565; batch adversarial loss: 0.543287\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323412; batch adversarial loss: 0.527548\n",
      "epoch 199; iter: 0; batch classifier loss: 0.484684; batch adversarial loss: 0.561791\n",
      "epoch 0; iter: 0; batch classifier loss: 0.800741; batch adversarial loss: 0.506862\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555446; batch adversarial loss: 0.644763\n",
      "epoch 2; iter: 0; batch classifier loss: 0.500374; batch adversarial loss: 0.617755\n",
      "epoch 3; iter: 0; batch classifier loss: 0.516921; batch adversarial loss: 0.637280\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547820; batch adversarial loss: 0.660361\n",
      "epoch 5; iter: 0; batch classifier loss: 0.606057; batch adversarial loss: 0.635495\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509946; batch adversarial loss: 0.662720\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580242; batch adversarial loss: 0.637627\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485765; batch adversarial loss: 0.635063\n",
      "epoch 9; iter: 0; batch classifier loss: 0.590398; batch adversarial loss: 0.588132\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581523; batch adversarial loss: 0.603997\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530677; batch adversarial loss: 0.535161\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509936; batch adversarial loss: 0.613642\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487880; batch adversarial loss: 0.535619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.521471; batch adversarial loss: 0.485145\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537921; batch adversarial loss: 0.555243\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529665; batch adversarial loss: 0.594263\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494356; batch adversarial loss: 0.535572\n",
      "epoch 18; iter: 0; batch classifier loss: 0.418249; batch adversarial loss: 0.511920\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470377; batch adversarial loss: 0.567960\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489090; batch adversarial loss: 0.528653\n",
      "epoch 21; iter: 0; batch classifier loss: 0.418495; batch adversarial loss: 0.478294\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522495; batch adversarial loss: 0.564467\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445588; batch adversarial loss: 0.547665\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446010; batch adversarial loss: 0.530141\n",
      "epoch 25; iter: 0; batch classifier loss: 0.463058; batch adversarial loss: 0.537610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491321; batch adversarial loss: 0.545447\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437220; batch adversarial loss: 0.553354\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431386; batch adversarial loss: 0.527245\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436468; batch adversarial loss: 0.545938\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428517; batch adversarial loss: 0.473232\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458018; batch adversarial loss: 0.562416\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470303; batch adversarial loss: 0.471934\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443921; batch adversarial loss: 0.555160\n",
      "epoch 34; iter: 0; batch classifier loss: 0.402267; batch adversarial loss: 0.590553\n",
      "epoch 35; iter: 0; batch classifier loss: 0.544921; batch adversarial loss: 0.545620\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504915; batch adversarial loss: 0.572401\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460002; batch adversarial loss: 0.644414\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464702; batch adversarial loss: 0.562927\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438908; batch adversarial loss: 0.480906\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522263; batch adversarial loss: 0.563370\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476600; batch adversarial loss: 0.478191\n",
      "epoch 42; iter: 0; batch classifier loss: 0.521861; batch adversarial loss: 0.600189\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445419; batch adversarial loss: 0.507698\n",
      "epoch 44; iter: 0; batch classifier loss: 0.527711; batch adversarial loss: 0.432312\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445772; batch adversarial loss: 0.507295\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409391; batch adversarial loss: 0.507719\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413801; batch adversarial loss: 0.488798\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410951; batch adversarial loss: 0.497538\n",
      "epoch 49; iter: 0; batch classifier loss: 0.483168; batch adversarial loss: 0.619698\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429968; batch adversarial loss: 0.648629\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384768; batch adversarial loss: 0.525179\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408742; batch adversarial loss: 0.506526\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439599; batch adversarial loss: 0.545676\n",
      "epoch 54; iter: 0; batch classifier loss: 0.343525; batch adversarial loss: 0.544257\n",
      "epoch 55; iter: 0; batch classifier loss: 0.464355; batch adversarial loss: 0.469880\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457258; batch adversarial loss: 0.535313\n",
      "epoch 57; iter: 0; batch classifier loss: 0.378666; batch adversarial loss: 0.488392\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389455; batch adversarial loss: 0.517167\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384844; batch adversarial loss: 0.583842\n",
      "epoch 60; iter: 0; batch classifier loss: 0.453826; batch adversarial loss: 0.525781\n",
      "epoch 61; iter: 0; batch classifier loss: 0.369292; batch adversarial loss: 0.562467\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395426; batch adversarial loss: 0.488093\n",
      "epoch 63; iter: 0; batch classifier loss: 0.528315; batch adversarial loss: 0.593072\n",
      "epoch 64; iter: 0; batch classifier loss: 0.541310; batch adversarial loss: 0.506935\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445411; batch adversarial loss: 0.537125\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447406; batch adversarial loss: 0.610736\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360331; batch adversarial loss: 0.637586\n",
      "epoch 68; iter: 0; batch classifier loss: 0.374892; batch adversarial loss: 0.591244\n",
      "epoch 69; iter: 0; batch classifier loss: 0.488510; batch adversarial loss: 0.655794\n",
      "epoch 70; iter: 0; batch classifier loss: 0.338852; batch adversarial loss: 0.609160\n",
      "epoch 71; iter: 0; batch classifier loss: 0.498210; batch adversarial loss: 0.450437\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422834; batch adversarial loss: 0.513995\n",
      "epoch 73; iter: 0; batch classifier loss: 0.354807; batch adversarial loss: 0.572023\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406050; batch adversarial loss: 0.569904\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401267; batch adversarial loss: 0.524459\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335529; batch adversarial loss: 0.514949\n",
      "epoch 77; iter: 0; batch classifier loss: 0.384141; batch adversarial loss: 0.534188\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370093; batch adversarial loss: 0.504249\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397309; batch adversarial loss: 0.535583\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426047; batch adversarial loss: 0.565469\n",
      "epoch 81; iter: 0; batch classifier loss: 0.335483; batch adversarial loss: 0.527125\n",
      "epoch 82; iter: 0; batch classifier loss: 0.442484; batch adversarial loss: 0.450260\n",
      "epoch 83; iter: 0; batch classifier loss: 0.439558; batch adversarial loss: 0.592373\n",
      "epoch 84; iter: 0; batch classifier loss: 0.472082; batch adversarial loss: 0.514134\n",
      "epoch 85; iter: 0; batch classifier loss: 0.469939; batch adversarial loss: 0.554041\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425399; batch adversarial loss: 0.526323\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374725; batch adversarial loss: 0.475398\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394327; batch adversarial loss: 0.527213\n",
      "epoch 89; iter: 0; batch classifier loss: 0.343903; batch adversarial loss: 0.439694\n",
      "epoch 90; iter: 0; batch classifier loss: 0.471033; batch adversarial loss: 0.495624\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374995; batch adversarial loss: 0.527040\n",
      "epoch 92; iter: 0; batch classifier loss: 0.444280; batch adversarial loss: 0.554010\n",
      "epoch 93; iter: 0; batch classifier loss: 0.314484; batch adversarial loss: 0.563984\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358134; batch adversarial loss: 0.544084\n",
      "epoch 95; iter: 0; batch classifier loss: 0.479404; batch adversarial loss: 0.507890\n",
      "epoch 96; iter: 0; batch classifier loss: 0.437129; batch adversarial loss: 0.584267\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397367; batch adversarial loss: 0.525327\n",
      "epoch 98; iter: 0; batch classifier loss: 0.459555; batch adversarial loss: 0.546693\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424787; batch adversarial loss: 0.526605\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364451; batch adversarial loss: 0.639429\n",
      "epoch 101; iter: 0; batch classifier loss: 0.303697; batch adversarial loss: 0.468025\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372999; batch adversarial loss: 0.526010\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426709; batch adversarial loss: 0.516022\n",
      "epoch 104; iter: 0; batch classifier loss: 0.477531; batch adversarial loss: 0.498344\n",
      "epoch 105; iter: 0; batch classifier loss: 0.338051; batch adversarial loss: 0.534303\n",
      "epoch 106; iter: 0; batch classifier loss: 0.368704; batch adversarial loss: 0.505392\n",
      "epoch 107; iter: 0; batch classifier loss: 0.336084; batch adversarial loss: 0.516032\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422105; batch adversarial loss: 0.478733\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363078; batch adversarial loss: 0.506639\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395517; batch adversarial loss: 0.494163\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376973; batch adversarial loss: 0.594332\n",
      "epoch 112; iter: 0; batch classifier loss: 0.315633; batch adversarial loss: 0.524814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.372550; batch adversarial loss: 0.534821\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402514; batch adversarial loss: 0.622198\n",
      "epoch 115; iter: 0; batch classifier loss: 0.432579; batch adversarial loss: 0.478904\n",
      "epoch 116; iter: 0; batch classifier loss: 0.421021; batch adversarial loss: 0.609192\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376823; batch adversarial loss: 0.526495\n",
      "epoch 118; iter: 0; batch classifier loss: 0.428294; batch adversarial loss: 0.590256\n",
      "epoch 119; iter: 0; batch classifier loss: 0.328214; batch adversarial loss: 0.458933\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349927; batch adversarial loss: 0.564928\n",
      "epoch 121; iter: 0; batch classifier loss: 0.353304; batch adversarial loss: 0.566288\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398893; batch adversarial loss: 0.555341\n",
      "epoch 123; iter: 0; batch classifier loss: 0.398259; batch adversarial loss: 0.508246\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407275; batch adversarial loss: 0.469563\n",
      "epoch 125; iter: 0; batch classifier loss: 0.338995; batch adversarial loss: 0.535792\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394518; batch adversarial loss: 0.515402\n",
      "epoch 127; iter: 0; batch classifier loss: 0.347660; batch adversarial loss: 0.573510\n",
      "epoch 128; iter: 0; batch classifier loss: 0.457307; batch adversarial loss: 0.504830\n",
      "epoch 129; iter: 0; batch classifier loss: 0.426059; batch adversarial loss: 0.582668\n",
      "epoch 130; iter: 0; batch classifier loss: 0.462494; batch adversarial loss: 0.505037\n",
      "epoch 131; iter: 0; batch classifier loss: 0.301599; batch adversarial loss: 0.621232\n",
      "epoch 132; iter: 0; batch classifier loss: 0.337355; batch adversarial loss: 0.544823\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353152; batch adversarial loss: 0.505931\n",
      "epoch 134; iter: 0; batch classifier loss: 0.433972; batch adversarial loss: 0.563837\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343292; batch adversarial loss: 0.507086\n",
      "epoch 136; iter: 0; batch classifier loss: 0.349420; batch adversarial loss: 0.583139\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374893; batch adversarial loss: 0.508534\n",
      "epoch 138; iter: 0; batch classifier loss: 0.399702; batch adversarial loss: 0.589072\n",
      "epoch 139; iter: 0; batch classifier loss: 0.331047; batch adversarial loss: 0.560606\n",
      "epoch 140; iter: 0; batch classifier loss: 0.429982; batch adversarial loss: 0.525943\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348652; batch adversarial loss: 0.479064\n",
      "epoch 142; iter: 0; batch classifier loss: 0.388467; batch adversarial loss: 0.555356\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356852; batch adversarial loss: 0.443936\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380426; batch adversarial loss: 0.574393\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331023; batch adversarial loss: 0.592092\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360598; batch adversarial loss: 0.617904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.435065; batch adversarial loss: 0.541909\n",
      "epoch 148; iter: 0; batch classifier loss: 0.513713; batch adversarial loss: 0.562628\n",
      "epoch 149; iter: 0; batch classifier loss: 0.301323; batch adversarial loss: 0.525150\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373131; batch adversarial loss: 0.564516\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379205; batch adversarial loss: 0.637767\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364382; batch adversarial loss: 0.479288\n",
      "epoch 153; iter: 0; batch classifier loss: 0.474803; batch adversarial loss: 0.537665\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348459; batch adversarial loss: 0.487855\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349238; batch adversarial loss: 0.572423\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381166; batch adversarial loss: 0.525082\n",
      "epoch 157; iter: 0; batch classifier loss: 0.437469; batch adversarial loss: 0.638599\n",
      "epoch 158; iter: 0; batch classifier loss: 0.371128; batch adversarial loss: 0.534771\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415425; batch adversarial loss: 0.545689\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353395; batch adversarial loss: 0.554339\n",
      "epoch 161; iter: 0; batch classifier loss: 0.379290; batch adversarial loss: 0.492367\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355376; batch adversarial loss: 0.620123\n",
      "epoch 163; iter: 0; batch classifier loss: 0.522536; batch adversarial loss: 0.526156\n",
      "epoch 164; iter: 0; batch classifier loss: 0.313487; batch adversarial loss: 0.592535\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372808; batch adversarial loss: 0.591012\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349171; batch adversarial loss: 0.618841\n",
      "epoch 167; iter: 0; batch classifier loss: 0.424351; batch adversarial loss: 0.515347\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335963; batch adversarial loss: 0.489120\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354476; batch adversarial loss: 0.554022\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324589; batch adversarial loss: 0.499423\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338325; batch adversarial loss: 0.478079\n",
      "epoch 172; iter: 0; batch classifier loss: 0.380268; batch adversarial loss: 0.593890\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381854; batch adversarial loss: 0.630312\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393311; batch adversarial loss: 0.583123\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332700; batch adversarial loss: 0.490938\n",
      "epoch 176; iter: 0; batch classifier loss: 0.406530; batch adversarial loss: 0.563657\n",
      "epoch 177; iter: 0; batch classifier loss: 0.379246; batch adversarial loss: 0.573573\n",
      "epoch 178; iter: 0; batch classifier loss: 0.356180; batch adversarial loss: 0.514060\n",
      "epoch 179; iter: 0; batch classifier loss: 0.338750; batch adversarial loss: 0.686206\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344787; batch adversarial loss: 0.544057\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350726; batch adversarial loss: 0.514790\n",
      "epoch 182; iter: 0; batch classifier loss: 0.360119; batch adversarial loss: 0.527665\n",
      "epoch 183; iter: 0; batch classifier loss: 0.410981; batch adversarial loss: 0.487424\n",
      "epoch 184; iter: 0; batch classifier loss: 0.395975; batch adversarial loss: 0.552589\n",
      "epoch 185; iter: 0; batch classifier loss: 0.394117; batch adversarial loss: 0.469810\n",
      "epoch 186; iter: 0; batch classifier loss: 0.396110; batch adversarial loss: 0.507219\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326224; batch adversarial loss: 0.591589\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366933; batch adversarial loss: 0.563287\n",
      "epoch 189; iter: 0; batch classifier loss: 0.423852; batch adversarial loss: 0.535600\n",
      "epoch 190; iter: 0; batch classifier loss: 0.362164; batch adversarial loss: 0.504963\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378727; batch adversarial loss: 0.562763\n",
      "epoch 192; iter: 0; batch classifier loss: 0.383072; batch adversarial loss: 0.581921\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372482; batch adversarial loss: 0.505867\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322242; batch adversarial loss: 0.581745\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341198; batch adversarial loss: 0.525770\n",
      "epoch 196; iter: 0; batch classifier loss: 0.348519; batch adversarial loss: 0.554377\n",
      "epoch 197; iter: 0; batch classifier loss: 0.379622; batch adversarial loss: 0.564874\n",
      "epoch 198; iter: 0; batch classifier loss: 0.283168; batch adversarial loss: 0.516634\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340128; batch adversarial loss: 0.600788\n",
      "epoch 0; iter: 0; batch classifier loss: 0.848168; batch adversarial loss: 0.517547\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608265; batch adversarial loss: 0.644872\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574016; batch adversarial loss: 0.688320\n",
      "epoch 3; iter: 0; batch classifier loss: 0.643460; batch adversarial loss: 0.652632\n",
      "epoch 4; iter: 0; batch classifier loss: 0.554076; batch adversarial loss: 0.698941\n",
      "epoch 5; iter: 0; batch classifier loss: 0.472789; batch adversarial loss: 0.604810\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552686; batch adversarial loss: 0.632067\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574636; batch adversarial loss: 0.615357\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577646; batch adversarial loss: 0.573824\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536685; batch adversarial loss: 0.626897\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548148; batch adversarial loss: 0.591698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.596606; batch adversarial loss: 0.654553\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554489; batch adversarial loss: 0.589511\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518805; batch adversarial loss: 0.577293\n",
      "epoch 14; iter: 0; batch classifier loss: 0.569885; batch adversarial loss: 0.626575\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556949; batch adversarial loss: 0.641700\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469334; batch adversarial loss: 0.574567\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484757; batch adversarial loss: 0.570772\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545768; batch adversarial loss: 0.572212\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542209; batch adversarial loss: 0.556065\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491547; batch adversarial loss: 0.549957\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502448; batch adversarial loss: 0.548005\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464075; batch adversarial loss: 0.491684\n",
      "epoch 23; iter: 0; batch classifier loss: 0.510379; batch adversarial loss: 0.516024\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471762; batch adversarial loss: 0.555255\n",
      "epoch 25; iter: 0; batch classifier loss: 0.450909; batch adversarial loss: 0.497332\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527489; batch adversarial loss: 0.487154\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455075; batch adversarial loss: 0.570616\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493846; batch adversarial loss: 0.552948\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475556; batch adversarial loss: 0.509672\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551488; batch adversarial loss: 0.509837\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481840; batch adversarial loss: 0.545206\n",
      "epoch 32; iter: 0; batch classifier loss: 0.463280; batch adversarial loss: 0.527857\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474298; batch adversarial loss: 0.534396\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462937; batch adversarial loss: 0.546576\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479360; batch adversarial loss: 0.545944\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424320; batch adversarial loss: 0.543173\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475870; batch adversarial loss: 0.535140\n",
      "epoch 38; iter: 0; batch classifier loss: 0.423060; batch adversarial loss: 0.581676\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482097; batch adversarial loss: 0.506943\n",
      "epoch 40; iter: 0; batch classifier loss: 0.539239; batch adversarial loss: 0.528234\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451057; batch adversarial loss: 0.534996\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432929; batch adversarial loss: 0.472658\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445439; batch adversarial loss: 0.607982\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414118; batch adversarial loss: 0.598765\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451824; batch adversarial loss: 0.516239\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437188; batch adversarial loss: 0.609525\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441788; batch adversarial loss: 0.450124\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464218; batch adversarial loss: 0.499123\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408532; batch adversarial loss: 0.508569\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442149; batch adversarial loss: 0.562595\n",
      "epoch 51; iter: 0; batch classifier loss: 0.498857; batch adversarial loss: 0.479173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385934; batch adversarial loss: 0.553423\n",
      "epoch 53; iter: 0; batch classifier loss: 0.433331; batch adversarial loss: 0.580729\n",
      "epoch 54; iter: 0; batch classifier loss: 0.372964; batch adversarial loss: 0.517413\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437683; batch adversarial loss: 0.590303\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423202; batch adversarial loss: 0.601161\n",
      "epoch 57; iter: 0; batch classifier loss: 0.460061; batch adversarial loss: 0.515660\n",
      "epoch 58; iter: 0; batch classifier loss: 0.534536; batch adversarial loss: 0.488445\n",
      "epoch 59; iter: 0; batch classifier loss: 0.436929; batch adversarial loss: 0.526199\n",
      "epoch 60; iter: 0; batch classifier loss: 0.465455; batch adversarial loss: 0.527126\n",
      "epoch 61; iter: 0; batch classifier loss: 0.493923; batch adversarial loss: 0.489005\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405930; batch adversarial loss: 0.480330\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418332; batch adversarial loss: 0.517065\n",
      "epoch 64; iter: 0; batch classifier loss: 0.349905; batch adversarial loss: 0.535477\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443494; batch adversarial loss: 0.534436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392065; batch adversarial loss: 0.544217\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403812; batch adversarial loss: 0.488796\n",
      "epoch 68; iter: 0; batch classifier loss: 0.379277; batch adversarial loss: 0.544776\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410215; batch adversarial loss: 0.610810\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380857; batch adversarial loss: 0.515729\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395985; batch adversarial loss: 0.497298\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380015; batch adversarial loss: 0.507222\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385414; batch adversarial loss: 0.544349\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372099; batch adversarial loss: 0.554143\n",
      "epoch 75; iter: 0; batch classifier loss: 0.439222; batch adversarial loss: 0.535168\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419187; batch adversarial loss: 0.535077\n",
      "epoch 77; iter: 0; batch classifier loss: 0.368800; batch adversarial loss: 0.506707\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341158; batch adversarial loss: 0.599310\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379490; batch adversarial loss: 0.506307\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408927; batch adversarial loss: 0.618585\n",
      "epoch 81; iter: 0; batch classifier loss: 0.357614; batch adversarial loss: 0.497838\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375257; batch adversarial loss: 0.571722\n",
      "epoch 83; iter: 0; batch classifier loss: 0.464057; batch adversarial loss: 0.533646\n",
      "epoch 84; iter: 0; batch classifier loss: 0.463377; batch adversarial loss: 0.534335\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392629; batch adversarial loss: 0.498532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.442764; batch adversarial loss: 0.525566\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413829; batch adversarial loss: 0.507703\n",
      "epoch 88; iter: 0; batch classifier loss: 0.346245; batch adversarial loss: 0.553793\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388577; batch adversarial loss: 0.545808\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405631; batch adversarial loss: 0.498769\n",
      "epoch 91; iter: 0; batch classifier loss: 0.418905; batch adversarial loss: 0.507878\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412511; batch adversarial loss: 0.497866\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364296; batch adversarial loss: 0.488106\n",
      "epoch 94; iter: 0; batch classifier loss: 0.395764; batch adversarial loss: 0.517006\n",
      "epoch 95; iter: 0; batch classifier loss: 0.517210; batch adversarial loss: 0.553004\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419323; batch adversarial loss: 0.571753\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346429; batch adversarial loss: 0.609858\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369282; batch adversarial loss: 0.534919\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413055; batch adversarial loss: 0.394254\n",
      "epoch 100; iter: 0; batch classifier loss: 0.477963; batch adversarial loss: 0.480953\n",
      "epoch 101; iter: 0; batch classifier loss: 0.389027; batch adversarial loss: 0.590645\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369850; batch adversarial loss: 0.535272\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381732; batch adversarial loss: 0.554896\n",
      "epoch 104; iter: 0; batch classifier loss: 0.445484; batch adversarial loss: 0.573112\n",
      "epoch 105; iter: 0; batch classifier loss: 0.439590; batch adversarial loss: 0.468531\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367052; batch adversarial loss: 0.555084\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358037; batch adversarial loss: 0.544092\n",
      "epoch 108; iter: 0; batch classifier loss: 0.442923; batch adversarial loss: 0.451331\n",
      "epoch 109; iter: 0; batch classifier loss: 0.392703; batch adversarial loss: 0.553889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.475382; batch adversarial loss: 0.460261\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353669; batch adversarial loss: 0.497886\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360949; batch adversarial loss: 0.516564\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368680; batch adversarial loss: 0.591290\n",
      "epoch 114; iter: 0; batch classifier loss: 0.454728; batch adversarial loss: 0.554433\n",
      "epoch 115; iter: 0; batch classifier loss: 0.403251; batch adversarial loss: 0.684547\n",
      "epoch 116; iter: 0; batch classifier loss: 0.283039; batch adversarial loss: 0.469493\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415716; batch adversarial loss: 0.563362\n",
      "epoch 118; iter: 0; batch classifier loss: 0.418202; batch adversarial loss: 0.581179\n",
      "epoch 119; iter: 0; batch classifier loss: 0.298026; batch adversarial loss: 0.516914\n",
      "epoch 120; iter: 0; batch classifier loss: 0.448280; batch adversarial loss: 0.525527\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389476; batch adversarial loss: 0.544828\n",
      "epoch 122; iter: 0; batch classifier loss: 0.438823; batch adversarial loss: 0.535233\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373295; batch adversarial loss: 0.600353\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352512; batch adversarial loss: 0.535078\n",
      "epoch 125; iter: 0; batch classifier loss: 0.429149; batch adversarial loss: 0.470269\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338880; batch adversarial loss: 0.442568\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377350; batch adversarial loss: 0.525296\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350109; batch adversarial loss: 0.599915\n",
      "epoch 129; iter: 0; batch classifier loss: 0.417927; batch adversarial loss: 0.517163\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356422; batch adversarial loss: 0.609129\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348465; batch adversarial loss: 0.609667\n",
      "epoch 132; iter: 0; batch classifier loss: 0.379106; batch adversarial loss: 0.581271\n",
      "epoch 133; iter: 0; batch classifier loss: 0.400473; batch adversarial loss: 0.590736\n",
      "epoch 134; iter: 0; batch classifier loss: 0.346039; batch adversarial loss: 0.619173\n",
      "epoch 135; iter: 0; batch classifier loss: 0.386907; batch adversarial loss: 0.516496\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425130; batch adversarial loss: 0.563315\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382014; batch adversarial loss: 0.563664\n",
      "epoch 138; iter: 0; batch classifier loss: 0.457023; batch adversarial loss: 0.580814\n",
      "epoch 139; iter: 0; batch classifier loss: 0.321506; batch adversarial loss: 0.544271\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340418; batch adversarial loss: 0.497192\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366146; batch adversarial loss: 0.533749\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375453; batch adversarial loss: 0.544774\n",
      "epoch 143; iter: 0; batch classifier loss: 0.392593; batch adversarial loss: 0.545256\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415924; batch adversarial loss: 0.544567\n",
      "epoch 145; iter: 0; batch classifier loss: 0.419692; batch adversarial loss: 0.535140\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345907; batch adversarial loss: 0.526756\n",
      "epoch 147; iter: 0; batch classifier loss: 0.408524; batch adversarial loss: 0.499665\n",
      "epoch 148; iter: 0; batch classifier loss: 0.413843; batch adversarial loss: 0.478498\n",
      "epoch 149; iter: 0; batch classifier loss: 0.380209; batch adversarial loss: 0.610097\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375904; batch adversarial loss: 0.498161\n",
      "epoch 151; iter: 0; batch classifier loss: 0.380624; batch adversarial loss: 0.478910\n",
      "epoch 152; iter: 0; batch classifier loss: 0.302802; batch adversarial loss: 0.563247\n",
      "epoch 153; iter: 0; batch classifier loss: 0.421995; batch adversarial loss: 0.525729\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344240; batch adversarial loss: 0.572406\n",
      "epoch 155; iter: 0; batch classifier loss: 0.396055; batch adversarial loss: 0.526203\n",
      "epoch 156; iter: 0; batch classifier loss: 0.405157; batch adversarial loss: 0.609869\n",
      "epoch 157; iter: 0; batch classifier loss: 0.505103; batch adversarial loss: 0.526008\n",
      "epoch 158; iter: 0; batch classifier loss: 0.406496; batch adversarial loss: 0.507436\n",
      "epoch 159; iter: 0; batch classifier loss: 0.287820; batch adversarial loss: 0.461367\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350438; batch adversarial loss: 0.591428\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347906; batch adversarial loss: 0.535078\n",
      "epoch 162; iter: 0; batch classifier loss: 0.468200; batch adversarial loss: 0.572442\n",
      "epoch 163; iter: 0; batch classifier loss: 0.395609; batch adversarial loss: 0.469795\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342273; batch adversarial loss: 0.581752\n",
      "epoch 165; iter: 0; batch classifier loss: 0.324931; batch adversarial loss: 0.581079\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372047; batch adversarial loss: 0.590501\n",
      "epoch 167; iter: 0; batch classifier loss: 0.386932; batch adversarial loss: 0.572680\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351713; batch adversarial loss: 0.479091\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355895; batch adversarial loss: 0.507183\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382218; batch adversarial loss: 0.619228\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411074; batch adversarial loss: 0.516382\n",
      "epoch 172; iter: 0; batch classifier loss: 0.390100; batch adversarial loss: 0.572473\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355235; batch adversarial loss: 0.544709\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345820; batch adversarial loss: 0.506965\n",
      "epoch 175; iter: 0; batch classifier loss: 0.414911; batch adversarial loss: 0.535517\n",
      "epoch 176; iter: 0; batch classifier loss: 0.391833; batch adversarial loss: 0.553571\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387422; batch adversarial loss: 0.618652\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369008; batch adversarial loss: 0.479508\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352860; batch adversarial loss: 0.525721\n",
      "epoch 180; iter: 0; batch classifier loss: 0.276142; batch adversarial loss: 0.553287\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410384; batch adversarial loss: 0.516154\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366934; batch adversarial loss: 0.581546\n",
      "epoch 183; iter: 0; batch classifier loss: 0.411128; batch adversarial loss: 0.507401\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339891; batch adversarial loss: 0.470061\n",
      "epoch 185; iter: 0; batch classifier loss: 0.274061; batch adversarial loss: 0.544692\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385824; batch adversarial loss: 0.507192\n",
      "epoch 187; iter: 0; batch classifier loss: 0.424237; batch adversarial loss: 0.544859\n",
      "epoch 188; iter: 0; batch classifier loss: 0.291068; batch adversarial loss: 0.479587\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315188; batch adversarial loss: 0.535115\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328204; batch adversarial loss: 0.544970\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346293; batch adversarial loss: 0.563257\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328402; batch adversarial loss: 0.497875\n",
      "epoch 193; iter: 0; batch classifier loss: 0.424636; batch adversarial loss: 0.590641\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357307; batch adversarial loss: 0.534936\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361518; batch adversarial loss: 0.507373\n",
      "epoch 196; iter: 0; batch classifier loss: 0.415269; batch adversarial loss: 0.515939\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350635; batch adversarial loss: 0.627843\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387747; batch adversarial loss: 0.618750\n",
      "epoch 199; iter: 0; batch classifier loss: 0.372903; batch adversarial loss: 0.553680\n",
      "epoch 0; iter: 0; batch classifier loss: 0.653295; batch adversarial loss: 0.640970\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585051; batch adversarial loss: 0.607504\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603220; batch adversarial loss: 0.668306\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605054; batch adversarial loss: 0.630018\n",
      "epoch 4; iter: 0; batch classifier loss: 0.678972; batch adversarial loss: 0.616469\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558577; batch adversarial loss: 0.667725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.570823; batch adversarial loss: 0.599789\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481543; batch adversarial loss: 0.583691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505324; batch adversarial loss: 0.557257\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585455; batch adversarial loss: 0.578268\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508011; batch adversarial loss: 0.536135\n",
      "epoch 11; iter: 0; batch classifier loss: 0.583647; batch adversarial loss: 0.509740\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495319; batch adversarial loss: 0.570337\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548894; batch adversarial loss: 0.573364\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526091; batch adversarial loss: 0.611363\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509804; batch adversarial loss: 0.548110\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520559; batch adversarial loss: 0.616913\n",
      "epoch 17; iter: 0; batch classifier loss: 0.574053; batch adversarial loss: 0.511426\n",
      "epoch 18; iter: 0; batch classifier loss: 0.459909; batch adversarial loss: 0.562112\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510186; batch adversarial loss: 0.579656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.526058; batch adversarial loss: 0.493349\n",
      "epoch 21; iter: 0; batch classifier loss: 0.555644; batch adversarial loss: 0.575707\n",
      "epoch 22; iter: 0; batch classifier loss: 0.511510; batch adversarial loss: 0.511023\n",
      "epoch 23; iter: 0; batch classifier loss: 0.435347; batch adversarial loss: 0.554958\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489175; batch adversarial loss: 0.581437\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488700; batch adversarial loss: 0.585120\n",
      "epoch 26; iter: 0; batch classifier loss: 0.398018; batch adversarial loss: 0.562826\n",
      "epoch 27; iter: 0; batch classifier loss: 0.569634; batch adversarial loss: 0.599792\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477785; batch adversarial loss: 0.546207\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508698; batch adversarial loss: 0.626415\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438525; batch adversarial loss: 0.628712\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452257; batch adversarial loss: 0.604797\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430256; batch adversarial loss: 0.503163\n",
      "epoch 33; iter: 0; batch classifier loss: 0.545026; batch adversarial loss: 0.546178\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464665; batch adversarial loss: 0.543898\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419148; batch adversarial loss: 0.479952\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476856; batch adversarial loss: 0.517933\n",
      "epoch 37; iter: 0; batch classifier loss: 0.344330; batch adversarial loss: 0.532544\n",
      "epoch 38; iter: 0; batch classifier loss: 0.529865; batch adversarial loss: 0.552720\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479272; batch adversarial loss: 0.556504\n",
      "epoch 40; iter: 0; batch classifier loss: 0.514249; batch adversarial loss: 0.533845\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456308; batch adversarial loss: 0.517376\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444524; batch adversarial loss: 0.545525\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464774; batch adversarial loss: 0.520919\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431633; batch adversarial loss: 0.423194\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419394; batch adversarial loss: 0.518351\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433150; batch adversarial loss: 0.542386\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452866; batch adversarial loss: 0.552469\n",
      "epoch 48; iter: 0; batch classifier loss: 0.500105; batch adversarial loss: 0.537154\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472303; batch adversarial loss: 0.515071\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471847; batch adversarial loss: 0.527700\n",
      "epoch 51; iter: 0; batch classifier loss: 0.517915; batch adversarial loss: 0.636488\n",
      "epoch 52; iter: 0; batch classifier loss: 0.454895; batch adversarial loss: 0.543688\n",
      "epoch 53; iter: 0; batch classifier loss: 0.361970; batch adversarial loss: 0.562767\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393402; batch adversarial loss: 0.507096\n",
      "epoch 55; iter: 0; batch classifier loss: 0.391952; batch adversarial loss: 0.436046\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420457; batch adversarial loss: 0.562210\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471561; batch adversarial loss: 0.581631\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437705; batch adversarial loss: 0.564832\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417660; batch adversarial loss: 0.516195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439475; batch adversarial loss: 0.592411\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446891; batch adversarial loss: 0.525714\n",
      "epoch 62; iter: 0; batch classifier loss: 0.485045; batch adversarial loss: 0.606787\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421615; batch adversarial loss: 0.519058\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440335; batch adversarial loss: 0.578091\n",
      "epoch 65; iter: 0; batch classifier loss: 0.348292; batch adversarial loss: 0.579177\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460769; batch adversarial loss: 0.519156\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406756; batch adversarial loss: 0.544449\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406453; batch adversarial loss: 0.572761\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390582; batch adversarial loss: 0.579323\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426383; batch adversarial loss: 0.560058\n",
      "epoch 71; iter: 0; batch classifier loss: 0.518424; batch adversarial loss: 0.598449\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457591; batch adversarial loss: 0.570721\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377367; batch adversarial loss: 0.606452\n",
      "epoch 74; iter: 0; batch classifier loss: 0.461125; batch adversarial loss: 0.465376\n",
      "epoch 75; iter: 0; batch classifier loss: 0.434133; batch adversarial loss: 0.581799\n",
      "epoch 76; iter: 0; batch classifier loss: 0.438922; batch adversarial loss: 0.563380\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417138; batch adversarial loss: 0.563594\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377375; batch adversarial loss: 0.507079\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411961; batch adversarial loss: 0.579042\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442066; batch adversarial loss: 0.563060\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410535; batch adversarial loss: 0.537867\n",
      "epoch 82; iter: 0; batch classifier loss: 0.492802; batch adversarial loss: 0.618068\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372950; batch adversarial loss: 0.673111\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441793; batch adversarial loss: 0.535495\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411151; batch adversarial loss: 0.542610\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395001; batch adversarial loss: 0.534748\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378996; batch adversarial loss: 0.507532\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379085; batch adversarial loss: 0.571243\n",
      "epoch 89; iter: 0; batch classifier loss: 0.418910; batch adversarial loss: 0.506513\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369576; batch adversarial loss: 0.625281\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423787; batch adversarial loss: 0.553621\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375551; batch adversarial loss: 0.563492\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391626; batch adversarial loss: 0.629265\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382197; batch adversarial loss: 0.471797\n",
      "epoch 95; iter: 0; batch classifier loss: 0.388576; batch adversarial loss: 0.560618\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419900; batch adversarial loss: 0.581419\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388982; batch adversarial loss: 0.525956\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357783; batch adversarial loss: 0.509817\n",
      "epoch 99; iter: 0; batch classifier loss: 0.411921; batch adversarial loss: 0.517478\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355012; batch adversarial loss: 0.588066\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417056; batch adversarial loss: 0.543494\n",
      "epoch 102; iter: 0; batch classifier loss: 0.454020; batch adversarial loss: 0.544105\n",
      "epoch 103; iter: 0; batch classifier loss: 0.458979; batch adversarial loss: 0.597660\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362918; batch adversarial loss: 0.609260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.440415; batch adversarial loss: 0.534784\n",
      "epoch 106; iter: 0; batch classifier loss: 0.356473; batch adversarial loss: 0.569308\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393195; batch adversarial loss: 0.552762\n",
      "epoch 108; iter: 0; batch classifier loss: 0.394533; batch adversarial loss: 0.551285\n",
      "epoch 109; iter: 0; batch classifier loss: 0.482286; batch adversarial loss: 0.597908\n",
      "epoch 110; iter: 0; batch classifier loss: 0.342037; batch adversarial loss: 0.544217\n",
      "epoch 111; iter: 0; batch classifier loss: 0.458980; batch adversarial loss: 0.571260\n",
      "epoch 112; iter: 0; batch classifier loss: 0.425464; batch adversarial loss: 0.507818\n",
      "epoch 113; iter: 0; batch classifier loss: 0.398069; batch adversarial loss: 0.543707\n",
      "epoch 114; iter: 0; batch classifier loss: 0.443141; batch adversarial loss: 0.516130\n",
      "epoch 115; iter: 0; batch classifier loss: 0.449195; batch adversarial loss: 0.499438\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325532; batch adversarial loss: 0.516666\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406946; batch adversarial loss: 0.607514\n",
      "epoch 118; iter: 0; batch classifier loss: 0.450803; batch adversarial loss: 0.644702\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392022; batch adversarial loss: 0.526512\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413958; batch adversarial loss: 0.555915\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361635; batch adversarial loss: 0.516300\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380948; batch adversarial loss: 0.563984\n",
      "epoch 123; iter: 0; batch classifier loss: 0.321276; batch adversarial loss: 0.571737\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397528; batch adversarial loss: 0.507624\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383412; batch adversarial loss: 0.609785\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351116; batch adversarial loss: 0.582214\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381668; batch adversarial loss: 0.543859\n",
      "epoch 128; iter: 0; batch classifier loss: 0.334206; batch adversarial loss: 0.562102\n",
      "epoch 129; iter: 0; batch classifier loss: 0.429910; batch adversarial loss: 0.498140\n",
      "epoch 130; iter: 0; batch classifier loss: 0.337560; batch adversarial loss: 0.563190\n",
      "epoch 131; iter: 0; batch classifier loss: 0.461542; batch adversarial loss: 0.580502\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396601; batch adversarial loss: 0.554137\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410652; batch adversarial loss: 0.555193\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356194; batch adversarial loss: 0.509136\n",
      "epoch 135; iter: 0; batch classifier loss: 0.386747; batch adversarial loss: 0.508788\n",
      "epoch 136; iter: 0; batch classifier loss: 0.345098; batch adversarial loss: 0.562154\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367954; batch adversarial loss: 0.608729\n",
      "epoch 138; iter: 0; batch classifier loss: 0.334616; batch adversarial loss: 0.544782\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373457; batch adversarial loss: 0.609285\n",
      "epoch 140; iter: 0; batch classifier loss: 0.382782; batch adversarial loss: 0.637116\n",
      "epoch 141; iter: 0; batch classifier loss: 0.318118; batch adversarial loss: 0.489330\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331896; batch adversarial loss: 0.590531\n",
      "epoch 143; iter: 0; batch classifier loss: 0.336132; batch adversarial loss: 0.535558\n",
      "epoch 144; iter: 0; batch classifier loss: 0.393281; batch adversarial loss: 0.526362\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399573; batch adversarial loss: 0.443205\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368751; batch adversarial loss: 0.517480\n",
      "epoch 147; iter: 0; batch classifier loss: 0.451862; batch adversarial loss: 0.580334\n",
      "epoch 148; iter: 0; batch classifier loss: 0.419152; batch adversarial loss: 0.573177\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377051; batch adversarial loss: 0.560985\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379506; batch adversarial loss: 0.507992\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405127; batch adversarial loss: 0.563462\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369451; batch adversarial loss: 0.533515\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338913; batch adversarial loss: 0.444259\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385554; batch adversarial loss: 0.463358\n",
      "epoch 155; iter: 0; batch classifier loss: 0.422396; batch adversarial loss: 0.534686\n",
      "epoch 156; iter: 0; batch classifier loss: 0.397009; batch adversarial loss: 0.553685\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385134; batch adversarial loss: 0.562698\n",
      "epoch 158; iter: 0; batch classifier loss: 0.452414; batch adversarial loss: 0.508089\n",
      "epoch 159; iter: 0; batch classifier loss: 0.397956; batch adversarial loss: 0.435670\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368807; batch adversarial loss: 0.490702\n",
      "epoch 161; iter: 0; batch classifier loss: 0.407595; batch adversarial loss: 0.564156\n",
      "epoch 162; iter: 0; batch classifier loss: 0.403328; batch adversarial loss: 0.490152\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379987; batch adversarial loss: 0.552230\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387764; batch adversarial loss: 0.580010\n",
      "epoch 165; iter: 0; batch classifier loss: 0.423797; batch adversarial loss: 0.591466\n",
      "epoch 166; iter: 0; batch classifier loss: 0.427650; batch adversarial loss: 0.553922\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341805; batch adversarial loss: 0.480811\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363913; batch adversarial loss: 0.543175\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370979; batch adversarial loss: 0.490055\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355032; batch adversarial loss: 0.507017\n",
      "epoch 171; iter: 0; batch classifier loss: 0.356390; batch adversarial loss: 0.626315\n",
      "epoch 172; iter: 0; batch classifier loss: 0.382299; batch adversarial loss: 0.517562\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387031; batch adversarial loss: 0.517000\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396871; batch adversarial loss: 0.608383\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338721; batch adversarial loss: 0.545235\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354136; batch adversarial loss: 0.561539\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354221; batch adversarial loss: 0.626959\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371628; batch adversarial loss: 0.561266\n",
      "epoch 179; iter: 0; batch classifier loss: 0.314819; batch adversarial loss: 0.533734\n",
      "epoch 180; iter: 0; batch classifier loss: 0.332499; batch adversarial loss: 0.508111\n",
      "epoch 181; iter: 0; batch classifier loss: 0.466373; batch adversarial loss: 0.507373\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349419; batch adversarial loss: 0.598923\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388081; batch adversarial loss: 0.553486\n",
      "epoch 184; iter: 0; batch classifier loss: 0.471438; batch adversarial loss: 0.608850\n",
      "epoch 185; iter: 0; batch classifier loss: 0.420489; batch adversarial loss: 0.517423\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357022; batch adversarial loss: 0.526861\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313694; batch adversarial loss: 0.553955\n",
      "epoch 188; iter: 0; batch classifier loss: 0.459048; batch adversarial loss: 0.491153\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369768; batch adversarial loss: 0.544361\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375501; batch adversarial loss: 0.542803\n",
      "epoch 191; iter: 0; batch classifier loss: 0.446831; batch adversarial loss: 0.563189\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335938; batch adversarial loss: 0.572541\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345046; batch adversarial loss: 0.535764\n",
      "epoch 194; iter: 0; batch classifier loss: 0.452103; batch adversarial loss: 0.562451\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399900; batch adversarial loss: 0.608297\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346163; batch adversarial loss: 0.472761\n",
      "epoch 197; iter: 0; batch classifier loss: 0.436456; batch adversarial loss: 0.571704\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403573; batch adversarial loss: 0.508995\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357378; batch adversarial loss: 0.626189\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728124; batch adversarial loss: 0.756501\n",
      "epoch 1; iter: 0; batch classifier loss: 0.649951; batch adversarial loss: 0.734960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.796042; batch adversarial loss: 0.684232\n",
      "epoch 3; iter: 0; batch classifier loss: 0.587574; batch adversarial loss: 0.643985\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588641; batch adversarial loss: 0.617503\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575878; batch adversarial loss: 0.618648\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573771; batch adversarial loss: 0.628451\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570172; batch adversarial loss: 0.626048\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505872; batch adversarial loss: 0.607767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527661; batch adversarial loss: 0.611235\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528156; batch adversarial loss: 0.610420\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541508; batch adversarial loss: 0.582267\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511996; batch adversarial loss: 0.573425\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541412; batch adversarial loss: 0.550149\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552960; batch adversarial loss: 0.548359\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503815; batch adversarial loss: 0.571986\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495662; batch adversarial loss: 0.502606\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505367; batch adversarial loss: 0.521293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.440023; batch adversarial loss: 0.527323\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478958; batch adversarial loss: 0.506086\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493967; batch adversarial loss: 0.499167\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536441; batch adversarial loss: 0.543593\n",
      "epoch 22; iter: 0; batch classifier loss: 0.528012; batch adversarial loss: 0.506323\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523318; batch adversarial loss: 0.561228\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471398; batch adversarial loss: 0.552882\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506618; batch adversarial loss: 0.562131\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452060; batch adversarial loss: 0.522045\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453957; batch adversarial loss: 0.585132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471579; batch adversarial loss: 0.522901\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464700; batch adversarial loss: 0.558299\n",
      "epoch 30; iter: 0; batch classifier loss: 0.497028; batch adversarial loss: 0.604449\n",
      "epoch 31; iter: 0; batch classifier loss: 0.450130; batch adversarial loss: 0.531372\n",
      "epoch 32; iter: 0; batch classifier loss: 0.393228; batch adversarial loss: 0.504403\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474602; batch adversarial loss: 0.561777\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473189; batch adversarial loss: 0.484971\n",
      "epoch 35; iter: 0; batch classifier loss: 0.384730; batch adversarial loss: 0.607035\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494243; batch adversarial loss: 0.493962\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392967; batch adversarial loss: 0.645902\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468153; batch adversarial loss: 0.604542\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440710; batch adversarial loss: 0.571672\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500007; batch adversarial loss: 0.625131\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438527; batch adversarial loss: 0.545290\n",
      "epoch 42; iter: 0; batch classifier loss: 0.357791; batch adversarial loss: 0.517800\n",
      "epoch 43; iter: 0; batch classifier loss: 0.345389; batch adversarial loss: 0.510819\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407579; batch adversarial loss: 0.492085\n",
      "epoch 45; iter: 0; batch classifier loss: 0.378005; batch adversarial loss: 0.492132\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410980; batch adversarial loss: 0.579609\n",
      "epoch 47; iter: 0; batch classifier loss: 0.382852; batch adversarial loss: 0.536979\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443624; batch adversarial loss: 0.545670\n",
      "epoch 49; iter: 0; batch classifier loss: 0.359642; batch adversarial loss: 0.519196\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503806; batch adversarial loss: 0.481682\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438097; batch adversarial loss: 0.525704\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411403; batch adversarial loss: 0.553712\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374896; batch adversarial loss: 0.571046\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406729; batch adversarial loss: 0.553480\n",
      "epoch 55; iter: 0; batch classifier loss: 0.354656; batch adversarial loss: 0.598035\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415477; batch adversarial loss: 0.562702\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416875; batch adversarial loss: 0.562428\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419338; batch adversarial loss: 0.527210\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427249; batch adversarial loss: 0.526631\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451967; batch adversarial loss: 0.571613\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382146; batch adversarial loss: 0.490953\n",
      "epoch 62; iter: 0; batch classifier loss: 0.375424; batch adversarial loss: 0.562584\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450104; batch adversarial loss: 0.571407\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363503; batch adversarial loss: 0.633983\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374202; batch adversarial loss: 0.508700\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415555; batch adversarial loss: 0.526476\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412631; batch adversarial loss: 0.562508\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430681; batch adversarial loss: 0.607082\n",
      "epoch 69; iter: 0; batch classifier loss: 0.339744; batch adversarial loss: 0.598284\n",
      "epoch 70; iter: 0; batch classifier loss: 0.379448; batch adversarial loss: 0.535753\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480887; batch adversarial loss: 0.562379\n",
      "epoch 72; iter: 0; batch classifier loss: 0.363251; batch adversarial loss: 0.616040\n",
      "epoch 73; iter: 0; batch classifier loss: 0.318901; batch adversarial loss: 0.491836\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386374; batch adversarial loss: 0.607105\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422915; batch adversarial loss: 0.509048\n",
      "epoch 76; iter: 0; batch classifier loss: 0.460084; batch adversarial loss: 0.569837\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401412; batch adversarial loss: 0.553086\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390443; batch adversarial loss: 0.606774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417046; batch adversarial loss: 0.516472\n",
      "epoch 80; iter: 0; batch classifier loss: 0.315515; batch adversarial loss: 0.561355\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358988; batch adversarial loss: 0.543686\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387616; batch adversarial loss: 0.506993\n",
      "epoch 83; iter: 0; batch classifier loss: 0.447259; batch adversarial loss: 0.563171\n",
      "epoch 84; iter: 0; batch classifier loss: 0.345551; batch adversarial loss: 0.534307\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385377; batch adversarial loss: 0.535507\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374920; batch adversarial loss: 0.635684\n",
      "epoch 87; iter: 0; batch classifier loss: 0.323551; batch adversarial loss: 0.526299\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367614; batch adversarial loss: 0.626974\n",
      "epoch 89; iter: 0; batch classifier loss: 0.459374; batch adversarial loss: 0.608008\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417299; batch adversarial loss: 0.490138\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398911; batch adversarial loss: 0.517636\n",
      "epoch 92; iter: 0; batch classifier loss: 0.447369; batch adversarial loss: 0.508511\n",
      "epoch 93; iter: 0; batch classifier loss: 0.324498; batch adversarial loss: 0.625729\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406827; batch adversarial loss: 0.625541\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343473; batch adversarial loss: 0.562710\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443406; batch adversarial loss: 0.598455\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404932; batch adversarial loss: 0.607384\n",
      "epoch 98; iter: 0; batch classifier loss: 0.456410; batch adversarial loss: 0.553587\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350879; batch adversarial loss: 0.553610\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348999; batch adversarial loss: 0.526537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.393675; batch adversarial loss: 0.526435\n",
      "epoch 102; iter: 0; batch classifier loss: 0.341574; batch adversarial loss: 0.571619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.437148; batch adversarial loss: 0.571171\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374543; batch adversarial loss: 0.498652\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371354; batch adversarial loss: 0.551143\n",
      "epoch 106; iter: 0; batch classifier loss: 0.361207; batch adversarial loss: 0.590119\n",
      "epoch 107; iter: 0; batch classifier loss: 0.383156; batch adversarial loss: 0.467873\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351080; batch adversarial loss: 0.581191\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386701; batch adversarial loss: 0.570958\n",
      "epoch 110; iter: 0; batch classifier loss: 0.332369; batch adversarial loss: 0.509733\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406860; batch adversarial loss: 0.555372\n",
      "epoch 112; iter: 0; batch classifier loss: 0.406688; batch adversarial loss: 0.581479\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337903; batch adversarial loss: 0.643835\n",
      "epoch 114; iter: 0; batch classifier loss: 0.283145; batch adversarial loss: 0.580268\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371375; batch adversarial loss: 0.518241\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387154; batch adversarial loss: 0.517982\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382379; batch adversarial loss: 0.562302\n",
      "epoch 118; iter: 0; batch classifier loss: 0.314125; batch adversarial loss: 0.535596\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347829; batch adversarial loss: 0.501011\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379113; batch adversarial loss: 0.454982\n",
      "epoch 121; iter: 0; batch classifier loss: 0.374989; batch adversarial loss: 0.526985\n",
      "epoch 122; iter: 0; batch classifier loss: 0.347696; batch adversarial loss: 0.535156\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327498; batch adversarial loss: 0.536215\n",
      "epoch 124; iter: 0; batch classifier loss: 0.322915; batch adversarial loss: 0.588882\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375119; batch adversarial loss: 0.553217\n",
      "epoch 126; iter: 0; batch classifier loss: 0.432647; batch adversarial loss: 0.589181\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329147; batch adversarial loss: 0.491111\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343059; batch adversarial loss: 0.634866\n",
      "epoch 129; iter: 0; batch classifier loss: 0.404365; batch adversarial loss: 0.536054\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421697; batch adversarial loss: 0.624941\n",
      "epoch 131; iter: 0; batch classifier loss: 0.417458; batch adversarial loss: 0.464843\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388821; batch adversarial loss: 0.580397\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369747; batch adversarial loss: 0.491307\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351862; batch adversarial loss: 0.518067\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382612; batch adversarial loss: 0.632905\n",
      "epoch 136; iter: 0; batch classifier loss: 0.420069; batch adversarial loss: 0.535040\n",
      "epoch 137; iter: 0; batch classifier loss: 0.297099; batch adversarial loss: 0.580614\n",
      "epoch 138; iter: 0; batch classifier loss: 0.324163; batch adversarial loss: 0.570618\n",
      "epoch 139; iter: 0; batch classifier loss: 0.399405; batch adversarial loss: 0.492453\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405202; batch adversarial loss: 0.553968\n",
      "epoch 141; iter: 0; batch classifier loss: 0.420184; batch adversarial loss: 0.563853\n",
      "epoch 142; iter: 0; batch classifier loss: 0.349127; batch adversarial loss: 0.481015\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413019; batch adversarial loss: 0.564366\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351363; batch adversarial loss: 0.500692\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333891; batch adversarial loss: 0.535248\n",
      "epoch 146; iter: 0; batch classifier loss: 0.295264; batch adversarial loss: 0.616428\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393726; batch adversarial loss: 0.562843\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391326; batch adversarial loss: 0.481187\n",
      "epoch 149; iter: 0; batch classifier loss: 0.309877; batch adversarial loss: 0.607532\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371914; batch adversarial loss: 0.526441\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337296; batch adversarial loss: 0.562976\n",
      "epoch 152; iter: 0; batch classifier loss: 0.281457; batch adversarial loss: 0.553771\n",
      "epoch 153; iter: 0; batch classifier loss: 0.325334; batch adversarial loss: 0.606306\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350007; batch adversarial loss: 0.571588\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373205; batch adversarial loss: 0.571649\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373111; batch adversarial loss: 0.454505\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331385; batch adversarial loss: 0.607758\n",
      "epoch 158; iter: 0; batch classifier loss: 0.436477; batch adversarial loss: 0.544649\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372230; batch adversarial loss: 0.571077\n",
      "epoch 160; iter: 0; batch classifier loss: 0.298775; batch adversarial loss: 0.545262\n",
      "epoch 161; iter: 0; batch classifier loss: 0.288052; batch adversarial loss: 0.499579\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381118; batch adversarial loss: 0.580073\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382005; batch adversarial loss: 0.588151\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333542; batch adversarial loss: 0.552113\n",
      "epoch 165; iter: 0; batch classifier loss: 0.294258; batch adversarial loss: 0.553388\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354289; batch adversarial loss: 0.528140\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352685; batch adversarial loss: 0.545137\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317400; batch adversarial loss: 0.562720\n",
      "epoch 169; iter: 0; batch classifier loss: 0.286299; batch adversarial loss: 0.626420\n",
      "epoch 170; iter: 0; batch classifier loss: 0.282819; batch adversarial loss: 0.535193\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344436; batch adversarial loss: 0.526477\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355176; batch adversarial loss: 0.661261\n",
      "epoch 173; iter: 0; batch classifier loss: 0.287170; batch adversarial loss: 0.562625\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357608; batch adversarial loss: 0.535908\n",
      "epoch 175; iter: 0; batch classifier loss: 0.370553; batch adversarial loss: 0.518138\n",
      "epoch 176; iter: 0; batch classifier loss: 0.290650; batch adversarial loss: 0.527440\n",
      "epoch 177; iter: 0; batch classifier loss: 0.293621; batch adversarial loss: 0.527493\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328803; batch adversarial loss: 0.571236\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339121; batch adversarial loss: 0.544424\n",
      "epoch 180; iter: 0; batch classifier loss: 0.267577; batch adversarial loss: 0.561862\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353665; batch adversarial loss: 0.580425\n",
      "epoch 182; iter: 0; batch classifier loss: 0.283794; batch adversarial loss: 0.500746\n",
      "epoch 183; iter: 0; batch classifier loss: 0.326666; batch adversarial loss: 0.554479\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350166; batch adversarial loss: 0.553677\n",
      "epoch 185; iter: 0; batch classifier loss: 0.295350; batch adversarial loss: 0.536631\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315618; batch adversarial loss: 0.590149\n",
      "epoch 187; iter: 0; batch classifier loss: 0.417087; batch adversarial loss: 0.554004\n",
      "epoch 188; iter: 0; batch classifier loss: 0.303783; batch adversarial loss: 0.517796\n",
      "epoch 189; iter: 0; batch classifier loss: 0.325454; batch adversarial loss: 0.535478\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390477; batch adversarial loss: 0.580535\n",
      "epoch 191; iter: 0; batch classifier loss: 0.368449; batch adversarial loss: 0.570458\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351061; batch adversarial loss: 0.608506\n",
      "epoch 193; iter: 0; batch classifier loss: 0.404284; batch adversarial loss: 0.544798\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399796; batch adversarial loss: 0.571157\n",
      "epoch 195; iter: 0; batch classifier loss: 0.280514; batch adversarial loss: 0.536342\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310766; batch adversarial loss: 0.644519\n",
      "epoch 197; iter: 0; batch classifier loss: 0.334965; batch adversarial loss: 0.544956\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393239; batch adversarial loss: 0.499101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.378077; batch adversarial loss: 0.535837\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772791; batch adversarial loss: 0.667478\n",
      "epoch 1; iter: 0; batch classifier loss: 0.561906; batch adversarial loss: 0.666136\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609956; batch adversarial loss: 0.643942\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555541; batch adversarial loss: 0.603368\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520229; batch adversarial loss: 0.617695\n",
      "epoch 5; iter: 0; batch classifier loss: 0.560476; batch adversarial loss: 0.603797\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570713; batch adversarial loss: 0.663553\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550002; batch adversarial loss: 0.609636\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500856; batch adversarial loss: 0.632024\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541893; batch adversarial loss: 0.596550\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538005; batch adversarial loss: 0.599758\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536152; batch adversarial loss: 0.568901\n",
      "epoch 12; iter: 0; batch classifier loss: 0.597815; batch adversarial loss: 0.545344\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526692; batch adversarial loss: 0.548708\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523402; batch adversarial loss: 0.573192\n",
      "epoch 15; iter: 0; batch classifier loss: 0.603029; batch adversarial loss: 0.539190\n",
      "epoch 16; iter: 0; batch classifier loss: 0.426901; batch adversarial loss: 0.486244\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520413; batch adversarial loss: 0.600696\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502559; batch adversarial loss: 0.545040\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524405; batch adversarial loss: 0.605727\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462940; batch adversarial loss: 0.565876\n",
      "epoch 21; iter: 0; batch classifier loss: 0.531213; batch adversarial loss: 0.549234\n",
      "epoch 22; iter: 0; batch classifier loss: 0.544529; batch adversarial loss: 0.604045\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476047; batch adversarial loss: 0.533871\n",
      "epoch 24; iter: 0; batch classifier loss: 0.510362; batch adversarial loss: 0.578639\n",
      "epoch 25; iter: 0; batch classifier loss: 0.464439; batch adversarial loss: 0.592763\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466368; batch adversarial loss: 0.586609\n",
      "epoch 27; iter: 0; batch classifier loss: 0.452917; batch adversarial loss: 0.590259\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475851; batch adversarial loss: 0.562762\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443265; batch adversarial loss: 0.499662\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438796; batch adversarial loss: 0.536554\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494290; batch adversarial loss: 0.445086\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488969; batch adversarial loss: 0.533932\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469654; batch adversarial loss: 0.547644\n",
      "epoch 34; iter: 0; batch classifier loss: 0.370086; batch adversarial loss: 0.503150\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442961; batch adversarial loss: 0.563427\n",
      "epoch 36; iter: 0; batch classifier loss: 0.408850; batch adversarial loss: 0.559698\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483759; batch adversarial loss: 0.546670\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425976; batch adversarial loss: 0.563711\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420441; batch adversarial loss: 0.543783\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454636; batch adversarial loss: 0.544149\n",
      "epoch 41; iter: 0; batch classifier loss: 0.384553; batch adversarial loss: 0.580839\n",
      "epoch 42; iter: 0; batch classifier loss: 0.508966; batch adversarial loss: 0.609476\n",
      "epoch 43; iter: 0; batch classifier loss: 0.509399; batch adversarial loss: 0.497681\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437503; batch adversarial loss: 0.554140\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448347; batch adversarial loss: 0.545674\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429065; batch adversarial loss: 0.560115\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483282; batch adversarial loss: 0.597237\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485557; batch adversarial loss: 0.536868\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416789; batch adversarial loss: 0.618569\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451776; batch adversarial loss: 0.536230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444393; batch adversarial loss: 0.454180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411803; batch adversarial loss: 0.561558\n",
      "epoch 53; iter: 0; batch classifier loss: 0.338966; batch adversarial loss: 0.580936\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415760; batch adversarial loss: 0.596981\n",
      "epoch 55; iter: 0; batch classifier loss: 0.504455; batch adversarial loss: 0.444147\n",
      "epoch 56; iter: 0; batch classifier loss: 0.503992; batch adversarial loss: 0.579659\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404999; batch adversarial loss: 0.633614\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469256; batch adversarial loss: 0.499902\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404824; batch adversarial loss: 0.535327\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376031; batch adversarial loss: 0.562380\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397657; batch adversarial loss: 0.553353\n",
      "epoch 62; iter: 0; batch classifier loss: 0.365021; batch adversarial loss: 0.553583\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410996; batch adversarial loss: 0.535245\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410690; batch adversarial loss: 0.571596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382901; batch adversarial loss: 0.553926\n",
      "epoch 66; iter: 0; batch classifier loss: 0.375491; batch adversarial loss: 0.625697\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401675; batch adversarial loss: 0.570829\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397755; batch adversarial loss: 0.535704\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412354; batch adversarial loss: 0.562403\n",
      "epoch 70; iter: 0; batch classifier loss: 0.349278; batch adversarial loss: 0.535064\n",
      "epoch 71; iter: 0; batch classifier loss: 0.457241; batch adversarial loss: 0.472806\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355880; batch adversarial loss: 0.607711\n",
      "epoch 73; iter: 0; batch classifier loss: 0.344980; batch adversarial loss: 0.590544\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424953; batch adversarial loss: 0.525524\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391359; batch adversarial loss: 0.525571\n",
      "epoch 76; iter: 0; batch classifier loss: 0.327975; batch adversarial loss: 0.598711\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440807; batch adversarial loss: 0.571694\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448024; batch adversarial loss: 0.599893\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403922; batch adversarial loss: 0.490364\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390341; batch adversarial loss: 0.517398\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360400; batch adversarial loss: 0.544430\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383624; batch adversarial loss: 0.525505\n",
      "epoch 83; iter: 0; batch classifier loss: 0.351455; batch adversarial loss: 0.499014\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363116; batch adversarial loss: 0.553168\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411647; batch adversarial loss: 0.464098\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357262; batch adversarial loss: 0.571408\n",
      "epoch 87; iter: 0; batch classifier loss: 0.335627; batch adversarial loss: 0.626742\n",
      "epoch 88; iter: 0; batch classifier loss: 0.321562; batch adversarial loss: 0.563786\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412640; batch adversarial loss: 0.516494\n",
      "epoch 90; iter: 0; batch classifier loss: 0.385203; batch adversarial loss: 0.490147\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421811; batch adversarial loss: 0.472119\n",
      "epoch 92; iter: 0; batch classifier loss: 0.436428; batch adversarial loss: 0.517203\n",
      "epoch 93; iter: 0; batch classifier loss: 0.430833; batch adversarial loss: 0.535779\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410638; batch adversarial loss: 0.616412\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358094; batch adversarial loss: 0.444019\n",
      "epoch 96; iter: 0; batch classifier loss: 0.306188; batch adversarial loss: 0.580775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388862; batch adversarial loss: 0.544173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.389875; batch adversarial loss: 0.580640\n",
      "epoch 99; iter: 0; batch classifier loss: 0.447592; batch adversarial loss: 0.544724\n",
      "epoch 100; iter: 0; batch classifier loss: 0.536068; batch adversarial loss: 0.543858\n",
      "epoch 101; iter: 0; batch classifier loss: 0.320910; batch adversarial loss: 0.542654\n",
      "epoch 102; iter: 0; batch classifier loss: 0.419564; batch adversarial loss: 0.544556\n",
      "epoch 103; iter: 0; batch classifier loss: 0.470549; batch adversarial loss: 0.537598\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409541; batch adversarial loss: 0.564193\n",
      "epoch 105; iter: 0; batch classifier loss: 0.480038; batch adversarial loss: 0.572033\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355088; batch adversarial loss: 0.562943\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357689; batch adversarial loss: 0.624832\n",
      "epoch 108; iter: 0; batch classifier loss: 0.418550; batch adversarial loss: 0.525208\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331702; batch adversarial loss: 0.564019\n",
      "epoch 110; iter: 0; batch classifier loss: 0.331236; batch adversarial loss: 0.627581\n",
      "epoch 111; iter: 0; batch classifier loss: 0.457280; batch adversarial loss: 0.573895\n",
      "epoch 112; iter: 0; batch classifier loss: 0.333463; batch adversarial loss: 0.544495\n",
      "epoch 113; iter: 0; batch classifier loss: 0.334960; batch adversarial loss: 0.625906\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357419; batch adversarial loss: 0.498250\n",
      "epoch 115; iter: 0; batch classifier loss: 0.435215; batch adversarial loss: 0.561967\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376316; batch adversarial loss: 0.525831\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372499; batch adversarial loss: 0.492558\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405283; batch adversarial loss: 0.561490\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340569; batch adversarial loss: 0.562727\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349534; batch adversarial loss: 0.597902\n",
      "epoch 121; iter: 0; batch classifier loss: 0.296876; batch adversarial loss: 0.587950\n",
      "epoch 122; iter: 0; batch classifier loss: 0.439179; batch adversarial loss: 0.500409\n",
      "epoch 123; iter: 0; batch classifier loss: 0.298171; batch adversarial loss: 0.591178\n",
      "epoch 124; iter: 0; batch classifier loss: 0.427260; batch adversarial loss: 0.491860\n",
      "epoch 125; iter: 0; batch classifier loss: 0.417464; batch adversarial loss: 0.498907\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357993; batch adversarial loss: 0.499609\n",
      "epoch 127; iter: 0; batch classifier loss: 0.364731; batch adversarial loss: 0.453735\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392808; batch adversarial loss: 0.526645\n",
      "epoch 129; iter: 0; batch classifier loss: 0.408730; batch adversarial loss: 0.508468\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375994; batch adversarial loss: 0.508389\n",
      "epoch 131; iter: 0; batch classifier loss: 0.370129; batch adversarial loss: 0.489305\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421934; batch adversarial loss: 0.589769\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334530; batch adversarial loss: 0.517146\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387519; batch adversarial loss: 0.480591\n",
      "epoch 135; iter: 0; batch classifier loss: 0.503470; batch adversarial loss: 0.635858\n",
      "epoch 136; iter: 0; batch classifier loss: 0.316637; batch adversarial loss: 0.572076\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357759; batch adversarial loss: 0.626145\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364276; batch adversarial loss: 0.508314\n",
      "epoch 139; iter: 0; batch classifier loss: 0.419401; batch adversarial loss: 0.562922\n",
      "epoch 140; iter: 0; batch classifier loss: 0.426801; batch adversarial loss: 0.545012\n",
      "epoch 141; iter: 0; batch classifier loss: 0.489204; batch adversarial loss: 0.534586\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371843; batch adversarial loss: 0.517991\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306371; batch adversarial loss: 0.536764\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361131; batch adversarial loss: 0.526603\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375945; batch adversarial loss: 0.553849\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367077; batch adversarial loss: 0.553438\n",
      "epoch 147; iter: 0; batch classifier loss: 0.370402; batch adversarial loss: 0.525671\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336312; batch adversarial loss: 0.563451\n",
      "epoch 149; iter: 0; batch classifier loss: 0.397466; batch adversarial loss: 0.561888\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371156; batch adversarial loss: 0.545016\n",
      "epoch 151; iter: 0; batch classifier loss: 0.443658; batch adversarial loss: 0.544709\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385684; batch adversarial loss: 0.598664\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393275; batch adversarial loss: 0.517091\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345380; batch adversarial loss: 0.516837\n",
      "epoch 155; iter: 0; batch classifier loss: 0.428644; batch adversarial loss: 0.562863\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325316; batch adversarial loss: 0.508340\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376636; batch adversarial loss: 0.535601\n",
      "epoch 158; iter: 0; batch classifier loss: 0.328453; batch adversarial loss: 0.571823\n",
      "epoch 159; iter: 0; batch classifier loss: 0.327435; batch adversarial loss: 0.544259\n",
      "epoch 160; iter: 0; batch classifier loss: 0.279113; batch adversarial loss: 0.563196\n",
      "epoch 161; iter: 0; batch classifier loss: 0.359457; batch adversarial loss: 0.581110\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343127; batch adversarial loss: 0.535150\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328010; batch adversarial loss: 0.507784\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375201; batch adversarial loss: 0.653354\n",
      "epoch 165; iter: 0; batch classifier loss: 0.276995; batch adversarial loss: 0.608189\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343845; batch adversarial loss: 0.642685\n",
      "epoch 167; iter: 0; batch classifier loss: 0.481149; batch adversarial loss: 0.536452\n",
      "epoch 168; iter: 0; batch classifier loss: 0.324223; batch adversarial loss: 0.572682\n",
      "epoch 169; iter: 0; batch classifier loss: 0.285807; batch adversarial loss: 0.555093\n",
      "epoch 170; iter: 0; batch classifier loss: 0.358078; batch adversarial loss: 0.473093\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346985; batch adversarial loss: 0.489280\n",
      "epoch 172; iter: 0; batch classifier loss: 0.361844; batch adversarial loss: 0.597351\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322320; batch adversarial loss: 0.533782\n",
      "epoch 174; iter: 0; batch classifier loss: 0.478209; batch adversarial loss: 0.526816\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330073; batch adversarial loss: 0.554767\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328977; batch adversarial loss: 0.590821\n",
      "epoch 177; iter: 0; batch classifier loss: 0.427082; batch adversarial loss: 0.573430\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350335; batch adversarial loss: 0.590206\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372603; batch adversarial loss: 0.608768\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389846; batch adversarial loss: 0.572711\n",
      "epoch 181; iter: 0; batch classifier loss: 0.434648; batch adversarial loss: 0.519195\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378486; batch adversarial loss: 0.581704\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324008; batch adversarial loss: 0.561297\n",
      "epoch 184; iter: 0; batch classifier loss: 0.441462; batch adversarial loss: 0.552240\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390413; batch adversarial loss: 0.545156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.395289; batch adversarial loss: 0.562814\n",
      "epoch 187; iter: 0; batch classifier loss: 0.416990; batch adversarial loss: 0.516460\n",
      "epoch 188; iter: 0; batch classifier loss: 0.424812; batch adversarial loss: 0.599905\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382653; batch adversarial loss: 0.516693\n",
      "epoch 190; iter: 0; batch classifier loss: 0.429256; batch adversarial loss: 0.535455\n",
      "epoch 191; iter: 0; batch classifier loss: 0.343522; batch adversarial loss: 0.544291\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336207; batch adversarial loss: 0.498725\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347650; batch adversarial loss: 0.517325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.400376; batch adversarial loss: 0.471490\n",
      "epoch 195; iter: 0; batch classifier loss: 0.289000; batch adversarial loss: 0.526314\n",
      "epoch 196; iter: 0; batch classifier loss: 0.261184; batch adversarial loss: 0.535324\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349289; batch adversarial loss: 0.562625\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355718; batch adversarial loss: 0.517214\n",
      "epoch 199; iter: 0; batch classifier loss: 0.378352; batch adversarial loss: 0.562693\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736710; batch adversarial loss: 1.025093\n",
      "epoch 1; iter: 0; batch classifier loss: 0.796531; batch adversarial loss: 1.096956\n",
      "epoch 2; iter: 0; batch classifier loss: 0.866284; batch adversarial loss: 1.117698\n",
      "epoch 3; iter: 0; batch classifier loss: 0.808181; batch adversarial loss: 1.046200\n",
      "epoch 4; iter: 0; batch classifier loss: 0.951073; batch adversarial loss: 0.880423\n",
      "epoch 5; iter: 0; batch classifier loss: 0.851397; batch adversarial loss: 0.819187\n",
      "epoch 6; iter: 0; batch classifier loss: 0.742528; batch adversarial loss: 0.770102\n",
      "epoch 7; iter: 0; batch classifier loss: 0.675578; batch adversarial loss: 0.714842\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549156; batch adversarial loss: 0.648772\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573585; batch adversarial loss: 0.628489\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464870; batch adversarial loss: 0.629695\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547293; batch adversarial loss: 0.597256\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553208; batch adversarial loss: 0.592956\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513912; batch adversarial loss: 0.572568\n",
      "epoch 14; iter: 0; batch classifier loss: 0.536026; batch adversarial loss: 0.602343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521325; batch adversarial loss: 0.560788\n",
      "epoch 16; iter: 0; batch classifier loss: 0.597572; batch adversarial loss: 0.583885\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557273; batch adversarial loss: 0.588285\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520963; batch adversarial loss: 0.537080\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517683; batch adversarial loss: 0.627980\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462742; batch adversarial loss: 0.598590\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460577; batch adversarial loss: 0.544786\n",
      "epoch 22; iter: 0; batch classifier loss: 0.499271; batch adversarial loss: 0.499309\n",
      "epoch 23; iter: 0; batch classifier loss: 0.532463; batch adversarial loss: 0.561612\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435881; batch adversarial loss: 0.588384\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483986; batch adversarial loss: 0.569799\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480205; batch adversarial loss: 0.584361\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466338; batch adversarial loss: 0.564281\n",
      "epoch 28; iter: 0; batch classifier loss: 0.546325; batch adversarial loss: 0.572559\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472483; batch adversarial loss: 0.493609\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502765; batch adversarial loss: 0.529809\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422722; batch adversarial loss: 0.519555\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457208; batch adversarial loss: 0.569541\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461362; batch adversarial loss: 0.595918\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492857; batch adversarial loss: 0.574156\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424029; batch adversarial loss: 0.569228\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470210; batch adversarial loss: 0.501880\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465261; batch adversarial loss: 0.521181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454187; batch adversarial loss: 0.594097\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442142; batch adversarial loss: 0.537360\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419488; batch adversarial loss: 0.599142\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487751; batch adversarial loss: 0.508111\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410480; batch adversarial loss: 0.526769\n",
      "epoch 43; iter: 0; batch classifier loss: 0.355961; batch adversarial loss: 0.517782\n",
      "epoch 44; iter: 0; batch classifier loss: 0.399958; batch adversarial loss: 0.535479\n",
      "epoch 45; iter: 0; batch classifier loss: 0.365265; batch adversarial loss: 0.580521\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458755; batch adversarial loss: 0.517742\n",
      "epoch 47; iter: 0; batch classifier loss: 0.391485; batch adversarial loss: 0.590966\n",
      "epoch 48; iter: 0; batch classifier loss: 0.367149; batch adversarial loss: 0.591287\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403221; batch adversarial loss: 0.581160\n",
      "epoch 50; iter: 0; batch classifier loss: 0.383559; batch adversarial loss: 0.546336\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374984; batch adversarial loss: 0.569021\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401339; batch adversarial loss: 0.619272\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445369; batch adversarial loss: 0.555345\n",
      "epoch 54; iter: 0; batch classifier loss: 0.456299; batch adversarial loss: 0.457307\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422330; batch adversarial loss: 0.547658\n",
      "epoch 56; iter: 0; batch classifier loss: 0.400464; batch adversarial loss: 0.546371\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390778; batch adversarial loss: 0.509020\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409067; batch adversarial loss: 0.524759\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388432; batch adversarial loss: 0.527395\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406012; batch adversarial loss: 0.570422\n",
      "epoch 61; iter: 0; batch classifier loss: 0.384614; batch adversarial loss: 0.552365\n",
      "epoch 62; iter: 0; batch classifier loss: 0.493310; batch adversarial loss: 0.562738\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459378; batch adversarial loss: 0.534778\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403236; batch adversarial loss: 0.467226\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438788; batch adversarial loss: 0.488444\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410231; batch adversarial loss: 0.548385\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351752; batch adversarial loss: 0.523397\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408632; batch adversarial loss: 0.488667\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412787; batch adversarial loss: 0.629463\n",
      "epoch 70; iter: 0; batch classifier loss: 0.448499; batch adversarial loss: 0.531456\n",
      "epoch 71; iter: 0; batch classifier loss: 0.385450; batch adversarial loss: 0.533386\n",
      "epoch 72; iter: 0; batch classifier loss: 0.341612; batch adversarial loss: 0.525271\n",
      "epoch 73; iter: 0; batch classifier loss: 0.491785; batch adversarial loss: 0.570357\n",
      "epoch 74; iter: 0; batch classifier loss: 0.343266; batch adversarial loss: 0.535247\n",
      "epoch 75; iter: 0; batch classifier loss: 0.411630; batch adversarial loss: 0.554808\n",
      "epoch 76; iter: 0; batch classifier loss: 0.329525; batch adversarial loss: 0.546561\n",
      "epoch 77; iter: 0; batch classifier loss: 0.354752; batch adversarial loss: 0.535768\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395191; batch adversarial loss: 0.531037\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393466; batch adversarial loss: 0.655725\n",
      "epoch 80; iter: 0; batch classifier loss: 0.510361; batch adversarial loss: 0.504859\n",
      "epoch 81; iter: 0; batch classifier loss: 0.401467; batch adversarial loss: 0.551326\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382392; batch adversarial loss: 0.516140\n",
      "epoch 83; iter: 0; batch classifier loss: 0.332485; batch adversarial loss: 0.536315\n",
      "epoch 84; iter: 0; batch classifier loss: 0.463845; batch adversarial loss: 0.495757\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407338; batch adversarial loss: 0.529569\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398860; batch adversarial loss: 0.591601\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376704; batch adversarial loss: 0.496778\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387974; batch adversarial loss: 0.557193\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368806; batch adversarial loss: 0.555278\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402928; batch adversarial loss: 0.533420\n",
      "epoch 91; iter: 0; batch classifier loss: 0.447218; batch adversarial loss: 0.502108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.451142; batch adversarial loss: 0.468580\n",
      "epoch 93; iter: 0; batch classifier loss: 0.406829; batch adversarial loss: 0.542867\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380572; batch adversarial loss: 0.627871\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401518; batch adversarial loss: 0.573120\n",
      "epoch 96; iter: 0; batch classifier loss: 0.360591; batch adversarial loss: 0.544046\n",
      "epoch 97; iter: 0; batch classifier loss: 0.414065; batch adversarial loss: 0.443085\n",
      "epoch 98; iter: 0; batch classifier loss: 0.470671; batch adversarial loss: 0.564202\n",
      "epoch 99; iter: 0; batch classifier loss: 0.449752; batch adversarial loss: 0.499121\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403659; batch adversarial loss: 0.536367\n",
      "epoch 101; iter: 0; batch classifier loss: 0.419975; batch adversarial loss: 0.553824\n",
      "epoch 102; iter: 0; batch classifier loss: 0.453376; batch adversarial loss: 0.592081\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375380; batch adversarial loss: 0.543954\n",
      "epoch 104; iter: 0; batch classifier loss: 0.388306; batch adversarial loss: 0.431954\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347729; batch adversarial loss: 0.562021\n",
      "epoch 106; iter: 0; batch classifier loss: 0.323680; batch adversarial loss: 0.572431\n",
      "epoch 107; iter: 0; batch classifier loss: 0.428589; batch adversarial loss: 0.589738\n",
      "epoch 108; iter: 0; batch classifier loss: 0.359694; batch adversarial loss: 0.573289\n",
      "epoch 109; iter: 0; batch classifier loss: 0.408210; batch adversarial loss: 0.599884\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390961; batch adversarial loss: 0.525174\n",
      "epoch 111; iter: 0; batch classifier loss: 0.295814; batch adversarial loss: 0.599538\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388845; batch adversarial loss: 0.496203\n",
      "epoch 113; iter: 0; batch classifier loss: 0.425859; batch adversarial loss: 0.609914\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368465; batch adversarial loss: 0.534898\n",
      "epoch 115; iter: 0; batch classifier loss: 0.437830; batch adversarial loss: 0.496916\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391948; batch adversarial loss: 0.552791\n",
      "epoch 117; iter: 0; batch classifier loss: 0.468154; batch adversarial loss: 0.515139\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417252; batch adversarial loss: 0.434902\n",
      "epoch 119; iter: 0; batch classifier loss: 0.318881; batch adversarial loss: 0.600157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.309517; batch adversarial loss: 0.526395\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368454; batch adversarial loss: 0.609638\n",
      "epoch 122; iter: 0; batch classifier loss: 0.292775; batch adversarial loss: 0.590451\n",
      "epoch 123; iter: 0; batch classifier loss: 0.402839; batch adversarial loss: 0.507262\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358755; batch adversarial loss: 0.544698\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386473; batch adversarial loss: 0.526353\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374339; batch adversarial loss: 0.451246\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394091; batch adversarial loss: 0.506436\n",
      "epoch 128; iter: 0; batch classifier loss: 0.339778; batch adversarial loss: 0.507026\n",
      "epoch 129; iter: 0; batch classifier loss: 0.387153; batch adversarial loss: 0.525015\n",
      "epoch 130; iter: 0; batch classifier loss: 0.433652; batch adversarial loss: 0.572256\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366059; batch adversarial loss: 0.498651\n",
      "epoch 132; iter: 0; batch classifier loss: 0.301222; batch adversarial loss: 0.617709\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355895; batch adversarial loss: 0.515259\n",
      "epoch 134; iter: 0; batch classifier loss: 0.434878; batch adversarial loss: 0.487691\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353825; batch adversarial loss: 0.591075\n",
      "epoch 136; iter: 0; batch classifier loss: 0.350482; batch adversarial loss: 0.611162\n",
      "epoch 137; iter: 0; batch classifier loss: 0.217497; batch adversarial loss: 0.551861\n",
      "epoch 138; iter: 0; batch classifier loss: 0.454775; batch adversarial loss: 0.552547\n",
      "epoch 139; iter: 0; batch classifier loss: 0.454226; batch adversarial loss: 0.543903\n",
      "epoch 140; iter: 0; batch classifier loss: 0.410813; batch adversarial loss: 0.565280\n",
      "epoch 141; iter: 0; batch classifier loss: 0.396399; batch adversarial loss: 0.536651\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338731; batch adversarial loss: 0.481654\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361765; batch adversarial loss: 0.519804\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398137; batch adversarial loss: 0.536246\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379521; batch adversarial loss: 0.470353\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376279; batch adversarial loss: 0.525643\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382951; batch adversarial loss: 0.516144\n",
      "epoch 148; iter: 0; batch classifier loss: 0.275486; batch adversarial loss: 0.591001\n",
      "epoch 149; iter: 0; batch classifier loss: 0.409311; batch adversarial loss: 0.489634\n",
      "epoch 150; iter: 0; batch classifier loss: 0.292311; batch adversarial loss: 0.538199\n",
      "epoch 151; iter: 0; batch classifier loss: 0.311782; batch adversarial loss: 0.534902\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377546; batch adversarial loss: 0.609614\n",
      "epoch 153; iter: 0; batch classifier loss: 0.299524; batch adversarial loss: 0.562784\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402401; batch adversarial loss: 0.488190\n",
      "epoch 155; iter: 0; batch classifier loss: 0.302819; batch adversarial loss: 0.597538\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332749; batch adversarial loss: 0.507693\n",
      "epoch 157; iter: 0; batch classifier loss: 0.413380; batch adversarial loss: 0.544902\n",
      "epoch 158; iter: 0; batch classifier loss: 0.320994; batch adversarial loss: 0.581719\n",
      "epoch 159; iter: 0; batch classifier loss: 0.452058; batch adversarial loss: 0.527007\n",
      "epoch 160; iter: 0; batch classifier loss: 0.425310; batch adversarial loss: 0.498600\n",
      "epoch 161; iter: 0; batch classifier loss: 0.355108; batch adversarial loss: 0.638386\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365525; batch adversarial loss: 0.525778\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345257; batch adversarial loss: 0.507709\n",
      "epoch 164; iter: 0; batch classifier loss: 0.441404; batch adversarial loss: 0.562221\n",
      "epoch 165; iter: 0; batch classifier loss: 0.336973; batch adversarial loss: 0.571739\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346402; batch adversarial loss: 0.626750\n",
      "epoch 167; iter: 0; batch classifier loss: 0.411436; batch adversarial loss: 0.581081\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357011; batch adversarial loss: 0.562413\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385059; batch adversarial loss: 0.581813\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364592; batch adversarial loss: 0.581990\n",
      "epoch 171; iter: 0; batch classifier loss: 0.403093; batch adversarial loss: 0.572237\n",
      "epoch 172; iter: 0; batch classifier loss: 0.343973; batch adversarial loss: 0.461124\n",
      "epoch 173; iter: 0; batch classifier loss: 0.490943; batch adversarial loss: 0.489711\n",
      "epoch 174; iter: 0; batch classifier loss: 0.289811; batch adversarial loss: 0.526048\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322050; batch adversarial loss: 0.497929\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360231; batch adversarial loss: 0.543298\n",
      "epoch 177; iter: 0; batch classifier loss: 0.414221; batch adversarial loss: 0.563688\n",
      "epoch 178; iter: 0; batch classifier loss: 0.474236; batch adversarial loss: 0.487631\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383415; batch adversarial loss: 0.525212\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382442; batch adversarial loss: 0.515916\n",
      "epoch 181; iter: 0; batch classifier loss: 0.352406; batch adversarial loss: 0.479586\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342108; batch adversarial loss: 0.639203\n",
      "epoch 183; iter: 0; batch classifier loss: 0.319461; batch adversarial loss: 0.580787\n",
      "epoch 184; iter: 0; batch classifier loss: 0.284543; batch adversarial loss: 0.524722\n",
      "epoch 185; iter: 0; batch classifier loss: 0.462103; batch adversarial loss: 0.536162\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373420; batch adversarial loss: 0.526533\n",
      "epoch 187; iter: 0; batch classifier loss: 0.427568; batch adversarial loss: 0.526554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.321196; batch adversarial loss: 0.497582\n",
      "epoch 189; iter: 0; batch classifier loss: 0.406157; batch adversarial loss: 0.535881\n",
      "epoch 190; iter: 0; batch classifier loss: 0.291999; batch adversarial loss: 0.535113\n",
      "epoch 191; iter: 0; batch classifier loss: 0.304324; batch adversarial loss: 0.564526\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356122; batch adversarial loss: 0.526602\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318472; batch adversarial loss: 0.525675\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349691; batch adversarial loss: 0.535359\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321877; batch adversarial loss: 0.498346\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366638; batch adversarial loss: 0.571765\n",
      "epoch 197; iter: 0; batch classifier loss: 0.331145; batch adversarial loss: 0.508288\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369398; batch adversarial loss: 0.479894\n",
      "epoch 199; iter: 0; batch classifier loss: 0.420298; batch adversarial loss: 0.618695\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678688; batch adversarial loss: 0.621867\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574208; batch adversarial loss: 0.676376\n",
      "epoch 2; iter: 0; batch classifier loss: 0.584157; batch adversarial loss: 0.653918\n",
      "epoch 3; iter: 0; batch classifier loss: 0.684659; batch adversarial loss: 0.641233\n",
      "epoch 4; iter: 0; batch classifier loss: 0.612193; batch adversarial loss: 0.662273\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593430; batch adversarial loss: 0.633666\n",
      "epoch 6; iter: 0; batch classifier loss: 0.622106; batch adversarial loss: 0.662088\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546067; batch adversarial loss: 0.590605\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535250; batch adversarial loss: 0.630892\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573012; batch adversarial loss: 0.530634\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541214; batch adversarial loss: 0.587895\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531247; batch adversarial loss: 0.600129\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489691; batch adversarial loss: 0.612491\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546991; batch adversarial loss: 0.556510\n",
      "epoch 14; iter: 0; batch classifier loss: 0.492667; batch adversarial loss: 0.489716\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529214; batch adversarial loss: 0.594882\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531170; batch adversarial loss: 0.494606\n",
      "epoch 17; iter: 0; batch classifier loss: 0.577167; batch adversarial loss: 0.559120\n",
      "epoch 18; iter: 0; batch classifier loss: 0.577528; batch adversarial loss: 0.550353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437431; batch adversarial loss: 0.526528\n",
      "epoch 20; iter: 0; batch classifier loss: 0.422787; batch adversarial loss: 0.531541\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543197; batch adversarial loss: 0.514133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.428341; batch adversarial loss: 0.549523\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486707; batch adversarial loss: 0.541452\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482271; batch adversarial loss: 0.563742\n",
      "epoch 25; iter: 0; batch classifier loss: 0.558150; batch adversarial loss: 0.556561\n",
      "epoch 26; iter: 0; batch classifier loss: 0.408562; batch adversarial loss: 0.529495\n",
      "epoch 27; iter: 0; batch classifier loss: 0.456432; batch adversarial loss: 0.562143\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484017; batch adversarial loss: 0.528414\n",
      "epoch 29; iter: 0; batch classifier loss: 0.396966; batch adversarial loss: 0.579816\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495278; batch adversarial loss: 0.518263\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409198; batch adversarial loss: 0.497949\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493314; batch adversarial loss: 0.518834\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477651; batch adversarial loss: 0.537696\n",
      "epoch 34; iter: 0; batch classifier loss: 0.465627; batch adversarial loss: 0.552309\n",
      "epoch 35; iter: 0; batch classifier loss: 0.377763; batch adversarial loss: 0.525825\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432721; batch adversarial loss: 0.573066\n",
      "epoch 37; iter: 0; batch classifier loss: 0.437179; batch adversarial loss: 0.562825\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431068; batch adversarial loss: 0.533871\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485193; batch adversarial loss: 0.509451\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436059; batch adversarial loss: 0.527951\n",
      "epoch 41; iter: 0; batch classifier loss: 0.366261; batch adversarial loss: 0.609999\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408568; batch adversarial loss: 0.608205\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482357; batch adversarial loss: 0.562443\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401530; batch adversarial loss: 0.546284\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444642; batch adversarial loss: 0.565056\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495597; batch adversarial loss: 0.581474\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469323; batch adversarial loss: 0.563012\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430504; batch adversarial loss: 0.517660\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432480; batch adversarial loss: 0.544148\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411575; batch adversarial loss: 0.519384\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383630; batch adversarial loss: 0.598934\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429811; batch adversarial loss: 0.472541\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452898; batch adversarial loss: 0.491604\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410868; batch adversarial loss: 0.601335\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432164; batch adversarial loss: 0.535823\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434656; batch adversarial loss: 0.606818\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410450; batch adversarial loss: 0.554602\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389195; batch adversarial loss: 0.523335\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382440; batch adversarial loss: 0.507529\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473690; batch adversarial loss: 0.571030\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409614; batch adversarial loss: 0.487703\n",
      "epoch 62; iter: 0; batch classifier loss: 0.370322; batch adversarial loss: 0.552575\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404954; batch adversarial loss: 0.572995\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409780; batch adversarial loss: 0.471335\n",
      "epoch 65; iter: 0; batch classifier loss: 0.495679; batch adversarial loss: 0.535119\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409301; batch adversarial loss: 0.533450\n",
      "epoch 67; iter: 0; batch classifier loss: 0.464002; batch adversarial loss: 0.444303\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386804; batch adversarial loss: 0.564385\n",
      "epoch 69; iter: 0; batch classifier loss: 0.496218; batch adversarial loss: 0.516204\n",
      "epoch 70; iter: 0; batch classifier loss: 0.449618; batch adversarial loss: 0.524894\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349474; batch adversarial loss: 0.552625\n",
      "epoch 72; iter: 0; batch classifier loss: 0.526782; batch adversarial loss: 0.535092\n",
      "epoch 73; iter: 0; batch classifier loss: 0.365919; batch adversarial loss: 0.545832\n",
      "epoch 74; iter: 0; batch classifier loss: 0.331003; batch adversarial loss: 0.553772\n",
      "epoch 75; iter: 0; batch classifier loss: 0.368787; batch adversarial loss: 0.600413\n",
      "epoch 76; iter: 0; batch classifier loss: 0.304394; batch adversarial loss: 0.469249\n",
      "epoch 77; iter: 0; batch classifier loss: 0.368946; batch adversarial loss: 0.536547\n",
      "epoch 78; iter: 0; batch classifier loss: 0.422955; batch adversarial loss: 0.561812\n",
      "epoch 79; iter: 0; batch classifier loss: 0.363903; batch adversarial loss: 0.601836\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476436; batch adversarial loss: 0.544387\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423433; batch adversarial loss: 0.509284\n",
      "epoch 82; iter: 0; batch classifier loss: 0.378864; batch adversarial loss: 0.609828\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444638; batch adversarial loss: 0.554069\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355619; batch adversarial loss: 0.526501\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402440; batch adversarial loss: 0.544166\n",
      "epoch 86; iter: 0; batch classifier loss: 0.423801; batch adversarial loss: 0.506941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.391310; batch adversarial loss: 0.479404\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358617; batch adversarial loss: 0.534978\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405546; batch adversarial loss: 0.563556\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371646; batch adversarial loss: 0.506196\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400065; batch adversarial loss: 0.523104\n",
      "epoch 92; iter: 0; batch classifier loss: 0.451093; batch adversarial loss: 0.482242\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421492; batch adversarial loss: 0.507803\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382694; batch adversarial loss: 0.572401\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402266; batch adversarial loss: 0.528467\n",
      "epoch 96; iter: 0; batch classifier loss: 0.413617; batch adversarial loss: 0.609724\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382937; batch adversarial loss: 0.589745\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391401; batch adversarial loss: 0.590326\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410724; batch adversarial loss: 0.554228\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412881; batch adversarial loss: 0.507794\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390680; batch adversarial loss: 0.599780\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410279; batch adversarial loss: 0.571898\n",
      "epoch 103; iter: 0; batch classifier loss: 0.349094; batch adversarial loss: 0.535937\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354167; batch adversarial loss: 0.582334\n",
      "epoch 105; iter: 0; batch classifier loss: 0.420050; batch adversarial loss: 0.571472\n",
      "epoch 106; iter: 0; batch classifier loss: 0.430177; batch adversarial loss: 0.532780\n",
      "epoch 107; iter: 0; batch classifier loss: 0.492991; batch adversarial loss: 0.617626\n",
      "epoch 108; iter: 0; batch classifier loss: 0.394568; batch adversarial loss: 0.526319\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413154; batch adversarial loss: 0.535071\n",
      "epoch 110; iter: 0; batch classifier loss: 0.329610; batch adversarial loss: 0.498382\n",
      "epoch 111; iter: 0; batch classifier loss: 0.411554; batch adversarial loss: 0.581218\n",
      "epoch 112; iter: 0; batch classifier loss: 0.321050; batch adversarial loss: 0.533440\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391849; batch adversarial loss: 0.570175\n",
      "epoch 114; iter: 0; batch classifier loss: 0.409741; batch adversarial loss: 0.526984\n",
      "epoch 115; iter: 0; batch classifier loss: 0.429340; batch adversarial loss: 0.599883\n",
      "epoch 116; iter: 0; batch classifier loss: 0.449067; batch adversarial loss: 0.579126\n",
      "epoch 117; iter: 0; batch classifier loss: 0.437508; batch adversarial loss: 0.599598\n",
      "epoch 118; iter: 0; batch classifier loss: 0.446875; batch adversarial loss: 0.534904\n",
      "epoch 119; iter: 0; batch classifier loss: 0.360386; batch adversarial loss: 0.535203\n",
      "epoch 120; iter: 0; batch classifier loss: 0.421780; batch adversarial loss: 0.590419\n",
      "epoch 121; iter: 0; batch classifier loss: 0.501272; batch adversarial loss: 0.498366\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392321; batch adversarial loss: 0.553549\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425308; batch adversarial loss: 0.600120\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395327; batch adversarial loss: 0.505885\n",
      "epoch 125; iter: 0; batch classifier loss: 0.284767; batch adversarial loss: 0.516674\n",
      "epoch 126; iter: 0; batch classifier loss: 0.444435; batch adversarial loss: 0.554830\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374327; batch adversarial loss: 0.535551\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322777; batch adversarial loss: 0.573226\n",
      "epoch 129; iter: 0; batch classifier loss: 0.463272; batch adversarial loss: 0.518199\n",
      "epoch 130; iter: 0; batch classifier loss: 0.455159; batch adversarial loss: 0.597883\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388668; batch adversarial loss: 0.562251\n",
      "epoch 132; iter: 0; batch classifier loss: 0.471286; batch adversarial loss: 0.535035\n",
      "epoch 133; iter: 0; batch classifier loss: 0.479632; batch adversarial loss: 0.452570\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384248; batch adversarial loss: 0.508293\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381718; batch adversarial loss: 0.517102\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348695; batch adversarial loss: 0.560982\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424128; batch adversarial loss: 0.627270\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405105; batch adversarial loss: 0.619071\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386394; batch adversarial loss: 0.490249\n",
      "epoch 140; iter: 0; batch classifier loss: 0.453044; batch adversarial loss: 0.535803\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364088; batch adversarial loss: 0.552369\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396012; batch adversarial loss: 0.545403\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399918; batch adversarial loss: 0.582520\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354401; batch adversarial loss: 0.506685\n",
      "epoch 145; iter: 0; batch classifier loss: 0.357949; batch adversarial loss: 0.563797\n",
      "epoch 146; iter: 0; batch classifier loss: 0.314821; batch adversarial loss: 0.534770\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351667; batch adversarial loss: 0.545232\n",
      "epoch 148; iter: 0; batch classifier loss: 0.426806; batch adversarial loss: 0.507260\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361130; batch adversarial loss: 0.498477\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349525; batch adversarial loss: 0.535149\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387555; batch adversarial loss: 0.545042\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357025; batch adversarial loss: 0.626652\n",
      "epoch 153; iter: 0; batch classifier loss: 0.417153; batch adversarial loss: 0.507963\n",
      "epoch 154; iter: 0; batch classifier loss: 0.341521; batch adversarial loss: 0.581166\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397798; batch adversarial loss: 0.562617\n",
      "epoch 156; iter: 0; batch classifier loss: 0.413063; batch adversarial loss: 0.497204\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400503; batch adversarial loss: 0.589440\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370798; batch adversarial loss: 0.517522\n",
      "epoch 159; iter: 0; batch classifier loss: 0.399499; batch adversarial loss: 0.561849\n",
      "epoch 160; iter: 0; batch classifier loss: 0.429314; batch adversarial loss: 0.544921\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325520; batch adversarial loss: 0.508989\n",
      "epoch 162; iter: 0; batch classifier loss: 0.409605; batch adversarial loss: 0.480275\n",
      "epoch 163; iter: 0; batch classifier loss: 0.377244; batch adversarial loss: 0.524934\n",
      "epoch 164; iter: 0; batch classifier loss: 0.313770; batch adversarial loss: 0.572473\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356491; batch adversarial loss: 0.525314\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339021; batch adversarial loss: 0.535935\n",
      "epoch 167; iter: 0; batch classifier loss: 0.463077; batch adversarial loss: 0.563072\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389908; batch adversarial loss: 0.534637\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394928; batch adversarial loss: 0.580373\n",
      "epoch 170; iter: 0; batch classifier loss: 0.372570; batch adversarial loss: 0.572359\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329037; batch adversarial loss: 0.508598\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359660; batch adversarial loss: 0.533768\n",
      "epoch 173; iter: 0; batch classifier loss: 0.426447; batch adversarial loss: 0.562177\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324261; batch adversarial loss: 0.508732\n",
      "epoch 175; iter: 0; batch classifier loss: 0.421079; batch adversarial loss: 0.516822\n",
      "epoch 176; iter: 0; batch classifier loss: 0.434685; batch adversarial loss: 0.581565\n",
      "epoch 177; iter: 0; batch classifier loss: 0.393780; batch adversarial loss: 0.544858\n",
      "epoch 178; iter: 0; batch classifier loss: 0.427517; batch adversarial loss: 0.617287\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345973; batch adversarial loss: 0.563913\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389968; batch adversarial loss: 0.498159\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371287; batch adversarial loss: 0.553610\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405993; batch adversarial loss: 0.524749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.412030; batch adversarial loss: 0.608958\n",
      "epoch 184; iter: 0; batch classifier loss: 0.430108; batch adversarial loss: 0.581917\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384514; batch adversarial loss: 0.481215\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366817; batch adversarial loss: 0.598171\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341717; batch adversarial loss: 0.535873\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330871; batch adversarial loss: 0.589621\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378069; batch adversarial loss: 0.544148\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380820; batch adversarial loss: 0.499040\n",
      "epoch 191; iter: 0; batch classifier loss: 0.446906; batch adversarial loss: 0.498799\n",
      "epoch 192; iter: 0; batch classifier loss: 0.446709; batch adversarial loss: 0.479836\n",
      "epoch 193; iter: 0; batch classifier loss: 0.419347; batch adversarial loss: 0.479803\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419088; batch adversarial loss: 0.582191\n",
      "epoch 195; iter: 0; batch classifier loss: 0.307870; batch adversarial loss: 0.553703\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330275; batch adversarial loss: 0.534712\n",
      "epoch 197; iter: 0; batch classifier loss: 0.437506; batch adversarial loss: 0.563155\n",
      "epoch 198; iter: 0; batch classifier loss: 0.386987; batch adversarial loss: 0.525737\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351782; batch adversarial loss: 0.478764\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674418; batch adversarial loss: 0.980578\n",
      "epoch 1; iter: 0; batch classifier loss: 0.924636; batch adversarial loss: 1.396961\n",
      "epoch 2; iter: 0; batch classifier loss: 1.113365; batch adversarial loss: 1.394854\n",
      "epoch 3; iter: 0; batch classifier loss: 1.170556; batch adversarial loss: 1.316106\n",
      "epoch 4; iter: 0; batch classifier loss: 1.378078; batch adversarial loss: 1.250932\n",
      "epoch 5; iter: 0; batch classifier loss: 1.185790; batch adversarial loss: 1.043784\n",
      "epoch 6; iter: 0; batch classifier loss: 1.194432; batch adversarial loss: 1.006842\n",
      "epoch 7; iter: 0; batch classifier loss: 1.139073; batch adversarial loss: 0.937398\n",
      "epoch 8; iter: 0; batch classifier loss: 1.206452; batch adversarial loss: 0.886626\n",
      "epoch 9; iter: 0; batch classifier loss: 1.050478; batch adversarial loss: 0.794701\n",
      "epoch 10; iter: 0; batch classifier loss: 0.850166; batch adversarial loss: 0.756822\n",
      "epoch 11; iter: 0; batch classifier loss: 0.854964; batch adversarial loss: 0.690659\n",
      "epoch 12; iter: 0; batch classifier loss: 0.750700; batch adversarial loss: 0.634814\n",
      "epoch 13; iter: 0; batch classifier loss: 0.738493; batch adversarial loss: 0.633541\n",
      "epoch 14; iter: 0; batch classifier loss: 0.595409; batch adversarial loss: 0.628364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563771; batch adversarial loss: 0.589846\n",
      "epoch 16; iter: 0; batch classifier loss: 0.562143; batch adversarial loss: 0.535417\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521822; batch adversarial loss: 0.584851\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530743; batch adversarial loss: 0.568955\n",
      "epoch 19; iter: 0; batch classifier loss: 0.581158; batch adversarial loss: 0.568962\n",
      "epoch 20; iter: 0; batch classifier loss: 0.557561; batch adversarial loss: 0.605406\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499378; batch adversarial loss: 0.575826\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482807; batch adversarial loss: 0.566913\n",
      "epoch 23; iter: 0; batch classifier loss: 0.537798; batch adversarial loss: 0.522656\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493113; batch adversarial loss: 0.509653\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466703; batch adversarial loss: 0.526209\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498464; batch adversarial loss: 0.520047\n",
      "epoch 27; iter: 0; batch classifier loss: 0.426841; batch adversarial loss: 0.499375\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468887; batch adversarial loss: 0.510400\n",
      "epoch 29; iter: 0; batch classifier loss: 0.427223; batch adversarial loss: 0.528606\n",
      "epoch 30; iter: 0; batch classifier loss: 0.541141; batch adversarial loss: 0.527121\n",
      "epoch 31; iter: 0; batch classifier loss: 0.527674; batch adversarial loss: 0.558942\n",
      "epoch 32; iter: 0; batch classifier loss: 0.548841; batch adversarial loss: 0.593897\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439856; batch adversarial loss: 0.550561\n",
      "epoch 34; iter: 0; batch classifier loss: 0.510821; batch adversarial loss: 0.544155\n",
      "epoch 35; iter: 0; batch classifier loss: 0.497011; batch adversarial loss: 0.562405\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455453; batch adversarial loss: 0.546477\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486889; batch adversarial loss: 0.562455\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434082; batch adversarial loss: 0.523480\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438410; batch adversarial loss: 0.561841\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419855; batch adversarial loss: 0.566882\n",
      "epoch 41; iter: 0; batch classifier loss: 0.482637; batch adversarial loss: 0.606299\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461218; batch adversarial loss: 0.590346\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455241; batch adversarial loss: 0.604976\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490076; batch adversarial loss: 0.516467\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450727; batch adversarial loss: 0.544531\n",
      "epoch 46; iter: 0; batch classifier loss: 0.349575; batch adversarial loss: 0.465763\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383300; batch adversarial loss: 0.515898\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456138; batch adversarial loss: 0.566691\n",
      "epoch 49; iter: 0; batch classifier loss: 0.379656; batch adversarial loss: 0.547402\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431223; batch adversarial loss: 0.583698\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464345; batch adversarial loss: 0.503785\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416973; batch adversarial loss: 0.611603\n",
      "epoch 53; iter: 0; batch classifier loss: 0.491881; batch adversarial loss: 0.537492\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442217; batch adversarial loss: 0.581443\n",
      "epoch 55; iter: 0; batch classifier loss: 0.381441; batch adversarial loss: 0.503885\n",
      "epoch 56; iter: 0; batch classifier loss: 0.397587; batch adversarial loss: 0.584337\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393963; batch adversarial loss: 0.569695\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438771; batch adversarial loss: 0.496766\n",
      "epoch 59; iter: 0; batch classifier loss: 0.352085; batch adversarial loss: 0.565536\n",
      "epoch 60; iter: 0; batch classifier loss: 0.415515; batch adversarial loss: 0.518724\n",
      "epoch 61; iter: 0; batch classifier loss: 0.343861; batch adversarial loss: 0.562966\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405242; batch adversarial loss: 0.471311\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385304; batch adversarial loss: 0.507174\n",
      "epoch 64; iter: 0; batch classifier loss: 0.347269; batch adversarial loss: 0.545916\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429915; batch adversarial loss: 0.489794\n",
      "epoch 66; iter: 0; batch classifier loss: 0.344895; batch adversarial loss: 0.509002\n",
      "epoch 67; iter: 0; batch classifier loss: 0.482048; batch adversarial loss: 0.544496\n",
      "epoch 68; iter: 0; batch classifier loss: 0.459491; batch adversarial loss: 0.508856\n",
      "epoch 69; iter: 0; batch classifier loss: 0.380517; batch adversarial loss: 0.527002\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424290; batch adversarial loss: 0.563901\n",
      "epoch 71; iter: 0; batch classifier loss: 0.382696; batch adversarial loss: 0.480738\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427858; batch adversarial loss: 0.480393\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412262; batch adversarial loss: 0.636439\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415305; batch adversarial loss: 0.553748\n",
      "epoch 75; iter: 0; batch classifier loss: 0.350867; batch adversarial loss: 0.673516\n",
      "epoch 76; iter: 0; batch classifier loss: 0.505051; batch adversarial loss: 0.590272\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355987; batch adversarial loss: 0.562498\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365462; batch adversarial loss: 0.553649\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349461; batch adversarial loss: 0.516697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.483643; batch adversarial loss: 0.516980\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397569; batch adversarial loss: 0.516946\n",
      "epoch 82; iter: 0; batch classifier loss: 0.321497; batch adversarial loss: 0.553047\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386658; batch adversarial loss: 0.544289\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430723; batch adversarial loss: 0.506927\n",
      "epoch 85; iter: 0; batch classifier loss: 0.458306; batch adversarial loss: 0.516287\n",
      "epoch 86; iter: 0; batch classifier loss: 0.316951; batch adversarial loss: 0.571596\n",
      "epoch 87; iter: 0; batch classifier loss: 0.295101; batch adversarial loss: 0.543914\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375369; batch adversarial loss: 0.496051\n",
      "epoch 89; iter: 0; batch classifier loss: 0.435219; batch adversarial loss: 0.562653\n",
      "epoch 90; iter: 0; batch classifier loss: 0.318810; batch adversarial loss: 0.555273\n",
      "epoch 91; iter: 0; batch classifier loss: 0.346374; batch adversarial loss: 0.563129\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375448; batch adversarial loss: 0.581936\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371805; batch adversarial loss: 0.608113\n",
      "epoch 94; iter: 0; batch classifier loss: 0.316950; batch adversarial loss: 0.542679\n",
      "epoch 95; iter: 0; batch classifier loss: 0.335307; batch adversarial loss: 0.538543\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370065; batch adversarial loss: 0.490826\n",
      "epoch 97; iter: 0; batch classifier loss: 0.352241; batch adversarial loss: 0.505961\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359464; batch adversarial loss: 0.486888\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350272; batch adversarial loss: 0.571772\n",
      "epoch 100; iter: 0; batch classifier loss: 0.422905; batch adversarial loss: 0.506325\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371278; batch adversarial loss: 0.583438\n",
      "epoch 102; iter: 0; batch classifier loss: 0.437093; batch adversarial loss: 0.538050\n",
      "epoch 103; iter: 0; batch classifier loss: 0.330544; batch adversarial loss: 0.534174\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383485; batch adversarial loss: 0.620210\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355211; batch adversarial loss: 0.536757\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354242; batch adversarial loss: 0.561731\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393502; batch adversarial loss: 0.487523\n",
      "epoch 108; iter: 0; batch classifier loss: 0.345438; batch adversarial loss: 0.445244\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337688; batch adversarial loss: 0.545041\n",
      "epoch 110; iter: 0; batch classifier loss: 0.310751; batch adversarial loss: 0.580756\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391798; batch adversarial loss: 0.505093\n",
      "epoch 112; iter: 0; batch classifier loss: 0.341520; batch adversarial loss: 0.600718\n",
      "epoch 113; iter: 0; batch classifier loss: 0.434620; batch adversarial loss: 0.607844\n",
      "epoch 114; iter: 0; batch classifier loss: 0.361221; batch adversarial loss: 0.545683\n",
      "epoch 115; iter: 0; batch classifier loss: 0.281155; batch adversarial loss: 0.618259\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364269; batch adversarial loss: 0.570024\n",
      "epoch 117; iter: 0; batch classifier loss: 0.296271; batch adversarial loss: 0.618232\n",
      "epoch 118; iter: 0; batch classifier loss: 0.364975; batch adversarial loss: 0.632195\n",
      "epoch 119; iter: 0; batch classifier loss: 0.319516; batch adversarial loss: 0.583316\n",
      "epoch 120; iter: 0; batch classifier loss: 0.331191; batch adversarial loss: 0.533817\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379687; batch adversarial loss: 0.578775\n",
      "epoch 122; iter: 0; batch classifier loss: 0.315284; batch adversarial loss: 0.580634\n",
      "epoch 123; iter: 0; batch classifier loss: 0.340173; batch adversarial loss: 0.571950\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334837; batch adversarial loss: 0.477736\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340343; batch adversarial loss: 0.544494\n",
      "epoch 126; iter: 0; batch classifier loss: 0.301588; batch adversarial loss: 0.607534\n",
      "epoch 127; iter: 0; batch classifier loss: 0.423679; batch adversarial loss: 0.584558\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403901; batch adversarial loss: 0.415607\n",
      "epoch 129; iter: 0; batch classifier loss: 0.346489; batch adversarial loss: 0.620547\n",
      "epoch 130; iter: 0; batch classifier loss: 0.304839; batch adversarial loss: 0.600276\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399890; batch adversarial loss: 0.532703\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353014; batch adversarial loss: 0.573289\n",
      "epoch 133; iter: 0; batch classifier loss: 0.292086; batch adversarial loss: 0.578956\n",
      "epoch 134; iter: 0; batch classifier loss: 0.254055; batch adversarial loss: 0.500267\n",
      "epoch 135; iter: 0; batch classifier loss: 0.331455; batch adversarial loss: 0.635934\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372154; batch adversarial loss: 0.555937\n",
      "epoch 137; iter: 0; batch classifier loss: 0.280574; batch adversarial loss: 0.564149\n",
      "epoch 138; iter: 0; batch classifier loss: 0.323066; batch adversarial loss: 0.525391\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363941; batch adversarial loss: 0.518077\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332899; batch adversarial loss: 0.552517\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350872; batch adversarial loss: 0.611748\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322711; batch adversarial loss: 0.404734\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355831; batch adversarial loss: 0.516820\n",
      "epoch 144; iter: 0; batch classifier loss: 0.426341; batch adversarial loss: 0.568850\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347228; batch adversarial loss: 0.508970\n",
      "epoch 146; iter: 0; batch classifier loss: 0.424295; batch adversarial loss: 0.508573\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368799; batch adversarial loss: 0.509007\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328908; batch adversarial loss: 0.563551\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328867; batch adversarial loss: 0.546620\n",
      "epoch 150; iter: 0; batch classifier loss: 0.336716; batch adversarial loss: 0.540776\n",
      "epoch 151; iter: 0; batch classifier loss: 0.237453; batch adversarial loss: 0.490363\n",
      "epoch 152; iter: 0; batch classifier loss: 0.322165; batch adversarial loss: 0.585427\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399496; batch adversarial loss: 0.533880\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369559; batch adversarial loss: 0.515782\n",
      "epoch 155; iter: 0; batch classifier loss: 0.338760; batch adversarial loss: 0.536108\n",
      "epoch 156; iter: 0; batch classifier loss: 0.281478; batch adversarial loss: 0.592701\n",
      "epoch 157; iter: 0; batch classifier loss: 0.268912; batch adversarial loss: 0.598983\n",
      "epoch 158; iter: 0; batch classifier loss: 0.309617; batch adversarial loss: 0.587354\n",
      "epoch 159; iter: 0; batch classifier loss: 0.306024; batch adversarial loss: 0.563105\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404236; batch adversarial loss: 0.526114\n",
      "epoch 161; iter: 0; batch classifier loss: 0.257637; batch adversarial loss: 0.552503\n",
      "epoch 162; iter: 0; batch classifier loss: 0.332961; batch adversarial loss: 0.563391\n",
      "epoch 163; iter: 0; batch classifier loss: 0.273086; batch adversarial loss: 0.497664\n",
      "epoch 164; iter: 0; batch classifier loss: 0.367557; batch adversarial loss: 0.479461\n",
      "epoch 165; iter: 0; batch classifier loss: 0.279233; batch adversarial loss: 0.518274\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369468; batch adversarial loss: 0.524926\n",
      "epoch 167; iter: 0; batch classifier loss: 0.351092; batch adversarial loss: 0.640119\n",
      "epoch 168; iter: 0; batch classifier loss: 0.328574; batch adversarial loss: 0.589320\n",
      "epoch 169; iter: 0; batch classifier loss: 0.240592; batch adversarial loss: 0.563738\n",
      "epoch 170; iter: 0; batch classifier loss: 0.303633; batch adversarial loss: 0.496343\n",
      "epoch 171; iter: 0; batch classifier loss: 0.397148; batch adversarial loss: 0.590012\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375284; batch adversarial loss: 0.541917\n",
      "epoch 173; iter: 0; batch classifier loss: 0.365657; batch adversarial loss: 0.562859\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348067; batch adversarial loss: 0.608788\n",
      "epoch 175; iter: 0; batch classifier loss: 0.298972; batch adversarial loss: 0.609470\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335977; batch adversarial loss: 0.524097\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330219; batch adversarial loss: 0.518504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.276434; batch adversarial loss: 0.570830\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348280; batch adversarial loss: 0.534707\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315040; batch adversarial loss: 0.589274\n",
      "epoch 181; iter: 0; batch classifier loss: 0.336530; batch adversarial loss: 0.543967\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318032; batch adversarial loss: 0.600324\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354149; batch adversarial loss: 0.424615\n",
      "epoch 184; iter: 0; batch classifier loss: 0.326617; batch adversarial loss: 0.555456\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328543; batch adversarial loss: 0.525388\n",
      "epoch 186; iter: 0; batch classifier loss: 0.287778; batch adversarial loss: 0.537412\n",
      "epoch 187; iter: 0; batch classifier loss: 0.305588; batch adversarial loss: 0.470751\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348202; batch adversarial loss: 0.581026\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352979; batch adversarial loss: 0.572731\n",
      "epoch 190; iter: 0; batch classifier loss: 0.369755; batch adversarial loss: 0.588666\n",
      "epoch 191; iter: 0; batch classifier loss: 0.234604; batch adversarial loss: 0.560870\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330343; batch adversarial loss: 0.545539\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402447; batch adversarial loss: 0.545013\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322663; batch adversarial loss: 0.497813\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302817; batch adversarial loss: 0.524425\n",
      "epoch 196; iter: 0; batch classifier loss: 0.293206; batch adversarial loss: 0.664978\n",
      "epoch 197; iter: 0; batch classifier loss: 0.275987; batch adversarial loss: 0.551549\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329288; batch adversarial loss: 0.554556\n",
      "epoch 199; iter: 0; batch classifier loss: 0.324667; batch adversarial loss: 0.535568\n",
      "epoch 0; iter: 0; batch classifier loss: 0.775665; batch adversarial loss: 0.789136\n",
      "epoch 1; iter: 0; batch classifier loss: 0.665934; batch adversarial loss: 0.737273\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547453; batch adversarial loss: 0.701085\n",
      "epoch 3; iter: 0; batch classifier loss: 0.564876; batch adversarial loss: 0.659812\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545128; batch adversarial loss: 0.656254\n",
      "epoch 5; iter: 0; batch classifier loss: 0.508717; batch adversarial loss: 0.627665\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522387; batch adversarial loss: 0.619972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538286; batch adversarial loss: 0.610716\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564257; batch adversarial loss: 0.615932\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528310; batch adversarial loss: 0.571929\n",
      "epoch 10; iter: 0; batch classifier loss: 0.591868; batch adversarial loss: 0.573665\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565475; batch adversarial loss: 0.587189\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528392; batch adversarial loss: 0.596448\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526033; batch adversarial loss: 0.606059\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543218; batch adversarial loss: 0.514697\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503747; batch adversarial loss: 0.524838\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508737; batch adversarial loss: 0.560449\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503564; batch adversarial loss: 0.531586\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444433; batch adversarial loss: 0.573758\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483206; batch adversarial loss: 0.621969\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525894; batch adversarial loss: 0.584408\n",
      "epoch 21; iter: 0; batch classifier loss: 0.567771; batch adversarial loss: 0.664988\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502632; batch adversarial loss: 0.539920\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482934; batch adversarial loss: 0.608797\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526721; batch adversarial loss: 0.603684\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481899; batch adversarial loss: 0.539252\n",
      "epoch 26; iter: 0; batch classifier loss: 0.532111; batch adversarial loss: 0.588522\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469029; batch adversarial loss: 0.558026\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422938; batch adversarial loss: 0.471670\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436531; batch adversarial loss: 0.539541\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459225; batch adversarial loss: 0.490957\n",
      "epoch 31; iter: 0; batch classifier loss: 0.538151; batch adversarial loss: 0.570950\n",
      "epoch 32; iter: 0; batch classifier loss: 0.514817; batch adversarial loss: 0.562545\n",
      "epoch 33; iter: 0; batch classifier loss: 0.521385; batch adversarial loss: 0.504811\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473351; batch adversarial loss: 0.461117\n",
      "epoch 35; iter: 0; batch classifier loss: 0.506408; batch adversarial loss: 0.511762\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490863; batch adversarial loss: 0.477044\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470499; batch adversarial loss: 0.528129\n",
      "epoch 38; iter: 0; batch classifier loss: 0.524397; batch adversarial loss: 0.553882\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454624; batch adversarial loss: 0.623304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443595; batch adversarial loss: 0.544663\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445106; batch adversarial loss: 0.552928\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425315; batch adversarial loss: 0.544918\n",
      "epoch 43; iter: 0; batch classifier loss: 0.357962; batch adversarial loss: 0.642857\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395741; batch adversarial loss: 0.553137\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399650; batch adversarial loss: 0.492284\n",
      "epoch 46; iter: 0; batch classifier loss: 0.488191; batch adversarial loss: 0.571149\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450579; batch adversarial loss: 0.553339\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483121; batch adversarial loss: 0.579793\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439945; batch adversarial loss: 0.553643\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458574; batch adversarial loss: 0.571743\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408756; batch adversarial loss: 0.544648\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399180; batch adversarial loss: 0.545814\n",
      "epoch 53; iter: 0; batch classifier loss: 0.455809; batch adversarial loss: 0.518152\n",
      "epoch 54; iter: 0; batch classifier loss: 0.500719; batch adversarial loss: 0.578600\n",
      "epoch 55; iter: 0; batch classifier loss: 0.484311; batch adversarial loss: 0.681025\n",
      "epoch 56; iter: 0; batch classifier loss: 0.386185; batch adversarial loss: 0.536296\n",
      "epoch 57; iter: 0; batch classifier loss: 0.481169; batch adversarial loss: 0.560487\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407318; batch adversarial loss: 0.570545\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408163; batch adversarial loss: 0.456957\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456230; batch adversarial loss: 0.472368\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455771; batch adversarial loss: 0.602896\n",
      "epoch 62; iter: 0; batch classifier loss: 0.504400; batch adversarial loss: 0.551303\n",
      "epoch 63; iter: 0; batch classifier loss: 0.373520; batch adversarial loss: 0.595472\n",
      "epoch 64; iter: 0; batch classifier loss: 0.443316; batch adversarial loss: 0.567086\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437192; batch adversarial loss: 0.534214\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446958; batch adversarial loss: 0.529091\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395241; batch adversarial loss: 0.528209\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445173; batch adversarial loss: 0.528354\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424404; batch adversarial loss: 0.562092\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447418; batch adversarial loss: 0.490361\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425376; batch adversarial loss: 0.490141\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438380; batch adversarial loss: 0.562482\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386794; batch adversarial loss: 0.535841\n",
      "epoch 74; iter: 0; batch classifier loss: 0.362105; batch adversarial loss: 0.562145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.313959; batch adversarial loss: 0.481840\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409851; batch adversarial loss: 0.562902\n",
      "epoch 77; iter: 0; batch classifier loss: 0.373338; batch adversarial loss: 0.563225\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415035; batch adversarial loss: 0.544778\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428720; batch adversarial loss: 0.571328\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423898; batch adversarial loss: 0.544603\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396164; batch adversarial loss: 0.553443\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420688; batch adversarial loss: 0.562598\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341493; batch adversarial loss: 0.544833\n",
      "epoch 84; iter: 0; batch classifier loss: 0.352413; batch adversarial loss: 0.527219\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441455; batch adversarial loss: 0.527494\n",
      "epoch 86; iter: 0; batch classifier loss: 0.359035; batch adversarial loss: 0.499779\n",
      "epoch 87; iter: 0; batch classifier loss: 0.459563; batch adversarial loss: 0.509189\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406226; batch adversarial loss: 0.569977\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379946; batch adversarial loss: 0.482131\n",
      "epoch 90; iter: 0; batch classifier loss: 0.454615; batch adversarial loss: 0.545454\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393937; batch adversarial loss: 0.526631\n",
      "epoch 92; iter: 0; batch classifier loss: 0.409918; batch adversarial loss: 0.517659\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441053; batch adversarial loss: 0.491211\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368551; batch adversarial loss: 0.581829\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420676; batch adversarial loss: 0.544984\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417648; batch adversarial loss: 0.482845\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334043; batch adversarial loss: 0.489604\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392415; batch adversarial loss: 0.517947\n",
      "epoch 99; iter: 0; batch classifier loss: 0.324450; batch adversarial loss: 0.562296\n",
      "epoch 100; iter: 0; batch classifier loss: 0.434108; batch adversarial loss: 0.490825\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359996; batch adversarial loss: 0.578954\n",
      "epoch 102; iter: 0; batch classifier loss: 0.462533; batch adversarial loss: 0.481804\n",
      "epoch 103; iter: 0; batch classifier loss: 0.349141; batch adversarial loss: 0.608231\n",
      "epoch 104; iter: 0; batch classifier loss: 0.404046; batch adversarial loss: 0.499007\n",
      "epoch 105; iter: 0; batch classifier loss: 0.279417; batch adversarial loss: 0.586715\n",
      "epoch 106; iter: 0; batch classifier loss: 0.406597; batch adversarial loss: 0.605254\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363033; batch adversarial loss: 0.578164\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396211; batch adversarial loss: 0.473278\n",
      "epoch 109; iter: 0; batch classifier loss: 0.424519; batch adversarial loss: 0.535063\n",
      "epoch 110; iter: 0; batch classifier loss: 0.416837; batch adversarial loss: 0.595486\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361846; batch adversarial loss: 0.499436\n",
      "epoch 112; iter: 0; batch classifier loss: 0.399681; batch adversarial loss: 0.518996\n",
      "epoch 113; iter: 0; batch classifier loss: 0.506489; batch adversarial loss: 0.554809\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380326; batch adversarial loss: 0.561835\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417248; batch adversarial loss: 0.503006\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387226; batch adversarial loss: 0.571555\n",
      "epoch 117; iter: 0; batch classifier loss: 0.417355; batch adversarial loss: 0.509156\n",
      "epoch 118; iter: 0; batch classifier loss: 0.424078; batch adversarial loss: 0.542964\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414199; batch adversarial loss: 0.544514\n",
      "epoch 120; iter: 0; batch classifier loss: 0.443809; batch adversarial loss: 0.544530\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356626; batch adversarial loss: 0.589082\n",
      "epoch 122; iter: 0; batch classifier loss: 0.305188; batch adversarial loss: 0.661657\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414331; batch adversarial loss: 0.535312\n",
      "epoch 124; iter: 0; batch classifier loss: 0.413002; batch adversarial loss: 0.527010\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360841; batch adversarial loss: 0.591934\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360177; batch adversarial loss: 0.591577\n",
      "epoch 127; iter: 0; batch classifier loss: 0.405213; batch adversarial loss: 0.581143\n",
      "epoch 128; iter: 0; batch classifier loss: 0.426850; batch adversarial loss: 0.561570\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324692; batch adversarial loss: 0.553566\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353507; batch adversarial loss: 0.517903\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385594; batch adversarial loss: 0.589469\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360672; batch adversarial loss: 0.491042\n",
      "epoch 133; iter: 0; batch classifier loss: 0.426902; batch adversarial loss: 0.579444\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369996; batch adversarial loss: 0.536472\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366557; batch adversarial loss: 0.515615\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333685; batch adversarial loss: 0.545082\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396529; batch adversarial loss: 0.561697\n",
      "epoch 138; iter: 0; batch classifier loss: 0.343600; batch adversarial loss: 0.509864\n",
      "epoch 139; iter: 0; batch classifier loss: 0.289710; batch adversarial loss: 0.544660\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358799; batch adversarial loss: 0.482413\n",
      "epoch 141; iter: 0; batch classifier loss: 0.362905; batch adversarial loss: 0.537413\n",
      "epoch 142; iter: 0; batch classifier loss: 0.279671; batch adversarial loss: 0.533660\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395165; batch adversarial loss: 0.516781\n",
      "epoch 144; iter: 0; batch classifier loss: 0.329794; batch adversarial loss: 0.564038\n",
      "epoch 145; iter: 0; batch classifier loss: 0.361153; batch adversarial loss: 0.545711\n",
      "epoch 146; iter: 0; batch classifier loss: 0.447962; batch adversarial loss: 0.493210\n",
      "epoch 147; iter: 0; batch classifier loss: 0.450558; batch adversarial loss: 0.678106\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365376; batch adversarial loss: 0.534470\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418933; batch adversarial loss: 0.555133\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342913; batch adversarial loss: 0.664295\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395101; batch adversarial loss: 0.554621\n",
      "epoch 152; iter: 0; batch classifier loss: 0.358201; batch adversarial loss: 0.599608\n",
      "epoch 153; iter: 0; batch classifier loss: 0.397494; batch adversarial loss: 0.608378\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366175; batch adversarial loss: 0.507786\n",
      "epoch 155; iter: 0; batch classifier loss: 0.453814; batch adversarial loss: 0.626602\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325951; batch adversarial loss: 0.571585\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381807; batch adversarial loss: 0.553870\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352556; batch adversarial loss: 0.553549\n",
      "epoch 159; iter: 0; batch classifier loss: 0.308569; batch adversarial loss: 0.607869\n",
      "epoch 160; iter: 0; batch classifier loss: 0.354310; batch adversarial loss: 0.597949\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410769; batch adversarial loss: 0.544223\n",
      "epoch 162; iter: 0; batch classifier loss: 0.289446; batch adversarial loss: 0.599022\n",
      "epoch 163; iter: 0; batch classifier loss: 0.390674; batch adversarial loss: 0.589634\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376125; batch adversarial loss: 0.571566\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349560; batch adversarial loss: 0.580142\n",
      "epoch 166; iter: 0; batch classifier loss: 0.305467; batch adversarial loss: 0.508731\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345565; batch adversarial loss: 0.544415\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362182; batch adversarial loss: 0.499354\n",
      "epoch 169; iter: 0; batch classifier loss: 0.323315; batch adversarial loss: 0.500293\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318265; batch adversarial loss: 0.562350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.326571; batch adversarial loss: 0.606686\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365866; batch adversarial loss: 0.500329\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342284; batch adversarial loss: 0.562676\n",
      "epoch 174; iter: 0; batch classifier loss: 0.467267; batch adversarial loss: 0.473694\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332694; batch adversarial loss: 0.596039\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364322; batch adversarial loss: 0.527668\n",
      "epoch 177; iter: 0; batch classifier loss: 0.429182; batch adversarial loss: 0.580735\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383484; batch adversarial loss: 0.514826\n",
      "epoch 179; iter: 0; batch classifier loss: 0.297972; batch adversarial loss: 0.599061\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372621; batch adversarial loss: 0.594282\n",
      "epoch 181; iter: 0; batch classifier loss: 0.388403; batch adversarial loss: 0.516400\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336439; batch adversarial loss: 0.630829\n",
      "epoch 183; iter: 0; batch classifier loss: 0.331752; batch adversarial loss: 0.510553\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336278; batch adversarial loss: 0.536061\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356002; batch adversarial loss: 0.571989\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343008; batch adversarial loss: 0.609167\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369872; batch adversarial loss: 0.600338\n",
      "epoch 188; iter: 0; batch classifier loss: 0.399075; batch adversarial loss: 0.591014\n",
      "epoch 189; iter: 0; batch classifier loss: 0.400520; batch adversarial loss: 0.499255\n",
      "epoch 190; iter: 0; batch classifier loss: 0.377153; batch adversarial loss: 0.534042\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362833; batch adversarial loss: 0.498742\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394123; batch adversarial loss: 0.562558\n",
      "epoch 193; iter: 0; batch classifier loss: 0.414042; batch adversarial loss: 0.481510\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379665; batch adversarial loss: 0.589653\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351981; batch adversarial loss: 0.562297\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321670; batch adversarial loss: 0.543964\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364728; batch adversarial loss: 0.483078\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323094; batch adversarial loss: 0.569802\n",
      "epoch 199; iter: 0; batch classifier loss: 0.343503; batch adversarial loss: 0.517319\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711693; batch adversarial loss: 0.948087\n",
      "epoch 1; iter: 0; batch classifier loss: 0.771706; batch adversarial loss: 1.057600\n",
      "epoch 2; iter: 0; batch classifier loss: 0.776939; batch adversarial loss: 1.015661\n",
      "epoch 3; iter: 0; batch classifier loss: 0.841669; batch adversarial loss: 0.894329\n",
      "epoch 4; iter: 0; batch classifier loss: 0.637090; batch adversarial loss: 0.839969\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509809; batch adversarial loss: 0.726301\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589099; batch adversarial loss: 0.714181\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522299; batch adversarial loss: 0.681890\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527332; batch adversarial loss: 0.641888\n",
      "epoch 9; iter: 0; batch classifier loss: 0.588342; batch adversarial loss: 0.651738\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558668; batch adversarial loss: 0.625925\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518979; batch adversarial loss: 0.620714\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553686; batch adversarial loss: 0.596095\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542192; batch adversarial loss: 0.576394\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517889; batch adversarial loss: 0.621414\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496363; batch adversarial loss: 0.585915\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531065; batch adversarial loss: 0.553974\n",
      "epoch 17; iter: 0; batch classifier loss: 0.461497; batch adversarial loss: 0.557675\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539696; batch adversarial loss: 0.543434\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508181; batch adversarial loss: 0.551607\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528110; batch adversarial loss: 0.565480\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527025; batch adversarial loss: 0.504571\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517996; batch adversarial loss: 0.572639\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455328; batch adversarial loss: 0.527877\n",
      "epoch 24; iter: 0; batch classifier loss: 0.550156; batch adversarial loss: 0.534112\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461511; batch adversarial loss: 0.537848\n",
      "epoch 26; iter: 0; batch classifier loss: 0.411144; batch adversarial loss: 0.554824\n",
      "epoch 27; iter: 0; batch classifier loss: 0.583162; batch adversarial loss: 0.563737\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463490; batch adversarial loss: 0.555497\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501619; batch adversarial loss: 0.562941\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417972; batch adversarial loss: 0.681164\n",
      "epoch 31; iter: 0; batch classifier loss: 0.419134; batch adversarial loss: 0.558973\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472395; batch adversarial loss: 0.585650\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437315; batch adversarial loss: 0.535347\n",
      "epoch 34; iter: 0; batch classifier loss: 0.533293; batch adversarial loss: 0.648622\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460803; batch adversarial loss: 0.554627\n",
      "epoch 36; iter: 0; batch classifier loss: 0.529563; batch adversarial loss: 0.565906\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500329; batch adversarial loss: 0.553246\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470314; batch adversarial loss: 0.576331\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411142; batch adversarial loss: 0.586803\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472587; batch adversarial loss: 0.533291\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465801; batch adversarial loss: 0.494323\n",
      "epoch 42; iter: 0; batch classifier loss: 0.385965; batch adversarial loss: 0.474411\n",
      "epoch 43; iter: 0; batch classifier loss: 0.462327; batch adversarial loss: 0.523801\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490291; batch adversarial loss: 0.571850\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407885; batch adversarial loss: 0.640308\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378938; batch adversarial loss: 0.500833\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452759; batch adversarial loss: 0.582154\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435036; batch adversarial loss: 0.475176\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433352; batch adversarial loss: 0.567671\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453692; batch adversarial loss: 0.573581\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454067; batch adversarial loss: 0.527688\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412455; batch adversarial loss: 0.558100\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428959; batch adversarial loss: 0.511332\n",
      "epoch 54; iter: 0; batch classifier loss: 0.500673; batch adversarial loss: 0.584225\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433142; batch adversarial loss: 0.551847\n",
      "epoch 56; iter: 0; batch classifier loss: 0.370551; batch adversarial loss: 0.625206\n",
      "epoch 57; iter: 0; batch classifier loss: 0.430437; batch adversarial loss: 0.554577\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429730; batch adversarial loss: 0.563861\n",
      "epoch 59; iter: 0; batch classifier loss: 0.396915; batch adversarial loss: 0.543031\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401204; batch adversarial loss: 0.524109\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386683; batch adversarial loss: 0.582131\n",
      "epoch 62; iter: 0; batch classifier loss: 0.454271; batch adversarial loss: 0.535828\n",
      "epoch 63; iter: 0; batch classifier loss: 0.353071; batch adversarial loss: 0.507273\n",
      "epoch 64; iter: 0; batch classifier loss: 0.334930; batch adversarial loss: 0.590084\n",
      "epoch 65; iter: 0; batch classifier loss: 0.452185; batch adversarial loss: 0.534788\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449778; batch adversarial loss: 0.591947\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403880; batch adversarial loss: 0.489639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.460066; batch adversarial loss: 0.589352\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405621; batch adversarial loss: 0.582066\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407797; batch adversarial loss: 0.609442\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436914; batch adversarial loss: 0.534755\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413298; batch adversarial loss: 0.508140\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437348; batch adversarial loss: 0.499784\n",
      "epoch 74; iter: 0; batch classifier loss: 0.428951; batch adversarial loss: 0.563121\n",
      "epoch 75; iter: 0; batch classifier loss: 0.493488; batch adversarial loss: 0.487608\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385928; batch adversarial loss: 0.517013\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409976; batch adversarial loss: 0.542763\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444667; batch adversarial loss: 0.425581\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353423; batch adversarial loss: 0.553514\n",
      "epoch 80; iter: 0; batch classifier loss: 0.453603; batch adversarial loss: 0.535082\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433262; batch adversarial loss: 0.516920\n",
      "epoch 82; iter: 0; batch classifier loss: 0.431891; batch adversarial loss: 0.517142\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383177; batch adversarial loss: 0.599200\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386382; batch adversarial loss: 0.525232\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400648; batch adversarial loss: 0.534295\n",
      "epoch 86; iter: 0; batch classifier loss: 0.352350; batch adversarial loss: 0.609428\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370866; batch adversarial loss: 0.535446\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401384; batch adversarial loss: 0.507354\n",
      "epoch 89; iter: 0; batch classifier loss: 0.340559; batch adversarial loss: 0.571428\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425689; batch adversarial loss: 0.563071\n",
      "epoch 91; iter: 0; batch classifier loss: 0.430828; batch adversarial loss: 0.525490\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408559; batch adversarial loss: 0.544161\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412070; batch adversarial loss: 0.545129\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372633; batch adversarial loss: 0.544619\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368745; batch adversarial loss: 0.581446\n",
      "epoch 96; iter: 0; batch classifier loss: 0.456416; batch adversarial loss: 0.554151\n",
      "epoch 97; iter: 0; batch classifier loss: 0.503994; batch adversarial loss: 0.460546\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410272; batch adversarial loss: 0.590035\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414822; batch adversarial loss: 0.434229\n",
      "epoch 100; iter: 0; batch classifier loss: 0.485147; batch adversarial loss: 0.573085\n",
      "epoch 101; iter: 0; batch classifier loss: 0.315537; batch adversarial loss: 0.545494\n",
      "epoch 102; iter: 0; batch classifier loss: 0.384597; batch adversarial loss: 0.480256\n",
      "epoch 103; iter: 0; batch classifier loss: 0.422254; batch adversarial loss: 0.515922\n",
      "epoch 104; iter: 0; batch classifier loss: 0.417414; batch adversarial loss: 0.563973\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418020; batch adversarial loss: 0.581009\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443589; batch adversarial loss: 0.545798\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348518; batch adversarial loss: 0.488206\n",
      "epoch 108; iter: 0; batch classifier loss: 0.372051; batch adversarial loss: 0.562619\n",
      "epoch 109; iter: 0; batch classifier loss: 0.311052; batch adversarial loss: 0.562934\n",
      "epoch 110; iter: 0; batch classifier loss: 0.327742; batch adversarial loss: 0.544276\n",
      "epoch 111; iter: 0; batch classifier loss: 0.397566; batch adversarial loss: 0.497024\n",
      "epoch 112; iter: 0; batch classifier loss: 0.442354; batch adversarial loss: 0.544269\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350358; batch adversarial loss: 0.478954\n",
      "epoch 114; iter: 0; batch classifier loss: 0.361776; batch adversarial loss: 0.545484\n",
      "epoch 115; iter: 0; batch classifier loss: 0.436116; batch adversarial loss: 0.516382\n",
      "epoch 116; iter: 0; batch classifier loss: 0.341750; batch adversarial loss: 0.599170\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325288; batch adversarial loss: 0.570764\n",
      "epoch 118; iter: 0; batch classifier loss: 0.359254; batch adversarial loss: 0.490546\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428849; batch adversarial loss: 0.497873\n",
      "epoch 120; iter: 0; batch classifier loss: 0.498527; batch adversarial loss: 0.616345\n",
      "epoch 121; iter: 0; batch classifier loss: 0.512949; batch adversarial loss: 0.570717\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415698; batch adversarial loss: 0.495499\n",
      "epoch 123; iter: 0; batch classifier loss: 0.432148; batch adversarial loss: 0.564192\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392932; batch adversarial loss: 0.628588\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353509; batch adversarial loss: 0.514720\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347889; batch adversarial loss: 0.553179\n",
      "epoch 127; iter: 0; batch classifier loss: 0.423356; batch adversarial loss: 0.602576\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368144; batch adversarial loss: 0.572960\n",
      "epoch 129; iter: 0; batch classifier loss: 0.433695; batch adversarial loss: 0.515833\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354668; batch adversarial loss: 0.580128\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366018; batch adversarial loss: 0.516416\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335345; batch adversarial loss: 0.518197\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372825; batch adversarial loss: 0.527827\n",
      "epoch 134; iter: 0; batch classifier loss: 0.404192; batch adversarial loss: 0.487089\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402328; batch adversarial loss: 0.552902\n",
      "epoch 136; iter: 0; batch classifier loss: 0.290885; batch adversarial loss: 0.551873\n",
      "epoch 137; iter: 0; batch classifier loss: 0.453864; batch adversarial loss: 0.668755\n",
      "epoch 138; iter: 0; batch classifier loss: 0.424024; batch adversarial loss: 0.478981\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360363; batch adversarial loss: 0.516609\n",
      "epoch 140; iter: 0; batch classifier loss: 0.353959; batch adversarial loss: 0.608938\n",
      "epoch 141; iter: 0; batch classifier loss: 0.457426; batch adversarial loss: 0.544848\n",
      "epoch 142; iter: 0; batch classifier loss: 0.337088; batch adversarial loss: 0.516538\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363946; batch adversarial loss: 0.544708\n",
      "epoch 144; iter: 0; batch classifier loss: 0.305740; batch adversarial loss: 0.535140\n",
      "epoch 145; iter: 0; batch classifier loss: 0.446675; batch adversarial loss: 0.535069\n",
      "epoch 146; iter: 0; batch classifier loss: 0.392655; batch adversarial loss: 0.600845\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355125; batch adversarial loss: 0.516653\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417732; batch adversarial loss: 0.581758\n",
      "epoch 149; iter: 0; batch classifier loss: 0.436226; batch adversarial loss: 0.562920\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344493; batch adversarial loss: 0.497799\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395900; batch adversarial loss: 0.550416\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360061; batch adversarial loss: 0.516103\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367356; batch adversarial loss: 0.618198\n",
      "epoch 154; iter: 0; batch classifier loss: 0.428037; batch adversarial loss: 0.647206\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364458; batch adversarial loss: 0.561267\n",
      "epoch 156; iter: 0; batch classifier loss: 0.326599; batch adversarial loss: 0.507256\n",
      "epoch 157; iter: 0; batch classifier loss: 0.422294; batch adversarial loss: 0.516307\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382297; batch adversarial loss: 0.516627\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356912; batch adversarial loss: 0.535248\n",
      "epoch 160; iter: 0; batch classifier loss: 0.325399; batch adversarial loss: 0.525911\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373919; batch adversarial loss: 0.600856\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311058; batch adversarial loss: 0.562921\n",
      "epoch 163; iter: 0; batch classifier loss: 0.412048; batch adversarial loss: 0.590872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.351657; batch adversarial loss: 0.535396\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349927; batch adversarial loss: 0.562319\n",
      "epoch 166; iter: 0; batch classifier loss: 0.341728; batch adversarial loss: 0.619244\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395731; batch adversarial loss: 0.646420\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327294; batch adversarial loss: 0.507517\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339297; batch adversarial loss: 0.470338\n",
      "epoch 170; iter: 0; batch classifier loss: 0.331701; batch adversarial loss: 0.470713\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333936; batch adversarial loss: 0.489345\n",
      "epoch 172; iter: 0; batch classifier loss: 0.324332; batch adversarial loss: 0.535860\n",
      "epoch 173; iter: 0; batch classifier loss: 0.395500; batch adversarial loss: 0.515898\n",
      "epoch 174; iter: 0; batch classifier loss: 0.402790; batch adversarial loss: 0.581363\n",
      "epoch 175; iter: 0; batch classifier loss: 0.396289; batch adversarial loss: 0.561848\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413009; batch adversarial loss: 0.488000\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336154; batch adversarial loss: 0.498496\n",
      "epoch 178; iter: 0; batch classifier loss: 0.366273; batch adversarial loss: 0.460812\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355031; batch adversarial loss: 0.507580\n",
      "epoch 180; iter: 0; batch classifier loss: 0.386624; batch adversarial loss: 0.507888\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343109; batch adversarial loss: 0.563144\n",
      "epoch 182; iter: 0; batch classifier loss: 0.345141; batch adversarial loss: 0.600561\n",
      "epoch 183; iter: 0; batch classifier loss: 0.434231; batch adversarial loss: 0.562432\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356395; batch adversarial loss: 0.497281\n",
      "epoch 185; iter: 0; batch classifier loss: 0.394017; batch adversarial loss: 0.525773\n",
      "epoch 186; iter: 0; batch classifier loss: 0.397779; batch adversarial loss: 0.470582\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345263; batch adversarial loss: 0.552946\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337500; batch adversarial loss: 0.507310\n",
      "epoch 189; iter: 0; batch classifier loss: 0.483753; batch adversarial loss: 0.544639\n",
      "epoch 190; iter: 0; batch classifier loss: 0.445594; batch adversarial loss: 0.581585\n",
      "epoch 191; iter: 0; batch classifier loss: 0.376395; batch adversarial loss: 0.581442\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323814; batch adversarial loss: 0.488931\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337545; batch adversarial loss: 0.590632\n",
      "epoch 194; iter: 0; batch classifier loss: 0.301818; batch adversarial loss: 0.516798\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317126; batch adversarial loss: 0.478457\n",
      "epoch 196; iter: 0; batch classifier loss: 0.425564; batch adversarial loss: 0.497787\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323294; batch adversarial loss: 0.618363\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331065; batch adversarial loss: 0.553853\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396598; batch adversarial loss: 0.506626\n",
      "epoch 0; iter: 0; batch classifier loss: 0.816645; batch adversarial loss: 0.682203\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597171; batch adversarial loss: 0.653243\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547431; batch adversarial loss: 0.620527\n",
      "epoch 3; iter: 0; batch classifier loss: 0.608772; batch adversarial loss: 0.628682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.618056; batch adversarial loss: 0.630327\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521895; batch adversarial loss: 0.595289\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541248; batch adversarial loss: 0.571227\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555871; batch adversarial loss: 0.579741\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512380; batch adversarial loss: 0.565538\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538111; batch adversarial loss: 0.539779\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517750; batch adversarial loss: 0.604943\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592973; batch adversarial loss: 0.625574\n",
      "epoch 12; iter: 0; batch classifier loss: 0.591308; batch adversarial loss: 0.565345\n",
      "epoch 13; iter: 0; batch classifier loss: 0.603265; batch adversarial loss: 0.578140\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438967; batch adversarial loss: 0.587879\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534504; batch adversarial loss: 0.607923\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522160; batch adversarial loss: 0.541273\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513105; batch adversarial loss: 0.523283\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479341; batch adversarial loss: 0.599741\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516196; batch adversarial loss: 0.547647\n",
      "epoch 20; iter: 0; batch classifier loss: 0.550118; batch adversarial loss: 0.571260\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509949; batch adversarial loss: 0.517898\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497733; batch adversarial loss: 0.515067\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466729; batch adversarial loss: 0.571613\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518101; batch adversarial loss: 0.578868\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478493; batch adversarial loss: 0.545907\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479056; batch adversarial loss: 0.570236\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469791; batch adversarial loss: 0.554189\n",
      "epoch 28; iter: 0; batch classifier loss: 0.443626; batch adversarial loss: 0.493148\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521172; batch adversarial loss: 0.476580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.522979; batch adversarial loss: 0.501912\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462458; batch adversarial loss: 0.529223\n",
      "epoch 32; iter: 0; batch classifier loss: 0.456193; batch adversarial loss: 0.515953\n",
      "epoch 33; iter: 0; batch classifier loss: 0.418553; batch adversarial loss: 0.587803\n",
      "epoch 34; iter: 0; batch classifier loss: 0.536967; batch adversarial loss: 0.454565\n",
      "epoch 35; iter: 0; batch classifier loss: 0.510617; batch adversarial loss: 0.507915\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443789; batch adversarial loss: 0.555003\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418170; batch adversarial loss: 0.527348\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427682; batch adversarial loss: 0.480501\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470130; batch adversarial loss: 0.451013\n",
      "epoch 40; iter: 0; batch classifier loss: 0.410476; batch adversarial loss: 0.486181\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433471; batch adversarial loss: 0.525524\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498429; batch adversarial loss: 0.553653\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458016; batch adversarial loss: 0.489233\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403993; batch adversarial loss: 0.601813\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434643; batch adversarial loss: 0.589131\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447489; batch adversarial loss: 0.570759\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487806; batch adversarial loss: 0.545376\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445089; batch adversarial loss: 0.491196\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383128; batch adversarial loss: 0.634553\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455758; batch adversarial loss: 0.625043\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421947; batch adversarial loss: 0.589082\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432284; batch adversarial loss: 0.518036\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443343; batch adversarial loss: 0.606929\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397391; batch adversarial loss: 0.490447\n",
      "epoch 55; iter: 0; batch classifier loss: 0.372886; batch adversarial loss: 0.572095\n",
      "epoch 56; iter: 0; batch classifier loss: 0.492784; batch adversarial loss: 0.590219\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406330; batch adversarial loss: 0.600169\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469665; batch adversarial loss: 0.589781\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476695; batch adversarial loss: 0.516866\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370005; batch adversarial loss: 0.609088\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438240; batch adversarial loss: 0.544684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.357003; batch adversarial loss: 0.453148\n",
      "epoch 63; iter: 0; batch classifier loss: 0.452975; batch adversarial loss: 0.590174\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431805; batch adversarial loss: 0.453327\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386599; batch adversarial loss: 0.636416\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420063; batch adversarial loss: 0.526453\n",
      "epoch 67; iter: 0; batch classifier loss: 0.355369; batch adversarial loss: 0.516991\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417781; batch adversarial loss: 0.662246\n",
      "epoch 69; iter: 0; batch classifier loss: 0.479446; batch adversarial loss: 0.480928\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409024; batch adversarial loss: 0.462952\n",
      "epoch 71; iter: 0; batch classifier loss: 0.401673; batch adversarial loss: 0.462562\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438562; batch adversarial loss: 0.544387\n",
      "epoch 73; iter: 0; batch classifier loss: 0.420318; batch adversarial loss: 0.499574\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408164; batch adversarial loss: 0.454250\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413047; batch adversarial loss: 0.481081\n",
      "epoch 76; iter: 0; batch classifier loss: 0.347614; batch adversarial loss: 0.490081\n",
      "epoch 77; iter: 0; batch classifier loss: 0.334309; batch adversarial loss: 0.535517\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404479; batch adversarial loss: 0.562853\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394072; batch adversarial loss: 0.545501\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438049; batch adversarial loss: 0.572108\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367976; batch adversarial loss: 0.534538\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376328; batch adversarial loss: 0.462218\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382674; batch adversarial loss: 0.543985\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426221; batch adversarial loss: 0.544781\n",
      "epoch 85; iter: 0; batch classifier loss: 0.439421; batch adversarial loss: 0.572238\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373226; batch adversarial loss: 0.535913\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370774; batch adversarial loss: 0.589955\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424312; batch adversarial loss: 0.525830\n",
      "epoch 89; iter: 0; batch classifier loss: 0.349000; batch adversarial loss: 0.489610\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363640; batch adversarial loss: 0.535291\n",
      "epoch 91; iter: 0; batch classifier loss: 0.479827; batch adversarial loss: 0.489015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.349072; batch adversarial loss: 0.605557\n",
      "epoch 93; iter: 0; batch classifier loss: 0.430168; batch adversarial loss: 0.625876\n",
      "epoch 94; iter: 0; batch classifier loss: 0.341212; batch adversarial loss: 0.598957\n",
      "epoch 95; iter: 0; batch classifier loss: 0.435363; batch adversarial loss: 0.525044\n",
      "epoch 96; iter: 0; batch classifier loss: 0.407701; batch adversarial loss: 0.581595\n",
      "epoch 97; iter: 0; batch classifier loss: 0.433833; batch adversarial loss: 0.498961\n",
      "epoch 98; iter: 0; batch classifier loss: 0.333216; batch adversarial loss: 0.516587\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393906; batch adversarial loss: 0.591601\n",
      "epoch 100; iter: 0; batch classifier loss: 0.438215; batch adversarial loss: 0.525630\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420032; batch adversarial loss: 0.562484\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410945; batch adversarial loss: 0.534905\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346993; batch adversarial loss: 0.433708\n",
      "epoch 104; iter: 0; batch classifier loss: 0.408667; batch adversarial loss: 0.544796\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373764; batch adversarial loss: 0.553660\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412197; batch adversarial loss: 0.581397\n",
      "epoch 107; iter: 0; batch classifier loss: 0.342900; batch adversarial loss: 0.516838\n",
      "epoch 108; iter: 0; batch classifier loss: 0.365845; batch adversarial loss: 0.571445\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430057; batch adversarial loss: 0.516438\n",
      "epoch 110; iter: 0; batch classifier loss: 0.393530; batch adversarial loss: 0.608455\n",
      "epoch 111; iter: 0; batch classifier loss: 0.392054; batch adversarial loss: 0.526113\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388240; batch adversarial loss: 0.598120\n",
      "epoch 113; iter: 0; batch classifier loss: 0.348685; batch adversarial loss: 0.544534\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359896; batch adversarial loss: 0.517491\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367912; batch adversarial loss: 0.617803\n",
      "epoch 116; iter: 0; batch classifier loss: 0.461724; batch adversarial loss: 0.610363\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333377; batch adversarial loss: 0.563005\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395566; batch adversarial loss: 0.525744\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415081; batch adversarial loss: 0.489069\n",
      "epoch 120; iter: 0; batch classifier loss: 0.329176; batch adversarial loss: 0.526038\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388128; batch adversarial loss: 0.489339\n",
      "epoch 122; iter: 0; batch classifier loss: 0.407011; batch adversarial loss: 0.517029\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362601; batch adversarial loss: 0.516857\n",
      "epoch 124; iter: 0; batch classifier loss: 0.440628; batch adversarial loss: 0.535051\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401552; batch adversarial loss: 0.580899\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369499; batch adversarial loss: 0.534589\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408129; batch adversarial loss: 0.524741\n",
      "epoch 128; iter: 0; batch classifier loss: 0.455977; batch adversarial loss: 0.490209\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389604; batch adversarial loss: 0.573200\n",
      "epoch 130; iter: 0; batch classifier loss: 0.433453; batch adversarial loss: 0.489284\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363016; batch adversarial loss: 0.526663\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406297; batch adversarial loss: 0.526948\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336939; batch adversarial loss: 0.461648\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367980; batch adversarial loss: 0.517369\n",
      "epoch 135; iter: 0; batch classifier loss: 0.315822; batch adversarial loss: 0.499099\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366044; batch adversarial loss: 0.536135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403760; batch adversarial loss: 0.499179\n",
      "epoch 138; iter: 0; batch classifier loss: 0.352536; batch adversarial loss: 0.598287\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367863; batch adversarial loss: 0.553758\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327493; batch adversarial loss: 0.517757\n",
      "epoch 141; iter: 0; batch classifier loss: 0.361865; batch adversarial loss: 0.498988\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405454; batch adversarial loss: 0.507810\n",
      "epoch 143; iter: 0; batch classifier loss: 0.425942; batch adversarial loss: 0.562969\n",
      "epoch 144; iter: 0; batch classifier loss: 0.378995; batch adversarial loss: 0.471615\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366643; batch adversarial loss: 0.553530\n",
      "epoch 146; iter: 0; batch classifier loss: 0.335146; batch adversarial loss: 0.471712\n",
      "epoch 147; iter: 0; batch classifier loss: 0.333143; batch adversarial loss: 0.562892\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279034; batch adversarial loss: 0.553917\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391166; batch adversarial loss: 0.608341\n",
      "epoch 150; iter: 0; batch classifier loss: 0.495701; batch adversarial loss: 0.535533\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325853; batch adversarial loss: 0.525938\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405488; batch adversarial loss: 0.554090\n",
      "epoch 153; iter: 0; batch classifier loss: 0.439759; batch adversarial loss: 0.616481\n",
      "epoch 154; iter: 0; batch classifier loss: 0.364342; batch adversarial loss: 0.542200\n",
      "epoch 155; iter: 0; batch classifier loss: 0.395473; batch adversarial loss: 0.515832\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341169; batch adversarial loss: 0.536238\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372070; batch adversarial loss: 0.571092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.323914; batch adversarial loss: 0.534127\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372535; batch adversarial loss: 0.497312\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369770; batch adversarial loss: 0.480447\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319837; batch adversarial loss: 0.553333\n",
      "epoch 162; iter: 0; batch classifier loss: 0.367030; batch adversarial loss: 0.591765\n",
      "epoch 163; iter: 0; batch classifier loss: 0.284692; batch adversarial loss: 0.535910\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339157; batch adversarial loss: 0.573841\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366800; batch adversarial loss: 0.534936\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342541; batch adversarial loss: 0.489362\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383223; batch adversarial loss: 0.517070\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351575; batch adversarial loss: 0.570973\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408450; batch adversarial loss: 0.572772\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337264; batch adversarial loss: 0.572552\n",
      "epoch 171; iter: 0; batch classifier loss: 0.322215; batch adversarial loss: 0.600167\n",
      "epoch 172; iter: 0; batch classifier loss: 0.279672; batch adversarial loss: 0.600116\n",
      "epoch 173; iter: 0; batch classifier loss: 0.425014; batch adversarial loss: 0.535402\n",
      "epoch 174; iter: 0; batch classifier loss: 0.354771; batch adversarial loss: 0.572240\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378797; batch adversarial loss: 0.553727\n",
      "epoch 176; iter: 0; batch classifier loss: 0.306485; batch adversarial loss: 0.507663\n",
      "epoch 177; iter: 0; batch classifier loss: 0.309785; batch adversarial loss: 0.517257\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362460; batch adversarial loss: 0.526138\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389506; batch adversarial loss: 0.571965\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318440; batch adversarial loss: 0.526042\n",
      "epoch 181; iter: 0; batch classifier loss: 0.380624; batch adversarial loss: 0.626984\n",
      "epoch 182; iter: 0; batch classifier loss: 0.413881; batch adversarial loss: 0.508053\n",
      "epoch 183; iter: 0; batch classifier loss: 0.416721; batch adversarial loss: 0.571750\n",
      "epoch 184; iter: 0; batch classifier loss: 0.435675; batch adversarial loss: 0.544329\n",
      "epoch 185; iter: 0; batch classifier loss: 0.285673; batch adversarial loss: 0.544503\n",
      "epoch 186; iter: 0; batch classifier loss: 0.408880; batch adversarial loss: 0.453500\n",
      "epoch 187; iter: 0; batch classifier loss: 0.430102; batch adversarial loss: 0.553353\n",
      "epoch 188; iter: 0; batch classifier loss: 0.267439; batch adversarial loss: 0.562718\n",
      "epoch 189; iter: 0; batch classifier loss: 0.327119; batch adversarial loss: 0.471099\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384143; batch adversarial loss: 0.526786\n",
      "epoch 191; iter: 0; batch classifier loss: 0.287342; batch adversarial loss: 0.490530\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355524; batch adversarial loss: 0.544907\n",
      "epoch 193; iter: 0; batch classifier loss: 0.286137; batch adversarial loss: 0.617797\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368599; batch adversarial loss: 0.499051\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341761; batch adversarial loss: 0.553596\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381529; batch adversarial loss: 0.572161\n",
      "epoch 197; iter: 0; batch classifier loss: 0.423177; batch adversarial loss: 0.470977\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362171; batch adversarial loss: 0.526729\n",
      "epoch 199; iter: 0; batch classifier loss: 0.409006; batch adversarial loss: 0.544985\n",
      "epoch 0; iter: 0; batch classifier loss: 0.757842; batch adversarial loss: 0.693773\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608819; batch adversarial loss: 0.660995\n",
      "epoch 2; iter: 0; batch classifier loss: 0.516231; batch adversarial loss: 0.662808\n",
      "epoch 3; iter: 0; batch classifier loss: 0.527507; batch adversarial loss: 0.656400\n",
      "epoch 4; iter: 0; batch classifier loss: 0.599748; batch adversarial loss: 0.627265\n",
      "epoch 5; iter: 0; batch classifier loss: 0.604065; batch adversarial loss: 0.625819\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560099; batch adversarial loss: 0.618818\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524560; batch adversarial loss: 0.610106\n",
      "epoch 8; iter: 0; batch classifier loss: 0.636507; batch adversarial loss: 0.616628\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565419; batch adversarial loss: 0.559771\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521407; batch adversarial loss: 0.580691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.477923; batch adversarial loss: 0.538706\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547972; batch adversarial loss: 0.636306\n",
      "epoch 13; iter: 0; batch classifier loss: 0.620991; batch adversarial loss: 0.511674\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504182; batch adversarial loss: 0.597690\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470852; batch adversarial loss: 0.610464\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519364; batch adversarial loss: 0.601111\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492135; batch adversarial loss: 0.544266\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483166; batch adversarial loss: 0.566230\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495522; batch adversarial loss: 0.521062\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517960; batch adversarial loss: 0.524157\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509748; batch adversarial loss: 0.586427\n",
      "epoch 22; iter: 0; batch classifier loss: 0.541524; batch adversarial loss: 0.572267\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470739; batch adversarial loss: 0.591533\n",
      "epoch 24; iter: 0; batch classifier loss: 0.444796; batch adversarial loss: 0.512616\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428022; batch adversarial loss: 0.557537\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566220; batch adversarial loss: 0.583951\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441378; batch adversarial loss: 0.550886\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474908; batch adversarial loss: 0.557738\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494020; batch adversarial loss: 0.515767\n",
      "epoch 30; iter: 0; batch classifier loss: 0.412891; batch adversarial loss: 0.563316\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409805; batch adversarial loss: 0.539047\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409347; batch adversarial loss: 0.596416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.490694; batch adversarial loss: 0.559704\n",
      "epoch 34; iter: 0; batch classifier loss: 0.522309; batch adversarial loss: 0.500773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397102; batch adversarial loss: 0.571192\n",
      "epoch 36; iter: 0; batch classifier loss: 0.507239; batch adversarial loss: 0.544917\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461731; batch adversarial loss: 0.649946\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457648; batch adversarial loss: 0.588488\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468329; batch adversarial loss: 0.623033\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412400; batch adversarial loss: 0.545512\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422755; batch adversarial loss: 0.492388\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415530; batch adversarial loss: 0.571471\n",
      "epoch 43; iter: 0; batch classifier loss: 0.509943; batch adversarial loss: 0.544818\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456920; batch adversarial loss: 0.596324\n",
      "epoch 45; iter: 0; batch classifier loss: 0.503349; batch adversarial loss: 0.578808\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405098; batch adversarial loss: 0.536599\n",
      "epoch 47; iter: 0; batch classifier loss: 0.379793; batch adversarial loss: 0.545294\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388953; batch adversarial loss: 0.587616\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393253; batch adversarial loss: 0.579584\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479858; batch adversarial loss: 0.517569\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428615; batch adversarial loss: 0.607470\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425327; batch adversarial loss: 0.544570\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395495; batch adversarial loss: 0.554006\n",
      "epoch 54; iter: 0; batch classifier loss: 0.383471; batch adversarial loss: 0.545106\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465079; batch adversarial loss: 0.608173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.389191; batch adversarial loss: 0.607498\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443522; batch adversarial loss: 0.543868\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442920; batch adversarial loss: 0.590071\n",
      "epoch 59; iter: 0; batch classifier loss: 0.499370; batch adversarial loss: 0.554289\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457798; batch adversarial loss: 0.562738\n",
      "epoch 61; iter: 0; batch classifier loss: 0.359011; batch adversarial loss: 0.537035\n",
      "epoch 62; iter: 0; batch classifier loss: 0.454411; batch adversarial loss: 0.607426\n",
      "epoch 63; iter: 0; batch classifier loss: 0.443855; batch adversarial loss: 0.597990\n",
      "epoch 64; iter: 0; batch classifier loss: 0.451054; batch adversarial loss: 0.561428\n",
      "epoch 65; iter: 0; batch classifier loss: 0.363315; batch adversarial loss: 0.517871\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436145; batch adversarial loss: 0.526472\n",
      "epoch 67; iter: 0; batch classifier loss: 0.441066; batch adversarial loss: 0.552679\n",
      "epoch 68; iter: 0; batch classifier loss: 0.490647; batch adversarial loss: 0.562529\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371635; batch adversarial loss: 0.571111\n",
      "epoch 70; iter: 0; batch classifier loss: 0.342019; batch adversarial loss: 0.589529\n",
      "epoch 71; iter: 0; batch classifier loss: 0.340558; batch adversarial loss: 0.634576\n",
      "epoch 72; iter: 0; batch classifier loss: 0.344938; batch adversarial loss: 0.625231\n",
      "epoch 73; iter: 0; batch classifier loss: 0.343584; batch adversarial loss: 0.562334\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405655; batch adversarial loss: 0.562696\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422229; batch adversarial loss: 0.491150\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410401; batch adversarial loss: 0.527969\n",
      "epoch 77; iter: 0; batch classifier loss: 0.366375; batch adversarial loss: 0.599213\n",
      "epoch 78; iter: 0; batch classifier loss: 0.459531; batch adversarial loss: 0.578403\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377297; batch adversarial loss: 0.633232\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390924; batch adversarial loss: 0.580722\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443720; batch adversarial loss: 0.580832\n",
      "epoch 82; iter: 0; batch classifier loss: 0.343589; batch adversarial loss: 0.615760\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413113; batch adversarial loss: 0.526079\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403809; batch adversarial loss: 0.571043\n",
      "epoch 85; iter: 0; batch classifier loss: 0.467775; batch adversarial loss: 0.598619\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417471; batch adversarial loss: 0.481953\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376989; batch adversarial loss: 0.545117\n",
      "epoch 88; iter: 0; batch classifier loss: 0.407050; batch adversarial loss: 0.535663\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374420; batch adversarial loss: 0.615646\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399959; batch adversarial loss: 0.537496\n",
      "epoch 91; iter: 0; batch classifier loss: 0.442008; batch adversarial loss: 0.517786\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398247; batch adversarial loss: 0.562521\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427753; batch adversarial loss: 0.554342\n",
      "epoch 94; iter: 0; batch classifier loss: 0.395572; batch adversarial loss: 0.597905\n",
      "epoch 95; iter: 0; batch classifier loss: 0.372376; batch adversarial loss: 0.535607\n",
      "epoch 96; iter: 0; batch classifier loss: 0.421374; batch adversarial loss: 0.553361\n",
      "epoch 97; iter: 0; batch classifier loss: 0.428386; batch adversarial loss: 0.598415\n",
      "epoch 98; iter: 0; batch classifier loss: 0.354250; batch adversarial loss: 0.580935\n",
      "epoch 99; iter: 0; batch classifier loss: 0.473046; batch adversarial loss: 0.462851\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389922; batch adversarial loss: 0.526812\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406901; batch adversarial loss: 0.599258\n",
      "epoch 102; iter: 0; batch classifier loss: 0.339694; batch adversarial loss: 0.624251\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440457; batch adversarial loss: 0.580462\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377923; batch adversarial loss: 0.589639\n",
      "epoch 105; iter: 0; batch classifier loss: 0.348000; batch adversarial loss: 0.561961\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374691; batch adversarial loss: 0.462683\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413670; batch adversarial loss: 0.525626\n",
      "epoch 108; iter: 0; batch classifier loss: 0.409790; batch adversarial loss: 0.625769\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359876; batch adversarial loss: 0.563891\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381097; batch adversarial loss: 0.508804\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436092; batch adversarial loss: 0.554778\n",
      "epoch 112; iter: 0; batch classifier loss: 0.438004; batch adversarial loss: 0.563347\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345697; batch adversarial loss: 0.552477\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374901; batch adversarial loss: 0.608160\n",
      "epoch 115; iter: 0; batch classifier loss: 0.353150; batch adversarial loss: 0.543846\n",
      "epoch 116; iter: 0; batch classifier loss: 0.378827; batch adversarial loss: 0.517421\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389729; batch adversarial loss: 0.499705\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357071; batch adversarial loss: 0.554111\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425509; batch adversarial loss: 0.580413\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341615; batch adversarial loss: 0.615528\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355587; batch adversarial loss: 0.545451\n",
      "epoch 122; iter: 0; batch classifier loss: 0.319995; batch adversarial loss: 0.590196\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399618; batch adversarial loss: 0.554270\n",
      "epoch 124; iter: 0; batch classifier loss: 0.440864; batch adversarial loss: 0.517344\n",
      "epoch 125; iter: 0; batch classifier loss: 0.313119; batch adversarial loss: 0.526809\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387143; batch adversarial loss: 0.553247\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385377; batch adversarial loss: 0.616416\n",
      "epoch 128; iter: 0; batch classifier loss: 0.386177; batch adversarial loss: 0.570791\n",
      "epoch 129; iter: 0; batch classifier loss: 0.420630; batch adversarial loss: 0.544881\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387625; batch adversarial loss: 0.490957\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331120; batch adversarial loss: 0.508904\n",
      "epoch 132; iter: 0; batch classifier loss: 0.273304; batch adversarial loss: 0.553978\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364714; batch adversarial loss: 0.597977\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354583; batch adversarial loss: 0.606432\n",
      "epoch 135; iter: 0; batch classifier loss: 0.422843; batch adversarial loss: 0.527506\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385647; batch adversarial loss: 0.606780\n",
      "epoch 137; iter: 0; batch classifier loss: 0.315466; batch adversarial loss: 0.555019\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362202; batch adversarial loss: 0.632582\n",
      "epoch 139; iter: 0; batch classifier loss: 0.365178; batch adversarial loss: 0.483107\n",
      "epoch 140; iter: 0; batch classifier loss: 0.369253; batch adversarial loss: 0.490477\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346702; batch adversarial loss: 0.552910\n",
      "epoch 142; iter: 0; batch classifier loss: 0.484605; batch adversarial loss: 0.536199\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337583; batch adversarial loss: 0.553836\n",
      "epoch 144; iter: 0; batch classifier loss: 0.278209; batch adversarial loss: 0.545476\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376287; batch adversarial loss: 0.588008\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350772; batch adversarial loss: 0.455168\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344810; batch adversarial loss: 0.482288\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397433; batch adversarial loss: 0.588400\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392279; batch adversarial loss: 0.561849\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354311; batch adversarial loss: 0.526286\n",
      "epoch 151; iter: 0; batch classifier loss: 0.410502; batch adversarial loss: 0.536061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.440162; batch adversarial loss: 0.482294\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393958; batch adversarial loss: 0.490880\n",
      "epoch 154; iter: 0; batch classifier loss: 0.417861; batch adversarial loss: 0.615843\n",
      "epoch 155; iter: 0; batch classifier loss: 0.304678; batch adversarial loss: 0.579739\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374993; batch adversarial loss: 0.418545\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314856; batch adversarial loss: 0.545349\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353708; batch adversarial loss: 0.518426\n",
      "epoch 159; iter: 0; batch classifier loss: 0.281074; batch adversarial loss: 0.517381\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356437; batch adversarial loss: 0.572462\n",
      "epoch 161; iter: 0; batch classifier loss: 0.307881; batch adversarial loss: 0.605847\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369535; batch adversarial loss: 0.490346\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354416; batch adversarial loss: 0.535459\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373607; batch adversarial loss: 0.561715\n",
      "epoch 165; iter: 0; batch classifier loss: 0.324362; batch adversarial loss: 0.597577\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354627; batch adversarial loss: 0.579384\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367864; batch adversarial loss: 0.623955\n",
      "epoch 168; iter: 0; batch classifier loss: 0.312577; batch adversarial loss: 0.508917\n",
      "epoch 169; iter: 0; batch classifier loss: 0.457939; batch adversarial loss: 0.580243\n",
      "epoch 170; iter: 0; batch classifier loss: 0.396210; batch adversarial loss: 0.454200\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390080; batch adversarial loss: 0.580179\n",
      "epoch 172; iter: 0; batch classifier loss: 0.463778; batch adversarial loss: 0.535681\n",
      "epoch 173; iter: 0; batch classifier loss: 0.491714; batch adversarial loss: 0.571517\n",
      "epoch 174; iter: 0; batch classifier loss: 0.450064; batch adversarial loss: 0.571475\n",
      "epoch 175; iter: 0; batch classifier loss: 0.470417; batch adversarial loss: 0.527255\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387648; batch adversarial loss: 0.579862\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305297; batch adversarial loss: 0.580739\n",
      "epoch 178; iter: 0; batch classifier loss: 0.329035; batch adversarial loss: 0.553262\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329055; batch adversarial loss: 0.544682\n",
      "epoch 180; iter: 0; batch classifier loss: 0.325788; batch adversarial loss: 0.535038\n",
      "epoch 181; iter: 0; batch classifier loss: 0.329626; batch adversarial loss: 0.463410\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318850; batch adversarial loss: 0.597584\n",
      "epoch 183; iter: 0; batch classifier loss: 0.316128; batch adversarial loss: 0.526315\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376492; batch adversarial loss: 0.519048\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381385; batch adversarial loss: 0.464602\n",
      "epoch 186; iter: 0; batch classifier loss: 0.274795; batch adversarial loss: 0.634007\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353991; batch adversarial loss: 0.543278\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355669; batch adversarial loss: 0.517212\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328335; batch adversarial loss: 0.524749\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323831; batch adversarial loss: 0.553048\n",
      "epoch 191; iter: 0; batch classifier loss: 0.420561; batch adversarial loss: 0.543242\n",
      "epoch 192; iter: 0; batch classifier loss: 0.300444; batch adversarial loss: 0.510476\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383262; batch adversarial loss: 0.525549\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349597; batch adversarial loss: 0.581431\n",
      "epoch 195; iter: 0; batch classifier loss: 0.313854; batch adversarial loss: 0.526918\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338663; batch adversarial loss: 0.579157\n",
      "epoch 197; iter: 0; batch classifier loss: 0.374654; batch adversarial loss: 0.519248\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355678; batch adversarial loss: 0.615775\n",
      "epoch 199; iter: 0; batch classifier loss: 0.436005; batch adversarial loss: 0.463701\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721622; batch adversarial loss: 0.652166\n",
      "epoch 1; iter: 0; batch classifier loss: 0.656878; batch adversarial loss: 0.625864\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556599; batch adversarial loss: 0.627771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553409; batch adversarial loss: 0.620507\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517943; batch adversarial loss: 0.651747\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546693; batch adversarial loss: 0.592094\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599714; batch adversarial loss: 0.621590\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536881; batch adversarial loss: 0.621529\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529777; batch adversarial loss: 0.569900\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524772; batch adversarial loss: 0.615172\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522764; batch adversarial loss: 0.590246\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502091; batch adversarial loss: 0.549532\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513039; batch adversarial loss: 0.559093\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507522; batch adversarial loss: 0.570330\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540686; batch adversarial loss: 0.592046\n",
      "epoch 15; iter: 0; batch classifier loss: 0.586154; batch adversarial loss: 0.589046\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452475; batch adversarial loss: 0.513020\n",
      "epoch 17; iter: 0; batch classifier loss: 0.562963; batch adversarial loss: 0.530340\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508611; batch adversarial loss: 0.578507\n",
      "epoch 19; iter: 0; batch classifier loss: 0.446972; batch adversarial loss: 0.583377\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429728; batch adversarial loss: 0.548718\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502843; batch adversarial loss: 0.512559\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472109; batch adversarial loss: 0.458950\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467072; batch adversarial loss: 0.516466\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453341; batch adversarial loss: 0.565809\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434802; batch adversarial loss: 0.603936\n",
      "epoch 26; iter: 0; batch classifier loss: 0.427260; batch adversarial loss: 0.588398\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506477; batch adversarial loss: 0.542696\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478893; batch adversarial loss: 0.548944\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485136; batch adversarial loss: 0.665199\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478485; batch adversarial loss: 0.547039\n",
      "epoch 31; iter: 0; batch classifier loss: 0.403840; batch adversarial loss: 0.539261\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450655; batch adversarial loss: 0.501132\n",
      "epoch 33; iter: 0; batch classifier loss: 0.496818; batch adversarial loss: 0.535620\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436581; batch adversarial loss: 0.570890\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436272; batch adversarial loss: 0.497687\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428289; batch adversarial loss: 0.564988\n",
      "epoch 37; iter: 0; batch classifier loss: 0.505977; batch adversarial loss: 0.590461\n",
      "epoch 38; iter: 0; batch classifier loss: 0.531168; batch adversarial loss: 0.530596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500675; batch adversarial loss: 0.595034\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407536; batch adversarial loss: 0.572941\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462919; batch adversarial loss: 0.543045\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466739; batch adversarial loss: 0.480906\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444975; batch adversarial loss: 0.535790\n",
      "epoch 44; iter: 0; batch classifier loss: 0.527176; batch adversarial loss: 0.505955\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399563; batch adversarial loss: 0.546682\n",
      "epoch 46; iter: 0; batch classifier loss: 0.352212; batch adversarial loss: 0.481247\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421536; batch adversarial loss: 0.560312\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465184; batch adversarial loss: 0.455703\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432719; batch adversarial loss: 0.577799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.568004; batch adversarial loss: 0.553277\n",
      "epoch 51; iter: 0; batch classifier loss: 0.329593; batch adversarial loss: 0.482509\n",
      "epoch 52; iter: 0; batch classifier loss: 0.485193; batch adversarial loss: 0.533972\n",
      "epoch 53; iter: 0; batch classifier loss: 0.366642; batch adversarial loss: 0.562499\n",
      "epoch 54; iter: 0; batch classifier loss: 0.457481; batch adversarial loss: 0.561751\n",
      "epoch 55; iter: 0; batch classifier loss: 0.467638; batch adversarial loss: 0.497383\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430002; batch adversarial loss: 0.619410\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408391; batch adversarial loss: 0.543797\n",
      "epoch 58; iter: 0; batch classifier loss: 0.372117; batch adversarial loss: 0.507178\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401240; batch adversarial loss: 0.560421\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382098; batch adversarial loss: 0.598491\n",
      "epoch 61; iter: 0; batch classifier loss: 0.465413; batch adversarial loss: 0.544042\n",
      "epoch 62; iter: 0; batch classifier loss: 0.353754; batch adversarial loss: 0.571299\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406721; batch adversarial loss: 0.553404\n",
      "epoch 64; iter: 0; batch classifier loss: 0.383230; batch adversarial loss: 0.478598\n",
      "epoch 65; iter: 0; batch classifier loss: 0.418651; batch adversarial loss: 0.558426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.453394; batch adversarial loss: 0.475670\n",
      "epoch 67; iter: 0; batch classifier loss: 0.477605; batch adversarial loss: 0.522860\n",
      "epoch 68; iter: 0; batch classifier loss: 0.469530; batch adversarial loss: 0.461181\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387443; batch adversarial loss: 0.469425\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408348; batch adversarial loss: 0.634029\n",
      "epoch 71; iter: 0; batch classifier loss: 0.511606; batch adversarial loss: 0.497002\n",
      "epoch 72; iter: 0; batch classifier loss: 0.360511; batch adversarial loss: 0.544423\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374728; batch adversarial loss: 0.461949\n",
      "epoch 74; iter: 0; batch classifier loss: 0.451057; batch adversarial loss: 0.525472\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404604; batch adversarial loss: 0.554855\n",
      "epoch 76; iter: 0; batch classifier loss: 0.463229; batch adversarial loss: 0.573620\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399687; batch adversarial loss: 0.600591\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387694; batch adversarial loss: 0.516691\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372037; batch adversarial loss: 0.497687\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406432; batch adversarial loss: 0.470699\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428990; batch adversarial loss: 0.553917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375986; batch adversarial loss: 0.440056\n",
      "epoch 83; iter: 0; batch classifier loss: 0.433899; batch adversarial loss: 0.570749\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399745; batch adversarial loss: 0.616950\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364432; batch adversarial loss: 0.551003\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397953; batch adversarial loss: 0.581615\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382493; batch adversarial loss: 0.490889\n",
      "epoch 88; iter: 0; batch classifier loss: 0.450884; batch adversarial loss: 0.508920\n",
      "epoch 89; iter: 0; batch classifier loss: 0.487555; batch adversarial loss: 0.590987\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452081; batch adversarial loss: 0.471319\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427866; batch adversarial loss: 0.562501\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390539; batch adversarial loss: 0.562700\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383329; batch adversarial loss: 0.544425\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402112; batch adversarial loss: 0.534423\n",
      "epoch 95; iter: 0; batch classifier loss: 0.521857; batch adversarial loss: 0.600534\n",
      "epoch 96; iter: 0; batch classifier loss: 0.413901; batch adversarial loss: 0.544682\n",
      "epoch 97; iter: 0; batch classifier loss: 0.408605; batch adversarial loss: 0.608001\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356727; batch adversarial loss: 0.533964\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367084; batch adversarial loss: 0.554205\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431890; batch adversarial loss: 0.581537\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400244; batch adversarial loss: 0.507827\n",
      "epoch 102; iter: 0; batch classifier loss: 0.423671; batch adversarial loss: 0.526998\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364390; batch adversarial loss: 0.535042\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377659; batch adversarial loss: 0.495936\n",
      "epoch 105; iter: 0; batch classifier loss: 0.321840; batch adversarial loss: 0.489958\n",
      "epoch 106; iter: 0; batch classifier loss: 0.338949; batch adversarial loss: 0.509421\n",
      "epoch 107; iter: 0; batch classifier loss: 0.394538; batch adversarial loss: 0.564010\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387756; batch adversarial loss: 0.507618\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357005; batch adversarial loss: 0.490054\n",
      "epoch 110; iter: 0; batch classifier loss: 0.387473; batch adversarial loss: 0.533866\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345065; batch adversarial loss: 0.527218\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403233; batch adversarial loss: 0.552725\n",
      "epoch 113; iter: 0; batch classifier loss: 0.433482; batch adversarial loss: 0.489283\n",
      "epoch 114; iter: 0; batch classifier loss: 0.427717; batch adversarial loss: 0.488913\n",
      "epoch 115; iter: 0; batch classifier loss: 0.469294; batch adversarial loss: 0.582616\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369843; batch adversarial loss: 0.498539\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393458; batch adversarial loss: 0.479824\n",
      "epoch 118; iter: 0; batch classifier loss: 0.287215; batch adversarial loss: 0.621483\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375443; batch adversarial loss: 0.477827\n",
      "epoch 120; iter: 0; batch classifier loss: 0.411041; batch adversarial loss: 0.594870\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392110; batch adversarial loss: 0.579669\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343342; batch adversarial loss: 0.504308\n",
      "epoch 123; iter: 0; batch classifier loss: 0.316607; batch adversarial loss: 0.551818\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363032; batch adversarial loss: 0.490587\n",
      "epoch 125; iter: 0; batch classifier loss: 0.341376; batch adversarial loss: 0.515836\n",
      "epoch 126; iter: 0; batch classifier loss: 0.433839; batch adversarial loss: 0.553087\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376525; batch adversarial loss: 0.556035\n",
      "epoch 128; iter: 0; batch classifier loss: 0.464489; batch adversarial loss: 0.490112\n",
      "epoch 129; iter: 0; batch classifier loss: 0.449236; batch adversarial loss: 0.563436\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366828; batch adversarial loss: 0.537049\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349388; batch adversarial loss: 0.588828\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431134; batch adversarial loss: 0.544557\n",
      "epoch 133; iter: 0; batch classifier loss: 0.322013; batch adversarial loss: 0.527799\n",
      "epoch 134; iter: 0; batch classifier loss: 0.370653; batch adversarial loss: 0.571153\n",
      "epoch 135; iter: 0; batch classifier loss: 0.331613; batch adversarial loss: 0.521306\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334901; batch adversarial loss: 0.572753\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341077; batch adversarial loss: 0.544681\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364755; batch adversarial loss: 0.525612\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328462; batch adversarial loss: 0.590272\n",
      "epoch 140; iter: 0; batch classifier loss: 0.316864; batch adversarial loss: 0.598703\n",
      "epoch 141; iter: 0; batch classifier loss: 0.373615; batch adversarial loss: 0.488883\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368852; batch adversarial loss: 0.508913\n",
      "epoch 143; iter: 0; batch classifier loss: 0.431878; batch adversarial loss: 0.535080\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380626; batch adversarial loss: 0.554208\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346030; batch adversarial loss: 0.535763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.408891; batch adversarial loss: 0.517871\n",
      "epoch 147; iter: 0; batch classifier loss: 0.364781; batch adversarial loss: 0.618265\n",
      "epoch 148; iter: 0; batch classifier loss: 0.347387; batch adversarial loss: 0.564300\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341930; batch adversarial loss: 0.591906\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356308; batch adversarial loss: 0.535376\n",
      "epoch 151; iter: 0; batch classifier loss: 0.317800; batch adversarial loss: 0.433496\n",
      "epoch 152; iter: 0; batch classifier loss: 0.412933; batch adversarial loss: 0.562607\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405808; batch adversarial loss: 0.552783\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354726; batch adversarial loss: 0.564852\n",
      "epoch 155; iter: 0; batch classifier loss: 0.260752; batch adversarial loss: 0.479466\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384762; batch adversarial loss: 0.442195\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381663; batch adversarial loss: 0.525700\n",
      "epoch 158; iter: 0; batch classifier loss: 0.389967; batch adversarial loss: 0.556148\n",
      "epoch 159; iter: 0; batch classifier loss: 0.395468; batch adversarial loss: 0.588960\n",
      "epoch 160; iter: 0; batch classifier loss: 0.367572; batch adversarial loss: 0.563218\n",
      "epoch 161; iter: 0; batch classifier loss: 0.267724; batch adversarial loss: 0.543786\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334100; batch adversarial loss: 0.526182\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341453; batch adversarial loss: 0.555441\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400952; batch adversarial loss: 0.582680\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369059; batch adversarial loss: 0.507101\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357710; batch adversarial loss: 0.498697\n",
      "epoch 167; iter: 0; batch classifier loss: 0.475488; batch adversarial loss: 0.506453\n",
      "epoch 168; iter: 0; batch classifier loss: 0.336407; batch adversarial loss: 0.487228\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343501; batch adversarial loss: 0.562530\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364430; batch adversarial loss: 0.645273\n",
      "epoch 171; iter: 0; batch classifier loss: 0.412867; batch adversarial loss: 0.489130\n",
      "epoch 172; iter: 0; batch classifier loss: 0.321485; batch adversarial loss: 0.545609\n",
      "epoch 173; iter: 0; batch classifier loss: 0.449218; batch adversarial loss: 0.563224\n",
      "epoch 174; iter: 0; batch classifier loss: 0.315256; batch adversarial loss: 0.572169\n",
      "epoch 175; iter: 0; batch classifier loss: 0.414983; batch adversarial loss: 0.523936\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380270; batch adversarial loss: 0.637670\n",
      "epoch 177; iter: 0; batch classifier loss: 0.308812; batch adversarial loss: 0.507497\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358456; batch adversarial loss: 0.534486\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374407; batch adversarial loss: 0.534998\n",
      "epoch 180; iter: 0; batch classifier loss: 0.347856; batch adversarial loss: 0.571054\n",
      "epoch 181; iter: 0; batch classifier loss: 0.380351; batch adversarial loss: 0.562255\n",
      "epoch 182; iter: 0; batch classifier loss: 0.272144; batch adversarial loss: 0.589839\n",
      "epoch 183; iter: 0; batch classifier loss: 0.420496; batch adversarial loss: 0.461025\n",
      "epoch 184; iter: 0; batch classifier loss: 0.420949; batch adversarial loss: 0.507558\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376223; batch adversarial loss: 0.526523\n",
      "epoch 186; iter: 0; batch classifier loss: 0.402837; batch adversarial loss: 0.553921\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363223; batch adversarial loss: 0.450566\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379753; batch adversarial loss: 0.556091\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379296; batch adversarial loss: 0.488787\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352038; batch adversarial loss: 0.553756\n",
      "epoch 191; iter: 0; batch classifier loss: 0.408617; batch adversarial loss: 0.524741\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356598; batch adversarial loss: 0.535364\n",
      "epoch 193; iter: 0; batch classifier loss: 0.401731; batch adversarial loss: 0.580743\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419973; batch adversarial loss: 0.514938\n",
      "epoch 195; iter: 0; batch classifier loss: 0.410807; batch adversarial loss: 0.526088\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354158; batch adversarial loss: 0.507576\n",
      "epoch 197; iter: 0; batch classifier loss: 0.415434; batch adversarial loss: 0.571455\n",
      "epoch 198; iter: 0; batch classifier loss: 0.405335; batch adversarial loss: 0.621709\n",
      "epoch 199; iter: 0; batch classifier loss: 0.450962; batch adversarial loss: 0.386811\n",
      "epoch 0; iter: 0; batch classifier loss: 0.765715; batch adversarial loss: 0.797839\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537700; batch adversarial loss: 0.729770\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571267; batch adversarial loss: 0.693785\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548328; batch adversarial loss: 0.675581\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559749; batch adversarial loss: 0.652698\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598842; batch adversarial loss: 0.660723\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515743; batch adversarial loss: 0.617131\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557305; batch adversarial loss: 0.607149\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570129; batch adversarial loss: 0.596469\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560100; batch adversarial loss: 0.569576\n",
      "epoch 10; iter: 0; batch classifier loss: 0.607386; batch adversarial loss: 0.607226\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502401; batch adversarial loss: 0.557184\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551691; batch adversarial loss: 0.614479\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524364; batch adversarial loss: 0.557405\n",
      "epoch 14; iter: 0; batch classifier loss: 0.492097; batch adversarial loss: 0.550410\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566015; batch adversarial loss: 0.612747\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571545; batch adversarial loss: 0.614336\n",
      "epoch 17; iter: 0; batch classifier loss: 0.594043; batch adversarial loss: 0.615509\n",
      "epoch 18; iter: 0; batch classifier loss: 0.572369; batch adversarial loss: 0.566334\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517411; batch adversarial loss: 0.569172\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507985; batch adversarial loss: 0.543853\n",
      "epoch 21; iter: 0; batch classifier loss: 0.540246; batch adversarial loss: 0.569857\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497162; batch adversarial loss: 0.630234\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479453; batch adversarial loss: 0.612457\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517513; batch adversarial loss: 0.526820\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526039; batch adversarial loss: 0.627292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495606; batch adversarial loss: 0.522908\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505741; batch adversarial loss: 0.569701\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484194; batch adversarial loss: 0.588541\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489699; batch adversarial loss: 0.530239\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503193; batch adversarial loss: 0.552219\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461333; batch adversarial loss: 0.626256\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491480; batch adversarial loss: 0.497583\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467391; batch adversarial loss: 0.545006\n",
      "epoch 34; iter: 0; batch classifier loss: 0.552416; batch adversarial loss: 0.579742\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498719; batch adversarial loss: 0.593259\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435762; batch adversarial loss: 0.493979\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450916; batch adversarial loss: 0.512087\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452420; batch adversarial loss: 0.524916\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471680; batch adversarial loss: 0.595643\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443328; batch adversarial loss: 0.570939\n",
      "epoch 41; iter: 0; batch classifier loss: 0.390347; batch adversarial loss: 0.501085\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457483; batch adversarial loss: 0.593496\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483756; batch adversarial loss: 0.596975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.478417; batch adversarial loss: 0.508594\n",
      "epoch 45; iter: 0; batch classifier loss: 0.539780; batch adversarial loss: 0.519554\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461343; batch adversarial loss: 0.562982\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456086; batch adversarial loss: 0.625762\n",
      "epoch 48; iter: 0; batch classifier loss: 0.366216; batch adversarial loss: 0.517211\n",
      "epoch 49; iter: 0; batch classifier loss: 0.469295; batch adversarial loss: 0.490118\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455797; batch adversarial loss: 0.569401\n",
      "epoch 51; iter: 0; batch classifier loss: 0.534978; batch adversarial loss: 0.490061\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418627; batch adversarial loss: 0.543585\n",
      "epoch 53; iter: 0; batch classifier loss: 0.373153; batch adversarial loss: 0.554441\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412004; batch adversarial loss: 0.545215\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401128; batch adversarial loss: 0.550423\n",
      "epoch 56; iter: 0; batch classifier loss: 0.461995; batch adversarial loss: 0.533771\n",
      "epoch 57; iter: 0; batch classifier loss: 0.469500; batch adversarial loss: 0.528410\n",
      "epoch 58; iter: 0; batch classifier loss: 0.486635; batch adversarial loss: 0.517417\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423450; batch adversarial loss: 0.524254\n",
      "epoch 60; iter: 0; batch classifier loss: 0.424721; batch adversarial loss: 0.525310\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389903; batch adversarial loss: 0.553149\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377609; batch adversarial loss: 0.568933\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441312; batch adversarial loss: 0.538171\n",
      "epoch 64; iter: 0; batch classifier loss: 0.464781; batch adversarial loss: 0.527620\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367824; batch adversarial loss: 0.559873\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460474; batch adversarial loss: 0.528876\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411320; batch adversarial loss: 0.562624\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427455; batch adversarial loss: 0.580904\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402385; batch adversarial loss: 0.455625\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392535; batch adversarial loss: 0.625830\n",
      "epoch 71; iter: 0; batch classifier loss: 0.447252; batch adversarial loss: 0.518161\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379674; batch adversarial loss: 0.573113\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403771; batch adversarial loss: 0.431018\n",
      "epoch 74; iter: 0; batch classifier loss: 0.376950; batch adversarial loss: 0.582591\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362784; batch adversarial loss: 0.506780\n",
      "epoch 76; iter: 0; batch classifier loss: 0.358411; batch adversarial loss: 0.581151\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441050; batch adversarial loss: 0.581623\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393179; batch adversarial loss: 0.571837\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437565; batch adversarial loss: 0.525804\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403309; batch adversarial loss: 0.508199\n",
      "epoch 81; iter: 0; batch classifier loss: 0.366049; batch adversarial loss: 0.544195\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415986; batch adversarial loss: 0.635263\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404862; batch adversarial loss: 0.654212\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354966; batch adversarial loss: 0.488998\n",
      "epoch 85; iter: 0; batch classifier loss: 0.448089; batch adversarial loss: 0.535277\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416876; batch adversarial loss: 0.416448\n",
      "epoch 87; iter: 0; batch classifier loss: 0.353883; batch adversarial loss: 0.527210\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406251; batch adversarial loss: 0.490010\n",
      "epoch 89; iter: 0; batch classifier loss: 0.460648; batch adversarial loss: 0.551992\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435086; batch adversarial loss: 0.526007\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380725; batch adversarial loss: 0.499272\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384869; batch adversarial loss: 0.534863\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403257; batch adversarial loss: 0.572006\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446542; batch adversarial loss: 0.582248\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361911; batch adversarial loss: 0.435678\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418196; batch adversarial loss: 0.625754\n",
      "epoch 97; iter: 0; batch classifier loss: 0.419857; batch adversarial loss: 0.579671\n",
      "epoch 98; iter: 0; batch classifier loss: 0.476488; batch adversarial loss: 0.559828\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361048; batch adversarial loss: 0.508488\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386961; batch adversarial loss: 0.533288\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376184; batch adversarial loss: 0.554325\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385132; batch adversarial loss: 0.535828\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378422; batch adversarial loss: 0.461140\n",
      "epoch 104; iter: 0; batch classifier loss: 0.524790; batch adversarial loss: 0.517110\n",
      "epoch 105; iter: 0; batch classifier loss: 0.348951; batch adversarial loss: 0.564093\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374885; batch adversarial loss: 0.516426\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400224; batch adversarial loss: 0.506775\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348267; batch adversarial loss: 0.572067\n",
      "epoch 109; iter: 0; batch classifier loss: 0.439837; batch adversarial loss: 0.618375\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353771; batch adversarial loss: 0.526252\n",
      "epoch 111; iter: 0; batch classifier loss: 0.443627; batch adversarial loss: 0.527336\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387909; batch adversarial loss: 0.627070\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382499; batch adversarial loss: 0.517232\n",
      "epoch 114; iter: 0; batch classifier loss: 0.424279; batch adversarial loss: 0.544122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.424828; batch adversarial loss: 0.505776\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364295; batch adversarial loss: 0.537396\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392254; batch adversarial loss: 0.490434\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342725; batch adversarial loss: 0.526935\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376369; batch adversarial loss: 0.525175\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382233; batch adversarial loss: 0.516780\n",
      "epoch 121; iter: 0; batch classifier loss: 0.312156; batch adversarial loss: 0.517244\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361627; batch adversarial loss: 0.544167\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353731; batch adversarial loss: 0.527913\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358591; batch adversarial loss: 0.497984\n",
      "epoch 125; iter: 0; batch classifier loss: 0.345310; batch adversarial loss: 0.544261\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350747; batch adversarial loss: 0.579680\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379032; batch adversarial loss: 0.534844\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376243; batch adversarial loss: 0.542836\n",
      "epoch 129; iter: 0; batch classifier loss: 0.352619; batch adversarial loss: 0.626209\n",
      "epoch 130; iter: 0; batch classifier loss: 0.427449; batch adversarial loss: 0.520808\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347422; batch adversarial loss: 0.484588\n",
      "epoch 132; iter: 0; batch classifier loss: 0.374443; batch adversarial loss: 0.621409\n",
      "epoch 133; iter: 0; batch classifier loss: 0.461795; batch adversarial loss: 0.483408\n",
      "epoch 134; iter: 0; batch classifier loss: 0.327069; batch adversarial loss: 0.588542\n",
      "epoch 135; iter: 0; batch classifier loss: 0.339530; batch adversarial loss: 0.486228\n",
      "epoch 136; iter: 0; batch classifier loss: 0.438232; batch adversarial loss: 0.542350\n",
      "epoch 137; iter: 0; batch classifier loss: 0.448440; batch adversarial loss: 0.616508\n",
      "epoch 138; iter: 0; batch classifier loss: 0.336430; batch adversarial loss: 0.573485\n",
      "epoch 139; iter: 0; batch classifier loss: 0.394816; batch adversarial loss: 0.536455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.375307; batch adversarial loss: 0.572922\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368187; batch adversarial loss: 0.545544\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333917; batch adversarial loss: 0.516288\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405389; batch adversarial loss: 0.506701\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379360; batch adversarial loss: 0.526187\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397499; batch adversarial loss: 0.608672\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425196; batch adversarial loss: 0.553836\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383854; batch adversarial loss: 0.545192\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365491; batch adversarial loss: 0.535337\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347238; batch adversarial loss: 0.616301\n",
      "epoch 150; iter: 0; batch classifier loss: 0.387647; batch adversarial loss: 0.627232\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362874; batch adversarial loss: 0.579488\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331180; batch adversarial loss: 0.497982\n",
      "epoch 153; iter: 0; batch classifier loss: 0.311428; batch adversarial loss: 0.581291\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376439; batch adversarial loss: 0.536455\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327124; batch adversarial loss: 0.459255\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372593; batch adversarial loss: 0.654814\n",
      "epoch 157; iter: 0; batch classifier loss: 0.438779; batch adversarial loss: 0.508178\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356898; batch adversarial loss: 0.600354\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316597; batch adversarial loss: 0.489284\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365796; batch adversarial loss: 0.609592\n",
      "epoch 161; iter: 0; batch classifier loss: 0.481729; batch adversarial loss: 0.515682\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370935; batch adversarial loss: 0.552111\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373446; batch adversarial loss: 0.546672\n",
      "epoch 164; iter: 0; batch classifier loss: 0.450396; batch adversarial loss: 0.525699\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319374; batch adversarial loss: 0.497653\n",
      "epoch 166; iter: 0; batch classifier loss: 0.362422; batch adversarial loss: 0.527748\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332489; batch adversarial loss: 0.533260\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353318; batch adversarial loss: 0.562974\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366075; batch adversarial loss: 0.588805\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398449; batch adversarial loss: 0.499292\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335303; batch adversarial loss: 0.579491\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331772; batch adversarial loss: 0.588798\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364099; batch adversarial loss: 0.528256\n",
      "epoch 174; iter: 0; batch classifier loss: 0.434721; batch adversarial loss: 0.581955\n",
      "epoch 175; iter: 0; batch classifier loss: 0.394585; batch adversarial loss: 0.533685\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388958; batch adversarial loss: 0.635647\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329683; batch adversarial loss: 0.569126\n",
      "epoch 178; iter: 0; batch classifier loss: 0.294967; batch adversarial loss: 0.604353\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389537; batch adversarial loss: 0.600983\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334254; batch adversarial loss: 0.511234\n",
      "epoch 181; iter: 0; batch classifier loss: 0.310181; batch adversarial loss: 0.572093\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352964; batch adversarial loss: 0.563776\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385644; batch adversarial loss: 0.553229\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313162; batch adversarial loss: 0.579059\n",
      "epoch 185; iter: 0; batch classifier loss: 0.339799; batch adversarial loss: 0.450660\n",
      "epoch 186; iter: 0; batch classifier loss: 0.418535; batch adversarial loss: 0.542205\n",
      "epoch 187; iter: 0; batch classifier loss: 0.400956; batch adversarial loss: 0.564247\n",
      "epoch 188; iter: 0; batch classifier loss: 0.377580; batch adversarial loss: 0.539022\n",
      "epoch 189; iter: 0; batch classifier loss: 0.324297; batch adversarial loss: 0.617905\n",
      "epoch 190; iter: 0; batch classifier loss: 0.387778; batch adversarial loss: 0.580898\n",
      "epoch 191; iter: 0; batch classifier loss: 0.383833; batch adversarial loss: 0.581372\n",
      "epoch 192; iter: 0; batch classifier loss: 0.377167; batch adversarial loss: 0.581448\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389308; batch adversarial loss: 0.517299\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368014; batch adversarial loss: 0.518517\n",
      "epoch 195; iter: 0; batch classifier loss: 0.414371; batch adversarial loss: 0.537845\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316313; batch adversarial loss: 0.506884\n",
      "epoch 197; iter: 0; batch classifier loss: 0.378994; batch adversarial loss: 0.590060\n",
      "epoch 198; iter: 0; batch classifier loss: 0.426878; batch adversarial loss: 0.572655\n",
      "epoch 199; iter: 0; batch classifier loss: 0.373760; batch adversarial loss: 0.545597\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669311; batch adversarial loss: 0.814585\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718693; batch adversarial loss: 1.012027\n",
      "epoch 2; iter: 0; batch classifier loss: 0.689724; batch adversarial loss: 0.952330\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629049; batch adversarial loss: 0.825028\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573711; batch adversarial loss: 0.808361\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551121; batch adversarial loss: 0.712243\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519464; batch adversarial loss: 0.678781\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606560; batch adversarial loss: 0.657656\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524344; batch adversarial loss: 0.629631\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526946; batch adversarial loss: 0.643037\n",
      "epoch 10; iter: 0; batch classifier loss: 0.563386; batch adversarial loss: 0.596453\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533796; batch adversarial loss: 0.580850\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494891; batch adversarial loss: 0.610181\n",
      "epoch 13; iter: 0; batch classifier loss: 0.456174; batch adversarial loss: 0.561183\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520275; batch adversarial loss: 0.623412\n",
      "epoch 15; iter: 0; batch classifier loss: 0.517426; batch adversarial loss: 0.562325\n",
      "epoch 16; iter: 0; batch classifier loss: 0.440165; batch adversarial loss: 0.544551\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443347; batch adversarial loss: 0.536704\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484572; batch adversarial loss: 0.549764\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545103; batch adversarial loss: 0.561180\n",
      "epoch 20; iter: 0; batch classifier loss: 0.540381; batch adversarial loss: 0.598928\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487452; batch adversarial loss: 0.542995\n",
      "epoch 22; iter: 0; batch classifier loss: 0.421269; batch adversarial loss: 0.519002\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507825; batch adversarial loss: 0.543946\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501967; batch adversarial loss: 0.498558\n",
      "epoch 25; iter: 0; batch classifier loss: 0.425554; batch adversarial loss: 0.527974\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499302; batch adversarial loss: 0.562313\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501522; batch adversarial loss: 0.521514\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499335; batch adversarial loss: 0.524732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460018; batch adversarial loss: 0.541392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465371; batch adversarial loss: 0.578143\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489981; batch adversarial loss: 0.460296\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454527; batch adversarial loss: 0.571747\n",
      "epoch 33; iter: 0; batch classifier loss: 0.544625; batch adversarial loss: 0.512603\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432241; batch adversarial loss: 0.540141\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469417; batch adversarial loss: 0.620715\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490345; batch adversarial loss: 0.647706\n",
      "epoch 37; iter: 0; batch classifier loss: 0.494341; batch adversarial loss: 0.577859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.467482; batch adversarial loss: 0.471237\n",
      "epoch 39; iter: 0; batch classifier loss: 0.507106; batch adversarial loss: 0.485266\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439038; batch adversarial loss: 0.527505\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443435; batch adversarial loss: 0.577065\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451879; batch adversarial loss: 0.529912\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430790; batch adversarial loss: 0.502699\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465874; batch adversarial loss: 0.610561\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464320; batch adversarial loss: 0.557040\n",
      "epoch 46; iter: 0; batch classifier loss: 0.358034; batch adversarial loss: 0.482129\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520949; batch adversarial loss: 0.473239\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456817; batch adversarial loss: 0.570263\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474126; batch adversarial loss: 0.582471\n",
      "epoch 50; iter: 0; batch classifier loss: 0.399229; batch adversarial loss: 0.499790\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398869; batch adversarial loss: 0.552816\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455485; batch adversarial loss: 0.655367\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458036; batch adversarial loss: 0.525209\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429320; batch adversarial loss: 0.507743\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378691; batch adversarial loss: 0.498082\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394247; batch adversarial loss: 0.600675\n",
      "epoch 57; iter: 0; batch classifier loss: 0.520022; batch adversarial loss: 0.461103\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394652; batch adversarial loss: 0.544736\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398760; batch adversarial loss: 0.525941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420230; batch adversarial loss: 0.479255\n",
      "epoch 61; iter: 0; batch classifier loss: 0.437066; batch adversarial loss: 0.489130\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388974; batch adversarial loss: 0.637479\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413493; batch adversarial loss: 0.442690\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438631; batch adversarial loss: 0.534454\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370068; batch adversarial loss: 0.553401\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406384; batch adversarial loss: 0.517628\n",
      "epoch 67; iter: 0; batch classifier loss: 0.446841; batch adversarial loss: 0.498714\n",
      "epoch 68; iter: 0; batch classifier loss: 0.396052; batch adversarial loss: 0.589417\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417679; batch adversarial loss: 0.635789\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369233; batch adversarial loss: 0.617394\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417952; batch adversarial loss: 0.535315\n",
      "epoch 72; iter: 0; batch classifier loss: 0.470500; batch adversarial loss: 0.590280\n",
      "epoch 73; iter: 0; batch classifier loss: 0.348999; batch adversarial loss: 0.526613\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386298; batch adversarial loss: 0.543322\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371955; batch adversarial loss: 0.477111\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400044; batch adversarial loss: 0.676652\n",
      "epoch 77; iter: 0; batch classifier loss: 0.343891; batch adversarial loss: 0.452949\n",
      "epoch 78; iter: 0; batch classifier loss: 0.295588; batch adversarial loss: 0.599212\n",
      "epoch 79; iter: 0; batch classifier loss: 0.412071; batch adversarial loss: 0.582455\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381303; batch adversarial loss: 0.533406\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414021; batch adversarial loss: 0.567425\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395373; batch adversarial loss: 0.561595\n",
      "epoch 83; iter: 0; batch classifier loss: 0.430614; batch adversarial loss: 0.537138\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418957; batch adversarial loss: 0.525517\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411199; batch adversarial loss: 0.555882\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377191; batch adversarial loss: 0.600989\n",
      "epoch 87; iter: 0; batch classifier loss: 0.344722; batch adversarial loss: 0.516148\n",
      "epoch 88; iter: 0; batch classifier loss: 0.474180; batch adversarial loss: 0.495380\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362421; batch adversarial loss: 0.570780\n",
      "epoch 90; iter: 0; batch classifier loss: 0.424014; batch adversarial loss: 0.581478\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404900; batch adversarial loss: 0.560079\n",
      "epoch 92; iter: 0; batch classifier loss: 0.327355; batch adversarial loss: 0.461444\n",
      "epoch 93; iter: 0; batch classifier loss: 0.478111; batch adversarial loss: 0.552110\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380722; batch adversarial loss: 0.574366\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381907; batch adversarial loss: 0.517090\n",
      "epoch 96; iter: 0; batch classifier loss: 0.317938; batch adversarial loss: 0.553931\n",
      "epoch 97; iter: 0; batch classifier loss: 0.398932; batch adversarial loss: 0.545456\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373010; batch adversarial loss: 0.562236\n",
      "epoch 99; iter: 0; batch classifier loss: 0.383228; batch adversarial loss: 0.535026\n",
      "epoch 100; iter: 0; batch classifier loss: 0.466217; batch adversarial loss: 0.516465\n",
      "epoch 101; iter: 0; batch classifier loss: 0.423582; batch adversarial loss: 0.537205\n",
      "epoch 102; iter: 0; batch classifier loss: 0.433462; batch adversarial loss: 0.583451\n",
      "epoch 103; iter: 0; batch classifier loss: 0.422811; batch adversarial loss: 0.545088\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350809; batch adversarial loss: 0.588048\n",
      "epoch 105; iter: 0; batch classifier loss: 0.443776; batch adversarial loss: 0.561173\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369549; batch adversarial loss: 0.574299\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348308; batch adversarial loss: 0.563303\n",
      "epoch 108; iter: 0; batch classifier loss: 0.322170; batch adversarial loss: 0.563304\n",
      "epoch 109; iter: 0; batch classifier loss: 0.439238; batch adversarial loss: 0.507785\n",
      "epoch 110; iter: 0; batch classifier loss: 0.336993; batch adversarial loss: 0.570941\n",
      "epoch 111; iter: 0; batch classifier loss: 0.423693; batch adversarial loss: 0.515336\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410795; batch adversarial loss: 0.609607\n",
      "epoch 113; iter: 0; batch classifier loss: 0.442911; batch adversarial loss: 0.507572\n",
      "epoch 114; iter: 0; batch classifier loss: 0.462860; batch adversarial loss: 0.554771\n",
      "epoch 115; iter: 0; batch classifier loss: 0.359833; batch adversarial loss: 0.477736\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420246; batch adversarial loss: 0.525634\n",
      "epoch 117; iter: 0; batch classifier loss: 0.330607; batch adversarial loss: 0.629812\n",
      "epoch 118; iter: 0; batch classifier loss: 0.350469; batch adversarial loss: 0.581393\n",
      "epoch 119; iter: 0; batch classifier loss: 0.427526; batch adversarial loss: 0.506840\n",
      "epoch 120; iter: 0; batch classifier loss: 0.289393; batch adversarial loss: 0.571252\n",
      "epoch 121; iter: 0; batch classifier loss: 0.313975; batch adversarial loss: 0.478750\n",
      "epoch 122; iter: 0; batch classifier loss: 0.347235; batch adversarial loss: 0.591343\n",
      "epoch 123; iter: 0; batch classifier loss: 0.315421; batch adversarial loss: 0.620108\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385840; batch adversarial loss: 0.488709\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367107; batch adversarial loss: 0.506418\n",
      "epoch 126; iter: 0; batch classifier loss: 0.279283; batch adversarial loss: 0.535360\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376033; batch adversarial loss: 0.565028\n",
      "epoch 128; iter: 0; batch classifier loss: 0.394905; batch adversarial loss: 0.525306\n",
      "epoch 129; iter: 0; batch classifier loss: 0.427383; batch adversarial loss: 0.660417\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397507; batch adversarial loss: 0.538391\n",
      "epoch 131; iter: 0; batch classifier loss: 0.306217; batch adversarial loss: 0.479638\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351083; batch adversarial loss: 0.526555\n",
      "epoch 133; iter: 0; batch classifier loss: 0.309054; batch adversarial loss: 0.424136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.351437; batch adversarial loss: 0.477808\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413195; batch adversarial loss: 0.612928\n",
      "epoch 136; iter: 0; batch classifier loss: 0.407359; batch adversarial loss: 0.546967\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379826; batch adversarial loss: 0.470417\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335192; batch adversarial loss: 0.571622\n",
      "epoch 139; iter: 0; batch classifier loss: 0.464281; batch adversarial loss: 0.546461\n",
      "epoch 140; iter: 0; batch classifier loss: 0.324952; batch adversarial loss: 0.535333\n",
      "epoch 141; iter: 0; batch classifier loss: 0.370271; batch adversarial loss: 0.489042\n",
      "epoch 142; iter: 0; batch classifier loss: 0.411916; batch adversarial loss: 0.545013\n",
      "epoch 143; iter: 0; batch classifier loss: 0.318818; batch adversarial loss: 0.459875\n",
      "epoch 144; iter: 0; batch classifier loss: 0.298063; batch adversarial loss: 0.562735\n",
      "epoch 145; iter: 0; batch classifier loss: 0.409541; batch adversarial loss: 0.550072\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367324; batch adversarial loss: 0.571007\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327877; batch adversarial loss: 0.638641\n",
      "epoch 148; iter: 0; batch classifier loss: 0.407865; batch adversarial loss: 0.512586\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331158; batch adversarial loss: 0.523956\n",
      "epoch 150; iter: 0; batch classifier loss: 0.444965; batch adversarial loss: 0.580783\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353118; batch adversarial loss: 0.627722\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390588; batch adversarial loss: 0.487509\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342654; batch adversarial loss: 0.562153\n",
      "epoch 154; iter: 0; batch classifier loss: 0.416210; batch adversarial loss: 0.452743\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362478; batch adversarial loss: 0.560192\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355777; batch adversarial loss: 0.593345\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346957; batch adversarial loss: 0.600310\n",
      "epoch 158; iter: 0; batch classifier loss: 0.398328; batch adversarial loss: 0.574948\n",
      "epoch 159; iter: 0; batch classifier loss: 0.404704; batch adversarial loss: 0.534248\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314392; batch adversarial loss: 0.461000\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357276; batch adversarial loss: 0.553388\n",
      "epoch 162; iter: 0; batch classifier loss: 0.391432; batch adversarial loss: 0.552090\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379237; batch adversarial loss: 0.551949\n",
      "epoch 164; iter: 0; batch classifier loss: 0.365118; batch adversarial loss: 0.630806\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318704; batch adversarial loss: 0.554153\n",
      "epoch 166; iter: 0; batch classifier loss: 0.391512; batch adversarial loss: 0.544771\n",
      "epoch 167; iter: 0; batch classifier loss: 0.297618; batch adversarial loss: 0.590638\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362677; batch adversarial loss: 0.600143\n",
      "epoch 169; iter: 0; batch classifier loss: 0.402966; batch adversarial loss: 0.554273\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403659; batch adversarial loss: 0.488615\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384442; batch adversarial loss: 0.563625\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388529; batch adversarial loss: 0.528361\n",
      "epoch 173; iter: 0; batch classifier loss: 0.443140; batch adversarial loss: 0.563379\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340867; batch adversarial loss: 0.526587\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311337; batch adversarial loss: 0.601057\n",
      "epoch 176; iter: 0; batch classifier loss: 0.282633; batch adversarial loss: 0.514540\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339696; batch adversarial loss: 0.546351\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323426; batch adversarial loss: 0.626933\n",
      "epoch 179; iter: 0; batch classifier loss: 0.373884; batch adversarial loss: 0.592497\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316566; batch adversarial loss: 0.487910\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364835; batch adversarial loss: 0.534718\n",
      "epoch 182; iter: 0; batch classifier loss: 0.294147; batch adversarial loss: 0.564422\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337717; batch adversarial loss: 0.480726\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366320; batch adversarial loss: 0.562917\n",
      "epoch 185; iter: 0; batch classifier loss: 0.263062; batch adversarial loss: 0.470732\n",
      "epoch 186; iter: 0; batch classifier loss: 0.289296; batch adversarial loss: 0.535403\n",
      "epoch 187; iter: 0; batch classifier loss: 0.472819; batch adversarial loss: 0.551955\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385792; batch adversarial loss: 0.497903\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358170; batch adversarial loss: 0.517632\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395398; batch adversarial loss: 0.489284\n",
      "epoch 191; iter: 0; batch classifier loss: 0.387286; batch adversarial loss: 0.620177\n",
      "epoch 192; iter: 0; batch classifier loss: 0.405006; batch adversarial loss: 0.620122\n",
      "epoch 193; iter: 0; batch classifier loss: 0.420436; batch adversarial loss: 0.525482\n",
      "epoch 194; iter: 0; batch classifier loss: 0.333308; batch adversarial loss: 0.515423\n",
      "epoch 195; iter: 0; batch classifier loss: 0.352132; batch adversarial loss: 0.544922\n",
      "epoch 196; iter: 0; batch classifier loss: 0.405612; batch adversarial loss: 0.572726\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348715; batch adversarial loss: 0.591247\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324262; batch adversarial loss: 0.544663\n",
      "epoch 199; iter: 0; batch classifier loss: 0.249515; batch adversarial loss: 0.600739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681608; batch adversarial loss: 0.853065\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628270; batch adversarial loss: 0.922736\n",
      "epoch 2; iter: 0; batch classifier loss: 0.663674; batch adversarial loss: 0.816126\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605897; batch adversarial loss: 0.772122\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597110; batch adversarial loss: 0.739823\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552717; batch adversarial loss: 0.662962\n",
      "epoch 6; iter: 0; batch classifier loss: 0.498764; batch adversarial loss: 0.639966\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541082; batch adversarial loss: 0.672420\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526776; batch adversarial loss: 0.635536\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634501; batch adversarial loss: 0.615903\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518303; batch adversarial loss: 0.634260\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563032; batch adversarial loss: 0.613742\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481983; batch adversarial loss: 0.614783\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493773; batch adversarial loss: 0.607875\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530687; batch adversarial loss: 0.586277\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558208; batch adversarial loss: 0.583628\n",
      "epoch 16; iter: 0; batch classifier loss: 0.461868; batch adversarial loss: 0.527792\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550126; batch adversarial loss: 0.543589\n",
      "epoch 18; iter: 0; batch classifier loss: 0.550543; batch adversarial loss: 0.486900\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532670; batch adversarial loss: 0.516176\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528870; batch adversarial loss: 0.545124\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464613; batch adversarial loss: 0.580265\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470189; batch adversarial loss: 0.517510\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506926; batch adversarial loss: 0.550680\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507056; batch adversarial loss: 0.526656\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502145; batch adversarial loss: 0.622196\n",
      "epoch 26; iter: 0; batch classifier loss: 0.516194; batch adversarial loss: 0.556474\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474332; batch adversarial loss: 0.548162\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455081; batch adversarial loss: 0.565972\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430933; batch adversarial loss: 0.626728\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466976; batch adversarial loss: 0.569920\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484751; batch adversarial loss: 0.522885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.457175; batch adversarial loss: 0.531467\n",
      "epoch 33; iter: 0; batch classifier loss: 0.572889; batch adversarial loss: 0.518074\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446749; batch adversarial loss: 0.574847\n",
      "epoch 35; iter: 0; batch classifier loss: 0.554729; batch adversarial loss: 0.526017\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497207; batch adversarial loss: 0.599985\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404694; batch adversarial loss: 0.542640\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453260; batch adversarial loss: 0.571009\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454666; batch adversarial loss: 0.537119\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396689; batch adversarial loss: 0.597725\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426782; batch adversarial loss: 0.563559\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389419; batch adversarial loss: 0.521560\n",
      "epoch 43; iter: 0; batch classifier loss: 0.356314; batch adversarial loss: 0.642042\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424571; batch adversarial loss: 0.486628\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425713; batch adversarial loss: 0.582983\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474623; batch adversarial loss: 0.526525\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442160; batch adversarial loss: 0.552312\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377451; batch adversarial loss: 0.610237\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432359; batch adversarial loss: 0.608879\n",
      "epoch 50; iter: 0; batch classifier loss: 0.349118; batch adversarial loss: 0.571278\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469719; batch adversarial loss: 0.562493\n",
      "epoch 52; iter: 0; batch classifier loss: 0.482375; batch adversarial loss: 0.594420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.468747; batch adversarial loss: 0.542619\n",
      "epoch 54; iter: 0; batch classifier loss: 0.456387; batch adversarial loss: 0.556047\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405107; batch adversarial loss: 0.588495\n",
      "epoch 56; iter: 0; batch classifier loss: 0.510936; batch adversarial loss: 0.609681\n",
      "epoch 57; iter: 0; batch classifier loss: 0.325988; batch adversarial loss: 0.536352\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471131; batch adversarial loss: 0.498006\n",
      "epoch 59; iter: 0; batch classifier loss: 0.397710; batch adversarial loss: 0.553837\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388790; batch adversarial loss: 0.618121\n",
      "epoch 61; iter: 0; batch classifier loss: 0.350701; batch adversarial loss: 0.588540\n",
      "epoch 62; iter: 0; batch classifier loss: 0.355419; batch adversarial loss: 0.559675\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408197; batch adversarial loss: 0.572435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408762; batch adversarial loss: 0.526209\n",
      "epoch 65; iter: 0; batch classifier loss: 0.482807; batch adversarial loss: 0.529150\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437591; batch adversarial loss: 0.562464\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429484; batch adversarial loss: 0.555466\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410749; batch adversarial loss: 0.490795\n",
      "epoch 69; iter: 0; batch classifier loss: 0.492371; batch adversarial loss: 0.488297\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401292; batch adversarial loss: 0.468532\n",
      "epoch 71; iter: 0; batch classifier loss: 0.337011; batch adversarial loss: 0.536252\n",
      "epoch 72; iter: 0; batch classifier loss: 0.446445; batch adversarial loss: 0.543618\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442775; batch adversarial loss: 0.536475\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396423; batch adversarial loss: 0.521212\n",
      "epoch 75; iter: 0; batch classifier loss: 0.432714; batch adversarial loss: 0.529409\n",
      "epoch 76; iter: 0; batch classifier loss: 0.456548; batch adversarial loss: 0.544677\n",
      "epoch 77; iter: 0; batch classifier loss: 0.397798; batch adversarial loss: 0.542171\n",
      "epoch 78; iter: 0; batch classifier loss: 0.346917; batch adversarial loss: 0.547805\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424553; batch adversarial loss: 0.602188\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417409; batch adversarial loss: 0.616100\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382408; batch adversarial loss: 0.479389\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372766; batch adversarial loss: 0.609755\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371673; batch adversarial loss: 0.535189\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393188; batch adversarial loss: 0.526753\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369059; batch adversarial loss: 0.607582\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431428; batch adversarial loss: 0.617641\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391718; batch adversarial loss: 0.517563\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382964; batch adversarial loss: 0.591802\n",
      "epoch 89; iter: 0; batch classifier loss: 0.414412; batch adversarial loss: 0.589357\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450376; batch adversarial loss: 0.541358\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363819; batch adversarial loss: 0.543770\n",
      "epoch 92; iter: 0; batch classifier loss: 0.347246; batch adversarial loss: 0.598069\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364448; batch adversarial loss: 0.460658\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410006; batch adversarial loss: 0.543890\n",
      "epoch 95; iter: 0; batch classifier loss: 0.369351; batch adversarial loss: 0.615726\n",
      "epoch 96; iter: 0; batch classifier loss: 0.346189; batch adversarial loss: 0.553421\n",
      "epoch 97; iter: 0; batch classifier loss: 0.389010; batch adversarial loss: 0.552580\n",
      "epoch 98; iter: 0; batch classifier loss: 0.433387; batch adversarial loss: 0.600042\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405036; batch adversarial loss: 0.553129\n",
      "epoch 100; iter: 0; batch classifier loss: 0.342162; batch adversarial loss: 0.561660\n",
      "epoch 101; iter: 0; batch classifier loss: 0.404474; batch adversarial loss: 0.517311\n",
      "epoch 102; iter: 0; batch classifier loss: 0.301113; batch adversarial loss: 0.543818\n",
      "epoch 103; iter: 0; batch classifier loss: 0.444806; batch adversarial loss: 0.547341\n",
      "epoch 104; iter: 0; batch classifier loss: 0.446457; batch adversarial loss: 0.509088\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410392; batch adversarial loss: 0.568709\n",
      "epoch 106; iter: 0; batch classifier loss: 0.452855; batch adversarial loss: 0.630379\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388467; batch adversarial loss: 0.576446\n",
      "epoch 108; iter: 0; batch classifier loss: 0.468989; batch adversarial loss: 0.517832\n",
      "epoch 109; iter: 0; batch classifier loss: 0.428286; batch adversarial loss: 0.454399\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368289; batch adversarial loss: 0.600480\n",
      "epoch 111; iter: 0; batch classifier loss: 0.457259; batch adversarial loss: 0.605819\n",
      "epoch 112; iter: 0; batch classifier loss: 0.438298; batch adversarial loss: 0.571998\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399549; batch adversarial loss: 0.632140\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384985; batch adversarial loss: 0.499429\n",
      "epoch 115; iter: 0; batch classifier loss: 0.392056; batch adversarial loss: 0.478680\n",
      "epoch 116; iter: 0; batch classifier loss: 0.437545; batch adversarial loss: 0.523829\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333388; batch adversarial loss: 0.564508\n",
      "epoch 118; iter: 0; batch classifier loss: 0.491782; batch adversarial loss: 0.523750\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392025; batch adversarial loss: 0.475767\n",
      "epoch 120; iter: 0; batch classifier loss: 0.368512; batch adversarial loss: 0.580080\n",
      "epoch 121; iter: 0; batch classifier loss: 0.470741; batch adversarial loss: 0.566478\n",
      "epoch 122; iter: 0; batch classifier loss: 0.307394; batch adversarial loss: 0.505996\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365940; batch adversarial loss: 0.493946\n",
      "epoch 124; iter: 0; batch classifier loss: 0.319372; batch adversarial loss: 0.527600\n",
      "epoch 125; iter: 0; batch classifier loss: 0.426925; batch adversarial loss: 0.571342\n",
      "epoch 126; iter: 0; batch classifier loss: 0.310133; batch adversarial loss: 0.488405\n",
      "epoch 127; iter: 0; batch classifier loss: 0.434708; batch adversarial loss: 0.569235\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356048; batch adversarial loss: 0.612483\n",
      "epoch 129; iter: 0; batch classifier loss: 0.427164; batch adversarial loss: 0.595821\n",
      "epoch 130; iter: 0; batch classifier loss: 0.426732; batch adversarial loss: 0.544696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.392762; batch adversarial loss: 0.595569\n",
      "epoch 132; iter: 0; batch classifier loss: 0.356234; batch adversarial loss: 0.472358\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346333; batch adversarial loss: 0.543366\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416861; batch adversarial loss: 0.487366\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343430; batch adversarial loss: 0.582362\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401105; batch adversarial loss: 0.545280\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328043; batch adversarial loss: 0.562792\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363805; batch adversarial loss: 0.543846\n",
      "epoch 139; iter: 0; batch classifier loss: 0.312859; batch adversarial loss: 0.534950\n",
      "epoch 140; iter: 0; batch classifier loss: 0.488698; batch adversarial loss: 0.534590\n",
      "epoch 141; iter: 0; batch classifier loss: 0.292304; batch adversarial loss: 0.636937\n",
      "epoch 142; iter: 0; batch classifier loss: 0.349857; batch adversarial loss: 0.569181\n",
      "epoch 143; iter: 0; batch classifier loss: 0.436928; batch adversarial loss: 0.604120\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376044; batch adversarial loss: 0.531964\n",
      "epoch 145; iter: 0; batch classifier loss: 0.406814; batch adversarial loss: 0.596571\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341640; batch adversarial loss: 0.556020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.263582; batch adversarial loss: 0.523413\n",
      "epoch 148; iter: 0; batch classifier loss: 0.361590; batch adversarial loss: 0.559267\n",
      "epoch 149; iter: 0; batch classifier loss: 0.424613; batch adversarial loss: 0.527501\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421202; batch adversarial loss: 0.548670\n",
      "epoch 151; iter: 0; batch classifier loss: 0.317396; batch adversarial loss: 0.542029\n",
      "epoch 152; iter: 0; batch classifier loss: 0.392235; batch adversarial loss: 0.572807\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346771; batch adversarial loss: 0.537349\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358811; batch adversarial loss: 0.572226\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379851; batch adversarial loss: 0.582880\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374280; batch adversarial loss: 0.568962\n",
      "epoch 157; iter: 0; batch classifier loss: 0.394621; batch adversarial loss: 0.521466\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352708; batch adversarial loss: 0.537486\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348911; batch adversarial loss: 0.586969\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333066; batch adversarial loss: 0.544888\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319292; batch adversarial loss: 0.555088\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357805; batch adversarial loss: 0.603748\n",
      "epoch 163; iter: 0; batch classifier loss: 0.419117; batch adversarial loss: 0.535243\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361675; batch adversarial loss: 0.534865\n",
      "epoch 165; iter: 0; batch classifier loss: 0.310054; batch adversarial loss: 0.482183\n",
      "epoch 166; iter: 0; batch classifier loss: 0.310017; batch adversarial loss: 0.523518\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364281; batch adversarial loss: 0.536381\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348941; batch adversarial loss: 0.523376\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350578; batch adversarial loss: 0.540169\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318360; batch adversarial loss: 0.437277\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390208; batch adversarial loss: 0.618297\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349263; batch adversarial loss: 0.546739\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329367; batch adversarial loss: 0.574391\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321787; batch adversarial loss: 0.517626\n",
      "epoch 175; iter: 0; batch classifier loss: 0.305997; batch adversarial loss: 0.486907\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329457; batch adversarial loss: 0.436911\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346279; batch adversarial loss: 0.504145\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343510; batch adversarial loss: 0.489430\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333661; batch adversarial loss: 0.563988\n",
      "epoch 180; iter: 0; batch classifier loss: 0.332553; batch adversarial loss: 0.563019\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420136; batch adversarial loss: 0.580309\n",
      "epoch 182; iter: 0; batch classifier loss: 0.317900; batch adversarial loss: 0.526477\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354410; batch adversarial loss: 0.566968\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347039; batch adversarial loss: 0.482088\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368480; batch adversarial loss: 0.424776\n",
      "epoch 186; iter: 0; batch classifier loss: 0.372301; batch adversarial loss: 0.548460\n",
      "epoch 187; iter: 0; batch classifier loss: 0.418036; batch adversarial loss: 0.564124\n",
      "epoch 188; iter: 0; batch classifier loss: 0.401733; batch adversarial loss: 0.520311\n",
      "epoch 189; iter: 0; batch classifier loss: 0.398185; batch adversarial loss: 0.500261\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351005; batch adversarial loss: 0.580008\n",
      "epoch 191; iter: 0; batch classifier loss: 0.334699; batch adversarial loss: 0.562718\n",
      "epoch 192; iter: 0; batch classifier loss: 0.306134; batch adversarial loss: 0.590417\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300355; batch adversarial loss: 0.524263\n",
      "epoch 194; iter: 0; batch classifier loss: 0.299909; batch adversarial loss: 0.513457\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342403; batch adversarial loss: 0.549464\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366282; batch adversarial loss: 0.598975\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317144; batch adversarial loss: 0.478724\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336624; batch adversarial loss: 0.605272\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316628; batch adversarial loss: 0.577342\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709585; batch adversarial loss: 0.681326\n",
      "epoch 1; iter: 0; batch classifier loss: 0.625162; batch adversarial loss: 0.635253\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558648; batch adversarial loss: 0.626228\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603819; batch adversarial loss: 0.620736\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541277; batch adversarial loss: 0.588641\n",
      "epoch 5; iter: 0; batch classifier loss: 0.482987; batch adversarial loss: 0.581063\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533137; batch adversarial loss: 0.577296\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532668; batch adversarial loss: 0.604843\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527100; batch adversarial loss: 0.608705\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522557; batch adversarial loss: 0.558035\n",
      "epoch 10; iter: 0; batch classifier loss: 0.597246; batch adversarial loss: 0.532974\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538897; batch adversarial loss: 0.591025\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488069; batch adversarial loss: 0.574772\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524267; batch adversarial loss: 0.644422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564648; batch adversarial loss: 0.576404\n",
      "epoch 15; iter: 0; batch classifier loss: 0.444978; batch adversarial loss: 0.621103\n",
      "epoch 16; iter: 0; batch classifier loss: 0.577500; batch adversarial loss: 0.595535\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481130; batch adversarial loss: 0.596309\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556734; batch adversarial loss: 0.581822\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532474; batch adversarial loss: 0.552418\n",
      "epoch 20; iter: 0; batch classifier loss: 0.526936; batch adversarial loss: 0.567592\n",
      "epoch 21; iter: 0; batch classifier loss: 0.608066; batch adversarial loss: 0.547180\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530658; batch adversarial loss: 0.547714\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479668; batch adversarial loss: 0.535242\n",
      "epoch 24; iter: 0; batch classifier loss: 0.548505; batch adversarial loss: 0.525452\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474640; batch adversarial loss: 0.605142\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459188; batch adversarial loss: 0.523442\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513026; batch adversarial loss: 0.538376\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457932; batch adversarial loss: 0.571001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.448296; batch adversarial loss: 0.520438\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457629; batch adversarial loss: 0.631265\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457777; batch adversarial loss: 0.502326\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443903; batch adversarial loss: 0.527679\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461748; batch adversarial loss: 0.536614\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460228; batch adversarial loss: 0.509798\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444176; batch adversarial loss: 0.526920\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420865; batch adversarial loss: 0.508615\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463322; batch adversarial loss: 0.535540\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459009; batch adversarial loss: 0.580969\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441305; batch adversarial loss: 0.571636\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418541; batch adversarial loss: 0.553313\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417859; batch adversarial loss: 0.634795\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461884; batch adversarial loss: 0.526661\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410397; batch adversarial loss: 0.571969\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500797; batch adversarial loss: 0.516849\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433130; batch adversarial loss: 0.562972\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452080; batch adversarial loss: 0.526007\n",
      "epoch 47; iter: 0; batch classifier loss: 0.458100; batch adversarial loss: 0.581294\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421892; batch adversarial loss: 0.572485\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434882; batch adversarial loss: 0.646920\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416459; batch adversarial loss: 0.507251\n",
      "epoch 51; iter: 0; batch classifier loss: 0.467658; batch adversarial loss: 0.610108\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464937; batch adversarial loss: 0.508377\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461645; batch adversarial loss: 0.498393\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430199; batch adversarial loss: 0.580032\n",
      "epoch 55; iter: 0; batch classifier loss: 0.348394; batch adversarial loss: 0.480701\n",
      "epoch 56; iter: 0; batch classifier loss: 0.385667; batch adversarial loss: 0.534929\n",
      "epoch 57; iter: 0; batch classifier loss: 0.417490; batch adversarial loss: 0.526745\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441824; batch adversarial loss: 0.644852\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402323; batch adversarial loss: 0.524692\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450008; batch adversarial loss: 0.638063\n",
      "epoch 61; iter: 0; batch classifier loss: 0.349649; batch adversarial loss: 0.498429\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439572; batch adversarial loss: 0.480051\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388230; batch adversarial loss: 0.507897\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434324; batch adversarial loss: 0.571908\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433291; batch adversarial loss: 0.515906\n",
      "epoch 66; iter: 0; batch classifier loss: 0.358469; batch adversarial loss: 0.572502\n",
      "epoch 67; iter: 0; batch classifier loss: 0.463656; batch adversarial loss: 0.526626\n",
      "epoch 68; iter: 0; batch classifier loss: 0.448847; batch adversarial loss: 0.646123\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361277; batch adversarial loss: 0.499030\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433388; batch adversarial loss: 0.553804\n",
      "epoch 71; iter: 0; batch classifier loss: 0.447659; batch adversarial loss: 0.608072\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394385; batch adversarial loss: 0.580875\n",
      "epoch 73; iter: 0; batch classifier loss: 0.397638; batch adversarial loss: 0.544032\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367950; batch adversarial loss: 0.563521\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427706; batch adversarial loss: 0.582510\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440866; batch adversarial loss: 0.573601\n",
      "epoch 77; iter: 0; batch classifier loss: 0.450987; batch adversarial loss: 0.561517\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395865; batch adversarial loss: 0.497906\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405114; batch adversarial loss: 0.563244\n",
      "epoch 80; iter: 0; batch classifier loss: 0.342418; batch adversarial loss: 0.515887\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414515; batch adversarial loss: 0.460914\n",
      "epoch 82; iter: 0; batch classifier loss: 0.479512; batch adversarial loss: 0.507489\n",
      "epoch 83; iter: 0; batch classifier loss: 0.311372; batch adversarial loss: 0.599194\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384709; batch adversarial loss: 0.599215\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376864; batch adversarial loss: 0.534681\n",
      "epoch 86; iter: 0; batch classifier loss: 0.330883; batch adversarial loss: 0.560971\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398805; batch adversarial loss: 0.553836\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393879; batch adversarial loss: 0.490511\n",
      "epoch 89; iter: 0; batch classifier loss: 0.337451; batch adversarial loss: 0.587985\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376112; batch adversarial loss: 0.563184\n",
      "epoch 91; iter: 0; batch classifier loss: 0.359983; batch adversarial loss: 0.580779\n",
      "epoch 92; iter: 0; batch classifier loss: 0.470506; batch adversarial loss: 0.543434\n",
      "epoch 93; iter: 0; batch classifier loss: 0.325178; batch adversarial loss: 0.552225\n",
      "epoch 94; iter: 0; batch classifier loss: 0.313829; batch adversarial loss: 0.499089\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393987; batch adversarial loss: 0.506825\n",
      "epoch 96; iter: 0; batch classifier loss: 0.393818; batch adversarial loss: 0.600050\n",
      "epoch 97; iter: 0; batch classifier loss: 0.331498; batch adversarial loss: 0.563180\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403075; batch adversarial loss: 0.508768\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359738; batch adversarial loss: 0.508560\n",
      "epoch 100; iter: 0; batch classifier loss: 0.426627; batch adversarial loss: 0.582065\n",
      "epoch 101; iter: 0; batch classifier loss: 0.404928; batch adversarial loss: 0.526950\n",
      "epoch 102; iter: 0; batch classifier loss: 0.321875; batch adversarial loss: 0.654869\n",
      "epoch 103; iter: 0; batch classifier loss: 0.462994; batch adversarial loss: 0.544569\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416617; batch adversarial loss: 0.527828\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408653; batch adversarial loss: 0.563952\n",
      "epoch 106; iter: 0; batch classifier loss: 0.329928; batch adversarial loss: 0.591983\n",
      "epoch 107; iter: 0; batch classifier loss: 0.484319; batch adversarial loss: 0.525424\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393403; batch adversarial loss: 0.599569\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379118; batch adversarial loss: 0.546286\n",
      "epoch 110; iter: 0; batch classifier loss: 0.475747; batch adversarial loss: 0.543710\n",
      "epoch 111; iter: 0; batch classifier loss: 0.299475; batch adversarial loss: 0.516467\n",
      "epoch 112; iter: 0; batch classifier loss: 0.408669; batch adversarial loss: 0.480094\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394484; batch adversarial loss: 0.525619\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354201; batch adversarial loss: 0.506420\n",
      "epoch 115; iter: 0; batch classifier loss: 0.421408; batch adversarial loss: 0.470543\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358167; batch adversarial loss: 0.525102\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373055; batch adversarial loss: 0.508274\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402973; batch adversarial loss: 0.516626\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354145; batch adversarial loss: 0.545663\n",
      "epoch 120; iter: 0; batch classifier loss: 0.365643; batch adversarial loss: 0.582524\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371771; batch adversarial loss: 0.608927\n",
      "epoch 122; iter: 0; batch classifier loss: 0.423647; batch adversarial loss: 0.516920\n",
      "epoch 123; iter: 0; batch classifier loss: 0.439944; batch adversarial loss: 0.515133\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338176; batch adversarial loss: 0.547902\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368870; batch adversarial loss: 0.479564\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404584; batch adversarial loss: 0.572571\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390410; batch adversarial loss: 0.497721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.380594; batch adversarial loss: 0.581759\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406633; batch adversarial loss: 0.490967\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357961; batch adversarial loss: 0.498652\n",
      "epoch 131; iter: 0; batch classifier loss: 0.434026; batch adversarial loss: 0.473336\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329628; batch adversarial loss: 0.507488\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385053; batch adversarial loss: 0.544088\n",
      "epoch 134; iter: 0; batch classifier loss: 0.467635; batch adversarial loss: 0.601705\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380324; batch adversarial loss: 0.543270\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364055; batch adversarial loss: 0.544288\n",
      "epoch 137; iter: 0; batch classifier loss: 0.448276; batch adversarial loss: 0.468882\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348022; batch adversarial loss: 0.505268\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335285; batch adversarial loss: 0.526155\n",
      "epoch 140; iter: 0; batch classifier loss: 0.428093; batch adversarial loss: 0.562744\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363732; batch adversarial loss: 0.615560\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362044; batch adversarial loss: 0.534211\n",
      "epoch 143; iter: 0; batch classifier loss: 0.393140; batch adversarial loss: 0.507810\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352285; batch adversarial loss: 0.517454\n",
      "epoch 145; iter: 0; batch classifier loss: 0.424830; batch adversarial loss: 0.506623\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399820; batch adversarial loss: 0.560385\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369296; batch adversarial loss: 0.543416\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353314; batch adversarial loss: 0.462372\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378981; batch adversarial loss: 0.589199\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367594; batch adversarial loss: 0.579150\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387697; batch adversarial loss: 0.462206\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387366; batch adversarial loss: 0.497033\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348678; batch adversarial loss: 0.497953\n",
      "epoch 154; iter: 0; batch classifier loss: 0.466346; batch adversarial loss: 0.490110\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360331; batch adversarial loss: 0.553747\n",
      "epoch 156; iter: 0; batch classifier loss: 0.418640; batch adversarial loss: 0.552702\n",
      "epoch 157; iter: 0; batch classifier loss: 0.320644; batch adversarial loss: 0.508634\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338253; batch adversarial loss: 0.571871\n",
      "epoch 159; iter: 0; batch classifier loss: 0.448383; batch adversarial loss: 0.506920\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318796; batch adversarial loss: 0.571449\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339479; batch adversarial loss: 0.542708\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376171; batch adversarial loss: 0.499432\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385576; batch adversarial loss: 0.599615\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410275; batch adversarial loss: 0.533652\n",
      "epoch 165; iter: 0; batch classifier loss: 0.403595; batch adversarial loss: 0.543947\n",
      "epoch 166; iter: 0; batch classifier loss: 0.418730; batch adversarial loss: 0.589996\n",
      "epoch 167; iter: 0; batch classifier loss: 0.386705; batch adversarial loss: 0.479063\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341891; batch adversarial loss: 0.516033\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350199; batch adversarial loss: 0.519345\n",
      "epoch 170; iter: 0; batch classifier loss: 0.340640; batch adversarial loss: 0.497817\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372017; batch adversarial loss: 0.489705\n",
      "epoch 172; iter: 0; batch classifier loss: 0.306811; batch adversarial loss: 0.525910\n",
      "epoch 173; iter: 0; batch classifier loss: 0.327031; batch adversarial loss: 0.618399\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368551; batch adversarial loss: 0.570182\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365317; batch adversarial loss: 0.626430\n",
      "epoch 176; iter: 0; batch classifier loss: 0.371869; batch adversarial loss: 0.504958\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319618; batch adversarial loss: 0.554544\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355037; batch adversarial loss: 0.543956\n",
      "epoch 179; iter: 0; batch classifier loss: 0.440331; batch adversarial loss: 0.506875\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371889; batch adversarial loss: 0.503659\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386126; batch adversarial loss: 0.551900\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354724; batch adversarial loss: 0.628470\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385692; batch adversarial loss: 0.480552\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366316; batch adversarial loss: 0.432446\n",
      "epoch 185; iter: 0; batch classifier loss: 0.285476; batch adversarial loss: 0.526471\n",
      "epoch 186; iter: 0; batch classifier loss: 0.419271; batch adversarial loss: 0.627740\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362437; batch adversarial loss: 0.561875\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378843; batch adversarial loss: 0.628532\n",
      "epoch 189; iter: 0; batch classifier loss: 0.334973; batch adversarial loss: 0.488021\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343844; batch adversarial loss: 0.515690\n",
      "epoch 191; iter: 0; batch classifier loss: 0.353076; batch adversarial loss: 0.486470\n",
      "epoch 192; iter: 0; batch classifier loss: 0.390197; batch adversarial loss: 0.599961\n",
      "epoch 193; iter: 0; batch classifier loss: 0.384455; batch adversarial loss: 0.505593\n",
      "epoch 194; iter: 0; batch classifier loss: 0.444474; batch adversarial loss: 0.480388\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328299; batch adversarial loss: 0.537465\n",
      "epoch 196; iter: 0; batch classifier loss: 0.322117; batch adversarial loss: 0.514608\n",
      "epoch 197; iter: 0; batch classifier loss: 0.437610; batch adversarial loss: 0.462878\n",
      "epoch 198; iter: 0; batch classifier loss: 0.409248; batch adversarial loss: 0.509080\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360227; batch adversarial loss: 0.470885\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667771; batch adversarial loss: 0.894374\n",
      "epoch 1; iter: 0; batch classifier loss: 0.818016; batch adversarial loss: 1.196752\n",
      "epoch 2; iter: 0; batch classifier loss: 1.078271; batch adversarial loss: 1.228978\n",
      "epoch 3; iter: 0; batch classifier loss: 1.069342; batch adversarial loss: 1.111074\n",
      "epoch 4; iter: 0; batch classifier loss: 1.114457; batch adversarial loss: 1.064534\n",
      "epoch 5; iter: 0; batch classifier loss: 1.190570; batch adversarial loss: 0.995698\n",
      "epoch 6; iter: 0; batch classifier loss: 0.964246; batch adversarial loss: 0.861413\n",
      "epoch 7; iter: 0; batch classifier loss: 1.089092; batch adversarial loss: 0.848147\n",
      "epoch 8; iter: 0; batch classifier loss: 0.997267; batch adversarial loss: 0.773875\n",
      "epoch 9; iter: 0; batch classifier loss: 0.772295; batch adversarial loss: 0.689676\n",
      "epoch 10; iter: 0; batch classifier loss: 0.714364; batch adversarial loss: 0.656692\n",
      "epoch 11; iter: 0; batch classifier loss: 0.616232; batch adversarial loss: 0.628733\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578020; batch adversarial loss: 0.620087\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557431; batch adversarial loss: 0.574353\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530645; batch adversarial loss: 0.612542\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519848; batch adversarial loss: 0.627532\n",
      "epoch 16; iter: 0; batch classifier loss: 0.590619; batch adversarial loss: 0.522068\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516764; batch adversarial loss: 0.531995\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498102; batch adversarial loss: 0.641622\n",
      "epoch 19; iter: 0; batch classifier loss: 0.560974; batch adversarial loss: 0.570804\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527778; batch adversarial loss: 0.570336\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488092; batch adversarial loss: 0.613099\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509833; batch adversarial loss: 0.613599\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495021; batch adversarial loss: 0.559194\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502843; batch adversarial loss: 0.615639\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482650; batch adversarial loss: 0.535883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.471930; batch adversarial loss: 0.588436\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509687; batch adversarial loss: 0.565350\n",
      "epoch 28; iter: 0; batch classifier loss: 0.461603; batch adversarial loss: 0.522031\n",
      "epoch 29; iter: 0; batch classifier loss: 0.518339; batch adversarial loss: 0.573518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.536987; batch adversarial loss: 0.554208\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474800; batch adversarial loss: 0.548782\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454394; batch adversarial loss: 0.616594\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442110; batch adversarial loss: 0.582363\n",
      "epoch 34; iter: 0; batch classifier loss: 0.529932; batch adversarial loss: 0.508734\n",
      "epoch 35; iter: 0; batch classifier loss: 0.495657; batch adversarial loss: 0.504169\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454979; batch adversarial loss: 0.593939\n",
      "epoch 37; iter: 0; batch classifier loss: 0.478353; batch adversarial loss: 0.597280\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443899; batch adversarial loss: 0.588843\n",
      "epoch 39; iter: 0; batch classifier loss: 0.469880; batch adversarial loss: 0.585691\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470836; batch adversarial loss: 0.553402\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486846; batch adversarial loss: 0.613078\n",
      "epoch 42; iter: 0; batch classifier loss: 0.511772; batch adversarial loss: 0.524866\n",
      "epoch 43; iter: 0; batch classifier loss: 0.457252; batch adversarial loss: 0.538095\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489150; batch adversarial loss: 0.564703\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421662; batch adversarial loss: 0.492658\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422713; batch adversarial loss: 0.600454\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422903; batch adversarial loss: 0.495525\n",
      "epoch 48; iter: 0; batch classifier loss: 0.380919; batch adversarial loss: 0.565642\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433207; batch adversarial loss: 0.555632\n",
      "epoch 50; iter: 0; batch classifier loss: 0.481449; batch adversarial loss: 0.567563\n",
      "epoch 51; iter: 0; batch classifier loss: 0.452832; batch adversarial loss: 0.557860\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419783; batch adversarial loss: 0.531309\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462480; batch adversarial loss: 0.534509\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420097; batch adversarial loss: 0.593072\n",
      "epoch 55; iter: 0; batch classifier loss: 0.493950; batch adversarial loss: 0.481311\n",
      "epoch 56; iter: 0; batch classifier loss: 0.352329; batch adversarial loss: 0.544950\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422997; batch adversarial loss: 0.618381\n",
      "epoch 58; iter: 0; batch classifier loss: 0.374822; batch adversarial loss: 0.566228\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371909; batch adversarial loss: 0.570822\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432704; batch adversarial loss: 0.459147\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460947; batch adversarial loss: 0.588364\n",
      "epoch 62; iter: 0; batch classifier loss: 0.478711; batch adversarial loss: 0.544331\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391115; batch adversarial loss: 0.606921\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411860; batch adversarial loss: 0.492778\n",
      "epoch 65; iter: 0; batch classifier loss: 0.324056; batch adversarial loss: 0.562077\n",
      "epoch 66; iter: 0; batch classifier loss: 0.458841; batch adversarial loss: 0.566576\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460520; batch adversarial loss: 0.553626\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427677; batch adversarial loss: 0.537607\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457747; batch adversarial loss: 0.570396\n",
      "epoch 70; iter: 0; batch classifier loss: 0.458399; batch adversarial loss: 0.657451\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412919; batch adversarial loss: 0.482475\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440085; batch adversarial loss: 0.537395\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439452; batch adversarial loss: 0.587606\n",
      "epoch 74; iter: 0; batch classifier loss: 0.369701; batch adversarial loss: 0.492025\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401629; batch adversarial loss: 0.528531\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359109; batch adversarial loss: 0.589483\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399483; batch adversarial loss: 0.598490\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380848; batch adversarial loss: 0.571116\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416869; batch adversarial loss: 0.616065\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423862; batch adversarial loss: 0.606426\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375986; batch adversarial loss: 0.571675\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403016; batch adversarial loss: 0.555194\n",
      "epoch 83; iter: 0; batch classifier loss: 0.344498; batch adversarial loss: 0.570837\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431516; batch adversarial loss: 0.536836\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389434; batch adversarial loss: 0.571431\n",
      "epoch 86; iter: 0; batch classifier loss: 0.489068; batch adversarial loss: 0.554074\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345501; batch adversarial loss: 0.605061\n",
      "epoch 88; iter: 0; batch classifier loss: 0.332894; batch adversarial loss: 0.554138\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427792; batch adversarial loss: 0.606906\n",
      "epoch 90; iter: 0; batch classifier loss: 0.354154; batch adversarial loss: 0.561711\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409792; batch adversarial loss: 0.457758\n",
      "epoch 92; iter: 0; batch classifier loss: 0.447222; batch adversarial loss: 0.570132\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420143; batch adversarial loss: 0.527162\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408139; batch adversarial loss: 0.507681\n",
      "epoch 95; iter: 0; batch classifier loss: 0.310867; batch adversarial loss: 0.501704\n",
      "epoch 96; iter: 0; batch classifier loss: 0.456115; batch adversarial loss: 0.535723\n",
      "epoch 97; iter: 0; batch classifier loss: 0.314315; batch adversarial loss: 0.546054\n",
      "epoch 98; iter: 0; batch classifier loss: 0.459172; batch adversarial loss: 0.579482\n",
      "epoch 99; iter: 0; batch classifier loss: 0.305345; batch adversarial loss: 0.588583\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349453; batch adversarial loss: 0.571826\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368530; batch adversarial loss: 0.482284\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326833; batch adversarial loss: 0.553179\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377459; batch adversarial loss: 0.588043\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421942; batch adversarial loss: 0.571331\n",
      "epoch 105; iter: 0; batch classifier loss: 0.304510; batch adversarial loss: 0.606492\n",
      "epoch 106; iter: 0; batch classifier loss: 0.290079; batch adversarial loss: 0.509090\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387686; batch adversarial loss: 0.483930\n",
      "epoch 108; iter: 0; batch classifier loss: 0.344744; batch adversarial loss: 0.510143\n",
      "epoch 109; iter: 0; batch classifier loss: 0.427070; batch adversarial loss: 0.616077\n",
      "epoch 110; iter: 0; batch classifier loss: 0.360248; batch adversarial loss: 0.502204\n",
      "epoch 111; iter: 0; batch classifier loss: 0.331535; batch adversarial loss: 0.632253\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363574; batch adversarial loss: 0.542787\n",
      "epoch 113; iter: 0; batch classifier loss: 0.338556; batch adversarial loss: 0.562140\n",
      "epoch 114; iter: 0; batch classifier loss: 0.313151; batch adversarial loss: 0.570331\n",
      "epoch 115; iter: 0; batch classifier loss: 0.448279; batch adversarial loss: 0.570916\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350428; batch adversarial loss: 0.598112\n",
      "epoch 117; iter: 0; batch classifier loss: 0.400525; batch adversarial loss: 0.571085\n",
      "epoch 118; iter: 0; batch classifier loss: 0.439739; batch adversarial loss: 0.551284\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380745; batch adversarial loss: 0.571311\n",
      "epoch 120; iter: 0; batch classifier loss: 0.314518; batch adversarial loss: 0.623804\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385333; batch adversarial loss: 0.589850\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326073; batch adversarial loss: 0.546773\n",
      "epoch 123; iter: 0; batch classifier loss: 0.281959; batch adversarial loss: 0.571859\n",
      "epoch 124; iter: 0; batch classifier loss: 0.308404; batch adversarial loss: 0.589600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.339006; batch adversarial loss: 0.535444\n",
      "epoch 126; iter: 0; batch classifier loss: 0.289202; batch adversarial loss: 0.554127\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365896; batch adversarial loss: 0.596804\n",
      "epoch 128; iter: 0; batch classifier loss: 0.401408; batch adversarial loss: 0.552899\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356255; batch adversarial loss: 0.554840\n",
      "epoch 130; iter: 0; batch classifier loss: 0.309268; batch adversarial loss: 0.526299\n",
      "epoch 131; iter: 0; batch classifier loss: 0.307381; batch adversarial loss: 0.491543\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381511; batch adversarial loss: 0.500546\n",
      "epoch 133; iter: 0; batch classifier loss: 0.380859; batch adversarial loss: 0.590404\n",
      "epoch 134; iter: 0; batch classifier loss: 0.407163; batch adversarial loss: 0.564530\n",
      "epoch 135; iter: 0; batch classifier loss: 0.410328; batch adversarial loss: 0.588016\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324577; batch adversarial loss: 0.526208\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369680; batch adversarial loss: 0.545019\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375289; batch adversarial loss: 0.635452\n",
      "epoch 139; iter: 0; batch classifier loss: 0.282536; batch adversarial loss: 0.536495\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347450; batch adversarial loss: 0.571007\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359459; batch adversarial loss: 0.491231\n",
      "epoch 142; iter: 0; batch classifier loss: 0.316424; batch adversarial loss: 0.527490\n",
      "epoch 143; iter: 0; batch classifier loss: 0.297227; batch adversarial loss: 0.561390\n",
      "epoch 144; iter: 0; batch classifier loss: 0.332719; batch adversarial loss: 0.581078\n",
      "epoch 145; iter: 0; batch classifier loss: 0.423806; batch adversarial loss: 0.563790\n",
      "epoch 146; iter: 0; batch classifier loss: 0.309722; batch adversarial loss: 0.534497\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384776; batch adversarial loss: 0.535319\n",
      "epoch 148; iter: 0; batch classifier loss: 0.432385; batch adversarial loss: 0.534888\n",
      "epoch 149; iter: 0; batch classifier loss: 0.340679; batch adversarial loss: 0.553243\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384346; batch adversarial loss: 0.553821\n",
      "epoch 151; iter: 0; batch classifier loss: 0.293150; batch adversarial loss: 0.580770\n",
      "epoch 152; iter: 0; batch classifier loss: 0.429204; batch adversarial loss: 0.525856\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343712; batch adversarial loss: 0.606887\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332241; batch adversarial loss: 0.481951\n",
      "epoch 155; iter: 0; batch classifier loss: 0.308762; batch adversarial loss: 0.484447\n",
      "epoch 156; iter: 0; batch classifier loss: 0.464889; batch adversarial loss: 0.587907\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359037; batch adversarial loss: 0.518911\n",
      "epoch 158; iter: 0; batch classifier loss: 0.335354; batch adversarial loss: 0.526455\n",
      "epoch 159; iter: 0; batch classifier loss: 0.315361; batch adversarial loss: 0.536965\n",
      "epoch 160; iter: 0; batch classifier loss: 0.315244; batch adversarial loss: 0.534275\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354330; batch adversarial loss: 0.535456\n",
      "epoch 162; iter: 0; batch classifier loss: 0.286087; batch adversarial loss: 0.581805\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338314; batch adversarial loss: 0.510015\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324532; batch adversarial loss: 0.561611\n",
      "epoch 165; iter: 0; batch classifier loss: 0.268184; batch adversarial loss: 0.518418\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360023; batch adversarial loss: 0.537037\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329009; batch adversarial loss: 0.571892\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377717; batch adversarial loss: 0.625487\n",
      "epoch 169; iter: 0; batch classifier loss: 0.316682; batch adversarial loss: 0.544426\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330690; batch adversarial loss: 0.553411\n",
      "epoch 171; iter: 0; batch classifier loss: 0.272533; batch adversarial loss: 0.543850\n",
      "epoch 172; iter: 0; batch classifier loss: 0.283284; batch adversarial loss: 0.554278\n",
      "epoch 173; iter: 0; batch classifier loss: 0.264687; batch adversarial loss: 0.570825\n",
      "epoch 174; iter: 0; batch classifier loss: 0.296910; batch adversarial loss: 0.501317\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372892; batch adversarial loss: 0.554935\n",
      "epoch 176; iter: 0; batch classifier loss: 0.389965; batch adversarial loss: 0.561588\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351709; batch adversarial loss: 0.544142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340034; batch adversarial loss: 0.597041\n",
      "epoch 179; iter: 0; batch classifier loss: 0.306756; batch adversarial loss: 0.509437\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382129; batch adversarial loss: 0.518361\n",
      "epoch 181; iter: 0; batch classifier loss: 0.369513; batch adversarial loss: 0.492096\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344732; batch adversarial loss: 0.536834\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371603; batch adversarial loss: 0.527294\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353101; batch adversarial loss: 0.528076\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331171; batch adversarial loss: 0.518564\n",
      "epoch 186; iter: 0; batch classifier loss: 0.402647; batch adversarial loss: 0.578598\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313596; batch adversarial loss: 0.613856\n",
      "epoch 188; iter: 0; batch classifier loss: 0.419710; batch adversarial loss: 0.535504\n",
      "epoch 189; iter: 0; batch classifier loss: 0.334499; batch adversarial loss: 0.510727\n",
      "epoch 190; iter: 0; batch classifier loss: 0.251618; batch adversarial loss: 0.527672\n",
      "epoch 191; iter: 0; batch classifier loss: 0.348587; batch adversarial loss: 0.536719\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344796; batch adversarial loss: 0.562004\n",
      "epoch 193; iter: 0; batch classifier loss: 0.216248; batch adversarial loss: 0.552443\n",
      "epoch 194; iter: 0; batch classifier loss: 0.401728; batch adversarial loss: 0.563620\n",
      "epoch 195; iter: 0; batch classifier loss: 0.352518; batch adversarial loss: 0.491243\n",
      "epoch 196; iter: 0; batch classifier loss: 0.371453; batch adversarial loss: 0.544413\n",
      "epoch 197; iter: 0; batch classifier loss: 0.314982; batch adversarial loss: 0.599844\n",
      "epoch 198; iter: 0; batch classifier loss: 0.300535; batch adversarial loss: 0.527945\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357807; batch adversarial loss: 0.501231\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710508; batch adversarial loss: 0.763726\n",
      "epoch 1; iter: 0; batch classifier loss: 0.735724; batch adversarial loss: 0.737293\n",
      "epoch 2; iter: 0; batch classifier loss: 0.753137; batch adversarial loss: 0.689612\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556920; batch adversarial loss: 0.639996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544466; batch adversarial loss: 0.621939\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621996; batch adversarial loss: 0.624634\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545167; batch adversarial loss: 0.599926\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517984; batch adversarial loss: 0.547301\n",
      "epoch 8; iter: 0; batch classifier loss: 0.540371; batch adversarial loss: 0.555277\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494646; batch adversarial loss: 0.570131\n",
      "epoch 10; iter: 0; batch classifier loss: 0.583544; batch adversarial loss: 0.594275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521062; batch adversarial loss: 0.571005\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501563; batch adversarial loss: 0.586835\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556483; batch adversarial loss: 0.562684\n",
      "epoch 14; iter: 0; batch classifier loss: 0.454741; batch adversarial loss: 0.558696\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480183; batch adversarial loss: 0.541110\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423763; batch adversarial loss: 0.538022\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522707; batch adversarial loss: 0.563482\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458077; batch adversarial loss: 0.561880\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438713; batch adversarial loss: 0.618131\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495962; batch adversarial loss: 0.474530\n",
      "epoch 21; iter: 0; batch classifier loss: 0.561437; batch adversarial loss: 0.594596\n",
      "epoch 22; iter: 0; batch classifier loss: 0.448804; batch adversarial loss: 0.552821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.455621; batch adversarial loss: 0.597455\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501233; batch adversarial loss: 0.527840\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492957; batch adversarial loss: 0.506551\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510164; batch adversarial loss: 0.591198\n",
      "epoch 27; iter: 0; batch classifier loss: 0.384343; batch adversarial loss: 0.529404\n",
      "epoch 28; iter: 0; batch classifier loss: 0.458650; batch adversarial loss: 0.590216\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438130; batch adversarial loss: 0.540582\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485133; batch adversarial loss: 0.528577\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499555; batch adversarial loss: 0.528176\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488927; batch adversarial loss: 0.565842\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450050; batch adversarial loss: 0.516173\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455107; batch adversarial loss: 0.607028\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461194; batch adversarial loss: 0.520311\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403153; batch adversarial loss: 0.534707\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460971; batch adversarial loss: 0.573783\n",
      "epoch 38; iter: 0; batch classifier loss: 0.413945; batch adversarial loss: 0.509253\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437559; batch adversarial loss: 0.481729\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497613; batch adversarial loss: 0.562553\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445699; batch adversarial loss: 0.526326\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496244; batch adversarial loss: 0.562622\n",
      "epoch 43; iter: 0; batch classifier loss: 0.503959; batch adversarial loss: 0.553147\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418294; batch adversarial loss: 0.627312\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412078; batch adversarial loss: 0.524810\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440268; batch adversarial loss: 0.552309\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429730; batch adversarial loss: 0.535315\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439271; batch adversarial loss: 0.451937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398836; batch adversarial loss: 0.574746\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386206; batch adversarial loss: 0.546851\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411517; batch adversarial loss: 0.615778\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461314; batch adversarial loss: 0.537182\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437649; batch adversarial loss: 0.534505\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446587; batch adversarial loss: 0.577595\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433441; batch adversarial loss: 0.468616\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437719; batch adversarial loss: 0.535802\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440443; batch adversarial loss: 0.539331\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414935; batch adversarial loss: 0.406083\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444709; batch adversarial loss: 0.504964\n",
      "epoch 60; iter: 0; batch classifier loss: 0.371776; batch adversarial loss: 0.508612\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427765; batch adversarial loss: 0.574526\n",
      "epoch 62; iter: 0; batch classifier loss: 0.357218; batch adversarial loss: 0.520588\n",
      "epoch 63; iter: 0; batch classifier loss: 0.380598; batch adversarial loss: 0.628068\n",
      "epoch 64; iter: 0; batch classifier loss: 0.496231; batch adversarial loss: 0.511273\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431445; batch adversarial loss: 0.517473\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406516; batch adversarial loss: 0.535553\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379046; batch adversarial loss: 0.489426\n",
      "epoch 68; iter: 0; batch classifier loss: 0.477393; batch adversarial loss: 0.466062\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355024; batch adversarial loss: 0.614206\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434620; batch adversarial loss: 0.544827\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392298; batch adversarial loss: 0.563469\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432178; batch adversarial loss: 0.546398\n",
      "epoch 73; iter: 0; batch classifier loss: 0.339533; batch adversarial loss: 0.551755\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415164; batch adversarial loss: 0.481705\n",
      "epoch 75; iter: 0; batch classifier loss: 0.459168; batch adversarial loss: 0.512973\n",
      "epoch 76; iter: 0; batch classifier loss: 0.505131; batch adversarial loss: 0.545857\n",
      "epoch 77; iter: 0; batch classifier loss: 0.359798; batch adversarial loss: 0.573277\n",
      "epoch 78; iter: 0; batch classifier loss: 0.436025; batch adversarial loss: 0.475509\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389260; batch adversarial loss: 0.574602\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369962; batch adversarial loss: 0.612188\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433661; batch adversarial loss: 0.543924\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410192; batch adversarial loss: 0.575541\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326930; batch adversarial loss: 0.617214\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383102; batch adversarial loss: 0.514393\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434161; batch adversarial loss: 0.618581\n",
      "epoch 86; iter: 0; batch classifier loss: 0.454758; batch adversarial loss: 0.525434\n",
      "epoch 87; iter: 0; batch classifier loss: 0.357564; batch adversarial loss: 0.526389\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379986; batch adversarial loss: 0.534873\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394423; batch adversarial loss: 0.546012\n",
      "epoch 90; iter: 0; batch classifier loss: 0.448054; batch adversarial loss: 0.458132\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428767; batch adversarial loss: 0.547570\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434541; batch adversarial loss: 0.584181\n",
      "epoch 93; iter: 0; batch classifier loss: 0.345786; batch adversarial loss: 0.522032\n",
      "epoch 94; iter: 0; batch classifier loss: 0.326163; batch adversarial loss: 0.541912\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362586; batch adversarial loss: 0.516970\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355231; batch adversarial loss: 0.545613\n",
      "epoch 97; iter: 0; batch classifier loss: 0.455025; batch adversarial loss: 0.543014\n",
      "epoch 98; iter: 0; batch classifier loss: 0.340923; batch adversarial loss: 0.542092\n",
      "epoch 99; iter: 0; batch classifier loss: 0.345169; batch adversarial loss: 0.497311\n",
      "epoch 100; iter: 0; batch classifier loss: 0.422136; batch adversarial loss: 0.592761\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362543; batch adversarial loss: 0.449089\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414029; batch adversarial loss: 0.486249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365618; batch adversarial loss: 0.542123\n",
      "epoch 104; iter: 0; batch classifier loss: 0.353411; batch adversarial loss: 0.584990\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363326; batch adversarial loss: 0.561435\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389387; batch adversarial loss: 0.547296\n",
      "epoch 107; iter: 0; batch classifier loss: 0.301562; batch adversarial loss: 0.474816\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379297; batch adversarial loss: 0.641427\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358505; batch adversarial loss: 0.513487\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386092; batch adversarial loss: 0.588225\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372181; batch adversarial loss: 0.465327\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386451; batch adversarial loss: 0.481025\n",
      "epoch 113; iter: 0; batch classifier loss: 0.444692; batch adversarial loss: 0.476567\n",
      "epoch 114; iter: 0; batch classifier loss: 0.414955; batch adversarial loss: 0.557230\n",
      "epoch 115; iter: 0; batch classifier loss: 0.441788; batch adversarial loss: 0.518322\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319844; batch adversarial loss: 0.526587\n",
      "epoch 117; iter: 0; batch classifier loss: 0.366292; batch adversarial loss: 0.513202\n",
      "epoch 118; iter: 0; batch classifier loss: 0.388345; batch adversarial loss: 0.546015\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368619; batch adversarial loss: 0.572800\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370864; batch adversarial loss: 0.577690\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393335; batch adversarial loss: 0.488377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.366560; batch adversarial loss: 0.436323\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362842; batch adversarial loss: 0.535086\n",
      "epoch 124; iter: 0; batch classifier loss: 0.409029; batch adversarial loss: 0.516189\n",
      "epoch 125; iter: 0; batch classifier loss: 0.328385; batch adversarial loss: 0.557890\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380248; batch adversarial loss: 0.557959\n",
      "epoch 127; iter: 0; batch classifier loss: 0.459709; batch adversarial loss: 0.486099\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344498; batch adversarial loss: 0.602961\n",
      "epoch 129; iter: 0; batch classifier loss: 0.429628; batch adversarial loss: 0.601708\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384018; batch adversarial loss: 0.521891\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438027; batch adversarial loss: 0.497233\n",
      "epoch 132; iter: 0; batch classifier loss: 0.366067; batch adversarial loss: 0.532424\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302408; batch adversarial loss: 0.496965\n",
      "epoch 134; iter: 0; batch classifier loss: 0.415538; batch adversarial loss: 0.552293\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377149; batch adversarial loss: 0.534490\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333736; batch adversarial loss: 0.560155\n",
      "epoch 137; iter: 0; batch classifier loss: 0.318777; batch adversarial loss: 0.561304\n",
      "epoch 138; iter: 0; batch classifier loss: 0.449671; batch adversarial loss: 0.546181\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345195; batch adversarial loss: 0.446373\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371924; batch adversarial loss: 0.515959\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403096; batch adversarial loss: 0.621990\n",
      "epoch 142; iter: 0; batch classifier loss: 0.342939; batch adversarial loss: 0.499180\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334337; batch adversarial loss: 0.535914\n",
      "epoch 144; iter: 0; batch classifier loss: 0.294397; batch adversarial loss: 0.468213\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384280; batch adversarial loss: 0.575693\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359640; batch adversarial loss: 0.497783\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303373; batch adversarial loss: 0.513963\n",
      "epoch 148; iter: 0; batch classifier loss: 0.385441; batch adversarial loss: 0.545007\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391987; batch adversarial loss: 0.581676\n",
      "epoch 150; iter: 0; batch classifier loss: 0.346847; batch adversarial loss: 0.584891\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361276; batch adversarial loss: 0.603509\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378892; batch adversarial loss: 0.517435\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365709; batch adversarial loss: 0.527841\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319993; batch adversarial loss: 0.536911\n",
      "epoch 155; iter: 0; batch classifier loss: 0.390829; batch adversarial loss: 0.511132\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366934; batch adversarial loss: 0.496791\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411190; batch adversarial loss: 0.484194\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369238; batch adversarial loss: 0.565087\n",
      "epoch 159; iter: 0; batch classifier loss: 0.410743; batch adversarial loss: 0.536142\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347188; batch adversarial loss: 0.632619\n",
      "epoch 161; iter: 0; batch classifier loss: 0.312192; batch adversarial loss: 0.575264\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370322; batch adversarial loss: 0.573030\n",
      "epoch 163; iter: 0; batch classifier loss: 0.467590; batch adversarial loss: 0.532081\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360302; batch adversarial loss: 0.545151\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398665; batch adversarial loss: 0.534960\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388799; batch adversarial loss: 0.505451\n",
      "epoch 167; iter: 0; batch classifier loss: 0.421149; batch adversarial loss: 0.573060\n",
      "epoch 168; iter: 0; batch classifier loss: 0.404655; batch adversarial loss: 0.603002\n",
      "epoch 169; iter: 0; batch classifier loss: 0.439951; batch adversarial loss: 0.525107\n",
      "epoch 170; iter: 0; batch classifier loss: 0.376880; batch adversarial loss: 0.509386\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329278; batch adversarial loss: 0.544814\n",
      "epoch 172; iter: 0; batch classifier loss: 0.303409; batch adversarial loss: 0.602760\n",
      "epoch 173; iter: 0; batch classifier loss: 0.412854; batch adversarial loss: 0.438588\n",
      "epoch 174; iter: 0; batch classifier loss: 0.309387; batch adversarial loss: 0.535229\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388679; batch adversarial loss: 0.552131\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360664; batch adversarial loss: 0.523608\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389437; batch adversarial loss: 0.476388\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376799; batch adversarial loss: 0.594539\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390485; batch adversarial loss: 0.583077\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350924; batch adversarial loss: 0.527650\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395382; batch adversarial loss: 0.505705\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338748; batch adversarial loss: 0.488340\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386195; batch adversarial loss: 0.476352\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365833; batch adversarial loss: 0.615895\n",
      "epoch 185; iter: 0; batch classifier loss: 0.433645; batch adversarial loss: 0.621541\n",
      "epoch 186; iter: 0; batch classifier loss: 0.409517; batch adversarial loss: 0.629785\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358035; batch adversarial loss: 0.535072\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329927; batch adversarial loss: 0.450018\n",
      "epoch 189; iter: 0; batch classifier loss: 0.314414; batch adversarial loss: 0.506757\n",
      "epoch 190; iter: 0; batch classifier loss: 0.293545; batch adversarial loss: 0.514144\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362746; batch adversarial loss: 0.544101\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373275; batch adversarial loss: 0.546025\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368453; batch adversarial loss: 0.447026\n",
      "epoch 194; iter: 0; batch classifier loss: 0.388458; batch adversarial loss: 0.593228\n",
      "epoch 195; iter: 0; batch classifier loss: 0.405791; batch adversarial loss: 0.522970\n",
      "epoch 196; iter: 0; batch classifier loss: 0.386143; batch adversarial loss: 0.575216\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344738; batch adversarial loss: 0.470543\n",
      "epoch 198; iter: 0; batch classifier loss: 0.410951; batch adversarial loss: 0.553871\n",
      "epoch 199; iter: 0; batch classifier loss: 0.415240; batch adversarial loss: 0.487340\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666083; batch adversarial loss: 0.698591\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581487; batch adversarial loss: 0.678183\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579630; batch adversarial loss: 0.646439\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577363; batch adversarial loss: 0.612599\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566664; batch adversarial loss: 0.607089\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595811; batch adversarial loss: 0.570299\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486263; batch adversarial loss: 0.616717\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509456; batch adversarial loss: 0.549098\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514580; batch adversarial loss: 0.572780\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534098; batch adversarial loss: 0.579786\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520795; batch adversarial loss: 0.555213\n",
      "epoch 11; iter: 0; batch classifier loss: 0.460135; batch adversarial loss: 0.553467\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522869; batch adversarial loss: 0.541478\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525651; batch adversarial loss: 0.548420\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512634; batch adversarial loss: 0.551038\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554648; batch adversarial loss: 0.580006\n",
      "epoch 16; iter: 0; batch classifier loss: 0.595217; batch adversarial loss: 0.555680\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484996; batch adversarial loss: 0.541471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.547464; batch adversarial loss: 0.594000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542721; batch adversarial loss: 0.583622\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434981; batch adversarial loss: 0.541483\n",
      "epoch 21; iter: 0; batch classifier loss: 0.556937; batch adversarial loss: 0.551900\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457832; batch adversarial loss: 0.535724\n",
      "epoch 23; iter: 0; batch classifier loss: 0.442917; batch adversarial loss: 0.487487\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489980; batch adversarial loss: 0.515865\n",
      "epoch 25; iter: 0; batch classifier loss: 0.573343; batch adversarial loss: 0.571318\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513664; batch adversarial loss: 0.586075\n",
      "epoch 27; iter: 0; batch classifier loss: 0.496205; batch adversarial loss: 0.546855\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506222; batch adversarial loss: 0.494158\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524280; batch adversarial loss: 0.519213\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477167; batch adversarial loss: 0.553717\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500227; batch adversarial loss: 0.501826\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433579; batch adversarial loss: 0.570480\n",
      "epoch 33; iter: 0; batch classifier loss: 0.526288; batch adversarial loss: 0.471711\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422927; batch adversarial loss: 0.508588\n",
      "epoch 35; iter: 0; batch classifier loss: 0.495080; batch adversarial loss: 0.589832\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454654; batch adversarial loss: 0.589668\n",
      "epoch 37; iter: 0; batch classifier loss: 0.410831; batch adversarial loss: 0.507528\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446424; batch adversarial loss: 0.479151\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449511; batch adversarial loss: 0.589970\n",
      "epoch 40; iter: 0; batch classifier loss: 0.501330; batch adversarial loss: 0.552376\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477725; batch adversarial loss: 0.535814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459764; batch adversarial loss: 0.544535\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454809; batch adversarial loss: 0.554398\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438044; batch adversarial loss: 0.525729\n",
      "epoch 45; iter: 0; batch classifier loss: 0.340930; batch adversarial loss: 0.498615\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441912; batch adversarial loss: 0.526438\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421461; batch adversarial loss: 0.628395\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391823; batch adversarial loss: 0.496911\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449305; batch adversarial loss: 0.639279\n",
      "epoch 50; iter: 0; batch classifier loss: 0.427333; batch adversarial loss: 0.581950\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383695; batch adversarial loss: 0.535249\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450797; batch adversarial loss: 0.478189\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422925; batch adversarial loss: 0.600390\n",
      "epoch 54; iter: 0; batch classifier loss: 0.517774; batch adversarial loss: 0.534081\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431289; batch adversarial loss: 0.563352\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396953; batch adversarial loss: 0.516279\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423507; batch adversarial loss: 0.535612\n",
      "epoch 58; iter: 0; batch classifier loss: 0.342203; batch adversarial loss: 0.544252\n",
      "epoch 59; iter: 0; batch classifier loss: 0.386908; batch adversarial loss: 0.544414\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447159; batch adversarial loss: 0.515710\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428348; batch adversarial loss: 0.563912\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457936; batch adversarial loss: 0.487910\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386644; batch adversarial loss: 0.563340\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432678; batch adversarial loss: 0.573533\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420236; batch adversarial loss: 0.544508\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401004; batch adversarial loss: 0.488332\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379097; batch adversarial loss: 0.610145\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386932; batch adversarial loss: 0.517680\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406286; batch adversarial loss: 0.497773\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414772; batch adversarial loss: 0.543900\n",
      "epoch 71; iter: 0; batch classifier loss: 0.340053; batch adversarial loss: 0.506077\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355956; batch adversarial loss: 0.477775\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382161; batch adversarial loss: 0.616615\n",
      "epoch 74; iter: 0; batch classifier loss: 0.566660; batch adversarial loss: 0.537110\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380788; batch adversarial loss: 0.583733\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414243; batch adversarial loss: 0.494805\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391677; batch adversarial loss: 0.497094\n",
      "epoch 78; iter: 0; batch classifier loss: 0.513056; batch adversarial loss: 0.551706\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394803; batch adversarial loss: 0.488389\n",
      "epoch 80; iter: 0; batch classifier loss: 0.482004; batch adversarial loss: 0.528921\n",
      "epoch 81; iter: 0; batch classifier loss: 0.338916; batch adversarial loss: 0.547730\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413844; batch adversarial loss: 0.620638\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367033; batch adversarial loss: 0.497432\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408647; batch adversarial loss: 0.505145\n",
      "epoch 85; iter: 0; batch classifier loss: 0.455836; batch adversarial loss: 0.582111\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356466; batch adversarial loss: 0.458457\n",
      "epoch 87; iter: 0; batch classifier loss: 0.408345; batch adversarial loss: 0.514967\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388483; batch adversarial loss: 0.580762\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422833; batch adversarial loss: 0.561412\n",
      "epoch 90; iter: 0; batch classifier loss: 0.337901; batch adversarial loss: 0.555052\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363014; batch adversarial loss: 0.526942\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367272; batch adversarial loss: 0.514920\n",
      "epoch 93; iter: 0; batch classifier loss: 0.326862; batch adversarial loss: 0.534779\n",
      "epoch 94; iter: 0; batch classifier loss: 0.473531; batch adversarial loss: 0.554265\n",
      "epoch 95; iter: 0; batch classifier loss: 0.490170; batch adversarial loss: 0.496888\n",
      "epoch 96; iter: 0; batch classifier loss: 0.351496; batch adversarial loss: 0.450692\n",
      "epoch 97; iter: 0; batch classifier loss: 0.452745; batch adversarial loss: 0.552719\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373938; batch adversarial loss: 0.619687\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361653; batch adversarial loss: 0.553539\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431173; batch adversarial loss: 0.580862\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393503; batch adversarial loss: 0.617362\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363116; batch adversarial loss: 0.495855\n",
      "epoch 103; iter: 0; batch classifier loss: 0.425425; batch adversarial loss: 0.582405\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392376; batch adversarial loss: 0.518005\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417295; batch adversarial loss: 0.535662\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389528; batch adversarial loss: 0.562195\n",
      "epoch 107; iter: 0; batch classifier loss: 0.335683; batch adversarial loss: 0.574242\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367685; batch adversarial loss: 0.497682\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421219; batch adversarial loss: 0.583719\n",
      "epoch 110; iter: 0; batch classifier loss: 0.380977; batch adversarial loss: 0.535267\n",
      "epoch 111; iter: 0; batch classifier loss: 0.426373; batch adversarial loss: 0.601663\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362756; batch adversarial loss: 0.544069\n",
      "epoch 113; iter: 0; batch classifier loss: 0.438128; batch adversarial loss: 0.543399\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381739; batch adversarial loss: 0.486553\n",
      "epoch 115; iter: 0; batch classifier loss: 0.496616; batch adversarial loss: 0.620005\n",
      "epoch 116; iter: 0; batch classifier loss: 0.363284; batch adversarial loss: 0.590325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.353650; batch adversarial loss: 0.579574\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395430; batch adversarial loss: 0.525011\n",
      "epoch 119; iter: 0; batch classifier loss: 0.346854; batch adversarial loss: 0.544478\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363812; batch adversarial loss: 0.592813\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381715; batch adversarial loss: 0.478541\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383759; batch adversarial loss: 0.506133\n",
      "epoch 123; iter: 0; batch classifier loss: 0.335656; batch adversarial loss: 0.525264\n",
      "epoch 124; iter: 0; batch classifier loss: 0.390543; batch adversarial loss: 0.554684\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356283; batch adversarial loss: 0.526462\n",
      "epoch 126; iter: 0; batch classifier loss: 0.416256; batch adversarial loss: 0.553922\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340085; batch adversarial loss: 0.535322\n",
      "epoch 128; iter: 0; batch classifier loss: 0.442139; batch adversarial loss: 0.553399\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388927; batch adversarial loss: 0.511057\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358651; batch adversarial loss: 0.499074\n",
      "epoch 131; iter: 0; batch classifier loss: 0.334866; batch adversarial loss: 0.496726\n",
      "epoch 132; iter: 0; batch classifier loss: 0.419510; batch adversarial loss: 0.515312\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335908; batch adversarial loss: 0.515550\n",
      "epoch 134; iter: 0; batch classifier loss: 0.428665; batch adversarial loss: 0.555176\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347887; batch adversarial loss: 0.516079\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336523; batch adversarial loss: 0.650599\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352414; batch adversarial loss: 0.516424\n",
      "epoch 138; iter: 0; batch classifier loss: 0.371482; batch adversarial loss: 0.535655\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358965; batch adversarial loss: 0.545446\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405480; batch adversarial loss: 0.620042\n",
      "epoch 141; iter: 0; batch classifier loss: 0.392761; batch adversarial loss: 0.487236\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418660; batch adversarial loss: 0.563288\n",
      "epoch 143; iter: 0; batch classifier loss: 0.324897; batch adversarial loss: 0.543713\n",
      "epoch 144; iter: 0; batch classifier loss: 0.469227; batch adversarial loss: 0.572514\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379315; batch adversarial loss: 0.563298\n",
      "epoch 146; iter: 0; batch classifier loss: 0.504372; batch adversarial loss: 0.497831\n",
      "epoch 147; iter: 0; batch classifier loss: 0.357680; batch adversarial loss: 0.544809\n",
      "epoch 148; iter: 0; batch classifier loss: 0.477806; batch adversarial loss: 0.524779\n",
      "epoch 149; iter: 0; batch classifier loss: 0.308005; batch adversarial loss: 0.564410\n",
      "epoch 150; iter: 0; batch classifier loss: 0.319980; batch adversarial loss: 0.572588\n",
      "epoch 151; iter: 0; batch classifier loss: 0.308338; batch adversarial loss: 0.524976\n",
      "epoch 152; iter: 0; batch classifier loss: 0.423340; batch adversarial loss: 0.440119\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405628; batch adversarial loss: 0.516256\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357903; batch adversarial loss: 0.534400\n",
      "epoch 155; iter: 0; batch classifier loss: 0.353869; batch adversarial loss: 0.506635\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325242; batch adversarial loss: 0.658745\n",
      "epoch 157; iter: 0; batch classifier loss: 0.343397; batch adversarial loss: 0.525450\n",
      "epoch 158; iter: 0; batch classifier loss: 0.325439; batch adversarial loss: 0.544517\n",
      "epoch 159; iter: 0; batch classifier loss: 0.324787; batch adversarial loss: 0.468593\n",
      "epoch 160; iter: 0; batch classifier loss: 0.346190; batch adversarial loss: 0.515882\n",
      "epoch 161; iter: 0; batch classifier loss: 0.313437; batch adversarial loss: 0.534694\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385651; batch adversarial loss: 0.533873\n",
      "epoch 163; iter: 0; batch classifier loss: 0.315159; batch adversarial loss: 0.588917\n",
      "epoch 164; iter: 0; batch classifier loss: 0.331311; batch adversarial loss: 0.532460\n",
      "epoch 165; iter: 0; batch classifier loss: 0.414577; batch adversarial loss: 0.572963\n",
      "epoch 166; iter: 0; batch classifier loss: 0.272858; batch adversarial loss: 0.516783\n",
      "epoch 167; iter: 0; batch classifier loss: 0.355919; batch adversarial loss: 0.572273\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354565; batch adversarial loss: 0.477974\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386359; batch adversarial loss: 0.524457\n",
      "epoch 170; iter: 0; batch classifier loss: 0.394766; batch adversarial loss: 0.508359\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334086; batch adversarial loss: 0.535450\n",
      "epoch 172; iter: 0; batch classifier loss: 0.452787; batch adversarial loss: 0.617262\n",
      "epoch 173; iter: 0; batch classifier loss: 0.399357; batch adversarial loss: 0.592960\n",
      "epoch 174; iter: 0; batch classifier loss: 0.342990; batch adversarial loss: 0.506268\n",
      "epoch 175; iter: 0; batch classifier loss: 0.370999; batch adversarial loss: 0.516342\n",
      "epoch 176; iter: 0; batch classifier loss: 0.327618; batch adversarial loss: 0.544240\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312500; batch adversarial loss: 0.554320\n",
      "epoch 178; iter: 0; batch classifier loss: 0.424152; batch adversarial loss: 0.611112\n",
      "epoch 179; iter: 0; batch classifier loss: 0.404668; batch adversarial loss: 0.506568\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360401; batch adversarial loss: 0.554895\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323472; batch adversarial loss: 0.515779\n",
      "epoch 182; iter: 0; batch classifier loss: 0.345843; batch adversarial loss: 0.563064\n",
      "epoch 183; iter: 0; batch classifier loss: 0.409831; batch adversarial loss: 0.543136\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413816; batch adversarial loss: 0.533264\n",
      "epoch 185; iter: 0; batch classifier loss: 0.345147; batch adversarial loss: 0.497422\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361248; batch adversarial loss: 0.565340\n",
      "epoch 187; iter: 0; batch classifier loss: 0.480172; batch adversarial loss: 0.573753\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396319; batch adversarial loss: 0.572545\n",
      "epoch 189; iter: 0; batch classifier loss: 0.440821; batch adversarial loss: 0.650057\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361254; batch adversarial loss: 0.544521\n",
      "epoch 191; iter: 0; batch classifier loss: 0.305288; batch adversarial loss: 0.525078\n",
      "epoch 192; iter: 0; batch classifier loss: 0.366203; batch adversarial loss: 0.496673\n",
      "epoch 193; iter: 0; batch classifier loss: 0.367874; batch adversarial loss: 0.458250\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376699; batch adversarial loss: 0.478314\n",
      "epoch 195; iter: 0; batch classifier loss: 0.355626; batch adversarial loss: 0.477455\n",
      "epoch 196; iter: 0; batch classifier loss: 0.396042; batch adversarial loss: 0.601800\n",
      "epoch 197; iter: 0; batch classifier loss: 0.427132; batch adversarial loss: 0.542771\n",
      "epoch 198; iter: 0; batch classifier loss: 0.432515; batch adversarial loss: 0.495458\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363350; batch adversarial loss: 0.518723\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673228; batch adversarial loss: 0.721725\n",
      "epoch 1; iter: 0; batch classifier loss: 0.636776; batch adversarial loss: 0.680743\n",
      "epoch 2; iter: 0; batch classifier loss: 0.549156; batch adversarial loss: 0.642879\n",
      "epoch 3; iter: 0; batch classifier loss: 0.549683; batch adversarial loss: 0.639688\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640763; batch adversarial loss: 0.634401\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549046; batch adversarial loss: 0.631088\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532768; batch adversarial loss: 0.653950\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493589; batch adversarial loss: 0.619245\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498028; batch adversarial loss: 0.573982\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602852; batch adversarial loss: 0.557432\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529669; batch adversarial loss: 0.616006\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470929; batch adversarial loss: 0.562066\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543598; batch adversarial loss: 0.557335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481733; batch adversarial loss: 0.589845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.515535; batch adversarial loss: 0.554688\n",
      "epoch 15; iter: 0; batch classifier loss: 0.412918; batch adversarial loss: 0.536452\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511554; batch adversarial loss: 0.593580\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383583; batch adversarial loss: 0.556488\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497957; batch adversarial loss: 0.509331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468895; batch adversarial loss: 0.573568\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474919; batch adversarial loss: 0.508873\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490440; batch adversarial loss: 0.528767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466073; batch adversarial loss: 0.571081\n",
      "epoch 23; iter: 0; batch classifier loss: 0.440244; batch adversarial loss: 0.559256\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478113; batch adversarial loss: 0.611085\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508341; batch adversarial loss: 0.599408\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452593; batch adversarial loss: 0.496016\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462919; batch adversarial loss: 0.609448\n",
      "epoch 28; iter: 0; batch classifier loss: 0.412646; batch adversarial loss: 0.531785\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483791; batch adversarial loss: 0.499885\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506244; batch adversarial loss: 0.551373\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485979; batch adversarial loss: 0.565275\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423852; batch adversarial loss: 0.586449\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460786; batch adversarial loss: 0.474353\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488524; batch adversarial loss: 0.530435\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436766; batch adversarial loss: 0.566014\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465651; batch adversarial loss: 0.563093\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476156; batch adversarial loss: 0.617772\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478380; batch adversarial loss: 0.437510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.456138; batch adversarial loss: 0.539939\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465009; batch adversarial loss: 0.463833\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452445; batch adversarial loss: 0.571676\n",
      "epoch 42; iter: 0; batch classifier loss: 0.510367; batch adversarial loss: 0.505128\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489695; batch adversarial loss: 0.454333\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464093; batch adversarial loss: 0.543545\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466570; batch adversarial loss: 0.498354\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508769; batch adversarial loss: 0.515496\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475886; batch adversarial loss: 0.517352\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450258; batch adversarial loss: 0.508766\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396025; batch adversarial loss: 0.525315\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424688; batch adversarial loss: 0.570340\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442957; batch adversarial loss: 0.658906\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410956; batch adversarial loss: 0.517198\n",
      "epoch 53; iter: 0; batch classifier loss: 0.350783; batch adversarial loss: 0.588951\n",
      "epoch 54; iter: 0; batch classifier loss: 0.484403; batch adversarial loss: 0.628318\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415604; batch adversarial loss: 0.543652\n",
      "epoch 56; iter: 0; batch classifier loss: 0.373643; batch adversarial loss: 0.573247\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471342; batch adversarial loss: 0.543677\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447723; batch adversarial loss: 0.499327\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442551; batch adversarial loss: 0.544283\n",
      "epoch 60; iter: 0; batch classifier loss: 0.485772; batch adversarial loss: 0.479326\n",
      "epoch 61; iter: 0; batch classifier loss: 0.365731; batch adversarial loss: 0.534896\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378880; batch adversarial loss: 0.515884\n",
      "epoch 63; iter: 0; batch classifier loss: 0.315658; batch adversarial loss: 0.460934\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427482; batch adversarial loss: 0.516596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402827; batch adversarial loss: 0.535695\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385084; batch adversarial loss: 0.572560\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388318; batch adversarial loss: 0.526200\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434445; batch adversarial loss: 0.506825\n",
      "epoch 69; iter: 0; batch classifier loss: 0.394908; batch adversarial loss: 0.609760\n",
      "epoch 70; iter: 0; batch classifier loss: 0.437715; batch adversarial loss: 0.506816\n",
      "epoch 71; iter: 0; batch classifier loss: 0.443741; batch adversarial loss: 0.591487\n",
      "epoch 72; iter: 0; batch classifier loss: 0.367611; batch adversarial loss: 0.526193\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380948; batch adversarial loss: 0.479338\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404394; batch adversarial loss: 0.563347\n",
      "epoch 75; iter: 0; batch classifier loss: 0.442343; batch adversarial loss: 0.469786\n",
      "epoch 76; iter: 0; batch classifier loss: 0.343330; batch adversarial loss: 0.563432\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417009; batch adversarial loss: 0.526033\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415511; batch adversarial loss: 0.571963\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405834; batch adversarial loss: 0.496817\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435869; batch adversarial loss: 0.534039\n",
      "epoch 81; iter: 0; batch classifier loss: 0.286737; batch adversarial loss: 0.515777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.474133; batch adversarial loss: 0.534804\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372987; batch adversarial loss: 0.563522\n",
      "epoch 84; iter: 0; batch classifier loss: 0.309678; batch adversarial loss: 0.553487\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364579; batch adversarial loss: 0.581554\n",
      "epoch 86; iter: 0; batch classifier loss: 0.311611; batch adversarial loss: 0.544327\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412212; batch adversarial loss: 0.460263\n",
      "epoch 88; iter: 0; batch classifier loss: 0.439781; batch adversarial loss: 0.516498\n",
      "epoch 89; iter: 0; batch classifier loss: 0.441661; batch adversarial loss: 0.563084\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351514; batch adversarial loss: 0.451047\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367776; batch adversarial loss: 0.562945\n",
      "epoch 92; iter: 0; batch classifier loss: 0.310145; batch adversarial loss: 0.516636\n",
      "epoch 93; iter: 0; batch classifier loss: 0.351932; batch adversarial loss: 0.525995\n",
      "epoch 94; iter: 0; batch classifier loss: 0.287350; batch adversarial loss: 0.451440\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382022; batch adversarial loss: 0.582207\n",
      "epoch 96; iter: 0; batch classifier loss: 0.316330; batch adversarial loss: 0.554329\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413210; batch adversarial loss: 0.534464\n",
      "epoch 98; iter: 0; batch classifier loss: 0.360684; batch adversarial loss: 0.554224\n",
      "epoch 99; iter: 0; batch classifier loss: 0.330335; batch adversarial loss: 0.525860\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360255; batch adversarial loss: 0.544532\n",
      "epoch 101; iter: 0; batch classifier loss: 0.427317; batch adversarial loss: 0.554166\n",
      "epoch 102; iter: 0; batch classifier loss: 0.335460; batch adversarial loss: 0.535128\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378131; batch adversarial loss: 0.535737\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428336; batch adversarial loss: 0.535204\n",
      "epoch 105; iter: 0; batch classifier loss: 0.445611; batch adversarial loss: 0.554194\n",
      "epoch 106; iter: 0; batch classifier loss: 0.405101; batch adversarial loss: 0.600785\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365308; batch adversarial loss: 0.553879\n",
      "epoch 108; iter: 0; batch classifier loss: 0.481346; batch adversarial loss: 0.525750\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379031; batch adversarial loss: 0.544499\n",
      "epoch 110; iter: 0; batch classifier loss: 0.318110; batch adversarial loss: 0.516566\n",
      "epoch 111; iter: 0; batch classifier loss: 0.422894; batch adversarial loss: 0.562893\n",
      "epoch 112; iter: 0; batch classifier loss: 0.432032; batch adversarial loss: 0.515583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.386913; batch adversarial loss: 0.591884\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422576; batch adversarial loss: 0.516598\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419611; batch adversarial loss: 0.533938\n",
      "epoch 116; iter: 0; batch classifier loss: 0.338944; batch adversarial loss: 0.562119\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340678; batch adversarial loss: 0.565286\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387008; batch adversarial loss: 0.540603\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370833; batch adversarial loss: 0.600369\n",
      "epoch 120; iter: 0; batch classifier loss: 0.385437; batch adversarial loss: 0.506107\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403174; batch adversarial loss: 0.583860\n",
      "epoch 122; iter: 0; batch classifier loss: 0.390606; batch adversarial loss: 0.603706\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348063; batch adversarial loss: 0.463551\n",
      "epoch 124; iter: 0; batch classifier loss: 0.351185; batch adversarial loss: 0.535675\n",
      "epoch 125; iter: 0; batch classifier loss: 0.313174; batch adversarial loss: 0.524642\n",
      "epoch 126; iter: 0; batch classifier loss: 0.319480; batch adversarial loss: 0.518749\n",
      "epoch 127; iter: 0; batch classifier loss: 0.313146; batch adversarial loss: 0.554034\n",
      "epoch 128; iter: 0; batch classifier loss: 0.323392; batch adversarial loss: 0.657973\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347072; batch adversarial loss: 0.543150\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387579; batch adversarial loss: 0.488498\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387395; batch adversarial loss: 0.610924\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396741; batch adversarial loss: 0.524732\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386095; batch adversarial loss: 0.498698\n",
      "epoch 134; iter: 0; batch classifier loss: 0.262164; batch adversarial loss: 0.573142\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378812; batch adversarial loss: 0.508614\n",
      "epoch 136; iter: 0; batch classifier loss: 0.345924; batch adversarial loss: 0.581477\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356025; batch adversarial loss: 0.645881\n",
      "epoch 138; iter: 0; batch classifier loss: 0.409910; batch adversarial loss: 0.525727\n",
      "epoch 139; iter: 0; batch classifier loss: 0.327524; batch adversarial loss: 0.432973\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361578; batch adversarial loss: 0.525908\n",
      "epoch 141; iter: 0; batch classifier loss: 0.304396; batch adversarial loss: 0.544826\n",
      "epoch 142; iter: 0; batch classifier loss: 0.411211; batch adversarial loss: 0.582971\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379271; batch adversarial loss: 0.582239\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331033; batch adversarial loss: 0.543795\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352617; batch adversarial loss: 0.543406\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367213; batch adversarial loss: 0.545192\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344734; batch adversarial loss: 0.591434\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349719; batch adversarial loss: 0.461143\n",
      "epoch 149; iter: 0; batch classifier loss: 0.406263; batch adversarial loss: 0.609066\n",
      "epoch 150; iter: 0; batch classifier loss: 0.366026; batch adversarial loss: 0.488765\n",
      "epoch 151; iter: 0; batch classifier loss: 0.319031; batch adversarial loss: 0.553767\n",
      "epoch 152; iter: 0; batch classifier loss: 0.420922; batch adversarial loss: 0.572464\n",
      "epoch 153; iter: 0; batch classifier loss: 0.331363; batch adversarial loss: 0.627562\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375726; batch adversarial loss: 0.552729\n",
      "epoch 155; iter: 0; batch classifier loss: 0.381503; batch adversarial loss: 0.563511\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359640; batch adversarial loss: 0.553567\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328615; batch adversarial loss: 0.507324\n",
      "epoch 158; iter: 0; batch classifier loss: 0.393495; batch adversarial loss: 0.489134\n",
      "epoch 159; iter: 0; batch classifier loss: 0.308414; batch adversarial loss: 0.554163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387013; batch adversarial loss: 0.554694\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361453; batch adversarial loss: 0.488986\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412947; batch adversarial loss: 0.553509\n",
      "epoch 163; iter: 0; batch classifier loss: 0.358555; batch adversarial loss: 0.526489\n",
      "epoch 164; iter: 0; batch classifier loss: 0.274135; batch adversarial loss: 0.506604\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318391; batch adversarial loss: 0.619442\n",
      "epoch 166; iter: 0; batch classifier loss: 0.293241; batch adversarial loss: 0.526125\n",
      "epoch 167; iter: 0; batch classifier loss: 0.406408; batch adversarial loss: 0.572807\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378484; batch adversarial loss: 0.431362\n",
      "epoch 169; iter: 0; batch classifier loss: 0.464679; batch adversarial loss: 0.553491\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342151; batch adversarial loss: 0.562485\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380727; batch adversarial loss: 0.545276\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378308; batch adversarial loss: 0.535250\n",
      "epoch 173; iter: 0; batch classifier loss: 0.458815; batch adversarial loss: 0.468919\n",
      "epoch 174; iter: 0; batch classifier loss: 0.367473; batch adversarial loss: 0.534883\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329312; batch adversarial loss: 0.545344\n",
      "epoch 176; iter: 0; batch classifier loss: 0.311400; batch adversarial loss: 0.573369\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389471; batch adversarial loss: 0.572125\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307048; batch adversarial loss: 0.535871\n",
      "epoch 179; iter: 0; batch classifier loss: 0.375454; batch adversarial loss: 0.460871\n",
      "epoch 180; iter: 0; batch classifier loss: 0.397077; batch adversarial loss: 0.554498\n",
      "epoch 181; iter: 0; batch classifier loss: 0.302420; batch adversarial loss: 0.553521\n",
      "epoch 182; iter: 0; batch classifier loss: 0.331930; batch adversarial loss: 0.535470\n",
      "epoch 183; iter: 0; batch classifier loss: 0.427336; batch adversarial loss: 0.591400\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379200; batch adversarial loss: 0.600929\n",
      "epoch 185; iter: 0; batch classifier loss: 0.396121; batch adversarial loss: 0.563087\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382267; batch adversarial loss: 0.526246\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358799; batch adversarial loss: 0.553633\n",
      "epoch 188; iter: 0; batch classifier loss: 0.339199; batch adversarial loss: 0.554524\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382348; batch adversarial loss: 0.619585\n",
      "epoch 190; iter: 0; batch classifier loss: 0.408006; batch adversarial loss: 0.469744\n",
      "epoch 191; iter: 0; batch classifier loss: 0.287804; batch adversarial loss: 0.516922\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340847; batch adversarial loss: 0.488118\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336258; batch adversarial loss: 0.460888\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358781; batch adversarial loss: 0.535126\n",
      "epoch 195; iter: 0; batch classifier loss: 0.417444; batch adversarial loss: 0.572771\n",
      "epoch 196; iter: 0; batch classifier loss: 0.289947; batch adversarial loss: 0.469515\n",
      "epoch 197; iter: 0; batch classifier loss: 0.307207; batch adversarial loss: 0.469375\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331391; batch adversarial loss: 0.442091\n",
      "epoch 199; iter: 0; batch classifier loss: 0.327746; batch adversarial loss: 0.506903\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657465; batch adversarial loss: 0.651385\n",
      "epoch 1; iter: 0; batch classifier loss: 0.549893; batch adversarial loss: 0.685494\n",
      "epoch 2; iter: 0; batch classifier loss: 0.559674; batch adversarial loss: 0.651732\n",
      "epoch 3; iter: 0; batch classifier loss: 0.564923; batch adversarial loss: 0.619522\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562362; batch adversarial loss: 0.654229\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586154; batch adversarial loss: 0.687422\n",
      "epoch 6; iter: 0; batch classifier loss: 0.656250; batch adversarial loss: 0.671070\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596143; batch adversarial loss: 0.652735\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613214; batch adversarial loss: 0.605418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.511334; batch adversarial loss: 0.587436\n",
      "epoch 10; iter: 0; batch classifier loss: 0.527000; batch adversarial loss: 0.581511\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498351; batch adversarial loss: 0.572950\n",
      "epoch 12; iter: 0; batch classifier loss: 0.615881; batch adversarial loss: 0.563948\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554094; batch adversarial loss: 0.589752\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528190; batch adversarial loss: 0.579586\n",
      "epoch 15; iter: 0; batch classifier loss: 0.567986; batch adversarial loss: 0.609779\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534073; batch adversarial loss: 0.589646\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533087; batch adversarial loss: 0.555172\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487818; batch adversarial loss: 0.565863\n",
      "epoch 19; iter: 0; batch classifier loss: 0.549913; batch adversarial loss: 0.513384\n",
      "epoch 20; iter: 0; batch classifier loss: 0.563242; batch adversarial loss: 0.570779\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520023; batch adversarial loss: 0.594818\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522376; batch adversarial loss: 0.578848\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497380; batch adversarial loss: 0.587283\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476647; batch adversarial loss: 0.544843\n",
      "epoch 25; iter: 0; batch classifier loss: 0.475166; batch adversarial loss: 0.528308\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446550; batch adversarial loss: 0.510264\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479274; batch adversarial loss: 0.549439\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512004; batch adversarial loss: 0.553635\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438164; batch adversarial loss: 0.625014\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533958; batch adversarial loss: 0.509685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.518062; batch adversarial loss: 0.607569\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493170; batch adversarial loss: 0.535360\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465586; batch adversarial loss: 0.465546\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509130; batch adversarial loss: 0.608446\n",
      "epoch 35; iter: 0; batch classifier loss: 0.494527; batch adversarial loss: 0.604525\n",
      "epoch 36; iter: 0; batch classifier loss: 0.373235; batch adversarial loss: 0.524467\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420332; batch adversarial loss: 0.485266\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432895; batch adversarial loss: 0.504774\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468939; batch adversarial loss: 0.522467\n",
      "epoch 40; iter: 0; batch classifier loss: 0.487360; batch adversarial loss: 0.476317\n",
      "epoch 41; iter: 0; batch classifier loss: 0.393746; batch adversarial loss: 0.552870\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400654; batch adversarial loss: 0.565315\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407400; batch adversarial loss: 0.539420\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421336; batch adversarial loss: 0.561753\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428154; batch adversarial loss: 0.554925\n",
      "epoch 46; iter: 0; batch classifier loss: 0.526703; batch adversarial loss: 0.499930\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399806; batch adversarial loss: 0.589365\n",
      "epoch 48; iter: 0; batch classifier loss: 0.475993; batch adversarial loss: 0.544180\n",
      "epoch 49; iter: 0; batch classifier loss: 0.485127; batch adversarial loss: 0.545727\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400970; batch adversarial loss: 0.571897\n",
      "epoch 51; iter: 0; batch classifier loss: 0.541396; batch adversarial loss: 0.525937\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398609; batch adversarial loss: 0.543673\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439790; batch adversarial loss: 0.552202\n",
      "epoch 54; iter: 0; batch classifier loss: 0.375212; batch adversarial loss: 0.572657\n",
      "epoch 55; iter: 0; batch classifier loss: 0.463153; batch adversarial loss: 0.479822\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426484; batch adversarial loss: 0.524882\n",
      "epoch 57; iter: 0; batch classifier loss: 0.451749; batch adversarial loss: 0.525615\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426631; batch adversarial loss: 0.497840\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431124; batch adversarial loss: 0.514702\n",
      "epoch 60; iter: 0; batch classifier loss: 0.417913; batch adversarial loss: 0.515126\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373093; batch adversarial loss: 0.506009\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424573; batch adversarial loss: 0.506250\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379011; batch adversarial loss: 0.616967\n",
      "epoch 64; iter: 0; batch classifier loss: 0.360945; batch adversarial loss: 0.561981\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430063; batch adversarial loss: 0.573003\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403837; batch adversarial loss: 0.472061\n",
      "epoch 67; iter: 0; batch classifier loss: 0.466538; batch adversarial loss: 0.590117\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394840; batch adversarial loss: 0.553425\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436520; batch adversarial loss: 0.525015\n",
      "epoch 70; iter: 0; batch classifier loss: 0.478249; batch adversarial loss: 0.553070\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358457; batch adversarial loss: 0.507682\n",
      "epoch 72; iter: 0; batch classifier loss: 0.489952; batch adversarial loss: 0.516193\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366161; batch adversarial loss: 0.506432\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381380; batch adversarial loss: 0.599540\n",
      "epoch 75; iter: 0; batch classifier loss: 0.323308; batch adversarial loss: 0.628072\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382876; batch adversarial loss: 0.470171\n",
      "epoch 77; iter: 0; batch classifier loss: 0.403371; batch adversarial loss: 0.626063\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421547; batch adversarial loss: 0.479546\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404358; batch adversarial loss: 0.491402\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421930; batch adversarial loss: 0.562414\n",
      "epoch 81; iter: 0; batch classifier loss: 0.487273; batch adversarial loss: 0.478809\n",
      "epoch 82; iter: 0; batch classifier loss: 0.362215; batch adversarial loss: 0.515646\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385679; batch adversarial loss: 0.631053\n",
      "epoch 84; iter: 0; batch classifier loss: 0.348480; batch adversarial loss: 0.591894\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373942; batch adversarial loss: 0.609516\n",
      "epoch 86; iter: 0; batch classifier loss: 0.385598; batch adversarial loss: 0.463946\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352092; batch adversarial loss: 0.508649\n",
      "epoch 88; iter: 0; batch classifier loss: 0.431332; batch adversarial loss: 0.536130\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395594; batch adversarial loss: 0.607997\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456714; batch adversarial loss: 0.517633\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382578; batch adversarial loss: 0.562386\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398119; batch adversarial loss: 0.643755\n",
      "epoch 93; iter: 0; batch classifier loss: 0.345105; batch adversarial loss: 0.580899\n",
      "epoch 94; iter: 0; batch classifier loss: 0.492026; batch adversarial loss: 0.562733\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413539; batch adversarial loss: 0.525956\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355320; batch adversarial loss: 0.589367\n",
      "epoch 97; iter: 0; batch classifier loss: 0.349895; batch adversarial loss: 0.597096\n",
      "epoch 98; iter: 0; batch classifier loss: 0.344041; batch adversarial loss: 0.589423\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416122; batch adversarial loss: 0.516836\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388781; batch adversarial loss: 0.504653\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413239; batch adversarial loss: 0.697190\n",
      "epoch 102; iter: 0; batch classifier loss: 0.424110; batch adversarial loss: 0.591443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.329983; batch adversarial loss: 0.598326\n",
      "epoch 104; iter: 0; batch classifier loss: 0.427448; batch adversarial loss: 0.570956\n",
      "epoch 105; iter: 0; batch classifier loss: 0.456235; batch adversarial loss: 0.489130\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365492; batch adversarial loss: 0.685860\n",
      "epoch 107; iter: 0; batch classifier loss: 0.411630; batch adversarial loss: 0.608769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.431157; batch adversarial loss: 0.636041\n",
      "epoch 109; iter: 0; batch classifier loss: 0.438749; batch adversarial loss: 0.536613\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348218; batch adversarial loss: 0.537322\n",
      "epoch 111; iter: 0; batch classifier loss: 0.420251; batch adversarial loss: 0.534436\n",
      "epoch 112; iter: 0; batch classifier loss: 0.459111; batch adversarial loss: 0.483061\n",
      "epoch 113; iter: 0; batch classifier loss: 0.420421; batch adversarial loss: 0.469194\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392075; batch adversarial loss: 0.526958\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411575; batch adversarial loss: 0.498623\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328367; batch adversarial loss: 0.496858\n",
      "epoch 117; iter: 0; batch classifier loss: 0.429532; batch adversarial loss: 0.581452\n",
      "epoch 118; iter: 0; batch classifier loss: 0.452916; batch adversarial loss: 0.469431\n",
      "epoch 119; iter: 0; batch classifier loss: 0.346948; batch adversarial loss: 0.526230\n",
      "epoch 120; iter: 0; batch classifier loss: 0.384435; batch adversarial loss: 0.543551\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382303; batch adversarial loss: 0.546145\n",
      "epoch 122; iter: 0; batch classifier loss: 0.341844; batch adversarial loss: 0.516873\n",
      "epoch 123; iter: 0; batch classifier loss: 0.347124; batch adversarial loss: 0.563631\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329619; batch adversarial loss: 0.625597\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362644; batch adversarial loss: 0.481213\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386662; batch adversarial loss: 0.542075\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366630; batch adversarial loss: 0.563320\n",
      "epoch 128; iter: 0; batch classifier loss: 0.358088; batch adversarial loss: 0.599098\n",
      "epoch 129; iter: 0; batch classifier loss: 0.420861; batch adversarial loss: 0.543925\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370507; batch adversarial loss: 0.536953\n",
      "epoch 131; iter: 0; batch classifier loss: 0.434485; batch adversarial loss: 0.617719\n",
      "epoch 132; iter: 0; batch classifier loss: 0.418046; batch adversarial loss: 0.544746\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356802; batch adversarial loss: 0.535773\n",
      "epoch 134; iter: 0; batch classifier loss: 0.359949; batch adversarial loss: 0.516271\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341353; batch adversarial loss: 0.552436\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332650; batch adversarial loss: 0.543721\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402689; batch adversarial loss: 0.490948\n",
      "epoch 138; iter: 0; batch classifier loss: 0.310683; batch adversarial loss: 0.564266\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357604; batch adversarial loss: 0.562994\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373419; batch adversarial loss: 0.517447\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357887; batch adversarial loss: 0.508789\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368864; batch adversarial loss: 0.536194\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355636; batch adversarial loss: 0.544228\n",
      "epoch 144; iter: 0; batch classifier loss: 0.267718; batch adversarial loss: 0.563445\n",
      "epoch 145; iter: 0; batch classifier loss: 0.432260; batch adversarial loss: 0.616391\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352002; batch adversarial loss: 0.462435\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358356; batch adversarial loss: 0.487804\n",
      "epoch 148; iter: 0; batch classifier loss: 0.431164; batch adversarial loss: 0.553550\n",
      "epoch 149; iter: 0; batch classifier loss: 0.381956; batch adversarial loss: 0.510359\n",
      "epoch 150; iter: 0; batch classifier loss: 0.443086; batch adversarial loss: 0.553986\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368466; batch adversarial loss: 0.505976\n",
      "epoch 152; iter: 0; batch classifier loss: 0.428538; batch adversarial loss: 0.610294\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367834; batch adversarial loss: 0.488560\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321324; batch adversarial loss: 0.526956\n",
      "epoch 155; iter: 0; batch classifier loss: 0.368507; batch adversarial loss: 0.490133\n",
      "epoch 156; iter: 0; batch classifier loss: 0.369046; batch adversarial loss: 0.534964\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416186; batch adversarial loss: 0.562878\n",
      "epoch 158; iter: 0; batch classifier loss: 0.314561; batch adversarial loss: 0.488937\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342674; batch adversarial loss: 0.509207\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358800; batch adversarial loss: 0.508637\n",
      "epoch 161; iter: 0; batch classifier loss: 0.420952; batch adversarial loss: 0.552578\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366849; batch adversarial loss: 0.516955\n",
      "epoch 163; iter: 0; batch classifier loss: 0.378787; batch adversarial loss: 0.507991\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409497; batch adversarial loss: 0.516731\n",
      "epoch 165; iter: 0; batch classifier loss: 0.304837; batch adversarial loss: 0.626988\n",
      "epoch 166; iter: 0; batch classifier loss: 0.422005; batch adversarial loss: 0.516906\n",
      "epoch 167; iter: 0; batch classifier loss: 0.388762; batch adversarial loss: 0.463596\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372207; batch adversarial loss: 0.608488\n",
      "epoch 169; iter: 0; batch classifier loss: 0.439349; batch adversarial loss: 0.508278\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363943; batch adversarial loss: 0.563388\n",
      "epoch 171; iter: 0; batch classifier loss: 0.418240; batch adversarial loss: 0.489435\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395196; batch adversarial loss: 0.545248\n",
      "epoch 173; iter: 0; batch classifier loss: 0.405111; batch adversarial loss: 0.563258\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372773; batch adversarial loss: 0.536278\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331197; batch adversarial loss: 0.617957\n",
      "epoch 176; iter: 0; batch classifier loss: 0.355085; batch adversarial loss: 0.571469\n",
      "epoch 177; iter: 0; batch classifier loss: 0.481330; batch adversarial loss: 0.571036\n",
      "epoch 178; iter: 0; batch classifier loss: 0.405222; batch adversarial loss: 0.598847\n",
      "epoch 179; iter: 0; batch classifier loss: 0.417787; batch adversarial loss: 0.498623\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331863; batch adversarial loss: 0.610293\n",
      "epoch 181; iter: 0; batch classifier loss: 0.393289; batch adversarial loss: 0.651910\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404616; batch adversarial loss: 0.616061\n",
      "epoch 183; iter: 0; batch classifier loss: 0.329709; batch adversarial loss: 0.562654\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397140; batch adversarial loss: 0.571943\n",
      "epoch 185; iter: 0; batch classifier loss: 0.350433; batch adversarial loss: 0.525974\n",
      "epoch 186; iter: 0; batch classifier loss: 0.391987; batch adversarial loss: 0.499763\n",
      "epoch 187; iter: 0; batch classifier loss: 0.383547; batch adversarial loss: 0.489684\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375606; batch adversarial loss: 0.497889\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369320; batch adversarial loss: 0.544794\n",
      "epoch 190; iter: 0; batch classifier loss: 0.420294; batch adversarial loss: 0.526203\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337791; batch adversarial loss: 0.480406\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315340; batch adversarial loss: 0.544224\n",
      "epoch 193; iter: 0; batch classifier loss: 0.445982; batch adversarial loss: 0.553623\n",
      "epoch 194; iter: 0; batch classifier loss: 0.529554; batch adversarial loss: 0.544274\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398781; batch adversarial loss: 0.507770\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345430; batch adversarial loss: 0.600065\n",
      "epoch 197; iter: 0; batch classifier loss: 0.304101; batch adversarial loss: 0.543898\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341810; batch adversarial loss: 0.543041\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380420; batch adversarial loss: 0.525520\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716787; batch adversarial loss: 0.626125\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592157; batch adversarial loss: 0.660979\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605310; batch adversarial loss: 0.669480\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623112; batch adversarial loss: 0.607001\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606440; batch adversarial loss: 0.632761\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489813; batch adversarial loss: 0.626526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.620634; batch adversarial loss: 0.580148\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499037; batch adversarial loss: 0.593859\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574441; batch adversarial loss: 0.572828\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567784; batch adversarial loss: 0.596593\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526354; batch adversarial loss: 0.486680\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493361; batch adversarial loss: 0.542377\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557172; batch adversarial loss: 0.586708\n",
      "epoch 13; iter: 0; batch classifier loss: 0.595517; batch adversarial loss: 0.519423\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489561; batch adversarial loss: 0.564723\n",
      "epoch 15; iter: 0; batch classifier loss: 0.479493; batch adversarial loss: 0.575228\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497197; batch adversarial loss: 0.484283\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499183; batch adversarial loss: 0.578213\n",
      "epoch 18; iter: 0; batch classifier loss: 0.392549; batch adversarial loss: 0.578755\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505555; batch adversarial loss: 0.650700\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517226; batch adversarial loss: 0.531276\n",
      "epoch 21; iter: 0; batch classifier loss: 0.432432; batch adversarial loss: 0.554255\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490595; batch adversarial loss: 0.561007\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480583; batch adversarial loss: 0.494397\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488169; batch adversarial loss: 0.536379\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478730; batch adversarial loss: 0.568042\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473134; batch adversarial loss: 0.581573\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450165; batch adversarial loss: 0.531482\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492603; batch adversarial loss: 0.615623\n",
      "epoch 29; iter: 0; batch classifier loss: 0.491165; batch adversarial loss: 0.527367\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463809; batch adversarial loss: 0.525104\n",
      "epoch 31; iter: 0; batch classifier loss: 0.546900; batch adversarial loss: 0.515391\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458375; batch adversarial loss: 0.565014\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400696; batch adversarial loss: 0.583319\n",
      "epoch 34; iter: 0; batch classifier loss: 0.489590; batch adversarial loss: 0.610511\n",
      "epoch 35; iter: 0; batch classifier loss: 0.399772; batch adversarial loss: 0.509432\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444699; batch adversarial loss: 0.444259\n",
      "epoch 37; iter: 0; batch classifier loss: 0.433726; batch adversarial loss: 0.563110\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483690; batch adversarial loss: 0.452232\n",
      "epoch 39; iter: 0; batch classifier loss: 0.542210; batch adversarial loss: 0.535895\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477458; batch adversarial loss: 0.553381\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467845; batch adversarial loss: 0.581542\n",
      "epoch 42; iter: 0; batch classifier loss: 0.412563; batch adversarial loss: 0.554449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.500106; batch adversarial loss: 0.516925\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447603; batch adversarial loss: 0.573131\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411530; batch adversarial loss: 0.609967\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408059; batch adversarial loss: 0.497262\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452608; batch adversarial loss: 0.515684\n",
      "epoch 48; iter: 0; batch classifier loss: 0.318157; batch adversarial loss: 0.504984\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477000; batch adversarial loss: 0.534095\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429066; batch adversarial loss: 0.536815\n",
      "epoch 51; iter: 0; batch classifier loss: 0.342721; batch adversarial loss: 0.535710\n",
      "epoch 52; iter: 0; batch classifier loss: 0.350650; batch adversarial loss: 0.460870\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390797; batch adversarial loss: 0.498545\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384565; batch adversarial loss: 0.544507\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419251; batch adversarial loss: 0.571813\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417207; batch adversarial loss: 0.534882\n",
      "epoch 57; iter: 0; batch classifier loss: 0.372290; batch adversarial loss: 0.480464\n",
      "epoch 58; iter: 0; batch classifier loss: 0.289676; batch adversarial loss: 0.580684\n",
      "epoch 59; iter: 0; batch classifier loss: 0.364327; batch adversarial loss: 0.512286\n",
      "epoch 60; iter: 0; batch classifier loss: 0.462027; batch adversarial loss: 0.639985\n",
      "epoch 61; iter: 0; batch classifier loss: 0.474400; batch adversarial loss: 0.580634\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439178; batch adversarial loss: 0.505235\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383692; batch adversarial loss: 0.608006\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427291; batch adversarial loss: 0.537621\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438910; batch adversarial loss: 0.554348\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418206; batch adversarial loss: 0.603401\n",
      "epoch 67; iter: 0; batch classifier loss: 0.378086; batch adversarial loss: 0.571315\n",
      "epoch 68; iter: 0; batch classifier loss: 0.385548; batch adversarial loss: 0.541506\n",
      "epoch 69; iter: 0; batch classifier loss: 0.367600; batch adversarial loss: 0.517417\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369002; batch adversarial loss: 0.571915\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412402; batch adversarial loss: 0.553359\n",
      "epoch 72; iter: 0; batch classifier loss: 0.454005; batch adversarial loss: 0.526377\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404037; batch adversarial loss: 0.492990\n",
      "epoch 74; iter: 0; batch classifier loss: 0.398842; batch adversarial loss: 0.573218\n",
      "epoch 75; iter: 0; batch classifier loss: 0.414162; batch adversarial loss: 0.500146\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387399; batch adversarial loss: 0.525893\n",
      "epoch 77; iter: 0; batch classifier loss: 0.357412; batch adversarial loss: 0.564342\n",
      "epoch 78; iter: 0; batch classifier loss: 0.408437; batch adversarial loss: 0.586629\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424203; batch adversarial loss: 0.527135\n",
      "epoch 80; iter: 0; batch classifier loss: 0.482785; batch adversarial loss: 0.555221\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430884; batch adversarial loss: 0.563622\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408690; batch adversarial loss: 0.554156\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369866; batch adversarial loss: 0.506525\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360786; batch adversarial loss: 0.515632\n",
      "epoch 85; iter: 0; batch classifier loss: 0.334677; batch adversarial loss: 0.468786\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418604; batch adversarial loss: 0.535628\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387679; batch adversarial loss: 0.543037\n",
      "epoch 88; iter: 0; batch classifier loss: 0.380730; batch adversarial loss: 0.478337\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405212; batch adversarial loss: 0.497350\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363297; batch adversarial loss: 0.515269\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423878; batch adversarial loss: 0.562034\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411893; batch adversarial loss: 0.525941\n",
      "epoch 93; iter: 0; batch classifier loss: 0.466794; batch adversarial loss: 0.579192\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435712; batch adversarial loss: 0.544264\n",
      "epoch 95; iter: 0; batch classifier loss: 0.327649; batch adversarial loss: 0.555711\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350997; batch adversarial loss: 0.552624\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400546; batch adversarial loss: 0.525034\n",
      "epoch 98; iter: 0; batch classifier loss: 0.429333; batch adversarial loss: 0.441086\n",
      "epoch 99; iter: 0; batch classifier loss: 0.331236; batch adversarial loss: 0.458901\n",
      "epoch 100; iter: 0; batch classifier loss: 0.419222; batch adversarial loss: 0.551986\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366548; batch adversarial loss: 0.554389\n",
      "epoch 102; iter: 0; batch classifier loss: 0.384118; batch adversarial loss: 0.582328\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395637; batch adversarial loss: 0.478869\n",
      "epoch 104; iter: 0; batch classifier loss: 0.340237; batch adversarial loss: 0.515177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.323563; batch adversarial loss: 0.458264\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367770; batch adversarial loss: 0.450547\n",
      "epoch 107; iter: 0; batch classifier loss: 0.398345; batch adversarial loss: 0.525774\n",
      "epoch 108; iter: 0; batch classifier loss: 0.374138; batch adversarial loss: 0.562649\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419583; batch adversarial loss: 0.575365\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414128; batch adversarial loss: 0.641125\n",
      "epoch 111; iter: 0; batch classifier loss: 0.478221; batch adversarial loss: 0.583931\n",
      "epoch 112; iter: 0; batch classifier loss: 0.344876; batch adversarial loss: 0.572799\n",
      "epoch 113; iter: 0; batch classifier loss: 0.452906; batch adversarial loss: 0.516105\n",
      "epoch 114; iter: 0; batch classifier loss: 0.331057; batch adversarial loss: 0.581421\n",
      "epoch 115; iter: 0; batch classifier loss: 0.300569; batch adversarial loss: 0.524860\n",
      "epoch 116; iter: 0; batch classifier loss: 0.302095; batch adversarial loss: 0.477674\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376148; batch adversarial loss: 0.487708\n",
      "epoch 118; iter: 0; batch classifier loss: 0.426823; batch adversarial loss: 0.496915\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383362; batch adversarial loss: 0.468541\n",
      "epoch 120; iter: 0; batch classifier loss: 0.294214; batch adversarial loss: 0.563447\n",
      "epoch 121; iter: 0; batch classifier loss: 0.477665; batch adversarial loss: 0.572860\n",
      "epoch 122; iter: 0; batch classifier loss: 0.340256; batch adversarial loss: 0.524963\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349148; batch adversarial loss: 0.620171\n",
      "epoch 124; iter: 0; batch classifier loss: 0.305699; batch adversarial loss: 0.609946\n",
      "epoch 125; iter: 0; batch classifier loss: 0.363660; batch adversarial loss: 0.647333\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358798; batch adversarial loss: 0.666478\n",
      "epoch 127; iter: 0; batch classifier loss: 0.418799; batch adversarial loss: 0.616144\n",
      "epoch 128; iter: 0; batch classifier loss: 0.462348; batch adversarial loss: 0.517772\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343440; batch adversarial loss: 0.564173\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390851; batch adversarial loss: 0.545196\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382886; batch adversarial loss: 0.554251\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390303; batch adversarial loss: 0.477942\n",
      "epoch 133; iter: 0; batch classifier loss: 0.404289; batch adversarial loss: 0.543541\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372504; batch adversarial loss: 0.621368\n",
      "epoch 135; iter: 0; batch classifier loss: 0.313710; batch adversarial loss: 0.524730\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363436; batch adversarial loss: 0.534195\n",
      "epoch 137; iter: 0; batch classifier loss: 0.303590; batch adversarial loss: 0.525217\n",
      "epoch 138; iter: 0; batch classifier loss: 0.329934; batch adversarial loss: 0.642099\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395199; batch adversarial loss: 0.534992\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393709; batch adversarial loss: 0.497923\n",
      "epoch 141; iter: 0; batch classifier loss: 0.335274; batch adversarial loss: 0.593954\n",
      "epoch 142; iter: 0; batch classifier loss: 0.404070; batch adversarial loss: 0.582823\n",
      "epoch 143; iter: 0; batch classifier loss: 0.332429; batch adversarial loss: 0.658083\n",
      "epoch 144; iter: 0; batch classifier loss: 0.393593; batch adversarial loss: 0.573271\n",
      "epoch 145; iter: 0; batch classifier loss: 0.400300; batch adversarial loss: 0.619640\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410023; batch adversarial loss: 0.470093\n",
      "epoch 147; iter: 0; batch classifier loss: 0.305881; batch adversarial loss: 0.554252\n",
      "epoch 148; iter: 0; batch classifier loss: 0.481099; batch adversarial loss: 0.580607\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374144; batch adversarial loss: 0.506710\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381185; batch adversarial loss: 0.554877\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422640; batch adversarial loss: 0.518808\n",
      "epoch 152; iter: 0; batch classifier loss: 0.274766; batch adversarial loss: 0.600402\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365506; batch adversarial loss: 0.535943\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350524; batch adversarial loss: 0.497246\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342360; batch adversarial loss: 0.582540\n",
      "epoch 156; iter: 0; batch classifier loss: 0.365779; batch adversarial loss: 0.486743\n",
      "epoch 157; iter: 0; batch classifier loss: 0.424996; batch adversarial loss: 0.525691\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315255; batch adversarial loss: 0.571398\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367909; batch adversarial loss: 0.504946\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348112; batch adversarial loss: 0.449551\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380138; batch adversarial loss: 0.477516\n",
      "epoch 162; iter: 0; batch classifier loss: 0.282266; batch adversarial loss: 0.572997\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392414; batch adversarial loss: 0.477697\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387445; batch adversarial loss: 0.496127\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326481; batch adversarial loss: 0.630600\n",
      "epoch 166; iter: 0; batch classifier loss: 0.397154; batch adversarial loss: 0.506241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363792; batch adversarial loss: 0.506537\n",
      "epoch 168; iter: 0; batch classifier loss: 0.400893; batch adversarial loss: 0.516671\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312801; batch adversarial loss: 0.553708\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359704; batch adversarial loss: 0.515785\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359549; batch adversarial loss: 0.554301\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366527; batch adversarial loss: 0.564014\n",
      "epoch 173; iter: 0; batch classifier loss: 0.310604; batch adversarial loss: 0.535700\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363361; batch adversarial loss: 0.582932\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349525; batch adversarial loss: 0.564035\n",
      "epoch 176; iter: 0; batch classifier loss: 0.440476; batch adversarial loss: 0.534604\n",
      "epoch 177; iter: 0; batch classifier loss: 0.299411; batch adversarial loss: 0.524526\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391504; batch adversarial loss: 0.554218\n",
      "epoch 179; iter: 0; batch classifier loss: 0.324702; batch adversarial loss: 0.525584\n",
      "epoch 180; iter: 0; batch classifier loss: 0.292335; batch adversarial loss: 0.477975\n",
      "epoch 181; iter: 0; batch classifier loss: 0.294757; batch adversarial loss: 0.601571\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379853; batch adversarial loss: 0.583115\n",
      "epoch 183; iter: 0; batch classifier loss: 0.334644; batch adversarial loss: 0.554091\n",
      "epoch 184; iter: 0; batch classifier loss: 0.438134; batch adversarial loss: 0.525075\n",
      "epoch 185; iter: 0; batch classifier loss: 0.375904; batch adversarial loss: 0.582270\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312593; batch adversarial loss: 0.573753\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327556; batch adversarial loss: 0.535302\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381343; batch adversarial loss: 0.487827\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395955; batch adversarial loss: 0.525564\n",
      "epoch 190; iter: 0; batch classifier loss: 0.278016; batch adversarial loss: 0.553705\n",
      "epoch 191; iter: 0; batch classifier loss: 0.278447; batch adversarial loss: 0.581971\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375814; batch adversarial loss: 0.554338\n",
      "epoch 193; iter: 0; batch classifier loss: 0.424757; batch adversarial loss: 0.582460\n",
      "epoch 194; iter: 0; batch classifier loss: 0.333932; batch adversarial loss: 0.496879\n",
      "epoch 195; iter: 0; batch classifier loss: 0.286824; batch adversarial loss: 0.555055\n",
      "epoch 196; iter: 0; batch classifier loss: 0.279787; batch adversarial loss: 0.525952\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323834; batch adversarial loss: 0.506423\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335471; batch adversarial loss: 0.478432\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331186; batch adversarial loss: 0.563270\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711947; batch adversarial loss: 0.987681\n",
      "epoch 1; iter: 0; batch classifier loss: 0.844601; batch adversarial loss: 1.076461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.975946; batch adversarial loss: 1.046149\n",
      "epoch 3; iter: 0; batch classifier loss: 1.142462; batch adversarial loss: 0.971817\n",
      "epoch 4; iter: 0; batch classifier loss: 1.031349; batch adversarial loss: 0.892675\n",
      "epoch 5; iter: 0; batch classifier loss: 1.167681; batch adversarial loss: 0.823173\n",
      "epoch 6; iter: 0; batch classifier loss: 1.024937; batch adversarial loss: 0.760498\n",
      "epoch 7; iter: 0; batch classifier loss: 0.944715; batch adversarial loss: 0.734201\n",
      "epoch 8; iter: 0; batch classifier loss: 0.922037; batch adversarial loss: 0.681694\n",
      "epoch 9; iter: 0; batch classifier loss: 0.999069; batch adversarial loss: 0.599189\n",
      "epoch 10; iter: 0; batch classifier loss: 0.777267; batch adversarial loss: 0.586684\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588362; batch adversarial loss: 0.575393\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590742; batch adversarial loss: 0.581741\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599334; batch adversarial loss: 0.546495\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461293; batch adversarial loss: 0.563178\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539972; batch adversarial loss: 0.590318\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494496; batch adversarial loss: 0.609449\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546968; batch adversarial loss: 0.579684\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505653; batch adversarial loss: 0.539209\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528084; batch adversarial loss: 0.530774\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477075; batch adversarial loss: 0.564278\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477260; batch adversarial loss: 0.538465\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495807; batch adversarial loss: 0.588013\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521482; batch adversarial loss: 0.580800\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547131; batch adversarial loss: 0.565648\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429943; batch adversarial loss: 0.564073\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473756; batch adversarial loss: 0.538127\n",
      "epoch 27; iter: 0; batch classifier loss: 0.547814; batch adversarial loss: 0.513066\n",
      "epoch 28; iter: 0; batch classifier loss: 0.444063; batch adversarial loss: 0.523010\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431190; batch adversarial loss: 0.529497\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480929; batch adversarial loss: 0.499677\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440580; batch adversarial loss: 0.532551\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461713; batch adversarial loss: 0.606706\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468219; batch adversarial loss: 0.617285\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485652; batch adversarial loss: 0.527319\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444112; batch adversarial loss: 0.585223\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474352; batch adversarial loss: 0.502178\n",
      "epoch 37; iter: 0; batch classifier loss: 0.507270; batch adversarial loss: 0.511752\n",
      "epoch 38; iter: 0; batch classifier loss: 0.532179; batch adversarial loss: 0.518611\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392933; batch adversarial loss: 0.530576\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426263; batch adversarial loss: 0.586953\n",
      "epoch 41; iter: 0; batch classifier loss: 0.384315; batch adversarial loss: 0.527055\n",
      "epoch 42; iter: 0; batch classifier loss: 0.345270; batch adversarial loss: 0.519488\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390975; batch adversarial loss: 0.560590\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436623; batch adversarial loss: 0.632130\n",
      "epoch 45; iter: 0; batch classifier loss: 0.510329; batch adversarial loss: 0.570642\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433855; batch adversarial loss: 0.551973\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409553; batch adversarial loss: 0.545826\n",
      "epoch 48; iter: 0; batch classifier loss: 0.357474; batch adversarial loss: 0.597629\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437221; batch adversarial loss: 0.524533\n",
      "epoch 50; iter: 0; batch classifier loss: 0.481444; batch adversarial loss: 0.516950\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465884; batch adversarial loss: 0.520079\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400419; batch adversarial loss: 0.490892\n",
      "epoch 53; iter: 0; batch classifier loss: 0.457703; batch adversarial loss: 0.555834\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463856; batch adversarial loss: 0.542308\n",
      "epoch 55; iter: 0; batch classifier loss: 0.372872; batch adversarial loss: 0.500444\n",
      "epoch 56; iter: 0; batch classifier loss: 0.366126; batch adversarial loss: 0.474147\n",
      "epoch 57; iter: 0; batch classifier loss: 0.455699; batch adversarial loss: 0.539839\n",
      "epoch 58; iter: 0; batch classifier loss: 0.454022; batch adversarial loss: 0.492384\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417108; batch adversarial loss: 0.498060\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393909; batch adversarial loss: 0.597735\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442594; batch adversarial loss: 0.572123\n",
      "epoch 62; iter: 0; batch classifier loss: 0.337756; batch adversarial loss: 0.647250\n",
      "epoch 63; iter: 0; batch classifier loss: 0.496376; batch adversarial loss: 0.578517\n",
      "epoch 64; iter: 0; batch classifier loss: 0.391261; batch adversarial loss: 0.534079\n",
      "epoch 65; iter: 0; batch classifier loss: 0.422827; batch adversarial loss: 0.546543\n",
      "epoch 66; iter: 0; batch classifier loss: 0.352053; batch adversarial loss: 0.488013\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447279; batch adversarial loss: 0.587376\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402525; batch adversarial loss: 0.526163\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420650; batch adversarial loss: 0.533190\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392045; batch adversarial loss: 0.543901\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416133; batch adversarial loss: 0.580846\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435456; batch adversarial loss: 0.517377\n",
      "epoch 73; iter: 0; batch classifier loss: 0.462045; batch adversarial loss: 0.573744\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424229; batch adversarial loss: 0.563251\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364388; batch adversarial loss: 0.552920\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391583; batch adversarial loss: 0.527066\n",
      "epoch 77; iter: 0; batch classifier loss: 0.432597; batch adversarial loss: 0.471586\n",
      "epoch 78; iter: 0; batch classifier loss: 0.410910; batch adversarial loss: 0.572978\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407767; batch adversarial loss: 0.534218\n",
      "epoch 80; iter: 0; batch classifier loss: 0.382101; batch adversarial loss: 0.545884\n",
      "epoch 81; iter: 0; batch classifier loss: 0.454523; batch adversarial loss: 0.598729\n",
      "epoch 82; iter: 0; batch classifier loss: 0.392947; batch adversarial loss: 0.505713\n",
      "epoch 83; iter: 0; batch classifier loss: 0.437270; batch adversarial loss: 0.541383\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362892; batch adversarial loss: 0.593235\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363792; batch adversarial loss: 0.536554\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418402; batch adversarial loss: 0.524540\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372672; batch adversarial loss: 0.506291\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392593; batch adversarial loss: 0.526781\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412647; batch adversarial loss: 0.570415\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412534; batch adversarial loss: 0.570387\n",
      "epoch 91; iter: 0; batch classifier loss: 0.313042; batch adversarial loss: 0.517293\n",
      "epoch 92; iter: 0; batch classifier loss: 0.463475; batch adversarial loss: 0.599175\n",
      "epoch 93; iter: 0; batch classifier loss: 0.370688; batch adversarial loss: 0.518393\n",
      "epoch 94; iter: 0; batch classifier loss: 0.349500; batch adversarial loss: 0.534986\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395905; batch adversarial loss: 0.553294\n",
      "epoch 96; iter: 0; batch classifier loss: 0.351346; batch adversarial loss: 0.490602\n",
      "epoch 97; iter: 0; batch classifier loss: 0.345593; batch adversarial loss: 0.480413\n",
      "epoch 98; iter: 0; batch classifier loss: 0.327889; batch adversarial loss: 0.564012\n",
      "epoch 99; iter: 0; batch classifier loss: 0.340922; batch adversarial loss: 0.590626\n",
      "epoch 100; iter: 0; batch classifier loss: 0.285563; batch adversarial loss: 0.590072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.379744; batch adversarial loss: 0.507474\n",
      "epoch 102; iter: 0; batch classifier loss: 0.381004; batch adversarial loss: 0.543680\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371988; batch adversarial loss: 0.517261\n",
      "epoch 104; iter: 0; batch classifier loss: 0.440826; batch adversarial loss: 0.451648\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360566; batch adversarial loss: 0.480474\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389528; batch adversarial loss: 0.480506\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365556; batch adversarial loss: 0.588119\n",
      "epoch 108; iter: 0; batch classifier loss: 0.330222; batch adversarial loss: 0.594071\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344088; batch adversarial loss: 0.565693\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371094; batch adversarial loss: 0.555917\n",
      "epoch 111; iter: 0; batch classifier loss: 0.291391; batch adversarial loss: 0.518593\n",
      "epoch 112; iter: 0; batch classifier loss: 0.408375; batch adversarial loss: 0.571329\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387404; batch adversarial loss: 0.551943\n",
      "epoch 114; iter: 0; batch classifier loss: 0.320233; batch adversarial loss: 0.534888\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398022; batch adversarial loss: 0.527401\n",
      "epoch 116; iter: 0; batch classifier loss: 0.360120; batch adversarial loss: 0.537442\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356320; batch adversarial loss: 0.535605\n",
      "epoch 118; iter: 0; batch classifier loss: 0.304216; batch adversarial loss: 0.534379\n",
      "epoch 119; iter: 0; batch classifier loss: 0.294487; batch adversarial loss: 0.535179\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406508; batch adversarial loss: 0.550901\n",
      "epoch 121; iter: 0; batch classifier loss: 0.289325; batch adversarial loss: 0.525908\n",
      "epoch 122; iter: 0; batch classifier loss: 0.357049; batch adversarial loss: 0.517068\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376570; batch adversarial loss: 0.508581\n",
      "epoch 124; iter: 0; batch classifier loss: 0.327751; batch adversarial loss: 0.479175\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326151; batch adversarial loss: 0.508789\n",
      "epoch 126; iter: 0; batch classifier loss: 0.318857; batch adversarial loss: 0.626269\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370594; batch adversarial loss: 0.534090\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344150; batch adversarial loss: 0.507248\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358161; batch adversarial loss: 0.625516\n",
      "epoch 130; iter: 0; batch classifier loss: 0.284592; batch adversarial loss: 0.545183\n",
      "epoch 131; iter: 0; batch classifier loss: 0.302030; batch adversarial loss: 0.674431\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320984; batch adversarial loss: 0.470536\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375929; batch adversarial loss: 0.516672\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344227; batch adversarial loss: 0.563953\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354367; batch adversarial loss: 0.616041\n",
      "epoch 136; iter: 0; batch classifier loss: 0.307471; batch adversarial loss: 0.601116\n",
      "epoch 137; iter: 0; batch classifier loss: 0.320450; batch adversarial loss: 0.498078\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384438; batch adversarial loss: 0.590558\n",
      "epoch 139; iter: 0; batch classifier loss: 0.283036; batch adversarial loss: 0.460980\n",
      "epoch 140; iter: 0; batch classifier loss: 0.314151; batch adversarial loss: 0.534124\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332241; batch adversarial loss: 0.611016\n",
      "epoch 142; iter: 0; batch classifier loss: 0.317656; batch adversarial loss: 0.571054\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346925; batch adversarial loss: 0.528596\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327560; batch adversarial loss: 0.498756\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323732; batch adversarial loss: 0.569472\n",
      "epoch 146; iter: 0; batch classifier loss: 0.391036; batch adversarial loss: 0.472150\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326427; batch adversarial loss: 0.597853\n",
      "epoch 148; iter: 0; batch classifier loss: 0.291574; batch adversarial loss: 0.472252\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334450; batch adversarial loss: 0.582711\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353904; batch adversarial loss: 0.470086\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379566; batch adversarial loss: 0.506290\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362919; batch adversarial loss: 0.555049\n",
      "epoch 153; iter: 0; batch classifier loss: 0.453224; batch adversarial loss: 0.492699\n",
      "epoch 154; iter: 0; batch classifier loss: 0.407859; batch adversarial loss: 0.481222\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336520; batch adversarial loss: 0.497110\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395063; batch adversarial loss: 0.532334\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350489; batch adversarial loss: 0.565127\n",
      "epoch 158; iter: 0; batch classifier loss: 0.283945; batch adversarial loss: 0.555367\n",
      "epoch 159; iter: 0; batch classifier loss: 0.297477; batch adversarial loss: 0.526006\n",
      "epoch 160; iter: 0; batch classifier loss: 0.355148; batch adversarial loss: 0.524758\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411283; batch adversarial loss: 0.530508\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369014; batch adversarial loss: 0.546909\n",
      "epoch 163; iter: 0; batch classifier loss: 0.360992; batch adversarial loss: 0.590513\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355986; batch adversarial loss: 0.533398\n",
      "epoch 165; iter: 0; batch classifier loss: 0.288760; batch adversarial loss: 0.524689\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322200; batch adversarial loss: 0.536876\n",
      "epoch 167; iter: 0; batch classifier loss: 0.318256; batch adversarial loss: 0.505745\n",
      "epoch 168; iter: 0; batch classifier loss: 0.410269; batch adversarial loss: 0.501246\n",
      "epoch 169; iter: 0; batch classifier loss: 0.316925; batch adversarial loss: 0.551991\n",
      "epoch 170; iter: 0; batch classifier loss: 0.341439; batch adversarial loss: 0.516205\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317020; batch adversarial loss: 0.590727\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377905; batch adversarial loss: 0.572194\n",
      "epoch 173; iter: 0; batch classifier loss: 0.284334; batch adversarial loss: 0.470749\n",
      "epoch 174; iter: 0; batch classifier loss: 0.286748; batch adversarial loss: 0.515028\n",
      "epoch 175; iter: 0; batch classifier loss: 0.303431; batch adversarial loss: 0.516962\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329083; batch adversarial loss: 0.571307\n",
      "epoch 177; iter: 0; batch classifier loss: 0.302202; batch adversarial loss: 0.571656\n",
      "epoch 178; iter: 0; batch classifier loss: 0.412225; batch adversarial loss: 0.437012\n",
      "epoch 179; iter: 0; batch classifier loss: 0.469188; batch adversarial loss: 0.555611\n",
      "epoch 180; iter: 0; batch classifier loss: 0.280848; batch adversarial loss: 0.527986\n",
      "epoch 181; iter: 0; batch classifier loss: 0.390622; batch adversarial loss: 0.590562\n",
      "epoch 182; iter: 0; batch classifier loss: 0.468295; batch adversarial loss: 0.552614\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369048; batch adversarial loss: 0.557014\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287935; batch adversarial loss: 0.617276\n",
      "epoch 185; iter: 0; batch classifier loss: 0.345825; batch adversarial loss: 0.553817\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385562; batch adversarial loss: 0.489124\n",
      "epoch 187; iter: 0; batch classifier loss: 0.315196; batch adversarial loss: 0.557841\n",
      "epoch 188; iter: 0; batch classifier loss: 0.277583; batch adversarial loss: 0.565055\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292502; batch adversarial loss: 0.598625\n",
      "epoch 190; iter: 0; batch classifier loss: 0.291776; batch adversarial loss: 0.587687\n",
      "epoch 191; iter: 0; batch classifier loss: 0.294032; batch adversarial loss: 0.607087\n",
      "epoch 192; iter: 0; batch classifier loss: 0.311116; batch adversarial loss: 0.609223\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325230; batch adversarial loss: 0.592742\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380312; batch adversarial loss: 0.561561\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332460; batch adversarial loss: 0.625406\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328398; batch adversarial loss: 0.619071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.299385; batch adversarial loss: 0.537657\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370159; batch adversarial loss: 0.546419\n",
      "epoch 199; iter: 0; batch classifier loss: 0.266915; batch adversarial loss: 0.561146\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730847; batch adversarial loss: 0.830499\n",
      "epoch 1; iter: 0; batch classifier loss: 0.755423; batch adversarial loss: 0.880186\n",
      "epoch 2; iter: 0; batch classifier loss: 0.926238; batch adversarial loss: 0.861027\n",
      "epoch 3; iter: 0; batch classifier loss: 0.858566; batch adversarial loss: 0.787334\n",
      "epoch 4; iter: 0; batch classifier loss: 0.760559; batch adversarial loss: 0.688137\n",
      "epoch 5; iter: 0; batch classifier loss: 0.708583; batch adversarial loss: 0.671557\n",
      "epoch 6; iter: 0; batch classifier loss: 0.601536; batch adversarial loss: 0.662167\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488632; batch adversarial loss: 0.595778\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552750; batch adversarial loss: 0.580997\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561832; batch adversarial loss: 0.595633\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505142; batch adversarial loss: 0.616935\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532809; batch adversarial loss: 0.607367\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509369; batch adversarial loss: 0.536229\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509411; batch adversarial loss: 0.564760\n",
      "epoch 14; iter: 0; batch classifier loss: 0.433286; batch adversarial loss: 0.571890\n",
      "epoch 15; iter: 0; batch classifier loss: 0.476502; batch adversarial loss: 0.565628\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498557; batch adversarial loss: 0.501995\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503323; batch adversarial loss: 0.556928\n",
      "epoch 18; iter: 0; batch classifier loss: 0.579759; batch adversarial loss: 0.641936\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471665; batch adversarial loss: 0.527239\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503101; batch adversarial loss: 0.544013\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520125; batch adversarial loss: 0.513602\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468622; batch adversarial loss: 0.517053\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522277; batch adversarial loss: 0.536171\n",
      "epoch 24; iter: 0; batch classifier loss: 0.598182; batch adversarial loss: 0.524177\n",
      "epoch 25; iter: 0; batch classifier loss: 0.477422; batch adversarial loss: 0.530093\n",
      "epoch 26; iter: 0; batch classifier loss: 0.412105; batch adversarial loss: 0.527561\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510981; batch adversarial loss: 0.553163\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435570; batch adversarial loss: 0.503052\n",
      "epoch 29; iter: 0; batch classifier loss: 0.519228; batch adversarial loss: 0.583504\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515714; batch adversarial loss: 0.593102\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459065; batch adversarial loss: 0.575925\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490585; batch adversarial loss: 0.445098\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458439; batch adversarial loss: 0.563454\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438336; batch adversarial loss: 0.485822\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485178; batch adversarial loss: 0.565580\n",
      "epoch 36; iter: 0; batch classifier loss: 0.574670; batch adversarial loss: 0.564613\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459923; batch adversarial loss: 0.550819\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471062; batch adversarial loss: 0.559474\n",
      "epoch 39; iter: 0; batch classifier loss: 0.387050; batch adversarial loss: 0.481034\n",
      "epoch 40; iter: 0; batch classifier loss: 0.427626; batch adversarial loss: 0.510072\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481305; batch adversarial loss: 0.582014\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496751; batch adversarial loss: 0.572790\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484864; batch adversarial loss: 0.482092\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410352; batch adversarial loss: 0.512176\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481922; batch adversarial loss: 0.574917\n",
      "epoch 46; iter: 0; batch classifier loss: 0.526708; batch adversarial loss: 0.529431\n",
      "epoch 47; iter: 0; batch classifier loss: 0.402998; batch adversarial loss: 0.473713\n",
      "epoch 48; iter: 0; batch classifier loss: 0.355964; batch adversarial loss: 0.544827\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414983; batch adversarial loss: 0.536377\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411050; batch adversarial loss: 0.490094\n",
      "epoch 51; iter: 0; batch classifier loss: 0.497188; batch adversarial loss: 0.543626\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444579; batch adversarial loss: 0.581969\n",
      "epoch 53; iter: 0; batch classifier loss: 0.370449; batch adversarial loss: 0.526133\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463783; batch adversarial loss: 0.524907\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387503; batch adversarial loss: 0.604952\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394100; batch adversarial loss: 0.541282\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402000; batch adversarial loss: 0.527137\n",
      "epoch 58; iter: 0; batch classifier loss: 0.489276; batch adversarial loss: 0.461849\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438349; batch adversarial loss: 0.552474\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446261; batch adversarial loss: 0.546255\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385242; batch adversarial loss: 0.461003\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432784; batch adversarial loss: 0.525756\n",
      "epoch 63; iter: 0; batch classifier loss: 0.360767; batch adversarial loss: 0.564472\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384189; batch adversarial loss: 0.562889\n",
      "epoch 65; iter: 0; batch classifier loss: 0.348278; batch adversarial loss: 0.610184\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418526; batch adversarial loss: 0.507468\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351706; batch adversarial loss: 0.564016\n",
      "epoch 68; iter: 0; batch classifier loss: 0.449030; batch adversarial loss: 0.488703\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420722; batch adversarial loss: 0.498150\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402243; batch adversarial loss: 0.525833\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416429; batch adversarial loss: 0.572831\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414348; batch adversarial loss: 0.563382\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414088; batch adversarial loss: 0.591322\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385603; batch adversarial loss: 0.582313\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391991; batch adversarial loss: 0.572792\n",
      "epoch 76; iter: 0; batch classifier loss: 0.456673; batch adversarial loss: 0.468814\n",
      "epoch 77; iter: 0; batch classifier loss: 0.430764; batch adversarial loss: 0.572688\n",
      "epoch 78; iter: 0; batch classifier loss: 0.388009; batch adversarial loss: 0.516225\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370392; batch adversarial loss: 0.496912\n",
      "epoch 80; iter: 0; batch classifier loss: 0.445725; batch adversarial loss: 0.642841\n",
      "epoch 81; iter: 0; batch classifier loss: 0.439931; batch adversarial loss: 0.515383\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404252; batch adversarial loss: 0.487463\n",
      "epoch 83; iter: 0; batch classifier loss: 0.316814; batch adversarial loss: 0.527598\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393485; batch adversarial loss: 0.555942\n",
      "epoch 85; iter: 0; batch classifier loss: 0.352970; batch adversarial loss: 0.515122\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387102; batch adversarial loss: 0.554223\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373628; batch adversarial loss: 0.441526\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440420; batch adversarial loss: 0.525206\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368409; batch adversarial loss: 0.536003\n",
      "epoch 90; iter: 0; batch classifier loss: 0.400114; batch adversarial loss: 0.478848\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367945; batch adversarial loss: 0.470505\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376584; batch adversarial loss: 0.600386\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455999; batch adversarial loss: 0.592037\n",
      "epoch 94; iter: 0; batch classifier loss: 0.340087; batch adversarial loss: 0.600709\n",
      "epoch 95; iter: 0; batch classifier loss: 0.346478; batch adversarial loss: 0.497012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.391652; batch adversarial loss: 0.495990\n",
      "epoch 97; iter: 0; batch classifier loss: 0.454860; batch adversarial loss: 0.515913\n",
      "epoch 98; iter: 0; batch classifier loss: 0.335826; batch adversarial loss: 0.572778\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402618; batch adversarial loss: 0.544218\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345397; batch adversarial loss: 0.610342\n",
      "epoch 101; iter: 0; batch classifier loss: 0.327183; batch adversarial loss: 0.525422\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417072; batch adversarial loss: 0.535028\n",
      "epoch 103; iter: 0; batch classifier loss: 0.392129; batch adversarial loss: 0.507320\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363286; batch adversarial loss: 0.525261\n",
      "epoch 105; iter: 0; batch classifier loss: 0.420593; batch adversarial loss: 0.516375\n",
      "epoch 106; iter: 0; batch classifier loss: 0.340025; batch adversarial loss: 0.525618\n",
      "epoch 107; iter: 0; batch classifier loss: 0.442181; batch adversarial loss: 0.506673\n",
      "epoch 108; iter: 0; batch classifier loss: 0.340734; batch adversarial loss: 0.554003\n",
      "epoch 109; iter: 0; batch classifier loss: 0.298299; batch adversarial loss: 0.601447\n",
      "epoch 110; iter: 0; batch classifier loss: 0.335786; batch adversarial loss: 0.488220\n",
      "epoch 111; iter: 0; batch classifier loss: 0.441494; batch adversarial loss: 0.411359\n",
      "epoch 112; iter: 0; batch classifier loss: 0.332584; batch adversarial loss: 0.545096\n",
      "epoch 113; iter: 0; batch classifier loss: 0.424808; batch adversarial loss: 0.563798\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377068; batch adversarial loss: 0.573351\n",
      "epoch 115; iter: 0; batch classifier loss: 0.428690; batch adversarial loss: 0.524604\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387041; batch adversarial loss: 0.467937\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414922; batch adversarial loss: 0.525686\n",
      "epoch 118; iter: 0; batch classifier loss: 0.314264; batch adversarial loss: 0.572414\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394277; batch adversarial loss: 0.516719\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363509; batch adversarial loss: 0.505261\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393007; batch adversarial loss: 0.563492\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362870; batch adversarial loss: 0.552576\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378831; batch adversarial loss: 0.460622\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353292; batch adversarial loss: 0.535332\n",
      "epoch 125; iter: 0; batch classifier loss: 0.322579; batch adversarial loss: 0.451614\n",
      "epoch 126; iter: 0; batch classifier loss: 0.356533; batch adversarial loss: 0.479322\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378349; batch adversarial loss: 0.553389\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357986; batch adversarial loss: 0.544365\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394100; batch adversarial loss: 0.478162\n",
      "epoch 130; iter: 0; batch classifier loss: 0.442613; batch adversarial loss: 0.564083\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405637; batch adversarial loss: 0.610387\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382581; batch adversarial loss: 0.582496\n",
      "epoch 133; iter: 0; batch classifier loss: 0.430759; batch adversarial loss: 0.535453\n",
      "epoch 134; iter: 0; batch classifier loss: 0.353564; batch adversarial loss: 0.581936\n",
      "epoch 135; iter: 0; batch classifier loss: 0.440823; batch adversarial loss: 0.487983\n",
      "epoch 136; iter: 0; batch classifier loss: 0.464208; batch adversarial loss: 0.572753\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367352; batch adversarial loss: 0.487990\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376767; batch adversarial loss: 0.591577\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349208; batch adversarial loss: 0.497421\n",
      "epoch 140; iter: 0; batch classifier loss: 0.404609; batch adversarial loss: 0.516158\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323399; batch adversarial loss: 0.497550\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336142; batch adversarial loss: 0.506595\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374406; batch adversarial loss: 0.487921\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356673; batch adversarial loss: 0.563086\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332320; batch adversarial loss: 0.516450\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378519; batch adversarial loss: 0.535845\n",
      "epoch 147; iter: 0; batch classifier loss: 0.305506; batch adversarial loss: 0.620241\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341541; batch adversarial loss: 0.572878\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335919; batch adversarial loss: 0.516746\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359270; batch adversarial loss: 0.488361\n",
      "epoch 151; iter: 0; batch classifier loss: 0.311040; batch adversarial loss: 0.506640\n",
      "epoch 152; iter: 0; batch classifier loss: 0.261315; batch adversarial loss: 0.563056\n",
      "epoch 153; iter: 0; batch classifier loss: 0.332209; batch adversarial loss: 0.620309\n",
      "epoch 154; iter: 0; batch classifier loss: 0.387498; batch adversarial loss: 0.535489\n",
      "epoch 155; iter: 0; batch classifier loss: 0.254250; batch adversarial loss: 0.497177\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328995; batch adversarial loss: 0.591349\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393357; batch adversarial loss: 0.602329\n",
      "epoch 158; iter: 0; batch classifier loss: 0.377105; batch adversarial loss: 0.496880\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316281; batch adversarial loss: 0.592302\n",
      "epoch 160; iter: 0; batch classifier loss: 0.297706; batch adversarial loss: 0.581776\n",
      "epoch 161; iter: 0; batch classifier loss: 0.349277; batch adversarial loss: 0.487644\n",
      "epoch 162; iter: 0; batch classifier loss: 0.520300; batch adversarial loss: 0.506772\n",
      "epoch 163; iter: 0; batch classifier loss: 0.306072; batch adversarial loss: 0.573184\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340103; batch adversarial loss: 0.507133\n",
      "epoch 165; iter: 0; batch classifier loss: 0.331794; batch adversarial loss: 0.554057\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372857; batch adversarial loss: 0.506612\n",
      "epoch 167; iter: 0; batch classifier loss: 0.326324; batch adversarial loss: 0.515740\n",
      "epoch 168; iter: 0; batch classifier loss: 0.379362; batch adversarial loss: 0.611728\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408065; batch adversarial loss: 0.535444\n",
      "epoch 170; iter: 0; batch classifier loss: 0.306458; batch adversarial loss: 0.534950\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347896; batch adversarial loss: 0.621598\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374914; batch adversarial loss: 0.554064\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351288; batch adversarial loss: 0.526655\n",
      "epoch 174; iter: 0; batch classifier loss: 0.386740; batch adversarial loss: 0.487314\n",
      "epoch 175; iter: 0; batch classifier loss: 0.422833; batch adversarial loss: 0.554048\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361651; batch adversarial loss: 0.506146\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381023; batch adversarial loss: 0.516958\n",
      "epoch 178; iter: 0; batch classifier loss: 0.425482; batch adversarial loss: 0.534776\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298987; batch adversarial loss: 0.554118\n",
      "epoch 180; iter: 0; batch classifier loss: 0.447701; batch adversarial loss: 0.554112\n",
      "epoch 181; iter: 0; batch classifier loss: 0.403202; batch adversarial loss: 0.572847\n",
      "epoch 182; iter: 0; batch classifier loss: 0.298315; batch adversarial loss: 0.497160\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370455; batch adversarial loss: 0.554178\n",
      "epoch 184; iter: 0; batch classifier loss: 0.392235; batch adversarial loss: 0.544751\n",
      "epoch 185; iter: 0; batch classifier loss: 0.335851; batch adversarial loss: 0.534910\n",
      "epoch 186; iter: 0; batch classifier loss: 0.310290; batch adversarial loss: 0.487575\n",
      "epoch 187; iter: 0; batch classifier loss: 0.274753; batch adversarial loss: 0.496816\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345929; batch adversarial loss: 0.583200\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354212; batch adversarial loss: 0.629972\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368808; batch adversarial loss: 0.591707\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322405; batch adversarial loss: 0.544453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.383272; batch adversarial loss: 0.554308\n",
      "epoch 193; iter: 0; batch classifier loss: 0.286547; batch adversarial loss: 0.582194\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384670; batch adversarial loss: 0.516030\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398830; batch adversarial loss: 0.505963\n",
      "epoch 196; iter: 0; batch classifier loss: 0.325677; batch adversarial loss: 0.497288\n",
      "epoch 197; iter: 0; batch classifier loss: 0.298093; batch adversarial loss: 0.497529\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338829; batch adversarial loss: 0.553435\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386753; batch adversarial loss: 0.572268\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642020; batch adversarial loss: 0.585319\n",
      "epoch 1; iter: 0; batch classifier loss: 0.633366; batch adversarial loss: 0.672807\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621485; batch adversarial loss: 0.653265\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547100; batch adversarial loss: 0.663562\n",
      "epoch 4; iter: 0; batch classifier loss: 0.618199; batch adversarial loss: 0.687226\n",
      "epoch 5; iter: 0; batch classifier loss: 0.659064; batch adversarial loss: 0.617762\n",
      "epoch 6; iter: 0; batch classifier loss: 0.469165; batch adversarial loss: 0.625821\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503074; batch adversarial loss: 0.571028\n",
      "epoch 8; iter: 0; batch classifier loss: 0.589048; batch adversarial loss: 0.641119\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584383; batch adversarial loss: 0.553248\n",
      "epoch 10; iter: 0; batch classifier loss: 0.607465; batch adversarial loss: 0.633573\n",
      "epoch 11; iter: 0; batch classifier loss: 0.510518; batch adversarial loss: 0.553563\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542202; batch adversarial loss: 0.657346\n",
      "epoch 13; iter: 0; batch classifier loss: 0.459991; batch adversarial loss: 0.612618\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544907; batch adversarial loss: 0.602797\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544095; batch adversarial loss: 0.528926\n",
      "epoch 16; iter: 0; batch classifier loss: 0.479451; batch adversarial loss: 0.551630\n",
      "epoch 17; iter: 0; batch classifier loss: 0.421264; batch adversarial loss: 0.563487\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479377; batch adversarial loss: 0.563254\n",
      "epoch 19; iter: 0; batch classifier loss: 0.567414; batch adversarial loss: 0.560208\n",
      "epoch 20; iter: 0; batch classifier loss: 0.442503; batch adversarial loss: 0.554537\n",
      "epoch 21; iter: 0; batch classifier loss: 0.445610; batch adversarial loss: 0.507018\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497083; batch adversarial loss: 0.592121\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501231; batch adversarial loss: 0.509535\n",
      "epoch 24; iter: 0; batch classifier loss: 0.539626; batch adversarial loss: 0.554154\n",
      "epoch 25; iter: 0; batch classifier loss: 0.556004; batch adversarial loss: 0.548891\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444738; batch adversarial loss: 0.557704\n",
      "epoch 27; iter: 0; batch classifier loss: 0.435057; batch adversarial loss: 0.516337\n",
      "epoch 28; iter: 0; batch classifier loss: 0.553816; batch adversarial loss: 0.579351\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524297; batch adversarial loss: 0.571117\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439656; batch adversarial loss: 0.527423\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454578; batch adversarial loss: 0.547620\n",
      "epoch 32; iter: 0; batch classifier loss: 0.514719; batch adversarial loss: 0.549739\n",
      "epoch 33; iter: 0; batch classifier loss: 0.523690; batch adversarial loss: 0.582031\n",
      "epoch 34; iter: 0; batch classifier loss: 0.517541; batch adversarial loss: 0.500208\n",
      "epoch 35; iter: 0; batch classifier loss: 0.416123; batch adversarial loss: 0.534259\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472096; batch adversarial loss: 0.492380\n",
      "epoch 37; iter: 0; batch classifier loss: 0.468994; batch adversarial loss: 0.483848\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460118; batch adversarial loss: 0.549414\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460550; batch adversarial loss: 0.491326\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462279; batch adversarial loss: 0.474012\n",
      "epoch 41; iter: 0; batch classifier loss: 0.372370; batch adversarial loss: 0.555677\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416891; batch adversarial loss: 0.429087\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493176; batch adversarial loss: 0.579177\n",
      "epoch 44; iter: 0; batch classifier loss: 0.374275; batch adversarial loss: 0.563544\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405631; batch adversarial loss: 0.618075\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454583; batch adversarial loss: 0.560904\n",
      "epoch 47; iter: 0; batch classifier loss: 0.496342; batch adversarial loss: 0.560101\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426469; batch adversarial loss: 0.534196\n",
      "epoch 49; iter: 0; batch classifier loss: 0.538138; batch adversarial loss: 0.469134\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426513; batch adversarial loss: 0.579045\n",
      "epoch 51; iter: 0; batch classifier loss: 0.507458; batch adversarial loss: 0.508055\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448945; batch adversarial loss: 0.504787\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403041; batch adversarial loss: 0.602880\n",
      "epoch 54; iter: 0; batch classifier loss: 0.383364; batch adversarial loss: 0.505828\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415977; batch adversarial loss: 0.589689\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383777; batch adversarial loss: 0.509396\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466714; batch adversarial loss: 0.587669\n",
      "epoch 58; iter: 0; batch classifier loss: 0.408583; batch adversarial loss: 0.488204\n",
      "epoch 59; iter: 0; batch classifier loss: 0.501411; batch adversarial loss: 0.533223\n",
      "epoch 60; iter: 0; batch classifier loss: 0.417509; batch adversarial loss: 0.515660\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430057; batch adversarial loss: 0.537362\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436580; batch adversarial loss: 0.546797\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463742; batch adversarial loss: 0.463197\n",
      "epoch 64; iter: 0; batch classifier loss: 0.417459; batch adversarial loss: 0.469633\n",
      "epoch 65; iter: 0; batch classifier loss: 0.364959; batch adversarial loss: 0.644777\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407898; batch adversarial loss: 0.544090\n",
      "epoch 67; iter: 0; batch classifier loss: 0.496452; batch adversarial loss: 0.462723\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408137; batch adversarial loss: 0.644171\n",
      "epoch 69; iter: 0; batch classifier loss: 0.453343; batch adversarial loss: 0.505626\n",
      "epoch 70; iter: 0; batch classifier loss: 0.405733; batch adversarial loss: 0.525395\n",
      "epoch 71; iter: 0; batch classifier loss: 0.375788; batch adversarial loss: 0.599234\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382772; batch adversarial loss: 0.570282\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368129; batch adversarial loss: 0.544122\n",
      "epoch 74; iter: 0; batch classifier loss: 0.442198; batch adversarial loss: 0.591566\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421585; batch adversarial loss: 0.561070\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419352; batch adversarial loss: 0.517315\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425861; batch adversarial loss: 0.496258\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416357; batch adversarial loss: 0.506686\n",
      "epoch 79; iter: 0; batch classifier loss: 0.453582; batch adversarial loss: 0.534235\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407527; batch adversarial loss: 0.528508\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406619; batch adversarial loss: 0.600702\n",
      "epoch 82; iter: 0; batch classifier loss: 0.391164; batch adversarial loss: 0.462942\n",
      "epoch 83; iter: 0; batch classifier loss: 0.348453; batch adversarial loss: 0.531757\n",
      "epoch 84; iter: 0; batch classifier loss: 0.508260; batch adversarial loss: 0.508692\n",
      "epoch 85; iter: 0; batch classifier loss: 0.335873; batch adversarial loss: 0.580732\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440786; batch adversarial loss: 0.519508\n",
      "epoch 87; iter: 0; batch classifier loss: 0.470926; batch adversarial loss: 0.535929\n",
      "epoch 88; iter: 0; batch classifier loss: 0.452488; batch adversarial loss: 0.588675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.472237; batch adversarial loss: 0.479967\n",
      "epoch 90; iter: 0; batch classifier loss: 0.454964; batch adversarial loss: 0.519341\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373888; batch adversarial loss: 0.571045\n",
      "epoch 92; iter: 0; batch classifier loss: 0.423573; batch adversarial loss: 0.568618\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431826; batch adversarial loss: 0.510033\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405654; batch adversarial loss: 0.490246\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396418; batch adversarial loss: 0.606707\n",
      "epoch 96; iter: 0; batch classifier loss: 0.499569; batch adversarial loss: 0.453000\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370146; batch adversarial loss: 0.646201\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376212; batch adversarial loss: 0.597864\n",
      "epoch 99; iter: 0; batch classifier loss: 0.474812; batch adversarial loss: 0.518319\n",
      "epoch 100; iter: 0; batch classifier loss: 0.454196; batch adversarial loss: 0.543387\n",
      "epoch 101; iter: 0; batch classifier loss: 0.343031; batch adversarial loss: 0.544813\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417032; batch adversarial loss: 0.544287\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416828; batch adversarial loss: 0.618143\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390692; batch adversarial loss: 0.643564\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432773; batch adversarial loss: 0.492813\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354271; batch adversarial loss: 0.563560\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339729; batch adversarial loss: 0.561979\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381667; batch adversarial loss: 0.527290\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412125; batch adversarial loss: 0.518160\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395113; batch adversarial loss: 0.563355\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403151; batch adversarial loss: 0.570495\n",
      "epoch 112; iter: 0; batch classifier loss: 0.400619; batch adversarial loss: 0.561987\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351548; batch adversarial loss: 0.571992\n",
      "epoch 114; iter: 0; batch classifier loss: 0.419276; batch adversarial loss: 0.572245\n",
      "epoch 115; iter: 0; batch classifier loss: 0.322279; batch adversarial loss: 0.589692\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350191; batch adversarial loss: 0.537487\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389122; batch adversarial loss: 0.608747\n",
      "epoch 118; iter: 0; batch classifier loss: 0.432937; batch adversarial loss: 0.480261\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414511; batch adversarial loss: 0.509128\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328128; batch adversarial loss: 0.534233\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368126; batch adversarial loss: 0.498460\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391882; batch adversarial loss: 0.469385\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370470; batch adversarial loss: 0.478721\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366275; batch adversarial loss: 0.563904\n",
      "epoch 125; iter: 0; batch classifier loss: 0.328442; batch adversarial loss: 0.489764\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376682; batch adversarial loss: 0.546199\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387939; batch adversarial loss: 0.553629\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389251; batch adversarial loss: 0.560564\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375866; batch adversarial loss: 0.516011\n",
      "epoch 130; iter: 0; batch classifier loss: 0.464766; batch adversarial loss: 0.507771\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359654; batch adversarial loss: 0.555359\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341151; batch adversarial loss: 0.538085\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331843; batch adversarial loss: 0.544301\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377291; batch adversarial loss: 0.543810\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354400; batch adversarial loss: 0.499806\n",
      "epoch 136; iter: 0; batch classifier loss: 0.329374; batch adversarial loss: 0.588925\n",
      "epoch 137; iter: 0; batch classifier loss: 0.423160; batch adversarial loss: 0.534058\n",
      "epoch 138; iter: 0; batch classifier loss: 0.418579; batch adversarial loss: 0.552746\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366026; batch adversarial loss: 0.507970\n",
      "epoch 140; iter: 0; batch classifier loss: 0.437775; batch adversarial loss: 0.508549\n",
      "epoch 141; iter: 0; batch classifier loss: 0.297646; batch adversarial loss: 0.564036\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331408; batch adversarial loss: 0.536254\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414805; batch adversarial loss: 0.533987\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389232; batch adversarial loss: 0.545154\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403835; batch adversarial loss: 0.508598\n",
      "epoch 146; iter: 0; batch classifier loss: 0.397487; batch adversarial loss: 0.463317\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345509; batch adversarial loss: 0.571622\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345119; batch adversarial loss: 0.570911\n",
      "epoch 149; iter: 0; batch classifier loss: 0.389251; batch adversarial loss: 0.480467\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391380; batch adversarial loss: 0.492197\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354003; batch adversarial loss: 0.508268\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344119; batch adversarial loss: 0.507303\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362923; batch adversarial loss: 0.524499\n",
      "epoch 154; iter: 0; batch classifier loss: 0.392926; batch adversarial loss: 0.572192\n",
      "epoch 155; iter: 0; batch classifier loss: 0.454861; batch adversarial loss: 0.608180\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354496; batch adversarial loss: 0.553877\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367963; batch adversarial loss: 0.497808\n",
      "epoch 158; iter: 0; batch classifier loss: 0.447021; batch adversarial loss: 0.619714\n",
      "epoch 159; iter: 0; batch classifier loss: 0.414384; batch adversarial loss: 0.526224\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380539; batch adversarial loss: 0.544325\n",
      "epoch 161; iter: 0; batch classifier loss: 0.467739; batch adversarial loss: 0.546444\n",
      "epoch 162; iter: 0; batch classifier loss: 0.406859; batch adversarial loss: 0.570240\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367281; batch adversarial loss: 0.598709\n",
      "epoch 164; iter: 0; batch classifier loss: 0.332444; batch adversarial loss: 0.533521\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360523; batch adversarial loss: 0.590180\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347696; batch adversarial loss: 0.571084\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393527; batch adversarial loss: 0.535325\n",
      "epoch 168; iter: 0; batch classifier loss: 0.440336; batch adversarial loss: 0.517080\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326357; batch adversarial loss: 0.525628\n",
      "epoch 170; iter: 0; batch classifier loss: 0.437960; batch adversarial loss: 0.498382\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411172; batch adversarial loss: 0.562431\n",
      "epoch 172; iter: 0; batch classifier loss: 0.536178; batch adversarial loss: 0.551329\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316056; batch adversarial loss: 0.591376\n",
      "epoch 174; iter: 0; batch classifier loss: 0.283916; batch adversarial loss: 0.497412\n",
      "epoch 175; iter: 0; batch classifier loss: 0.334925; batch adversarial loss: 0.592050\n",
      "epoch 176; iter: 0; batch classifier loss: 0.439651; batch adversarial loss: 0.489796\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314900; batch adversarial loss: 0.599307\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355936; batch adversarial loss: 0.500542\n",
      "epoch 179; iter: 0; batch classifier loss: 0.365176; batch adversarial loss: 0.544390\n",
      "epoch 180; iter: 0; batch classifier loss: 0.401270; batch adversarial loss: 0.488743\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343372; batch adversarial loss: 0.444684\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378744; batch adversarial loss: 0.518568\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378529; batch adversarial loss: 0.651613\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339411; batch adversarial loss: 0.563337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.306007; batch adversarial loss: 0.514786\n",
      "epoch 186; iter: 0; batch classifier loss: 0.332027; batch adversarial loss: 0.481290\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340365; batch adversarial loss: 0.581968\n",
      "epoch 188; iter: 0; batch classifier loss: 0.364469; batch adversarial loss: 0.535349\n",
      "epoch 189; iter: 0; batch classifier loss: 0.426871; batch adversarial loss: 0.517016\n",
      "epoch 190; iter: 0; batch classifier loss: 0.317041; batch adversarial loss: 0.553752\n",
      "epoch 191; iter: 0; batch classifier loss: 0.368470; batch adversarial loss: 0.461945\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315681; batch adversarial loss: 0.562891\n",
      "epoch 193; iter: 0; batch classifier loss: 0.407495; batch adversarial loss: 0.554585\n",
      "epoch 194; iter: 0; batch classifier loss: 0.409484; batch adversarial loss: 0.563738\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338154; batch adversarial loss: 0.509627\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354815; batch adversarial loss: 0.596687\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368610; batch adversarial loss: 0.534009\n",
      "epoch 198; iter: 0; batch classifier loss: 0.468712; batch adversarial loss: 0.561828\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359991; batch adversarial loss: 0.506854\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637590; batch adversarial loss: 0.711662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670928; batch adversarial loss: 0.689972\n",
      "epoch 2; iter: 0; batch classifier loss: 0.627486; batch adversarial loss: 0.646180\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542745; batch adversarial loss: 0.645959\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544734; batch adversarial loss: 0.622825\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588915; batch adversarial loss: 0.623912\n",
      "epoch 6; iter: 0; batch classifier loss: 0.576416; batch adversarial loss: 0.588045\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490718; batch adversarial loss: 0.556304\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562911; batch adversarial loss: 0.567816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499692; batch adversarial loss: 0.557908\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546654; batch adversarial loss: 0.567264\n",
      "epoch 11; iter: 0; batch classifier loss: 0.578404; batch adversarial loss: 0.607621\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518868; batch adversarial loss: 0.560665\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507318; batch adversarial loss: 0.592952\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479464; batch adversarial loss: 0.544833\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493286; batch adversarial loss: 0.523429\n",
      "epoch 16; iter: 0; batch classifier loss: 0.516406; batch adversarial loss: 0.605573\n",
      "epoch 17; iter: 0; batch classifier loss: 0.464991; batch adversarial loss: 0.566308\n",
      "epoch 18; iter: 0; batch classifier loss: 0.428674; batch adversarial loss: 0.540328\n",
      "epoch 19; iter: 0; batch classifier loss: 0.558685; batch adversarial loss: 0.530980\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441739; batch adversarial loss: 0.502112\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454871; batch adversarial loss: 0.606230\n",
      "epoch 22; iter: 0; batch classifier loss: 0.356380; batch adversarial loss: 0.587348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531901; batch adversarial loss: 0.580365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506108; batch adversarial loss: 0.580400\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483393; batch adversarial loss: 0.549291\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470141; batch adversarial loss: 0.533814\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430473; batch adversarial loss: 0.559522\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425588; batch adversarial loss: 0.563428\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458910; batch adversarial loss: 0.635081\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510986; batch adversarial loss: 0.516676\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496036; batch adversarial loss: 0.582623\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472422; batch adversarial loss: 0.537593\n",
      "epoch 33; iter: 0; batch classifier loss: 0.520997; batch adversarial loss: 0.478787\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477893; batch adversarial loss: 0.460210\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438540; batch adversarial loss: 0.493770\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463489; batch adversarial loss: 0.538992\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487292; batch adversarial loss: 0.606990\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417616; batch adversarial loss: 0.544739\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414290; batch adversarial loss: 0.482834\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454833; batch adversarial loss: 0.563811\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420411; batch adversarial loss: 0.562139\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403636; batch adversarial loss: 0.489242\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483239; batch adversarial loss: 0.500366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.425553; batch adversarial loss: 0.555005\n",
      "epoch 45; iter: 0; batch classifier loss: 0.525252; batch adversarial loss: 0.580761\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439532; batch adversarial loss: 0.508989\n",
      "epoch 47; iter: 0; batch classifier loss: 0.497253; batch adversarial loss: 0.580438\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440819; batch adversarial loss: 0.553560\n",
      "epoch 49; iter: 0; batch classifier loss: 0.482168; batch adversarial loss: 0.598404\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426255; batch adversarial loss: 0.508459\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383448; batch adversarial loss: 0.472849\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434835; batch adversarial loss: 0.562278\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386301; batch adversarial loss: 0.562708\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429643; batch adversarial loss: 0.545656\n",
      "epoch 55; iter: 0; batch classifier loss: 0.463047; batch adversarial loss: 0.581602\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383519; batch adversarial loss: 0.581254\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435975; batch adversarial loss: 0.495428\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458002; batch adversarial loss: 0.515376\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408294; batch adversarial loss: 0.514875\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370096; batch adversarial loss: 0.543200\n",
      "epoch 61; iter: 0; batch classifier loss: 0.443866; batch adversarial loss: 0.497972\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438017; batch adversarial loss: 0.619007\n",
      "epoch 63; iter: 0; batch classifier loss: 0.307298; batch adversarial loss: 0.609462\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440733; batch adversarial loss: 0.590755\n",
      "epoch 65; iter: 0; batch classifier loss: 0.405231; batch adversarial loss: 0.544506\n",
      "epoch 66; iter: 0; batch classifier loss: 0.368671; batch adversarial loss: 0.580107\n",
      "epoch 67; iter: 0; batch classifier loss: 0.365249; batch adversarial loss: 0.526428\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432058; batch adversarial loss: 0.525969\n",
      "epoch 69; iter: 0; batch classifier loss: 0.423930; batch adversarial loss: 0.582864\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416696; batch adversarial loss: 0.499616\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372401; batch adversarial loss: 0.526306\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435424; batch adversarial loss: 0.554351\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389197; batch adversarial loss: 0.516340\n",
      "epoch 74; iter: 0; batch classifier loss: 0.290450; batch adversarial loss: 0.517461\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426343; batch adversarial loss: 0.443295\n",
      "epoch 76; iter: 0; batch classifier loss: 0.484108; batch adversarial loss: 0.589939\n",
      "epoch 77; iter: 0; batch classifier loss: 0.461506; batch adversarial loss: 0.452554\n",
      "epoch 78; iter: 0; batch classifier loss: 0.514660; batch adversarial loss: 0.590894\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462793; batch adversarial loss: 0.545159\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381398; batch adversarial loss: 0.480461\n",
      "epoch 81; iter: 0; batch classifier loss: 0.366609; batch adversarial loss: 0.635563\n",
      "epoch 82; iter: 0; batch classifier loss: 0.337898; batch adversarial loss: 0.526283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.385436; batch adversarial loss: 0.461559\n",
      "epoch 84; iter: 0; batch classifier loss: 0.436809; batch adversarial loss: 0.553302\n",
      "epoch 85; iter: 0; batch classifier loss: 0.355803; batch adversarial loss: 0.507671\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425736; batch adversarial loss: 0.517077\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418157; batch adversarial loss: 0.544495\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356641; batch adversarial loss: 0.581591\n",
      "epoch 89; iter: 0; batch classifier loss: 0.444989; batch adversarial loss: 0.515967\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378431; batch adversarial loss: 0.507040\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400409; batch adversarial loss: 0.488207\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394608; batch adversarial loss: 0.526435\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431295; batch adversarial loss: 0.516737\n",
      "epoch 94; iter: 0; batch classifier loss: 0.388309; batch adversarial loss: 0.544684\n",
      "epoch 95; iter: 0; batch classifier loss: 0.461755; batch adversarial loss: 0.534718\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349820; batch adversarial loss: 0.571859\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360626; batch adversarial loss: 0.553792\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394712; batch adversarial loss: 0.507766\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413429; batch adversarial loss: 0.525715\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370181; batch adversarial loss: 0.609327\n",
      "epoch 101; iter: 0; batch classifier loss: 0.436622; batch adversarial loss: 0.508438\n",
      "epoch 102; iter: 0; batch classifier loss: 0.346680; batch adversarial loss: 0.507166\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403296; batch adversarial loss: 0.535922\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365469; batch adversarial loss: 0.480062\n",
      "epoch 105; iter: 0; batch classifier loss: 0.421359; batch adversarial loss: 0.646350\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363666; batch adversarial loss: 0.572418\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386710; batch adversarial loss: 0.507701\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393091; batch adversarial loss: 0.636843\n",
      "epoch 109; iter: 0; batch classifier loss: 0.467637; batch adversarial loss: 0.553850\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384477; batch adversarial loss: 0.609559\n",
      "epoch 111; iter: 0; batch classifier loss: 0.349187; batch adversarial loss: 0.572415\n",
      "epoch 112; iter: 0; batch classifier loss: 0.458601; batch adversarial loss: 0.562451\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401182; batch adversarial loss: 0.535629\n",
      "epoch 114; iter: 0; batch classifier loss: 0.326091; batch adversarial loss: 0.626614\n",
      "epoch 115; iter: 0; batch classifier loss: 0.385460; batch adversarial loss: 0.581977\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339462; batch adversarial loss: 0.489220\n",
      "epoch 117; iter: 0; batch classifier loss: 0.439210; batch adversarial loss: 0.600532\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343524; batch adversarial loss: 0.525635\n",
      "epoch 119; iter: 0; batch classifier loss: 0.422201; batch adversarial loss: 0.507571\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408882; batch adversarial loss: 0.544785\n",
      "epoch 121; iter: 0; batch classifier loss: 0.359173; batch adversarial loss: 0.516730\n",
      "epoch 122; iter: 0; batch classifier loss: 0.440614; batch adversarial loss: 0.589965\n",
      "epoch 123; iter: 0; batch classifier loss: 0.413439; batch adversarial loss: 0.526378\n",
      "epoch 124; iter: 0; batch classifier loss: 0.315438; batch adversarial loss: 0.488922\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362417; batch adversarial loss: 0.589817\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353327; batch adversarial loss: 0.516808\n",
      "epoch 127; iter: 0; batch classifier loss: 0.326724; batch adversarial loss: 0.644585\n",
      "epoch 128; iter: 0; batch classifier loss: 0.380982; batch adversarial loss: 0.554128\n",
      "epoch 129; iter: 0; batch classifier loss: 0.296127; batch adversarial loss: 0.572237\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349265; batch adversarial loss: 0.590093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348543; batch adversarial loss: 0.553683\n",
      "epoch 132; iter: 0; batch classifier loss: 0.356097; batch adversarial loss: 0.581376\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370088; batch adversarial loss: 0.470327\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343081; batch adversarial loss: 0.487752\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373401; batch adversarial loss: 0.609898\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403352; batch adversarial loss: 0.499122\n",
      "epoch 137; iter: 0; batch classifier loss: 0.426000; batch adversarial loss: 0.543548\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414022; batch adversarial loss: 0.489438\n",
      "epoch 139; iter: 0; batch classifier loss: 0.292063; batch adversarial loss: 0.563555\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327539; batch adversarial loss: 0.470944\n",
      "epoch 141; iter: 0; batch classifier loss: 0.443584; batch adversarial loss: 0.571951\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375197; batch adversarial loss: 0.563286\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380828; batch adversarial loss: 0.553563\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381459; batch adversarial loss: 0.563663\n",
      "epoch 145; iter: 0; batch classifier loss: 0.392387; batch adversarial loss: 0.572384\n",
      "epoch 146; iter: 0; batch classifier loss: 0.387149; batch adversarial loss: 0.590601\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381902; batch adversarial loss: 0.543448\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328865; batch adversarial loss: 0.488259\n",
      "epoch 149; iter: 0; batch classifier loss: 0.455135; batch adversarial loss: 0.526880\n",
      "epoch 150; iter: 0; batch classifier loss: 0.318732; batch adversarial loss: 0.581117\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363069; batch adversarial loss: 0.525926\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355970; batch adversarial loss: 0.572480\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329877; batch adversarial loss: 0.517250\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345542; batch adversarial loss: 0.516226\n",
      "epoch 155; iter: 0; batch classifier loss: 0.322548; batch adversarial loss: 0.544662\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396325; batch adversarial loss: 0.572294\n",
      "epoch 157; iter: 0; batch classifier loss: 0.357954; batch adversarial loss: 0.535728\n",
      "epoch 158; iter: 0; batch classifier loss: 0.322930; batch adversarial loss: 0.517311\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374254; batch adversarial loss: 0.480232\n",
      "epoch 160; iter: 0; batch classifier loss: 0.362372; batch adversarial loss: 0.507931\n",
      "epoch 161; iter: 0; batch classifier loss: 0.308410; batch adversarial loss: 0.525443\n",
      "epoch 162; iter: 0; batch classifier loss: 0.349346; batch adversarial loss: 0.554453\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346253; batch adversarial loss: 0.580843\n",
      "epoch 164; iter: 0; batch classifier loss: 0.427794; batch adversarial loss: 0.488803\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365696; batch adversarial loss: 0.590831\n",
      "epoch 166; iter: 0; batch classifier loss: 0.362474; batch adversarial loss: 0.581296\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384703; batch adversarial loss: 0.526369\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322046; batch adversarial loss: 0.498466\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362381; batch adversarial loss: 0.534883\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368255; batch adversarial loss: 0.535249\n",
      "epoch 171; iter: 0; batch classifier loss: 0.361925; batch adversarial loss: 0.517124\n",
      "epoch 172; iter: 0; batch classifier loss: 0.298691; batch adversarial loss: 0.591325\n",
      "epoch 173; iter: 0; batch classifier loss: 0.453639; batch adversarial loss: 0.534134\n",
      "epoch 174; iter: 0; batch classifier loss: 0.293723; batch adversarial loss: 0.562179\n",
      "epoch 175; iter: 0; batch classifier loss: 0.384218; batch adversarial loss: 0.525886\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343279; batch adversarial loss: 0.619094\n",
      "epoch 177; iter: 0; batch classifier loss: 0.295813; batch adversarial loss: 0.544160\n",
      "epoch 178; iter: 0; batch classifier loss: 0.294291; batch adversarial loss: 0.516561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.261507; batch adversarial loss: 0.553104\n",
      "epoch 180; iter: 0; batch classifier loss: 0.409612; batch adversarial loss: 0.609448\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363534; batch adversarial loss: 0.517136\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381193; batch adversarial loss: 0.433869\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321426; batch adversarial loss: 0.544353\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383462; batch adversarial loss: 0.590436\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333124; batch adversarial loss: 0.572585\n",
      "epoch 186; iter: 0; batch classifier loss: 0.463051; batch adversarial loss: 0.563230\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340412; batch adversarial loss: 0.563450\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348351; batch adversarial loss: 0.618019\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368179; batch adversarial loss: 0.525945\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342269; batch adversarial loss: 0.582304\n",
      "epoch 191; iter: 0; batch classifier loss: 0.349429; batch adversarial loss: 0.508038\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305318; batch adversarial loss: 0.507072\n",
      "epoch 193; iter: 0; batch classifier loss: 0.323037; batch adversarial loss: 0.553586\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403870; batch adversarial loss: 0.498426\n",
      "epoch 195; iter: 0; batch classifier loss: 0.410381; batch adversarial loss: 0.571906\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381185; batch adversarial loss: 0.525368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.278006; batch adversarial loss: 0.572381\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404795; batch adversarial loss: 0.516790\n",
      "epoch 199; iter: 0; batch classifier loss: 0.321013; batch adversarial loss: 0.498902\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772667; batch adversarial loss: 0.791390\n",
      "epoch 1; iter: 0; batch classifier loss: 0.719708; batch adversarial loss: 0.740528\n",
      "epoch 2; iter: 0; batch classifier loss: 0.721666; batch adversarial loss: 0.693102\n",
      "epoch 3; iter: 0; batch classifier loss: 0.677929; batch adversarial loss: 0.644404\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523552; batch adversarial loss: 0.645315\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530691; batch adversarial loss: 0.632136\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555584; batch adversarial loss: 0.635082\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574663; batch adversarial loss: 0.606200\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553603; batch adversarial loss: 0.606876\n",
      "epoch 9; iter: 0; batch classifier loss: 0.478112; batch adversarial loss: 0.580807\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480102; batch adversarial loss: 0.568894\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493644; batch adversarial loss: 0.618983\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521450; batch adversarial loss: 0.594209\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483178; batch adversarial loss: 0.580373\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461286; batch adversarial loss: 0.519463\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527981; batch adversarial loss: 0.594506\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485435; batch adversarial loss: 0.542569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501671; batch adversarial loss: 0.580120\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478081; batch adversarial loss: 0.588890\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458239; batch adversarial loss: 0.579482\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506262; batch adversarial loss: 0.517726\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507325; batch adversarial loss: 0.569898\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483905; batch adversarial loss: 0.593569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458585; batch adversarial loss: 0.567408\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507081; batch adversarial loss: 0.533127\n",
      "epoch 25; iter: 0; batch classifier loss: 0.545615; batch adversarial loss: 0.605409\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500641; batch adversarial loss: 0.560476\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518301; batch adversarial loss: 0.599199\n",
      "epoch 28; iter: 0; batch classifier loss: 0.448821; batch adversarial loss: 0.595682\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454682; batch adversarial loss: 0.597445\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438698; batch adversarial loss: 0.546362\n",
      "epoch 31; iter: 0; batch classifier loss: 0.419596; batch adversarial loss: 0.531050\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458016; batch adversarial loss: 0.530552\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519161; batch adversarial loss: 0.503380\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445563; batch adversarial loss: 0.562361\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432621; batch adversarial loss: 0.527357\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490821; batch adversarial loss: 0.528184\n",
      "epoch 37; iter: 0; batch classifier loss: 0.369984; batch adversarial loss: 0.518966\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471718; batch adversarial loss: 0.597280\n",
      "epoch 39; iter: 0; batch classifier loss: 0.409757; batch adversarial loss: 0.632277\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367999; batch adversarial loss: 0.500865\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460764; batch adversarial loss: 0.491220\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400985; batch adversarial loss: 0.544263\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408836; batch adversarial loss: 0.543932\n",
      "epoch 44; iter: 0; batch classifier loss: 0.344872; batch adversarial loss: 0.571230\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430488; batch adversarial loss: 0.507154\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396628; batch adversarial loss: 0.542892\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416994; batch adversarial loss: 0.492370\n",
      "epoch 48; iter: 0; batch classifier loss: 0.369244; batch adversarial loss: 0.563045\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438862; batch adversarial loss: 0.515996\n",
      "epoch 50; iter: 0; batch classifier loss: 0.358680; batch adversarial loss: 0.544317\n",
      "epoch 51; iter: 0; batch classifier loss: 0.492185; batch adversarial loss: 0.574173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380863; batch adversarial loss: 0.463282\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424299; batch adversarial loss: 0.508473\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416502; batch adversarial loss: 0.510075\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386990; batch adversarial loss: 0.507553\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428315; batch adversarial loss: 0.592778\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408875; batch adversarial loss: 0.635100\n",
      "epoch 58; iter: 0; batch classifier loss: 0.385346; batch adversarial loss: 0.536295\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378948; batch adversarial loss: 0.460314\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452899; batch adversarial loss: 0.510329\n",
      "epoch 61; iter: 0; batch classifier loss: 0.368613; batch adversarial loss: 0.533934\n",
      "epoch 62; iter: 0; batch classifier loss: 0.437462; batch adversarial loss: 0.497118\n",
      "epoch 63; iter: 0; batch classifier loss: 0.366661; batch adversarial loss: 0.541253\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413711; batch adversarial loss: 0.534032\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388936; batch adversarial loss: 0.571832\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385508; batch adversarial loss: 0.559002\n",
      "epoch 67; iter: 0; batch classifier loss: 0.440509; batch adversarial loss: 0.541556\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408478; batch adversarial loss: 0.476594\n",
      "epoch 69; iter: 0; batch classifier loss: 0.380491; batch adversarial loss: 0.479889\n",
      "epoch 70; iter: 0; batch classifier loss: 0.395565; batch adversarial loss: 0.431789\n",
      "epoch 71; iter: 0; batch classifier loss: 0.367347; batch adversarial loss: 0.534543\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432645; batch adversarial loss: 0.542609\n",
      "epoch 73; iter: 0; batch classifier loss: 0.360177; batch adversarial loss: 0.525203\n",
      "epoch 74; iter: 0; batch classifier loss: 0.352116; batch adversarial loss: 0.555407\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387184; batch adversarial loss: 0.527266\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391869; batch adversarial loss: 0.515580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.381980; batch adversarial loss: 0.553935\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413689; batch adversarial loss: 0.579552\n",
      "epoch 79; iter: 0; batch classifier loss: 0.330215; batch adversarial loss: 0.578156\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387855; batch adversarial loss: 0.532740\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422419; batch adversarial loss: 0.540273\n",
      "epoch 82; iter: 0; batch classifier loss: 0.442745; batch adversarial loss: 0.521835\n",
      "epoch 83; iter: 0; batch classifier loss: 0.349710; batch adversarial loss: 0.539733\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368329; batch adversarial loss: 0.583305\n",
      "epoch 85; iter: 0; batch classifier loss: 0.339362; batch adversarial loss: 0.513519\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401307; batch adversarial loss: 0.553753\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433858; batch adversarial loss: 0.606410\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392538; batch adversarial loss: 0.556614\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411520; batch adversarial loss: 0.513298\n",
      "epoch 90; iter: 0; batch classifier loss: 0.421271; batch adversarial loss: 0.565358\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414170; batch adversarial loss: 0.528773\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398894; batch adversarial loss: 0.560447\n",
      "epoch 93; iter: 0; batch classifier loss: 0.294111; batch adversarial loss: 0.534611\n",
      "epoch 94; iter: 0; batch classifier loss: 0.349662; batch adversarial loss: 0.525485\n",
      "epoch 95; iter: 0; batch classifier loss: 0.482816; batch adversarial loss: 0.571053\n",
      "epoch 96; iter: 0; batch classifier loss: 0.415116; batch adversarial loss: 0.444088\n",
      "epoch 97; iter: 0; batch classifier loss: 0.353029; batch adversarial loss: 0.470074\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395870; batch adversarial loss: 0.599958\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359168; batch adversarial loss: 0.626120\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399841; batch adversarial loss: 0.601580\n",
      "epoch 101; iter: 0; batch classifier loss: 0.380843; batch adversarial loss: 0.527443\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340153; batch adversarial loss: 0.517991\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412493; batch adversarial loss: 0.592462\n",
      "epoch 104; iter: 0; batch classifier loss: 0.303450; batch adversarial loss: 0.581144\n",
      "epoch 105; iter: 0; batch classifier loss: 0.377215; batch adversarial loss: 0.536532\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383740; batch adversarial loss: 0.521313\n",
      "epoch 107; iter: 0; batch classifier loss: 0.417837; batch adversarial loss: 0.563270\n",
      "epoch 108; iter: 0; batch classifier loss: 0.436746; batch adversarial loss: 0.545279\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364861; batch adversarial loss: 0.501409\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349699; batch adversarial loss: 0.599005\n",
      "epoch 111; iter: 0; batch classifier loss: 0.445962; batch adversarial loss: 0.572976\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359147; batch adversarial loss: 0.556064\n",
      "epoch 113; iter: 0; batch classifier loss: 0.325999; batch adversarial loss: 0.590887\n",
      "epoch 114; iter: 0; batch classifier loss: 0.431958; batch adversarial loss: 0.595213\n",
      "epoch 115; iter: 0; batch classifier loss: 0.402188; batch adversarial loss: 0.559819\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369987; batch adversarial loss: 0.444561\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325018; batch adversarial loss: 0.572195\n",
      "epoch 118; iter: 0; batch classifier loss: 0.327339; batch adversarial loss: 0.581483\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386347; batch adversarial loss: 0.580168\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388013; batch adversarial loss: 0.546797\n",
      "epoch 121; iter: 0; batch classifier loss: 0.321388; batch adversarial loss: 0.568088\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378934; batch adversarial loss: 0.461225\n",
      "epoch 123; iter: 0; batch classifier loss: 0.448212; batch adversarial loss: 0.508124\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376040; batch adversarial loss: 0.558073\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394420; batch adversarial loss: 0.580811\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334607; batch adversarial loss: 0.557889\n",
      "epoch 127; iter: 0; batch classifier loss: 0.441560; batch adversarial loss: 0.511674\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340175; batch adversarial loss: 0.534378\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337482; batch adversarial loss: 0.534318\n",
      "epoch 130; iter: 0; batch classifier loss: 0.312533; batch adversarial loss: 0.534343\n",
      "epoch 131; iter: 0; batch classifier loss: 0.309640; batch adversarial loss: 0.666131\n",
      "epoch 132; iter: 0; batch classifier loss: 0.324295; batch adversarial loss: 0.572065\n",
      "epoch 133; iter: 0; batch classifier loss: 0.405484; batch adversarial loss: 0.526538\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339632; batch adversarial loss: 0.497485\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320127; batch adversarial loss: 0.529531\n",
      "epoch 136; iter: 0; batch classifier loss: 0.310581; batch adversarial loss: 0.487525\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386610; batch adversarial loss: 0.503190\n",
      "epoch 138; iter: 0; batch classifier loss: 0.421289; batch adversarial loss: 0.536933\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344186; batch adversarial loss: 0.492730\n",
      "epoch 140; iter: 0; batch classifier loss: 0.302383; batch adversarial loss: 0.497616\n",
      "epoch 141; iter: 0; batch classifier loss: 0.370558; batch adversarial loss: 0.505315\n",
      "epoch 142; iter: 0; batch classifier loss: 0.332749; batch adversarial loss: 0.645371\n",
      "epoch 143; iter: 0; batch classifier loss: 0.284083; batch adversarial loss: 0.539672\n",
      "epoch 144; iter: 0; batch classifier loss: 0.326773; batch adversarial loss: 0.541007\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363301; batch adversarial loss: 0.512556\n",
      "epoch 146; iter: 0; batch classifier loss: 0.479546; batch adversarial loss: 0.548393\n",
      "epoch 147; iter: 0; batch classifier loss: 0.294301; batch adversarial loss: 0.516298\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364120; batch adversarial loss: 0.533762\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349606; batch adversarial loss: 0.490454\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356765; batch adversarial loss: 0.506531\n",
      "epoch 151; iter: 0; batch classifier loss: 0.317964; batch adversarial loss: 0.555261\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365233; batch adversarial loss: 0.458390\n",
      "epoch 153; iter: 0; batch classifier loss: 0.347317; batch adversarial loss: 0.549404\n",
      "epoch 154; iter: 0; batch classifier loss: 0.306833; batch adversarial loss: 0.568998\n",
      "epoch 155; iter: 0; batch classifier loss: 0.301757; batch adversarial loss: 0.544863\n",
      "epoch 156; iter: 0; batch classifier loss: 0.327208; batch adversarial loss: 0.527935\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360180; batch adversarial loss: 0.554777\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365371; batch adversarial loss: 0.538637\n",
      "epoch 159; iter: 0; batch classifier loss: 0.307100; batch adversarial loss: 0.518595\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358712; batch adversarial loss: 0.534147\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383724; batch adversarial loss: 0.592870\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313936; batch adversarial loss: 0.528050\n",
      "epoch 163; iter: 0; batch classifier loss: 0.324293; batch adversarial loss: 0.534759\n",
      "epoch 164; iter: 0; batch classifier loss: 0.419952; batch adversarial loss: 0.525618\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366974; batch adversarial loss: 0.608487\n",
      "epoch 166; iter: 0; batch classifier loss: 0.393674; batch adversarial loss: 0.512392\n",
      "epoch 167; iter: 0; batch classifier loss: 0.392019; batch adversarial loss: 0.531165\n",
      "epoch 168; iter: 0; batch classifier loss: 0.355744; batch adversarial loss: 0.536703\n",
      "epoch 169; iter: 0; batch classifier loss: 0.445316; batch adversarial loss: 0.608555\n",
      "epoch 170; iter: 0; batch classifier loss: 0.375397; batch adversarial loss: 0.544534\n",
      "epoch 171; iter: 0; batch classifier loss: 0.280009; batch adversarial loss: 0.534141\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387930; batch adversarial loss: 0.605708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.292535; batch adversarial loss: 0.515820\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344305; batch adversarial loss: 0.610098\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366015; batch adversarial loss: 0.545601\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356498; batch adversarial loss: 0.631036\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314787; batch adversarial loss: 0.440120\n",
      "epoch 178; iter: 0; batch classifier loss: 0.274332; batch adversarial loss: 0.443063\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347890; batch adversarial loss: 0.561391\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340542; batch adversarial loss: 0.517552\n",
      "epoch 181; iter: 0; batch classifier loss: 0.352440; batch adversarial loss: 0.508317\n",
      "epoch 182; iter: 0; batch classifier loss: 0.245635; batch adversarial loss: 0.613905\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358026; batch adversarial loss: 0.533920\n",
      "epoch 184; iter: 0; batch classifier loss: 0.333379; batch adversarial loss: 0.499302\n",
      "epoch 185; iter: 0; batch classifier loss: 0.292910; batch adversarial loss: 0.515591\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377347; batch adversarial loss: 0.600845\n",
      "epoch 187; iter: 0; batch classifier loss: 0.283014; batch adversarial loss: 0.506804\n",
      "epoch 188; iter: 0; batch classifier loss: 0.270090; batch adversarial loss: 0.541626\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354024; batch adversarial loss: 0.473465\n",
      "epoch 190; iter: 0; batch classifier loss: 0.363645; batch adversarial loss: 0.508768\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365486; batch adversarial loss: 0.528617\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340936; batch adversarial loss: 0.475849\n",
      "epoch 193; iter: 0; batch classifier loss: 0.412769; batch adversarial loss: 0.552017\n",
      "epoch 194; iter: 0; batch classifier loss: 0.352026; batch adversarial loss: 0.575036\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350650; batch adversarial loss: 0.553754\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359549; batch adversarial loss: 0.558744\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337219; batch adversarial loss: 0.541968\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336043; batch adversarial loss: 0.490774\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364320; batch adversarial loss: 0.520352\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662332; batch adversarial loss: 0.710691\n",
      "epoch 1; iter: 0; batch classifier loss: 0.569362; batch adversarial loss: 0.710051\n",
      "epoch 2; iter: 0; batch classifier loss: 0.620455; batch adversarial loss: 0.675142\n",
      "epoch 3; iter: 0; batch classifier loss: 0.529580; batch adversarial loss: 0.652677\n",
      "epoch 4; iter: 0; batch classifier loss: 0.526283; batch adversarial loss: 0.632153\n",
      "epoch 5; iter: 0; batch classifier loss: 0.653705; batch adversarial loss: 0.636720\n",
      "epoch 6; iter: 0; batch classifier loss: 0.526507; batch adversarial loss: 0.571240\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509098; batch adversarial loss: 0.594964\n",
      "epoch 8; iter: 0; batch classifier loss: 0.489906; batch adversarial loss: 0.559840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552487; batch adversarial loss: 0.555640\n",
      "epoch 10; iter: 0; batch classifier loss: 0.608105; batch adversarial loss: 0.514621\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511603; batch adversarial loss: 0.628165\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504415; batch adversarial loss: 0.598535\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526656; batch adversarial loss: 0.553496\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533767; batch adversarial loss: 0.570123\n",
      "epoch 15; iter: 0; batch classifier loss: 0.456252; batch adversarial loss: 0.598062\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506408; batch adversarial loss: 0.564451\n",
      "epoch 17; iter: 0; batch classifier loss: 0.570754; batch adversarial loss: 0.609439\n",
      "epoch 18; iter: 0; batch classifier loss: 0.480653; batch adversarial loss: 0.508515\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530886; batch adversarial loss: 0.561860\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530682; batch adversarial loss: 0.587672\n",
      "epoch 21; iter: 0; batch classifier loss: 0.446544; batch adversarial loss: 0.552543\n",
      "epoch 22; iter: 0; batch classifier loss: 0.408103; batch adversarial loss: 0.568783\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471380; batch adversarial loss: 0.548623\n",
      "epoch 24; iter: 0; batch classifier loss: 0.450588; batch adversarial loss: 0.620221\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495056; batch adversarial loss: 0.611517\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432626; batch adversarial loss: 0.487373\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457282; batch adversarial loss: 0.555174\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465945; batch adversarial loss: 0.514312\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466899; batch adversarial loss: 0.594006\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477002; batch adversarial loss: 0.560927\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448891; batch adversarial loss: 0.503093\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488261; batch adversarial loss: 0.451722\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433616; batch adversarial loss: 0.501045\n",
      "epoch 34; iter: 0; batch classifier loss: 0.524858; batch adversarial loss: 0.545176\n",
      "epoch 35; iter: 0; batch classifier loss: 0.428802; batch adversarial loss: 0.572070\n",
      "epoch 36; iter: 0; batch classifier loss: 0.384271; batch adversarial loss: 0.542980\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450619; batch adversarial loss: 0.508516\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461043; batch adversarial loss: 0.509240\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460293; batch adversarial loss: 0.572070\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425981; batch adversarial loss: 0.535780\n",
      "epoch 41; iter: 0; batch classifier loss: 0.455270; batch adversarial loss: 0.562187\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408781; batch adversarial loss: 0.535257\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420418; batch adversarial loss: 0.535651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422897; batch adversarial loss: 0.479769\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398595; batch adversarial loss: 0.646865\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426055; batch adversarial loss: 0.507640\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447951; batch adversarial loss: 0.479543\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392630; batch adversarial loss: 0.636814\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436296; batch adversarial loss: 0.489398\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469951; batch adversarial loss: 0.562709\n",
      "epoch 51; iter: 0; batch classifier loss: 0.558572; batch adversarial loss: 0.489041\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444290; batch adversarial loss: 0.553901\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412180; batch adversarial loss: 0.544675\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454193; batch adversarial loss: 0.469776\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406024; batch adversarial loss: 0.535564\n",
      "epoch 56; iter: 0; batch classifier loss: 0.370943; batch adversarial loss: 0.554205\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445741; batch adversarial loss: 0.507377\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458756; batch adversarial loss: 0.488136\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464010; batch adversarial loss: 0.535317\n",
      "epoch 60; iter: 0; batch classifier loss: 0.448314; batch adversarial loss: 0.581550\n",
      "epoch 61; iter: 0; batch classifier loss: 0.499590; batch adversarial loss: 0.488369\n",
      "epoch 62; iter: 0; batch classifier loss: 0.449636; batch adversarial loss: 0.525240\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371517; batch adversarial loss: 0.572189\n",
      "epoch 64; iter: 0; batch classifier loss: 0.493902; batch adversarial loss: 0.590671\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430782; batch adversarial loss: 0.526295\n",
      "epoch 66; iter: 0; batch classifier loss: 0.484416; batch adversarial loss: 0.554057\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403662; batch adversarial loss: 0.470433\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439226; batch adversarial loss: 0.609466\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406306; batch adversarial loss: 0.488726\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383892; batch adversarial loss: 0.600467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.367310; batch adversarial loss: 0.562934\n",
      "epoch 72; iter: 0; batch classifier loss: 0.409237; batch adversarial loss: 0.544706\n",
      "epoch 73; iter: 0; batch classifier loss: 0.451778; batch adversarial loss: 0.516553\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444454; batch adversarial loss: 0.600335\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354198; batch adversarial loss: 0.516504\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413933; batch adversarial loss: 0.581892\n",
      "epoch 77; iter: 0; batch classifier loss: 0.364056; batch adversarial loss: 0.562429\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428782; batch adversarial loss: 0.545259\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384316; batch adversarial loss: 0.526764\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426670; batch adversarial loss: 0.535668\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403881; batch adversarial loss: 0.572698\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412112; batch adversarial loss: 0.516557\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387350; batch adversarial loss: 0.553609\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395878; batch adversarial loss: 0.506793\n",
      "epoch 85; iter: 0; batch classifier loss: 0.293111; batch adversarial loss: 0.516692\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380287; batch adversarial loss: 0.498191\n",
      "epoch 87; iter: 0; batch classifier loss: 0.444809; batch adversarial loss: 0.470692\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360143; batch adversarial loss: 0.479205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397667; batch adversarial loss: 0.543958\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353336; batch adversarial loss: 0.535314\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394815; batch adversarial loss: 0.581568\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405951; batch adversarial loss: 0.563491\n",
      "epoch 93; iter: 0; batch classifier loss: 0.466767; batch adversarial loss: 0.488634\n",
      "epoch 94; iter: 0; batch classifier loss: 0.398668; batch adversarial loss: 0.563271\n",
      "epoch 95; iter: 0; batch classifier loss: 0.456547; batch adversarial loss: 0.590422\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405143; batch adversarial loss: 0.553164\n",
      "epoch 97; iter: 0; batch classifier loss: 0.435154; batch adversarial loss: 0.535586\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406061; batch adversarial loss: 0.516085\n",
      "epoch 99; iter: 0; batch classifier loss: 0.473090; batch adversarial loss: 0.572759\n",
      "epoch 100; iter: 0; batch classifier loss: 0.444798; batch adversarial loss: 0.553566\n",
      "epoch 101; iter: 0; batch classifier loss: 0.425891; batch adversarial loss: 0.525658\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400674; batch adversarial loss: 0.571833\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413775; batch adversarial loss: 0.498594\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361985; batch adversarial loss: 0.553579\n",
      "epoch 105; iter: 0; batch classifier loss: 0.333987; batch adversarial loss: 0.600667\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369641; batch adversarial loss: 0.497527\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362983; batch adversarial loss: 0.488233\n",
      "epoch 108; iter: 0; batch classifier loss: 0.347549; batch adversarial loss: 0.692148\n",
      "epoch 109; iter: 0; batch classifier loss: 0.340622; batch adversarial loss: 0.516741\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381839; batch adversarial loss: 0.582641\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347477; batch adversarial loss: 0.590807\n",
      "epoch 112; iter: 0; batch classifier loss: 0.427148; batch adversarial loss: 0.562950\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382558; batch adversarial loss: 0.590845\n",
      "epoch 114; iter: 0; batch classifier loss: 0.355523; batch adversarial loss: 0.572221\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381982; batch adversarial loss: 0.571963\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388436; batch adversarial loss: 0.544654\n",
      "epoch 117; iter: 0; batch classifier loss: 0.324466; batch adversarial loss: 0.516941\n",
      "epoch 118; iter: 0; batch classifier loss: 0.407301; batch adversarial loss: 0.516112\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349908; batch adversarial loss: 0.571919\n",
      "epoch 120; iter: 0; batch classifier loss: 0.327214; batch adversarial loss: 0.516723\n",
      "epoch 121; iter: 0; batch classifier loss: 0.416369; batch adversarial loss: 0.572624\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364553; batch adversarial loss: 0.553319\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372049; batch adversarial loss: 0.609422\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368512; batch adversarial loss: 0.544607\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382739; batch adversarial loss: 0.516386\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403933; batch adversarial loss: 0.582143\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389494; batch adversarial loss: 0.525309\n",
      "epoch 128; iter: 0; batch classifier loss: 0.430846; batch adversarial loss: 0.554403\n",
      "epoch 129; iter: 0; batch classifier loss: 0.439602; batch adversarial loss: 0.572618\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371550; batch adversarial loss: 0.572327\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349345; batch adversarial loss: 0.544438\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340129; batch adversarial loss: 0.525555\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386457; batch adversarial loss: 0.582021\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365927; batch adversarial loss: 0.534946\n",
      "epoch 135; iter: 0; batch classifier loss: 0.319675; batch adversarial loss: 0.656082\n",
      "epoch 136; iter: 0; batch classifier loss: 0.318762; batch adversarial loss: 0.581358\n",
      "epoch 137; iter: 0; batch classifier loss: 0.380483; batch adversarial loss: 0.535087\n",
      "epoch 138; iter: 0; batch classifier loss: 0.333113; batch adversarial loss: 0.535443\n",
      "epoch 139; iter: 0; batch classifier loss: 0.305591; batch adversarial loss: 0.525529\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387398; batch adversarial loss: 0.581649\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342855; batch adversarial loss: 0.590198\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383980; batch adversarial loss: 0.534520\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350603; batch adversarial loss: 0.525863\n",
      "epoch 144; iter: 0; batch classifier loss: 0.431384; batch adversarial loss: 0.506796\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353784; batch adversarial loss: 0.544409\n",
      "epoch 146; iter: 0; batch classifier loss: 0.472683; batch adversarial loss: 0.561461\n",
      "epoch 147; iter: 0; batch classifier loss: 0.367517; batch adversarial loss: 0.581531\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410733; batch adversarial loss: 0.544962\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323780; batch adversarial loss: 0.545063\n",
      "epoch 150; iter: 0; batch classifier loss: 0.357224; batch adversarial loss: 0.507459\n",
      "epoch 151; iter: 0; batch classifier loss: 0.305677; batch adversarial loss: 0.609832\n",
      "epoch 152; iter: 0; batch classifier loss: 0.317558; batch adversarial loss: 0.563224\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353304; batch adversarial loss: 0.525323\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357731; batch adversarial loss: 0.591839\n",
      "epoch 155; iter: 0; batch classifier loss: 0.436952; batch adversarial loss: 0.516420\n",
      "epoch 156; iter: 0; batch classifier loss: 0.343100; batch adversarial loss: 0.673968\n",
      "epoch 157; iter: 0; batch classifier loss: 0.343233; batch adversarial loss: 0.489035\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364217; batch adversarial loss: 0.535028\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375347; batch adversarial loss: 0.618602\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377096; batch adversarial loss: 0.507537\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392963; batch adversarial loss: 0.452661\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326509; batch adversarial loss: 0.636356\n",
      "epoch 163; iter: 0; batch classifier loss: 0.439697; batch adversarial loss: 0.562660\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352440; batch adversarial loss: 0.543639\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410170; batch adversarial loss: 0.488590\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333607; batch adversarial loss: 0.563442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.361814; batch adversarial loss: 0.572560\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335694; batch adversarial loss: 0.590537\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380407; batch adversarial loss: 0.479733\n",
      "epoch 170; iter: 0; batch classifier loss: 0.331356; batch adversarial loss: 0.525555\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384725; batch adversarial loss: 0.554421\n",
      "epoch 172; iter: 0; batch classifier loss: 0.432747; batch adversarial loss: 0.526428\n",
      "epoch 173; iter: 0; batch classifier loss: 0.314393; batch adversarial loss: 0.638754\n",
      "epoch 174; iter: 0; batch classifier loss: 0.409790; batch adversarial loss: 0.544528\n",
      "epoch 175; iter: 0; batch classifier loss: 0.438925; batch adversarial loss: 0.581827\n",
      "epoch 176; iter: 0; batch classifier loss: 0.288609; batch adversarial loss: 0.498909\n",
      "epoch 177; iter: 0; batch classifier loss: 0.331585; batch adversarial loss: 0.508069\n",
      "epoch 178; iter: 0; batch classifier loss: 0.424076; batch adversarial loss: 0.554065\n",
      "epoch 179; iter: 0; batch classifier loss: 0.376844; batch adversarial loss: 0.581249\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322263; batch adversarial loss: 0.553633\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319002; batch adversarial loss: 0.563203\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391770; batch adversarial loss: 0.535367\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354489; batch adversarial loss: 0.572073\n",
      "epoch 184; iter: 0; batch classifier loss: 0.417483; batch adversarial loss: 0.562822\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351777; batch adversarial loss: 0.543150\n",
      "epoch 186; iter: 0; batch classifier loss: 0.337392; batch adversarial loss: 0.516949\n",
      "epoch 187; iter: 0; batch classifier loss: 0.308888; batch adversarial loss: 0.573007\n",
      "epoch 188; iter: 0; batch classifier loss: 0.433802; batch adversarial loss: 0.516516\n",
      "epoch 189; iter: 0; batch classifier loss: 0.400459; batch adversarial loss: 0.544793\n",
      "epoch 190; iter: 0; batch classifier loss: 0.490729; batch adversarial loss: 0.526538\n",
      "epoch 191; iter: 0; batch classifier loss: 0.406483; batch adversarial loss: 0.609022\n",
      "epoch 192; iter: 0; batch classifier loss: 0.374130; batch adversarial loss: 0.479065\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308366; batch adversarial loss: 0.553465\n",
      "epoch 194; iter: 0; batch classifier loss: 0.319501; batch adversarial loss: 0.609705\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393632; batch adversarial loss: 0.498102\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387404; batch adversarial loss: 0.554491\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358221; batch adversarial loss: 0.553859\n",
      "epoch 198; iter: 0; batch classifier loss: 0.295054; batch adversarial loss: 0.535087\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350051; batch adversarial loss: 0.497977\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669907; batch adversarial loss: 0.598296\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608334; batch adversarial loss: 0.639888\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595587; batch adversarial loss: 0.641761\n",
      "epoch 3; iter: 0; batch classifier loss: 0.533653; batch adversarial loss: 0.658851\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544051; batch adversarial loss: 0.614724\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571582; batch adversarial loss: 0.646994\n",
      "epoch 6; iter: 0; batch classifier loss: 0.631967; batch adversarial loss: 0.659800\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535791; batch adversarial loss: 0.602046\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570288; batch adversarial loss: 0.576080\n",
      "epoch 9; iter: 0; batch classifier loss: 0.666476; batch adversarial loss: 0.658273\n",
      "epoch 10; iter: 0; batch classifier loss: 0.631258; batch adversarial loss: 0.592605\n",
      "epoch 11; iter: 0; batch classifier loss: 0.483257; batch adversarial loss: 0.595889\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530902; batch adversarial loss: 0.631305\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521022; batch adversarial loss: 0.555906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509437; batch adversarial loss: 0.548653\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533000; batch adversarial loss: 0.572262\n",
      "epoch 16; iter: 0; batch classifier loss: 0.524194; batch adversarial loss: 0.582717\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510864; batch adversarial loss: 0.567863\n",
      "epoch 18; iter: 0; batch classifier loss: 0.459795; batch adversarial loss: 0.652440\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502799; batch adversarial loss: 0.642428\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482166; batch adversarial loss: 0.503576\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492420; batch adversarial loss: 0.581807\n",
      "epoch 22; iter: 0; batch classifier loss: 0.505965; batch adversarial loss: 0.479878\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466356; batch adversarial loss: 0.637140\n",
      "epoch 24; iter: 0; batch classifier loss: 0.546190; batch adversarial loss: 0.622517\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503991; batch adversarial loss: 0.556207\n",
      "epoch 26; iter: 0; batch classifier loss: 0.633447; batch adversarial loss: 0.572685\n",
      "epoch 27; iter: 0; batch classifier loss: 0.555816; batch adversarial loss: 0.647266\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456357; batch adversarial loss: 0.528873\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467170; batch adversarial loss: 0.605868\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467734; batch adversarial loss: 0.546565\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467780; batch adversarial loss: 0.554331\n",
      "epoch 32; iter: 0; batch classifier loss: 0.383762; batch adversarial loss: 0.573087\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480690; batch adversarial loss: 0.555018\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466216; batch adversarial loss: 0.572344\n",
      "epoch 35; iter: 0; batch classifier loss: 0.495993; batch adversarial loss: 0.571621\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366428; batch adversarial loss: 0.518061\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450583; batch adversarial loss: 0.517499\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444401; batch adversarial loss: 0.571412\n",
      "epoch 39; iter: 0; batch classifier loss: 0.412297; batch adversarial loss: 0.509597\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467450; batch adversarial loss: 0.525893\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427373; batch adversarial loss: 0.545867\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420953; batch adversarial loss: 0.597714\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383939; batch adversarial loss: 0.536674\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500595; batch adversarial loss: 0.563756\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415051; batch adversarial loss: 0.544954\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382168; batch adversarial loss: 0.477778\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424152; batch adversarial loss: 0.609196\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428048; batch adversarial loss: 0.588782\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382551; batch adversarial loss: 0.564337\n",
      "epoch 50; iter: 0; batch classifier loss: 0.484936; batch adversarial loss: 0.553987\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447238; batch adversarial loss: 0.562424\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448672; batch adversarial loss: 0.526897\n",
      "epoch 53; iter: 0; batch classifier loss: 0.434441; batch adversarial loss: 0.472805\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434433; batch adversarial loss: 0.598695\n",
      "epoch 55; iter: 0; batch classifier loss: 0.369751; batch adversarial loss: 0.562556\n",
      "epoch 56; iter: 0; batch classifier loss: 0.506872; batch adversarial loss: 0.553552\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446633; batch adversarial loss: 0.553470\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443753; batch adversarial loss: 0.471203\n",
      "epoch 59; iter: 0; batch classifier loss: 0.343827; batch adversarial loss: 0.517323\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431749; batch adversarial loss: 0.526191\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409830; batch adversarial loss: 0.673028\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428058; batch adversarial loss: 0.480240\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408327; batch adversarial loss: 0.590212\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380020; batch adversarial loss: 0.526307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.440579; batch adversarial loss: 0.571912\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454953; batch adversarial loss: 0.599263\n",
      "epoch 67; iter: 0; batch classifier loss: 0.441714; batch adversarial loss: 0.535564\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373547; batch adversarial loss: 0.553770\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405755; batch adversarial loss: 0.572154\n",
      "epoch 70; iter: 0; batch classifier loss: 0.371500; batch adversarial loss: 0.572009\n",
      "epoch 71; iter: 0; batch classifier loss: 0.371459; batch adversarial loss: 0.572102\n",
      "epoch 72; iter: 0; batch classifier loss: 0.521726; batch adversarial loss: 0.553676\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379684; batch adversarial loss: 0.498754\n",
      "epoch 74; iter: 0; batch classifier loss: 0.431022; batch adversarial loss: 0.508179\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396166; batch adversarial loss: 0.553577\n",
      "epoch 76; iter: 0; batch classifier loss: 0.338080; batch adversarial loss: 0.562585\n",
      "epoch 77; iter: 0; batch classifier loss: 0.447536; batch adversarial loss: 0.617491\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371625; batch adversarial loss: 0.589912\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391515; batch adversarial loss: 0.535025\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421916; batch adversarial loss: 0.544602\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432136; batch adversarial loss: 0.646042\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404436; batch adversarial loss: 0.563274\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422579; batch adversarial loss: 0.506964\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421607; batch adversarial loss: 0.543802\n",
      "epoch 85; iter: 0; batch classifier loss: 0.328503; batch adversarial loss: 0.507282\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368110; batch adversarial loss: 0.516424\n",
      "epoch 87; iter: 0; batch classifier loss: 0.408353; batch adversarial loss: 0.562886\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391707; batch adversarial loss: 0.608921\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379730; batch adversarial loss: 0.562938\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443053; batch adversarial loss: 0.505766\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399167; batch adversarial loss: 0.599198\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389507; batch adversarial loss: 0.497873\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422814; batch adversarial loss: 0.508214\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381510; batch adversarial loss: 0.518589\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402616; batch adversarial loss: 0.589600\n",
      "epoch 96; iter: 0; batch classifier loss: 0.357083; batch adversarial loss: 0.462980\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394110; batch adversarial loss: 0.599750\n",
      "epoch 98; iter: 0; batch classifier loss: 0.462959; batch adversarial loss: 0.508129\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356717; batch adversarial loss: 0.599534\n",
      "epoch 100; iter: 0; batch classifier loss: 0.380209; batch adversarial loss: 0.553379\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413721; batch adversarial loss: 0.627581\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416679; batch adversarial loss: 0.544824\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407016; batch adversarial loss: 0.508162\n",
      "epoch 104; iter: 0; batch classifier loss: 0.327249; batch adversarial loss: 0.571312\n",
      "epoch 105; iter: 0; batch classifier loss: 0.328656; batch adversarial loss: 0.535573\n",
      "epoch 106; iter: 0; batch classifier loss: 0.492111; batch adversarial loss: 0.563003\n",
      "epoch 107; iter: 0; batch classifier loss: 0.446558; batch adversarial loss: 0.507440\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387009; batch adversarial loss: 0.599733\n",
      "epoch 109; iter: 0; batch classifier loss: 0.435261; batch adversarial loss: 0.562683\n",
      "epoch 110; iter: 0; batch classifier loss: 0.439314; batch adversarial loss: 0.479855\n",
      "epoch 111; iter: 0; batch classifier loss: 0.435902; batch adversarial loss: 0.581161\n",
      "epoch 112; iter: 0; batch classifier loss: 0.421990; batch adversarial loss: 0.552766\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387873; batch adversarial loss: 0.580022\n",
      "epoch 114; iter: 0; batch classifier loss: 0.356696; batch adversarial loss: 0.507222\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388798; batch adversarial loss: 0.562461\n",
      "epoch 116; iter: 0; batch classifier loss: 0.298577; batch adversarial loss: 0.554746\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367294; batch adversarial loss: 0.543789\n",
      "epoch 118; iter: 0; batch classifier loss: 0.460452; batch adversarial loss: 0.524584\n",
      "epoch 119; iter: 0; batch classifier loss: 0.432150; batch adversarial loss: 0.561879\n",
      "epoch 120; iter: 0; batch classifier loss: 0.403972; batch adversarial loss: 0.487169\n",
      "epoch 121; iter: 0; batch classifier loss: 0.354934; batch adversarial loss: 0.499499\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380890; batch adversarial loss: 0.644960\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336116; batch adversarial loss: 0.497841\n",
      "epoch 124; iter: 0; batch classifier loss: 0.383782; batch adversarial loss: 0.543521\n",
      "epoch 125; iter: 0; batch classifier loss: 0.405237; batch adversarial loss: 0.609245\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360045; batch adversarial loss: 0.601985\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385920; batch adversarial loss: 0.553771\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377156; batch adversarial loss: 0.628321\n",
      "epoch 129; iter: 0; batch classifier loss: 0.346950; batch adversarial loss: 0.472512\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391198; batch adversarial loss: 0.516923\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375165; batch adversarial loss: 0.526480\n",
      "epoch 132; iter: 0; batch classifier loss: 0.448712; batch adversarial loss: 0.562903\n",
      "epoch 133; iter: 0; batch classifier loss: 0.456840; batch adversarial loss: 0.554700\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358751; batch adversarial loss: 0.480277\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371296; batch adversarial loss: 0.461196\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369316; batch adversarial loss: 0.553038\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372582; batch adversarial loss: 0.598397\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346913; batch adversarial loss: 0.555217\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366132; batch adversarial loss: 0.508182\n",
      "epoch 140; iter: 0; batch classifier loss: 0.419119; batch adversarial loss: 0.580791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.320452; batch adversarial loss: 0.618284\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346067; batch adversarial loss: 0.416955\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373487; batch adversarial loss: 0.564285\n",
      "epoch 144; iter: 0; batch classifier loss: 0.400869; batch adversarial loss: 0.570878\n",
      "epoch 145; iter: 0; batch classifier loss: 0.447532; batch adversarial loss: 0.527021\n",
      "epoch 146; iter: 0; batch classifier loss: 0.472715; batch adversarial loss: 0.541983\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381003; batch adversarial loss: 0.580672\n",
      "epoch 148; iter: 0; batch classifier loss: 0.423151; batch adversarial loss: 0.553904\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350561; batch adversarial loss: 0.552619\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367302; batch adversarial loss: 0.562888\n",
      "epoch 151; iter: 0; batch classifier loss: 0.427769; batch adversarial loss: 0.554790\n",
      "epoch 152; iter: 0; batch classifier loss: 0.318664; batch adversarial loss: 0.581510\n",
      "epoch 153; iter: 0; batch classifier loss: 0.323756; batch adversarial loss: 0.507348\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382661; batch adversarial loss: 0.517783\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314642; batch adversarial loss: 0.599037\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395199; batch adversarial loss: 0.627168\n",
      "epoch 157; iter: 0; batch classifier loss: 0.386916; batch adversarial loss: 0.499936\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384865; batch adversarial loss: 0.618464\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373653; batch adversarial loss: 0.526233\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373245; batch adversarial loss: 0.534677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.427684; batch adversarial loss: 0.554097\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412974; batch adversarial loss: 0.581345\n",
      "epoch 163; iter: 0; batch classifier loss: 0.472619; batch adversarial loss: 0.589367\n",
      "epoch 164; iter: 0; batch classifier loss: 0.377008; batch adversarial loss: 0.525844\n",
      "epoch 165; iter: 0; batch classifier loss: 0.378699; batch adversarial loss: 0.581755\n",
      "epoch 166; iter: 0; batch classifier loss: 0.396245; batch adversarial loss: 0.562379\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370631; batch adversarial loss: 0.554830\n",
      "epoch 168; iter: 0; batch classifier loss: 0.296801; batch adversarial loss: 0.498335\n",
      "epoch 169; iter: 0; batch classifier loss: 0.406537; batch adversarial loss: 0.515986\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360280; batch adversarial loss: 0.590185\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363036; batch adversarial loss: 0.546439\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379913; batch adversarial loss: 0.516479\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414724; batch adversarial loss: 0.619581\n",
      "epoch 174; iter: 0; batch classifier loss: 0.408940; batch adversarial loss: 0.533641\n",
      "epoch 175; iter: 0; batch classifier loss: 0.361016; batch adversarial loss: 0.462206\n",
      "epoch 176; iter: 0; batch classifier loss: 0.432759; batch adversarial loss: 0.571892\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391861; batch adversarial loss: 0.588765\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376970; batch adversarial loss: 0.560322\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340882; batch adversarial loss: 0.617018\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333348; batch adversarial loss: 0.535372\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384573; batch adversarial loss: 0.599661\n",
      "epoch 182; iter: 0; batch classifier loss: 0.258561; batch adversarial loss: 0.525238\n",
      "epoch 183; iter: 0; batch classifier loss: 0.290936; batch adversarial loss: 0.563283\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365042; batch adversarial loss: 0.533970\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367255; batch adversarial loss: 0.569154\n",
      "epoch 186; iter: 0; batch classifier loss: 0.310154; batch adversarial loss: 0.555171\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362142; batch adversarial loss: 0.535057\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383727; batch adversarial loss: 0.507937\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315593; batch adversarial loss: 0.554764\n",
      "epoch 190; iter: 0; batch classifier loss: 0.401469; batch adversarial loss: 0.552857\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352887; batch adversarial loss: 0.516522\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353634; batch adversarial loss: 0.560510\n",
      "epoch 193; iter: 0; batch classifier loss: 0.334085; batch adversarial loss: 0.525926\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403120; batch adversarial loss: 0.626342\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357944; batch adversarial loss: 0.499041\n",
      "epoch 196; iter: 0; batch classifier loss: 0.421276; batch adversarial loss: 0.544508\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342624; batch adversarial loss: 0.525210\n",
      "epoch 198; iter: 0; batch classifier loss: 0.405961; batch adversarial loss: 0.518184\n",
      "epoch 199; iter: 0; batch classifier loss: 0.294885; batch adversarial loss: 0.544780\n",
      "epoch 0; iter: 0; batch classifier loss: 0.776438; batch adversarial loss: 0.726603\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583328; batch adversarial loss: 0.657591\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578470; batch adversarial loss: 0.689606\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579169; batch adversarial loss: 0.613760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.524642; batch adversarial loss: 0.567084\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592474; batch adversarial loss: 0.581406\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486292; batch adversarial loss: 0.613468\n",
      "epoch 7; iter: 0; batch classifier loss: 0.551170; batch adversarial loss: 0.596951\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576093; batch adversarial loss: 0.559863\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487758; batch adversarial loss: 0.569101\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489335; batch adversarial loss: 0.561290\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593746; batch adversarial loss: 0.609133\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498746; batch adversarial loss: 0.491336\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490707; batch adversarial loss: 0.543860\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500527; batch adversarial loss: 0.569682\n",
      "epoch 15; iter: 0; batch classifier loss: 0.456511; batch adversarial loss: 0.524669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.535987; batch adversarial loss: 0.542314\n",
      "epoch 17; iter: 0; batch classifier loss: 0.461618; batch adversarial loss: 0.548737\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517399; batch adversarial loss: 0.500691\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473840; batch adversarial loss: 0.499905\n",
      "epoch 20; iter: 0; batch classifier loss: 0.446398; batch adversarial loss: 0.613536\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510425; batch adversarial loss: 0.589174\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446500; batch adversarial loss: 0.541710\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487957; batch adversarial loss: 0.556108\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466448; batch adversarial loss: 0.620206\n",
      "epoch 25; iter: 0; batch classifier loss: 0.475794; batch adversarial loss: 0.569717\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465331; batch adversarial loss: 0.615994\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470426; batch adversarial loss: 0.534578\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494502; batch adversarial loss: 0.580539\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490476; batch adversarial loss: 0.575209\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478100; batch adversarial loss: 0.499493\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453444; batch adversarial loss: 0.601880\n",
      "epoch 32; iter: 0; batch classifier loss: 0.507306; batch adversarial loss: 0.548337\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486692; batch adversarial loss: 0.528253\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511609; batch adversarial loss: 0.574199\n",
      "epoch 35; iter: 0; batch classifier loss: 0.380693; batch adversarial loss: 0.531467\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437874; batch adversarial loss: 0.565825\n",
      "epoch 37; iter: 0; batch classifier loss: 0.488599; batch adversarial loss: 0.569912\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459462; batch adversarial loss: 0.600625\n",
      "epoch 39; iter: 0; batch classifier loss: 0.524902; batch adversarial loss: 0.498540\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446687; batch adversarial loss: 0.581298\n",
      "epoch 41; iter: 0; batch classifier loss: 0.368002; batch adversarial loss: 0.473632\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444692; batch adversarial loss: 0.624381\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460880; batch adversarial loss: 0.518122\n",
      "epoch 44; iter: 0; batch classifier loss: 0.497825; batch adversarial loss: 0.517646\n",
      "epoch 45; iter: 0; batch classifier loss: 0.462455; batch adversarial loss: 0.600699\n",
      "epoch 46; iter: 0; batch classifier loss: 0.488098; batch adversarial loss: 0.543101\n",
      "epoch 47; iter: 0; batch classifier loss: 0.481980; batch adversarial loss: 0.655171\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401726; batch adversarial loss: 0.544012\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411188; batch adversarial loss: 0.508208\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469001; batch adversarial loss: 0.517116\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449695; batch adversarial loss: 0.535293\n",
      "epoch 52; iter: 0; batch classifier loss: 0.530740; batch adversarial loss: 0.517129\n",
      "epoch 53; iter: 0; batch classifier loss: 0.490374; batch adversarial loss: 0.560039\n",
      "epoch 54; iter: 0; batch classifier loss: 0.472954; batch adversarial loss: 0.524977\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404742; batch adversarial loss: 0.598366\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438942; batch adversarial loss: 0.506761\n",
      "epoch 57; iter: 0; batch classifier loss: 0.384271; batch adversarial loss: 0.535796\n",
      "epoch 58; iter: 0; batch classifier loss: 0.537692; batch adversarial loss: 0.525478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.422937; batch adversarial loss: 0.490052\n",
      "epoch 60; iter: 0; batch classifier loss: 0.419307; batch adversarial loss: 0.563507\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380322; batch adversarial loss: 0.497144\n",
      "epoch 62; iter: 0; batch classifier loss: 0.470594; batch adversarial loss: 0.608958\n",
      "epoch 63; iter: 0; batch classifier loss: 0.311849; batch adversarial loss: 0.506951\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436765; batch adversarial loss: 0.581405\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388771; batch adversarial loss: 0.535230\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409276; batch adversarial loss: 0.487965\n",
      "epoch 67; iter: 0; batch classifier loss: 0.332543; batch adversarial loss: 0.590963\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423372; batch adversarial loss: 0.526918\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355911; batch adversarial loss: 0.554507\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419643; batch adversarial loss: 0.508559\n",
      "epoch 71; iter: 0; batch classifier loss: 0.483377; batch adversarial loss: 0.526133\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385168; batch adversarial loss: 0.579698\n",
      "epoch 73; iter: 0; batch classifier loss: 0.478009; batch adversarial loss: 0.505917\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385812; batch adversarial loss: 0.591866\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389125; batch adversarial loss: 0.525974\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427726; batch adversarial loss: 0.524756\n",
      "epoch 77; iter: 0; batch classifier loss: 0.344567; batch adversarial loss: 0.553559\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391366; batch adversarial loss: 0.613558\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422850; batch adversarial loss: 0.544650\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417318; batch adversarial loss: 0.534284\n",
      "epoch 81; iter: 0; batch classifier loss: 0.431199; batch adversarial loss: 0.514160\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413560; batch adversarial loss: 0.511555\n",
      "epoch 83; iter: 0; batch classifier loss: 0.451326; batch adversarial loss: 0.544953\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397194; batch adversarial loss: 0.561792\n",
      "epoch 85; iter: 0; batch classifier loss: 0.348913; batch adversarial loss: 0.475000\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367243; batch adversarial loss: 0.581180\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416148; batch adversarial loss: 0.653743\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382394; batch adversarial loss: 0.591762\n",
      "epoch 89; iter: 0; batch classifier loss: 0.372920; batch adversarial loss: 0.509223\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419578; batch adversarial loss: 0.516738\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354598; batch adversarial loss: 0.626214\n",
      "epoch 92; iter: 0; batch classifier loss: 0.357687; batch adversarial loss: 0.562954\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390490; batch adversarial loss: 0.571598\n",
      "epoch 94; iter: 0; batch classifier loss: 0.467474; batch adversarial loss: 0.525587\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382714; batch adversarial loss: 0.525587\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408423; batch adversarial loss: 0.563663\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420975; batch adversarial loss: 0.498155\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364644; batch adversarial loss: 0.527624\n",
      "epoch 99; iter: 0; batch classifier loss: 0.329304; batch adversarial loss: 0.433442\n",
      "epoch 100; iter: 0; batch classifier loss: 0.316142; batch adversarial loss: 0.563963\n",
      "epoch 101; iter: 0; batch classifier loss: 0.320712; batch adversarial loss: 0.552449\n",
      "epoch 102; iter: 0; batch classifier loss: 0.346909; batch adversarial loss: 0.449777\n",
      "epoch 103; iter: 0; batch classifier loss: 0.470310; batch adversarial loss: 0.478225\n",
      "epoch 104; iter: 0; batch classifier loss: 0.461566; batch adversarial loss: 0.505633\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406463; batch adversarial loss: 0.609075\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377464; batch adversarial loss: 0.480760\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396805; batch adversarial loss: 0.479103\n",
      "epoch 108; iter: 0; batch classifier loss: 0.449130; batch adversarial loss: 0.506882\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352589; batch adversarial loss: 0.508516\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396457; batch adversarial loss: 0.584524\n",
      "epoch 111; iter: 0; batch classifier loss: 0.317496; batch adversarial loss: 0.655056\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435981; batch adversarial loss: 0.517691\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417498; batch adversarial loss: 0.490912\n",
      "epoch 114; iter: 0; batch classifier loss: 0.420864; batch adversarial loss: 0.609178\n",
      "epoch 115; iter: 0; batch classifier loss: 0.408356; batch adversarial loss: 0.562442\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388398; batch adversarial loss: 0.535221\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374888; batch adversarial loss: 0.598482\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363541; batch adversarial loss: 0.545406\n",
      "epoch 119; iter: 0; batch classifier loss: 0.319302; batch adversarial loss: 0.441808\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407246; batch adversarial loss: 0.525171\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355883; batch adversarial loss: 0.563451\n",
      "epoch 122; iter: 0; batch classifier loss: 0.336853; batch adversarial loss: 0.599424\n",
      "epoch 123; iter: 0; batch classifier loss: 0.337670; batch adversarial loss: 0.544946\n",
      "epoch 124; iter: 0; batch classifier loss: 0.520124; batch adversarial loss: 0.534814\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349320; batch adversarial loss: 0.563008\n",
      "epoch 126; iter: 0; batch classifier loss: 0.437935; batch adversarial loss: 0.562883\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395505; batch adversarial loss: 0.544677\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403886; batch adversarial loss: 0.516647\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350917; batch adversarial loss: 0.517233\n",
      "epoch 130; iter: 0; batch classifier loss: 0.416454; batch adversarial loss: 0.452232\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391333; batch adversarial loss: 0.498392\n",
      "epoch 132; iter: 0; batch classifier loss: 0.328563; batch adversarial loss: 0.515427\n",
      "epoch 133; iter: 0; batch classifier loss: 0.407575; batch adversarial loss: 0.564874\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399873; batch adversarial loss: 0.582238\n",
      "epoch 135; iter: 0; batch classifier loss: 0.417950; batch adversarial loss: 0.507756\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359639; batch adversarial loss: 0.517672\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424776; batch adversarial loss: 0.615440\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376799; batch adversarial loss: 0.506555\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397182; batch adversarial loss: 0.517032\n",
      "epoch 140; iter: 0; batch classifier loss: 0.331472; batch adversarial loss: 0.551345\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390394; batch adversarial loss: 0.462068\n",
      "epoch 142; iter: 0; batch classifier loss: 0.423406; batch adversarial loss: 0.432761\n",
      "epoch 143; iter: 0; batch classifier loss: 0.479993; batch adversarial loss: 0.554034\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367575; batch adversarial loss: 0.535993\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341029; batch adversarial loss: 0.563511\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358615; batch adversarial loss: 0.480238\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379187; batch adversarial loss: 0.553784\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386903; batch adversarial loss: 0.610327\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323081; batch adversarial loss: 0.609848\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372501; batch adversarial loss: 0.601146\n",
      "epoch 151; iter: 0; batch classifier loss: 0.461306; batch adversarial loss: 0.459243\n",
      "epoch 152; iter: 0; batch classifier loss: 0.371581; batch adversarial loss: 0.638362\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344697; batch adversarial loss: 0.517373\n",
      "epoch 154; iter: 0; batch classifier loss: 0.318623; batch adversarial loss: 0.599860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.393381; batch adversarial loss: 0.498443\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334206; batch adversarial loss: 0.498357\n",
      "epoch 157; iter: 0; batch classifier loss: 0.406703; batch adversarial loss: 0.553344\n",
      "epoch 158; iter: 0; batch classifier loss: 0.424211; batch adversarial loss: 0.543406\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407391; batch adversarial loss: 0.516352\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308345; batch adversarial loss: 0.656112\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366471; batch adversarial loss: 0.544059\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401606; batch adversarial loss: 0.610689\n",
      "epoch 163; iter: 0; batch classifier loss: 0.376170; batch adversarial loss: 0.543515\n",
      "epoch 164; iter: 0; batch classifier loss: 0.388377; batch adversarial loss: 0.496534\n",
      "epoch 165; iter: 0; batch classifier loss: 0.316161; batch adversarial loss: 0.506337\n",
      "epoch 166; iter: 0; batch classifier loss: 0.397481; batch adversarial loss: 0.582799\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358601; batch adversarial loss: 0.572774\n",
      "epoch 168; iter: 0; batch classifier loss: 0.381131; batch adversarial loss: 0.562488\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363001; batch adversarial loss: 0.581024\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359458; batch adversarial loss: 0.626846\n",
      "epoch 171; iter: 0; batch classifier loss: 0.356579; batch adversarial loss: 0.506827\n",
      "epoch 172; iter: 0; batch classifier loss: 0.536411; batch adversarial loss: 0.590173\n",
      "epoch 173; iter: 0; batch classifier loss: 0.309029; batch adversarial loss: 0.617767\n",
      "epoch 174; iter: 0; batch classifier loss: 0.394179; batch adversarial loss: 0.515406\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306921; batch adversarial loss: 0.638512\n",
      "epoch 176; iter: 0; batch classifier loss: 0.467004; batch adversarial loss: 0.581574\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396357; batch adversarial loss: 0.506051\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354987; batch adversarial loss: 0.629451\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378751; batch adversarial loss: 0.563061\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339896; batch adversarial loss: 0.497591\n",
      "epoch 181; iter: 0; batch classifier loss: 0.427507; batch adversarial loss: 0.553717\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376330; batch adversarial loss: 0.534539\n",
      "epoch 183; iter: 0; batch classifier loss: 0.357433; batch adversarial loss: 0.545786\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370918; batch adversarial loss: 0.508724\n",
      "epoch 185; iter: 0; batch classifier loss: 0.312544; batch adversarial loss: 0.508843\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375124; batch adversarial loss: 0.617706\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343805; batch adversarial loss: 0.480224\n",
      "epoch 188; iter: 0; batch classifier loss: 0.326670; batch adversarial loss: 0.480343\n",
      "epoch 189; iter: 0; batch classifier loss: 0.427781; batch adversarial loss: 0.562759\n",
      "epoch 190; iter: 0; batch classifier loss: 0.317277; batch adversarial loss: 0.609203\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330467; batch adversarial loss: 0.562121\n",
      "epoch 192; iter: 0; batch classifier loss: 0.325742; batch adversarial loss: 0.580532\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350268; batch adversarial loss: 0.534768\n",
      "epoch 194; iter: 0; batch classifier loss: 0.284229; batch adversarial loss: 0.601405\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309180; batch adversarial loss: 0.515001\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328191; batch adversarial loss: 0.629069\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309890; batch adversarial loss: 0.535208\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354293; batch adversarial loss: 0.543253\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357424; batch adversarial loss: 0.611071\n",
      "epoch 0; iter: 0; batch classifier loss: 0.777174; batch adversarial loss: 0.600873\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586862; batch adversarial loss: 0.660002\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586976; batch adversarial loss: 0.670199\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594802; batch adversarial loss: 0.618405\n",
      "epoch 4; iter: 0; batch classifier loss: 0.491578; batch adversarial loss: 0.631449\n",
      "epoch 5; iter: 0; batch classifier loss: 0.522207; batch adversarial loss: 0.655712\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606678; batch adversarial loss: 0.597434\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461054; batch adversarial loss: 0.629999\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532402; batch adversarial loss: 0.596699\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475612; batch adversarial loss: 0.584223\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498445; batch adversarial loss: 0.615191\n",
      "epoch 11; iter: 0; batch classifier loss: 0.497594; batch adversarial loss: 0.600332\n",
      "epoch 12; iter: 0; batch classifier loss: 0.607705; batch adversarial loss: 0.583430\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473898; batch adversarial loss: 0.594018\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576055; batch adversarial loss: 0.553480\n",
      "epoch 15; iter: 0; batch classifier loss: 0.599624; batch adversarial loss: 0.597345\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465368; batch adversarial loss: 0.594279\n",
      "epoch 17; iter: 0; batch classifier loss: 0.538679; batch adversarial loss: 0.520235\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521284; batch adversarial loss: 0.565955\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520522; batch adversarial loss: 0.584406\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503694; batch adversarial loss: 0.501307\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513377; batch adversarial loss: 0.490634\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489080; batch adversarial loss: 0.542327\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471690; batch adversarial loss: 0.532141\n",
      "epoch 24; iter: 0; batch classifier loss: 0.566437; batch adversarial loss: 0.563978\n",
      "epoch 25; iter: 0; batch classifier loss: 0.534806; batch adversarial loss: 0.557678\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438623; batch adversarial loss: 0.496937\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477472; batch adversarial loss: 0.604349\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493277; batch adversarial loss: 0.537188\n",
      "epoch 29; iter: 0; batch classifier loss: 0.412279; batch adversarial loss: 0.596780\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443291; batch adversarial loss: 0.536380\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429331; batch adversarial loss: 0.475413\n",
      "epoch 32; iter: 0; batch classifier loss: 0.527135; batch adversarial loss: 0.519163\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462726; batch adversarial loss: 0.510260\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456693; batch adversarial loss: 0.579355\n",
      "epoch 35; iter: 0; batch classifier loss: 0.515565; batch adversarial loss: 0.569946\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503612; batch adversarial loss: 0.490367\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529931; batch adversarial loss: 0.473928\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442886; batch adversarial loss: 0.552400\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433574; batch adversarial loss: 0.580546\n",
      "epoch 40; iter: 0; batch classifier loss: 0.473977; batch adversarial loss: 0.534568\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447976; batch adversarial loss: 0.497346\n",
      "epoch 42; iter: 0; batch classifier loss: 0.352598; batch adversarial loss: 0.552641\n",
      "epoch 43; iter: 0; batch classifier loss: 0.462272; batch adversarial loss: 0.543499\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477572; batch adversarial loss: 0.517288\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451193; batch adversarial loss: 0.582618\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423080; batch adversarial loss: 0.621869\n",
      "epoch 47; iter: 0; batch classifier loss: 0.377823; batch adversarial loss: 0.546860\n",
      "epoch 48; iter: 0; batch classifier loss: 0.334589; batch adversarial loss: 0.519692\n",
      "epoch 49; iter: 0; batch classifier loss: 0.386563; batch adversarial loss: 0.544480\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413665; batch adversarial loss: 0.497033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.467867; batch adversarial loss: 0.560436\n",
      "epoch 52; iter: 0; batch classifier loss: 0.459238; batch adversarial loss: 0.592231\n",
      "epoch 53; iter: 0; batch classifier loss: 0.482387; batch adversarial loss: 0.504082\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384473; batch adversarial loss: 0.555001\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400563; batch adversarial loss: 0.557181\n",
      "epoch 56; iter: 0; batch classifier loss: 0.512055; batch adversarial loss: 0.516352\n",
      "epoch 57; iter: 0; batch classifier loss: 0.372323; batch adversarial loss: 0.565866\n",
      "epoch 58; iter: 0; batch classifier loss: 0.456637; batch adversarial loss: 0.507101\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440799; batch adversarial loss: 0.505196\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441255; batch adversarial loss: 0.583721\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379181; batch adversarial loss: 0.496575\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393897; batch adversarial loss: 0.585565\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379431; batch adversarial loss: 0.611560\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400812; batch adversarial loss: 0.625403\n",
      "epoch 65; iter: 0; batch classifier loss: 0.375962; batch adversarial loss: 0.542468\n",
      "epoch 66; iter: 0; batch classifier loss: 0.357953; batch adversarial loss: 0.469188\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401408; batch adversarial loss: 0.559317\n",
      "epoch 68; iter: 0; batch classifier loss: 0.478226; batch adversarial loss: 0.534879\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358778; batch adversarial loss: 0.644291\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416699; batch adversarial loss: 0.645192\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419839; batch adversarial loss: 0.594140\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448818; batch adversarial loss: 0.497731\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384794; batch adversarial loss: 0.564831\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419865; batch adversarial loss: 0.572510\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393477; batch adversarial loss: 0.557076\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393189; batch adversarial loss: 0.544028\n",
      "epoch 77; iter: 0; batch classifier loss: 0.474857; batch adversarial loss: 0.612925\n",
      "epoch 78; iter: 0; batch classifier loss: 0.433974; batch adversarial loss: 0.532374\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421752; batch adversarial loss: 0.561540\n",
      "epoch 80; iter: 0; batch classifier loss: 0.388950; batch adversarial loss: 0.589521\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361971; batch adversarial loss: 0.549488\n",
      "epoch 82; iter: 0; batch classifier loss: 0.448309; batch adversarial loss: 0.464012\n",
      "epoch 83; iter: 0; batch classifier loss: 0.418024; batch adversarial loss: 0.585747\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431607; batch adversarial loss: 0.574715\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350239; batch adversarial loss: 0.508047\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420881; batch adversarial loss: 0.562436\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350308; batch adversarial loss: 0.552408\n",
      "epoch 88; iter: 0; batch classifier loss: 0.327248; batch adversarial loss: 0.439817\n",
      "epoch 89; iter: 0; batch classifier loss: 0.461208; batch adversarial loss: 0.503774\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390179; batch adversarial loss: 0.568135\n",
      "epoch 91; iter: 0; batch classifier loss: 0.342591; batch adversarial loss: 0.528323\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412832; batch adversarial loss: 0.510199\n",
      "epoch 93; iter: 0; batch classifier loss: 0.433978; batch adversarial loss: 0.511398\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414065; batch adversarial loss: 0.563542\n",
      "epoch 95; iter: 0; batch classifier loss: 0.453463; batch adversarial loss: 0.536250\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380219; batch adversarial loss: 0.544820\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344545; batch adversarial loss: 0.551226\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412815; batch adversarial loss: 0.564557\n",
      "epoch 99; iter: 0; batch classifier loss: 0.454468; batch adversarial loss: 0.548327\n",
      "epoch 100; iter: 0; batch classifier loss: 0.336142; batch adversarial loss: 0.622817\n",
      "epoch 101; iter: 0; batch classifier loss: 0.428925; batch adversarial loss: 0.603573\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345151; batch adversarial loss: 0.545605\n",
      "epoch 103; iter: 0; batch classifier loss: 0.418642; batch adversarial loss: 0.577025\n",
      "epoch 104; iter: 0; batch classifier loss: 0.379841; batch adversarial loss: 0.568073\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352895; batch adversarial loss: 0.545736\n",
      "epoch 106; iter: 0; batch classifier loss: 0.422772; batch adversarial loss: 0.474552\n",
      "epoch 107; iter: 0; batch classifier loss: 0.410563; batch adversarial loss: 0.559206\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352158; batch adversarial loss: 0.620319\n",
      "epoch 109; iter: 0; batch classifier loss: 0.350245; batch adversarial loss: 0.597510\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384149; batch adversarial loss: 0.533811\n",
      "epoch 111; iter: 0; batch classifier loss: 0.342585; batch adversarial loss: 0.516854\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382821; batch adversarial loss: 0.533226\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395429; batch adversarial loss: 0.581215\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383314; batch adversarial loss: 0.603758\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404678; batch adversarial loss: 0.516865\n",
      "epoch 116; iter: 0; batch classifier loss: 0.424715; batch adversarial loss: 0.594271\n",
      "epoch 117; iter: 0; batch classifier loss: 0.484764; batch adversarial loss: 0.627174\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368856; batch adversarial loss: 0.506184\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428361; batch adversarial loss: 0.479372\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382377; batch adversarial loss: 0.452001\n",
      "epoch 121; iter: 0; batch classifier loss: 0.425566; batch adversarial loss: 0.548988\n",
      "epoch 122; iter: 0; batch classifier loss: 0.441575; batch adversarial loss: 0.604941\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341588; batch adversarial loss: 0.582062\n",
      "epoch 124; iter: 0; batch classifier loss: 0.431941; batch adversarial loss: 0.541409\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375755; batch adversarial loss: 0.528104\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367308; batch adversarial loss: 0.563711\n",
      "epoch 127; iter: 0; batch classifier loss: 0.537129; batch adversarial loss: 0.572545\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343376; batch adversarial loss: 0.614360\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319485; batch adversarial loss: 0.562916\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353470; batch adversarial loss: 0.491393\n",
      "epoch 131; iter: 0; batch classifier loss: 0.462751; batch adversarial loss: 0.563125\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329650; batch adversarial loss: 0.586853\n",
      "epoch 133; iter: 0; batch classifier loss: 0.424130; batch adversarial loss: 0.543832\n",
      "epoch 134; iter: 0; batch classifier loss: 0.432247; batch adversarial loss: 0.533035\n",
      "epoch 135; iter: 0; batch classifier loss: 0.299008; batch adversarial loss: 0.530291\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363089; batch adversarial loss: 0.583934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.437491; batch adversarial loss: 0.523499\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415381; batch adversarial loss: 0.510456\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356743; batch adversarial loss: 0.605676\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341466; batch adversarial loss: 0.435078\n",
      "epoch 141; iter: 0; batch classifier loss: 0.479190; batch adversarial loss: 0.599120\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346384; batch adversarial loss: 0.548651\n",
      "epoch 143; iter: 0; batch classifier loss: 0.423881; batch adversarial loss: 0.521747\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377633; batch adversarial loss: 0.559246\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327720; batch adversarial loss: 0.463531\n",
      "epoch 146; iter: 0; batch classifier loss: 0.328110; batch adversarial loss: 0.564583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.416720; batch adversarial loss: 0.551054\n",
      "epoch 148; iter: 0; batch classifier loss: 0.307053; batch adversarial loss: 0.590331\n",
      "epoch 149; iter: 0; batch classifier loss: 0.389722; batch adversarial loss: 0.612973\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391573; batch adversarial loss: 0.536526\n",
      "epoch 151; iter: 0; batch classifier loss: 0.453934; batch adversarial loss: 0.640672\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364716; batch adversarial loss: 0.547920\n",
      "epoch 153; iter: 0; batch classifier loss: 0.424129; batch adversarial loss: 0.566946\n",
      "epoch 154; iter: 0; batch classifier loss: 0.378261; batch adversarial loss: 0.544565\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374804; batch adversarial loss: 0.574412\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367015; batch adversarial loss: 0.481237\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336866; batch adversarial loss: 0.532924\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396218; batch adversarial loss: 0.596540\n",
      "epoch 159; iter: 0; batch classifier loss: 0.481955; batch adversarial loss: 0.507593\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368708; batch adversarial loss: 0.486778\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343011; batch adversarial loss: 0.495583\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376098; batch adversarial loss: 0.555753\n",
      "epoch 163; iter: 0; batch classifier loss: 0.412085; batch adversarial loss: 0.569230\n",
      "epoch 164; iter: 0; batch classifier loss: 0.456068; batch adversarial loss: 0.555766\n",
      "epoch 165; iter: 0; batch classifier loss: 0.421296; batch adversarial loss: 0.609422\n",
      "epoch 166; iter: 0; batch classifier loss: 0.329458; batch adversarial loss: 0.591060\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387327; batch adversarial loss: 0.584411\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380497; batch adversarial loss: 0.592524\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337729; batch adversarial loss: 0.579267\n",
      "epoch 170; iter: 0; batch classifier loss: 0.306103; batch adversarial loss: 0.593504\n",
      "epoch 171; iter: 0; batch classifier loss: 0.255309; batch adversarial loss: 0.521840\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389683; batch adversarial loss: 0.595323\n",
      "epoch 173; iter: 0; batch classifier loss: 0.286343; batch adversarial loss: 0.515207\n",
      "epoch 174; iter: 0; batch classifier loss: 0.300494; batch adversarial loss: 0.503698\n",
      "epoch 175; iter: 0; batch classifier loss: 0.320164; batch adversarial loss: 0.599686\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413207; batch adversarial loss: 0.488071\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352036; batch adversarial loss: 0.571543\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369556; batch adversarial loss: 0.559162\n",
      "epoch 179; iter: 0; batch classifier loss: 0.335162; batch adversarial loss: 0.543683\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366719; batch adversarial loss: 0.487864\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411794; batch adversarial loss: 0.581630\n",
      "epoch 182; iter: 0; batch classifier loss: 0.411434; batch adversarial loss: 0.637567\n",
      "epoch 183; iter: 0; batch classifier loss: 0.383437; batch adversarial loss: 0.610188\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382498; batch adversarial loss: 0.567129\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328058; batch adversarial loss: 0.569960\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390552; batch adversarial loss: 0.541745\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322978; batch adversarial loss: 0.620596\n",
      "epoch 188; iter: 0; batch classifier loss: 0.436118; batch adversarial loss: 0.593117\n",
      "epoch 189; iter: 0; batch classifier loss: 0.389241; batch adversarial loss: 0.526328\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333171; batch adversarial loss: 0.532141\n",
      "epoch 191; iter: 0; batch classifier loss: 0.427077; batch adversarial loss: 0.547828\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353689; batch adversarial loss: 0.493221\n",
      "epoch 193; iter: 0; batch classifier loss: 0.396382; batch adversarial loss: 0.555381\n",
      "epoch 194; iter: 0; batch classifier loss: 0.334868; batch adversarial loss: 0.513889\n",
      "epoch 195; iter: 0; batch classifier loss: 0.377634; batch adversarial loss: 0.578241\n",
      "epoch 196; iter: 0; batch classifier loss: 0.365382; batch adversarial loss: 0.584364\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396753; batch adversarial loss: 0.528041\n",
      "epoch 198; iter: 0; batch classifier loss: 0.419564; batch adversarial loss: 0.527173\n",
      "epoch 199; iter: 0; batch classifier loss: 0.343906; batch adversarial loss: 0.557134\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724374; batch adversarial loss: 0.949469\n",
      "epoch 1; iter: 0; batch classifier loss: 0.846506; batch adversarial loss: 1.017999\n",
      "epoch 2; iter: 0; batch classifier loss: 1.035100; batch adversarial loss: 1.005799\n",
      "epoch 3; iter: 0; batch classifier loss: 1.104293; batch adversarial loss: 0.959423\n",
      "epoch 4; iter: 0; batch classifier loss: 0.910624; batch adversarial loss: 0.822570\n",
      "epoch 5; iter: 0; batch classifier loss: 0.834013; batch adversarial loss: 0.774578\n",
      "epoch 6; iter: 0; batch classifier loss: 0.780151; batch adversarial loss: 0.729866\n",
      "epoch 7; iter: 0; batch classifier loss: 0.697680; batch adversarial loss: 0.649668\n",
      "epoch 8; iter: 0; batch classifier loss: 0.608984; batch adversarial loss: 0.655449\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552900; batch adversarial loss: 0.617836\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564143; batch adversarial loss: 0.552163\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566642; batch adversarial loss: 0.647068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550036; batch adversarial loss: 0.562705\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563386; batch adversarial loss: 0.580624\n",
      "epoch 14; iter: 0; batch classifier loss: 0.537180; batch adversarial loss: 0.564715\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477888; batch adversarial loss: 0.603991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561352; batch adversarial loss: 0.582555\n",
      "epoch 17; iter: 0; batch classifier loss: 0.430146; batch adversarial loss: 0.560209\n",
      "epoch 18; iter: 0; batch classifier loss: 0.437381; batch adversarial loss: 0.588446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509663; batch adversarial loss: 0.508309\n",
      "epoch 20; iter: 0; batch classifier loss: 0.533690; batch adversarial loss: 0.554999\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503817; batch adversarial loss: 0.590002\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513489; batch adversarial loss: 0.557940\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501257; batch adversarial loss: 0.518123\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481102; batch adversarial loss: 0.552801\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504126; batch adversarial loss: 0.559709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502241; batch adversarial loss: 0.549314\n",
      "epoch 27; iter: 0; batch classifier loss: 0.395871; batch adversarial loss: 0.576756\n",
      "epoch 28; iter: 0; batch classifier loss: 0.417747; batch adversarial loss: 0.558393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419885; batch adversarial loss: 0.563515\n",
      "epoch 30; iter: 0; batch classifier loss: 0.410745; batch adversarial loss: 0.545428\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439891; batch adversarial loss: 0.521154\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462097; batch adversarial loss: 0.545643\n",
      "epoch 33; iter: 0; batch classifier loss: 0.423766; batch adversarial loss: 0.592988\n",
      "epoch 34; iter: 0; batch classifier loss: 0.479711; batch adversarial loss: 0.512974\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454581; batch adversarial loss: 0.632378\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435100; batch adversarial loss: 0.531244\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418615; batch adversarial loss: 0.547537\n",
      "epoch 38; iter: 0; batch classifier loss: 0.371691; batch adversarial loss: 0.543099\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447537; batch adversarial loss: 0.518633\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416220; batch adversarial loss: 0.534518\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441196; batch adversarial loss: 0.623040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.381317; batch adversarial loss: 0.574181\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425386; batch adversarial loss: 0.557545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.454092; batch adversarial loss: 0.536356\n",
      "epoch 45; iter: 0; batch classifier loss: 0.482401; batch adversarial loss: 0.542460\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398310; batch adversarial loss: 0.506204\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433298; batch adversarial loss: 0.538054\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428735; batch adversarial loss: 0.579849\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470645; batch adversarial loss: 0.496734\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389935; batch adversarial loss: 0.596167\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450543; batch adversarial loss: 0.501945\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389284; batch adversarial loss: 0.588897\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425980; batch adversarial loss: 0.562126\n",
      "epoch 54; iter: 0; batch classifier loss: 0.383759; batch adversarial loss: 0.556477\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388062; batch adversarial loss: 0.506948\n",
      "epoch 56; iter: 0; batch classifier loss: 0.384824; batch adversarial loss: 0.530636\n",
      "epoch 57; iter: 0; batch classifier loss: 0.508670; batch adversarial loss: 0.563847\n",
      "epoch 58; iter: 0; batch classifier loss: 0.456941; batch adversarial loss: 0.596817\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429084; batch adversarial loss: 0.500604\n",
      "epoch 60; iter: 0; batch classifier loss: 0.448564; batch adversarial loss: 0.499758\n",
      "epoch 61; iter: 0; batch classifier loss: 0.388699; batch adversarial loss: 0.546870\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410407; batch adversarial loss: 0.577151\n",
      "epoch 63; iter: 0; batch classifier loss: 0.453802; batch adversarial loss: 0.479643\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414611; batch adversarial loss: 0.513814\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398353; batch adversarial loss: 0.595217\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410637; batch adversarial loss: 0.553150\n",
      "epoch 67; iter: 0; batch classifier loss: 0.343481; batch adversarial loss: 0.535873\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384964; batch adversarial loss: 0.527817\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439568; batch adversarial loss: 0.500690\n",
      "epoch 70; iter: 0; batch classifier loss: 0.491130; batch adversarial loss: 0.582792\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420640; batch adversarial loss: 0.641194\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408023; batch adversarial loss: 0.486456\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382508; batch adversarial loss: 0.634802\n",
      "epoch 74; iter: 0; batch classifier loss: 0.454936; batch adversarial loss: 0.516829\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408334; batch adversarial loss: 0.562939\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370096; batch adversarial loss: 0.553863\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413424; batch adversarial loss: 0.508785\n",
      "epoch 78; iter: 0; batch classifier loss: 0.411436; batch adversarial loss: 0.509029\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405493; batch adversarial loss: 0.508390\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330209; batch adversarial loss: 0.508128\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358631; batch adversarial loss: 0.498714\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353749; batch adversarial loss: 0.535450\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376918; batch adversarial loss: 0.599378\n",
      "epoch 84; iter: 0; batch classifier loss: 0.459506; batch adversarial loss: 0.580779\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343224; batch adversarial loss: 0.526143\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360524; batch adversarial loss: 0.534629\n",
      "epoch 87; iter: 0; batch classifier loss: 0.358842; batch adversarial loss: 0.536084\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406909; batch adversarial loss: 0.581346\n",
      "epoch 89; iter: 0; batch classifier loss: 0.325739; batch adversarial loss: 0.553649\n",
      "epoch 90; iter: 0; batch classifier loss: 0.379808; batch adversarial loss: 0.635903\n",
      "epoch 91; iter: 0; batch classifier loss: 0.344579; batch adversarial loss: 0.525796\n",
      "epoch 92; iter: 0; batch classifier loss: 0.327802; batch adversarial loss: 0.535350\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404804; batch adversarial loss: 0.599772\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380910; batch adversarial loss: 0.563136\n",
      "epoch 95; iter: 0; batch classifier loss: 0.371473; batch adversarial loss: 0.498471\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355576; batch adversarial loss: 0.572288\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413189; batch adversarial loss: 0.645396\n",
      "epoch 98; iter: 0; batch classifier loss: 0.346315; batch adversarial loss: 0.525679\n",
      "epoch 99; iter: 0; batch classifier loss: 0.470303; batch adversarial loss: 0.553597\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358673; batch adversarial loss: 0.535634\n",
      "epoch 101; iter: 0; batch classifier loss: 0.315553; batch adversarial loss: 0.581098\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330457; batch adversarial loss: 0.526469\n",
      "epoch 103; iter: 0; batch classifier loss: 0.329583; batch adversarial loss: 0.507443\n",
      "epoch 104; iter: 0; batch classifier loss: 0.346536; batch adversarial loss: 0.590457\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382317; batch adversarial loss: 0.471106\n",
      "epoch 106; iter: 0; batch classifier loss: 0.339433; batch adversarial loss: 0.507714\n",
      "epoch 107; iter: 0; batch classifier loss: 0.427875; batch adversarial loss: 0.517435\n",
      "epoch 108; iter: 0; batch classifier loss: 0.331506; batch adversarial loss: 0.480177\n",
      "epoch 109; iter: 0; batch classifier loss: 0.324301; batch adversarial loss: 0.480056\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369002; batch adversarial loss: 0.507547\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345260; batch adversarial loss: 0.645876\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394669; batch adversarial loss: 0.451962\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343250; batch adversarial loss: 0.544077\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422902; batch adversarial loss: 0.572119\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348823; batch adversarial loss: 0.517281\n",
      "epoch 116; iter: 0; batch classifier loss: 0.318479; batch adversarial loss: 0.516081\n",
      "epoch 117; iter: 0; batch classifier loss: 0.290956; batch adversarial loss: 0.554382\n",
      "epoch 118; iter: 0; batch classifier loss: 0.318284; batch adversarial loss: 0.516822\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394192; batch adversarial loss: 0.553652\n",
      "epoch 120; iter: 0; batch classifier loss: 0.395449; batch adversarial loss: 0.472023\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366460; batch adversarial loss: 0.535317\n",
      "epoch 122; iter: 0; batch classifier loss: 0.454555; batch adversarial loss: 0.498633\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349099; batch adversarial loss: 0.535315\n",
      "epoch 124; iter: 0; batch classifier loss: 0.333812; batch adversarial loss: 0.534707\n",
      "epoch 125; iter: 0; batch classifier loss: 0.414473; batch adversarial loss: 0.571591\n",
      "epoch 126; iter: 0; batch classifier loss: 0.431944; batch adversarial loss: 0.572513\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407069; batch adversarial loss: 0.554282\n",
      "epoch 128; iter: 0; batch classifier loss: 0.391721; batch adversarial loss: 0.528181\n",
      "epoch 129; iter: 0; batch classifier loss: 0.372685; batch adversarial loss: 0.581294\n",
      "epoch 130; iter: 0; batch classifier loss: 0.294780; batch adversarial loss: 0.562601\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328117; batch adversarial loss: 0.545086\n",
      "epoch 132; iter: 0; batch classifier loss: 0.310200; batch adversarial loss: 0.507621\n",
      "epoch 133; iter: 0; batch classifier loss: 0.444901; batch adversarial loss: 0.562942\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351941; batch adversarial loss: 0.581647\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340879; batch adversarial loss: 0.535331\n",
      "epoch 136; iter: 0; batch classifier loss: 0.314731; batch adversarial loss: 0.525901\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392758; batch adversarial loss: 0.590002\n",
      "epoch 138; iter: 0; batch classifier loss: 0.339658; batch adversarial loss: 0.507533\n",
      "epoch 139; iter: 0; batch classifier loss: 0.398715; batch adversarial loss: 0.581225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.366275; batch adversarial loss: 0.644721\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336934; batch adversarial loss: 0.499335\n",
      "epoch 142; iter: 0; batch classifier loss: 0.337354; batch adversarial loss: 0.563504\n",
      "epoch 143; iter: 0; batch classifier loss: 0.274717; batch adversarial loss: 0.562919\n",
      "epoch 144; iter: 0; batch classifier loss: 0.287701; batch adversarial loss: 0.516552\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359071; batch adversarial loss: 0.636025\n",
      "epoch 146; iter: 0; batch classifier loss: 0.386238; batch adversarial loss: 0.636835\n",
      "epoch 147; iter: 0; batch classifier loss: 0.284228; batch adversarial loss: 0.517287\n",
      "epoch 148; iter: 0; batch classifier loss: 0.398111; batch adversarial loss: 0.655997\n",
      "epoch 149; iter: 0; batch classifier loss: 0.245605; batch adversarial loss: 0.562639\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396537; batch adversarial loss: 0.564025\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349228; batch adversarial loss: 0.598853\n",
      "epoch 152; iter: 0; batch classifier loss: 0.426825; batch adversarial loss: 0.480209\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344873; batch adversarial loss: 0.489770\n",
      "epoch 154; iter: 0; batch classifier loss: 0.407230; batch adversarial loss: 0.516959\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365796; batch adversarial loss: 0.572193\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376666; batch adversarial loss: 0.535190\n",
      "epoch 157; iter: 0; batch classifier loss: 0.286878; batch adversarial loss: 0.544862\n",
      "epoch 158; iter: 0; batch classifier loss: 0.457205; batch adversarial loss: 0.553618\n",
      "epoch 159; iter: 0; batch classifier loss: 0.365495; batch adversarial loss: 0.517109\n",
      "epoch 160; iter: 0; batch classifier loss: 0.324908; batch adversarial loss: 0.562769\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357857; batch adversarial loss: 0.507844\n",
      "epoch 162; iter: 0; batch classifier loss: 0.292170; batch adversarial loss: 0.526143\n",
      "epoch 163; iter: 0; batch classifier loss: 0.383186; batch adversarial loss: 0.600157\n",
      "epoch 164; iter: 0; batch classifier loss: 0.310701; batch adversarial loss: 0.526476\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353373; batch adversarial loss: 0.608491\n",
      "epoch 166; iter: 0; batch classifier loss: 0.277507; batch adversarial loss: 0.562626\n",
      "epoch 167; iter: 0; batch classifier loss: 0.400298; batch adversarial loss: 0.553523\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331961; batch adversarial loss: 0.590450\n",
      "epoch 169; iter: 0; batch classifier loss: 0.345947; batch adversarial loss: 0.572053\n",
      "epoch 170; iter: 0; batch classifier loss: 0.328312; batch adversarial loss: 0.535146\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394366; batch adversarial loss: 0.480091\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374514; batch adversarial loss: 0.507288\n",
      "epoch 173; iter: 0; batch classifier loss: 0.297779; batch adversarial loss: 0.489029\n",
      "epoch 174; iter: 0; batch classifier loss: 0.279758; batch adversarial loss: 0.572057\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337261; batch adversarial loss: 0.444122\n",
      "epoch 176; iter: 0; batch classifier loss: 0.293682; batch adversarial loss: 0.471148\n",
      "epoch 177; iter: 0; batch classifier loss: 0.309419; batch adversarial loss: 0.525969\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314364; batch adversarial loss: 0.562269\n",
      "epoch 179; iter: 0; batch classifier loss: 0.268716; batch adversarial loss: 0.563124\n",
      "epoch 180; iter: 0; batch classifier loss: 0.313171; batch adversarial loss: 0.599743\n",
      "epoch 181; iter: 0; batch classifier loss: 0.324818; batch adversarial loss: 0.516888\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377092; batch adversarial loss: 0.470736\n",
      "epoch 183; iter: 0; batch classifier loss: 0.295470; batch adversarial loss: 0.544976\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287425; batch adversarial loss: 0.581138\n",
      "epoch 185; iter: 0; batch classifier loss: 0.353715; batch adversarial loss: 0.508269\n",
      "epoch 186; iter: 0; batch classifier loss: 0.413101; batch adversarial loss: 0.535309\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327153; batch adversarial loss: 0.462439\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335723; batch adversarial loss: 0.627111\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338387; batch adversarial loss: 0.535464\n",
      "epoch 190; iter: 0; batch classifier loss: 0.337215; batch adversarial loss: 0.554003\n",
      "epoch 191; iter: 0; batch classifier loss: 0.318781; batch adversarial loss: 0.571678\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347382; batch adversarial loss: 0.599431\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342384; batch adversarial loss: 0.535346\n",
      "epoch 194; iter: 0; batch classifier loss: 0.314670; batch adversarial loss: 0.526197\n",
      "epoch 195; iter: 0; batch classifier loss: 0.293472; batch adversarial loss: 0.609433\n",
      "epoch 196; iter: 0; batch classifier loss: 0.352835; batch adversarial loss: 0.470599\n",
      "epoch 197; iter: 0; batch classifier loss: 0.298825; batch adversarial loss: 0.516597\n",
      "epoch 198; iter: 0; batch classifier loss: 0.351275; batch adversarial loss: 0.516647\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308977; batch adversarial loss: 0.535202\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718614; batch adversarial loss: 0.549027\n",
      "epoch 1; iter: 0; batch classifier loss: 0.544335; batch adversarial loss: 0.688622\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547419; batch adversarial loss: 0.616553\n",
      "epoch 3; iter: 0; batch classifier loss: 0.608272; batch adversarial loss: 0.639819\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567928; batch adversarial loss: 0.539575\n",
      "epoch 5; iter: 0; batch classifier loss: 0.476733; batch adversarial loss: 0.623024\n",
      "epoch 6; iter: 0; batch classifier loss: 0.480388; batch adversarial loss: 0.645824\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533254; batch adversarial loss: 0.602491\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571522; batch adversarial loss: 0.601361\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521956; batch adversarial loss: 0.576164\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594894; batch adversarial loss: 0.600841\n",
      "epoch 11; iter: 0; batch classifier loss: 0.461181; batch adversarial loss: 0.616102\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512771; batch adversarial loss: 0.568581\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503827; batch adversarial loss: 0.544239\n",
      "epoch 14; iter: 0; batch classifier loss: 0.593917; batch adversarial loss: 0.580576\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504917; batch adversarial loss: 0.518537\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495329; batch adversarial loss: 0.578354\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496689; batch adversarial loss: 0.531785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482492; batch adversarial loss: 0.496732\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471358; batch adversarial loss: 0.531882\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503964; batch adversarial loss: 0.481104\n",
      "epoch 21; iter: 0; batch classifier loss: 0.572853; batch adversarial loss: 0.529217\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526856; batch adversarial loss: 0.529409\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472794; batch adversarial loss: 0.530501\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448301; batch adversarial loss: 0.543764\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461768; batch adversarial loss: 0.475236\n",
      "epoch 26; iter: 0; batch classifier loss: 0.427395; batch adversarial loss: 0.500510\n",
      "epoch 27; iter: 0; batch classifier loss: 0.421384; batch adversarial loss: 0.589869\n",
      "epoch 28; iter: 0; batch classifier loss: 0.505337; batch adversarial loss: 0.473205\n",
      "epoch 29; iter: 0; batch classifier loss: 0.514747; batch adversarial loss: 0.536004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452747; batch adversarial loss: 0.468731\n",
      "epoch 31; iter: 0; batch classifier loss: 0.618715; batch adversarial loss: 0.563265\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414819; batch adversarial loss: 0.527189\n",
      "epoch 33; iter: 0; batch classifier loss: 0.416668; batch adversarial loss: 0.459231\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481599; batch adversarial loss: 0.488457\n",
      "epoch 35; iter: 0; batch classifier loss: 0.552988; batch adversarial loss: 0.498594\n",
      "epoch 36; iter: 0; batch classifier loss: 0.530479; batch adversarial loss: 0.479600\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503674; batch adversarial loss: 0.525363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.423744; batch adversarial loss: 0.515741\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403046; batch adversarial loss: 0.516572\n",
      "epoch 40; iter: 0; batch classifier loss: 0.370731; batch adversarial loss: 0.525600\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440263; batch adversarial loss: 0.591988\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447571; batch adversarial loss: 0.544590\n",
      "epoch 43; iter: 0; batch classifier loss: 0.506395; batch adversarial loss: 0.477680\n",
      "epoch 44; iter: 0; batch classifier loss: 0.515893; batch adversarial loss: 0.563948\n",
      "epoch 45; iter: 0; batch classifier loss: 0.379643; batch adversarial loss: 0.458414\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385589; batch adversarial loss: 0.525505\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483562; batch adversarial loss: 0.516058\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391785; batch adversarial loss: 0.563682\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458086; batch adversarial loss: 0.506554\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402554; batch adversarial loss: 0.506523\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427791; batch adversarial loss: 0.513655\n",
      "epoch 52; iter: 0; batch classifier loss: 0.402416; batch adversarial loss: 0.513316\n",
      "epoch 53; iter: 0; batch classifier loss: 0.451015; batch adversarial loss: 0.485319\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399328; batch adversarial loss: 0.496125\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450272; batch adversarial loss: 0.523807\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409020; batch adversarial loss: 0.545181\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441980; batch adversarial loss: 0.466145\n",
      "epoch 58; iter: 0; batch classifier loss: 0.449524; batch adversarial loss: 0.601664\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411302; batch adversarial loss: 0.448551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.399279; batch adversarial loss: 0.565475\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440495; batch adversarial loss: 0.581660\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415258; batch adversarial loss: 0.538686\n",
      "epoch 63; iter: 0; batch classifier loss: 0.440944; batch adversarial loss: 0.524919\n",
      "epoch 64; iter: 0; batch classifier loss: 0.389931; batch adversarial loss: 0.554786\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401978; batch adversarial loss: 0.516241\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433625; batch adversarial loss: 0.545054\n",
      "epoch 67; iter: 0; batch classifier loss: 0.441079; batch adversarial loss: 0.524993\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395074; batch adversarial loss: 0.496055\n",
      "epoch 69; iter: 0; batch classifier loss: 0.349000; batch adversarial loss: 0.515728\n",
      "epoch 70; iter: 0; batch classifier loss: 0.357686; batch adversarial loss: 0.544858\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377930; batch adversarial loss: 0.574129\n",
      "epoch 72; iter: 0; batch classifier loss: 0.322244; batch adversarial loss: 0.486656\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383833; batch adversarial loss: 0.603273\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412814; batch adversarial loss: 0.525556\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364685; batch adversarial loss: 0.525218\n",
      "epoch 76; iter: 0; batch classifier loss: 0.338050; batch adversarial loss: 0.516642\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407695; batch adversarial loss: 0.533844\n",
      "epoch 78; iter: 0; batch classifier loss: 0.426156; batch adversarial loss: 0.486409\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462058; batch adversarial loss: 0.545283\n",
      "epoch 80; iter: 0; batch classifier loss: 0.459847; batch adversarial loss: 0.537052\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356638; batch adversarial loss: 0.553394\n",
      "epoch 82; iter: 0; batch classifier loss: 0.433476; batch adversarial loss: 0.572195\n",
      "epoch 83; iter: 0; batch classifier loss: 0.393667; batch adversarial loss: 0.629793\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388408; batch adversarial loss: 0.475577\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412186; batch adversarial loss: 0.541813\n",
      "epoch 86; iter: 0; batch classifier loss: 0.342532; batch adversarial loss: 0.572285\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367991; batch adversarial loss: 0.505922\n",
      "epoch 88; iter: 0; batch classifier loss: 0.469967; batch adversarial loss: 0.496947\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362938; batch adversarial loss: 0.545328\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399470; batch adversarial loss: 0.525369\n",
      "epoch 91; iter: 0; batch classifier loss: 0.290021; batch adversarial loss: 0.429003\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351889; batch adversarial loss: 0.496194\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389398; batch adversarial loss: 0.552218\n",
      "epoch 94; iter: 0; batch classifier loss: 0.355181; batch adversarial loss: 0.554042\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420224; batch adversarial loss: 0.496010\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370324; batch adversarial loss: 0.494692\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390340; batch adversarial loss: 0.530417\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402757; batch adversarial loss: 0.486567\n",
      "epoch 99; iter: 0; batch classifier loss: 0.391799; batch adversarial loss: 0.556255\n",
      "epoch 100; iter: 0; batch classifier loss: 0.353435; batch adversarial loss: 0.495870\n",
      "epoch 101; iter: 0; batch classifier loss: 0.504343; batch adversarial loss: 0.545379\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363814; batch adversarial loss: 0.593690\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413006; batch adversarial loss: 0.526829\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370441; batch adversarial loss: 0.497953\n",
      "epoch 105; iter: 0; batch classifier loss: 0.366140; batch adversarial loss: 0.556511\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412347; batch adversarial loss: 0.476547\n",
      "epoch 107; iter: 0; batch classifier loss: 0.351488; batch adversarial loss: 0.619957\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386571; batch adversarial loss: 0.534765\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410039; batch adversarial loss: 0.516087\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383740; batch adversarial loss: 0.515931\n",
      "epoch 111; iter: 0; batch classifier loss: 0.383979; batch adversarial loss: 0.496284\n",
      "epoch 112; iter: 0; batch classifier loss: 0.342139; batch adversarial loss: 0.554864\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377408; batch adversarial loss: 0.554210\n",
      "epoch 114; iter: 0; batch classifier loss: 0.404842; batch adversarial loss: 0.438432\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411036; batch adversarial loss: 0.554737\n",
      "epoch 116; iter: 0; batch classifier loss: 0.429953; batch adversarial loss: 0.573166\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362853; batch adversarial loss: 0.544310\n",
      "epoch 118; iter: 0; batch classifier loss: 0.399377; batch adversarial loss: 0.553715\n",
      "epoch 119; iter: 0; batch classifier loss: 0.460804; batch adversarial loss: 0.584020\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352530; batch adversarial loss: 0.506358\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397088; batch adversarial loss: 0.553883\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421628; batch adversarial loss: 0.573780\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354105; batch adversarial loss: 0.571631\n",
      "epoch 124; iter: 0; batch classifier loss: 0.427405; batch adversarial loss: 0.572655\n",
      "epoch 125; iter: 0; batch classifier loss: 0.416619; batch adversarial loss: 0.513365\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400242; batch adversarial loss: 0.554524\n",
      "epoch 127; iter: 0; batch classifier loss: 0.478973; batch adversarial loss: 0.515778\n",
      "epoch 128; iter: 0; batch classifier loss: 0.277966; batch adversarial loss: 0.533341\n",
      "epoch 129; iter: 0; batch classifier loss: 0.462266; batch adversarial loss: 0.467798\n",
      "epoch 130; iter: 0; batch classifier loss: 0.441076; batch adversarial loss: 0.547909\n",
      "epoch 131; iter: 0; batch classifier loss: 0.334669; batch adversarial loss: 0.512903\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330060; batch adversarial loss: 0.514011\n",
      "epoch 133; iter: 0; batch classifier loss: 0.430538; batch adversarial loss: 0.458932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.400014; batch adversarial loss: 0.565610\n",
      "epoch 135; iter: 0; batch classifier loss: 0.435092; batch adversarial loss: 0.534168\n",
      "epoch 136; iter: 0; batch classifier loss: 0.427068; batch adversarial loss: 0.476330\n",
      "epoch 137; iter: 0; batch classifier loss: 0.292846; batch adversarial loss: 0.535698\n",
      "epoch 138; iter: 0; batch classifier loss: 0.374223; batch adversarial loss: 0.514578\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313606; batch adversarial loss: 0.526270\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373665; batch adversarial loss: 0.554962\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358338; batch adversarial loss: 0.457396\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398886; batch adversarial loss: 0.496446\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373622; batch adversarial loss: 0.632297\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360609; batch adversarial loss: 0.573747\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374219; batch adversarial loss: 0.534857\n",
      "epoch 146; iter: 0; batch classifier loss: 0.426674; batch adversarial loss: 0.611414\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383145; batch adversarial loss: 0.554444\n",
      "epoch 148; iter: 0; batch classifier loss: 0.440764; batch adversarial loss: 0.584180\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415638; batch adversarial loss: 0.573465\n",
      "epoch 150; iter: 0; batch classifier loss: 0.433149; batch adversarial loss: 0.631193\n",
      "epoch 151; iter: 0; batch classifier loss: 0.266398; batch adversarial loss: 0.629637\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395840; batch adversarial loss: 0.592967\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405753; batch adversarial loss: 0.497034\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320929; batch adversarial loss: 0.544757\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314027; batch adversarial loss: 0.523953\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362589; batch adversarial loss: 0.573497\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375554; batch adversarial loss: 0.564337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.340089; batch adversarial loss: 0.573436\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377106; batch adversarial loss: 0.517908\n",
      "epoch 160; iter: 0; batch classifier loss: 0.305966; batch adversarial loss: 0.526138\n",
      "epoch 161; iter: 0; batch classifier loss: 0.331043; batch adversarial loss: 0.495662\n",
      "epoch 162; iter: 0; batch classifier loss: 0.354435; batch adversarial loss: 0.543103\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386338; batch adversarial loss: 0.574112\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378272; batch adversarial loss: 0.525867\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410386; batch adversarial loss: 0.448226\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361871; batch adversarial loss: 0.544322\n",
      "epoch 167; iter: 0; batch classifier loss: 0.405730; batch adversarial loss: 0.468512\n",
      "epoch 168; iter: 0; batch classifier loss: 0.409066; batch adversarial loss: 0.554046\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341315; batch adversarial loss: 0.553789\n",
      "epoch 170; iter: 0; batch classifier loss: 0.424903; batch adversarial loss: 0.487191\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358918; batch adversarial loss: 0.582288\n",
      "epoch 172; iter: 0; batch classifier loss: 0.433529; batch adversarial loss: 0.613011\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387450; batch adversarial loss: 0.564294\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381583; batch adversarial loss: 0.504907\n",
      "epoch 175; iter: 0; batch classifier loss: 0.401722; batch adversarial loss: 0.593685\n",
      "epoch 176; iter: 0; batch classifier loss: 0.327393; batch adversarial loss: 0.467477\n",
      "epoch 177; iter: 0; batch classifier loss: 0.418925; batch adversarial loss: 0.525142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.485363; batch adversarial loss: 0.554708\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370995; batch adversarial loss: 0.486611\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328270; batch adversarial loss: 0.650329\n",
      "epoch 181; iter: 0; batch classifier loss: 0.369351; batch adversarial loss: 0.516209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382941; batch adversarial loss: 0.651172\n",
      "epoch 183; iter: 0; batch classifier loss: 0.425830; batch adversarial loss: 0.573599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372987; batch adversarial loss: 0.497106\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381948; batch adversarial loss: 0.477182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.419525; batch adversarial loss: 0.545234\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367904; batch adversarial loss: 0.564576\n",
      "epoch 188; iter: 0; batch classifier loss: 0.388022; batch adversarial loss: 0.573540\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382737; batch adversarial loss: 0.525135\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372485; batch adversarial loss: 0.525088\n",
      "epoch 191; iter: 0; batch classifier loss: 0.394349; batch adversarial loss: 0.534760\n",
      "epoch 192; iter: 0; batch classifier loss: 0.314477; batch adversarial loss: 0.526028\n",
      "epoch 193; iter: 0; batch classifier loss: 0.413677; batch adversarial loss: 0.601339\n",
      "epoch 194; iter: 0; batch classifier loss: 0.437645; batch adversarial loss: 0.458417\n",
      "epoch 195; iter: 0; batch classifier loss: 0.388347; batch adversarial loss: 0.541720\n",
      "epoch 196; iter: 0; batch classifier loss: 0.333371; batch adversarial loss: 0.505674\n",
      "epoch 197; iter: 0; batch classifier loss: 0.325138; batch adversarial loss: 0.555874\n",
      "epoch 198; iter: 0; batch classifier loss: 0.381366; batch adversarial loss: 0.524472\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323418; batch adversarial loss: 0.581626\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738916; batch adversarial loss: 0.831950\n",
      "epoch 1; iter: 0; batch classifier loss: 0.774639; batch adversarial loss: 0.880583\n",
      "epoch 2; iter: 0; batch classifier loss: 0.993821; batch adversarial loss: 0.838465\n",
      "epoch 3; iter: 0; batch classifier loss: 0.925152; batch adversarial loss: 0.765836\n",
      "epoch 4; iter: 0; batch classifier loss: 0.927460; batch adversarial loss: 0.704061\n",
      "epoch 5; iter: 0; batch classifier loss: 0.816631; batch adversarial loss: 0.665020\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563695; batch adversarial loss: 0.624608\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612477; batch adversarial loss: 0.618856\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583439; batch adversarial loss: 0.608398\n",
      "epoch 9; iter: 0; batch classifier loss: 0.642683; batch adversarial loss: 0.626748\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547185; batch adversarial loss: 0.587542\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520361; batch adversarial loss: 0.615287\n",
      "epoch 12; iter: 0; batch classifier loss: 0.580464; batch adversarial loss: 0.568607\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546486; batch adversarial loss: 0.549836\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463851; batch adversarial loss: 0.550978\n",
      "epoch 15; iter: 0; batch classifier loss: 0.595339; batch adversarial loss: 0.581663\n",
      "epoch 16; iter: 0; batch classifier loss: 0.535284; batch adversarial loss: 0.555444\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500944; batch adversarial loss: 0.582081\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498163; batch adversarial loss: 0.535519\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509774; batch adversarial loss: 0.503009\n",
      "epoch 20; iter: 0; batch classifier loss: 0.421667; batch adversarial loss: 0.521808\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516771; batch adversarial loss: 0.515556\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513551; batch adversarial loss: 0.531483\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488285; batch adversarial loss: 0.573959\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506942; batch adversarial loss: 0.549365\n",
      "epoch 25; iter: 0; batch classifier loss: 0.436008; batch adversarial loss: 0.570440\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486959; batch adversarial loss: 0.584753\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474212; batch adversarial loss: 0.582719\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481347; batch adversarial loss: 0.538748\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446351; batch adversarial loss: 0.577998\n",
      "epoch 30; iter: 0; batch classifier loss: 0.492802; batch adversarial loss: 0.509682\n",
      "epoch 31; iter: 0; batch classifier loss: 0.493367; batch adversarial loss: 0.539315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.467676; batch adversarial loss: 0.607459\n",
      "epoch 33; iter: 0; batch classifier loss: 0.496244; batch adversarial loss: 0.577602\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412662; batch adversarial loss: 0.546950\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502017; batch adversarial loss: 0.544147\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477552; batch adversarial loss: 0.494255\n",
      "epoch 37; iter: 0; batch classifier loss: 0.405191; batch adversarial loss: 0.561554\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443774; batch adversarial loss: 0.563186\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418550; batch adversarial loss: 0.595840\n",
      "epoch 40; iter: 0; batch classifier loss: 0.499678; batch adversarial loss: 0.483184\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434422; batch adversarial loss: 0.573479\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450114; batch adversarial loss: 0.593040\n",
      "epoch 43; iter: 0; batch classifier loss: 0.372142; batch adversarial loss: 0.506835\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474225; batch adversarial loss: 0.499035\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419621; batch adversarial loss: 0.581131\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495600; batch adversarial loss: 0.525555\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460555; batch adversarial loss: 0.546021\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454600; batch adversarial loss: 0.665009\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410088; batch adversarial loss: 0.590307\n",
      "epoch 50; iter: 0; batch classifier loss: 0.379890; batch adversarial loss: 0.497316\n",
      "epoch 51; iter: 0; batch classifier loss: 0.403727; batch adversarial loss: 0.564252\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406227; batch adversarial loss: 0.581374\n",
      "epoch 53; iter: 0; batch classifier loss: 0.394419; batch adversarial loss: 0.507212\n",
      "epoch 54; iter: 0; batch classifier loss: 0.336616; batch adversarial loss: 0.507450\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393021; batch adversarial loss: 0.526192\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398031; batch adversarial loss: 0.452698\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424990; batch adversarial loss: 0.516455\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414820; batch adversarial loss: 0.561968\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444677; batch adversarial loss: 0.599516\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422116; batch adversarial loss: 0.571649\n",
      "epoch 61; iter: 0; batch classifier loss: 0.374956; batch adversarial loss: 0.599870\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396783; batch adversarial loss: 0.554757\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385705; batch adversarial loss: 0.470463\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412728; batch adversarial loss: 0.535377\n",
      "epoch 65; iter: 0; batch classifier loss: 0.361426; batch adversarial loss: 0.592161\n",
      "epoch 66; iter: 0; batch classifier loss: 0.479755; batch adversarial loss: 0.479355\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411577; batch adversarial loss: 0.526331\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405556; batch adversarial loss: 0.526951\n",
      "epoch 69; iter: 0; batch classifier loss: 0.331851; batch adversarial loss: 0.516751\n",
      "epoch 70; iter: 0; batch classifier loss: 0.371370; batch adversarial loss: 0.545817\n",
      "epoch 71; iter: 0; batch classifier loss: 0.388181; batch adversarial loss: 0.515685\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404570; batch adversarial loss: 0.563773\n",
      "epoch 73; iter: 0; batch classifier loss: 0.333596; batch adversarial loss: 0.545708\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399384; batch adversarial loss: 0.509847\n",
      "epoch 75; iter: 0; batch classifier loss: 0.419567; batch adversarial loss: 0.479031\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424490; batch adversarial loss: 0.564053\n",
      "epoch 77; iter: 0; batch classifier loss: 0.377093; batch adversarial loss: 0.573380\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341791; batch adversarial loss: 0.572216\n",
      "epoch 79; iter: 0; batch classifier loss: 0.350504; batch adversarial loss: 0.545027\n",
      "epoch 80; iter: 0; batch classifier loss: 0.373963; batch adversarial loss: 0.526475\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415673; batch adversarial loss: 0.638154\n",
      "epoch 82; iter: 0; batch classifier loss: 0.440647; batch adversarial loss: 0.554346\n",
      "epoch 83; iter: 0; batch classifier loss: 0.331371; batch adversarial loss: 0.515491\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426020; batch adversarial loss: 0.612394\n",
      "epoch 85; iter: 0; batch classifier loss: 0.359823; batch adversarial loss: 0.496864\n",
      "epoch 86; iter: 0; batch classifier loss: 0.334981; batch adversarial loss: 0.476814\n",
      "epoch 87; iter: 0; batch classifier loss: 0.359014; batch adversarial loss: 0.578599\n",
      "epoch 88; iter: 0; batch classifier loss: 0.466397; batch adversarial loss: 0.598959\n",
      "epoch 89; iter: 0; batch classifier loss: 0.308179; batch adversarial loss: 0.499867\n",
      "epoch 90; iter: 0; batch classifier loss: 0.334604; batch adversarial loss: 0.536164\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365263; batch adversarial loss: 0.554694\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414230; batch adversarial loss: 0.552199\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386553; batch adversarial loss: 0.416795\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356105; batch adversarial loss: 0.598550\n",
      "epoch 95; iter: 0; batch classifier loss: 0.363019; batch adversarial loss: 0.431358\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403973; batch adversarial loss: 0.617219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.327444; batch adversarial loss: 0.505371\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373669; batch adversarial loss: 0.498426\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351951; batch adversarial loss: 0.526546\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398836; batch adversarial loss: 0.586667\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391876; batch adversarial loss: 0.553173\n",
      "epoch 102; iter: 0; batch classifier loss: 0.361934; batch adversarial loss: 0.543452\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398445; batch adversarial loss: 0.557963\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384853; batch adversarial loss: 0.601254\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413654; batch adversarial loss: 0.532748\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334292; batch adversarial loss: 0.459111\n",
      "epoch 107; iter: 0; batch classifier loss: 0.314393; batch adversarial loss: 0.508671\n",
      "epoch 108; iter: 0; batch classifier loss: 0.359242; batch adversarial loss: 0.529556\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365083; batch adversarial loss: 0.440300\n",
      "epoch 110; iter: 0; batch classifier loss: 0.313762; batch adversarial loss: 0.474634\n",
      "epoch 111; iter: 0; batch classifier loss: 0.322612; batch adversarial loss: 0.531388\n",
      "epoch 112; iter: 0; batch classifier loss: 0.331166; batch adversarial loss: 0.479574\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387189; batch adversarial loss: 0.441215\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374197; batch adversarial loss: 0.545738\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364566; batch adversarial loss: 0.572220\n",
      "epoch 116; iter: 0; batch classifier loss: 0.419660; batch adversarial loss: 0.542775\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351010; batch adversarial loss: 0.516726\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378751; batch adversarial loss: 0.534191\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348324; batch adversarial loss: 0.516745\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341533; batch adversarial loss: 0.535114\n",
      "epoch 121; iter: 0; batch classifier loss: 0.290520; batch adversarial loss: 0.506456\n",
      "epoch 122; iter: 0; batch classifier loss: 0.302557; batch adversarial loss: 0.573917\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349895; batch adversarial loss: 0.586998\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325397; batch adversarial loss: 0.458304\n",
      "epoch 125; iter: 0; batch classifier loss: 0.314696; batch adversarial loss: 0.594692\n",
      "epoch 126; iter: 0; batch classifier loss: 0.278665; batch adversarial loss: 0.597130\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352687; batch adversarial loss: 0.589835\n",
      "epoch 128; iter: 0; batch classifier loss: 0.263300; batch adversarial loss: 0.514309\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342655; batch adversarial loss: 0.530642\n",
      "epoch 130; iter: 0; batch classifier loss: 0.309562; batch adversarial loss: 0.508978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.373888; batch adversarial loss: 0.564377\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342439; batch adversarial loss: 0.479533\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353726; batch adversarial loss: 0.573267\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372808; batch adversarial loss: 0.543341\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347957; batch adversarial loss: 0.470500\n",
      "epoch 136; iter: 0; batch classifier loss: 0.269752; batch adversarial loss: 0.496308\n",
      "epoch 137; iter: 0; batch classifier loss: 0.311364; batch adversarial loss: 0.515469\n",
      "epoch 138; iter: 0; batch classifier loss: 0.292530; batch adversarial loss: 0.503873\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334538; batch adversarial loss: 0.573078\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367753; batch adversarial loss: 0.563993\n",
      "epoch 141; iter: 0; batch classifier loss: 0.307561; batch adversarial loss: 0.535498\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367594; batch adversarial loss: 0.525815\n",
      "epoch 143; iter: 0; batch classifier loss: 0.292895; batch adversarial loss: 0.592907\n",
      "epoch 144; iter: 0; batch classifier loss: 0.281487; batch adversarial loss: 0.542981\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362797; batch adversarial loss: 0.518088\n",
      "epoch 146; iter: 0; batch classifier loss: 0.287212; batch adversarial loss: 0.553373\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358545; batch adversarial loss: 0.641179\n",
      "epoch 148; iter: 0; batch classifier loss: 0.347232; batch adversarial loss: 0.523133\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346535; batch adversarial loss: 0.524776\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342650; batch adversarial loss: 0.583769\n",
      "epoch 151; iter: 0; batch classifier loss: 0.366983; batch adversarial loss: 0.471443\n",
      "epoch 152; iter: 0; batch classifier loss: 0.235644; batch adversarial loss: 0.610135\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346216; batch adversarial loss: 0.506550\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359296; batch adversarial loss: 0.533748\n",
      "epoch 155; iter: 0; batch classifier loss: 0.335971; batch adversarial loss: 0.542921\n",
      "epoch 156; iter: 0; batch classifier loss: 0.400795; batch adversarial loss: 0.505252\n",
      "epoch 157; iter: 0; batch classifier loss: 0.325785; batch adversarial loss: 0.597894\n",
      "epoch 158; iter: 0; batch classifier loss: 0.332809; batch adversarial loss: 0.565044\n",
      "epoch 159; iter: 0; batch classifier loss: 0.368616; batch adversarial loss: 0.535416\n",
      "epoch 160; iter: 0; batch classifier loss: 0.391945; batch adversarial loss: 0.534561\n",
      "epoch 161; iter: 0; batch classifier loss: 0.340960; batch adversarial loss: 0.544495\n",
      "epoch 162; iter: 0; batch classifier loss: 0.321562; batch adversarial loss: 0.525657\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335257; batch adversarial loss: 0.534904\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363401; batch adversarial loss: 0.562978\n",
      "epoch 165; iter: 0; batch classifier loss: 0.363136; batch adversarial loss: 0.517010\n",
      "epoch 166; iter: 0; batch classifier loss: 0.321061; batch adversarial loss: 0.545831\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319873; batch adversarial loss: 0.505751\n",
      "epoch 168; iter: 0; batch classifier loss: 0.260834; batch adversarial loss: 0.505302\n",
      "epoch 169; iter: 0; batch classifier loss: 0.400959; batch adversarial loss: 0.513635\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367539; batch adversarial loss: 0.484989\n",
      "epoch 171; iter: 0; batch classifier loss: 0.273359; batch adversarial loss: 0.562154\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363267; batch adversarial loss: 0.619551\n",
      "epoch 173; iter: 0; batch classifier loss: 0.370177; batch adversarial loss: 0.554976\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340540; batch adversarial loss: 0.508165\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337481; batch adversarial loss: 0.524926\n",
      "epoch 176; iter: 0; batch classifier loss: 0.436253; batch adversarial loss: 0.562371\n",
      "epoch 177; iter: 0; batch classifier loss: 0.323566; batch adversarial loss: 0.545560\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352911; batch adversarial loss: 0.541907\n",
      "epoch 179; iter: 0; batch classifier loss: 0.316844; batch adversarial loss: 0.485905\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323358; batch adversarial loss: 0.517198\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343064; batch adversarial loss: 0.528121\n",
      "epoch 182; iter: 0; batch classifier loss: 0.281640; batch adversarial loss: 0.526118\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321009; batch adversarial loss: 0.545865\n",
      "epoch 184; iter: 0; batch classifier loss: 0.301632; batch adversarial loss: 0.506350\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366206; batch adversarial loss: 0.523416\n",
      "epoch 186; iter: 0; batch classifier loss: 0.255810; batch adversarial loss: 0.545395\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332107; batch adversarial loss: 0.476028\n",
      "epoch 188; iter: 0; batch classifier loss: 0.274488; batch adversarial loss: 0.557332\n",
      "epoch 189; iter: 0; batch classifier loss: 0.391847; batch adversarial loss: 0.571357\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333427; batch adversarial loss: 0.527125\n",
      "epoch 191; iter: 0; batch classifier loss: 0.308947; batch adversarial loss: 0.581738\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351171; batch adversarial loss: 0.518174\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342344; batch adversarial loss: 0.554194\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379615; batch adversarial loss: 0.571724\n",
      "epoch 195; iter: 0; batch classifier loss: 0.255928; batch adversarial loss: 0.489098\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394906; batch adversarial loss: 0.450469\n",
      "epoch 197; iter: 0; batch classifier loss: 0.300137; batch adversarial loss: 0.514175\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338912; batch adversarial loss: 0.599866\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334163; batch adversarial loss: 0.562459\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694569; batch adversarial loss: 0.979238\n",
      "epoch 1; iter: 0; batch classifier loss: 0.955675; batch adversarial loss: 1.333469\n",
      "epoch 2; iter: 0; batch classifier loss: 0.949813; batch adversarial loss: 1.232630\n",
      "epoch 3; iter: 0; batch classifier loss: 1.086377; batch adversarial loss: 1.112841\n",
      "epoch 4; iter: 0; batch classifier loss: 1.309350; batch adversarial loss: 1.180790\n",
      "epoch 5; iter: 0; batch classifier loss: 1.133373; batch adversarial loss: 1.018402\n",
      "epoch 6; iter: 0; batch classifier loss: 1.243141; batch adversarial loss: 0.961653\n",
      "epoch 7; iter: 0; batch classifier loss: 1.218377; batch adversarial loss: 0.902014\n",
      "epoch 8; iter: 0; batch classifier loss: 1.033148; batch adversarial loss: 0.830954\n",
      "epoch 9; iter: 0; batch classifier loss: 0.922492; batch adversarial loss: 0.756598\n",
      "epoch 10; iter: 0; batch classifier loss: 0.777638; batch adversarial loss: 0.685537\n",
      "epoch 11; iter: 0; batch classifier loss: 0.691704; batch adversarial loss: 0.641829\n",
      "epoch 12; iter: 0; batch classifier loss: 0.593002; batch adversarial loss: 0.618654\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534308; batch adversarial loss: 0.636419\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501616; batch adversarial loss: 0.634409\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525164; batch adversarial loss: 0.582579\n",
      "epoch 16; iter: 0; batch classifier loss: 0.596308; batch adversarial loss: 0.633908\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519715; batch adversarial loss: 0.575263\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506217; batch adversarial loss: 0.545227\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513583; batch adversarial loss: 0.582799\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525168; batch adversarial loss: 0.552688\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530309; batch adversarial loss: 0.564813\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450504; batch adversarial loss: 0.580813\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488485; batch adversarial loss: 0.556237\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508693; batch adversarial loss: 0.634986\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516927; batch adversarial loss: 0.490349\n",
      "epoch 26; iter: 0; batch classifier loss: 0.507609; batch adversarial loss: 0.617681\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437865; batch adversarial loss: 0.560925\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454430; batch adversarial loss: 0.589933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.505918; batch adversarial loss: 0.535823\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479507; batch adversarial loss: 0.597548\n",
      "epoch 31; iter: 0; batch classifier loss: 0.508256; batch adversarial loss: 0.522630\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422636; batch adversarial loss: 0.562427\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456243; batch adversarial loss: 0.563751\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468011; batch adversarial loss: 0.552950\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465753; batch adversarial loss: 0.548336\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449293; batch adversarial loss: 0.593082\n",
      "epoch 37; iter: 0; batch classifier loss: 0.498770; batch adversarial loss: 0.574233\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450443; batch adversarial loss: 0.515628\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458487; batch adversarial loss: 0.531147\n",
      "epoch 40; iter: 0; batch classifier loss: 0.509955; batch adversarial loss: 0.604347\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476747; batch adversarial loss: 0.466271\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471360; batch adversarial loss: 0.556632\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435279; batch adversarial loss: 0.505931\n",
      "epoch 44; iter: 0; batch classifier loss: 0.552816; batch adversarial loss: 0.596837\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394444; batch adversarial loss: 0.553840\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480059; batch adversarial loss: 0.555260\n",
      "epoch 47; iter: 0; batch classifier loss: 0.481276; batch adversarial loss: 0.586618\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385760; batch adversarial loss: 0.581448\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406482; batch adversarial loss: 0.563866\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453734; batch adversarial loss: 0.522777\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442201; batch adversarial loss: 0.579001\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418663; batch adversarial loss: 0.558386\n",
      "epoch 53; iter: 0; batch classifier loss: 0.377746; batch adversarial loss: 0.528486\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439490; batch adversarial loss: 0.445767\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377262; batch adversarial loss: 0.555277\n",
      "epoch 56; iter: 0; batch classifier loss: 0.422049; batch adversarial loss: 0.555510\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425690; batch adversarial loss: 0.572829\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421576; batch adversarial loss: 0.605646\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440945; batch adversarial loss: 0.579197\n",
      "epoch 60; iter: 0; batch classifier loss: 0.468387; batch adversarial loss: 0.488876\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445224; batch adversarial loss: 0.600588\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387657; batch adversarial loss: 0.583382\n",
      "epoch 63; iter: 0; batch classifier loss: 0.440578; batch adversarial loss: 0.507365\n",
      "epoch 64; iter: 0; batch classifier loss: 0.451951; batch adversarial loss: 0.590398\n",
      "epoch 65; iter: 0; batch classifier loss: 0.363451; batch adversarial loss: 0.535185\n",
      "epoch 66; iter: 0; batch classifier loss: 0.456462; batch adversarial loss: 0.554555\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428917; batch adversarial loss: 0.573920\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434962; batch adversarial loss: 0.482220\n",
      "epoch 69; iter: 0; batch classifier loss: 0.501033; batch adversarial loss: 0.571420\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424485; batch adversarial loss: 0.591204\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405133; batch adversarial loss: 0.619564\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415578; batch adversarial loss: 0.554398\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422298; batch adversarial loss: 0.553928\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419355; batch adversarial loss: 0.572603\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422974; batch adversarial loss: 0.562869\n",
      "epoch 76; iter: 0; batch classifier loss: 0.338355; batch adversarial loss: 0.536118\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371577; batch adversarial loss: 0.581334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.364526; batch adversarial loss: 0.554455\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378473; batch adversarial loss: 0.534367\n",
      "epoch 80; iter: 0; batch classifier loss: 0.340041; batch adversarial loss: 0.525873\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432055; batch adversarial loss: 0.543553\n",
      "epoch 82; iter: 0; batch classifier loss: 0.295222; batch adversarial loss: 0.598659\n",
      "epoch 83; iter: 0; batch classifier loss: 0.333633; batch adversarial loss: 0.635012\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349814; batch adversarial loss: 0.526497\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391364; batch adversarial loss: 0.517474\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353793; batch adversarial loss: 0.517260\n",
      "epoch 87; iter: 0; batch classifier loss: 0.353721; batch adversarial loss: 0.525777\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411233; batch adversarial loss: 0.547472\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417475; batch adversarial loss: 0.610977\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351172; batch adversarial loss: 0.527794\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370453; batch adversarial loss: 0.490142\n",
      "epoch 92; iter: 0; batch classifier loss: 0.401893; batch adversarial loss: 0.567917\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422975; batch adversarial loss: 0.516608\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362480; batch adversarial loss: 0.545638\n",
      "epoch 95; iter: 0; batch classifier loss: 0.448690; batch adversarial loss: 0.563219\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422917; batch adversarial loss: 0.567465\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315188; batch adversarial loss: 0.581383\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401562; batch adversarial loss: 0.516101\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368891; batch adversarial loss: 0.462270\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361718; batch adversarial loss: 0.545437\n",
      "epoch 101; iter: 0; batch classifier loss: 0.333178; batch adversarial loss: 0.573054\n",
      "epoch 102; iter: 0; batch classifier loss: 0.384953; batch adversarial loss: 0.513434\n",
      "epoch 103; iter: 0; batch classifier loss: 0.320449; batch adversarial loss: 0.532532\n",
      "epoch 104; iter: 0; batch classifier loss: 0.388125; batch adversarial loss: 0.561471\n",
      "epoch 105; iter: 0; batch classifier loss: 0.316583; batch adversarial loss: 0.581659\n",
      "epoch 106; iter: 0; batch classifier loss: 0.488788; batch adversarial loss: 0.553370\n",
      "epoch 107; iter: 0; batch classifier loss: 0.395640; batch adversarial loss: 0.471040\n",
      "epoch 108; iter: 0; batch classifier loss: 0.333300; batch adversarial loss: 0.547697\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358218; batch adversarial loss: 0.581047\n",
      "epoch 110; iter: 0; batch classifier loss: 0.321973; batch adversarial loss: 0.537792\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403425; batch adversarial loss: 0.572648\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367641; batch adversarial loss: 0.572479\n",
      "epoch 113; iter: 0; batch classifier loss: 0.316519; batch adversarial loss: 0.531451\n",
      "epoch 114; iter: 0; batch classifier loss: 0.465299; batch adversarial loss: 0.504966\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372507; batch adversarial loss: 0.534889\n",
      "epoch 116; iter: 0; batch classifier loss: 0.411591; batch adversarial loss: 0.505760\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333678; batch adversarial loss: 0.590904\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386558; batch adversarial loss: 0.537999\n",
      "epoch 119; iter: 0; batch classifier loss: 0.341130; batch adversarial loss: 0.534802\n",
      "epoch 120; iter: 0; batch classifier loss: 0.460200; batch adversarial loss: 0.565079\n",
      "epoch 121; iter: 0; batch classifier loss: 0.417218; batch adversarial loss: 0.526131\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339307; batch adversarial loss: 0.559526\n",
      "epoch 123; iter: 0; batch classifier loss: 0.374525; batch adversarial loss: 0.540115\n",
      "epoch 124; iter: 0; batch classifier loss: 0.409066; batch adversarial loss: 0.572425\n",
      "epoch 125; iter: 0; batch classifier loss: 0.338376; batch adversarial loss: 0.552514\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383508; batch adversarial loss: 0.525119\n",
      "epoch 127; iter: 0; batch classifier loss: 0.410272; batch adversarial loss: 0.634134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.382060; batch adversarial loss: 0.601128\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399765; batch adversarial loss: 0.581411\n",
      "epoch 130; iter: 0; batch classifier loss: 0.378652; batch adversarial loss: 0.610824\n",
      "epoch 131; iter: 0; batch classifier loss: 0.315246; batch adversarial loss: 0.487718\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354333; batch adversarial loss: 0.467215\n",
      "epoch 133; iter: 0; batch classifier loss: 0.301377; batch adversarial loss: 0.449008\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365839; batch adversarial loss: 0.572475\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368085; batch adversarial loss: 0.580037\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341588; batch adversarial loss: 0.537534\n",
      "epoch 137; iter: 0; batch classifier loss: 0.431837; batch adversarial loss: 0.470448\n",
      "epoch 138; iter: 0; batch classifier loss: 0.396868; batch adversarial loss: 0.485130\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350174; batch adversarial loss: 0.588230\n",
      "epoch 140; iter: 0; batch classifier loss: 0.288443; batch adversarial loss: 0.590739\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349245; batch adversarial loss: 0.549643\n",
      "epoch 142; iter: 0; batch classifier loss: 0.332630; batch adversarial loss: 0.554103\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348208; batch adversarial loss: 0.627383\n",
      "epoch 144; iter: 0; batch classifier loss: 0.323930; batch adversarial loss: 0.502109\n",
      "epoch 145; iter: 0; batch classifier loss: 0.450336; batch adversarial loss: 0.539900\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330927; batch adversarial loss: 0.501443\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326633; batch adversarial loss: 0.517148\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374391; batch adversarial loss: 0.448630\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328207; batch adversarial loss: 0.569221\n",
      "epoch 150; iter: 0; batch classifier loss: 0.286358; batch adversarial loss: 0.571362\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392029; batch adversarial loss: 0.527695\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355684; batch adversarial loss: 0.464503\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381876; batch adversarial loss: 0.478467\n",
      "epoch 154; iter: 0; batch classifier loss: 0.300651; batch adversarial loss: 0.590374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.417820; batch adversarial loss: 0.589970\n",
      "epoch 156; iter: 0; batch classifier loss: 0.421492; batch adversarial loss: 0.520939\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393989; batch adversarial loss: 0.553304\n",
      "epoch 158; iter: 0; batch classifier loss: 0.276047; batch adversarial loss: 0.527660\n",
      "epoch 159; iter: 0; batch classifier loss: 0.365294; batch adversarial loss: 0.552242\n",
      "epoch 160; iter: 0; batch classifier loss: 0.330463; batch adversarial loss: 0.562805\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346513; batch adversarial loss: 0.578686\n",
      "epoch 162; iter: 0; batch classifier loss: 0.298803; batch adversarial loss: 0.598291\n",
      "epoch 163; iter: 0; batch classifier loss: 0.414502; batch adversarial loss: 0.526174\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355030; batch adversarial loss: 0.590034\n",
      "epoch 165; iter: 0; batch classifier loss: 0.294765; batch adversarial loss: 0.570243\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332793; batch adversarial loss: 0.466403\n",
      "epoch 167; iter: 0; batch classifier loss: 0.320410; batch adversarial loss: 0.554644\n",
      "epoch 168; iter: 0; batch classifier loss: 0.297494; batch adversarial loss: 0.541452\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357877; batch adversarial loss: 0.531522\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365430; batch adversarial loss: 0.488689\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408646; batch adversarial loss: 0.521778\n",
      "epoch 172; iter: 0; batch classifier loss: 0.307527; batch adversarial loss: 0.497160\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367527; batch adversarial loss: 0.567993\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360108; batch adversarial loss: 0.492680\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364736; batch adversarial loss: 0.507042\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348772; batch adversarial loss: 0.469905\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329930; batch adversarial loss: 0.496177\n",
      "epoch 178; iter: 0; batch classifier loss: 0.394311; batch adversarial loss: 0.536557\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348907; batch adversarial loss: 0.569755\n",
      "epoch 180; iter: 0; batch classifier loss: 0.299697; batch adversarial loss: 0.607042\n",
      "epoch 181; iter: 0; batch classifier loss: 0.278022; batch adversarial loss: 0.504042\n",
      "epoch 182; iter: 0; batch classifier loss: 0.298349; batch adversarial loss: 0.528180\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347935; batch adversarial loss: 0.557615\n",
      "epoch 184; iter: 0; batch classifier loss: 0.271937; batch adversarial loss: 0.562903\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311562; batch adversarial loss: 0.540475\n",
      "epoch 186; iter: 0; batch classifier loss: 0.362972; batch adversarial loss: 0.554614\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364929; batch adversarial loss: 0.469155\n",
      "epoch 188; iter: 0; batch classifier loss: 0.322438; batch adversarial loss: 0.514416\n",
      "epoch 189; iter: 0; batch classifier loss: 0.316920; batch adversarial loss: 0.550459\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344362; batch adversarial loss: 0.511546\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330252; batch adversarial loss: 0.533576\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336307; batch adversarial loss: 0.590913\n",
      "epoch 193; iter: 0; batch classifier loss: 0.380408; batch adversarial loss: 0.592162\n",
      "epoch 194; iter: 0; batch classifier loss: 0.346144; batch adversarial loss: 0.582400\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338992; batch adversarial loss: 0.547564\n",
      "epoch 196; iter: 0; batch classifier loss: 0.253259; batch adversarial loss: 0.514008\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332991; batch adversarial loss: 0.582959\n",
      "epoch 198; iter: 0; batch classifier loss: 0.351216; batch adversarial loss: 0.531085\n",
      "epoch 199; iter: 0; batch classifier loss: 0.259453; batch adversarial loss: 0.554882\n",
      "epoch 0; iter: 0; batch classifier loss: 0.762072; batch adversarial loss: 0.789162\n",
      "epoch 1; iter: 0; batch classifier loss: 0.677974; batch adversarial loss: 0.770356\n",
      "epoch 2; iter: 0; batch classifier loss: 0.703345; batch adversarial loss: 0.719812\n",
      "epoch 3; iter: 0; batch classifier loss: 0.734295; batch adversarial loss: 0.686813\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596824; batch adversarial loss: 0.640175\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530252; batch adversarial loss: 0.629202\n",
      "epoch 6; iter: 0; batch classifier loss: 0.649146; batch adversarial loss: 0.594151\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494543; batch adversarial loss: 0.600097\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578697; batch adversarial loss: 0.577727\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484541; batch adversarial loss: 0.568352\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548398; batch adversarial loss: 0.610587\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564929; batch adversarial loss: 0.634721\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536217; batch adversarial loss: 0.546937\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534809; batch adversarial loss: 0.595751\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520579; batch adversarial loss: 0.534847\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525763; batch adversarial loss: 0.591727\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473814; batch adversarial loss: 0.536229\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481914; batch adversarial loss: 0.541972\n",
      "epoch 18; iter: 0; batch classifier loss: 0.423739; batch adversarial loss: 0.593159\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543037; batch adversarial loss: 0.519382\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503576; batch adversarial loss: 0.594426\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490631; batch adversarial loss: 0.587531\n",
      "epoch 22; iter: 0; batch classifier loss: 0.435527; batch adversarial loss: 0.656950\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443935; batch adversarial loss: 0.499347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.475522; batch adversarial loss: 0.496845\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455291; batch adversarial loss: 0.521543\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506625; batch adversarial loss: 0.577292\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454768; batch adversarial loss: 0.499389\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460621; batch adversarial loss: 0.597691\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422781; batch adversarial loss: 0.600858\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421910; batch adversarial loss: 0.620761\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505787; batch adversarial loss: 0.527349\n",
      "epoch 32; iter: 0; batch classifier loss: 0.387220; batch adversarial loss: 0.466955\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483752; batch adversarial loss: 0.541905\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484961; batch adversarial loss: 0.479712\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458737; batch adversarial loss: 0.511498\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440893; batch adversarial loss: 0.580268\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446484; batch adversarial loss: 0.528805\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389118; batch adversarial loss: 0.491712\n",
      "epoch 39; iter: 0; batch classifier loss: 0.469072; batch adversarial loss: 0.523214\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492996; batch adversarial loss: 0.496793\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443808; batch adversarial loss: 0.589447\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470383; batch adversarial loss: 0.526812\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421284; batch adversarial loss: 0.588642\n",
      "epoch 44; iter: 0; batch classifier loss: 0.351269; batch adversarial loss: 0.482170\n",
      "epoch 45; iter: 0; batch classifier loss: 0.354009; batch adversarial loss: 0.532957\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439876; batch adversarial loss: 0.507210\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444824; batch adversarial loss: 0.535679\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443613; batch adversarial loss: 0.545102\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445068; batch adversarial loss: 0.582829\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411448; batch adversarial loss: 0.580354\n",
      "epoch 51; iter: 0; batch classifier loss: 0.387785; batch adversarial loss: 0.425567\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419668; batch adversarial loss: 0.480373\n",
      "epoch 53; iter: 0; batch classifier loss: 0.343401; batch adversarial loss: 0.600071\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395575; batch adversarial loss: 0.498233\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388047; batch adversarial loss: 0.516931\n",
      "epoch 56; iter: 0; batch classifier loss: 0.362522; batch adversarial loss: 0.526431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.463134; batch adversarial loss: 0.553431\n",
      "epoch 58; iter: 0; batch classifier loss: 0.362855; batch adversarial loss: 0.554283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398739; batch adversarial loss: 0.553683\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384384; batch adversarial loss: 0.553502\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380878; batch adversarial loss: 0.581811\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407422; batch adversarial loss: 0.581249\n",
      "epoch 63; iter: 0; batch classifier loss: 0.368959; batch adversarial loss: 0.544842\n",
      "epoch 64; iter: 0; batch classifier loss: 0.483080; batch adversarial loss: 0.554049\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376472; batch adversarial loss: 0.488398\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423648; batch adversarial loss: 0.554141\n",
      "epoch 67; iter: 0; batch classifier loss: 0.441306; batch adversarial loss: 0.516901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389708; batch adversarial loss: 0.544489\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410157; batch adversarial loss: 0.581564\n",
      "epoch 70; iter: 0; batch classifier loss: 0.321034; batch adversarial loss: 0.469545\n",
      "epoch 71; iter: 0; batch classifier loss: 0.353671; batch adversarial loss: 0.562910\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388349; batch adversarial loss: 0.563160\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379564; batch adversarial loss: 0.552242\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411586; batch adversarial loss: 0.495861\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400449; batch adversarial loss: 0.581582\n",
      "epoch 76; iter: 0; batch classifier loss: 0.353111; batch adversarial loss: 0.459851\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374366; batch adversarial loss: 0.535225\n",
      "epoch 78; iter: 0; batch classifier loss: 0.456168; batch adversarial loss: 0.620106\n",
      "epoch 79; iter: 0; batch classifier loss: 0.454809; batch adversarial loss: 0.559943\n",
      "epoch 80; iter: 0; batch classifier loss: 0.359130; batch adversarial loss: 0.497674\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386610; batch adversarial loss: 0.573510\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381358; batch adversarial loss: 0.580006\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421277; batch adversarial loss: 0.595290\n",
      "epoch 84; iter: 0; batch classifier loss: 0.499059; batch adversarial loss: 0.464124\n",
      "epoch 85; iter: 0; batch classifier loss: 0.340082; batch adversarial loss: 0.517917\n",
      "epoch 86; iter: 0; batch classifier loss: 0.364874; batch adversarial loss: 0.526208\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356591; batch adversarial loss: 0.626042\n",
      "epoch 88; iter: 0; batch classifier loss: 0.475802; batch adversarial loss: 0.535055\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390551; batch adversarial loss: 0.609029\n",
      "epoch 90; iter: 0; batch classifier loss: 0.332564; batch adversarial loss: 0.591049\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417627; batch adversarial loss: 0.581141\n",
      "epoch 92; iter: 0; batch classifier loss: 0.331001; batch adversarial loss: 0.517123\n",
      "epoch 93; iter: 0; batch classifier loss: 0.348898; batch adversarial loss: 0.580820\n",
      "epoch 94; iter: 0; batch classifier loss: 0.398804; batch adversarial loss: 0.553784\n",
      "epoch 95; iter: 0; batch classifier loss: 0.377965; batch adversarial loss: 0.543447\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377208; batch adversarial loss: 0.546023\n",
      "epoch 97; iter: 0; batch classifier loss: 0.337616; batch adversarial loss: 0.523460\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380119; batch adversarial loss: 0.535063\n",
      "epoch 99; iter: 0; batch classifier loss: 0.345669; batch adversarial loss: 0.546300\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365447; batch adversarial loss: 0.508059\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360521; batch adversarial loss: 0.528212\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326658; batch adversarial loss: 0.496774\n",
      "epoch 103; iter: 0; batch classifier loss: 0.300853; batch adversarial loss: 0.471204\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373115; batch adversarial loss: 0.581012\n",
      "epoch 105; iter: 0; batch classifier loss: 0.339126; batch adversarial loss: 0.535891\n",
      "epoch 106; iter: 0; batch classifier loss: 0.348086; batch adversarial loss: 0.599585\n",
      "epoch 107; iter: 0; batch classifier loss: 0.310799; batch adversarial loss: 0.581200\n",
      "epoch 108; iter: 0; batch classifier loss: 0.324300; batch adversarial loss: 0.581506\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370506; batch adversarial loss: 0.609099\n",
      "epoch 110; iter: 0; batch classifier loss: 0.291884; batch adversarial loss: 0.609135\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345425; batch adversarial loss: 0.609129\n",
      "epoch 112; iter: 0; batch classifier loss: 0.321790; batch adversarial loss: 0.507291\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370719; batch adversarial loss: 0.562981\n",
      "epoch 114; iter: 0; batch classifier loss: 0.312758; batch adversarial loss: 0.507155\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348544; batch adversarial loss: 0.562793\n",
      "epoch 116; iter: 0; batch classifier loss: 0.304184; batch adversarial loss: 0.572037\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326751; batch adversarial loss: 0.516842\n",
      "epoch 118; iter: 0; batch classifier loss: 0.293658; batch adversarial loss: 0.553619\n",
      "epoch 119; iter: 0; batch classifier loss: 0.321825; batch adversarial loss: 0.451745\n",
      "epoch 120; iter: 0; batch classifier loss: 0.353485; batch adversarial loss: 0.507238\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346469; batch adversarial loss: 0.553693\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391268; batch adversarial loss: 0.553961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.318019; batch adversarial loss: 0.498297\n",
      "epoch 124; iter: 0; batch classifier loss: 0.333741; batch adversarial loss: 0.544447\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390227; batch adversarial loss: 0.507533\n",
      "epoch 126; iter: 0; batch classifier loss: 0.302536; batch adversarial loss: 0.534759\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383664; batch adversarial loss: 0.469008\n",
      "epoch 128; iter: 0; batch classifier loss: 0.307572; batch adversarial loss: 0.571933\n",
      "epoch 129; iter: 0; batch classifier loss: 0.301183; batch adversarial loss: 0.468394\n",
      "epoch 130; iter: 0; batch classifier loss: 0.381519; batch adversarial loss: 0.487891\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394364; batch adversarial loss: 0.601945\n",
      "epoch 132; iter: 0; batch classifier loss: 0.308160; batch adversarial loss: 0.562182\n",
      "epoch 133; iter: 0; batch classifier loss: 0.308457; batch adversarial loss: 0.553194\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376694; batch adversarial loss: 0.590719\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364625; batch adversarial loss: 0.498621\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387063; batch adversarial loss: 0.516957\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328345; batch adversarial loss: 0.489110\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353301; batch adversarial loss: 0.562841\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332247; batch adversarial loss: 0.572281\n",
      "epoch 140; iter: 0; batch classifier loss: 0.331616; batch adversarial loss: 0.581653\n",
      "epoch 141; iter: 0; batch classifier loss: 0.274670; batch adversarial loss: 0.553844\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386649; batch adversarial loss: 0.525689\n",
      "epoch 143; iter: 0; batch classifier loss: 0.418212; batch adversarial loss: 0.526135\n",
      "epoch 144; iter: 0; batch classifier loss: 0.281624; batch adversarial loss: 0.553737\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387092; batch adversarial loss: 0.562999\n",
      "epoch 146; iter: 0; batch classifier loss: 0.340950; batch adversarial loss: 0.489083\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360185; batch adversarial loss: 0.526035\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403834; batch adversarial loss: 0.572243\n",
      "epoch 149; iter: 0; batch classifier loss: 0.307708; batch adversarial loss: 0.590775\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359420; batch adversarial loss: 0.535161\n",
      "epoch 151; iter: 0; batch classifier loss: 0.323587; batch adversarial loss: 0.609498\n",
      "epoch 152; iter: 0; batch classifier loss: 0.312917; batch adversarial loss: 0.451369\n",
      "epoch 153; iter: 0; batch classifier loss: 0.337185; batch adversarial loss: 0.544505\n",
      "epoch 154; iter: 0; batch classifier loss: 0.314943; batch adversarial loss: 0.563165\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379377; batch adversarial loss: 0.507544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317387; batch adversarial loss: 0.544414\n",
      "epoch 157; iter: 0; batch classifier loss: 0.268841; batch adversarial loss: 0.525877\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396095; batch adversarial loss: 0.544498\n",
      "epoch 159; iter: 0; batch classifier loss: 0.294137; batch adversarial loss: 0.553950\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335620; batch adversarial loss: 0.525541\n",
      "epoch 161; iter: 0; batch classifier loss: 0.340384; batch adversarial loss: 0.526025\n",
      "epoch 162; iter: 0; batch classifier loss: 0.287610; batch adversarial loss: 0.610788\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335324; batch adversarial loss: 0.524973\n",
      "epoch 164; iter: 0; batch classifier loss: 0.432720; batch adversarial loss: 0.526355\n",
      "epoch 165; iter: 0; batch classifier loss: 0.316237; batch adversarial loss: 0.536225\n",
      "epoch 166; iter: 0; batch classifier loss: 0.459607; batch adversarial loss: 0.515903\n",
      "epoch 167; iter: 0; batch classifier loss: 0.317702; batch adversarial loss: 0.516810\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341288; batch adversarial loss: 0.480132\n",
      "epoch 169; iter: 0; batch classifier loss: 0.338830; batch adversarial loss: 0.526160\n",
      "epoch 170; iter: 0; batch classifier loss: 0.357127; batch adversarial loss: 0.608269\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362395; batch adversarial loss: 0.620628\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370437; batch adversarial loss: 0.544069\n",
      "epoch 173; iter: 0; batch classifier loss: 0.303042; batch adversarial loss: 0.553985\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377038; batch adversarial loss: 0.620233\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363078; batch adversarial loss: 0.517578\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336239; batch adversarial loss: 0.562032\n",
      "epoch 177; iter: 0; batch classifier loss: 0.364581; batch adversarial loss: 0.449505\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337245; batch adversarial loss: 0.551103\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339887; batch adversarial loss: 0.584068\n",
      "epoch 180; iter: 0; batch classifier loss: 0.341169; batch adversarial loss: 0.600649\n",
      "epoch 181; iter: 0; batch classifier loss: 0.261997; batch adversarial loss: 0.544234\n",
      "epoch 182; iter: 0; batch classifier loss: 0.267039; batch adversarial loss: 0.467767\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315356; batch adversarial loss: 0.590698\n",
      "epoch 184; iter: 0; batch classifier loss: 0.402693; batch adversarial loss: 0.584413\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316818; batch adversarial loss: 0.542521\n",
      "epoch 186; iter: 0; batch classifier loss: 0.297832; batch adversarial loss: 0.573281\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348460; batch adversarial loss: 0.528289\n",
      "epoch 188; iter: 0; batch classifier loss: 0.284477; batch adversarial loss: 0.516089\n",
      "epoch 189; iter: 0; batch classifier loss: 0.329174; batch adversarial loss: 0.544727\n",
      "epoch 190; iter: 0; batch classifier loss: 0.382857; batch adversarial loss: 0.588596\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347576; batch adversarial loss: 0.535926\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308522; batch adversarial loss: 0.555568\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313396; batch adversarial loss: 0.563022\n",
      "epoch 194; iter: 0; batch classifier loss: 0.415902; batch adversarial loss: 0.544342\n",
      "epoch 195; iter: 0; batch classifier loss: 0.308224; batch adversarial loss: 0.562236\n",
      "epoch 196; iter: 0; batch classifier loss: 0.344279; batch adversarial loss: 0.535825\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348471; batch adversarial loss: 0.554855\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359924; batch adversarial loss: 0.563037\n",
      "epoch 199; iter: 0; batch classifier loss: 0.392870; batch adversarial loss: 0.527536\n",
      "epoch 0; iter: 0; batch classifier loss: 0.737563; batch adversarial loss: 0.683143\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624360; batch adversarial loss: 0.639323\n",
      "epoch 2; iter: 0; batch classifier loss: 0.531264; batch adversarial loss: 0.653242\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603343; batch adversarial loss: 0.647900\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574029; batch adversarial loss: 0.635214\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573849; batch adversarial loss: 0.608104\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524915; batch adversarial loss: 0.618550\n",
      "epoch 7; iter: 0; batch classifier loss: 0.475320; batch adversarial loss: 0.592563\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549761; batch adversarial loss: 0.580678\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573980; batch adversarial loss: 0.610943\n",
      "epoch 10; iter: 0; batch classifier loss: 0.497106; batch adversarial loss: 0.507958\n",
      "epoch 11; iter: 0; batch classifier loss: 0.438610; batch adversarial loss: 0.560225\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557056; batch adversarial loss: 0.604354\n",
      "epoch 13; iter: 0; batch classifier loss: 0.433254; batch adversarial loss: 0.604382\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506796; batch adversarial loss: 0.574554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.620234; batch adversarial loss: 0.535510\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514594; batch adversarial loss: 0.619194\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507870; batch adversarial loss: 0.561636\n",
      "epoch 18; iter: 0; batch classifier loss: 0.553068; batch adversarial loss: 0.564631\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531407; batch adversarial loss: 0.567218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.469333; batch adversarial loss: 0.549597\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519773; batch adversarial loss: 0.547389\n",
      "epoch 22; iter: 0; batch classifier loss: 0.518745; batch adversarial loss: 0.521994\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459690; batch adversarial loss: 0.587022\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511459; batch adversarial loss: 0.561215\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434205; batch adversarial loss: 0.564137\n",
      "epoch 26; iter: 0; batch classifier loss: 0.542309; batch adversarial loss: 0.585720\n",
      "epoch 27; iter: 0; batch classifier loss: 0.398753; batch adversarial loss: 0.539579\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434441; batch adversarial loss: 0.560579\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489543; batch adversarial loss: 0.615838\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457839; batch adversarial loss: 0.553730\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490385; batch adversarial loss: 0.579608\n",
      "epoch 32; iter: 0; batch classifier loss: 0.440231; batch adversarial loss: 0.542808\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435176; batch adversarial loss: 0.545460\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448768; batch adversarial loss: 0.589298\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460993; batch adversarial loss: 0.612843\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472240; batch adversarial loss: 0.553389\n",
      "epoch 37; iter: 0; batch classifier loss: 0.504062; batch adversarial loss: 0.500487\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483310; batch adversarial loss: 0.562427\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418026; batch adversarial loss: 0.553459\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434559; batch adversarial loss: 0.535599\n",
      "epoch 41; iter: 0; batch classifier loss: 0.412357; batch adversarial loss: 0.552960\n",
      "epoch 42; iter: 0; batch classifier loss: 0.535671; batch adversarial loss: 0.570949\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458081; batch adversarial loss: 0.643417\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443691; batch adversarial loss: 0.480443\n",
      "epoch 45; iter: 0; batch classifier loss: 0.324326; batch adversarial loss: 0.591041\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420566; batch adversarial loss: 0.616870\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403489; batch adversarial loss: 0.633869\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381757; batch adversarial loss: 0.572133\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433606; batch adversarial loss: 0.580260\n",
      "epoch 50; iter: 0; batch classifier loss: 0.354789; batch adversarial loss: 0.545255\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441921; batch adversarial loss: 0.597764\n",
      "epoch 52; iter: 0; batch classifier loss: 0.498997; batch adversarial loss: 0.555020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.419243; batch adversarial loss: 0.500225\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438966; batch adversarial loss: 0.499794\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408660; batch adversarial loss: 0.526421\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410491; batch adversarial loss: 0.536700\n",
      "epoch 57; iter: 0; batch classifier loss: 0.348758; batch adversarial loss: 0.554216\n",
      "epoch 58; iter: 0; batch classifier loss: 0.408743; batch adversarial loss: 0.517765\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387567; batch adversarial loss: 0.544333\n",
      "epoch 60; iter: 0; batch classifier loss: 0.380851; batch adversarial loss: 0.562509\n",
      "epoch 61; iter: 0; batch classifier loss: 0.452654; batch adversarial loss: 0.535744\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416888; batch adversarial loss: 0.571225\n",
      "epoch 63; iter: 0; batch classifier loss: 0.437435; batch adversarial loss: 0.499075\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412854; batch adversarial loss: 0.516959\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394744; batch adversarial loss: 0.562961\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386700; batch adversarial loss: 0.589456\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444639; batch adversarial loss: 0.562574\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425434; batch adversarial loss: 0.544746\n",
      "epoch 69; iter: 0; batch classifier loss: 0.398553; batch adversarial loss: 0.516857\n",
      "epoch 70; iter: 0; batch classifier loss: 0.370504; batch adversarial loss: 0.580489\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422947; batch adversarial loss: 0.580948\n",
      "epoch 72; iter: 0; batch classifier loss: 0.360533; batch adversarial loss: 0.571340\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427348; batch adversarial loss: 0.616058\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410999; batch adversarial loss: 0.579896\n",
      "epoch 75; iter: 0; batch classifier loss: 0.435862; batch adversarial loss: 0.607898\n",
      "epoch 76; iter: 0; batch classifier loss: 0.329367; batch adversarial loss: 0.626041\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427736; batch adversarial loss: 0.545259\n",
      "epoch 78; iter: 0; batch classifier loss: 0.430942; batch adversarial loss: 0.572135\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462724; batch adversarial loss: 0.589745\n",
      "epoch 80; iter: 0; batch classifier loss: 0.361303; batch adversarial loss: 0.606328\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404490; batch adversarial loss: 0.589441\n",
      "epoch 82; iter: 0; batch classifier loss: 0.402732; batch adversarial loss: 0.536287\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367963; batch adversarial loss: 0.545802\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413943; batch adversarial loss: 0.680416\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409455; batch adversarial loss: 0.472690\n",
      "epoch 86; iter: 0; batch classifier loss: 0.346769; batch adversarial loss: 0.580105\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386460; batch adversarial loss: 0.600021\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356841; batch adversarial loss: 0.525407\n",
      "epoch 89; iter: 0; batch classifier loss: 0.461504; batch adversarial loss: 0.544390\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363905; batch adversarial loss: 0.563097\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395479; batch adversarial loss: 0.544267\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355242; batch adversarial loss: 0.490696\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429592; batch adversarial loss: 0.518552\n",
      "epoch 94; iter: 0; batch classifier loss: 0.329770; batch adversarial loss: 0.571194\n",
      "epoch 95; iter: 0; batch classifier loss: 0.461217; batch adversarial loss: 0.526853\n",
      "epoch 96; iter: 0; batch classifier loss: 0.413534; batch adversarial loss: 0.518637\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399515; batch adversarial loss: 0.590064\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379891; batch adversarial loss: 0.544113\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341375; batch adversarial loss: 0.579702\n",
      "epoch 100; iter: 0; batch classifier loss: 0.427406; batch adversarial loss: 0.572168\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395296; batch adversarial loss: 0.490099\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402244; batch adversarial loss: 0.554030\n",
      "epoch 103; iter: 0; batch classifier loss: 0.476927; batch adversarial loss: 0.562978\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384604; batch adversarial loss: 0.580767\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352272; batch adversarial loss: 0.562415\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393351; batch adversarial loss: 0.554198\n",
      "epoch 107; iter: 0; batch classifier loss: 0.320518; batch adversarial loss: 0.535148\n",
      "epoch 108; iter: 0; batch classifier loss: 0.359633; batch adversarial loss: 0.609282\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355244; batch adversarial loss: 0.535407\n",
      "epoch 110; iter: 0; batch classifier loss: 0.452946; batch adversarial loss: 0.472111\n",
      "epoch 111; iter: 0; batch classifier loss: 0.324042; batch adversarial loss: 0.581051\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388814; batch adversarial loss: 0.545101\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358791; batch adversarial loss: 0.526076\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394373; batch adversarial loss: 0.563551\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389035; batch adversarial loss: 0.553504\n",
      "epoch 116; iter: 0; batch classifier loss: 0.311659; batch adversarial loss: 0.598854\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405748; batch adversarial loss: 0.544498\n",
      "epoch 118; iter: 0; batch classifier loss: 0.348848; batch adversarial loss: 0.608765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.370033; batch adversarial loss: 0.589440\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373644; batch adversarial loss: 0.526934\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366715; batch adversarial loss: 0.507847\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391413; batch adversarial loss: 0.516985\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355301; batch adversarial loss: 0.669916\n",
      "epoch 124; iter: 0; batch classifier loss: 0.294686; batch adversarial loss: 0.544259\n",
      "epoch 125; iter: 0; batch classifier loss: 0.358723; batch adversarial loss: 0.589552\n",
      "epoch 126; iter: 0; batch classifier loss: 0.331631; batch adversarial loss: 0.644124\n",
      "epoch 127; iter: 0; batch classifier loss: 0.411544; batch adversarial loss: 0.553515\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366398; batch adversarial loss: 0.472228\n",
      "epoch 129; iter: 0; batch classifier loss: 0.381037; batch adversarial loss: 0.563323\n",
      "epoch 130; iter: 0; batch classifier loss: 0.330908; batch adversarial loss: 0.562779\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371375; batch adversarial loss: 0.562154\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329059; batch adversarial loss: 0.526748\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372003; batch adversarial loss: 0.508362\n",
      "epoch 134; iter: 0; batch classifier loss: 0.300238; batch adversarial loss: 0.571591\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377427; batch adversarial loss: 0.508477\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363267; batch adversarial loss: 0.615629\n",
      "epoch 137; iter: 0; batch classifier loss: 0.269851; batch adversarial loss: 0.626806\n",
      "epoch 138; iter: 0; batch classifier loss: 0.378066; batch adversarial loss: 0.581054\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416246; batch adversarial loss: 0.554079\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397646; batch adversarial loss: 0.525530\n",
      "epoch 141; iter: 0; batch classifier loss: 0.394081; batch adversarial loss: 0.598692\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322854; batch adversarial loss: 0.535598\n",
      "epoch 143; iter: 0; batch classifier loss: 0.343869; batch adversarial loss: 0.499531\n",
      "epoch 144; iter: 0; batch classifier loss: 0.477661; batch adversarial loss: 0.498880\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398577; batch adversarial loss: 0.553814\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371412; batch adversarial loss: 0.509267\n",
      "epoch 147; iter: 0; batch classifier loss: 0.418128; batch adversarial loss: 0.535523\n",
      "epoch 148; iter: 0; batch classifier loss: 0.326222; batch adversarial loss: 0.554185\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376481; batch adversarial loss: 0.517018\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375123; batch adversarial loss: 0.535224\n",
      "epoch 151; iter: 0; batch classifier loss: 0.381130; batch adversarial loss: 0.571120\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335374; batch adversarial loss: 0.598836\n",
      "epoch 153; iter: 0; batch classifier loss: 0.396880; batch adversarial loss: 0.562780\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384801; batch adversarial loss: 0.553294\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373183; batch adversarial loss: 0.554080\n",
      "epoch 156; iter: 0; batch classifier loss: 0.307948; batch adversarial loss: 0.526795\n",
      "epoch 157; iter: 0; batch classifier loss: 0.428538; batch adversarial loss: 0.634645\n",
      "epoch 158; iter: 0; batch classifier loss: 0.374256; batch adversarial loss: 0.580549\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377000; batch adversarial loss: 0.490427\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351593; batch adversarial loss: 0.545601\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411993; batch adversarial loss: 0.518157\n",
      "epoch 162; iter: 0; batch classifier loss: 0.289526; batch adversarial loss: 0.545164\n",
      "epoch 163; iter: 0; batch classifier loss: 0.312432; batch adversarial loss: 0.571643\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363562; batch adversarial loss: 0.572420\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405877; batch adversarial loss: 0.445983\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332416; batch adversarial loss: 0.597696\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409998; batch adversarial loss: 0.545048\n",
      "epoch 168; iter: 0; batch classifier loss: 0.423953; batch adversarial loss: 0.652557\n",
      "epoch 169; iter: 0; batch classifier loss: 0.397028; batch adversarial loss: 0.598942\n",
      "epoch 170; iter: 0; batch classifier loss: 0.376208; batch adversarial loss: 0.553752\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327056; batch adversarial loss: 0.571216\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370255; batch adversarial loss: 0.553760\n",
      "epoch 173; iter: 0; batch classifier loss: 0.318989; batch adversarial loss: 0.580928\n",
      "epoch 174; iter: 0; batch classifier loss: 0.428845; batch adversarial loss: 0.598747\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351001; batch adversarial loss: 0.563093\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408539; batch adversarial loss: 0.589732\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336265; batch adversarial loss: 0.517857\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361330; batch adversarial loss: 0.536166\n",
      "epoch 179; iter: 0; batch classifier loss: 0.405968; batch adversarial loss: 0.445459\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391446; batch adversarial loss: 0.572065\n",
      "epoch 181; iter: 0; batch classifier loss: 0.434583; batch adversarial loss: 0.562605\n",
      "epoch 182; iter: 0; batch classifier loss: 0.319154; batch adversarial loss: 0.516887\n",
      "epoch 183; iter: 0; batch classifier loss: 0.381501; batch adversarial loss: 0.598599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384556; batch adversarial loss: 0.625723\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377272; batch adversarial loss: 0.526666\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390308; batch adversarial loss: 0.508545\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327135; batch adversarial loss: 0.544873\n",
      "epoch 188; iter: 0; batch classifier loss: 0.305249; batch adversarial loss: 0.516920\n",
      "epoch 189; iter: 0; batch classifier loss: 0.459279; batch adversarial loss: 0.499632\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326691; batch adversarial loss: 0.562475\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379553; batch adversarial loss: 0.572341\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365842; batch adversarial loss: 0.589516\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313855; batch adversarial loss: 0.544784\n",
      "epoch 194; iter: 0; batch classifier loss: 0.477697; batch adversarial loss: 0.625562\n",
      "epoch 195; iter: 0; batch classifier loss: 0.283082; batch adversarial loss: 0.526406\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351354; batch adversarial loss: 0.571666\n",
      "epoch 197; iter: 0; batch classifier loss: 0.298652; batch adversarial loss: 0.472270\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369494; batch adversarial loss: 0.517315\n",
      "epoch 199; iter: 0; batch classifier loss: 0.373502; batch adversarial loss: 0.562292\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680776; batch adversarial loss: 0.639827\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613770; batch adversarial loss: 0.637959\n",
      "epoch 2; iter: 0; batch classifier loss: 0.552225; batch adversarial loss: 0.667862\n",
      "epoch 3; iter: 0; batch classifier loss: 0.505298; batch adversarial loss: 0.685020\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573518; batch adversarial loss: 0.674047\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563757; batch adversarial loss: 0.625559\n",
      "epoch 6; iter: 0; batch classifier loss: 0.483141; batch adversarial loss: 0.634669\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532886; batch adversarial loss: 0.640599\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520906; batch adversarial loss: 0.583172\n",
      "epoch 9; iter: 0; batch classifier loss: 0.644538; batch adversarial loss: 0.616974\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562254; batch adversarial loss: 0.577907\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548162; batch adversarial loss: 0.589584\n",
      "epoch 12; iter: 0; batch classifier loss: 0.568394; batch adversarial loss: 0.600121\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491693; batch adversarial loss: 0.605139\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540408; batch adversarial loss: 0.599983\n",
      "epoch 15; iter: 0; batch classifier loss: 0.444513; batch adversarial loss: 0.552260\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483176; batch adversarial loss: 0.576901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.564246; batch adversarial loss: 0.549550\n",
      "epoch 18; iter: 0; batch classifier loss: 0.510067; batch adversarial loss: 0.583558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543930; batch adversarial loss: 0.531794\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516407; batch adversarial loss: 0.514342\n",
      "epoch 21; iter: 0; batch classifier loss: 0.518250; batch adversarial loss: 0.478128\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464922; batch adversarial loss: 0.539501\n",
      "epoch 23; iter: 0; batch classifier loss: 0.410593; batch adversarial loss: 0.492853\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508034; batch adversarial loss: 0.580759\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489194; batch adversarial loss: 0.578690\n",
      "epoch 26; iter: 0; batch classifier loss: 0.528590; batch adversarial loss: 0.604955\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473872; batch adversarial loss: 0.562889\n",
      "epoch 28; iter: 0; batch classifier loss: 0.448539; batch adversarial loss: 0.485404\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527291; batch adversarial loss: 0.596983\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430339; batch adversarial loss: 0.528202\n",
      "epoch 31; iter: 0; batch classifier loss: 0.385222; batch adversarial loss: 0.562366\n",
      "epoch 32; iter: 0; batch classifier loss: 0.507678; batch adversarial loss: 0.561907\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451302; batch adversarial loss: 0.545711\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408964; batch adversarial loss: 0.500960\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457891; batch adversarial loss: 0.615301\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490021; batch adversarial loss: 0.526840\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431190; batch adversarial loss: 0.580025\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480763; batch adversarial loss: 0.509039\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449156; batch adversarial loss: 0.464087\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431065; batch adversarial loss: 0.553657\n",
      "epoch 41; iter: 0; batch classifier loss: 0.509562; batch adversarial loss: 0.482728\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429424; batch adversarial loss: 0.526365\n",
      "epoch 43; iter: 0; batch classifier loss: 0.380538; batch adversarial loss: 0.535576\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398176; batch adversarial loss: 0.606173\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443136; batch adversarial loss: 0.544597\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398858; batch adversarial loss: 0.544335\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401550; batch adversarial loss: 0.518236\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422316; batch adversarial loss: 0.516596\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440192; batch adversarial loss: 0.544926\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438620; batch adversarial loss: 0.552277\n",
      "epoch 51; iter: 0; batch classifier loss: 0.388045; batch adversarial loss: 0.535730\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391609; batch adversarial loss: 0.533994\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391382; batch adversarial loss: 0.543968\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449390; batch adversarial loss: 0.483395\n",
      "epoch 55; iter: 0; batch classifier loss: 0.366251; batch adversarial loss: 0.510352\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421751; batch adversarial loss: 0.628178\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450677; batch adversarial loss: 0.510489\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414006; batch adversarial loss: 0.479719\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462789; batch adversarial loss: 0.535110\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376679; batch adversarial loss: 0.535150\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425815; batch adversarial loss: 0.507310\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398081; batch adversarial loss: 0.600233\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438942; batch adversarial loss: 0.535343\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418151; batch adversarial loss: 0.498632\n",
      "epoch 65; iter: 0; batch classifier loss: 0.336017; batch adversarial loss: 0.535097\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408407; batch adversarial loss: 0.554434\n",
      "epoch 67; iter: 0; batch classifier loss: 0.419233; batch adversarial loss: 0.562506\n",
      "epoch 68; iter: 0; batch classifier loss: 0.440953; batch adversarial loss: 0.479895\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396105; batch adversarial loss: 0.581103\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406081; batch adversarial loss: 0.554035\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436932; batch adversarial loss: 0.534703\n",
      "epoch 72; iter: 0; batch classifier loss: 0.451550; batch adversarial loss: 0.535733\n",
      "epoch 73; iter: 0; batch classifier loss: 0.491240; batch adversarial loss: 0.543836\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384515; batch adversarial loss: 0.517299\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367695; batch adversarial loss: 0.617058\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381509; batch adversarial loss: 0.526081\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436552; batch adversarial loss: 0.527626\n",
      "epoch 78; iter: 0; batch classifier loss: 0.313536; batch adversarial loss: 0.526958\n",
      "epoch 79; iter: 0; batch classifier loss: 0.295796; batch adversarial loss: 0.581643\n",
      "epoch 80; iter: 0; batch classifier loss: 0.448666; batch adversarial loss: 0.499140\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406048; batch adversarial loss: 0.637243\n",
      "epoch 82; iter: 0; batch classifier loss: 0.379232; batch adversarial loss: 0.535485\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410983; batch adversarial loss: 0.507308\n",
      "epoch 84; iter: 0; batch classifier loss: 0.342839; batch adversarial loss: 0.535193\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393305; batch adversarial loss: 0.536049\n",
      "epoch 86; iter: 0; batch classifier loss: 0.501637; batch adversarial loss: 0.490030\n",
      "epoch 87; iter: 0; batch classifier loss: 0.381217; batch adversarial loss: 0.525030\n",
      "epoch 88; iter: 0; batch classifier loss: 0.398850; batch adversarial loss: 0.598908\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378882; batch adversarial loss: 0.471941\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384227; batch adversarial loss: 0.572205\n",
      "epoch 91; iter: 0; batch classifier loss: 0.343265; batch adversarial loss: 0.580687\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390406; batch adversarial loss: 0.563648\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367626; batch adversarial loss: 0.543000\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402845; batch adversarial loss: 0.562816\n",
      "epoch 95; iter: 0; batch classifier loss: 0.453773; batch adversarial loss: 0.516771\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377393; batch adversarial loss: 0.489918\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397613; batch adversarial loss: 0.618045\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396585; batch adversarial loss: 0.600101\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350106; batch adversarial loss: 0.681637\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398028; batch adversarial loss: 0.536052\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359998; batch adversarial loss: 0.489892\n",
      "epoch 102; iter: 0; batch classifier loss: 0.368110; batch adversarial loss: 0.590276\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388679; batch adversarial loss: 0.544833\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341948; batch adversarial loss: 0.563980\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352445; batch adversarial loss: 0.672731\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407033; batch adversarial loss: 0.583322\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368461; batch adversarial loss: 0.524861\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363403; batch adversarial loss: 0.506740\n",
      "epoch 109; iter: 0; batch classifier loss: 0.305256; batch adversarial loss: 0.471697\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362767; batch adversarial loss: 0.544275\n",
      "epoch 111; iter: 0; batch classifier loss: 0.430884; batch adversarial loss: 0.561576\n",
      "epoch 112; iter: 0; batch classifier loss: 0.373528; batch adversarial loss: 0.526669\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396989; batch adversarial loss: 0.498410\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381899; batch adversarial loss: 0.617887\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417226; batch adversarial loss: 0.580710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.340720; batch adversarial loss: 0.600605\n",
      "epoch 117; iter: 0; batch classifier loss: 0.308016; batch adversarial loss: 0.535571\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427861; batch adversarial loss: 0.471961\n",
      "epoch 119; iter: 0; batch classifier loss: 0.305813; batch adversarial loss: 0.527298\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356049; batch adversarial loss: 0.508238\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316259; batch adversarial loss: 0.508563\n",
      "epoch 122; iter: 0; batch classifier loss: 0.414349; batch adversarial loss: 0.534824\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352053; batch adversarial loss: 0.543875\n",
      "epoch 124; iter: 0; batch classifier loss: 0.256420; batch adversarial loss: 0.499427\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365920; batch adversarial loss: 0.528558\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361759; batch adversarial loss: 0.536550\n",
      "epoch 127; iter: 0; batch classifier loss: 0.452603; batch adversarial loss: 0.497269\n",
      "epoch 128; iter: 0; batch classifier loss: 0.450055; batch adversarial loss: 0.516952\n",
      "epoch 129; iter: 0; batch classifier loss: 0.416174; batch adversarial loss: 0.580457\n",
      "epoch 130; iter: 0; batch classifier loss: 0.410032; batch adversarial loss: 0.562473\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385140; batch adversarial loss: 0.554302\n",
      "epoch 132; iter: 0; batch classifier loss: 0.422037; batch adversarial loss: 0.515574\n",
      "epoch 133; iter: 0; batch classifier loss: 0.314737; batch adversarial loss: 0.544631\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379294; batch adversarial loss: 0.544325\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368262; batch adversarial loss: 0.508238\n",
      "epoch 136; iter: 0; batch classifier loss: 0.465862; batch adversarial loss: 0.591761\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328418; batch adversarial loss: 0.607549\n",
      "epoch 138; iter: 0; batch classifier loss: 0.279137; batch adversarial loss: 0.609350\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342108; batch adversarial loss: 0.524741\n",
      "epoch 140; iter: 0; batch classifier loss: 0.414526; batch adversarial loss: 0.516876\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409227; batch adversarial loss: 0.654467\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412699; batch adversarial loss: 0.581252\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389602; batch adversarial loss: 0.536071\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367033; batch adversarial loss: 0.600086\n",
      "epoch 145; iter: 0; batch classifier loss: 0.456165; batch adversarial loss: 0.561908\n",
      "epoch 146; iter: 0; batch classifier loss: 0.409159; batch adversarial loss: 0.570821\n",
      "epoch 147; iter: 0; batch classifier loss: 0.406096; batch adversarial loss: 0.635742\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357918; batch adversarial loss: 0.563890\n",
      "epoch 149; iter: 0; batch classifier loss: 0.327344; batch adversarial loss: 0.517605\n",
      "epoch 150; iter: 0; batch classifier loss: 0.334468; batch adversarial loss: 0.580498\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378676; batch adversarial loss: 0.573301\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357500; batch adversarial loss: 0.582266\n",
      "epoch 153; iter: 0; batch classifier loss: 0.308214; batch adversarial loss: 0.599534\n",
      "epoch 154; iter: 0; batch classifier loss: 0.305749; batch adversarial loss: 0.581428\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365992; batch adversarial loss: 0.589806\n",
      "epoch 156; iter: 0; batch classifier loss: 0.471245; batch adversarial loss: 0.444544\n",
      "epoch 157; iter: 0; batch classifier loss: 0.327048; batch adversarial loss: 0.535456\n",
      "epoch 158; iter: 0; batch classifier loss: 0.427003; batch adversarial loss: 0.541751\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350169; batch adversarial loss: 0.552496\n",
      "epoch 160; iter: 0; batch classifier loss: 0.421295; batch adversarial loss: 0.561100\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333766; batch adversarial loss: 0.517052\n",
      "epoch 162; iter: 0; batch classifier loss: 0.396611; batch adversarial loss: 0.536044\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367316; batch adversarial loss: 0.534578\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375567; batch adversarial loss: 0.654063\n",
      "epoch 165; iter: 0; batch classifier loss: 0.390126; batch adversarial loss: 0.470096\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333641; batch adversarial loss: 0.609051\n",
      "epoch 167; iter: 0; batch classifier loss: 0.351304; batch adversarial loss: 0.532403\n",
      "epoch 168; iter: 0; batch classifier loss: 0.316588; batch adversarial loss: 0.617325\n",
      "epoch 169; iter: 0; batch classifier loss: 0.292853; batch adversarial loss: 0.600609\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395618; batch adversarial loss: 0.562058\n",
      "epoch 171; iter: 0; batch classifier loss: 0.281741; batch adversarial loss: 0.527134\n",
      "epoch 172; iter: 0; batch classifier loss: 0.432553; batch adversarial loss: 0.526914\n",
      "epoch 173; iter: 0; batch classifier loss: 0.402678; batch adversarial loss: 0.416202\n",
      "epoch 174; iter: 0; batch classifier loss: 0.282196; batch adversarial loss: 0.572625\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339003; batch adversarial loss: 0.535196\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360213; batch adversarial loss: 0.552972\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335183; batch adversarial loss: 0.536448\n",
      "epoch 178; iter: 0; batch classifier loss: 0.366103; batch adversarial loss: 0.480141\n",
      "epoch 179; iter: 0; batch classifier loss: 0.371908; batch adversarial loss: 0.562075\n",
      "epoch 180; iter: 0; batch classifier loss: 0.411128; batch adversarial loss: 0.471490\n",
      "epoch 181; iter: 0; batch classifier loss: 0.366795; batch adversarial loss: 0.563862\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373805; batch adversarial loss: 0.600507\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353397; batch adversarial loss: 0.544267\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373678; batch adversarial loss: 0.535144\n",
      "epoch 185; iter: 0; batch classifier loss: 0.403764; batch adversarial loss: 0.525694\n",
      "epoch 186; iter: 0; batch classifier loss: 0.288029; batch adversarial loss: 0.570016\n",
      "epoch 187; iter: 0; batch classifier loss: 0.323876; batch adversarial loss: 0.588818\n",
      "epoch 188; iter: 0; batch classifier loss: 0.415978; batch adversarial loss: 0.526547\n",
      "epoch 189; iter: 0; batch classifier loss: 0.302329; batch adversarial loss: 0.545591\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297860; batch adversarial loss: 0.533976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.294692; batch adversarial loss: 0.545728\n",
      "epoch 192; iter: 0; batch classifier loss: 0.301393; batch adversarial loss: 0.506063\n",
      "epoch 193; iter: 0; batch classifier loss: 0.367638; batch adversarial loss: 0.526249\n",
      "epoch 194; iter: 0; batch classifier loss: 0.311536; batch adversarial loss: 0.546926\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321234; batch adversarial loss: 0.489000\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345683; batch adversarial loss: 0.543757\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356494; batch adversarial loss: 0.488974\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333427; batch adversarial loss: 0.572279\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332606; batch adversarial loss: 0.607113\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740537; batch adversarial loss: 0.606500\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595238; batch adversarial loss: 0.621782\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573469; batch adversarial loss: 0.654334\n",
      "epoch 3; iter: 0; batch classifier loss: 0.546546; batch adversarial loss: 0.639862\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589564; batch adversarial loss: 0.632818\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541375; batch adversarial loss: 0.679481\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573902; batch adversarial loss: 0.577597\n",
      "epoch 7; iter: 0; batch classifier loss: 0.617361; batch adversarial loss: 0.618324\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634369; batch adversarial loss: 0.647694\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556036; batch adversarial loss: 0.563747\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578757; batch adversarial loss: 0.590851\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511770; batch adversarial loss: 0.607515\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559276; batch adversarial loss: 0.592207\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510019; batch adversarial loss: 0.567185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.465138; batch adversarial loss: 0.517175\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550871; batch adversarial loss: 0.552420\n",
      "epoch 16; iter: 0; batch classifier loss: 0.428568; batch adversarial loss: 0.485088\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397032; batch adversarial loss: 0.511442\n",
      "epoch 18; iter: 0; batch classifier loss: 0.605373; batch adversarial loss: 0.567467\n",
      "epoch 19; iter: 0; batch classifier loss: 0.403745; batch adversarial loss: 0.533884\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495745; batch adversarial loss: 0.649244\n",
      "epoch 21; iter: 0; batch classifier loss: 0.577403; batch adversarial loss: 0.545500\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468500; batch adversarial loss: 0.496074\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520615; batch adversarial loss: 0.578843\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479298; batch adversarial loss: 0.541512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474250; batch adversarial loss: 0.459476\n",
      "epoch 26; iter: 0; batch classifier loss: 0.447582; batch adversarial loss: 0.511680\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465749; batch adversarial loss: 0.523939\n",
      "epoch 28; iter: 0; batch classifier loss: 0.401811; batch adversarial loss: 0.575112\n",
      "epoch 29; iter: 0; batch classifier loss: 0.429951; batch adversarial loss: 0.550408\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461377; batch adversarial loss: 0.572265\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438957; batch adversarial loss: 0.526588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.489783; batch adversarial loss: 0.525164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445468; batch adversarial loss: 0.558367\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429931; batch adversarial loss: 0.549809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390928; batch adversarial loss: 0.602302\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473359; batch adversarial loss: 0.506930\n",
      "epoch 37; iter: 0; batch classifier loss: 0.490620; batch adversarial loss: 0.462181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439560; batch adversarial loss: 0.515838\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415818; batch adversarial loss: 0.545011\n",
      "epoch 40; iter: 0; batch classifier loss: 0.356908; batch adversarial loss: 0.622950\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421882; batch adversarial loss: 0.559647\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422376; batch adversarial loss: 0.522427\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420567; batch adversarial loss: 0.552241\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456439; batch adversarial loss: 0.514521\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439532; batch adversarial loss: 0.420210\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356412; batch adversarial loss: 0.494230\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408842; batch adversarial loss: 0.535335\n",
      "epoch 48; iter: 0; batch classifier loss: 0.477294; batch adversarial loss: 0.533754\n",
      "epoch 49; iter: 0; batch classifier loss: 0.494278; batch adversarial loss: 0.450355\n",
      "epoch 50; iter: 0; batch classifier loss: 0.456797; batch adversarial loss: 0.603990\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437109; batch adversarial loss: 0.514913\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435008; batch adversarial loss: 0.599192\n",
      "epoch 53; iter: 0; batch classifier loss: 0.363861; batch adversarial loss: 0.526629\n",
      "epoch 54; iter: 0; batch classifier loss: 0.376490; batch adversarial loss: 0.583098\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420872; batch adversarial loss: 0.564696\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408241; batch adversarial loss: 0.538054\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402629; batch adversarial loss: 0.572908\n",
      "epoch 58; iter: 0; batch classifier loss: 0.406743; batch adversarial loss: 0.565443\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441493; batch adversarial loss: 0.486457\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401578; batch adversarial loss: 0.592518\n",
      "epoch 61; iter: 0; batch classifier loss: 0.372761; batch adversarial loss: 0.526974\n",
      "epoch 62; iter: 0; batch classifier loss: 0.413041; batch adversarial loss: 0.535855\n",
      "epoch 63; iter: 0; batch classifier loss: 0.357773; batch adversarial loss: 0.430720\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419856; batch adversarial loss: 0.582749\n",
      "epoch 65; iter: 0; batch classifier loss: 0.464585; batch adversarial loss: 0.534734\n",
      "epoch 66; iter: 0; batch classifier loss: 0.372189; batch adversarial loss: 0.602703\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405107; batch adversarial loss: 0.400745\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437064; batch adversarial loss: 0.498582\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417349; batch adversarial loss: 0.507440\n",
      "epoch 70; iter: 0; batch classifier loss: 0.309411; batch adversarial loss: 0.534797\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428829; batch adversarial loss: 0.498199\n",
      "epoch 72; iter: 0; batch classifier loss: 0.363376; batch adversarial loss: 0.479108\n",
      "epoch 73; iter: 0; batch classifier loss: 0.457828; batch adversarial loss: 0.506928\n",
      "epoch 74; iter: 0; batch classifier loss: 0.326712; batch adversarial loss: 0.621443\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417798; batch adversarial loss: 0.564671\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383434; batch adversarial loss: 0.552859\n",
      "epoch 77; iter: 0; batch classifier loss: 0.314587; batch adversarial loss: 0.477329\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448097; batch adversarial loss: 0.488474\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381591; batch adversarial loss: 0.537492\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406358; batch adversarial loss: 0.562091\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405583; batch adversarial loss: 0.554955\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352776; batch adversarial loss: 0.572631\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369040; batch adversarial loss: 0.469157\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435669; batch adversarial loss: 0.537274\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408851; batch adversarial loss: 0.525820\n",
      "epoch 86; iter: 0; batch classifier loss: 0.441740; batch adversarial loss: 0.497526\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350356; batch adversarial loss: 0.609634\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363280; batch adversarial loss: 0.497221\n",
      "epoch 89; iter: 0; batch classifier loss: 0.474836; batch adversarial loss: 0.496617\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371599; batch adversarial loss: 0.534666\n",
      "epoch 91; iter: 0; batch classifier loss: 0.424628; batch adversarial loss: 0.535063\n",
      "epoch 92; iter: 0; batch classifier loss: 0.430541; batch adversarial loss: 0.507308\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431341; batch adversarial loss: 0.571989\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449093; batch adversarial loss: 0.478303\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402441; batch adversarial loss: 0.544224\n",
      "epoch 96; iter: 0; batch classifier loss: 0.407047; batch adversarial loss: 0.573949\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383027; batch adversarial loss: 0.545341\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397492; batch adversarial loss: 0.553892\n",
      "epoch 99; iter: 0; batch classifier loss: 0.502690; batch adversarial loss: 0.505740\n",
      "epoch 100; iter: 0; batch classifier loss: 0.448423; batch adversarial loss: 0.477925\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390359; batch adversarial loss: 0.477098\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357562; batch adversarial loss: 0.515258\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361031; batch adversarial loss: 0.573823\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363738; batch adversarial loss: 0.545146\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391427; batch adversarial loss: 0.448829\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413876; batch adversarial loss: 0.468880\n",
      "epoch 107; iter: 0; batch classifier loss: 0.329781; batch adversarial loss: 0.467974\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387500; batch adversarial loss: 0.571928\n",
      "epoch 109; iter: 0; batch classifier loss: 0.293001; batch adversarial loss: 0.467397\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343174; batch adversarial loss: 0.505946\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387470; batch adversarial loss: 0.630850\n",
      "epoch 112; iter: 0; batch classifier loss: 0.354136; batch adversarial loss: 0.602405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.322307; batch adversarial loss: 0.478574\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346123; batch adversarial loss: 0.524714\n",
      "epoch 115; iter: 0; batch classifier loss: 0.324382; batch adversarial loss: 0.525414\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388100; batch adversarial loss: 0.563083\n",
      "epoch 117; iter: 0; batch classifier loss: 0.355073; batch adversarial loss: 0.525270\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406479; batch adversarial loss: 0.601776\n",
      "epoch 119; iter: 0; batch classifier loss: 0.419907; batch adversarial loss: 0.469014\n",
      "epoch 120; iter: 0; batch classifier loss: 0.396351; batch adversarial loss: 0.515832\n",
      "epoch 121; iter: 0; batch classifier loss: 0.315149; batch adversarial loss: 0.515306\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364867; batch adversarial loss: 0.496455\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348333; batch adversarial loss: 0.518138\n",
      "epoch 124; iter: 0; batch classifier loss: 0.413274; batch adversarial loss: 0.525867\n",
      "epoch 125; iter: 0; batch classifier loss: 0.407971; batch adversarial loss: 0.648580\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314593; batch adversarial loss: 0.459151\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390171; batch adversarial loss: 0.554074\n",
      "epoch 128; iter: 0; batch classifier loss: 0.337699; batch adversarial loss: 0.478382\n",
      "epoch 129; iter: 0; batch classifier loss: 0.428043; batch adversarial loss: 0.450193\n",
      "epoch 130; iter: 0; batch classifier loss: 0.336976; batch adversarial loss: 0.535787\n",
      "epoch 131; iter: 0; batch classifier loss: 0.423106; batch adversarial loss: 0.554078\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382211; batch adversarial loss: 0.563335\n",
      "epoch 133; iter: 0; batch classifier loss: 0.449085; batch adversarial loss: 0.506413\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377504; batch adversarial loss: 0.515878\n",
      "epoch 135; iter: 0; batch classifier loss: 0.345808; batch adversarial loss: 0.458330\n",
      "epoch 136; iter: 0; batch classifier loss: 0.442194; batch adversarial loss: 0.610193\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386966; batch adversarial loss: 0.458850\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364047; batch adversarial loss: 0.506686\n",
      "epoch 139; iter: 0; batch classifier loss: 0.431246; batch adversarial loss: 0.649609\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360869; batch adversarial loss: 0.496434\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365186; batch adversarial loss: 0.525361\n",
      "epoch 142; iter: 0; batch classifier loss: 0.337714; batch adversarial loss: 0.583150\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383129; batch adversarial loss: 0.497207\n",
      "epoch 144; iter: 0; batch classifier loss: 0.452448; batch adversarial loss: 0.572957\n",
      "epoch 145; iter: 0; batch classifier loss: 0.406912; batch adversarial loss: 0.544423\n",
      "epoch 146; iter: 0; batch classifier loss: 0.340920; batch adversarial loss: 0.572725\n",
      "epoch 147; iter: 0; batch classifier loss: 0.434862; batch adversarial loss: 0.611374\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376380; batch adversarial loss: 0.506730\n",
      "epoch 149; iter: 0; batch classifier loss: 0.403494; batch adversarial loss: 0.544590\n",
      "epoch 150; iter: 0; batch classifier loss: 0.424798; batch adversarial loss: 0.459460\n",
      "epoch 151; iter: 0; batch classifier loss: 0.380996; batch adversarial loss: 0.667621\n",
      "epoch 152; iter: 0; batch classifier loss: 0.359423; batch adversarial loss: 0.477958\n",
      "epoch 153; iter: 0; batch classifier loss: 0.300697; batch adversarial loss: 0.401463\n",
      "epoch 154; iter: 0; batch classifier loss: 0.331745; batch adversarial loss: 0.497097\n",
      "epoch 155; iter: 0; batch classifier loss: 0.315504; batch adversarial loss: 0.553671\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371806; batch adversarial loss: 0.478687\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363267; batch adversarial loss: 0.553545\n",
      "epoch 158; iter: 0; batch classifier loss: 0.400641; batch adversarial loss: 0.459360\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351487; batch adversarial loss: 0.611553\n",
      "epoch 160; iter: 0; batch classifier loss: 0.271234; batch adversarial loss: 0.649350\n",
      "epoch 161; iter: 0; batch classifier loss: 0.327125; batch adversarial loss: 0.573045\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382488; batch adversarial loss: 0.544040\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366236; batch adversarial loss: 0.497429\n",
      "epoch 164; iter: 0; batch classifier loss: 0.300038; batch adversarial loss: 0.507155\n",
      "epoch 165; iter: 0; batch classifier loss: 0.407584; batch adversarial loss: 0.487042\n",
      "epoch 166; iter: 0; batch classifier loss: 0.321571; batch adversarial loss: 0.554069\n",
      "epoch 167; iter: 0; batch classifier loss: 0.292794; batch adversarial loss: 0.507222\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333261; batch adversarial loss: 0.468421\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379401; batch adversarial loss: 0.563622\n",
      "epoch 170; iter: 0; batch classifier loss: 0.401326; batch adversarial loss: 0.564116\n",
      "epoch 171; iter: 0; batch classifier loss: 0.337773; batch adversarial loss: 0.554202\n",
      "epoch 172; iter: 0; batch classifier loss: 0.337665; batch adversarial loss: 0.573839\n",
      "epoch 173; iter: 0; batch classifier loss: 0.374366; batch adversarial loss: 0.553771\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325092; batch adversarial loss: 0.592098\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363506; batch adversarial loss: 0.582705\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335078; batch adversarial loss: 0.535313\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391752; batch adversarial loss: 0.468304\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374937; batch adversarial loss: 0.534949\n",
      "epoch 179; iter: 0; batch classifier loss: 0.299564; batch adversarial loss: 0.516098\n",
      "epoch 180; iter: 0; batch classifier loss: 0.402912; batch adversarial loss: 0.554662\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383816; batch adversarial loss: 0.487232\n",
      "epoch 182; iter: 0; batch classifier loss: 0.323191; batch adversarial loss: 0.535815\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313351; batch adversarial loss: 0.544618\n",
      "epoch 184; iter: 0; batch classifier loss: 0.411566; batch adversarial loss: 0.649643\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315776; batch adversarial loss: 0.573438\n",
      "epoch 186; iter: 0; batch classifier loss: 0.405020; batch adversarial loss: 0.534955\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325517; batch adversarial loss: 0.497636\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371203; batch adversarial loss: 0.601754\n",
      "epoch 189; iter: 0; batch classifier loss: 0.451650; batch adversarial loss: 0.516339\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326916; batch adversarial loss: 0.582412\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365518; batch adversarial loss: 0.477408\n",
      "epoch 192; iter: 0; batch classifier loss: 0.312389; batch adversarial loss: 0.601654\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350527; batch adversarial loss: 0.506127\n",
      "epoch 194; iter: 0; batch classifier loss: 0.276336; batch adversarial loss: 0.477903\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343128; batch adversarial loss: 0.544503\n",
      "epoch 196; iter: 0; batch classifier loss: 0.307237; batch adversarial loss: 0.601644\n",
      "epoch 197; iter: 0; batch classifier loss: 0.410677; batch adversarial loss: 0.525726\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343288; batch adversarial loss: 0.534922\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342220; batch adversarial loss: 0.526036\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741374; batch adversarial loss: 0.924063\n",
      "epoch 1; iter: 0; batch classifier loss: 0.745633; batch adversarial loss: 0.976869\n",
      "epoch 2; iter: 0; batch classifier loss: 0.766797; batch adversarial loss: 0.933443\n",
      "epoch 3; iter: 0; batch classifier loss: 0.634187; batch adversarial loss: 0.821262\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610529; batch adversarial loss: 0.752901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512832; batch adversarial loss: 0.682472\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555796; batch adversarial loss: 0.677915\n",
      "epoch 7; iter: 0; batch classifier loss: 0.502204; batch adversarial loss: 0.612941\n",
      "epoch 8; iter: 0; batch classifier loss: 0.489827; batch adversarial loss: 0.637766\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502120; batch adversarial loss: 0.641702\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503425; batch adversarial loss: 0.574967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.524898; batch adversarial loss: 0.586116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498387; batch adversarial loss: 0.616548\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553411; batch adversarial loss: 0.542644\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471134; batch adversarial loss: 0.594518\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534833; batch adversarial loss: 0.576262\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460673; batch adversarial loss: 0.573781\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518378; batch adversarial loss: 0.559134\n",
      "epoch 18; iter: 0; batch classifier loss: 0.494086; batch adversarial loss: 0.536553\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482028; batch adversarial loss: 0.603694\n",
      "epoch 20; iter: 0; batch classifier loss: 0.540882; batch adversarial loss: 0.568392\n",
      "epoch 21; iter: 0; batch classifier loss: 0.402305; batch adversarial loss: 0.602074\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515359; batch adversarial loss: 0.542471\n",
      "epoch 23; iter: 0; batch classifier loss: 0.530824; batch adversarial loss: 0.561763\n",
      "epoch 24; iter: 0; batch classifier loss: 0.380905; batch adversarial loss: 0.565315\n",
      "epoch 25; iter: 0; batch classifier loss: 0.469703; batch adversarial loss: 0.568316\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493738; batch adversarial loss: 0.632837\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464933; batch adversarial loss: 0.571719\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433610; batch adversarial loss: 0.576793\n",
      "epoch 29; iter: 0; batch classifier loss: 0.426260; batch adversarial loss: 0.617750\n",
      "epoch 30; iter: 0; batch classifier loss: 0.519716; batch adversarial loss: 0.536354\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454185; batch adversarial loss: 0.549536\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414629; batch adversarial loss: 0.543975\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465309; batch adversarial loss: 0.469254\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450303; batch adversarial loss: 0.495049\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449682; batch adversarial loss: 0.571456\n",
      "epoch 36; iter: 0; batch classifier loss: 0.423965; batch adversarial loss: 0.546153\n",
      "epoch 37; iter: 0; batch classifier loss: 0.401341; batch adversarial loss: 0.541458\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463839; batch adversarial loss: 0.504438\n",
      "epoch 39; iter: 0; batch classifier loss: 0.516078; batch adversarial loss: 0.489999\n",
      "epoch 40; iter: 0; batch classifier loss: 0.363119; batch adversarial loss: 0.524849\n",
      "epoch 41; iter: 0; batch classifier loss: 0.457613; batch adversarial loss: 0.555346\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429601; batch adversarial loss: 0.575241\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451813; batch adversarial loss: 0.528084\n",
      "epoch 44; iter: 0; batch classifier loss: 0.535104; batch adversarial loss: 0.524753\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409075; batch adversarial loss: 0.561177\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374534; batch adversarial loss: 0.571700\n",
      "epoch 47; iter: 0; batch classifier loss: 0.402288; batch adversarial loss: 0.591009\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386249; batch adversarial loss: 0.538453\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410185; batch adversarial loss: 0.523591\n",
      "epoch 50; iter: 0; batch classifier loss: 0.497566; batch adversarial loss: 0.521031\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400010; batch adversarial loss: 0.601735\n",
      "epoch 52; iter: 0; batch classifier loss: 0.333859; batch adversarial loss: 0.563560\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401484; batch adversarial loss: 0.562718\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393059; batch adversarial loss: 0.518772\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417307; batch adversarial loss: 0.602559\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425352; batch adversarial loss: 0.619524\n",
      "epoch 57; iter: 0; batch classifier loss: 0.451711; batch adversarial loss: 0.622052\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417579; batch adversarial loss: 0.597803\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402889; batch adversarial loss: 0.574206\n",
      "epoch 60; iter: 0; batch classifier loss: 0.360835; batch adversarial loss: 0.573994\n",
      "epoch 61; iter: 0; batch classifier loss: 0.448809; batch adversarial loss: 0.563127\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439543; batch adversarial loss: 0.578320\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447782; batch adversarial loss: 0.480119\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405179; batch adversarial loss: 0.497040\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433807; batch adversarial loss: 0.551722\n",
      "epoch 66; iter: 0; batch classifier loss: 0.333562; batch adversarial loss: 0.598731\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379876; batch adversarial loss: 0.542526\n",
      "epoch 68; iter: 0; batch classifier loss: 0.340674; batch adversarial loss: 0.591259\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378765; batch adversarial loss: 0.609054\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368094; batch adversarial loss: 0.534777\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407668; batch adversarial loss: 0.486756\n",
      "epoch 72; iter: 0; batch classifier loss: 0.339108; batch adversarial loss: 0.607515\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369483; batch adversarial loss: 0.570276\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413887; batch adversarial loss: 0.469896\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369810; batch adversarial loss: 0.553556\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375403; batch adversarial loss: 0.606812\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422465; batch adversarial loss: 0.479623\n",
      "epoch 78; iter: 0; batch classifier loss: 0.423955; batch adversarial loss: 0.522710\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400572; batch adversarial loss: 0.599058\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384798; batch adversarial loss: 0.548169\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424250; batch adversarial loss: 0.557035\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401063; batch adversarial loss: 0.554429\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406747; batch adversarial loss: 0.529437\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380266; batch adversarial loss: 0.584486\n",
      "epoch 85; iter: 0; batch classifier loss: 0.429253; batch adversarial loss: 0.567226\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416527; batch adversarial loss: 0.496271\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390751; batch adversarial loss: 0.493133\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387958; batch adversarial loss: 0.498995\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417469; batch adversarial loss: 0.556054\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408853; batch adversarial loss: 0.572069\n",
      "epoch 91; iter: 0; batch classifier loss: 0.330858; batch adversarial loss: 0.612703\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402087; batch adversarial loss: 0.575314\n",
      "epoch 93; iter: 0; batch classifier loss: 0.388254; batch adversarial loss: 0.489825\n",
      "epoch 94; iter: 0; batch classifier loss: 0.342276; batch adversarial loss: 0.535229\n",
      "epoch 95; iter: 0; batch classifier loss: 0.334046; batch adversarial loss: 0.544059\n",
      "epoch 96; iter: 0; batch classifier loss: 0.461232; batch adversarial loss: 0.583805\n",
      "epoch 97; iter: 0; batch classifier loss: 0.309465; batch adversarial loss: 0.524498\n",
      "epoch 98; iter: 0; batch classifier loss: 0.405672; batch adversarial loss: 0.490069\n",
      "epoch 99; iter: 0; batch classifier loss: 0.333994; batch adversarial loss: 0.524422\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374192; batch adversarial loss: 0.572766\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344332; batch adversarial loss: 0.563764\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386590; batch adversarial loss: 0.507292\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356382; batch adversarial loss: 0.579401\n",
      "epoch 104; iter: 0; batch classifier loss: 0.357119; batch adversarial loss: 0.544908\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373355; batch adversarial loss: 0.516756\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434866; batch adversarial loss: 0.574587\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399634; batch adversarial loss: 0.508131\n",
      "epoch 108; iter: 0; batch classifier loss: 0.319445; batch adversarial loss: 0.563210\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367033; batch adversarial loss: 0.572759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.416356; batch adversarial loss: 0.481495\n",
      "epoch 111; iter: 0; batch classifier loss: 0.455003; batch adversarial loss: 0.543943\n",
      "epoch 112; iter: 0; batch classifier loss: 0.429793; batch adversarial loss: 0.609350\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382359; batch adversarial loss: 0.480600\n",
      "epoch 114; iter: 0; batch classifier loss: 0.476684; batch adversarial loss: 0.551842\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342344; batch adversarial loss: 0.579453\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393468; batch adversarial loss: 0.537954\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350252; batch adversarial loss: 0.526396\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401240; batch adversarial loss: 0.531263\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339494; batch adversarial loss: 0.525246\n",
      "epoch 120; iter: 0; batch classifier loss: 0.376271; batch adversarial loss: 0.570545\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334009; batch adversarial loss: 0.488540\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406542; batch adversarial loss: 0.517400\n",
      "epoch 123; iter: 0; batch classifier loss: 0.426252; batch adversarial loss: 0.582039\n",
      "epoch 124; iter: 0; batch classifier loss: 0.350648; batch adversarial loss: 0.591834\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376818; batch adversarial loss: 0.554044\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395819; batch adversarial loss: 0.404501\n",
      "epoch 127; iter: 0; batch classifier loss: 0.425812; batch adversarial loss: 0.487708\n",
      "epoch 128; iter: 0; batch classifier loss: 0.393353; batch adversarial loss: 0.580711\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395184; batch adversarial loss: 0.478199\n",
      "epoch 130; iter: 0; batch classifier loss: 0.318596; batch adversarial loss: 0.582490\n",
      "epoch 131; iter: 0; batch classifier loss: 0.425989; batch adversarial loss: 0.619186\n",
      "epoch 132; iter: 0; batch classifier loss: 0.303526; batch adversarial loss: 0.526171\n",
      "epoch 133; iter: 0; batch classifier loss: 0.420876; batch adversarial loss: 0.533434\n",
      "epoch 134; iter: 0; batch classifier loss: 0.323291; batch adversarial loss: 0.591440\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336446; batch adversarial loss: 0.526282\n",
      "epoch 136; iter: 0; batch classifier loss: 0.335689; batch adversarial loss: 0.535375\n",
      "epoch 137; iter: 0; batch classifier loss: 0.294077; batch adversarial loss: 0.563462\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380531; batch adversarial loss: 0.525845\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388411; batch adversarial loss: 0.525245\n",
      "epoch 140; iter: 0; batch classifier loss: 0.318181; batch adversarial loss: 0.591253\n",
      "epoch 141; iter: 0; batch classifier loss: 0.438340; batch adversarial loss: 0.478614\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415208; batch adversarial loss: 0.478884\n",
      "epoch 143; iter: 0; batch classifier loss: 0.409135; batch adversarial loss: 0.582244\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360223; batch adversarial loss: 0.563249\n",
      "epoch 145; iter: 0; batch classifier loss: 0.293210; batch adversarial loss: 0.573405\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353552; batch adversarial loss: 0.580988\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349816; batch adversarial loss: 0.431872\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344961; batch adversarial loss: 0.525688\n",
      "epoch 149; iter: 0; batch classifier loss: 0.412834; batch adversarial loss: 0.516337\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384073; batch adversarial loss: 0.450749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.335494; batch adversarial loss: 0.581732\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360336; batch adversarial loss: 0.573139\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361025; batch adversarial loss: 0.497514\n",
      "epoch 154; iter: 0; batch classifier loss: 0.279973; batch adversarial loss: 0.562601\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365133; batch adversarial loss: 0.506320\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377001; batch adversarial loss: 0.507279\n",
      "epoch 157; iter: 0; batch classifier loss: 0.321429; batch adversarial loss: 0.581928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.420957; batch adversarial loss: 0.516757\n",
      "epoch 159; iter: 0; batch classifier loss: 0.395189; batch adversarial loss: 0.562339\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308995; batch adversarial loss: 0.609328\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347380; batch adversarial loss: 0.544869\n",
      "epoch 162; iter: 0; batch classifier loss: 0.309130; batch adversarial loss: 0.478349\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342150; batch adversarial loss: 0.562336\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366937; batch adversarial loss: 0.526785\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321047; batch adversarial loss: 0.609362\n",
      "epoch 166; iter: 0; batch classifier loss: 0.417883; batch adversarial loss: 0.525648\n",
      "epoch 167; iter: 0; batch classifier loss: 0.279834; batch adversarial loss: 0.563287\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340275; batch adversarial loss: 0.470117\n",
      "epoch 169; iter: 0; batch classifier loss: 0.419233; batch adversarial loss: 0.534093\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354413; batch adversarial loss: 0.617488\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370757; batch adversarial loss: 0.583000\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364996; batch adversarial loss: 0.535456\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378970; batch adversarial loss: 0.543157\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338437; batch adversarial loss: 0.647588\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363633; batch adversarial loss: 0.602123\n",
      "epoch 176; iter: 0; batch classifier loss: 0.421894; batch adversarial loss: 0.543975\n",
      "epoch 177; iter: 0; batch classifier loss: 0.416834; batch adversarial loss: 0.572038\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332286; batch adversarial loss: 0.505074\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407782; batch adversarial loss: 0.542968\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351521; batch adversarial loss: 0.517462\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383573; batch adversarial loss: 0.537491\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324014; batch adversarial loss: 0.580750\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332628; batch adversarial loss: 0.544657\n",
      "epoch 184; iter: 0; batch classifier loss: 0.435542; batch adversarial loss: 0.551597\n",
      "epoch 185; iter: 0; batch classifier loss: 0.437034; batch adversarial loss: 0.543733\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350120; batch adversarial loss: 0.564212\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350465; batch adversarial loss: 0.561099\n",
      "epoch 188; iter: 0; batch classifier loss: 0.422474; batch adversarial loss: 0.533865\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384856; batch adversarial loss: 0.591520\n",
      "epoch 190; iter: 0; batch classifier loss: 0.315186; batch adversarial loss: 0.591434\n",
      "epoch 191; iter: 0; batch classifier loss: 0.358448; batch adversarial loss: 0.497778\n",
      "epoch 192; iter: 0; batch classifier loss: 0.412077; batch adversarial loss: 0.506315\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353455; batch adversarial loss: 0.590566\n",
      "epoch 194; iter: 0; batch classifier loss: 0.299618; batch adversarial loss: 0.496610\n",
      "epoch 195; iter: 0; batch classifier loss: 0.269923; batch adversarial loss: 0.535649\n",
      "epoch 196; iter: 0; batch classifier loss: 0.333112; batch adversarial loss: 0.551105\n",
      "epoch 197; iter: 0; batch classifier loss: 0.289033; batch adversarial loss: 0.516470\n",
      "epoch 198; iter: 0; batch classifier loss: 0.510019; batch adversarial loss: 0.476521\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387225; batch adversarial loss: 0.601140\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684268; batch adversarial loss: 0.688048\n",
      "epoch 1; iter: 0; batch classifier loss: 0.648954; batch adversarial loss: 0.652762\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575440; batch adversarial loss: 0.632656\n",
      "epoch 3; iter: 0; batch classifier loss: 0.497504; batch adversarial loss: 0.623401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568161; batch adversarial loss: 0.634012\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533361; batch adversarial loss: 0.609731\n",
      "epoch 6; iter: 0; batch classifier loss: 0.556144; batch adversarial loss: 0.558724\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624311; batch adversarial loss: 0.596669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.581029; batch adversarial loss: 0.572981\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563580; batch adversarial loss: 0.540678\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514253; batch adversarial loss: 0.592425\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546074; batch adversarial loss: 0.583576\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567980; batch adversarial loss: 0.584268\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473075; batch adversarial loss: 0.536987\n",
      "epoch 14; iter: 0; batch classifier loss: 0.457127; batch adversarial loss: 0.599633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542900; batch adversarial loss: 0.490031\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528637; batch adversarial loss: 0.600883\n",
      "epoch 17; iter: 0; batch classifier loss: 0.444059; batch adversarial loss: 0.580428\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472179; batch adversarial loss: 0.545193\n",
      "epoch 19; iter: 0; batch classifier loss: 0.409890; batch adversarial loss: 0.533104\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499427; batch adversarial loss: 0.529383\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526705; batch adversarial loss: 0.564314\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474875; batch adversarial loss: 0.508106\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479574; batch adversarial loss: 0.619696\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466135; batch adversarial loss: 0.555838\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452784; batch adversarial loss: 0.546808\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490390; batch adversarial loss: 0.517951\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472362; batch adversarial loss: 0.519855\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422127; batch adversarial loss: 0.500677\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465191; batch adversarial loss: 0.521062\n",
      "epoch 30; iter: 0; batch classifier loss: 0.569242; batch adversarial loss: 0.498403\n",
      "epoch 31; iter: 0; batch classifier loss: 0.508846; batch adversarial loss: 0.519674\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467360; batch adversarial loss: 0.626989\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460850; batch adversarial loss: 0.588287\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449424; batch adversarial loss: 0.587969\n",
      "epoch 35; iter: 0; batch classifier loss: 0.497607; batch adversarial loss: 0.589896\n",
      "epoch 36; iter: 0; batch classifier loss: 0.510558; batch adversarial loss: 0.536739\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493382; batch adversarial loss: 0.553468\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469141; batch adversarial loss: 0.631709\n",
      "epoch 39; iter: 0; batch classifier loss: 0.506309; batch adversarial loss: 0.518779\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441016; batch adversarial loss: 0.526194\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429330; batch adversarial loss: 0.562309\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438243; batch adversarial loss: 0.499203\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442755; batch adversarial loss: 0.508350\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466635; batch adversarial loss: 0.550104\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446586; batch adversarial loss: 0.453811\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419839; batch adversarial loss: 0.545399\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471652; batch adversarial loss: 0.537544\n",
      "epoch 48; iter: 0; batch classifier loss: 0.395935; batch adversarial loss: 0.604559\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416728; batch adversarial loss: 0.638570\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393587; batch adversarial loss: 0.567454\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464715; batch adversarial loss: 0.604709\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416952; batch adversarial loss: 0.540084\n",
      "epoch 53; iter: 0; batch classifier loss: 0.489230; batch adversarial loss: 0.552713\n",
      "epoch 54; iter: 0; batch classifier loss: 0.510638; batch adversarial loss: 0.571090\n",
      "epoch 55; iter: 0; batch classifier loss: 0.350606; batch adversarial loss: 0.585466\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466745; batch adversarial loss: 0.555047\n",
      "epoch 57; iter: 0; batch classifier loss: 0.359000; batch adversarial loss: 0.508044\n",
      "epoch 58; iter: 0; batch classifier loss: 0.453445; batch adversarial loss: 0.543459\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428328; batch adversarial loss: 0.515663\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394664; batch adversarial loss: 0.656971\n",
      "epoch 61; iter: 0; batch classifier loss: 0.394391; batch adversarial loss: 0.590550\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394433; batch adversarial loss: 0.498338\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395208; batch adversarial loss: 0.432441\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425490; batch adversarial loss: 0.507658\n",
      "epoch 65; iter: 0; batch classifier loss: 0.496009; batch adversarial loss: 0.580302\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419560; batch adversarial loss: 0.490777\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404526; batch adversarial loss: 0.570380\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438250; batch adversarial loss: 0.533218\n",
      "epoch 69; iter: 0; batch classifier loss: 0.500139; batch adversarial loss: 0.508067\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384223; batch adversarial loss: 0.551331\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448680; batch adversarial loss: 0.570591\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417380; batch adversarial loss: 0.462912\n",
      "epoch 73; iter: 0; batch classifier loss: 0.406282; batch adversarial loss: 0.499068\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441729; batch adversarial loss: 0.580283\n",
      "epoch 75; iter: 0; batch classifier loss: 0.472988; batch adversarial loss: 0.564543\n",
      "epoch 76; iter: 0; batch classifier loss: 0.320823; batch adversarial loss: 0.526521\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382611; batch adversarial loss: 0.563819\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391394; batch adversarial loss: 0.535376\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373852; batch adversarial loss: 0.554929\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408146; batch adversarial loss: 0.491194\n",
      "epoch 81; iter: 0; batch classifier loss: 0.450288; batch adversarial loss: 0.544725\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418244; batch adversarial loss: 0.553765\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381725; batch adversarial loss: 0.543361\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386956; batch adversarial loss: 0.542026\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397598; batch adversarial loss: 0.554624\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370458; batch adversarial loss: 0.562026\n",
      "epoch 87; iter: 0; batch classifier loss: 0.435652; batch adversarial loss: 0.544348\n",
      "epoch 88; iter: 0; batch classifier loss: 0.316122; batch adversarial loss: 0.525733\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424370; batch adversarial loss: 0.655081\n",
      "epoch 90; iter: 0; batch classifier loss: 0.366264; batch adversarial loss: 0.525874\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383464; batch adversarial loss: 0.535361\n",
      "epoch 92; iter: 0; batch classifier loss: 0.356975; batch adversarial loss: 0.645909\n",
      "epoch 93; iter: 0; batch classifier loss: 0.331486; batch adversarial loss: 0.589182\n",
      "epoch 94; iter: 0; batch classifier loss: 0.352732; batch adversarial loss: 0.489351\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393454; batch adversarial loss: 0.608783\n",
      "epoch 96; iter: 0; batch classifier loss: 0.323014; batch adversarial loss: 0.563395\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397342; batch adversarial loss: 0.534980\n",
      "epoch 98; iter: 0; batch classifier loss: 0.423590; batch adversarial loss: 0.498092\n",
      "epoch 99; iter: 0; batch classifier loss: 0.307367; batch adversarial loss: 0.545497\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365843; batch adversarial loss: 0.517047\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390284; batch adversarial loss: 0.553762\n",
      "epoch 102; iter: 0; batch classifier loss: 0.413055; batch adversarial loss: 0.591620\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403547; batch adversarial loss: 0.534915\n",
      "epoch 104; iter: 0; batch classifier loss: 0.334673; batch adversarial loss: 0.526265\n",
      "epoch 105; iter: 0; batch classifier loss: 0.333906; batch adversarial loss: 0.552692\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367503; batch adversarial loss: 0.544772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.399789; batch adversarial loss: 0.534895\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336424; batch adversarial loss: 0.573264\n",
      "epoch 109; iter: 0; batch classifier loss: 0.411231; batch adversarial loss: 0.590831\n",
      "epoch 110; iter: 0; batch classifier loss: 0.309552; batch adversarial loss: 0.517442\n",
      "epoch 111; iter: 0; batch classifier loss: 0.312995; batch adversarial loss: 0.553657\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430896; batch adversarial loss: 0.544409\n",
      "epoch 113; iter: 0; batch classifier loss: 0.332103; batch adversarial loss: 0.506785\n",
      "epoch 114; iter: 0; batch classifier loss: 0.339125; batch adversarial loss: 0.527431\n",
      "epoch 115; iter: 0; batch classifier loss: 0.466457; batch adversarial loss: 0.500977\n",
      "epoch 116; iter: 0; batch classifier loss: 0.293750; batch adversarial loss: 0.572497\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368619; batch adversarial loss: 0.516383\n",
      "epoch 118; iter: 0; batch classifier loss: 0.346537; batch adversarial loss: 0.435335\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366852; batch adversarial loss: 0.517129\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382215; batch adversarial loss: 0.663607\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362998; batch adversarial loss: 0.581573\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366682; batch adversarial loss: 0.544530\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389590; batch adversarial loss: 0.599771\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373288; batch adversarial loss: 0.553540\n",
      "epoch 125; iter: 0; batch classifier loss: 0.354477; batch adversarial loss: 0.554297\n",
      "epoch 126; iter: 0; batch classifier loss: 0.283708; batch adversarial loss: 0.570803\n",
      "epoch 127; iter: 0; batch classifier loss: 0.322536; batch adversarial loss: 0.572382\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365462; batch adversarial loss: 0.544756\n",
      "epoch 129; iter: 0; batch classifier loss: 0.353009; batch adversarial loss: 0.562323\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355148; batch adversarial loss: 0.537498\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383548; batch adversarial loss: 0.515941\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395551; batch adversarial loss: 0.544121\n",
      "epoch 133; iter: 0; batch classifier loss: 0.265964; batch adversarial loss: 0.590221\n",
      "epoch 134; iter: 0; batch classifier loss: 0.287564; batch adversarial loss: 0.553111\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336779; batch adversarial loss: 0.535702\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387872; batch adversarial loss: 0.526935\n",
      "epoch 137; iter: 0; batch classifier loss: 0.420316; batch adversarial loss: 0.571301\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357124; batch adversarial loss: 0.480523\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366724; batch adversarial loss: 0.607465\n",
      "epoch 140; iter: 0; batch classifier loss: 0.370101; batch adversarial loss: 0.536328\n",
      "epoch 141; iter: 0; batch classifier loss: 0.264666; batch adversarial loss: 0.573732\n",
      "epoch 142; iter: 0; batch classifier loss: 0.432663; batch adversarial loss: 0.517421\n",
      "epoch 143; iter: 0; batch classifier loss: 0.433587; batch adversarial loss: 0.508267\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357622; batch adversarial loss: 0.535486\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364054; batch adversarial loss: 0.498374\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317236; batch adversarial loss: 0.488924\n",
      "epoch 147; iter: 0; batch classifier loss: 0.375857; batch adversarial loss: 0.535942\n",
      "epoch 148; iter: 0; batch classifier loss: 0.404600; batch adversarial loss: 0.598664\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349401; batch adversarial loss: 0.515696\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363832; batch adversarial loss: 0.580213\n",
      "epoch 151; iter: 0; batch classifier loss: 0.307883; batch adversarial loss: 0.564129\n",
      "epoch 152; iter: 0; batch classifier loss: 0.456028; batch adversarial loss: 0.580399\n",
      "epoch 153; iter: 0; batch classifier loss: 0.412336; batch adversarial loss: 0.537042\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397108; batch adversarial loss: 0.563606\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346235; batch adversarial loss: 0.499386\n",
      "epoch 156; iter: 0; batch classifier loss: 0.434953; batch adversarial loss: 0.507939\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314950; batch adversarial loss: 0.582433\n",
      "epoch 158; iter: 0; batch classifier loss: 0.331510; batch adversarial loss: 0.508175\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391649; batch adversarial loss: 0.526598\n",
      "epoch 160; iter: 0; batch classifier loss: 0.431621; batch adversarial loss: 0.525369\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367805; batch adversarial loss: 0.563836\n",
      "epoch 162; iter: 0; batch classifier loss: 0.295870; batch adversarial loss: 0.581998\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385197; batch adversarial loss: 0.516256\n",
      "epoch 164; iter: 0; batch classifier loss: 0.443843; batch adversarial loss: 0.544205\n",
      "epoch 165; iter: 0; batch classifier loss: 0.324615; batch adversarial loss: 0.616988\n",
      "epoch 166; iter: 0; batch classifier loss: 0.445738; batch adversarial loss: 0.582014\n",
      "epoch 167; iter: 0; batch classifier loss: 0.316346; batch adversarial loss: 0.627555\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389242; batch adversarial loss: 0.489859\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360065; batch adversarial loss: 0.489890\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336625; batch adversarial loss: 0.535838\n",
      "epoch 171; iter: 0; batch classifier loss: 0.235752; batch adversarial loss: 0.610351\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367117; batch adversarial loss: 0.516127\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410118; batch adversarial loss: 0.590788\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384481; batch adversarial loss: 0.581136\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380576; batch adversarial loss: 0.543539\n",
      "epoch 176; iter: 0; batch classifier loss: 0.430908; batch adversarial loss: 0.563258\n",
      "epoch 177; iter: 0; batch classifier loss: 0.388874; batch adversarial loss: 0.517096\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382225; batch adversarial loss: 0.606661\n",
      "epoch 179; iter: 0; batch classifier loss: 0.431990; batch adversarial loss: 0.517773\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388685; batch adversarial loss: 0.470226\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379025; batch adversarial loss: 0.600791\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405565; batch adversarial loss: 0.590822\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370348; batch adversarial loss: 0.535648\n",
      "epoch 184; iter: 0; batch classifier loss: 0.324469; batch adversarial loss: 0.617674\n",
      "epoch 185; iter: 0; batch classifier loss: 0.339205; batch adversarial loss: 0.452640\n",
      "epoch 186; iter: 0; batch classifier loss: 0.306155; batch adversarial loss: 0.517223\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375315; batch adversarial loss: 0.489675\n",
      "epoch 188; iter: 0; batch classifier loss: 0.321098; batch adversarial loss: 0.516746\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358597; batch adversarial loss: 0.562582\n",
      "epoch 190; iter: 0; batch classifier loss: 0.399482; batch adversarial loss: 0.552939\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330870; batch adversarial loss: 0.544133\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338634; batch adversarial loss: 0.524778\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342817; batch adversarial loss: 0.425581\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374749; batch adversarial loss: 0.590515\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376353; batch adversarial loss: 0.542465\n",
      "epoch 196; iter: 0; batch classifier loss: 0.276637; batch adversarial loss: 0.582125\n",
      "epoch 197; iter: 0; batch classifier loss: 0.460362; batch adversarial loss: 0.608549\n",
      "epoch 198; iter: 0; batch classifier loss: 0.449794; batch adversarial loss: 0.617065\n",
      "epoch 199; iter: 0; batch classifier loss: 0.410819; batch adversarial loss: 0.590933\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677781; batch adversarial loss: 0.637303\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609110; batch adversarial loss: 0.620050\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594109; batch adversarial loss: 0.647760\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575957; batch adversarial loss: 0.606853\n",
      "epoch 4; iter: 0; batch classifier loss: 0.613502; batch adversarial loss: 0.558342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.589605; batch adversarial loss: 0.634026\n",
      "epoch 6; iter: 0; batch classifier loss: 0.611602; batch adversarial loss: 0.587113\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481918; batch adversarial loss: 0.614588\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553618; batch adversarial loss: 0.585973\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551262; batch adversarial loss: 0.523692\n",
      "epoch 10; iter: 0; batch classifier loss: 0.447817; batch adversarial loss: 0.565073\n",
      "epoch 11; iter: 0; batch classifier loss: 0.482392; batch adversarial loss: 0.543336\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575185; batch adversarial loss: 0.589278\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542931; batch adversarial loss: 0.583235\n",
      "epoch 14; iter: 0; batch classifier loss: 0.404066; batch adversarial loss: 0.614952\n",
      "epoch 15; iter: 0; batch classifier loss: 0.532379; batch adversarial loss: 0.591294\n",
      "epoch 16; iter: 0; batch classifier loss: 0.574369; batch adversarial loss: 0.593321\n",
      "epoch 17; iter: 0; batch classifier loss: 0.599896; batch adversarial loss: 0.552964\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478687; batch adversarial loss: 0.572341\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518777; batch adversarial loss: 0.592899\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471300; batch adversarial loss: 0.542042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474062; batch adversarial loss: 0.516717\n",
      "epoch 22; iter: 0; batch classifier loss: 0.563572; batch adversarial loss: 0.539196\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470182; batch adversarial loss: 0.553033\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442483; batch adversarial loss: 0.550560\n",
      "epoch 25; iter: 0; batch classifier loss: 0.545762; batch adversarial loss: 0.603212\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513649; batch adversarial loss: 0.517259\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529119; batch adversarial loss: 0.585511\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475072; batch adversarial loss: 0.560981\n",
      "epoch 29; iter: 0; batch classifier loss: 0.498351; batch adversarial loss: 0.569962\n",
      "epoch 30; iter: 0; batch classifier loss: 0.517942; batch adversarial loss: 0.570237\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459475; batch adversarial loss: 0.524967\n",
      "epoch 32; iter: 0; batch classifier loss: 0.427226; batch adversarial loss: 0.528990\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514196; batch adversarial loss: 0.553541\n",
      "epoch 34; iter: 0; batch classifier loss: 0.444795; batch adversarial loss: 0.641469\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430294; batch adversarial loss: 0.466770\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448754; batch adversarial loss: 0.484941\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500282; batch adversarial loss: 0.500813\n",
      "epoch 38; iter: 0; batch classifier loss: 0.376377; batch adversarial loss: 0.640426\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437159; batch adversarial loss: 0.572909\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459493; batch adversarial loss: 0.517089\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418369; batch adversarial loss: 0.526975\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462338; batch adversarial loss: 0.598835\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401555; batch adversarial loss: 0.503801\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477499; batch adversarial loss: 0.598053\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479925; batch adversarial loss: 0.584028\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412471; batch adversarial loss: 0.509445\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456920; batch adversarial loss: 0.553741\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456608; batch adversarial loss: 0.563572\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427630; batch adversarial loss: 0.507663\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442845; batch adversarial loss: 0.479785\n",
      "epoch 51; iter: 0; batch classifier loss: 0.539405; batch adversarial loss: 0.470943\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466287; batch adversarial loss: 0.542580\n",
      "epoch 53; iter: 0; batch classifier loss: 0.440538; batch adversarial loss: 0.575087\n",
      "epoch 54; iter: 0; batch classifier loss: 0.480862; batch adversarial loss: 0.571179\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394214; batch adversarial loss: 0.608209\n",
      "epoch 56; iter: 0; batch classifier loss: 0.342801; batch adversarial loss: 0.598676\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448285; batch adversarial loss: 0.508647\n",
      "epoch 58; iter: 0; batch classifier loss: 0.491846; batch adversarial loss: 0.587459\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427506; batch adversarial loss: 0.573560\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431434; batch adversarial loss: 0.542202\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436498; batch adversarial loss: 0.537074\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439685; batch adversarial loss: 0.597844\n",
      "epoch 63; iter: 0; batch classifier loss: 0.439711; batch adversarial loss: 0.629448\n",
      "epoch 64; iter: 0; batch classifier loss: 0.491811; batch adversarial loss: 0.508810\n",
      "epoch 65; iter: 0; batch classifier loss: 0.462666; batch adversarial loss: 0.542744\n",
      "epoch 66; iter: 0; batch classifier loss: 0.521732; batch adversarial loss: 0.469040\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460916; batch adversarial loss: 0.530706\n",
      "epoch 68; iter: 0; batch classifier loss: 0.498533; batch adversarial loss: 0.573275\n",
      "epoch 69; iter: 0; batch classifier loss: 0.495208; batch adversarial loss: 0.487968\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445700; batch adversarial loss: 0.497813\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398225; batch adversarial loss: 0.561051\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403468; batch adversarial loss: 0.587911\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421343; batch adversarial loss: 0.507926\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397041; batch adversarial loss: 0.572255\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422859; batch adversarial loss: 0.521640\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465279; batch adversarial loss: 0.486659\n",
      "epoch 77; iter: 0; batch classifier loss: 0.319988; batch adversarial loss: 0.550934\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354192; batch adversarial loss: 0.591858\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425831; batch adversarial loss: 0.524651\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435381; batch adversarial loss: 0.597595\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394662; batch adversarial loss: 0.549513\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418638; batch adversarial loss: 0.612791\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370487; batch adversarial loss: 0.595542\n",
      "epoch 84; iter: 0; batch classifier loss: 0.472087; batch adversarial loss: 0.499604\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407097; batch adversarial loss: 0.666429\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427751; batch adversarial loss: 0.517414\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412722; batch adversarial loss: 0.560483\n",
      "epoch 88; iter: 0; batch classifier loss: 0.470026; batch adversarial loss: 0.591776\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409143; batch adversarial loss: 0.509767\n",
      "epoch 90; iter: 0; batch classifier loss: 0.460770; batch adversarial loss: 0.529074\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360063; batch adversarial loss: 0.520507\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411350; batch adversarial loss: 0.544781\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409118; batch adversarial loss: 0.535572\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434717; batch adversarial loss: 0.583233\n",
      "epoch 95; iter: 0; batch classifier loss: 0.432199; batch adversarial loss: 0.545099\n",
      "epoch 96; iter: 0; batch classifier loss: 0.479276; batch adversarial loss: 0.500876\n",
      "epoch 97; iter: 0; batch classifier loss: 0.419616; batch adversarial loss: 0.535926\n",
      "epoch 98; iter: 0; batch classifier loss: 0.475010; batch adversarial loss: 0.536094\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376930; batch adversarial loss: 0.524631\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345678; batch adversarial loss: 0.560527\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368846; batch adversarial loss: 0.471566\n",
      "epoch 102; iter: 0; batch classifier loss: 0.451015; batch adversarial loss: 0.488553\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406880; batch adversarial loss: 0.598928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.380279; batch adversarial loss: 0.480610\n",
      "epoch 105; iter: 0; batch classifier loss: 0.465546; batch adversarial loss: 0.573760\n",
      "epoch 106; iter: 0; batch classifier loss: 0.346699; batch adversarial loss: 0.624411\n",
      "epoch 107; iter: 0; batch classifier loss: 0.428123; batch adversarial loss: 0.543410\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411428; batch adversarial loss: 0.515742\n",
      "epoch 109; iter: 0; batch classifier loss: 0.429003; batch adversarial loss: 0.565116\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339240; batch adversarial loss: 0.552468\n",
      "epoch 111; iter: 0; batch classifier loss: 0.443409; batch adversarial loss: 0.524929\n",
      "epoch 112; iter: 0; batch classifier loss: 0.377938; batch adversarial loss: 0.619656\n",
      "epoch 113; iter: 0; batch classifier loss: 0.449095; batch adversarial loss: 0.573558\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426861; batch adversarial loss: 0.569947\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346977; batch adversarial loss: 0.580952\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369675; batch adversarial loss: 0.527511\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362751; batch adversarial loss: 0.615814\n",
      "epoch 118; iter: 0; batch classifier loss: 0.314850; batch adversarial loss: 0.598989\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394953; batch adversarial loss: 0.525088\n",
      "epoch 120; iter: 0; batch classifier loss: 0.414786; batch adversarial loss: 0.564484\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360369; batch adversarial loss: 0.617345\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369039; batch adversarial loss: 0.633957\n",
      "epoch 123; iter: 0; batch classifier loss: 0.325365; batch adversarial loss: 0.526320\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407410; batch adversarial loss: 0.498451\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409345; batch adversarial loss: 0.552381\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400222; batch adversarial loss: 0.491885\n",
      "epoch 127; iter: 0; batch classifier loss: 0.375493; batch adversarial loss: 0.609768\n",
      "epoch 128; iter: 0; batch classifier loss: 0.359962; batch adversarial loss: 0.573669\n",
      "epoch 129; iter: 0; batch classifier loss: 0.411527; batch adversarial loss: 0.518825\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366237; batch adversarial loss: 0.589298\n",
      "epoch 131; iter: 0; batch classifier loss: 0.410370; batch adversarial loss: 0.534379\n",
      "epoch 132; iter: 0; batch classifier loss: 0.375897; batch adversarial loss: 0.579239\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371521; batch adversarial loss: 0.562846\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356748; batch adversarial loss: 0.555195\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399380; batch adversarial loss: 0.517173\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387789; batch adversarial loss: 0.526455\n",
      "epoch 137; iter: 0; batch classifier loss: 0.419549; batch adversarial loss: 0.586891\n",
      "epoch 138; iter: 0; batch classifier loss: 0.436726; batch adversarial loss: 0.516958\n",
      "epoch 139; iter: 0; batch classifier loss: 0.339161; batch adversarial loss: 0.579053\n",
      "epoch 140; iter: 0; batch classifier loss: 0.418497; batch adversarial loss: 0.444101\n",
      "epoch 141; iter: 0; batch classifier loss: 0.407912; batch adversarial loss: 0.553042\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386271; batch adversarial loss: 0.543339\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394939; batch adversarial loss: 0.479663\n",
      "epoch 144; iter: 0; batch classifier loss: 0.407657; batch adversarial loss: 0.509025\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374480; batch adversarial loss: 0.579663\n",
      "epoch 146; iter: 0; batch classifier loss: 0.405336; batch adversarial loss: 0.542622\n",
      "epoch 147; iter: 0; batch classifier loss: 0.399319; batch adversarial loss: 0.499954\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417381; batch adversarial loss: 0.501549\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344544; batch adversarial loss: 0.556201\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330602; batch adversarial loss: 0.526652\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409841; batch adversarial loss: 0.540351\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372825; batch adversarial loss: 0.562837\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364584; batch adversarial loss: 0.524303\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389192; batch adversarial loss: 0.550449\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398514; batch adversarial loss: 0.589294\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363875; batch adversarial loss: 0.507807\n",
      "epoch 157; iter: 0; batch classifier loss: 0.440288; batch adversarial loss: 0.541323\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383051; batch adversarial loss: 0.572770\n",
      "epoch 159; iter: 0; batch classifier loss: 0.434397; batch adversarial loss: 0.445432\n",
      "epoch 160; iter: 0; batch classifier loss: 0.394209; batch adversarial loss: 0.545641\n",
      "epoch 161; iter: 0; batch classifier loss: 0.328160; batch adversarial loss: 0.535494\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368302; batch adversarial loss: 0.545409\n",
      "epoch 163; iter: 0; batch classifier loss: 0.324143; batch adversarial loss: 0.479992\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389782; batch adversarial loss: 0.554738\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385570; batch adversarial loss: 0.526379\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343738; batch adversarial loss: 0.516525\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329053; batch adversarial loss: 0.609406\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397535; batch adversarial loss: 0.582702\n",
      "epoch 169; iter: 0; batch classifier loss: 0.398555; batch adversarial loss: 0.503420\n",
      "epoch 170; iter: 0; batch classifier loss: 0.326083; batch adversarial loss: 0.519666\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333509; batch adversarial loss: 0.598593\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384432; batch adversarial loss: 0.598650\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430296; batch adversarial loss: 0.588893\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400481; batch adversarial loss: 0.551145\n",
      "epoch 175; iter: 0; batch classifier loss: 0.438996; batch adversarial loss: 0.499240\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354499; batch adversarial loss: 0.574534\n",
      "epoch 177; iter: 0; batch classifier loss: 0.420475; batch adversarial loss: 0.581264\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362902; batch adversarial loss: 0.554687\n",
      "epoch 179; iter: 0; batch classifier loss: 0.310838; batch adversarial loss: 0.604192\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323560; batch adversarial loss: 0.569053\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383510; batch adversarial loss: 0.496830\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364265; batch adversarial loss: 0.517581\n",
      "epoch 183; iter: 0; batch classifier loss: 0.407664; batch adversarial loss: 0.505827\n",
      "epoch 184; iter: 0; batch classifier loss: 0.400273; batch adversarial loss: 0.588497\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377085; batch adversarial loss: 0.608125\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404775; batch adversarial loss: 0.600623\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375910; batch adversarial loss: 0.588818\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368536; batch adversarial loss: 0.579642\n",
      "epoch 189; iter: 0; batch classifier loss: 0.373479; batch adversarial loss: 0.583915\n",
      "epoch 190; iter: 0; batch classifier loss: 0.432668; batch adversarial loss: 0.580864\n",
      "epoch 191; iter: 0; batch classifier loss: 0.286296; batch adversarial loss: 0.507681\n",
      "epoch 192; iter: 0; batch classifier loss: 0.427758; batch adversarial loss: 0.570588\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368462; batch adversarial loss: 0.517444\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325846; batch adversarial loss: 0.498442\n",
      "epoch 195; iter: 0; batch classifier loss: 0.422705; batch adversarial loss: 0.536548\n",
      "epoch 196; iter: 0; batch classifier loss: 0.282544; batch adversarial loss: 0.543949\n",
      "epoch 197; iter: 0; batch classifier loss: 0.399821; batch adversarial loss: 0.515614\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390075; batch adversarial loss: 0.510120\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306070; batch adversarial loss: 0.435871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.707958; batch adversarial loss: 0.807038\n",
      "epoch 1; iter: 0; batch classifier loss: 0.755512; batch adversarial loss: 0.812889\n",
      "epoch 2; iter: 0; batch classifier loss: 0.775251; batch adversarial loss: 0.753633\n",
      "epoch 3; iter: 0; batch classifier loss: 0.703786; batch adversarial loss: 0.695513\n",
      "epoch 4; iter: 0; batch classifier loss: 0.643857; batch adversarial loss: 0.675502\n",
      "epoch 5; iter: 0; batch classifier loss: 0.519464; batch adversarial loss: 0.615559\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590384; batch adversarial loss: 0.640080\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554720; batch adversarial loss: 0.590346\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547559; batch adversarial loss: 0.587996\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561536; batch adversarial loss: 0.600577\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487324; batch adversarial loss: 0.563359\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498306; batch adversarial loss: 0.568453\n",
      "epoch 12; iter: 0; batch classifier loss: 0.486837; batch adversarial loss: 0.602731\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550565; batch adversarial loss: 0.582766\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531524; batch adversarial loss: 0.557608\n",
      "epoch 15; iter: 0; batch classifier loss: 0.600882; batch adversarial loss: 0.572247\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506522; batch adversarial loss: 0.578669\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486210; batch adversarial loss: 0.564094\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545885; batch adversarial loss: 0.510729\n",
      "epoch 19; iter: 0; batch classifier loss: 0.570340; batch adversarial loss: 0.534198\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491935; batch adversarial loss: 0.498613\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454195; batch adversarial loss: 0.604239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.449188; batch adversarial loss: 0.629139\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520907; batch adversarial loss: 0.604446\n",
      "epoch 24; iter: 0; batch classifier loss: 0.612078; batch adversarial loss: 0.559457\n",
      "epoch 25; iter: 0; batch classifier loss: 0.454824; batch adversarial loss: 0.609841\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497546; batch adversarial loss: 0.585286\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450702; batch adversarial loss: 0.554475\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488446; batch adversarial loss: 0.555913\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475322; batch adversarial loss: 0.538715\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491050; batch adversarial loss: 0.652546\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490588; batch adversarial loss: 0.553096\n",
      "epoch 32; iter: 0; batch classifier loss: 0.502050; batch adversarial loss: 0.535545\n",
      "epoch 33; iter: 0; batch classifier loss: 0.500455; batch adversarial loss: 0.510759\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464108; batch adversarial loss: 0.566652\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470515; batch adversarial loss: 0.610207\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477085; batch adversarial loss: 0.581784\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450188; batch adversarial loss: 0.562109\n",
      "epoch 38; iter: 0; batch classifier loss: 0.513338; batch adversarial loss: 0.535826\n",
      "epoch 39; iter: 0; batch classifier loss: 0.508890; batch adversarial loss: 0.538674\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430254; batch adversarial loss: 0.553961\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429397; batch adversarial loss: 0.543673\n",
      "epoch 42; iter: 0; batch classifier loss: 0.426256; batch adversarial loss: 0.545537\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482054; batch adversarial loss: 0.589379\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406261; batch adversarial loss: 0.597333\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399180; batch adversarial loss: 0.607405\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474642; batch adversarial loss: 0.598718\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417260; batch adversarial loss: 0.526788\n",
      "epoch 48; iter: 0; batch classifier loss: 0.500627; batch adversarial loss: 0.482144\n",
      "epoch 49; iter: 0; batch classifier loss: 0.471578; batch adversarial loss: 0.510114\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390944; batch adversarial loss: 0.535652\n",
      "epoch 51; iter: 0; batch classifier loss: 0.451614; batch adversarial loss: 0.472169\n",
      "epoch 52; iter: 0; batch classifier loss: 0.354539; batch adversarial loss: 0.535424\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424915; batch adversarial loss: 0.517247\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437540; batch adversarial loss: 0.536287\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432511; batch adversarial loss: 0.554550\n",
      "epoch 56; iter: 0; batch classifier loss: 0.374193; batch adversarial loss: 0.581710\n",
      "epoch 57; iter: 0; batch classifier loss: 0.376983; batch adversarial loss: 0.580189\n",
      "epoch 58; iter: 0; batch classifier loss: 0.321415; batch adversarial loss: 0.490024\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424743; batch adversarial loss: 0.580950\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431999; batch adversarial loss: 0.616223\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379125; batch adversarial loss: 0.607798\n",
      "epoch 62; iter: 0; batch classifier loss: 0.499654; batch adversarial loss: 0.562134\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369356; batch adversarial loss: 0.535187\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441911; batch adversarial loss: 0.543806\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362221; batch adversarial loss: 0.553862\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396442; batch adversarial loss: 0.562079\n",
      "epoch 67; iter: 0; batch classifier loss: 0.505145; batch adversarial loss: 0.535347\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443742; batch adversarial loss: 0.563277\n",
      "epoch 69; iter: 0; batch classifier loss: 0.478028; batch adversarial loss: 0.552992\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444372; batch adversarial loss: 0.645584\n",
      "epoch 71; iter: 0; batch classifier loss: 0.328357; batch adversarial loss: 0.572049\n",
      "epoch 72; iter: 0; batch classifier loss: 0.349416; batch adversarial loss: 0.643942\n",
      "epoch 73; iter: 0; batch classifier loss: 0.459900; batch adversarial loss: 0.582153\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417504; batch adversarial loss: 0.489516\n",
      "epoch 75; iter: 0; batch classifier loss: 0.339741; batch adversarial loss: 0.526814\n",
      "epoch 76; iter: 0; batch classifier loss: 0.439613; batch adversarial loss: 0.599253\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422096; batch adversarial loss: 0.544419\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437029; batch adversarial loss: 0.470451\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402785; batch adversarial loss: 0.562307\n",
      "epoch 80; iter: 0; batch classifier loss: 0.373534; batch adversarial loss: 0.517516\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374852; batch adversarial loss: 0.499078\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413433; batch adversarial loss: 0.536134\n",
      "epoch 83; iter: 0; batch classifier loss: 0.305325; batch adversarial loss: 0.452941\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405870; batch adversarial loss: 0.618225\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349720; batch adversarial loss: 0.526519\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373027; batch adversarial loss: 0.507709\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372581; batch adversarial loss: 0.481993\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356636; batch adversarial loss: 0.645405\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339509; batch adversarial loss: 0.506668\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417393; batch adversarial loss: 0.563038\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405399; batch adversarial loss: 0.643894\n",
      "epoch 92; iter: 0; batch classifier loss: 0.339534; batch adversarial loss: 0.518401\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357950; batch adversarial loss: 0.581605\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402977; batch adversarial loss: 0.553823\n",
      "epoch 95; iter: 0; batch classifier loss: 0.377146; batch adversarial loss: 0.543756\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394088; batch adversarial loss: 0.544011\n",
      "epoch 97; iter: 0; batch classifier loss: 0.262631; batch adversarial loss: 0.480981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.348367; batch adversarial loss: 0.590097\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366468; batch adversarial loss: 0.599080\n",
      "epoch 100; iter: 0; batch classifier loss: 0.329487; batch adversarial loss: 0.554131\n",
      "epoch 101; iter: 0; batch classifier loss: 0.341000; batch adversarial loss: 0.516826\n",
      "epoch 102; iter: 0; batch classifier loss: 0.334836; batch adversarial loss: 0.544473\n",
      "epoch 103; iter: 0; batch classifier loss: 0.268875; batch adversarial loss: 0.507736\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350246; batch adversarial loss: 0.562194\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355364; batch adversarial loss: 0.599199\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379980; batch adversarial loss: 0.600310\n",
      "epoch 107; iter: 0; batch classifier loss: 0.423798; batch adversarial loss: 0.536937\n",
      "epoch 108; iter: 0; batch classifier loss: 0.304430; batch adversarial loss: 0.527194\n",
      "epoch 109; iter: 0; batch classifier loss: 0.452065; batch adversarial loss: 0.634797\n",
      "epoch 110; iter: 0; batch classifier loss: 0.404036; batch adversarial loss: 0.543604\n",
      "epoch 111; iter: 0; batch classifier loss: 0.352797; batch adversarial loss: 0.608246\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363146; batch adversarial loss: 0.554656\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357506; batch adversarial loss: 0.590114\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383258; batch adversarial loss: 0.554035\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343798; batch adversarial loss: 0.535630\n",
      "epoch 116; iter: 0; batch classifier loss: 0.280515; batch adversarial loss: 0.608532\n",
      "epoch 117; iter: 0; batch classifier loss: 0.310867; batch adversarial loss: 0.535792\n",
      "epoch 118; iter: 0; batch classifier loss: 0.293120; batch adversarial loss: 0.516479\n",
      "epoch 119; iter: 0; batch classifier loss: 0.337572; batch adversarial loss: 0.544420\n",
      "epoch 120; iter: 0; batch classifier loss: 0.327493; batch adversarial loss: 0.517541\n",
      "epoch 121; iter: 0; batch classifier loss: 0.409220; batch adversarial loss: 0.535130\n",
      "epoch 122; iter: 0; batch classifier loss: 0.307965; batch adversarial loss: 0.589510\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351615; batch adversarial loss: 0.526003\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403969; batch adversarial loss: 0.469788\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380933; batch adversarial loss: 0.609075\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375484; batch adversarial loss: 0.562594\n",
      "epoch 127; iter: 0; batch classifier loss: 0.467244; batch adversarial loss: 0.462444\n",
      "epoch 128; iter: 0; batch classifier loss: 0.445238; batch adversarial loss: 0.535599\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395253; batch adversarial loss: 0.443590\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387017; batch adversarial loss: 0.526621\n",
      "epoch 131; iter: 0; batch classifier loss: 0.410110; batch adversarial loss: 0.580136\n",
      "epoch 132; iter: 0; batch classifier loss: 0.314137; batch adversarial loss: 0.508008\n",
      "epoch 133; iter: 0; batch classifier loss: 0.295061; batch adversarial loss: 0.554589\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368548; batch adversarial loss: 0.525871\n",
      "epoch 135; iter: 0; batch classifier loss: 0.274957; batch adversarial loss: 0.498721\n",
      "epoch 136; iter: 0; batch classifier loss: 0.349546; batch adversarial loss: 0.562825\n",
      "epoch 137; iter: 0; batch classifier loss: 0.423162; batch adversarial loss: 0.636933\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346365; batch adversarial loss: 0.525941\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378400; batch adversarial loss: 0.498274\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390788; batch adversarial loss: 0.591347\n",
      "epoch 141; iter: 0; batch classifier loss: 0.290710; batch adversarial loss: 0.608651\n",
      "epoch 142; iter: 0; batch classifier loss: 0.426011; batch adversarial loss: 0.535114\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376717; batch adversarial loss: 0.590017\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408369; batch adversarial loss: 0.507370\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365722; batch adversarial loss: 0.562595\n",
      "epoch 146; iter: 0; batch classifier loss: 0.284116; batch adversarial loss: 0.626286\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359277; batch adversarial loss: 0.571414\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328666; batch adversarial loss: 0.544253\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402025; batch adversarial loss: 0.591170\n",
      "epoch 150; iter: 0; batch classifier loss: 0.283032; batch adversarial loss: 0.553845\n",
      "epoch 151; iter: 0; batch classifier loss: 0.419198; batch adversarial loss: 0.535210\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335731; batch adversarial loss: 0.545255\n",
      "epoch 153; iter: 0; batch classifier loss: 0.447392; batch adversarial loss: 0.524819\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390081; batch adversarial loss: 0.526158\n",
      "epoch 155; iter: 0; batch classifier loss: 0.410230; batch adversarial loss: 0.544749\n",
      "epoch 156; iter: 0; batch classifier loss: 0.421433; batch adversarial loss: 0.581253\n",
      "epoch 157; iter: 0; batch classifier loss: 0.327407; batch adversarial loss: 0.572498\n",
      "epoch 158; iter: 0; batch classifier loss: 0.271392; batch adversarial loss: 0.571652\n",
      "epoch 159; iter: 0; batch classifier loss: 0.422738; batch adversarial loss: 0.525992\n",
      "epoch 160; iter: 0; batch classifier loss: 0.394336; batch adversarial loss: 0.591185\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380757; batch adversarial loss: 0.599285\n",
      "epoch 162; iter: 0; batch classifier loss: 0.280650; batch adversarial loss: 0.609197\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349785; batch adversarial loss: 0.617978\n",
      "epoch 164; iter: 0; batch classifier loss: 0.276584; batch adversarial loss: 0.506983\n",
      "epoch 165; iter: 0; batch classifier loss: 0.274136; batch adversarial loss: 0.562648\n",
      "epoch 166; iter: 0; batch classifier loss: 0.311000; batch adversarial loss: 0.562439\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301438; batch adversarial loss: 0.572592\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326614; batch adversarial loss: 0.479997\n",
      "epoch 169; iter: 0; batch classifier loss: 0.446650; batch adversarial loss: 0.613921\n",
      "epoch 170; iter: 0; batch classifier loss: 0.300279; batch adversarial loss: 0.544767\n",
      "epoch 171; iter: 0; batch classifier loss: 0.423640; batch adversarial loss: 0.562903\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353157; batch adversarial loss: 0.544644\n",
      "epoch 173; iter: 0; batch classifier loss: 0.436833; batch adversarial loss: 0.581648\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343175; batch adversarial loss: 0.553612\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416817; batch adversarial loss: 0.581378\n",
      "epoch 176; iter: 0; batch classifier loss: 0.466553; batch adversarial loss: 0.553954\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330905; batch adversarial loss: 0.525631\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333476; batch adversarial loss: 0.562805\n",
      "epoch 179; iter: 0; batch classifier loss: 0.326525; batch adversarial loss: 0.589285\n",
      "epoch 180; iter: 0; batch classifier loss: 0.342445; batch adversarial loss: 0.507907\n",
      "epoch 181; iter: 0; batch classifier loss: 0.277826; batch adversarial loss: 0.563019\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341430; batch adversarial loss: 0.508249\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375580; batch adversarial loss: 0.644378\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353817; batch adversarial loss: 0.571336\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371877; batch adversarial loss: 0.527149\n",
      "epoch 186; iter: 0; batch classifier loss: 0.302893; batch adversarial loss: 0.572623\n",
      "epoch 187; iter: 0; batch classifier loss: 0.272617; batch adversarial loss: 0.489429\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347419; batch adversarial loss: 0.535935\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348623; batch adversarial loss: 0.488889\n",
      "epoch 190; iter: 0; batch classifier loss: 0.457270; batch adversarial loss: 0.579912\n",
      "epoch 191; iter: 0; batch classifier loss: 0.353914; batch adversarial loss: 0.553627\n",
      "epoch 192; iter: 0; batch classifier loss: 0.283866; batch adversarial loss: 0.563692\n",
      "epoch 193; iter: 0; batch classifier loss: 0.324197; batch adversarial loss: 0.562788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.400952; batch adversarial loss: 0.497851\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363638; batch adversarial loss: 0.471577\n",
      "epoch 196; iter: 0; batch classifier loss: 0.419577; batch adversarial loss: 0.489243\n",
      "epoch 197; iter: 0; batch classifier loss: 0.266895; batch adversarial loss: 0.435186\n",
      "epoch 198; iter: 0; batch classifier loss: 0.419313; batch adversarial loss: 0.600509\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314480; batch adversarial loss: 0.508636\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695785; batch adversarial loss: 0.697603\n",
      "epoch 1; iter: 0; batch classifier loss: 0.638631; batch adversarial loss: 0.651903\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578362; batch adversarial loss: 0.637377\n",
      "epoch 3; iter: 0; batch classifier loss: 0.526925; batch adversarial loss: 0.625031\n",
      "epoch 4; iter: 0; batch classifier loss: 0.623265; batch adversarial loss: 0.573079\n",
      "epoch 5; iter: 0; batch classifier loss: 0.498459; batch adversarial loss: 0.606750\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543563; batch adversarial loss: 0.581495\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567732; batch adversarial loss: 0.640737\n",
      "epoch 8; iter: 0; batch classifier loss: 0.480998; batch adversarial loss: 0.599396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561024; batch adversarial loss: 0.581343\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526648; batch adversarial loss: 0.652455\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575855; batch adversarial loss: 0.639151\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554887; batch adversarial loss: 0.591359\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538556; batch adversarial loss: 0.612712\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511741; batch adversarial loss: 0.652034\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489241; batch adversarial loss: 0.520236\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520476; batch adversarial loss: 0.559368\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506056; batch adversarial loss: 0.610394\n",
      "epoch 18; iter: 0; batch classifier loss: 0.589965; batch adversarial loss: 0.610506\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496794; batch adversarial loss: 0.514113\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483862; batch adversarial loss: 0.510077\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501905; batch adversarial loss: 0.540651\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494741; batch adversarial loss: 0.516936\n",
      "epoch 23; iter: 0; batch classifier loss: 0.607685; batch adversarial loss: 0.551788\n",
      "epoch 24; iter: 0; batch classifier loss: 0.533338; batch adversarial loss: 0.594441\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438944; batch adversarial loss: 0.534800\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517563; batch adversarial loss: 0.511989\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453489; batch adversarial loss: 0.545712\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455642; batch adversarial loss: 0.575810\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471355; batch adversarial loss: 0.469134\n",
      "epoch 30; iter: 0; batch classifier loss: 0.401309; batch adversarial loss: 0.545534\n",
      "epoch 31; iter: 0; batch classifier loss: 0.392998; batch adversarial loss: 0.552663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400629; batch adversarial loss: 0.622034\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484004; batch adversarial loss: 0.554960\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460214; batch adversarial loss: 0.553118\n",
      "epoch 35; iter: 0; batch classifier loss: 0.538925; batch adversarial loss: 0.562795\n",
      "epoch 36; iter: 0; batch classifier loss: 0.361964; batch adversarial loss: 0.535997\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503490; batch adversarial loss: 0.562816\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476624; batch adversarial loss: 0.615963\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430932; batch adversarial loss: 0.545457\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434755; batch adversarial loss: 0.544539\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411128; batch adversarial loss: 0.553439\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405450; batch adversarial loss: 0.544295\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450889; batch adversarial loss: 0.500407\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375912; batch adversarial loss: 0.482554\n",
      "epoch 45; iter: 0; batch classifier loss: 0.351142; batch adversarial loss: 0.579475\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430707; batch adversarial loss: 0.562771\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371537; batch adversarial loss: 0.563028\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428691; batch adversarial loss: 0.543977\n",
      "epoch 49; iter: 0; batch classifier loss: 0.494219; batch adversarial loss: 0.517886\n",
      "epoch 50; iter: 0; batch classifier loss: 0.477234; batch adversarial loss: 0.490752\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399475; batch adversarial loss: 0.562047\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418350; batch adversarial loss: 0.572146\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391347; batch adversarial loss: 0.561839\n",
      "epoch 54; iter: 0; batch classifier loss: 0.490949; batch adversarial loss: 0.499665\n",
      "epoch 55; iter: 0; batch classifier loss: 0.346607; batch adversarial loss: 0.563252\n",
      "epoch 56; iter: 0; batch classifier loss: 0.497250; batch adversarial loss: 0.518211\n",
      "epoch 57; iter: 0; batch classifier loss: 0.503147; batch adversarial loss: 0.463077\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471309; batch adversarial loss: 0.562613\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402086; batch adversarial loss: 0.553730\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410065; batch adversarial loss: 0.490566\n",
      "epoch 61; iter: 0; batch classifier loss: 0.337010; batch adversarial loss: 0.517501\n",
      "epoch 62; iter: 0; batch classifier loss: 0.473517; batch adversarial loss: 0.499867\n",
      "epoch 63; iter: 0; batch classifier loss: 0.328424; batch adversarial loss: 0.535340\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362673; batch adversarial loss: 0.562362\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428521; batch adversarial loss: 0.662377\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433356; batch adversarial loss: 0.653643\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403986; batch adversarial loss: 0.508251\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411808; batch adversarial loss: 0.544538\n",
      "epoch 69; iter: 0; batch classifier loss: 0.465515; batch adversarial loss: 0.554062\n",
      "epoch 70; iter: 0; batch classifier loss: 0.361779; batch adversarial loss: 0.543706\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422721; batch adversarial loss: 0.553929\n",
      "epoch 72; iter: 0; batch classifier loss: 0.395805; batch adversarial loss: 0.481040\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368619; batch adversarial loss: 0.580978\n",
      "epoch 74; iter: 0; batch classifier loss: 0.467874; batch adversarial loss: 0.472328\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391440; batch adversarial loss: 0.553449\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394638; batch adversarial loss: 0.581254\n",
      "epoch 77; iter: 0; batch classifier loss: 0.487815; batch adversarial loss: 0.617433\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416861; batch adversarial loss: 0.553864\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430187; batch adversarial loss: 0.526409\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436372; batch adversarial loss: 0.564066\n",
      "epoch 81; iter: 0; batch classifier loss: 0.465616; batch adversarial loss: 0.608618\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367603; batch adversarial loss: 0.634339\n",
      "epoch 83; iter: 0; batch classifier loss: 0.454590; batch adversarial loss: 0.562696\n",
      "epoch 84; iter: 0; batch classifier loss: 0.328890; batch adversarial loss: 0.571363\n",
      "epoch 85; iter: 0; batch classifier loss: 0.440925; batch adversarial loss: 0.543799\n",
      "epoch 86; iter: 0; batch classifier loss: 0.553585; batch adversarial loss: 0.499164\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405568; batch adversarial loss: 0.561622\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417809; batch adversarial loss: 0.635172\n",
      "epoch 89; iter: 0; batch classifier loss: 0.448797; batch adversarial loss: 0.545543\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359882; batch adversarial loss: 0.526132\n",
      "epoch 91; iter: 0; batch classifier loss: 0.341279; batch adversarial loss: 0.535980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.364002; batch adversarial loss: 0.435555\n",
      "epoch 93; iter: 0; batch classifier loss: 0.325756; batch adversarial loss: 0.553642\n",
      "epoch 94; iter: 0; batch classifier loss: 0.417582; batch adversarial loss: 0.444451\n",
      "epoch 95; iter: 0; batch classifier loss: 0.288069; batch adversarial loss: 0.580603\n",
      "epoch 96; iter: 0; batch classifier loss: 0.449469; batch adversarial loss: 0.652305\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315694; batch adversarial loss: 0.580879\n",
      "epoch 98; iter: 0; batch classifier loss: 0.426279; batch adversarial loss: 0.571668\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380357; batch adversarial loss: 0.553193\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384314; batch adversarial loss: 0.543787\n",
      "epoch 101; iter: 0; batch classifier loss: 0.350755; batch adversarial loss: 0.617712\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374282; batch adversarial loss: 0.635456\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352915; batch adversarial loss: 0.463089\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398208; batch adversarial loss: 0.616817\n",
      "epoch 105; iter: 0; batch classifier loss: 0.462605; batch adversarial loss: 0.499541\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366825; batch adversarial loss: 0.544799\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421537; batch adversarial loss: 0.517962\n",
      "epoch 108; iter: 0; batch classifier loss: 0.374463; batch adversarial loss: 0.580809\n",
      "epoch 109; iter: 0; batch classifier loss: 0.432379; batch adversarial loss: 0.507814\n",
      "epoch 110; iter: 0; batch classifier loss: 0.421595; batch adversarial loss: 0.544332\n",
      "epoch 111; iter: 0; batch classifier loss: 0.312182; batch adversarial loss: 0.535240\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371097; batch adversarial loss: 0.490809\n",
      "epoch 113; iter: 0; batch classifier loss: 0.435730; batch adversarial loss: 0.581035\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376702; batch adversarial loss: 0.608221\n",
      "epoch 115; iter: 0; batch classifier loss: 0.368427; batch adversarial loss: 0.472416\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406028; batch adversarial loss: 0.581934\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388679; batch adversarial loss: 0.544616\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427729; batch adversarial loss: 0.554166\n",
      "epoch 119; iter: 0; batch classifier loss: 0.327575; batch adversarial loss: 0.535481\n",
      "epoch 120; iter: 0; batch classifier loss: 0.384187; batch adversarial loss: 0.544348\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387363; batch adversarial loss: 0.634519\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339518; batch adversarial loss: 0.553645\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399670; batch adversarial loss: 0.598336\n",
      "epoch 124; iter: 0; batch classifier loss: 0.383411; batch adversarial loss: 0.563276\n",
      "epoch 125; iter: 0; batch classifier loss: 0.452576; batch adversarial loss: 0.535260\n",
      "epoch 126; iter: 0; batch classifier loss: 0.401789; batch adversarial loss: 0.626002\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384186; batch adversarial loss: 0.653099\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370510; batch adversarial loss: 0.489466\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327313; batch adversarial loss: 0.636165\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340478; batch adversarial loss: 0.535516\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392891; batch adversarial loss: 0.472079\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388269; batch adversarial loss: 0.498956\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340714; batch adversarial loss: 0.553508\n",
      "epoch 134; iter: 0; batch classifier loss: 0.322649; batch adversarial loss: 0.598759\n",
      "epoch 135; iter: 0; batch classifier loss: 0.344684; batch adversarial loss: 0.526117\n",
      "epoch 136; iter: 0; batch classifier loss: 0.312579; batch adversarial loss: 0.607726\n",
      "epoch 137; iter: 0; batch classifier loss: 0.422973; batch adversarial loss: 0.580758\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341618; batch adversarial loss: 0.544491\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408837; batch adversarial loss: 0.498319\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332933; batch adversarial loss: 0.516997\n",
      "epoch 141; iter: 0; batch classifier loss: 0.452674; batch adversarial loss: 0.535343\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362968; batch adversarial loss: 0.590329\n",
      "epoch 143; iter: 0; batch classifier loss: 0.437136; batch adversarial loss: 0.580920\n",
      "epoch 144; iter: 0; batch classifier loss: 0.325423; batch adversarial loss: 0.571509\n",
      "epoch 145; iter: 0; batch classifier loss: 0.452221; batch adversarial loss: 0.481330\n",
      "epoch 146; iter: 0; batch classifier loss: 0.324454; batch adversarial loss: 0.508199\n",
      "epoch 147; iter: 0; batch classifier loss: 0.414638; batch adversarial loss: 0.544670\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328748; batch adversarial loss: 0.489156\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344936; batch adversarial loss: 0.562148\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341759; batch adversarial loss: 0.489628\n",
      "epoch 151; iter: 0; batch classifier loss: 0.448733; batch adversarial loss: 0.579391\n",
      "epoch 152; iter: 0; batch classifier loss: 0.361368; batch adversarial loss: 0.589845\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383018; batch adversarial loss: 0.563055\n",
      "epoch 154; iter: 0; batch classifier loss: 0.399696; batch adversarial loss: 0.535399\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349608; batch adversarial loss: 0.535569\n",
      "epoch 156; iter: 0; batch classifier loss: 0.455784; batch adversarial loss: 0.536397\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367362; batch adversarial loss: 0.526599\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336284; batch adversarial loss: 0.508064\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366866; batch adversarial loss: 0.526652\n",
      "epoch 160; iter: 0; batch classifier loss: 0.385034; batch adversarial loss: 0.481368\n",
      "epoch 161; iter: 0; batch classifier loss: 0.298976; batch adversarial loss: 0.544513\n",
      "epoch 162; iter: 0; batch classifier loss: 0.305176; batch adversarial loss: 0.534680\n",
      "epoch 163; iter: 0; batch classifier loss: 0.416987; batch adversarial loss: 0.562934\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350555; batch adversarial loss: 0.553757\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380097; batch adversarial loss: 0.527510\n",
      "epoch 166; iter: 0; batch classifier loss: 0.430731; batch adversarial loss: 0.527683\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369945; batch adversarial loss: 0.490420\n",
      "epoch 168; iter: 0; batch classifier loss: 0.448266; batch adversarial loss: 0.671181\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366560; batch adversarial loss: 0.581143\n",
      "epoch 170; iter: 0; batch classifier loss: 0.429756; batch adversarial loss: 0.507816\n",
      "epoch 171; iter: 0; batch classifier loss: 0.469047; batch adversarial loss: 0.572046\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364496; batch adversarial loss: 0.534778\n",
      "epoch 173; iter: 0; batch classifier loss: 0.282594; batch adversarial loss: 0.553794\n",
      "epoch 174; iter: 0; batch classifier loss: 0.437477; batch adversarial loss: 0.608379\n",
      "epoch 175; iter: 0; batch classifier loss: 0.316639; batch adversarial loss: 0.581087\n",
      "epoch 176; iter: 0; batch classifier loss: 0.418477; batch adversarial loss: 0.562102\n",
      "epoch 177; iter: 0; batch classifier loss: 0.307088; batch adversarial loss: 0.636052\n",
      "epoch 178; iter: 0; batch classifier loss: 0.444658; batch adversarial loss: 0.581087\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352487; batch adversarial loss: 0.607817\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352230; batch adversarial loss: 0.544751\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349432; batch adversarial loss: 0.626488\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359335; batch adversarial loss: 0.525350\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375580; batch adversarial loss: 0.588798\n",
      "epoch 184; iter: 0; batch classifier loss: 0.418358; batch adversarial loss: 0.572532\n",
      "epoch 185; iter: 0; batch classifier loss: 0.422674; batch adversarial loss: 0.517074\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331837; batch adversarial loss: 0.580963\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343225; batch adversarial loss: 0.561386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.341104; batch adversarial loss: 0.569631\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340943; batch adversarial loss: 0.509412\n",
      "epoch 190; iter: 0; batch classifier loss: 0.453119; batch adversarial loss: 0.544092\n",
      "epoch 191; iter: 0; batch classifier loss: 0.399248; batch adversarial loss: 0.562534\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361880; batch adversarial loss: 0.442984\n",
      "epoch 193; iter: 0; batch classifier loss: 0.303354; batch adversarial loss: 0.518297\n",
      "epoch 194; iter: 0; batch classifier loss: 0.239704; batch adversarial loss: 0.536028\n",
      "epoch 195; iter: 0; batch classifier loss: 0.282540; batch adversarial loss: 0.580945\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354959; batch adversarial loss: 0.634146\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386438; batch adversarial loss: 0.571900\n",
      "epoch 198; iter: 0; batch classifier loss: 0.426170; batch adversarial loss: 0.553350\n",
      "epoch 199; iter: 0; batch classifier loss: 0.393025; batch adversarial loss: 0.518032\n",
      "epoch 0; iter: 0; batch classifier loss: 0.648856; batch adversarial loss: 0.702083\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542757; batch adversarial loss: 0.673343\n",
      "epoch 2; iter: 0; batch classifier loss: 0.569785; batch adversarial loss: 0.649309\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609519; batch adversarial loss: 0.610211\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535621; batch adversarial loss: 0.629272\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521106; batch adversarial loss: 0.594582\n",
      "epoch 6; iter: 0; batch classifier loss: 0.594260; batch adversarial loss: 0.587055\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529688; batch adversarial loss: 0.607684\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514224; batch adversarial loss: 0.540546\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538403; batch adversarial loss: 0.588851\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522914; batch adversarial loss: 0.576731\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534157; batch adversarial loss: 0.627114\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556775; batch adversarial loss: 0.587960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517950; batch adversarial loss: 0.584168\n",
      "epoch 14; iter: 0; batch classifier loss: 0.457597; batch adversarial loss: 0.577148\n",
      "epoch 15; iter: 0; batch classifier loss: 0.464201; batch adversarial loss: 0.518013\n",
      "epoch 16; iter: 0; batch classifier loss: 0.466436; batch adversarial loss: 0.523683\n",
      "epoch 17; iter: 0; batch classifier loss: 0.587993; batch adversarial loss: 0.524858\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509142; batch adversarial loss: 0.529932\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506726; batch adversarial loss: 0.552039\n",
      "epoch 20; iter: 0; batch classifier loss: 0.574740; batch adversarial loss: 0.576014\n",
      "epoch 21; iter: 0; batch classifier loss: 0.425348; batch adversarial loss: 0.581968\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447295; batch adversarial loss: 0.597648\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517409; batch adversarial loss: 0.564725\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503288; batch adversarial loss: 0.577567\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461747; batch adversarial loss: 0.528840\n",
      "epoch 26; iter: 0; batch classifier loss: 0.415891; batch adversarial loss: 0.521817\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479763; batch adversarial loss: 0.553235\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491324; batch adversarial loss: 0.610133\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462898; batch adversarial loss: 0.518856\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422590; batch adversarial loss: 0.523668\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490481; batch adversarial loss: 0.533329\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520506; batch adversarial loss: 0.523167\n",
      "epoch 33; iter: 0; batch classifier loss: 0.548586; batch adversarial loss: 0.520225\n",
      "epoch 34; iter: 0; batch classifier loss: 0.551174; batch adversarial loss: 0.552168\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390279; batch adversarial loss: 0.510218\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448595; batch adversarial loss: 0.497718\n",
      "epoch 37; iter: 0; batch classifier loss: 0.484221; batch adversarial loss: 0.503719\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420336; batch adversarial loss: 0.531642\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473489; batch adversarial loss: 0.529884\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452235; batch adversarial loss: 0.546193\n",
      "epoch 41; iter: 0; batch classifier loss: 0.503959; batch adversarial loss: 0.471733\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434167; batch adversarial loss: 0.493287\n",
      "epoch 43; iter: 0; batch classifier loss: 0.496845; batch adversarial loss: 0.598307\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398422; batch adversarial loss: 0.539966\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469472; batch adversarial loss: 0.543011\n",
      "epoch 46; iter: 0; batch classifier loss: 0.497117; batch adversarial loss: 0.550168\n",
      "epoch 47; iter: 0; batch classifier loss: 0.458246; batch adversarial loss: 0.494052\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406748; batch adversarial loss: 0.567849\n",
      "epoch 49; iter: 0; batch classifier loss: 0.483351; batch adversarial loss: 0.565512\n",
      "epoch 50; iter: 0; batch classifier loss: 0.494403; batch adversarial loss: 0.509086\n",
      "epoch 51; iter: 0; batch classifier loss: 0.382585; batch adversarial loss: 0.562899\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438190; batch adversarial loss: 0.545615\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444329; batch adversarial loss: 0.589476\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412591; batch adversarial loss: 0.543524\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389962; batch adversarial loss: 0.628668\n",
      "epoch 56; iter: 0; batch classifier loss: 0.474463; batch adversarial loss: 0.561961\n",
      "epoch 57; iter: 0; batch classifier loss: 0.478968; batch adversarial loss: 0.518055\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428646; batch adversarial loss: 0.553018\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409639; batch adversarial loss: 0.505642\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396282; batch adversarial loss: 0.581437\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408445; batch adversarial loss: 0.562352\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484693; batch adversarial loss: 0.628228\n",
      "epoch 63; iter: 0; batch classifier loss: 0.372789; batch adversarial loss: 0.551396\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397506; batch adversarial loss: 0.478800\n",
      "epoch 65; iter: 0; batch classifier loss: 0.490971; batch adversarial loss: 0.505403\n",
      "epoch 66; iter: 0; batch classifier loss: 0.391383; batch adversarial loss: 0.458483\n",
      "epoch 67; iter: 0; batch classifier loss: 0.482849; batch adversarial loss: 0.544620\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393469; batch adversarial loss: 0.507553\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376018; batch adversarial loss: 0.486899\n",
      "epoch 70; iter: 0; batch classifier loss: 0.348707; batch adversarial loss: 0.583291\n",
      "epoch 71; iter: 0; batch classifier loss: 0.345393; batch adversarial loss: 0.535259\n",
      "epoch 72; iter: 0; batch classifier loss: 0.396444; batch adversarial loss: 0.619396\n",
      "epoch 73; iter: 0; batch classifier loss: 0.420598; batch adversarial loss: 0.592519\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410354; batch adversarial loss: 0.525553\n",
      "epoch 75; iter: 0; batch classifier loss: 0.346457; batch adversarial loss: 0.570945\n",
      "epoch 76; iter: 0; batch classifier loss: 0.463644; batch adversarial loss: 0.552586\n",
      "epoch 77; iter: 0; batch classifier loss: 0.428318; batch adversarial loss: 0.600259\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417033; batch adversarial loss: 0.590056\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402673; batch adversarial loss: 0.506641\n",
      "epoch 80; iter: 0; batch classifier loss: 0.377517; batch adversarial loss: 0.553673\n",
      "epoch 81; iter: 0; batch classifier loss: 0.431644; batch adversarial loss: 0.581206\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398776; batch adversarial loss: 0.487883\n",
      "epoch 83; iter: 0; batch classifier loss: 0.343998; batch adversarial loss: 0.583713\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440132; batch adversarial loss: 0.470357\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393041; batch adversarial loss: 0.525156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.383899; batch adversarial loss: 0.470715\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405656; batch adversarial loss: 0.543969\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356935; batch adversarial loss: 0.545057\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381390; batch adversarial loss: 0.553918\n",
      "epoch 90; iter: 0; batch classifier loss: 0.314497; batch adversarial loss: 0.523225\n",
      "epoch 91; iter: 0; batch classifier loss: 0.476854; batch adversarial loss: 0.533782\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411921; batch adversarial loss: 0.485354\n",
      "epoch 93; iter: 0; batch classifier loss: 0.370319; batch adversarial loss: 0.583118\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404072; batch adversarial loss: 0.574530\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429883; batch adversarial loss: 0.610942\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380786; batch adversarial loss: 0.573506\n",
      "epoch 97; iter: 0; batch classifier loss: 0.314699; batch adversarial loss: 0.627373\n",
      "epoch 98; iter: 0; batch classifier loss: 0.482616; batch adversarial loss: 0.656646\n",
      "epoch 99; iter: 0; batch classifier loss: 0.387463; batch adversarial loss: 0.562460\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346161; batch adversarial loss: 0.515671\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390354; batch adversarial loss: 0.591216\n",
      "epoch 102; iter: 0; batch classifier loss: 0.299819; batch adversarial loss: 0.606983\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389974; batch adversarial loss: 0.466280\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370194; batch adversarial loss: 0.569827\n",
      "epoch 105; iter: 0; batch classifier loss: 0.431202; batch adversarial loss: 0.570022\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350922; batch adversarial loss: 0.471213\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355904; batch adversarial loss: 0.571157\n",
      "epoch 108; iter: 0; batch classifier loss: 0.414044; batch adversarial loss: 0.608662\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358924; batch adversarial loss: 0.591085\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403390; batch adversarial loss: 0.507271\n",
      "epoch 111; iter: 0; batch classifier loss: 0.377984; batch adversarial loss: 0.552624\n",
      "epoch 112; iter: 0; batch classifier loss: 0.424770; batch adversarial loss: 0.535069\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333745; batch adversarial loss: 0.478035\n",
      "epoch 114; iter: 0; batch classifier loss: 0.321169; batch adversarial loss: 0.393274\n",
      "epoch 115; iter: 0; batch classifier loss: 0.472960; batch adversarial loss: 0.581727\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328050; batch adversarial loss: 0.584856\n",
      "epoch 117; iter: 0; batch classifier loss: 0.444423; batch adversarial loss: 0.506478\n",
      "epoch 118; iter: 0; batch classifier loss: 0.346438; batch adversarial loss: 0.497271\n",
      "epoch 119; iter: 0; batch classifier loss: 0.362340; batch adversarial loss: 0.573527\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363898; batch adversarial loss: 0.553284\n",
      "epoch 121; iter: 0; batch classifier loss: 0.307191; batch adversarial loss: 0.528318\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415798; batch adversarial loss: 0.517537\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408924; batch adversarial loss: 0.580519\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377836; batch adversarial loss: 0.506509\n",
      "epoch 125; iter: 0; batch classifier loss: 0.385041; batch adversarial loss: 0.535578\n",
      "epoch 126; iter: 0; batch classifier loss: 0.507178; batch adversarial loss: 0.461723\n",
      "epoch 127; iter: 0; batch classifier loss: 0.431673; batch adversarial loss: 0.507574\n",
      "epoch 128; iter: 0; batch classifier loss: 0.354390; batch adversarial loss: 0.582730\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375413; batch adversarial loss: 0.534493\n",
      "epoch 130; iter: 0; batch classifier loss: 0.462368; batch adversarial loss: 0.583414\n",
      "epoch 131; iter: 0; batch classifier loss: 0.456590; batch adversarial loss: 0.554521\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349658; batch adversarial loss: 0.563062\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392323; batch adversarial loss: 0.488194\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356663; batch adversarial loss: 0.497438\n",
      "epoch 135; iter: 0; batch classifier loss: 0.322895; batch adversarial loss: 0.627195\n",
      "epoch 136; iter: 0; batch classifier loss: 0.422968; batch adversarial loss: 0.503729\n",
      "epoch 137; iter: 0; batch classifier loss: 0.414148; batch adversarial loss: 0.585390\n",
      "epoch 138; iter: 0; batch classifier loss: 0.354054; batch adversarial loss: 0.551333\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366242; batch adversarial loss: 0.551927\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387032; batch adversarial loss: 0.533460\n",
      "epoch 141; iter: 0; batch classifier loss: 0.419972; batch adversarial loss: 0.508396\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358872; batch adversarial loss: 0.591492\n",
      "epoch 143; iter: 0; batch classifier loss: 0.462472; batch adversarial loss: 0.573501\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405232; batch adversarial loss: 0.564710\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381543; batch adversarial loss: 0.535865\n",
      "epoch 146; iter: 0; batch classifier loss: 0.386438; batch adversarial loss: 0.525086\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368665; batch adversarial loss: 0.555463\n",
      "epoch 148; iter: 0; batch classifier loss: 0.382557; batch adversarial loss: 0.544721\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334070; batch adversarial loss: 0.582099\n",
      "epoch 150; iter: 0; batch classifier loss: 0.398821; batch adversarial loss: 0.505247\n",
      "epoch 151; iter: 0; batch classifier loss: 0.320172; batch adversarial loss: 0.507642\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349900; batch adversarial loss: 0.563063\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430023; batch adversarial loss: 0.617776\n",
      "epoch 154; iter: 0; batch classifier loss: 0.391606; batch adversarial loss: 0.564855\n",
      "epoch 155; iter: 0; batch classifier loss: 0.385428; batch adversarial loss: 0.608820\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401135; batch adversarial loss: 0.534838\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363570; batch adversarial loss: 0.639071\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381339; batch adversarial loss: 0.637063\n",
      "epoch 159; iter: 0; batch classifier loss: 0.314152; batch adversarial loss: 0.526862\n",
      "epoch 160; iter: 0; batch classifier loss: 0.279198; batch adversarial loss: 0.460319\n",
      "epoch 161; iter: 0; batch classifier loss: 0.444472; batch adversarial loss: 0.526175\n",
      "epoch 162; iter: 0; batch classifier loss: 0.375374; batch adversarial loss: 0.496392\n",
      "epoch 163; iter: 0; batch classifier loss: 0.360140; batch adversarial loss: 0.563958\n",
      "epoch 164; iter: 0; batch classifier loss: 0.426530; batch adversarial loss: 0.601476\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387710; batch adversarial loss: 0.564698\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365889; batch adversarial loss: 0.525238\n",
      "epoch 167; iter: 0; batch classifier loss: 0.442516; batch adversarial loss: 0.504994\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345920; batch adversarial loss: 0.601829\n",
      "epoch 169; iter: 0; batch classifier loss: 0.345195; batch adversarial loss: 0.544709\n",
      "epoch 170; iter: 0; batch classifier loss: 0.387994; batch adversarial loss: 0.535019\n",
      "epoch 171; iter: 0; batch classifier loss: 0.426129; batch adversarial loss: 0.542789\n",
      "epoch 172; iter: 0; batch classifier loss: 0.295851; batch adversarial loss: 0.488286\n",
      "epoch 173; iter: 0; batch classifier loss: 0.384978; batch adversarial loss: 0.505760\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359743; batch adversarial loss: 0.450532\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356390; batch adversarial loss: 0.560889\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384321; batch adversarial loss: 0.506835\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312191; batch adversarial loss: 0.514913\n",
      "epoch 178; iter: 0; batch classifier loss: 0.310751; batch adversarial loss: 0.564145\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406295; batch adversarial loss: 0.532691\n",
      "epoch 180; iter: 0; batch classifier loss: 0.424450; batch adversarial loss: 0.619072\n",
      "epoch 181; iter: 0; batch classifier loss: 0.327254; batch adversarial loss: 0.571043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.313059; batch adversarial loss: 0.500878\n",
      "epoch 183; iter: 0; batch classifier loss: 0.462839; batch adversarial loss: 0.534152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381459; batch adversarial loss: 0.581630\n",
      "epoch 185; iter: 0; batch classifier loss: 0.307361; batch adversarial loss: 0.600950\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371090; batch adversarial loss: 0.535513\n",
      "epoch 187; iter: 0; batch classifier loss: 0.328807; batch adversarial loss: 0.551446\n",
      "epoch 188; iter: 0; batch classifier loss: 0.434887; batch adversarial loss: 0.536069\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365636; batch adversarial loss: 0.554453\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365732; batch adversarial loss: 0.591775\n",
      "epoch 191; iter: 0; batch classifier loss: 0.431673; batch adversarial loss: 0.509096\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338097; batch adversarial loss: 0.461533\n",
      "epoch 193; iter: 0; batch classifier loss: 0.299743; batch adversarial loss: 0.628420\n",
      "epoch 194; iter: 0; batch classifier loss: 0.296989; batch adversarial loss: 0.545588\n",
      "epoch 195; iter: 0; batch classifier loss: 0.271641; batch adversarial loss: 0.498484\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374216; batch adversarial loss: 0.517246\n",
      "epoch 197; iter: 0; batch classifier loss: 0.290824; batch adversarial loss: 0.508108\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355913; batch adversarial loss: 0.535802\n",
      "epoch 199; iter: 0; batch classifier loss: 0.446087; batch adversarial loss: 0.497011\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734822; batch adversarial loss: 0.651944\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530919; batch adversarial loss: 0.656007\n",
      "epoch 2; iter: 0; batch classifier loss: 0.512781; batch adversarial loss: 0.645792\n",
      "epoch 3; iter: 0; batch classifier loss: 0.658029; batch adversarial loss: 0.630375\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541014; batch adversarial loss: 0.623385\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466328; batch adversarial loss: 0.605087\n",
      "epoch 6; iter: 0; batch classifier loss: 0.511602; batch adversarial loss: 0.564284\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626782; batch adversarial loss: 0.575527\n",
      "epoch 8; iter: 0; batch classifier loss: 0.624622; batch adversarial loss: 0.545558\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561893; batch adversarial loss: 0.530276\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529171; batch adversarial loss: 0.593097\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548194; batch adversarial loss: 0.574872\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498812; batch adversarial loss: 0.638054\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518237; batch adversarial loss: 0.576046\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472752; batch adversarial loss: 0.602628\n",
      "epoch 15; iter: 0; batch classifier loss: 0.564655; batch adversarial loss: 0.547110\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472159; batch adversarial loss: 0.619772\n",
      "epoch 17; iter: 0; batch classifier loss: 0.458080; batch adversarial loss: 0.566435\n",
      "epoch 18; iter: 0; batch classifier loss: 0.495191; batch adversarial loss: 0.475344\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530434; batch adversarial loss: 0.508069\n",
      "epoch 20; iter: 0; batch classifier loss: 0.414728; batch adversarial loss: 0.582976\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524853; batch adversarial loss: 0.623848\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440572; batch adversarial loss: 0.569087\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504042; batch adversarial loss: 0.482304\n",
      "epoch 24; iter: 0; batch classifier loss: 0.521134; batch adversarial loss: 0.585424\n",
      "epoch 25; iter: 0; batch classifier loss: 0.551187; batch adversarial loss: 0.562773\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496171; batch adversarial loss: 0.593648\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487100; batch adversarial loss: 0.613417\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475507; batch adversarial loss: 0.580405\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475621; batch adversarial loss: 0.554080\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428507; batch adversarial loss: 0.570205\n",
      "epoch 31; iter: 0; batch classifier loss: 0.502645; batch adversarial loss: 0.577287\n",
      "epoch 32; iter: 0; batch classifier loss: 0.413722; batch adversarial loss: 0.548873\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408818; batch adversarial loss: 0.582284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439082; batch adversarial loss: 0.537419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412036; batch adversarial loss: 0.622781\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426705; batch adversarial loss: 0.492888\n",
      "epoch 37; iter: 0; batch classifier loss: 0.395964; batch adversarial loss: 0.618239\n",
      "epoch 38; iter: 0; batch classifier loss: 0.508704; batch adversarial loss: 0.503412\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437704; batch adversarial loss: 0.589407\n",
      "epoch 40; iter: 0; batch classifier loss: 0.485049; batch adversarial loss: 0.580370\n",
      "epoch 41; iter: 0; batch classifier loss: 0.406934; batch adversarial loss: 0.509416\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433597; batch adversarial loss: 0.572922\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419806; batch adversarial loss: 0.536052\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420114; batch adversarial loss: 0.526950\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426740; batch adversarial loss: 0.623916\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431048; batch adversarial loss: 0.571198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.378257; batch adversarial loss: 0.527270\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473529; batch adversarial loss: 0.527533\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456162; batch adversarial loss: 0.537224\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414735; batch adversarial loss: 0.563092\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379678; batch adversarial loss: 0.562276\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433167; batch adversarial loss: 0.464289\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436427; batch adversarial loss: 0.598808\n",
      "epoch 54; iter: 0; batch classifier loss: 0.365985; batch adversarial loss: 0.588903\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398842; batch adversarial loss: 0.526881\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383598; batch adversarial loss: 0.562302\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396424; batch adversarial loss: 0.571805\n",
      "epoch 58; iter: 0; batch classifier loss: 0.354617; batch adversarial loss: 0.661212\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428778; batch adversarial loss: 0.553804\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386096; batch adversarial loss: 0.580687\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438501; batch adversarial loss: 0.606823\n",
      "epoch 62; iter: 0; batch classifier loss: 0.478864; batch adversarial loss: 0.624431\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441260; batch adversarial loss: 0.553628\n",
      "epoch 64; iter: 0; batch classifier loss: 0.472942; batch adversarial loss: 0.526588\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385072; batch adversarial loss: 0.598213\n",
      "epoch 66; iter: 0; batch classifier loss: 0.355302; batch adversarial loss: 0.482285\n",
      "epoch 67; iter: 0; batch classifier loss: 0.373373; batch adversarial loss: 0.580100\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399062; batch adversarial loss: 0.544722\n",
      "epoch 69; iter: 0; batch classifier loss: 0.445094; batch adversarial loss: 0.464080\n",
      "epoch 70; iter: 0; batch classifier loss: 0.341105; batch adversarial loss: 0.571771\n",
      "epoch 71; iter: 0; batch classifier loss: 0.443582; batch adversarial loss: 0.562754\n",
      "epoch 72; iter: 0; batch classifier loss: 0.361371; batch adversarial loss: 0.589445\n",
      "epoch 73; iter: 0; batch classifier loss: 0.317344; batch adversarial loss: 0.472457\n",
      "epoch 74; iter: 0; batch classifier loss: 0.463777; batch adversarial loss: 0.541672\n",
      "epoch 75; iter: 0; batch classifier loss: 0.466716; batch adversarial loss: 0.470922\n",
      "epoch 76; iter: 0; batch classifier loss: 0.474297; batch adversarial loss: 0.557535\n",
      "epoch 77; iter: 0; batch classifier loss: 0.462423; batch adversarial loss: 0.457958\n",
      "epoch 78; iter: 0; batch classifier loss: 0.323276; batch adversarial loss: 0.577627\n",
      "epoch 79; iter: 0; batch classifier loss: 0.318942; batch adversarial loss: 0.681138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.402617; batch adversarial loss: 0.510249\n",
      "epoch 81; iter: 0; batch classifier loss: 0.466844; batch adversarial loss: 0.510386\n",
      "epoch 82; iter: 0; batch classifier loss: 0.433880; batch adversarial loss: 0.579980\n",
      "epoch 83; iter: 0; batch classifier loss: 0.350532; batch adversarial loss: 0.527571\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399018; batch adversarial loss: 0.580134\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392912; batch adversarial loss: 0.562523\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353310; batch adversarial loss: 0.597971\n",
      "epoch 87; iter: 0; batch classifier loss: 0.453506; batch adversarial loss: 0.580292\n",
      "epoch 88; iter: 0; batch classifier loss: 0.380498; batch adversarial loss: 0.597828\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383357; batch adversarial loss: 0.543946\n",
      "epoch 90; iter: 0; batch classifier loss: 0.337802; batch adversarial loss: 0.563623\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428554; batch adversarial loss: 0.597837\n",
      "epoch 92; iter: 0; batch classifier loss: 0.469320; batch adversarial loss: 0.572585\n",
      "epoch 93; iter: 0; batch classifier loss: 0.330326; batch adversarial loss: 0.490573\n",
      "epoch 94; iter: 0; batch classifier loss: 0.315181; batch adversarial loss: 0.515796\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398173; batch adversarial loss: 0.525241\n",
      "epoch 96; iter: 0; batch classifier loss: 0.407824; batch adversarial loss: 0.506440\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338915; batch adversarial loss: 0.483347\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373665; batch adversarial loss: 0.562037\n",
      "epoch 99; iter: 0; batch classifier loss: 0.426861; batch adversarial loss: 0.465629\n",
      "epoch 100; iter: 0; batch classifier loss: 0.362549; batch adversarial loss: 0.580683\n",
      "epoch 101; iter: 0; batch classifier loss: 0.333838; batch adversarial loss: 0.536242\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401329; batch adversarial loss: 0.483366\n",
      "epoch 103; iter: 0; batch classifier loss: 0.344894; batch adversarial loss: 0.553774\n",
      "epoch 104; iter: 0; batch classifier loss: 0.457028; batch adversarial loss: 0.579721\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415892; batch adversarial loss: 0.509056\n",
      "epoch 106; iter: 0; batch classifier loss: 0.400512; batch adversarial loss: 0.624487\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346760; batch adversarial loss: 0.580479\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387870; batch adversarial loss: 0.517900\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377155; batch adversarial loss: 0.552835\n",
      "epoch 110; iter: 0; batch classifier loss: 0.288769; batch adversarial loss: 0.571843\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386440; batch adversarial loss: 0.544738\n",
      "epoch 112; iter: 0; batch classifier loss: 0.343838; batch adversarial loss: 0.509408\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375485; batch adversarial loss: 0.500613\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373337; batch adversarial loss: 0.553708\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370720; batch adversarial loss: 0.482731\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373089; batch adversarial loss: 0.571375\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363977; batch adversarial loss: 0.650377\n",
      "epoch 118; iter: 0; batch classifier loss: 0.407281; batch adversarial loss: 0.518334\n",
      "epoch 119; iter: 0; batch classifier loss: 0.299029; batch adversarial loss: 0.562810\n",
      "epoch 120; iter: 0; batch classifier loss: 0.334581; batch adversarial loss: 0.580825\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360347; batch adversarial loss: 0.616105\n",
      "epoch 122; iter: 0; batch classifier loss: 0.426691; batch adversarial loss: 0.491021\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353813; batch adversarial loss: 0.526774\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398333; batch adversarial loss: 0.526783\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332928; batch adversarial loss: 0.535644\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405608; batch adversarial loss: 0.562718\n",
      "epoch 127; iter: 0; batch classifier loss: 0.428420; batch adversarial loss: 0.535609\n",
      "epoch 128; iter: 0; batch classifier loss: 0.412323; batch adversarial loss: 0.651630\n",
      "epoch 129; iter: 0; batch classifier loss: 0.286227; batch adversarial loss: 0.535644\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356093; batch adversarial loss: 0.607149\n",
      "epoch 131; iter: 0; batch classifier loss: 0.324187; batch adversarial loss: 0.589373\n",
      "epoch 132; iter: 0; batch classifier loss: 0.369405; batch adversarial loss: 0.535957\n",
      "epoch 133; iter: 0; batch classifier loss: 0.268151; batch adversarial loss: 0.562472\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416986; batch adversarial loss: 0.562450\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354090; batch adversarial loss: 0.589486\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416313; batch adversarial loss: 0.598364\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396968; batch adversarial loss: 0.508854\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348626; batch adversarial loss: 0.607136\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388103; batch adversarial loss: 0.562323\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333034; batch adversarial loss: 0.589428\n",
      "epoch 141; iter: 0; batch classifier loss: 0.331914; batch adversarial loss: 0.526821\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359342; batch adversarial loss: 0.598097\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381529; batch adversarial loss: 0.580454\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380715; batch adversarial loss: 0.553515\n",
      "epoch 145; iter: 0; batch classifier loss: 0.286732; batch adversarial loss: 0.580359\n",
      "epoch 146; iter: 0; batch classifier loss: 0.342856; batch adversarial loss: 0.607046\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340694; batch adversarial loss: 0.535467\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338033; batch adversarial loss: 0.598318\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377309; batch adversarial loss: 0.534004\n",
      "epoch 150; iter: 0; batch classifier loss: 0.303503; batch adversarial loss: 0.552735\n",
      "epoch 151; iter: 0; batch classifier loss: 0.332400; batch adversarial loss: 0.563344\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346524; batch adversarial loss: 0.535953\n",
      "epoch 153; iter: 0; batch classifier loss: 0.332770; batch adversarial loss: 0.499512\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369339; batch adversarial loss: 0.499222\n",
      "epoch 155; iter: 0; batch classifier loss: 0.272188; batch adversarial loss: 0.499512\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396277; batch adversarial loss: 0.634457\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315627; batch adversarial loss: 0.544778\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329001; batch adversarial loss: 0.580135\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351440; batch adversarial loss: 0.508523\n",
      "epoch 160; iter: 0; batch classifier loss: 0.327908; batch adversarial loss: 0.580459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.332955; batch adversarial loss: 0.553877\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325841; batch adversarial loss: 0.499689\n",
      "epoch 163; iter: 0; batch classifier loss: 0.281411; batch adversarial loss: 0.553448\n",
      "epoch 164; iter: 0; batch classifier loss: 0.449739; batch adversarial loss: 0.499858\n",
      "epoch 165; iter: 0; batch classifier loss: 0.255029; batch adversarial loss: 0.535558\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335067; batch adversarial loss: 0.634565\n",
      "epoch 167; iter: 0; batch classifier loss: 0.351527; batch adversarial loss: 0.535751\n",
      "epoch 168; iter: 0; batch classifier loss: 0.319031; batch adversarial loss: 0.589404\n",
      "epoch 169; iter: 0; batch classifier loss: 0.442247; batch adversarial loss: 0.544555\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335149; batch adversarial loss: 0.607515\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358892; batch adversarial loss: 0.633941\n",
      "epoch 172; iter: 0; batch classifier loss: 0.320133; batch adversarial loss: 0.606979\n",
      "epoch 173; iter: 0; batch classifier loss: 0.332116; batch adversarial loss: 0.535816\n",
      "epoch 174; iter: 0; batch classifier loss: 0.289581; batch adversarial loss: 0.517572\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346585; batch adversarial loss: 0.616459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.385355; batch adversarial loss: 0.562607\n",
      "epoch 177; iter: 0; batch classifier loss: 0.402907; batch adversarial loss: 0.580495\n",
      "epoch 178; iter: 0; batch classifier loss: 0.303959; batch adversarial loss: 0.589702\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330723; batch adversarial loss: 0.464458\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391119; batch adversarial loss: 0.590083\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420272; batch adversarial loss: 0.589135\n",
      "epoch 182; iter: 0; batch classifier loss: 0.413195; batch adversarial loss: 0.516495\n",
      "epoch 183; iter: 0; batch classifier loss: 0.314766; batch adversarial loss: 0.480700\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382603; batch adversarial loss: 0.652147\n",
      "epoch 185; iter: 0; batch classifier loss: 0.448622; batch adversarial loss: 0.428494\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334945; batch adversarial loss: 0.508375\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327576; batch adversarial loss: 0.643309\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346371; batch adversarial loss: 0.515740\n",
      "epoch 189; iter: 0; batch classifier loss: 0.454101; batch adversarial loss: 0.621661\n",
      "epoch 190; iter: 0; batch classifier loss: 0.363674; batch adversarial loss: 0.516574\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392566; batch adversarial loss: 0.519096\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319421; batch adversarial loss: 0.501828\n",
      "epoch 193; iter: 0; batch classifier loss: 0.371816; batch adversarial loss: 0.536317\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324200; batch adversarial loss: 0.572510\n",
      "epoch 195; iter: 0; batch classifier loss: 0.326975; batch adversarial loss: 0.615199\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360159; batch adversarial loss: 0.562507\n",
      "epoch 197; iter: 0; batch classifier loss: 0.404127; batch adversarial loss: 0.499881\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362878; batch adversarial loss: 0.509464\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385176; batch adversarial loss: 0.678451\n",
      "epoch 0; iter: 0; batch classifier loss: 0.630532; batch adversarial loss: 0.673728\n",
      "epoch 1; iter: 0; batch classifier loss: 0.568315; batch adversarial loss: 0.647300\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586494; batch adversarial loss: 0.653601\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562487; batch adversarial loss: 0.615275\n",
      "epoch 4; iter: 0; batch classifier loss: 0.527339; batch adversarial loss: 0.586390\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563157; batch adversarial loss: 0.591877\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486150; batch adversarial loss: 0.584800\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557098; batch adversarial loss: 0.544537\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498227; batch adversarial loss: 0.573942\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516415; batch adversarial loss: 0.601368\n",
      "epoch 10; iter: 0; batch classifier loss: 0.497214; batch adversarial loss: 0.593170\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494230; batch adversarial loss: 0.542584\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567777; batch adversarial loss: 0.577124\n",
      "epoch 13; iter: 0; batch classifier loss: 0.478891; batch adversarial loss: 0.578700\n",
      "epoch 14; iter: 0; batch classifier loss: 0.536827; batch adversarial loss: 0.564324\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512131; batch adversarial loss: 0.540119\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542424; batch adversarial loss: 0.533524\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471360; batch adversarial loss: 0.632785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500364; batch adversarial loss: 0.498973\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536728; batch adversarial loss: 0.514445\n",
      "epoch 20; iter: 0; batch classifier loss: 0.557006; batch adversarial loss: 0.594355\n",
      "epoch 21; iter: 0; batch classifier loss: 0.457947; batch adversarial loss: 0.561366\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512075; batch adversarial loss: 0.538418\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482781; batch adversarial loss: 0.511365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456499; batch adversarial loss: 0.554571\n",
      "epoch 25; iter: 0; batch classifier loss: 0.395342; batch adversarial loss: 0.499241\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435871; batch adversarial loss: 0.485382\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453460; batch adversarial loss: 0.509823\n",
      "epoch 28; iter: 0; batch classifier loss: 0.505127; batch adversarial loss: 0.578768\n",
      "epoch 29; iter: 0; batch classifier loss: 0.537734; batch adversarial loss: 0.590321\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430052; batch adversarial loss: 0.500911\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414031; batch adversarial loss: 0.558646\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448596; batch adversarial loss: 0.586661\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451348; batch adversarial loss: 0.584029\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483761; batch adversarial loss: 0.486422\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499005; batch adversarial loss: 0.510287\n",
      "epoch 36; iter: 0; batch classifier loss: 0.483652; batch adversarial loss: 0.536784\n",
      "epoch 37; iter: 0; batch classifier loss: 0.405927; batch adversarial loss: 0.556834\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381271; batch adversarial loss: 0.547953\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410656; batch adversarial loss: 0.565137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.414306; batch adversarial loss: 0.540069\n",
      "epoch 41; iter: 0; batch classifier loss: 0.387392; batch adversarial loss: 0.596663\n",
      "epoch 42; iter: 0; batch classifier loss: 0.412517; batch adversarial loss: 0.564048\n",
      "epoch 43; iter: 0; batch classifier loss: 0.428884; batch adversarial loss: 0.581294\n",
      "epoch 44; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.487288\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419421; batch adversarial loss: 0.461020\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423036; batch adversarial loss: 0.615080\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441436; batch adversarial loss: 0.665210\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403934; batch adversarial loss: 0.610868\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420580; batch adversarial loss: 0.569661\n",
      "epoch 50; iter: 0; batch classifier loss: 0.383694; batch adversarial loss: 0.569384\n",
      "epoch 51; iter: 0; batch classifier loss: 0.401976; batch adversarial loss: 0.564503\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437040; batch adversarial loss: 0.497260\n",
      "epoch 53; iter: 0; batch classifier loss: 0.434659; batch adversarial loss: 0.516219\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432969; batch adversarial loss: 0.499979\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419736; batch adversarial loss: 0.617204\n",
      "epoch 56; iter: 0; batch classifier loss: 0.354104; batch adversarial loss: 0.607498\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374333; batch adversarial loss: 0.544507\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469181; batch adversarial loss: 0.500698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.443788; batch adversarial loss: 0.536201\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397994; batch adversarial loss: 0.545230\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419999; batch adversarial loss: 0.599854\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376043; batch adversarial loss: 0.656268\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406814; batch adversarial loss: 0.498434\n",
      "epoch 64; iter: 0; batch classifier loss: 0.492991; batch adversarial loss: 0.521516\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397717; batch adversarial loss: 0.506261\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384025; batch adversarial loss: 0.526219\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413160; batch adversarial loss: 0.560589\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386363; batch adversarial loss: 0.477464\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440661; batch adversarial loss: 0.539685\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399446; batch adversarial loss: 0.561839\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381666; batch adversarial loss: 0.544685\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403042; batch adversarial loss: 0.515952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.381468; batch adversarial loss: 0.562644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.363338; batch adversarial loss: 0.477586\n",
      "epoch 75; iter: 0; batch classifier loss: 0.490739; batch adversarial loss: 0.586603\n",
      "epoch 76; iter: 0; batch classifier loss: 0.445863; batch adversarial loss: 0.592924\n",
      "epoch 77; iter: 0; batch classifier loss: 0.336158; batch adversarial loss: 0.518263\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399267; batch adversarial loss: 0.506619\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425802; batch adversarial loss: 0.600130\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330147; batch adversarial loss: 0.550614\n",
      "epoch 81; iter: 0; batch classifier loss: 0.347603; batch adversarial loss: 0.600954\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366037; batch adversarial loss: 0.549470\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412504; batch adversarial loss: 0.525091\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376007; batch adversarial loss: 0.487374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404495; batch adversarial loss: 0.530391\n",
      "epoch 86; iter: 0; batch classifier loss: 0.451171; batch adversarial loss: 0.566137\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364755; batch adversarial loss: 0.570420\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392941; batch adversarial loss: 0.526467\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334227; batch adversarial loss: 0.497497\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403365; batch adversarial loss: 0.507783\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383320; batch adversarial loss: 0.516576\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413168; batch adversarial loss: 0.500688\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421436; batch adversarial loss: 0.543283\n",
      "epoch 94; iter: 0; batch classifier loss: 0.338343; batch adversarial loss: 0.534367\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384469; batch adversarial loss: 0.579338\n",
      "epoch 96; iter: 0; batch classifier loss: 0.465451; batch adversarial loss: 0.563672\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410941; batch adversarial loss: 0.544600\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356079; batch adversarial loss: 0.599172\n",
      "epoch 99; iter: 0; batch classifier loss: 0.392723; batch adversarial loss: 0.469843\n",
      "epoch 100; iter: 0; batch classifier loss: 0.405073; batch adversarial loss: 0.535241\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405093; batch adversarial loss: 0.517435\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370793; batch adversarial loss: 0.497777\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358552; batch adversarial loss: 0.580435\n",
      "epoch 104; iter: 0; batch classifier loss: 0.342959; batch adversarial loss: 0.626645\n",
      "epoch 105; iter: 0; batch classifier loss: 0.436514; batch adversarial loss: 0.589642\n",
      "epoch 106; iter: 0; batch classifier loss: 0.396796; batch adversarial loss: 0.514575\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368481; batch adversarial loss: 0.554432\n",
      "epoch 108; iter: 0; batch classifier loss: 0.415161; batch adversarial loss: 0.590570\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346269; batch adversarial loss: 0.519955\n",
      "epoch 110; iter: 0; batch classifier loss: 0.307903; batch adversarial loss: 0.505949\n",
      "epoch 111; iter: 0; batch classifier loss: 0.392577; batch adversarial loss: 0.461350\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402596; batch adversarial loss: 0.561110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378831; batch adversarial loss: 0.477759\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363702; batch adversarial loss: 0.524803\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419270; batch adversarial loss: 0.486720\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364682; batch adversarial loss: 0.552282\n",
      "epoch 117; iter: 0; batch classifier loss: 0.395818; batch adversarial loss: 0.510666\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405371; batch adversarial loss: 0.568818\n",
      "epoch 119; iter: 0; batch classifier loss: 0.313918; batch adversarial loss: 0.594387\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386849; batch adversarial loss: 0.508223\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404592; batch adversarial loss: 0.590383\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400088; batch adversarial loss: 0.610206\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327863; batch adversarial loss: 0.525825\n",
      "epoch 124; iter: 0; batch classifier loss: 0.423955; batch adversarial loss: 0.617446\n",
      "epoch 125; iter: 0; batch classifier loss: 0.443524; batch adversarial loss: 0.516409\n",
      "epoch 126; iter: 0; batch classifier loss: 0.299459; batch adversarial loss: 0.516628\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333002; batch adversarial loss: 0.490975\n",
      "epoch 128; iter: 0; batch classifier loss: 0.435568; batch adversarial loss: 0.508006\n",
      "epoch 129; iter: 0; batch classifier loss: 0.416382; batch adversarial loss: 0.526189\n",
      "epoch 130; iter: 0; batch classifier loss: 0.392870; batch adversarial loss: 0.563082\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371010; batch adversarial loss: 0.581768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.418685; batch adversarial loss: 0.544642\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340203; batch adversarial loss: 0.537906\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390324; batch adversarial loss: 0.581220\n",
      "epoch 135; iter: 0; batch classifier loss: 0.374284; batch adversarial loss: 0.441278\n",
      "epoch 136; iter: 0; batch classifier loss: 0.414146; batch adversarial loss: 0.469917\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351442; batch adversarial loss: 0.601429\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349680; batch adversarial loss: 0.537645\n",
      "epoch 139; iter: 0; batch classifier loss: 0.370737; batch adversarial loss: 0.509096\n",
      "epoch 140; iter: 0; batch classifier loss: 0.339687; batch adversarial loss: 0.505546\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367330; batch adversarial loss: 0.487529\n",
      "epoch 142; iter: 0; batch classifier loss: 0.304577; batch adversarial loss: 0.450361\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382125; batch adversarial loss: 0.549013\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337521; batch adversarial loss: 0.555624\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412139; batch adversarial loss: 0.497482\n",
      "epoch 146; iter: 0; batch classifier loss: 0.370125; batch adversarial loss: 0.507853\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379684; batch adversarial loss: 0.561836\n",
      "epoch 148; iter: 0; batch classifier loss: 0.291909; batch adversarial loss: 0.533995\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368588; batch adversarial loss: 0.507277\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354072; batch adversarial loss: 0.589069\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354259; batch adversarial loss: 0.519055\n",
      "epoch 152; iter: 0; batch classifier loss: 0.288082; batch adversarial loss: 0.542782\n",
      "epoch 153; iter: 0; batch classifier loss: 0.347016; batch adversarial loss: 0.561857\n",
      "epoch 154; iter: 0; batch classifier loss: 0.367955; batch adversarial loss: 0.563718\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334705; batch adversarial loss: 0.451066\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333764; batch adversarial loss: 0.528152\n",
      "epoch 157; iter: 0; batch classifier loss: 0.447359; batch adversarial loss: 0.489017\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364884; batch adversarial loss: 0.537322\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370844; batch adversarial loss: 0.543799\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372931; batch adversarial loss: 0.547490\n",
      "epoch 161; iter: 0; batch classifier loss: 0.285485; batch adversarial loss: 0.556296\n",
      "epoch 162; iter: 0; batch classifier loss: 0.457655; batch adversarial loss: 0.553294\n",
      "epoch 163; iter: 0; batch classifier loss: 0.310080; batch adversarial loss: 0.553037\n",
      "epoch 164; iter: 0; batch classifier loss: 0.391967; batch adversarial loss: 0.598606\n",
      "epoch 165; iter: 0; batch classifier loss: 0.402767; batch adversarial loss: 0.563602\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351121; batch adversarial loss: 0.470005\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367549; batch adversarial loss: 0.506121\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327281; batch adversarial loss: 0.564132\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343955; batch adversarial loss: 0.590987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.321199; batch adversarial loss: 0.442095\n",
      "epoch 171; iter: 0; batch classifier loss: 0.322381; batch adversarial loss: 0.636656\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388795; batch adversarial loss: 0.460104\n",
      "epoch 173; iter: 0; batch classifier loss: 0.413945; batch adversarial loss: 0.571826\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370731; batch adversarial loss: 0.592707\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378520; batch adversarial loss: 0.562077\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340101; batch adversarial loss: 0.573206\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391354; batch adversarial loss: 0.526466\n",
      "epoch 178; iter: 0; batch classifier loss: 0.322085; batch adversarial loss: 0.479224\n",
      "epoch 179; iter: 0; batch classifier loss: 0.278838; batch adversarial loss: 0.457639\n",
      "epoch 180; iter: 0; batch classifier loss: 0.365577; batch adversarial loss: 0.594559\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374368; batch adversarial loss: 0.588957\n",
      "epoch 182; iter: 0; batch classifier loss: 0.293573; batch adversarial loss: 0.567119\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393848; batch adversarial loss: 0.533584\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352763; batch adversarial loss: 0.555848\n",
      "epoch 185; iter: 0; batch classifier loss: 0.304476; batch adversarial loss: 0.524490\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342203; batch adversarial loss: 0.544364\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313066; batch adversarial loss: 0.544369\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361731; batch adversarial loss: 0.543391\n",
      "epoch 189; iter: 0; batch classifier loss: 0.441444; batch adversarial loss: 0.600803\n",
      "epoch 190; iter: 0; batch classifier loss: 0.335338; batch adversarial loss: 0.544827\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320111; batch adversarial loss: 0.533690\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320214; batch adversarial loss: 0.496747\n",
      "epoch 193; iter: 0; batch classifier loss: 0.317102; batch adversarial loss: 0.599528\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353531; batch adversarial loss: 0.600872\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397870; batch adversarial loss: 0.560682\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373630; batch adversarial loss: 0.527196\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332992; batch adversarial loss: 0.563744\n",
      "epoch 198; iter: 0; batch classifier loss: 0.399566; batch adversarial loss: 0.609145\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386328; batch adversarial loss: 0.506559\n",
      "epoch 0; iter: 0; batch classifier loss: 0.780093; batch adversarial loss: 0.719103\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619585; batch adversarial loss: 0.667417\n",
      "epoch 2; iter: 0; batch classifier loss: 0.531619; batch adversarial loss: 0.610422\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543790; batch adversarial loss: 0.659270\n",
      "epoch 4; iter: 0; batch classifier loss: 0.631558; batch adversarial loss: 0.617703\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589130; batch adversarial loss: 0.614435\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544684; batch adversarial loss: 0.639563\n",
      "epoch 7; iter: 0; batch classifier loss: 0.590132; batch adversarial loss: 0.667256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551671; batch adversarial loss: 0.588109\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523000; batch adversarial loss: 0.642905\n",
      "epoch 10; iter: 0; batch classifier loss: 0.608757; batch adversarial loss: 0.609473\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520415; batch adversarial loss: 0.584455\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489433; batch adversarial loss: 0.575045\n",
      "epoch 13; iter: 0; batch classifier loss: 0.628031; batch adversarial loss: 0.533443\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515905; batch adversarial loss: 0.601246\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508858; batch adversarial loss: 0.532328\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522054; batch adversarial loss: 0.518317\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523456; batch adversarial loss: 0.565056\n",
      "epoch 18; iter: 0; batch classifier loss: 0.437212; batch adversarial loss: 0.560754\n",
      "epoch 19; iter: 0; batch classifier loss: 0.460240; batch adversarial loss: 0.593554\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543302; batch adversarial loss: 0.628055\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470084; batch adversarial loss: 0.577681\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441379; batch adversarial loss: 0.556707\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479036; batch adversarial loss: 0.555496\n",
      "epoch 24; iter: 0; batch classifier loss: 0.546991; batch adversarial loss: 0.546647\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490396; batch adversarial loss: 0.591402\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536262; batch adversarial loss: 0.523736\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470949; batch adversarial loss: 0.621003\n",
      "epoch 28; iter: 0; batch classifier loss: 0.437893; batch adversarial loss: 0.613407\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480648; batch adversarial loss: 0.559561\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456986; batch adversarial loss: 0.501320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.539862; batch adversarial loss: 0.551594\n",
      "epoch 32; iter: 0; batch classifier loss: 0.389149; batch adversarial loss: 0.475209\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415717; batch adversarial loss: 0.554665\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446061; batch adversarial loss: 0.546293\n",
      "epoch 35; iter: 0; batch classifier loss: 0.500986; batch adversarial loss: 0.497723\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454287; batch adversarial loss: 0.496129\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463731; batch adversarial loss: 0.527813\n",
      "epoch 38; iter: 0; batch classifier loss: 0.534168; batch adversarial loss: 0.515330\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424675; batch adversarial loss: 0.527363\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481840; batch adversarial loss: 0.501655\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487460; batch adversarial loss: 0.547272\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417260; batch adversarial loss: 0.491822\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398555; batch adversarial loss: 0.556778\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444900; batch adversarial loss: 0.481096\n",
      "epoch 45; iter: 0; batch classifier loss: 0.492390; batch adversarial loss: 0.627177\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371030; batch adversarial loss: 0.516834\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449307; batch adversarial loss: 0.555280\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396422; batch adversarial loss: 0.503155\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413790; batch adversarial loss: 0.579738\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414617; batch adversarial loss: 0.598061\n",
      "epoch 51; iter: 0; batch classifier loss: 0.559800; batch adversarial loss: 0.543418\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466877; batch adversarial loss: 0.527838\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464988; batch adversarial loss: 0.525486\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427136; batch adversarial loss: 0.590227\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436837; batch adversarial loss: 0.526666\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417723; batch adversarial loss: 0.526153\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399243; batch adversarial loss: 0.590931\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424449; batch adversarial loss: 0.570683\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426859; batch adversarial loss: 0.535394\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390644; batch adversarial loss: 0.509754\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427790; batch adversarial loss: 0.552788\n",
      "epoch 62; iter: 0; batch classifier loss: 0.357886; batch adversarial loss: 0.517168\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370842; batch adversarial loss: 0.525415\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412697; batch adversarial loss: 0.546082\n",
      "epoch 65; iter: 0; batch classifier loss: 0.405926; batch adversarial loss: 0.535171\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427983; batch adversarial loss: 0.591048\n",
      "epoch 67; iter: 0; batch classifier loss: 0.443900; batch adversarial loss: 0.470325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.372330; batch adversarial loss: 0.637290\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382838; batch adversarial loss: 0.599413\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402671; batch adversarial loss: 0.582424\n",
      "epoch 71; iter: 0; batch classifier loss: 0.382785; batch adversarial loss: 0.516816\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408064; batch adversarial loss: 0.460811\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396067; batch adversarial loss: 0.532050\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387411; batch adversarial loss: 0.551376\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352484; batch adversarial loss: 0.525598\n",
      "epoch 76; iter: 0; batch classifier loss: 0.403982; batch adversarial loss: 0.573278\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414514; batch adversarial loss: 0.525479\n",
      "epoch 78; iter: 0; batch classifier loss: 0.443889; batch adversarial loss: 0.579981\n",
      "epoch 79; iter: 0; batch classifier loss: 0.466367; batch adversarial loss: 0.571790\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387217; batch adversarial loss: 0.461448\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415461; batch adversarial loss: 0.573428\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443259; batch adversarial loss: 0.571381\n",
      "epoch 83; iter: 0; batch classifier loss: 0.354266; batch adversarial loss: 0.482724\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386059; batch adversarial loss: 0.590912\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393012; batch adversarial loss: 0.471922\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425030; batch adversarial loss: 0.517127\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405700; batch adversarial loss: 0.563388\n",
      "epoch 88; iter: 0; batch classifier loss: 0.452134; batch adversarial loss: 0.537133\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379574; batch adversarial loss: 0.472552\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432614; batch adversarial loss: 0.534896\n",
      "epoch 91; iter: 0; batch classifier loss: 0.431657; batch adversarial loss: 0.627775\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414474; batch adversarial loss: 0.608029\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405505; batch adversarial loss: 0.599101\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375537; batch adversarial loss: 0.517168\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409633; batch adversarial loss: 0.598300\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375450; batch adversarial loss: 0.616643\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334761; batch adversarial loss: 0.581494\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403667; batch adversarial loss: 0.590226\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390885; batch adversarial loss: 0.617411\n",
      "epoch 100; iter: 0; batch classifier loss: 0.328781; batch adversarial loss: 0.599424\n",
      "epoch 101; iter: 0; batch classifier loss: 0.319126; batch adversarial loss: 0.497826\n",
      "epoch 102; iter: 0; batch classifier loss: 0.450705; batch adversarial loss: 0.507885\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402063; batch adversarial loss: 0.599985\n",
      "epoch 104; iter: 0; batch classifier loss: 0.382438; batch adversarial loss: 0.498184\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359125; batch adversarial loss: 0.559888\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373310; batch adversarial loss: 0.544499\n",
      "epoch 107; iter: 0; batch classifier loss: 0.351251; batch adversarial loss: 0.500807\n",
      "epoch 108; iter: 0; batch classifier loss: 0.476616; batch adversarial loss: 0.480904\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368863; batch adversarial loss: 0.526372\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386860; batch adversarial loss: 0.517581\n",
      "epoch 111; iter: 0; batch classifier loss: 0.370596; batch adversarial loss: 0.499478\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415434; batch adversarial loss: 0.508730\n",
      "epoch 113; iter: 0; batch classifier loss: 0.359856; batch adversarial loss: 0.499322\n",
      "epoch 114; iter: 0; batch classifier loss: 0.423251; batch adversarial loss: 0.553330\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405800; batch adversarial loss: 0.508234\n",
      "epoch 116; iter: 0; batch classifier loss: 0.419671; batch adversarial loss: 0.544294\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408623; batch adversarial loss: 0.517187\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386925; batch adversarial loss: 0.599266\n",
      "epoch 119; iter: 0; batch classifier loss: 0.427349; batch adversarial loss: 0.526300\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377030; batch adversarial loss: 0.572606\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355240; batch adversarial loss: 0.553834\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424118; batch adversarial loss: 0.471093\n",
      "epoch 123; iter: 0; batch classifier loss: 0.424547; batch adversarial loss: 0.498638\n",
      "epoch 124; iter: 0; batch classifier loss: 0.411932; batch adversarial loss: 0.562781\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375640; batch adversarial loss: 0.499309\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357903; batch adversarial loss: 0.608177\n",
      "epoch 127; iter: 0; batch classifier loss: 0.409459; batch adversarial loss: 0.617208\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373141; batch adversarial loss: 0.490110\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394372; batch adversarial loss: 0.562881\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354360; batch adversarial loss: 0.635096\n",
      "epoch 131; iter: 0; batch classifier loss: 0.306760; batch adversarial loss: 0.490076\n",
      "epoch 132; iter: 0; batch classifier loss: 0.416487; batch adversarial loss: 0.507969\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393578; batch adversarial loss: 0.518299\n",
      "epoch 134; iter: 0; batch classifier loss: 0.453868; batch adversarial loss: 0.561990\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389619; batch adversarial loss: 0.562791\n",
      "epoch 136; iter: 0; batch classifier loss: 0.312624; batch adversarial loss: 0.581485\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350863; batch adversarial loss: 0.607764\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393868; batch adversarial loss: 0.533637\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381174; batch adversarial loss: 0.573661\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329802; batch adversarial loss: 0.536017\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358944; batch adversarial loss: 0.499023\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330916; batch adversarial loss: 0.638502\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376923; batch adversarial loss: 0.553940\n",
      "epoch 144; iter: 0; batch classifier loss: 0.445821; batch adversarial loss: 0.562661\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364106; batch adversarial loss: 0.535972\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416850; batch adversarial loss: 0.543671\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394773; batch adversarial loss: 0.545129\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339167; batch adversarial loss: 0.554503\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328615; batch adversarial loss: 0.572586\n",
      "epoch 150; iter: 0; batch classifier loss: 0.357507; batch adversarial loss: 0.535046\n",
      "epoch 151; iter: 0; batch classifier loss: 0.312131; batch adversarial loss: 0.562652\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382358; batch adversarial loss: 0.553810\n",
      "epoch 153; iter: 0; batch classifier loss: 0.435083; batch adversarial loss: 0.507519\n",
      "epoch 154; iter: 0; batch classifier loss: 0.334015; batch adversarial loss: 0.562887\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325872; batch adversarial loss: 0.498954\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346713; batch adversarial loss: 0.544178\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359733; batch adversarial loss: 0.581662\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390214; batch adversarial loss: 0.562605\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376712; batch adversarial loss: 0.562665\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321826; batch adversarial loss: 0.498779\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370026; batch adversarial loss: 0.526369\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364041; batch adversarial loss: 0.498516\n",
      "epoch 163; iter: 0; batch classifier loss: 0.427799; batch adversarial loss: 0.647115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.440787; batch adversarial loss: 0.571938\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418452; batch adversarial loss: 0.571362\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325460; batch adversarial loss: 0.581234\n",
      "epoch 167; iter: 0; batch classifier loss: 0.306873; batch adversarial loss: 0.544819\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378190; batch adversarial loss: 0.535788\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403533; batch adversarial loss: 0.490093\n",
      "epoch 170; iter: 0; batch classifier loss: 0.376947; batch adversarial loss: 0.535544\n",
      "epoch 171; iter: 0; batch classifier loss: 0.354456; batch adversarial loss: 0.535174\n",
      "epoch 172; iter: 0; batch classifier loss: 0.335348; batch adversarial loss: 0.563364\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301689; batch adversarial loss: 0.443667\n",
      "epoch 174; iter: 0; batch classifier loss: 0.485987; batch adversarial loss: 0.598861\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368734; batch adversarial loss: 0.470491\n",
      "epoch 176; iter: 0; batch classifier loss: 0.399849; batch adversarial loss: 0.544730\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358104; batch adversarial loss: 0.608662\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330653; batch adversarial loss: 0.562291\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334090; batch adversarial loss: 0.497772\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360943; batch adversarial loss: 0.509119\n",
      "epoch 181; iter: 0; batch classifier loss: 0.427427; batch adversarial loss: 0.516966\n",
      "epoch 182; iter: 0; batch classifier loss: 0.299309; batch adversarial loss: 0.681813\n",
      "epoch 183; iter: 0; batch classifier loss: 0.467842; batch adversarial loss: 0.544635\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360953; batch adversarial loss: 0.526463\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355276; batch adversarial loss: 0.508363\n",
      "epoch 186; iter: 0; batch classifier loss: 0.438704; batch adversarial loss: 0.490295\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382540; batch adversarial loss: 0.481033\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391041; batch adversarial loss: 0.580786\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361169; batch adversarial loss: 0.517000\n",
      "epoch 190; iter: 0; batch classifier loss: 0.334882; batch adversarial loss: 0.544653\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354298; batch adversarial loss: 0.526337\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326102; batch adversarial loss: 0.535604\n",
      "epoch 193; iter: 0; batch classifier loss: 0.365211; batch adversarial loss: 0.544606\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335860; batch adversarial loss: 0.572241\n",
      "epoch 195; iter: 0; batch classifier loss: 0.433372; batch adversarial loss: 0.553803\n",
      "epoch 196; iter: 0; batch classifier loss: 0.427400; batch adversarial loss: 0.553715\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370533; batch adversarial loss: 0.590450\n",
      "epoch 198; iter: 0; batch classifier loss: 0.460110; batch adversarial loss: 0.544379\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318738; batch adversarial loss: 0.562488\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711995; batch adversarial loss: 0.739022\n",
      "epoch 1; iter: 0; batch classifier loss: 0.568795; batch adversarial loss: 0.682074\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547587; batch adversarial loss: 0.682947\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585670; batch adversarial loss: 0.669948\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571696; batch adversarial loss: 0.603818\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570612; batch adversarial loss: 0.605125\n",
      "epoch 6; iter: 0; batch classifier loss: 0.556818; batch adversarial loss: 0.558483\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557337; batch adversarial loss: 0.577357\n",
      "epoch 8; iter: 0; batch classifier loss: 0.468858; batch adversarial loss: 0.583674\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537975; batch adversarial loss: 0.545475\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558402; batch adversarial loss: 0.537503\n",
      "epoch 11; iter: 0; batch classifier loss: 0.455268; batch adversarial loss: 0.636667\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476810; batch adversarial loss: 0.574812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519474; batch adversarial loss: 0.546767\n",
      "epoch 14; iter: 0; batch classifier loss: 0.447621; batch adversarial loss: 0.549781\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540198; batch adversarial loss: 0.576955\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561588; batch adversarial loss: 0.692129\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550954; batch adversarial loss: 0.580029\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496922; batch adversarial loss: 0.587377\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505243; batch adversarial loss: 0.560428\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489749; batch adversarial loss: 0.530652\n",
      "epoch 21; iter: 0; batch classifier loss: 0.438391; batch adversarial loss: 0.540545\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478026; batch adversarial loss: 0.624702\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490937; batch adversarial loss: 0.546248\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471467; batch adversarial loss: 0.548145\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492686; batch adversarial loss: 0.493047\n",
      "epoch 26; iter: 0; batch classifier loss: 0.420052; batch adversarial loss: 0.552894\n",
      "epoch 27; iter: 0; batch classifier loss: 0.522203; batch adversarial loss: 0.577942\n",
      "epoch 28; iter: 0; batch classifier loss: 0.535358; batch adversarial loss: 0.590976\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502840; batch adversarial loss: 0.578591\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484761; batch adversarial loss: 0.556430\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436827; batch adversarial loss: 0.565965\n",
      "epoch 32; iter: 0; batch classifier loss: 0.507579; batch adversarial loss: 0.558700\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447127; batch adversarial loss: 0.537993\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449859; batch adversarial loss: 0.581558\n",
      "epoch 35; iter: 0; batch classifier loss: 0.531435; batch adversarial loss: 0.469782\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457753; batch adversarial loss: 0.528868\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436755; batch adversarial loss: 0.580121\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440982; batch adversarial loss: 0.665792\n",
      "epoch 39; iter: 0; batch classifier loss: 0.517327; batch adversarial loss: 0.588443\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393079; batch adversarial loss: 0.518449\n",
      "epoch 41; iter: 0; batch classifier loss: 0.502301; batch adversarial loss: 0.562385\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464170; batch adversarial loss: 0.614550\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449712; batch adversarial loss: 0.583260\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465256; batch adversarial loss: 0.599022\n",
      "epoch 45; iter: 0; batch classifier loss: 0.501086; batch adversarial loss: 0.608422\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462775; batch adversarial loss: 0.526215\n",
      "epoch 47; iter: 0; batch classifier loss: 0.501290; batch adversarial loss: 0.573500\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401166; batch adversarial loss: 0.572398\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405011; batch adversarial loss: 0.452370\n",
      "epoch 50; iter: 0; batch classifier loss: 0.373690; batch adversarial loss: 0.522512\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463185; batch adversarial loss: 0.572971\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410692; batch adversarial loss: 0.598351\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403222; batch adversarial loss: 0.601720\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415743; batch adversarial loss: 0.493293\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423387; batch adversarial loss: 0.645975\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449304; batch adversarial loss: 0.558151\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402669; batch adversarial loss: 0.572908\n",
      "epoch 58; iter: 0; batch classifier loss: 0.375744; batch adversarial loss: 0.588753\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419167; batch adversarial loss: 0.553764\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389043; batch adversarial loss: 0.513305\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386831; batch adversarial loss: 0.570406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.369088; batch adversarial loss: 0.617562\n",
      "epoch 63; iter: 0; batch classifier loss: 0.405270; batch adversarial loss: 0.570327\n",
      "epoch 64; iter: 0; batch classifier loss: 0.314868; batch adversarial loss: 0.569482\n",
      "epoch 65; iter: 0; batch classifier loss: 0.354225; batch adversarial loss: 0.542879\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405423; batch adversarial loss: 0.572486\n",
      "epoch 67; iter: 0; batch classifier loss: 0.448637; batch adversarial loss: 0.536004\n",
      "epoch 68; iter: 0; batch classifier loss: 0.446175; batch adversarial loss: 0.527278\n",
      "epoch 69; iter: 0; batch classifier loss: 0.491199; batch adversarial loss: 0.536515\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464264; batch adversarial loss: 0.596998\n",
      "epoch 71; iter: 0; batch classifier loss: 0.472826; batch adversarial loss: 0.579934\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390068; batch adversarial loss: 0.516797\n",
      "epoch 73; iter: 0; batch classifier loss: 0.343226; batch adversarial loss: 0.544195\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401361; batch adversarial loss: 0.570865\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382653; batch adversarial loss: 0.526582\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376868; batch adversarial loss: 0.553971\n",
      "epoch 77; iter: 0; batch classifier loss: 0.343863; batch adversarial loss: 0.555126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347615; batch adversarial loss: 0.518915\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439728; batch adversarial loss: 0.509299\n",
      "epoch 80; iter: 0; batch classifier loss: 0.460915; batch adversarial loss: 0.525173\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403273; batch adversarial loss: 0.517024\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342704; batch adversarial loss: 0.635255\n",
      "epoch 83; iter: 0; batch classifier loss: 0.366076; batch adversarial loss: 0.461831\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377622; batch adversarial loss: 0.515772\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367600; batch adversarial loss: 0.590687\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432597; batch adversarial loss: 0.489321\n",
      "epoch 87; iter: 0; batch classifier loss: 0.327029; batch adversarial loss: 0.625951\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393526; batch adversarial loss: 0.544616\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415427; batch adversarial loss: 0.617973\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428727; batch adversarial loss: 0.536030\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428263; batch adversarial loss: 0.535253\n",
      "epoch 92; iter: 0; batch classifier loss: 0.345997; batch adversarial loss: 0.572217\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385759; batch adversarial loss: 0.551241\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414073; batch adversarial loss: 0.600310\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379767; batch adversarial loss: 0.514457\n",
      "epoch 96; iter: 0; batch classifier loss: 0.433776; batch adversarial loss: 0.553425\n",
      "epoch 97; iter: 0; batch classifier loss: 0.432357; batch adversarial loss: 0.582527\n",
      "epoch 98; iter: 0; batch classifier loss: 0.318611; batch adversarial loss: 0.572587\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456627; batch adversarial loss: 0.573438\n",
      "epoch 100; iter: 0; batch classifier loss: 0.371638; batch adversarial loss: 0.508088\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344084; batch adversarial loss: 0.489074\n",
      "epoch 102; iter: 0; batch classifier loss: 0.390804; batch adversarial loss: 0.589638\n",
      "epoch 103; iter: 0; batch classifier loss: 0.454345; batch adversarial loss: 0.516257\n",
      "epoch 104; iter: 0; batch classifier loss: 0.437411; batch adversarial loss: 0.581572\n",
      "epoch 105; iter: 0; batch classifier loss: 0.326040; batch adversarial loss: 0.569843\n",
      "epoch 106; iter: 0; batch classifier loss: 0.317300; batch adversarial loss: 0.518036\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347008; batch adversarial loss: 0.600731\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384855; batch adversarial loss: 0.511021\n",
      "epoch 109; iter: 0; batch classifier loss: 0.422188; batch adversarial loss: 0.591486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381796; batch adversarial loss: 0.554966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.318066; batch adversarial loss: 0.516918\n",
      "epoch 112; iter: 0; batch classifier loss: 0.350994; batch adversarial loss: 0.580971\n",
      "epoch 113; iter: 0; batch classifier loss: 0.325382; batch adversarial loss: 0.601223\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375156; batch adversarial loss: 0.544796\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332559; batch adversarial loss: 0.535128\n",
      "epoch 116; iter: 0; batch classifier loss: 0.386676; batch adversarial loss: 0.547415\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385676; batch adversarial loss: 0.499372\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363776; batch adversarial loss: 0.661517\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382790; batch adversarial loss: 0.581043\n",
      "epoch 120; iter: 0; batch classifier loss: 0.317824; batch adversarial loss: 0.498410\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344903; batch adversarial loss: 0.518415\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379256; batch adversarial loss: 0.498995\n",
      "epoch 123; iter: 0; batch classifier loss: 0.340621; batch adversarial loss: 0.546067\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338864; batch adversarial loss: 0.589011\n",
      "epoch 125; iter: 0; batch classifier loss: 0.388766; batch adversarial loss: 0.489034\n",
      "epoch 126; iter: 0; batch classifier loss: 0.281064; batch adversarial loss: 0.536629\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415600; batch adversarial loss: 0.568476\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356869; batch adversarial loss: 0.534628\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376774; batch adversarial loss: 0.556321\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413705; batch adversarial loss: 0.572253\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414010; batch adversarial loss: 0.580700\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340412; batch adversarial loss: 0.561156\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355805; batch adversarial loss: 0.545796\n",
      "epoch 134; iter: 0; batch classifier loss: 0.380801; batch adversarial loss: 0.517089\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314246; batch adversarial loss: 0.488991\n",
      "epoch 136; iter: 0; batch classifier loss: 0.315481; batch adversarial loss: 0.572264\n",
      "epoch 137; iter: 0; batch classifier loss: 0.342136; batch adversarial loss: 0.590741\n",
      "epoch 138; iter: 0; batch classifier loss: 0.434748; batch adversarial loss: 0.580350\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341966; batch adversarial loss: 0.472146\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333756; batch adversarial loss: 0.536350\n",
      "epoch 141; iter: 0; batch classifier loss: 0.360076; batch adversarial loss: 0.472548\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400813; batch adversarial loss: 0.554303\n",
      "epoch 143; iter: 0; batch classifier loss: 0.407545; batch adversarial loss: 0.561624\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340698; batch adversarial loss: 0.535981\n",
      "epoch 145; iter: 0; batch classifier loss: 0.360998; batch adversarial loss: 0.490682\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395493; batch adversarial loss: 0.554186\n",
      "epoch 147; iter: 0; batch classifier loss: 0.411757; batch adversarial loss: 0.515431\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386777; batch adversarial loss: 0.588045\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376556; batch adversarial loss: 0.526461\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355483; batch adversarial loss: 0.571027\n",
      "epoch 151; iter: 0; batch classifier loss: 0.419224; batch adversarial loss: 0.525751\n",
      "epoch 152; iter: 0; batch classifier loss: 0.380601; batch adversarial loss: 0.553408\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402954; batch adversarial loss: 0.526435\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345758; batch adversarial loss: 0.571274\n",
      "epoch 155; iter: 0; batch classifier loss: 0.306698; batch adversarial loss: 0.516447\n",
      "epoch 156; iter: 0; batch classifier loss: 0.471630; batch adversarial loss: 0.526480\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334444; batch adversarial loss: 0.480034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.415372; batch adversarial loss: 0.572377\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363157; batch adversarial loss: 0.618183\n",
      "epoch 160; iter: 0; batch classifier loss: 0.292896; batch adversarial loss: 0.572118\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368292; batch adversarial loss: 0.556217\n",
      "epoch 162; iter: 0; batch classifier loss: 0.375572; batch adversarial loss: 0.570922\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379992; batch adversarial loss: 0.562283\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346802; batch adversarial loss: 0.552875\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410045; batch adversarial loss: 0.581144\n",
      "epoch 166; iter: 0; batch classifier loss: 0.290583; batch adversarial loss: 0.578940\n",
      "epoch 167; iter: 0; batch classifier loss: 0.396966; batch adversarial loss: 0.569631\n",
      "epoch 168; iter: 0; batch classifier loss: 0.406473; batch adversarial loss: 0.563964\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352912; batch adversarial loss: 0.562830\n",
      "epoch 170; iter: 0; batch classifier loss: 0.375115; batch adversarial loss: 0.616744\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369349; batch adversarial loss: 0.572186\n",
      "epoch 172; iter: 0; batch classifier loss: 0.369414; batch adversarial loss: 0.546372\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321556; batch adversarial loss: 0.554932\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336894; batch adversarial loss: 0.498138\n",
      "epoch 175; iter: 0; batch classifier loss: 0.312920; batch adversarial loss: 0.562157\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349217; batch adversarial loss: 0.508012\n",
      "epoch 177; iter: 0; batch classifier loss: 0.301532; batch adversarial loss: 0.501508\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343838; batch adversarial loss: 0.526756\n",
      "epoch 179; iter: 0; batch classifier loss: 0.332874; batch adversarial loss: 0.510006\n",
      "epoch 180; iter: 0; batch classifier loss: 0.443035; batch adversarial loss: 0.561435\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334936; batch adversarial loss: 0.535225\n",
      "epoch 182; iter: 0; batch classifier loss: 0.241188; batch adversarial loss: 0.508238\n",
      "epoch 183; iter: 0; batch classifier loss: 0.283992; batch adversarial loss: 0.561349\n",
      "epoch 184; iter: 0; batch classifier loss: 0.420361; batch adversarial loss: 0.508306\n",
      "epoch 185; iter: 0; batch classifier loss: 0.412277; batch adversarial loss: 0.552346\n",
      "epoch 186; iter: 0; batch classifier loss: 0.316437; batch adversarial loss: 0.516779\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395815; batch adversarial loss: 0.435273\n",
      "epoch 188; iter: 0; batch classifier loss: 0.388218; batch adversarial loss: 0.534898\n",
      "epoch 189; iter: 0; batch classifier loss: 0.327518; batch adversarial loss: 0.498683\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297453; batch adversarial loss: 0.488164\n",
      "epoch 191; iter: 0; batch classifier loss: 0.410053; batch adversarial loss: 0.599274\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348799; batch adversarial loss: 0.544083\n",
      "epoch 193; iter: 0; batch classifier loss: 0.274329; batch adversarial loss: 0.590514\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347235; batch adversarial loss: 0.544498\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321846; batch adversarial loss: 0.526945\n",
      "epoch 196; iter: 0; batch classifier loss: 0.259615; batch adversarial loss: 0.572230\n",
      "epoch 197; iter: 0; batch classifier loss: 0.233802; batch adversarial loss: 0.527374\n",
      "epoch 198; iter: 0; batch classifier loss: 0.314200; batch adversarial loss: 0.570981\n",
      "epoch 199; iter: 0; batch classifier loss: 0.548197; batch adversarial loss: 0.473211\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739699; batch adversarial loss: 0.648450\n",
      "epoch 1; iter: 0; batch classifier loss: 0.541158; batch adversarial loss: 0.654621\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561285; batch adversarial loss: 0.636726\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591955; batch adversarial loss: 0.624576\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640664; batch adversarial loss: 0.626576\n",
      "epoch 5; iter: 0; batch classifier loss: 0.617045; batch adversarial loss: 0.642354\n",
      "epoch 6; iter: 0; batch classifier loss: 0.615243; batch adversarial loss: 0.634395\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612421; batch adversarial loss: 0.603435\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586140; batch adversarial loss: 0.584996\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522210; batch adversarial loss: 0.615222\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506711; batch adversarial loss: 0.582784\n",
      "epoch 11; iter: 0; batch classifier loss: 0.471115; batch adversarial loss: 0.540049\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452396; batch adversarial loss: 0.551023\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530370; batch adversarial loss: 0.596515\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515583; batch adversarial loss: 0.560400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.479091; batch adversarial loss: 0.550786\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523078; batch adversarial loss: 0.491404\n",
      "epoch 17; iter: 0; batch classifier loss: 0.448428; batch adversarial loss: 0.489927\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489732; batch adversarial loss: 0.559267\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489479; batch adversarial loss: 0.606627\n",
      "epoch 20; iter: 0; batch classifier loss: 0.464678; batch adversarial loss: 0.566096\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495080; batch adversarial loss: 0.641233\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487602; batch adversarial loss: 0.503318\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493786; batch adversarial loss: 0.591347\n",
      "epoch 24; iter: 0; batch classifier loss: 0.444433; batch adversarial loss: 0.536370\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456679; batch adversarial loss: 0.526672\n",
      "epoch 26; iter: 0; batch classifier loss: 0.529844; batch adversarial loss: 0.503234\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445994; batch adversarial loss: 0.494592\n",
      "epoch 28; iter: 0; batch classifier loss: 0.517685; batch adversarial loss: 0.564147\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461894; batch adversarial loss: 0.601044\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421022; batch adversarial loss: 0.537444\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425286; batch adversarial loss: 0.545951\n",
      "epoch 32; iter: 0; batch classifier loss: 0.446899; batch adversarial loss: 0.574545\n",
      "epoch 33; iter: 0; batch classifier loss: 0.397526; batch adversarial loss: 0.502977\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415569; batch adversarial loss: 0.578326\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411620; batch adversarial loss: 0.560776\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407765; batch adversarial loss: 0.555416\n",
      "epoch 37; iter: 0; batch classifier loss: 0.387749; batch adversarial loss: 0.587902\n",
      "epoch 38; iter: 0; batch classifier loss: 0.395536; batch adversarial loss: 0.625222\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452720; batch adversarial loss: 0.544567\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455579; batch adversarial loss: 0.527267\n",
      "epoch 41; iter: 0; batch classifier loss: 0.479464; batch adversarial loss: 0.580913\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456702; batch adversarial loss: 0.660832\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399680; batch adversarial loss: 0.616256\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422559; batch adversarial loss: 0.517849\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448194; batch adversarial loss: 0.517660\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402040; batch adversarial loss: 0.472702\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440179; batch adversarial loss: 0.544498\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412005; batch adversarial loss: 0.589595\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369726; batch adversarial loss: 0.634834\n",
      "epoch 50; iter: 0; batch classifier loss: 0.475359; batch adversarial loss: 0.607834\n",
      "epoch 51; iter: 0; batch classifier loss: 0.504149; batch adversarial loss: 0.544913\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460326; batch adversarial loss: 0.481536\n",
      "epoch 53; iter: 0; batch classifier loss: 0.407016; batch adversarial loss: 0.471712\n",
      "epoch 54; iter: 0; batch classifier loss: 0.383595; batch adversarial loss: 0.544327\n",
      "epoch 55; iter: 0; batch classifier loss: 0.361135; batch adversarial loss: 0.589558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.427015; batch adversarial loss: 0.534922\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471209; batch adversarial loss: 0.463703\n",
      "epoch 58; iter: 0; batch classifier loss: 0.416897; batch adversarial loss: 0.598267\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445138; batch adversarial loss: 0.577875\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396861; batch adversarial loss: 0.612208\n",
      "epoch 61; iter: 0; batch classifier loss: 0.374833; batch adversarial loss: 0.536009\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401629; batch adversarial loss: 0.508184\n",
      "epoch 63; iter: 0; batch classifier loss: 0.345645; batch adversarial loss: 0.570297\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401206; batch adversarial loss: 0.506259\n",
      "epoch 65; iter: 0; batch classifier loss: 0.372570; batch adversarial loss: 0.578136\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411156; batch adversarial loss: 0.508340\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399313; batch adversarial loss: 0.472776\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438031; batch adversarial loss: 0.590044\n",
      "epoch 69; iter: 0; batch classifier loss: 0.464287; batch adversarial loss: 0.536361\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421716; batch adversarial loss: 0.620456\n",
      "epoch 71; iter: 0; batch classifier loss: 0.482227; batch adversarial loss: 0.516494\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397471; batch adversarial loss: 0.526159\n",
      "epoch 73; iter: 0; batch classifier loss: 0.458983; batch adversarial loss: 0.610097\n",
      "epoch 74; iter: 0; batch classifier loss: 0.448300; batch adversarial loss: 0.581583\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400944; batch adversarial loss: 0.562978\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409450; batch adversarial loss: 0.553677\n",
      "epoch 77; iter: 0; batch classifier loss: 0.354162; batch adversarial loss: 0.534963\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386241; batch adversarial loss: 0.489836\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368259; batch adversarial loss: 0.471785\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374944; batch adversarial loss: 0.563000\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396908; batch adversarial loss: 0.553493\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367979; batch adversarial loss: 0.572018\n",
      "epoch 83; iter: 0; batch classifier loss: 0.463893; batch adversarial loss: 0.572116\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449729; batch adversarial loss: 0.561309\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452695; batch adversarial loss: 0.562866\n",
      "epoch 86; iter: 0; batch classifier loss: 0.354696; batch adversarial loss: 0.489789\n",
      "epoch 87; iter: 0; batch classifier loss: 0.354216; batch adversarial loss: 0.517156\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421497; batch adversarial loss: 0.616765\n",
      "epoch 89; iter: 0; batch classifier loss: 0.466323; batch adversarial loss: 0.535279\n",
      "epoch 90; iter: 0; batch classifier loss: 0.358807; batch adversarial loss: 0.590811\n",
      "epoch 91; iter: 0; batch classifier loss: 0.451578; batch adversarial loss: 0.561883\n",
      "epoch 92; iter: 0; batch classifier loss: 0.369218; batch adversarial loss: 0.498940\n",
      "epoch 93; iter: 0; batch classifier loss: 0.428198; batch adversarial loss: 0.490512\n",
      "epoch 94; iter: 0; batch classifier loss: 0.388547; batch adversarial loss: 0.626389\n",
      "epoch 95; iter: 0; batch classifier loss: 0.388402; batch adversarial loss: 0.554262\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410922; batch adversarial loss: 0.525895\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379045; batch adversarial loss: 0.490908\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402775; batch adversarial loss: 0.598623\n",
      "epoch 99; iter: 0; batch classifier loss: 0.319156; batch adversarial loss: 0.517600\n",
      "epoch 100; iter: 0; batch classifier loss: 0.331687; batch adversarial loss: 0.554032\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355844; batch adversarial loss: 0.590112\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363019; batch adversarial loss: 0.453485\n",
      "epoch 103; iter: 0; batch classifier loss: 0.424949; batch adversarial loss: 0.571125\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385187; batch adversarial loss: 0.480666\n",
      "epoch 105; iter: 0; batch classifier loss: 0.320111; batch adversarial loss: 0.490755\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443070; batch adversarial loss: 0.654676\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382584; batch adversarial loss: 0.553824\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403594; batch adversarial loss: 0.543721\n",
      "epoch 109; iter: 0; batch classifier loss: 0.283596; batch adversarial loss: 0.517500\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366176; batch adversarial loss: 0.571040\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380011; batch adversarial loss: 0.644679\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383040; batch adversarial loss: 0.508275\n",
      "epoch 113; iter: 0; batch classifier loss: 0.430653; batch adversarial loss: 0.507554\n",
      "epoch 114; iter: 0; batch classifier loss: 0.332026; batch adversarial loss: 0.526286\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357099; batch adversarial loss: 0.652822\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380618; batch adversarial loss: 0.535788\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351075; batch adversarial loss: 0.534615\n",
      "epoch 118; iter: 0; batch classifier loss: 0.331516; batch adversarial loss: 0.488906\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392263; batch adversarial loss: 0.489524\n",
      "epoch 120; iter: 0; batch classifier loss: 0.348927; batch adversarial loss: 0.580550\n",
      "epoch 121; iter: 0; batch classifier loss: 0.359150; batch adversarial loss: 0.500209\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368384; batch adversarial loss: 0.588603\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354821; batch adversarial loss: 0.500135\n",
      "epoch 124; iter: 0; batch classifier loss: 0.294601; batch adversarial loss: 0.543668\n",
      "epoch 125; iter: 0; batch classifier loss: 0.446386; batch adversarial loss: 0.571602\n",
      "epoch 126; iter: 0; batch classifier loss: 0.345155; batch adversarial loss: 0.552677\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376109; batch adversarial loss: 0.653929\n",
      "epoch 128; iter: 0; batch classifier loss: 0.371824; batch adversarial loss: 0.453295\n",
      "epoch 129; iter: 0; batch classifier loss: 0.345470; batch adversarial loss: 0.525597\n",
      "epoch 130; iter: 0; batch classifier loss: 0.330557; batch adversarial loss: 0.471937\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361472; batch adversarial loss: 0.553295\n",
      "epoch 132; iter: 0; batch classifier loss: 0.365065; batch adversarial loss: 0.526240\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351834; batch adversarial loss: 0.600863\n",
      "epoch 134; iter: 0; batch classifier loss: 0.360385; batch adversarial loss: 0.507009\n",
      "epoch 135; iter: 0; batch classifier loss: 0.355748; batch adversarial loss: 0.554153\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328315; batch adversarial loss: 0.589204\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371801; batch adversarial loss: 0.518307\n",
      "epoch 138; iter: 0; batch classifier loss: 0.327364; batch adversarial loss: 0.489725\n",
      "epoch 139; iter: 0; batch classifier loss: 0.382394; batch adversarial loss: 0.626780\n",
      "epoch 140; iter: 0; batch classifier loss: 0.330235; batch adversarial loss: 0.518128\n",
      "epoch 141; iter: 0; batch classifier loss: 0.327116; batch adversarial loss: 0.499767\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410103; batch adversarial loss: 0.536118\n",
      "epoch 143; iter: 0; batch classifier loss: 0.392171; batch adversarial loss: 0.636276\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312851; batch adversarial loss: 0.617063\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380594; batch adversarial loss: 0.572294\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383721; batch adversarial loss: 0.553297\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410976; batch adversarial loss: 0.535769\n",
      "epoch 148; iter: 0; batch classifier loss: 0.427761; batch adversarial loss: 0.581477\n",
      "epoch 149; iter: 0; batch classifier loss: 0.444524; batch adversarial loss: 0.471926\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311742; batch adversarial loss: 0.525378\n",
      "epoch 151; iter: 0; batch classifier loss: 0.358038; batch adversarial loss: 0.544695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.386889; batch adversarial loss: 0.582517\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343711; batch adversarial loss: 0.517419\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400231; batch adversarial loss: 0.561657\n",
      "epoch 155; iter: 0; batch classifier loss: 0.260054; batch adversarial loss: 0.472080\n",
      "epoch 156; iter: 0; batch classifier loss: 0.319656; batch adversarial loss: 0.535719\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393661; batch adversarial loss: 0.580067\n",
      "epoch 158; iter: 0; batch classifier loss: 0.303234; batch adversarial loss: 0.553858\n",
      "epoch 159; iter: 0; batch classifier loss: 0.299590; batch adversarial loss: 0.628361\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356926; batch adversarial loss: 0.626609\n",
      "epoch 161; iter: 0; batch classifier loss: 0.404657; batch adversarial loss: 0.625149\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381079; batch adversarial loss: 0.507840\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338057; batch adversarial loss: 0.461426\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366787; batch adversarial loss: 0.599934\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371222; batch adversarial loss: 0.545174\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342141; batch adversarial loss: 0.572211\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324324; batch adversarial loss: 0.609306\n",
      "epoch 168; iter: 0; batch classifier loss: 0.313016; batch adversarial loss: 0.579882\n",
      "epoch 169; iter: 0; batch classifier loss: 0.422359; batch adversarial loss: 0.591033\n",
      "epoch 170; iter: 0; batch classifier loss: 0.419850; batch adversarial loss: 0.517272\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396316; batch adversarial loss: 0.498827\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331310; batch adversarial loss: 0.589581\n",
      "epoch 173; iter: 0; batch classifier loss: 0.390190; batch adversarial loss: 0.644800\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338828; batch adversarial loss: 0.562715\n",
      "epoch 175; iter: 0; batch classifier loss: 0.385419; batch adversarial loss: 0.571352\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310252; batch adversarial loss: 0.543894\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321315; batch adversarial loss: 0.526201\n",
      "epoch 178; iter: 0; batch classifier loss: 0.277442; batch adversarial loss: 0.463639\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390766; batch adversarial loss: 0.490639\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323237; batch adversarial loss: 0.553462\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411662; batch adversarial loss: 0.544708\n",
      "epoch 182; iter: 0; batch classifier loss: 0.347668; batch adversarial loss: 0.490938\n",
      "epoch 183; iter: 0; batch classifier loss: 0.416480; batch adversarial loss: 0.600336\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350448; batch adversarial loss: 0.562810\n",
      "epoch 185; iter: 0; batch classifier loss: 0.329175; batch adversarial loss: 0.471293\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386125; batch adversarial loss: 0.536611\n",
      "epoch 187; iter: 0; batch classifier loss: 0.316563; batch adversarial loss: 0.607908\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359867; batch adversarial loss: 0.526849\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361416; batch adversarial loss: 0.562904\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340974; batch adversarial loss: 0.506677\n",
      "epoch 191; iter: 0; batch classifier loss: 0.396209; batch adversarial loss: 0.499272\n",
      "epoch 192; iter: 0; batch classifier loss: 0.329993; batch adversarial loss: 0.543924\n",
      "epoch 193; iter: 0; batch classifier loss: 0.317264; batch adversarial loss: 0.570703\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324674; batch adversarial loss: 0.471301\n",
      "epoch 195; iter: 0; batch classifier loss: 0.391243; batch adversarial loss: 0.544508\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321135; batch adversarial loss: 0.526011\n",
      "epoch 197; iter: 0; batch classifier loss: 0.376940; batch adversarial loss: 0.599210\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389560; batch adversarial loss: 0.562342\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349547; batch adversarial loss: 0.626028\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683090; batch adversarial loss: 0.648954\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587064; batch adversarial loss: 0.654275\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581098; batch adversarial loss: 0.630488\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651679; batch adversarial loss: 0.647369\n",
      "epoch 4; iter: 0; batch classifier loss: 0.508179; batch adversarial loss: 0.623756\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612757; batch adversarial loss: 0.634619\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574165; batch adversarial loss: 0.603363\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498130; batch adversarial loss: 0.601238\n",
      "epoch 8; iter: 0; batch classifier loss: 0.697028; batch adversarial loss: 0.589630\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578858; batch adversarial loss: 0.590554\n",
      "epoch 10; iter: 0; batch classifier loss: 0.596467; batch adversarial loss: 0.560061\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580925; batch adversarial loss: 0.615199\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544804; batch adversarial loss: 0.582318\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518683; batch adversarial loss: 0.555891\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541038; batch adversarial loss: 0.568576\n",
      "epoch 15; iter: 0; batch classifier loss: 0.589306; batch adversarial loss: 0.561938\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483664; batch adversarial loss: 0.552457\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519190; batch adversarial loss: 0.596627\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548095; batch adversarial loss: 0.567348\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521243; batch adversarial loss: 0.541017\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450688; batch adversarial loss: 0.563593\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510484; batch adversarial loss: 0.535879\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440575; batch adversarial loss: 0.464723\n",
      "epoch 23; iter: 0; batch classifier loss: 0.565406; batch adversarial loss: 0.613787\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422459; batch adversarial loss: 0.466605\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490746; batch adversarial loss: 0.516397\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512995; batch adversarial loss: 0.562156\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517168; batch adversarial loss: 0.512938\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431490; batch adversarial loss: 0.516483\n",
      "epoch 29; iter: 0; batch classifier loss: 0.525722; batch adversarial loss: 0.530227\n",
      "epoch 30; iter: 0; batch classifier loss: 0.520695; batch adversarial loss: 0.602155\n",
      "epoch 31; iter: 0; batch classifier loss: 0.585551; batch adversarial loss: 0.461578\n",
      "epoch 32; iter: 0; batch classifier loss: 0.563215; batch adversarial loss: 0.506425\n",
      "epoch 33; iter: 0; batch classifier loss: 0.558569; batch adversarial loss: 0.612456\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446158; batch adversarial loss: 0.617805\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454820; batch adversarial loss: 0.603768\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448764; batch adversarial loss: 0.566513\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465916; batch adversarial loss: 0.587076\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488062; batch adversarial loss: 0.477318\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425255; batch adversarial loss: 0.559265\n",
      "epoch 40; iter: 0; batch classifier loss: 0.499208; batch adversarial loss: 0.531804\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424736; batch adversarial loss: 0.604867\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469062; batch adversarial loss: 0.538471\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435880; batch adversarial loss: 0.510330\n",
      "epoch 44; iter: 0; batch classifier loss: 0.432677; batch adversarial loss: 0.492537\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489861; batch adversarial loss: 0.510858\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448364; batch adversarial loss: 0.580038\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452770; batch adversarial loss: 0.598679\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446673; batch adversarial loss: 0.499982\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442053; batch adversarial loss: 0.570605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.434403; batch adversarial loss: 0.533946\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424077; batch adversarial loss: 0.560680\n",
      "epoch 52; iter: 0; batch classifier loss: 0.371513; batch adversarial loss: 0.561037\n",
      "epoch 53; iter: 0; batch classifier loss: 0.459828; batch adversarial loss: 0.561084\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454301; batch adversarial loss: 0.582540\n",
      "epoch 55; iter: 0; batch classifier loss: 0.469902; batch adversarial loss: 0.667296\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431189; batch adversarial loss: 0.570764\n",
      "epoch 57; iter: 0; batch classifier loss: 0.521436; batch adversarial loss: 0.500513\n",
      "epoch 58; iter: 0; batch classifier loss: 0.519686; batch adversarial loss: 0.615772\n",
      "epoch 59; iter: 0; batch classifier loss: 0.455195; batch adversarial loss: 0.570684\n",
      "epoch 60; iter: 0; batch classifier loss: 0.353811; batch adversarial loss: 0.633398\n",
      "epoch 61; iter: 0; batch classifier loss: 0.465617; batch adversarial loss: 0.589576\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400104; batch adversarial loss: 0.580080\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392580; batch adversarial loss: 0.563333\n",
      "epoch 64; iter: 0; batch classifier loss: 0.447914; batch adversarial loss: 0.562993\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431223; batch adversarial loss: 0.463974\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449344; batch adversarial loss: 0.561904\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444764; batch adversarial loss: 0.508091\n",
      "epoch 68; iter: 0; batch classifier loss: 0.348765; batch adversarial loss: 0.570289\n",
      "epoch 69; iter: 0; batch classifier loss: 0.472730; batch adversarial loss: 0.545281\n",
      "epoch 70; iter: 0; batch classifier loss: 0.321745; batch adversarial loss: 0.545309\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389654; batch adversarial loss: 0.534580\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415567; batch adversarial loss: 0.517829\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442116; batch adversarial loss: 0.598555\n",
      "epoch 74; iter: 0; batch classifier loss: 0.494329; batch adversarial loss: 0.499622\n",
      "epoch 75; iter: 0; batch classifier loss: 0.320908; batch adversarial loss: 0.481624\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382346; batch adversarial loss: 0.599048\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410836; batch adversarial loss: 0.555363\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396485; batch adversarial loss: 0.635358\n",
      "epoch 79; iter: 0; batch classifier loss: 0.363323; batch adversarial loss: 0.554175\n",
      "epoch 80; iter: 0; batch classifier loss: 0.349707; batch adversarial loss: 0.491868\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430691; batch adversarial loss: 0.525125\n",
      "epoch 82; iter: 0; batch classifier loss: 0.470196; batch adversarial loss: 0.454072\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364034; batch adversarial loss: 0.526645\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370199; batch adversarial loss: 0.526612\n",
      "epoch 85; iter: 0; batch classifier loss: 0.331899; batch adversarial loss: 0.617280\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350237; batch adversarial loss: 0.561613\n",
      "epoch 87; iter: 0; batch classifier loss: 0.450144; batch adversarial loss: 0.608252\n",
      "epoch 88; iter: 0; batch classifier loss: 0.488526; batch adversarial loss: 0.563265\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406767; batch adversarial loss: 0.609048\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412474; batch adversarial loss: 0.570989\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384562; batch adversarial loss: 0.543139\n",
      "epoch 92; iter: 0; batch classifier loss: 0.333202; batch adversarial loss: 0.517694\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420986; batch adversarial loss: 0.552890\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415626; batch adversarial loss: 0.562278\n",
      "epoch 95; iter: 0; batch classifier loss: 0.457737; batch adversarial loss: 0.490258\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391557; batch adversarial loss: 0.481341\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440935; batch adversarial loss: 0.580840\n",
      "epoch 98; iter: 0; batch classifier loss: 0.423461; batch adversarial loss: 0.598591\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415994; batch adversarial loss: 0.616724\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399064; batch adversarial loss: 0.507984\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365292; batch adversarial loss: 0.543555\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357216; batch adversarial loss: 0.553020\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354906; batch adversarial loss: 0.535381\n",
      "epoch 104; iter: 0; batch classifier loss: 0.449502; batch adversarial loss: 0.572670\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391827; batch adversarial loss: 0.563230\n",
      "epoch 106; iter: 0; batch classifier loss: 0.445117; batch adversarial loss: 0.526449\n",
      "epoch 107; iter: 0; batch classifier loss: 0.434780; batch adversarial loss: 0.562707\n",
      "epoch 108; iter: 0; batch classifier loss: 0.342438; batch adversarial loss: 0.545189\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376350; batch adversarial loss: 0.553231\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401604; batch adversarial loss: 0.481405\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379313; batch adversarial loss: 0.642871\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405469; batch adversarial loss: 0.616331\n",
      "epoch 113; iter: 0; batch classifier loss: 0.341582; batch adversarial loss: 0.517218\n",
      "epoch 114; iter: 0; batch classifier loss: 0.338785; batch adversarial loss: 0.598759\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363372; batch adversarial loss: 0.525728\n",
      "epoch 116; iter: 0; batch classifier loss: 0.337751; batch adversarial loss: 0.525519\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337382; batch adversarial loss: 0.571129\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412485; batch adversarial loss: 0.561891\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396735; batch adversarial loss: 0.526747\n",
      "epoch 120; iter: 0; batch classifier loss: 0.461292; batch adversarial loss: 0.544978\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362873; batch adversarial loss: 0.462889\n",
      "epoch 122; iter: 0; batch classifier loss: 0.446439; batch adversarial loss: 0.626208\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377864; batch adversarial loss: 0.543915\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404001; batch adversarial loss: 0.589678\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418927; batch adversarial loss: 0.535620\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405721; batch adversarial loss: 0.544443\n",
      "epoch 127; iter: 0; batch classifier loss: 0.406505; batch adversarial loss: 0.535000\n",
      "epoch 128; iter: 0; batch classifier loss: 0.443543; batch adversarial loss: 0.562618\n",
      "epoch 129; iter: 0; batch classifier loss: 0.449997; batch adversarial loss: 0.490097\n",
      "epoch 130; iter: 0; batch classifier loss: 0.460980; batch adversarial loss: 0.517703\n",
      "epoch 131; iter: 0; batch classifier loss: 0.301402; batch adversarial loss: 0.535178\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346440; batch adversarial loss: 0.490465\n",
      "epoch 133; iter: 0; batch classifier loss: 0.418852; batch adversarial loss: 0.527051\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341950; batch adversarial loss: 0.517272\n",
      "epoch 135; iter: 0; batch classifier loss: 0.308532; batch adversarial loss: 0.581096\n",
      "epoch 136; iter: 0; batch classifier loss: 0.380004; batch adversarial loss: 0.589577\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383737; batch adversarial loss: 0.598868\n",
      "epoch 138; iter: 0; batch classifier loss: 0.351457; batch adversarial loss: 0.562835\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415491; batch adversarial loss: 0.563098\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391922; batch adversarial loss: 0.562518\n",
      "epoch 141; iter: 0; batch classifier loss: 0.315921; batch adversarial loss: 0.553501\n",
      "epoch 142; iter: 0; batch classifier loss: 0.452883; batch adversarial loss: 0.526021\n",
      "epoch 143; iter: 0; batch classifier loss: 0.289286; batch adversarial loss: 0.535499\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356618; batch adversarial loss: 0.572768\n",
      "epoch 145; iter: 0; batch classifier loss: 0.475744; batch adversarial loss: 0.544397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.365249; batch adversarial loss: 0.616719\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359193; batch adversarial loss: 0.462777\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389954; batch adversarial loss: 0.508352\n",
      "epoch 149; iter: 0; batch classifier loss: 0.407026; batch adversarial loss: 0.544484\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413831; batch adversarial loss: 0.526530\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368660; batch adversarial loss: 0.480945\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365682; batch adversarial loss: 0.571428\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386899; batch adversarial loss: 0.581287\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389437; batch adversarial loss: 0.553359\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380060; batch adversarial loss: 0.508516\n",
      "epoch 156; iter: 0; batch classifier loss: 0.353478; batch adversarial loss: 0.525890\n",
      "epoch 157; iter: 0; batch classifier loss: 0.388375; batch adversarial loss: 0.599159\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327602; batch adversarial loss: 0.543945\n",
      "epoch 159; iter: 0; batch classifier loss: 0.428838; batch adversarial loss: 0.535562\n",
      "epoch 160; iter: 0; batch classifier loss: 0.440386; batch adversarial loss: 0.625696\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370524; batch adversarial loss: 0.589068\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397171; batch adversarial loss: 0.536308\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311183; batch adversarial loss: 0.580553\n",
      "epoch 164; iter: 0; batch classifier loss: 0.379784; batch adversarial loss: 0.569879\n",
      "epoch 165; iter: 0; batch classifier loss: 0.331919; batch adversarial loss: 0.524820\n",
      "epoch 166; iter: 0; batch classifier loss: 0.412682; batch adversarial loss: 0.551231\n",
      "epoch 167; iter: 0; batch classifier loss: 0.386003; batch adversarial loss: 0.554343\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378277; batch adversarial loss: 0.535552\n",
      "epoch 169; iter: 0; batch classifier loss: 0.406432; batch adversarial loss: 0.489589\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366205; batch adversarial loss: 0.588378\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378270; batch adversarial loss: 0.625631\n",
      "epoch 172; iter: 0; batch classifier loss: 0.307280; batch adversarial loss: 0.643766\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351968; batch adversarial loss: 0.470926\n",
      "epoch 174; iter: 0; batch classifier loss: 0.451465; batch adversarial loss: 0.526476\n",
      "epoch 175; iter: 0; batch classifier loss: 0.457472; batch adversarial loss: 0.563124\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410001; batch adversarial loss: 0.589388\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337736; batch adversarial loss: 0.553716\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357714; batch adversarial loss: 0.509218\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351335; batch adversarial loss: 0.625101\n",
      "epoch 180; iter: 0; batch classifier loss: 0.330547; batch adversarial loss: 0.597701\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360452; batch adversarial loss: 0.543440\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402267; batch adversarial loss: 0.508455\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358368; batch adversarial loss: 0.526364\n",
      "epoch 184; iter: 0; batch classifier loss: 0.464903; batch adversarial loss: 0.561307\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308618; batch adversarial loss: 0.634980\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385405; batch adversarial loss: 0.553270\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350164; batch adversarial loss: 0.561348\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311744; batch adversarial loss: 0.590026\n",
      "epoch 189; iter: 0; batch classifier loss: 0.349707; batch adversarial loss: 0.525201\n",
      "epoch 190; iter: 0; batch classifier loss: 0.362093; batch adversarial loss: 0.572079\n",
      "epoch 191; iter: 0; batch classifier loss: 0.412432; batch adversarial loss: 0.590264\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404299; batch adversarial loss: 0.508829\n",
      "epoch 193; iter: 0; batch classifier loss: 0.397951; batch adversarial loss: 0.545233\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398058; batch adversarial loss: 0.544546\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376428; batch adversarial loss: 0.516846\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387520; batch adversarial loss: 0.570614\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342392; batch adversarial loss: 0.544730\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348444; batch adversarial loss: 0.600789\n",
      "epoch 199; iter: 0; batch classifier loss: 0.347896; batch adversarial loss: 0.526980\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702489; batch adversarial loss: 0.625745\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577271; batch adversarial loss: 0.657227\n",
      "epoch 2; iter: 0; batch classifier loss: 0.569497; batch adversarial loss: 0.641047\n",
      "epoch 3; iter: 0; batch classifier loss: 0.620025; batch adversarial loss: 0.593957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.488995; batch adversarial loss: 0.626494\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589247; batch adversarial loss: 0.592680\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560181; batch adversarial loss: 0.589052\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566154; batch adversarial loss: 0.618246\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547667; batch adversarial loss: 0.535046\n",
      "epoch 9; iter: 0; batch classifier loss: 0.478178; batch adversarial loss: 0.570256\n",
      "epoch 10; iter: 0; batch classifier loss: 0.626418; batch adversarial loss: 0.614555\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534924; batch adversarial loss: 0.544139\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560241; batch adversarial loss: 0.535537\n",
      "epoch 13; iter: 0; batch classifier loss: 0.588975; batch adversarial loss: 0.623216\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518688; batch adversarial loss: 0.598931\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480187; batch adversarial loss: 0.524077\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571259; batch adversarial loss: 0.546935\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488990; batch adversarial loss: 0.614983\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536685; batch adversarial loss: 0.594582\n",
      "epoch 19; iter: 0; batch classifier loss: 0.539385; batch adversarial loss: 0.596884\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522791; batch adversarial loss: 0.434960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478705; batch adversarial loss: 0.553721\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524145; batch adversarial loss: 0.526869\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505732; batch adversarial loss: 0.510576\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478946; batch adversarial loss: 0.538741\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482114; batch adversarial loss: 0.454985\n",
      "epoch 26; iter: 0; batch classifier loss: 0.394069; batch adversarial loss: 0.503102\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461652; batch adversarial loss: 0.500279\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418620; batch adversarial loss: 0.495052\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452484; batch adversarial loss: 0.556259\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496234; batch adversarial loss: 0.597843\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400377; batch adversarial loss: 0.480118\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462719; batch adversarial loss: 0.511497\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467561; batch adversarial loss: 0.628087\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412210; batch adversarial loss: 0.608573\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426417; batch adversarial loss: 0.537113\n",
      "epoch 36; iter: 0; batch classifier loss: 0.519642; batch adversarial loss: 0.588838\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418005; batch adversarial loss: 0.579892\n",
      "epoch 38; iter: 0; batch classifier loss: 0.404360; batch adversarial loss: 0.505918\n",
      "epoch 39; iter: 0; batch classifier loss: 0.488335; batch adversarial loss: 0.533683\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431961; batch adversarial loss: 0.534446\n",
      "epoch 41; iter: 0; batch classifier loss: 0.394828; batch adversarial loss: 0.553504\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443382; batch adversarial loss: 0.535666\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465440; batch adversarial loss: 0.545862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.417149; batch adversarial loss: 0.535694\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400626; batch adversarial loss: 0.450580\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418432; batch adversarial loss: 0.506422\n",
      "epoch 47; iter: 0; batch classifier loss: 0.377093; batch adversarial loss: 0.582482\n",
      "epoch 48; iter: 0; batch classifier loss: 0.603690; batch adversarial loss: 0.622839\n",
      "epoch 49; iter: 0; batch classifier loss: 0.509941; batch adversarial loss: 0.544585\n",
      "epoch 50; iter: 0; batch classifier loss: 0.450186; batch adversarial loss: 0.610546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455562; batch adversarial loss: 0.563967\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434230; batch adversarial loss: 0.467641\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379348; batch adversarial loss: 0.553692\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412976; batch adversarial loss: 0.525864\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433797; batch adversarial loss: 0.515727\n",
      "epoch 56; iter: 0; batch classifier loss: 0.455596; batch adversarial loss: 0.532490\n",
      "epoch 57; iter: 0; batch classifier loss: 0.322537; batch adversarial loss: 0.564993\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464694; batch adversarial loss: 0.458686\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387795; batch adversarial loss: 0.515242\n",
      "epoch 60; iter: 0; batch classifier loss: 0.341315; batch adversarial loss: 0.448258\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420248; batch adversarial loss: 0.544854\n",
      "epoch 62; iter: 0; batch classifier loss: 0.336105; batch adversarial loss: 0.610890\n",
      "epoch 63; iter: 0; batch classifier loss: 0.452965; batch adversarial loss: 0.546287\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423215; batch adversarial loss: 0.515167\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398680; batch adversarial loss: 0.487453\n",
      "epoch 66; iter: 0; batch classifier loss: 0.356899; batch adversarial loss: 0.494677\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444386; batch adversarial loss: 0.544212\n",
      "epoch 68; iter: 0; batch classifier loss: 0.440279; batch adversarial loss: 0.496711\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401595; batch adversarial loss: 0.524666\n",
      "epoch 70; iter: 0; batch classifier loss: 0.303763; batch adversarial loss: 0.544862\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392778; batch adversarial loss: 0.580651\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377540; batch adversarial loss: 0.516657\n",
      "epoch 73; iter: 0; batch classifier loss: 0.500935; batch adversarial loss: 0.487251\n",
      "epoch 74; iter: 0; batch classifier loss: 0.342984; batch adversarial loss: 0.535479\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425733; batch adversarial loss: 0.563190\n",
      "epoch 76; iter: 0; batch classifier loss: 0.443501; batch adversarial loss: 0.515685\n",
      "epoch 77; iter: 0; batch classifier loss: 0.467603; batch adversarial loss: 0.506101\n",
      "epoch 78; iter: 0; batch classifier loss: 0.345105; batch adversarial loss: 0.477941\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433957; batch adversarial loss: 0.576291\n",
      "epoch 80; iter: 0; batch classifier loss: 0.514521; batch adversarial loss: 0.506213\n",
      "epoch 81; iter: 0; batch classifier loss: 0.458518; batch adversarial loss: 0.611551\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383961; batch adversarial loss: 0.458801\n",
      "epoch 83; iter: 0; batch classifier loss: 0.358861; batch adversarial loss: 0.496755\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388276; batch adversarial loss: 0.649758\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405513; batch adversarial loss: 0.592639\n",
      "epoch 86; iter: 0; batch classifier loss: 0.396317; batch adversarial loss: 0.601280\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433817; batch adversarial loss: 0.525621\n",
      "epoch 88; iter: 0; batch classifier loss: 0.486225; batch adversarial loss: 0.554265\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375446; batch adversarial loss: 0.485849\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359506; batch adversarial loss: 0.533784\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413591; batch adversarial loss: 0.553612\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364694; batch adversarial loss: 0.467794\n",
      "epoch 93; iter: 0; batch classifier loss: 0.457679; batch adversarial loss: 0.497241\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372012; batch adversarial loss: 0.544073\n",
      "epoch 95; iter: 0; batch classifier loss: 0.342803; batch adversarial loss: 0.526600\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368103; batch adversarial loss: 0.534723\n",
      "epoch 97; iter: 0; batch classifier loss: 0.278096; batch adversarial loss: 0.544584\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439412; batch adversarial loss: 0.554714\n",
      "epoch 99; iter: 0; batch classifier loss: 0.489939; batch adversarial loss: 0.466868\n",
      "epoch 100; iter: 0; batch classifier loss: 0.335055; batch adversarial loss: 0.583700\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383115; batch adversarial loss: 0.477141\n",
      "epoch 102; iter: 0; batch classifier loss: 0.413691; batch adversarial loss: 0.535082\n",
      "epoch 103; iter: 0; batch classifier loss: 0.479994; batch adversarial loss: 0.487945\n",
      "epoch 104; iter: 0; batch classifier loss: 0.359230; batch adversarial loss: 0.581361\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388690; batch adversarial loss: 0.515818\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441681; batch adversarial loss: 0.535926\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364291; batch adversarial loss: 0.601959\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366536; batch adversarial loss: 0.563787\n",
      "epoch 109; iter: 0; batch classifier loss: 0.354975; batch adversarial loss: 0.582451\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369962; batch adversarial loss: 0.612211\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345405; batch adversarial loss: 0.506730\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405591; batch adversarial loss: 0.601290\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366463; batch adversarial loss: 0.667570\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327551; batch adversarial loss: 0.525785\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342079; batch adversarial loss: 0.459848\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377626; batch adversarial loss: 0.572342\n",
      "epoch 117; iter: 0; batch classifier loss: 0.355793; batch adversarial loss: 0.497034\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361061; batch adversarial loss: 0.496732\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395611; batch adversarial loss: 0.544717\n",
      "epoch 120; iter: 0; batch classifier loss: 0.437695; batch adversarial loss: 0.506679\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385722; batch adversarial loss: 0.583744\n",
      "epoch 122; iter: 0; batch classifier loss: 0.334614; batch adversarial loss: 0.610453\n",
      "epoch 123; iter: 0; batch classifier loss: 0.503577; batch adversarial loss: 0.498039\n",
      "epoch 124; iter: 0; batch classifier loss: 0.417995; batch adversarial loss: 0.496909\n",
      "epoch 125; iter: 0; batch classifier loss: 0.420466; batch adversarial loss: 0.525338\n",
      "epoch 126; iter: 0; batch classifier loss: 0.422257; batch adversarial loss: 0.516339\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353932; batch adversarial loss: 0.506611\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351447; batch adversarial loss: 0.545759\n",
      "epoch 129; iter: 0; batch classifier loss: 0.460497; batch adversarial loss: 0.504891\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385955; batch adversarial loss: 0.553746\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355854; batch adversarial loss: 0.507774\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325055; batch adversarial loss: 0.535003\n",
      "epoch 133; iter: 0; batch classifier loss: 0.333971; batch adversarial loss: 0.546613\n",
      "epoch 134; iter: 0; batch classifier loss: 0.320319; batch adversarial loss: 0.477903\n",
      "epoch 135; iter: 0; batch classifier loss: 0.332910; batch adversarial loss: 0.592657\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381729; batch adversarial loss: 0.545215\n",
      "epoch 137; iter: 0; batch classifier loss: 0.395372; batch adversarial loss: 0.554437\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392503; batch adversarial loss: 0.563644\n",
      "epoch 139; iter: 0; batch classifier loss: 0.439736; batch adversarial loss: 0.507399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.406261; batch adversarial loss: 0.555087\n",
      "epoch 141; iter: 0; batch classifier loss: 0.301141; batch adversarial loss: 0.458628\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370150; batch adversarial loss: 0.554186\n",
      "epoch 143; iter: 0; batch classifier loss: 0.372129; batch adversarial loss: 0.477954\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395709; batch adversarial loss: 0.553703\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365075; batch adversarial loss: 0.524653\n",
      "epoch 146; iter: 0; batch classifier loss: 0.445080; batch adversarial loss: 0.525738\n",
      "epoch 147; iter: 0; batch classifier loss: 0.302836; batch adversarial loss: 0.552959\n",
      "epoch 148; iter: 0; batch classifier loss: 0.434508; batch adversarial loss: 0.649293\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367395; batch adversarial loss: 0.477368\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352358; batch adversarial loss: 0.553627\n",
      "epoch 151; iter: 0; batch classifier loss: 0.404409; batch adversarial loss: 0.544318\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374756; batch adversarial loss: 0.401391\n",
      "epoch 153; iter: 0; batch classifier loss: 0.422218; batch adversarial loss: 0.544630\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363514; batch adversarial loss: 0.524421\n",
      "epoch 155; iter: 0; batch classifier loss: 0.282003; batch adversarial loss: 0.458392\n",
      "epoch 156; iter: 0; batch classifier loss: 0.414856; batch adversarial loss: 0.429577\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359507; batch adversarial loss: 0.506803\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403860; batch adversarial loss: 0.515717\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354100; batch adversarial loss: 0.591764\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342782; batch adversarial loss: 0.506640\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350600; batch adversarial loss: 0.506253\n",
      "epoch 162; iter: 0; batch classifier loss: 0.418374; batch adversarial loss: 0.535191\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340612; batch adversarial loss: 0.573468\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339791; batch adversarial loss: 0.525271\n",
      "epoch 165; iter: 0; batch classifier loss: 0.322754; batch adversarial loss: 0.507252\n",
      "epoch 166; iter: 0; batch classifier loss: 0.348640; batch adversarial loss: 0.516829\n",
      "epoch 167; iter: 0; batch classifier loss: 0.434220; batch adversarial loss: 0.497482\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397732; batch adversarial loss: 0.555342\n",
      "epoch 169; iter: 0; batch classifier loss: 0.336843; batch adversarial loss: 0.562362\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330424; batch adversarial loss: 0.506301\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385851; batch adversarial loss: 0.496687\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395007; batch adversarial loss: 0.582864\n",
      "epoch 173; iter: 0; batch classifier loss: 0.323358; batch adversarial loss: 0.668131\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353249; batch adversarial loss: 0.582935\n",
      "epoch 175; iter: 0; batch classifier loss: 0.411059; batch adversarial loss: 0.573844\n",
      "epoch 176; iter: 0; batch classifier loss: 0.392933; batch adversarial loss: 0.496967\n",
      "epoch 177; iter: 0; batch classifier loss: 0.317056; batch adversarial loss: 0.574054\n",
      "epoch 178; iter: 0; batch classifier loss: 0.395756; batch adversarial loss: 0.468567\n",
      "epoch 179; iter: 0; batch classifier loss: 0.426728; batch adversarial loss: 0.477584\n",
      "epoch 180; iter: 0; batch classifier loss: 0.408692; batch adversarial loss: 0.563320\n",
      "epoch 181; iter: 0; batch classifier loss: 0.433143; batch adversarial loss: 0.573585\n",
      "epoch 182; iter: 0; batch classifier loss: 0.325421; batch adversarial loss: 0.563923\n",
      "epoch 183; iter: 0; batch classifier loss: 0.339312; batch adversarial loss: 0.582787\n",
      "epoch 184; iter: 0; batch classifier loss: 0.406555; batch adversarial loss: 0.515068\n",
      "epoch 185; iter: 0; batch classifier loss: 0.425090; batch adversarial loss: 0.525548\n",
      "epoch 186; iter: 0; batch classifier loss: 0.336704; batch adversarial loss: 0.562619\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360495; batch adversarial loss: 0.487209\n",
      "epoch 188; iter: 0; batch classifier loss: 0.308637; batch adversarial loss: 0.544993\n",
      "epoch 189; iter: 0; batch classifier loss: 0.440745; batch adversarial loss: 0.506539\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364675; batch adversarial loss: 0.525137\n",
      "epoch 191; iter: 0; batch classifier loss: 0.420019; batch adversarial loss: 0.515844\n",
      "epoch 192; iter: 0; batch classifier loss: 0.324034; batch adversarial loss: 0.574041\n",
      "epoch 193; iter: 0; batch classifier loss: 0.371715; batch adversarial loss: 0.477097\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358809; batch adversarial loss: 0.478725\n",
      "epoch 195; iter: 0; batch classifier loss: 0.371848; batch adversarial loss: 0.525053\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345504; batch adversarial loss: 0.591745\n",
      "epoch 197; iter: 0; batch classifier loss: 0.330434; batch adversarial loss: 0.506297\n",
      "epoch 198; iter: 0; batch classifier loss: 0.402121; batch adversarial loss: 0.515552\n",
      "epoch 199; iter: 0; batch classifier loss: 0.403670; batch adversarial loss: 0.582422\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673602; batch adversarial loss: 0.719244\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577257; batch adversarial loss: 0.678742\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542543; batch adversarial loss: 0.650351\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659800; batch adversarial loss: 0.663364\n",
      "epoch 4; iter: 0; batch classifier loss: 0.660684; batch adversarial loss: 0.593136\n",
      "epoch 5; iter: 0; batch classifier loss: 0.518327; batch adversarial loss: 0.622901\n",
      "epoch 6; iter: 0; batch classifier loss: 0.526182; batch adversarial loss: 0.636536\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561589; batch adversarial loss: 0.572876\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476763; batch adversarial loss: 0.606443\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507553; batch adversarial loss: 0.581358\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556216; batch adversarial loss: 0.538245\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480274; batch adversarial loss: 0.629791\n",
      "epoch 12; iter: 0; batch classifier loss: 0.568770; batch adversarial loss: 0.590496\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471334; batch adversarial loss: 0.569526\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509904; batch adversarial loss: 0.640478\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496103; batch adversarial loss: 0.505739\n",
      "epoch 16; iter: 0; batch classifier loss: 0.434605; batch adversarial loss: 0.531178\n",
      "epoch 17; iter: 0; batch classifier loss: 0.456043; batch adversarial loss: 0.620326\n",
      "epoch 18; iter: 0; batch classifier loss: 0.538257; batch adversarial loss: 0.541862\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519677; batch adversarial loss: 0.557697\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457825; batch adversarial loss: 0.596729\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481810; batch adversarial loss: 0.573888\n",
      "epoch 22; iter: 0; batch classifier loss: 0.535382; batch adversarial loss: 0.576271\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528777; batch adversarial loss: 0.566884\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460390; batch adversarial loss: 0.506438\n",
      "epoch 25; iter: 0; batch classifier loss: 0.415446; batch adversarial loss: 0.589620\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484865; batch adversarial loss: 0.541454\n",
      "epoch 27; iter: 0; batch classifier loss: 0.503511; batch adversarial loss: 0.497262\n",
      "epoch 28; iter: 0; batch classifier loss: 0.557927; batch adversarial loss: 0.492018\n",
      "epoch 29; iter: 0; batch classifier loss: 0.442664; batch adversarial loss: 0.563817\n",
      "epoch 30; iter: 0; batch classifier loss: 0.505603; batch adversarial loss: 0.520763\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455596; batch adversarial loss: 0.557615\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517358; batch adversarial loss: 0.583425\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388848; batch adversarial loss: 0.652226\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452538; batch adversarial loss: 0.549262\n",
      "epoch 35; iter: 0; batch classifier loss: 0.462594; batch adversarial loss: 0.534474\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469683; batch adversarial loss: 0.526252\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495739; batch adversarial loss: 0.615640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.525604; batch adversarial loss: 0.587038\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489468; batch adversarial loss: 0.535123\n",
      "epoch 40; iter: 0; batch classifier loss: 0.485027; batch adversarial loss: 0.527485\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421926; batch adversarial loss: 0.572024\n",
      "epoch 42; iter: 0; batch classifier loss: 0.486928; batch adversarial loss: 0.580249\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493817; batch adversarial loss: 0.551879\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436466; batch adversarial loss: 0.537080\n",
      "epoch 45; iter: 0; batch classifier loss: 0.490887; batch adversarial loss: 0.671005\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457755; batch adversarial loss: 0.618803\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462501; batch adversarial loss: 0.552687\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409800; batch adversarial loss: 0.610349\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398892; batch adversarial loss: 0.518488\n",
      "epoch 50; iter: 0; batch classifier loss: 0.476687; batch adversarial loss: 0.564428\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453644; batch adversarial loss: 0.535933\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387957; batch adversarial loss: 0.589372\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437764; batch adversarial loss: 0.570400\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447295; batch adversarial loss: 0.527915\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454278; batch adversarial loss: 0.682041\n",
      "epoch 56; iter: 0; batch classifier loss: 0.513256; batch adversarial loss: 0.553816\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389007; batch adversarial loss: 0.544314\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424402; batch adversarial loss: 0.517384\n",
      "epoch 59; iter: 0; batch classifier loss: 0.397041; batch adversarial loss: 0.554003\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432088; batch adversarial loss: 0.506272\n",
      "epoch 61; iter: 0; batch classifier loss: 0.374626; batch adversarial loss: 0.562824\n",
      "epoch 62; iter: 0; batch classifier loss: 0.369598; batch adversarial loss: 0.470888\n",
      "epoch 63; iter: 0; batch classifier loss: 0.365961; batch adversarial loss: 0.535084\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425954; batch adversarial loss: 0.498103\n",
      "epoch 65; iter: 0; batch classifier loss: 0.531704; batch adversarial loss: 0.590302\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427950; batch adversarial loss: 0.561858\n",
      "epoch 67; iter: 0; batch classifier loss: 0.449351; batch adversarial loss: 0.508149\n",
      "epoch 68; iter: 0; batch classifier loss: 0.538559; batch adversarial loss: 0.572769\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409940; batch adversarial loss: 0.544331\n",
      "epoch 70; iter: 0; batch classifier loss: 0.488335; batch adversarial loss: 0.526600\n",
      "epoch 71; iter: 0; batch classifier loss: 0.459094; batch adversarial loss: 0.527190\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455910; batch adversarial loss: 0.508161\n",
      "epoch 73; iter: 0; batch classifier loss: 0.492993; batch adversarial loss: 0.471052\n",
      "epoch 74; iter: 0; batch classifier loss: 0.458093; batch adversarial loss: 0.582217\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433880; batch adversarial loss: 0.534631\n",
      "epoch 76; iter: 0; batch classifier loss: 0.436285; batch adversarial loss: 0.581693\n",
      "epoch 77; iter: 0; batch classifier loss: 0.472208; batch adversarial loss: 0.525780\n",
      "epoch 78; iter: 0; batch classifier loss: 0.458907; batch adversarial loss: 0.608407\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403416; batch adversarial loss: 0.535030\n",
      "epoch 80; iter: 0; batch classifier loss: 0.443494; batch adversarial loss: 0.489377\n",
      "epoch 81; iter: 0; batch classifier loss: 0.411090; batch adversarial loss: 0.590814\n",
      "epoch 82; iter: 0; batch classifier loss: 0.427764; batch adversarial loss: 0.507834\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413379; batch adversarial loss: 0.507806\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370940; batch adversarial loss: 0.617830\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408381; batch adversarial loss: 0.489954\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409248; batch adversarial loss: 0.618022\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455674; batch adversarial loss: 0.599665\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427095; batch adversarial loss: 0.535614\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395931; batch adversarial loss: 0.498716\n",
      "epoch 90; iter: 0; batch classifier loss: 0.431804; batch adversarial loss: 0.461662\n",
      "epoch 91; iter: 0; batch classifier loss: 0.415328; batch adversarial loss: 0.544205\n",
      "epoch 92; iter: 0; batch classifier loss: 0.361870; batch adversarial loss: 0.526052\n",
      "epoch 93; iter: 0; batch classifier loss: 0.351798; batch adversarial loss: 0.599932\n",
      "epoch 94; iter: 0; batch classifier loss: 0.423856; batch adversarial loss: 0.507145\n",
      "epoch 95; iter: 0; batch classifier loss: 0.457022; batch adversarial loss: 0.618109\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388211; batch adversarial loss: 0.544044\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362848; batch adversarial loss: 0.489551\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361596; batch adversarial loss: 0.534640\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350141; batch adversarial loss: 0.553890\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401894; batch adversarial loss: 0.544712\n",
      "epoch 101; iter: 0; batch classifier loss: 0.469043; batch adversarial loss: 0.544418\n",
      "epoch 102; iter: 0; batch classifier loss: 0.454333; batch adversarial loss: 0.489429\n",
      "epoch 103; iter: 0; batch classifier loss: 0.461982; batch adversarial loss: 0.572012\n",
      "epoch 104; iter: 0; batch classifier loss: 0.410940; batch adversarial loss: 0.645891\n",
      "epoch 105; iter: 0; batch classifier loss: 0.465681; batch adversarial loss: 0.571566\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369530; batch adversarial loss: 0.553652\n",
      "epoch 107; iter: 0; batch classifier loss: 0.441007; batch adversarial loss: 0.498497\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380015; batch adversarial loss: 0.517188\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351216; batch adversarial loss: 0.525647\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386870; batch adversarial loss: 0.571827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.312969; batch adversarial loss: 0.480452\n",
      "epoch 112; iter: 0; batch classifier loss: 0.468026; batch adversarial loss: 0.516831\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395890; batch adversarial loss: 0.580959\n",
      "epoch 114; iter: 0; batch classifier loss: 0.510262; batch adversarial loss: 0.498394\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342359; batch adversarial loss: 0.609222\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413139; batch adversarial loss: 0.525959\n",
      "epoch 117; iter: 0; batch classifier loss: 0.403878; batch adversarial loss: 0.526566\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383206; batch adversarial loss: 0.563090\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377128; batch adversarial loss: 0.609491\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415482; batch adversarial loss: 0.554157\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.526580\n",
      "epoch 122; iter: 0; batch classifier loss: 0.344231; batch adversarial loss: 0.526759\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394558; batch adversarial loss: 0.581256\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385432; batch adversarial loss: 0.572057\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368120; batch adversarial loss: 0.599069\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363376; batch adversarial loss: 0.599401\n",
      "epoch 127; iter: 0; batch classifier loss: 0.463924; batch adversarial loss: 0.507945\n",
      "epoch 128; iter: 0; batch classifier loss: 0.436125; batch adversarial loss: 0.488940\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369817; batch adversarial loss: 0.526151\n",
      "epoch 130; iter: 0; batch classifier loss: 0.453087; batch adversarial loss: 0.590733\n",
      "epoch 131; iter: 0; batch classifier loss: 0.390271; batch adversarial loss: 0.516959\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390118; batch adversarial loss: 0.553755\n",
      "epoch 133; iter: 0; batch classifier loss: 0.432279; batch adversarial loss: 0.526196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.490500; batch adversarial loss: 0.572291\n",
      "epoch 135; iter: 0; batch classifier loss: 0.412554; batch adversarial loss: 0.544365\n",
      "epoch 136; iter: 0; batch classifier loss: 0.449582; batch adversarial loss: 0.664489\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348825; batch adversarial loss: 0.581303\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362049; batch adversarial loss: 0.470650\n",
      "epoch 139; iter: 0; batch classifier loss: 0.407545; batch adversarial loss: 0.471342\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396717; batch adversarial loss: 0.517137\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380424; batch adversarial loss: 0.563157\n",
      "epoch 142; iter: 0; batch classifier loss: 0.552712; batch adversarial loss: 0.636437\n",
      "epoch 143; iter: 0; batch classifier loss: 0.400539; batch adversarial loss: 0.516802\n",
      "epoch 144; iter: 0; batch classifier loss: 0.428350; batch adversarial loss: 0.599498\n",
      "epoch 145; iter: 0; batch classifier loss: 0.443365; batch adversarial loss: 0.480273\n",
      "epoch 146; iter: 0; batch classifier loss: 0.451705; batch adversarial loss: 0.526200\n",
      "epoch 147; iter: 0; batch classifier loss: 0.417416; batch adversarial loss: 0.581174\n",
      "epoch 148; iter: 0; batch classifier loss: 0.408139; batch adversarial loss: 0.554353\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355624; batch adversarial loss: 0.590079\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326701; batch adversarial loss: 0.553545\n",
      "epoch 151; iter: 0; batch classifier loss: 0.414702; batch adversarial loss: 0.571693\n",
      "epoch 152; iter: 0; batch classifier loss: 0.359467; batch adversarial loss: 0.654465\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316692; batch adversarial loss: 0.562474\n",
      "epoch 154; iter: 0; batch classifier loss: 0.485404; batch adversarial loss: 0.563533\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349393; batch adversarial loss: 0.581578\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376198; batch adversarial loss: 0.581130\n",
      "epoch 157; iter: 0; batch classifier loss: 0.469632; batch adversarial loss: 0.580925\n",
      "epoch 158; iter: 0; batch classifier loss: 0.287171; batch adversarial loss: 0.600114\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345937; batch adversarial loss: 0.572170\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365924; batch adversarial loss: 0.617784\n",
      "epoch 161; iter: 0; batch classifier loss: 0.377801; batch adversarial loss: 0.590775\n",
      "epoch 162; iter: 0; batch classifier loss: 0.424628; batch adversarial loss: 0.517039\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350321; batch adversarial loss: 0.562634\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397748; batch adversarial loss: 0.562803\n",
      "epoch 165; iter: 0; batch classifier loss: 0.464375; batch adversarial loss: 0.562631\n",
      "epoch 166; iter: 0; batch classifier loss: 0.405326; batch adversarial loss: 0.618765\n",
      "epoch 167; iter: 0; batch classifier loss: 0.357737; batch adversarial loss: 0.535043\n",
      "epoch 168; iter: 0; batch classifier loss: 0.336363; batch adversarial loss: 0.498160\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375459; batch adversarial loss: 0.580730\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333552; batch adversarial loss: 0.544711\n",
      "epoch 171; iter: 0; batch classifier loss: 0.399588; batch adversarial loss: 0.544085\n",
      "epoch 172; iter: 0; batch classifier loss: 0.448044; batch adversarial loss: 0.572307\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430752; batch adversarial loss: 0.591204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.436904; batch adversarial loss: 0.516932\n",
      "epoch 175; iter: 0; batch classifier loss: 0.415676; batch adversarial loss: 0.589893\n",
      "epoch 176; iter: 0; batch classifier loss: 0.385908; batch adversarial loss: 0.637051\n",
      "epoch 177; iter: 0; batch classifier loss: 0.441711; batch adversarial loss: 0.544731\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336494; batch adversarial loss: 0.508303\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379706; batch adversarial loss: 0.608400\n",
      "epoch 180; iter: 0; batch classifier loss: 0.386800; batch adversarial loss: 0.572719\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332672; batch adversarial loss: 0.525837\n",
      "epoch 182; iter: 0; batch classifier loss: 0.439879; batch adversarial loss: 0.517617\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324425; batch adversarial loss: 0.544308\n",
      "epoch 184; iter: 0; batch classifier loss: 0.387901; batch adversarial loss: 0.553718\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369132; batch adversarial loss: 0.636557\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385202; batch adversarial loss: 0.572099\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376407; batch adversarial loss: 0.535413\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313695; batch adversarial loss: 0.535397\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352933; batch adversarial loss: 0.581118\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351658; batch adversarial loss: 0.489799\n",
      "epoch 191; iter: 0; batch classifier loss: 0.393283; batch adversarial loss: 0.581439\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381768; batch adversarial loss: 0.599846\n",
      "epoch 193; iter: 0; batch classifier loss: 0.352939; batch adversarial loss: 0.655190\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344387; batch adversarial loss: 0.498497\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353579; batch adversarial loss: 0.544150\n",
      "epoch 196; iter: 0; batch classifier loss: 0.461989; batch adversarial loss: 0.710018\n",
      "epoch 197; iter: 0; batch classifier loss: 0.410915; batch adversarial loss: 0.581056\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329503; batch adversarial loss: 0.637236\n",
      "epoch 199; iter: 0; batch classifier loss: 0.416573; batch adversarial loss: 0.516730\n",
      "epoch 0; iter: 0; batch classifier loss: 0.737966; batch adversarial loss: 0.784020\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642124; batch adversarial loss: 0.743514\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577279; batch adversarial loss: 0.705749\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580662; batch adversarial loss: 0.683686\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558821; batch adversarial loss: 0.696387\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580542; batch adversarial loss: 0.652236\n",
      "epoch 6; iter: 0; batch classifier loss: 0.499606; batch adversarial loss: 0.652061\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545378; batch adversarial loss: 0.615613\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564088; batch adversarial loss: 0.601627\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551277; batch adversarial loss: 0.600240\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562949; batch adversarial loss: 0.616795\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566373; batch adversarial loss: 0.565036\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558153; batch adversarial loss: 0.563302\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542276; batch adversarial loss: 0.567481\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512300; batch adversarial loss: 0.550626\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499090; batch adversarial loss: 0.566467\n",
      "epoch 16; iter: 0; batch classifier loss: 0.644184; batch adversarial loss: 0.546497\n",
      "epoch 17; iter: 0; batch classifier loss: 0.563901; batch adversarial loss: 0.518950\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469311; batch adversarial loss: 0.604285\n",
      "epoch 19; iter: 0; batch classifier loss: 0.557715; batch adversarial loss: 0.597756\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524408; batch adversarial loss: 0.548374\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485047; batch adversarial loss: 0.472701\n",
      "epoch 22; iter: 0; batch classifier loss: 0.538651; batch adversarial loss: 0.565210\n",
      "epoch 23; iter: 0; batch classifier loss: 0.530670; batch adversarial loss: 0.463475\n",
      "epoch 24; iter: 0; batch classifier loss: 0.431845; batch adversarial loss: 0.618415\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476793; batch adversarial loss: 0.586298\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497922; batch adversarial loss: 0.540050\n",
      "epoch 27; iter: 0; batch classifier loss: 0.421320; batch adversarial loss: 0.600068\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480099; batch adversarial loss: 0.578411\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452318; batch adversarial loss: 0.534665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.534979; batch adversarial loss: 0.557506\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435270; batch adversarial loss: 0.514797\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471018; batch adversarial loss: 0.524783\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444994; batch adversarial loss: 0.580999\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390642; batch adversarial loss: 0.572560\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420383; batch adversarial loss: 0.605477\n",
      "epoch 36; iter: 0; batch classifier loss: 0.409368; batch adversarial loss: 0.570210\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447024; batch adversarial loss: 0.528880\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444908; batch adversarial loss: 0.492058\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458011; batch adversarial loss: 0.536069\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411478; batch adversarial loss: 0.509428\n",
      "epoch 41; iter: 0; batch classifier loss: 0.363297; batch adversarial loss: 0.518077\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398544; batch adversarial loss: 0.517731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440698; batch adversarial loss: 0.580653\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493604; batch adversarial loss: 0.562839\n",
      "epoch 45; iter: 0; batch classifier loss: 0.389983; batch adversarial loss: 0.589773\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403252; batch adversarial loss: 0.581117\n",
      "epoch 47; iter: 0; batch classifier loss: 0.397165; batch adversarial loss: 0.480426\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484195; batch adversarial loss: 0.516190\n",
      "epoch 49; iter: 0; batch classifier loss: 0.499863; batch adversarial loss: 0.545114\n",
      "epoch 50; iter: 0; batch classifier loss: 0.464293; batch adversarial loss: 0.590773\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463069; batch adversarial loss: 0.498986\n",
      "epoch 52; iter: 0; batch classifier loss: 0.524353; batch adversarial loss: 0.599918\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452016; batch adversarial loss: 0.656347\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455770; batch adversarial loss: 0.517621\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403340; batch adversarial loss: 0.563210\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435818; batch adversarial loss: 0.553809\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397287; batch adversarial loss: 0.535582\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440636; batch adversarial loss: 0.461824\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416760; batch adversarial loss: 0.516771\n",
      "epoch 60; iter: 0; batch classifier loss: 0.476855; batch adversarial loss: 0.516547\n",
      "epoch 61; iter: 0; batch classifier loss: 0.361340; batch adversarial loss: 0.607675\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394758; batch adversarial loss: 0.544290\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374826; batch adversarial loss: 0.571764\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393465; batch adversarial loss: 0.533710\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398612; batch adversarial loss: 0.599287\n",
      "epoch 66; iter: 0; batch classifier loss: 0.440385; batch adversarial loss: 0.471294\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421758; batch adversarial loss: 0.525199\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391653; batch adversarial loss: 0.550429\n",
      "epoch 69; iter: 0; batch classifier loss: 0.454898; batch adversarial loss: 0.564760\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424703; batch adversarial loss: 0.609405\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396971; batch adversarial loss: 0.567692\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413629; batch adversarial loss: 0.580708\n",
      "epoch 73; iter: 0; batch classifier loss: 0.416467; batch adversarial loss: 0.535524\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387104; batch adversarial loss: 0.553053\n",
      "epoch 75; iter: 0; batch classifier loss: 0.376924; batch adversarial loss: 0.515393\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402984; batch adversarial loss: 0.469033\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386893; batch adversarial loss: 0.580395\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380131; batch adversarial loss: 0.544485\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359948; batch adversarial loss: 0.646870\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421172; batch adversarial loss: 0.547146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405914; batch adversarial loss: 0.535868\n",
      "epoch 82; iter: 0; batch classifier loss: 0.338494; batch adversarial loss: 0.564706\n",
      "epoch 83; iter: 0; batch classifier loss: 0.408295; batch adversarial loss: 0.563067\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370836; batch adversarial loss: 0.564369\n",
      "epoch 85; iter: 0; batch classifier loss: 0.335495; batch adversarial loss: 0.497858\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383359; batch adversarial loss: 0.516993\n",
      "epoch 87; iter: 0; batch classifier loss: 0.414914; batch adversarial loss: 0.535998\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384542; batch adversarial loss: 0.592521\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367758; batch adversarial loss: 0.563830\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409545; batch adversarial loss: 0.553921\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432596; batch adversarial loss: 0.562698\n",
      "epoch 92; iter: 0; batch classifier loss: 0.294518; batch adversarial loss: 0.572960\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361102; batch adversarial loss: 0.543919\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433932; batch adversarial loss: 0.570870\n",
      "epoch 95; iter: 0; batch classifier loss: 0.328685; batch adversarial loss: 0.544117\n",
      "epoch 96; iter: 0; batch classifier loss: 0.407326; batch adversarial loss: 0.581706\n",
      "epoch 97; iter: 0; batch classifier loss: 0.464065; batch adversarial loss: 0.609135\n",
      "epoch 98; iter: 0; batch classifier loss: 0.446159; batch adversarial loss: 0.542789\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396864; batch adversarial loss: 0.560392\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408384; batch adversarial loss: 0.593945\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395852; batch adversarial loss: 0.543650\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401820; batch adversarial loss: 0.552076\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384883; batch adversarial loss: 0.516173\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389415; batch adversarial loss: 0.517582\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380642; batch adversarial loss: 0.545991\n",
      "epoch 106; iter: 0; batch classifier loss: 0.451089; batch adversarial loss: 0.555392\n",
      "epoch 107; iter: 0; batch classifier loss: 0.320460; batch adversarial loss: 0.525747\n",
      "epoch 108; iter: 0; batch classifier loss: 0.365457; batch adversarial loss: 0.518449\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400677; batch adversarial loss: 0.479486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373241; batch adversarial loss: 0.516880\n",
      "epoch 111; iter: 0; batch classifier loss: 0.339534; batch adversarial loss: 0.619467\n",
      "epoch 112; iter: 0; batch classifier loss: 0.442243; batch adversarial loss: 0.507577\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363385; batch adversarial loss: 0.552521\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365072; batch adversarial loss: 0.545110\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366147; batch adversarial loss: 0.654402\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372412; batch adversarial loss: 0.542963\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402484; batch adversarial loss: 0.535345\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363818; batch adversarial loss: 0.471795\n",
      "epoch 119; iter: 0; batch classifier loss: 0.455047; batch adversarial loss: 0.542844\n",
      "epoch 120; iter: 0; batch classifier loss: 0.333340; batch adversarial loss: 0.474217\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378901; batch adversarial loss: 0.517786\n",
      "epoch 122; iter: 0; batch classifier loss: 0.471584; batch adversarial loss: 0.638802\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414818; batch adversarial loss: 0.508402\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358981; batch adversarial loss: 0.517423\n",
      "epoch 125; iter: 0; batch classifier loss: 0.378791; batch adversarial loss: 0.582258\n",
      "epoch 126; iter: 0; batch classifier loss: 0.423519; batch adversarial loss: 0.517204\n",
      "epoch 127; iter: 0; batch classifier loss: 0.426866; batch adversarial loss: 0.591867\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362698; batch adversarial loss: 0.507949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.351641; batch adversarial loss: 0.545156\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361129; batch adversarial loss: 0.545164\n",
      "epoch 131; iter: 0; batch classifier loss: 0.377516; batch adversarial loss: 0.497725\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406835; batch adversarial loss: 0.608194\n",
      "epoch 133; iter: 0; batch classifier loss: 0.425567; batch adversarial loss: 0.515860\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352156; batch adversarial loss: 0.554047\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424616; batch adversarial loss: 0.498197\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322312; batch adversarial loss: 0.591638\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401811; batch adversarial loss: 0.544956\n",
      "epoch 138; iter: 0; batch classifier loss: 0.385300; batch adversarial loss: 0.563485\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371068; batch adversarial loss: 0.581672\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367627; batch adversarial loss: 0.600261\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364461; batch adversarial loss: 0.535211\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405094; batch adversarial loss: 0.571874\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401355; batch adversarial loss: 0.554090\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376176; batch adversarial loss: 0.590822\n",
      "epoch 145; iter: 0; batch classifier loss: 0.497905; batch adversarial loss: 0.572566\n",
      "epoch 146; iter: 0; batch classifier loss: 0.305963; batch adversarial loss: 0.543257\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307134; batch adversarial loss: 0.553322\n",
      "epoch 148; iter: 0; batch classifier loss: 0.394613; batch adversarial loss: 0.552207\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353689; batch adversarial loss: 0.472904\n",
      "epoch 150; iter: 0; batch classifier loss: 0.412092; batch adversarial loss: 0.491530\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348345; batch adversarial loss: 0.608651\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370943; batch adversarial loss: 0.542659\n",
      "epoch 153; iter: 0; batch classifier loss: 0.390880; batch adversarial loss: 0.517254\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357031; batch adversarial loss: 0.580765\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362399; batch adversarial loss: 0.572112\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321049; batch adversarial loss: 0.515752\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328668; batch adversarial loss: 0.507985\n",
      "epoch 158; iter: 0; batch classifier loss: 0.340142; batch adversarial loss: 0.516721\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359958; batch adversarial loss: 0.470379\n",
      "epoch 160; iter: 0; batch classifier loss: 0.359552; batch adversarial loss: 0.601594\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351385; batch adversarial loss: 0.543200\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371961; batch adversarial loss: 0.544759\n",
      "epoch 163; iter: 0; batch classifier loss: 0.306082; batch adversarial loss: 0.534531\n",
      "epoch 164; iter: 0; batch classifier loss: 0.381157; batch adversarial loss: 0.522830\n",
      "epoch 165; iter: 0; batch classifier loss: 0.395761; batch adversarial loss: 0.544813\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369635; batch adversarial loss: 0.498056\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335756; batch adversarial loss: 0.536308\n",
      "epoch 168; iter: 0; batch classifier loss: 0.402090; batch adversarial loss: 0.553770\n",
      "epoch 169; iter: 0; batch classifier loss: 0.320886; batch adversarial loss: 0.497120\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386018; batch adversarial loss: 0.562867\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357743; batch adversarial loss: 0.591693\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387742; batch adversarial loss: 0.618274\n",
      "epoch 173; iter: 0; batch classifier loss: 0.320757; batch adversarial loss: 0.591078\n",
      "epoch 174; iter: 0; batch classifier loss: 0.405026; batch adversarial loss: 0.591528\n",
      "epoch 175; iter: 0; batch classifier loss: 0.377399; batch adversarial loss: 0.497588\n",
      "epoch 176; iter: 0; batch classifier loss: 0.456810; batch adversarial loss: 0.479797\n",
      "epoch 177; iter: 0; batch classifier loss: 0.401610; batch adversarial loss: 0.600548\n",
      "epoch 178; iter: 0; batch classifier loss: 0.308702; batch adversarial loss: 0.562873\n",
      "epoch 179; iter: 0; batch classifier loss: 0.371545; batch adversarial loss: 0.544082\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379040; batch adversarial loss: 0.525495\n",
      "epoch 181; iter: 0; batch classifier loss: 0.415664; batch adversarial loss: 0.507574\n",
      "epoch 182; iter: 0; batch classifier loss: 0.304391; batch adversarial loss: 0.497876\n",
      "epoch 183; iter: 0; batch classifier loss: 0.374458; batch adversarial loss: 0.509156\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346422; batch adversarial loss: 0.508699\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355017; batch adversarial loss: 0.518454\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347579; batch adversarial loss: 0.553846\n",
      "epoch 187; iter: 0; batch classifier loss: 0.469641; batch adversarial loss: 0.546919\n",
      "epoch 188; iter: 0; batch classifier loss: 0.402273; batch adversarial loss: 0.527989\n",
      "epoch 189; iter: 0; batch classifier loss: 0.331207; batch adversarial loss: 0.582254\n",
      "epoch 190; iter: 0; batch classifier loss: 0.284694; batch adversarial loss: 0.582247\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355862; batch adversarial loss: 0.627066\n",
      "epoch 192; iter: 0; batch classifier loss: 0.419365; batch adversarial loss: 0.516460\n",
      "epoch 193; iter: 0; batch classifier loss: 0.392516; batch adversarial loss: 0.599976\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395225; batch adversarial loss: 0.563525\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392126; batch adversarial loss: 0.582344\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301597; batch adversarial loss: 0.543225\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354540; batch adversarial loss: 0.517833\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350768; batch adversarial loss: 0.525927\n",
      "epoch 199; iter: 0; batch classifier loss: 0.312177; batch adversarial loss: 0.496022\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667853; batch adversarial loss: 0.904788\n",
      "epoch 1; iter: 0; batch classifier loss: 0.835971; batch adversarial loss: 1.175621\n",
      "epoch 2; iter: 0; batch classifier loss: 0.927787; batch adversarial loss: 1.098410\n",
      "epoch 3; iter: 0; batch classifier loss: 1.141670; batch adversarial loss: 1.016613\n",
      "epoch 4; iter: 0; batch classifier loss: 0.970470; batch adversarial loss: 0.926446\n",
      "epoch 5; iter: 0; batch classifier loss: 1.207685; batch adversarial loss: 0.859010\n",
      "epoch 6; iter: 0; batch classifier loss: 1.114471; batch adversarial loss: 0.791931\n",
      "epoch 7; iter: 0; batch classifier loss: 1.230002; batch adversarial loss: 0.720191\n",
      "epoch 8; iter: 0; batch classifier loss: 1.002896; batch adversarial loss: 0.686224\n",
      "epoch 9; iter: 0; batch classifier loss: 1.034529; batch adversarial loss: 0.663763\n",
      "epoch 10; iter: 0; batch classifier loss: 0.945044; batch adversarial loss: 0.601194\n",
      "epoch 11; iter: 0; batch classifier loss: 1.099584; batch adversarial loss: 0.590345\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590509; batch adversarial loss: 0.578624\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566999; batch adversarial loss: 0.566352\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506503; batch adversarial loss: 0.593021\n",
      "epoch 15; iter: 0; batch classifier loss: 0.632281; batch adversarial loss: 0.598994\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513096; batch adversarial loss: 0.572075\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522430; batch adversarial loss: 0.552652\n",
      "epoch 18; iter: 0; batch classifier loss: 0.601217; batch adversarial loss: 0.542981\n",
      "epoch 19; iter: 0; batch classifier loss: 0.414993; batch adversarial loss: 0.489255\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513856; batch adversarial loss: 0.573352\n",
      "epoch 21; iter: 0; batch classifier loss: 0.534862; batch adversarial loss: 0.566883\n",
      "epoch 22; iter: 0; batch classifier loss: 0.439007; batch adversarial loss: 0.594281\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487338; batch adversarial loss: 0.580351\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502181; batch adversarial loss: 0.539908\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512772; batch adversarial loss: 0.564421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.444930; batch adversarial loss: 0.655689\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447802; batch adversarial loss: 0.565891\n",
      "epoch 28; iter: 0; batch classifier loss: 0.549298; batch adversarial loss: 0.577092\n",
      "epoch 29; iter: 0; batch classifier loss: 0.551504; batch adversarial loss: 0.507777\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484120; batch adversarial loss: 0.532037\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498633; batch adversarial loss: 0.591348\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461635; batch adversarial loss: 0.537288\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457582; batch adversarial loss: 0.582909\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496021; batch adversarial loss: 0.520779\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421255; batch adversarial loss: 0.595427\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490904; batch adversarial loss: 0.624373\n",
      "epoch 37; iter: 0; batch classifier loss: 0.528049; batch adversarial loss: 0.523610\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415451; batch adversarial loss: 0.502024\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418443; batch adversarial loss: 0.514733\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408879; batch adversarial loss: 0.564391\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438619; batch adversarial loss: 0.530532\n",
      "epoch 42; iter: 0; batch classifier loss: 0.486690; batch adversarial loss: 0.587583\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408178; batch adversarial loss: 0.475272\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426367; batch adversarial loss: 0.566819\n",
      "epoch 45; iter: 0; batch classifier loss: 0.540787; batch adversarial loss: 0.634166\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429284; batch adversarial loss: 0.587808\n",
      "epoch 47; iter: 0; batch classifier loss: 0.391043; batch adversarial loss: 0.596468\n",
      "epoch 48; iter: 0; batch classifier loss: 0.479669; batch adversarial loss: 0.539455\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449004; batch adversarial loss: 0.531620\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458327; batch adversarial loss: 0.598588\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392670; batch adversarial loss: 0.563878\n",
      "epoch 52; iter: 0; batch classifier loss: 0.463672; batch adversarial loss: 0.562458\n",
      "epoch 53; iter: 0; batch classifier loss: 0.451366; batch adversarial loss: 0.595963\n",
      "epoch 54; iter: 0; batch classifier loss: 0.388080; batch adversarial loss: 0.528048\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393496; batch adversarial loss: 0.570816\n",
      "epoch 56; iter: 0; batch classifier loss: 0.334639; batch adversarial loss: 0.596725\n",
      "epoch 57; iter: 0; batch classifier loss: 0.447492; batch adversarial loss: 0.587814\n",
      "epoch 58; iter: 0; batch classifier loss: 0.372292; batch adversarial loss: 0.552305\n",
      "epoch 59; iter: 0; batch classifier loss: 0.507207; batch adversarial loss: 0.509171\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457767; batch adversarial loss: 0.490593\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439566; batch adversarial loss: 0.554021\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415722; batch adversarial loss: 0.554129\n",
      "epoch 63; iter: 0; batch classifier loss: 0.345762; batch adversarial loss: 0.535529\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440558; batch adversarial loss: 0.580343\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432495; batch adversarial loss: 0.623820\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400243; batch adversarial loss: 0.588778\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404053; batch adversarial loss: 0.588250\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373623; batch adversarial loss: 0.607457\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403191; batch adversarial loss: 0.543077\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412413; batch adversarial loss: 0.525190\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396429; batch adversarial loss: 0.584365\n",
      "epoch 72; iter: 0; batch classifier loss: 0.309653; batch adversarial loss: 0.479298\n",
      "epoch 73; iter: 0; batch classifier loss: 0.480375; batch adversarial loss: 0.535535\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441062; batch adversarial loss: 0.505541\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449441; batch adversarial loss: 0.554731\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364120; batch adversarial loss: 0.566280\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379270; batch adversarial loss: 0.610109\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387951; batch adversarial loss: 0.578191\n",
      "epoch 79; iter: 0; batch classifier loss: 0.438507; batch adversarial loss: 0.550554\n",
      "epoch 80; iter: 0; batch classifier loss: 0.353920; batch adversarial loss: 0.526354\n",
      "epoch 81; iter: 0; batch classifier loss: 0.437963; batch adversarial loss: 0.553982\n",
      "epoch 82; iter: 0; batch classifier loss: 0.328233; batch adversarial loss: 0.553788\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410815; batch adversarial loss: 0.498549\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410901; batch adversarial loss: 0.520383\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403741; batch adversarial loss: 0.659982\n",
      "epoch 86; iter: 0; batch classifier loss: 0.332524; batch adversarial loss: 0.481720\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455432; batch adversarial loss: 0.589470\n",
      "epoch 88; iter: 0; batch classifier loss: 0.341127; batch adversarial loss: 0.597050\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380098; batch adversarial loss: 0.572480\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340967; batch adversarial loss: 0.555156\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373863; batch adversarial loss: 0.598315\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389799; batch adversarial loss: 0.588301\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352626; batch adversarial loss: 0.553188\n",
      "epoch 94; iter: 0; batch classifier loss: 0.341508; batch adversarial loss: 0.517149\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401426; batch adversarial loss: 0.632428\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377948; batch adversarial loss: 0.562572\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386534; batch adversarial loss: 0.500325\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339201; batch adversarial loss: 0.499890\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396085; batch adversarial loss: 0.498901\n",
      "epoch 100; iter: 0; batch classifier loss: 0.298707; batch adversarial loss: 0.615218\n",
      "epoch 101; iter: 0; batch classifier loss: 0.351767; batch adversarial loss: 0.664678\n",
      "epoch 102; iter: 0; batch classifier loss: 0.381310; batch adversarial loss: 0.554381\n",
      "epoch 103; iter: 0; batch classifier loss: 0.400498; batch adversarial loss: 0.478726\n",
      "epoch 104; iter: 0; batch classifier loss: 0.323992; batch adversarial loss: 0.570396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361652; batch adversarial loss: 0.544990\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376998; batch adversarial loss: 0.507717\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388548; batch adversarial loss: 0.590232\n",
      "epoch 108; iter: 0; batch classifier loss: 0.259375; batch adversarial loss: 0.516380\n",
      "epoch 109; iter: 0; batch classifier loss: 0.327564; batch adversarial loss: 0.499305\n",
      "epoch 110; iter: 0; batch classifier loss: 0.347308; batch adversarial loss: 0.616189\n",
      "epoch 111; iter: 0; batch classifier loss: 0.383465; batch adversarial loss: 0.663667\n",
      "epoch 112; iter: 0; batch classifier loss: 0.321054; batch adversarial loss: 0.587753\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328182; batch adversarial loss: 0.543054\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384575; batch adversarial loss: 0.572494\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366289; batch adversarial loss: 0.560252\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370956; batch adversarial loss: 0.590055\n",
      "epoch 117; iter: 0; batch classifier loss: 0.419865; batch adversarial loss: 0.532938\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352022; batch adversarial loss: 0.537172\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366543; batch adversarial loss: 0.598467\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358399; batch adversarial loss: 0.563968\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383351; batch adversarial loss: 0.564011\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326864; batch adversarial loss: 0.546286\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365711; batch adversarial loss: 0.545274\n",
      "epoch 124; iter: 0; batch classifier loss: 0.330216; batch adversarial loss: 0.613935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.374030; batch adversarial loss: 0.591655\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317670; batch adversarial loss: 0.476068\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388204; batch adversarial loss: 0.561698\n",
      "epoch 128; iter: 0; batch classifier loss: 0.339703; batch adversarial loss: 0.534792\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379349; batch adversarial loss: 0.588522\n",
      "epoch 130; iter: 0; batch classifier loss: 0.333082; batch adversarial loss: 0.554060\n",
      "epoch 131; iter: 0; batch classifier loss: 0.403059; batch adversarial loss: 0.526515\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370029; batch adversarial loss: 0.517703\n",
      "epoch 133; iter: 0; batch classifier loss: 0.404230; batch adversarial loss: 0.501088\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381039; batch adversarial loss: 0.535393\n",
      "epoch 135; iter: 0; batch classifier loss: 0.339898; batch adversarial loss: 0.509307\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324725; batch adversarial loss: 0.536447\n",
      "epoch 137; iter: 0; batch classifier loss: 0.339629; batch adversarial loss: 0.642638\n",
      "epoch 138; iter: 0; batch classifier loss: 0.327561; batch adversarial loss: 0.535892\n",
      "epoch 139; iter: 0; batch classifier loss: 0.339846; batch adversarial loss: 0.508221\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335996; batch adversarial loss: 0.507727\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365987; batch adversarial loss: 0.481434\n",
      "epoch 142; iter: 0; batch classifier loss: 0.292233; batch adversarial loss: 0.570722\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353350; batch adversarial loss: 0.551443\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379896; batch adversarial loss: 0.528495\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385470; batch adversarial loss: 0.543362\n",
      "epoch 146; iter: 0; batch classifier loss: 0.306364; batch adversarial loss: 0.525956\n",
      "epoch 147; iter: 0; batch classifier loss: 0.418387; batch adversarial loss: 0.527677\n",
      "epoch 148; iter: 0; batch classifier loss: 0.464137; batch adversarial loss: 0.588101\n",
      "epoch 149; iter: 0; batch classifier loss: 0.394409; batch adversarial loss: 0.454264\n",
      "epoch 150; iter: 0; batch classifier loss: 0.263563; batch adversarial loss: 0.570261\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340253; batch adversarial loss: 0.535266\n",
      "epoch 152; iter: 0; batch classifier loss: 0.359727; batch adversarial loss: 0.527778\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328087; batch adversarial loss: 0.553991\n",
      "epoch 154; iter: 0; batch classifier loss: 0.336165; batch adversarial loss: 0.517169\n",
      "epoch 155; iter: 0; batch classifier loss: 0.390951; batch adversarial loss: 0.527960\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333541; batch adversarial loss: 0.608092\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381043; batch adversarial loss: 0.517006\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337696; batch adversarial loss: 0.606684\n",
      "epoch 159; iter: 0; batch classifier loss: 0.302051; batch adversarial loss: 0.553226\n",
      "epoch 160; iter: 0; batch classifier loss: 0.355372; batch adversarial loss: 0.589378\n",
      "epoch 161; iter: 0; batch classifier loss: 0.294051; batch adversarial loss: 0.535451\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364014; batch adversarial loss: 0.536082\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342360; batch adversarial loss: 0.454531\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346594; batch adversarial loss: 0.525938\n",
      "epoch 165; iter: 0; batch classifier loss: 0.271331; batch adversarial loss: 0.562499\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366463; batch adversarial loss: 0.506451\n",
      "epoch 167; iter: 0; batch classifier loss: 0.326504; batch adversarial loss: 0.534496\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306391; batch adversarial loss: 0.590190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.296622; batch adversarial loss: 0.543450\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322006; batch adversarial loss: 0.500132\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378645; batch adversarial loss: 0.509637\n",
      "epoch 172; iter: 0; batch classifier loss: 0.314139; batch adversarial loss: 0.527636\n",
      "epoch 173; iter: 0; batch classifier loss: 0.318462; batch adversarial loss: 0.553975\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363569; batch adversarial loss: 0.580454\n",
      "epoch 175; iter: 0; batch classifier loss: 0.310940; batch adversarial loss: 0.553660\n",
      "epoch 176; iter: 0; batch classifier loss: 0.327860; batch adversarial loss: 0.535989\n",
      "epoch 177; iter: 0; batch classifier loss: 0.276210; batch adversarial loss: 0.455772\n",
      "epoch 178; iter: 0; batch classifier loss: 0.280238; batch adversarial loss: 0.580382\n",
      "epoch 179; iter: 0; batch classifier loss: 0.319388; batch adversarial loss: 0.571760\n",
      "epoch 180; iter: 0; batch classifier loss: 0.301583; batch adversarial loss: 0.544388\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314543; batch adversarial loss: 0.571036\n",
      "epoch 182; iter: 0; batch classifier loss: 0.281486; batch adversarial loss: 0.571457\n",
      "epoch 183; iter: 0; batch classifier loss: 0.265816; batch adversarial loss: 0.598343\n",
      "epoch 184; iter: 0; batch classifier loss: 0.327657; batch adversarial loss: 0.607700\n",
      "epoch 185; iter: 0; batch classifier loss: 0.300259; batch adversarial loss: 0.589555\n",
      "epoch 186; iter: 0; batch classifier loss: 0.333476; batch adversarial loss: 0.508853\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352494; batch adversarial loss: 0.571635\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384270; batch adversarial loss: 0.535755\n",
      "epoch 189; iter: 0; batch classifier loss: 0.312282; batch adversarial loss: 0.535731\n",
      "epoch 190; iter: 0; batch classifier loss: 0.350956; batch adversarial loss: 0.499822\n",
      "epoch 191; iter: 0; batch classifier loss: 0.294811; batch adversarial loss: 0.562620\n",
      "epoch 192; iter: 0; batch classifier loss: 0.390650; batch adversarial loss: 0.580386\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347928; batch adversarial loss: 0.598405\n",
      "epoch 194; iter: 0; batch classifier loss: 0.307390; batch adversarial loss: 0.499862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332286; batch adversarial loss: 0.616161\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387938; batch adversarial loss: 0.499763\n",
      "epoch 197; iter: 0; batch classifier loss: 0.307482; batch adversarial loss: 0.598940\n",
      "epoch 198; iter: 0; batch classifier loss: 0.308162; batch adversarial loss: 0.562369\n",
      "epoch 199; iter: 0; batch classifier loss: 0.327881; batch adversarial loss: 0.517619\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725047; batch adversarial loss: 0.588795\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610205; batch adversarial loss: 0.645316\n",
      "epoch 2; iter: 0; batch classifier loss: 0.553568; batch adversarial loss: 0.647871\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568242; batch adversarial loss: 0.627737\n",
      "epoch 4; iter: 0; batch classifier loss: 0.522288; batch adversarial loss: 0.611742\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537303; batch adversarial loss: 0.632325\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582360; batch adversarial loss: 0.630302\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575175; batch adversarial loss: 0.572795\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525712; batch adversarial loss: 0.612343\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486543; batch adversarial loss: 0.636792\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477349; batch adversarial loss: 0.565851\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569888; batch adversarial loss: 0.579148\n",
      "epoch 12; iter: 0; batch classifier loss: 0.451084; batch adversarial loss: 0.604865\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483963; batch adversarial loss: 0.593844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463064; batch adversarial loss: 0.534604\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493773; batch adversarial loss: 0.592066\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550268; batch adversarial loss: 0.535216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536637; batch adversarial loss: 0.544265\n",
      "epoch 18; iter: 0; batch classifier loss: 0.439551; batch adversarial loss: 0.566146\n",
      "epoch 19; iter: 0; batch classifier loss: 0.383142; batch adversarial loss: 0.521656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496843; batch adversarial loss: 0.528344\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436498; batch adversarial loss: 0.554838\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485168; batch adversarial loss: 0.590358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.470563; batch adversarial loss: 0.567410\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503499; batch adversarial loss: 0.530406\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439631; batch adversarial loss: 0.505269\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465072; batch adversarial loss: 0.542006\n",
      "epoch 27; iter: 0; batch classifier loss: 0.504094; batch adversarial loss: 0.482855\n",
      "epoch 28; iter: 0; batch classifier loss: 0.359036; batch adversarial loss: 0.526173\n",
      "epoch 29; iter: 0; batch classifier loss: 0.589797; batch adversarial loss: 0.584488\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406476; batch adversarial loss: 0.540749\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457012; batch adversarial loss: 0.539209\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494702; batch adversarial loss: 0.510256\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445602; batch adversarial loss: 0.509539\n",
      "epoch 34; iter: 0; batch classifier loss: 0.405104; batch adversarial loss: 0.590992\n",
      "epoch 35; iter: 0; batch classifier loss: 0.477933; batch adversarial loss: 0.535329\n",
      "epoch 36; iter: 0; batch classifier loss: 0.364611; batch adversarial loss: 0.484006\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480973; batch adversarial loss: 0.581712\n",
      "epoch 38; iter: 0; batch classifier loss: 0.347486; batch adversarial loss: 0.525298\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419172; batch adversarial loss: 0.572639\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464108; batch adversarial loss: 0.560002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.400893; batch adversarial loss: 0.520042\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457141; batch adversarial loss: 0.552743\n",
      "epoch 43; iter: 0; batch classifier loss: 0.355656; batch adversarial loss: 0.443577\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408348; batch adversarial loss: 0.517802\n",
      "epoch 45; iter: 0; batch classifier loss: 0.355926; batch adversarial loss: 0.461625\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406173; batch adversarial loss: 0.573775\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399199; batch adversarial loss: 0.487506\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429889; batch adversarial loss: 0.546164\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408525; batch adversarial loss: 0.535813\n",
      "epoch 50; iter: 0; batch classifier loss: 0.382962; batch adversarial loss: 0.573887\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418090; batch adversarial loss: 0.619814\n",
      "epoch 52; iter: 0; batch classifier loss: 0.402820; batch adversarial loss: 0.611639\n",
      "epoch 53; iter: 0; batch classifier loss: 0.467909; batch adversarial loss: 0.656394\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432744; batch adversarial loss: 0.569901\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412462; batch adversarial loss: 0.515687\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431080; batch adversarial loss: 0.582929\n",
      "epoch 57; iter: 0; batch classifier loss: 0.510880; batch adversarial loss: 0.553142\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441289; batch adversarial loss: 0.525120\n",
      "epoch 59; iter: 0; batch classifier loss: 0.455385; batch adversarial loss: 0.575016\n",
      "epoch 60; iter: 0; batch classifier loss: 0.361331; batch adversarial loss: 0.589600\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409023; batch adversarial loss: 0.489816\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417802; batch adversarial loss: 0.523199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449722; batch adversarial loss: 0.525909\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365345; batch adversarial loss: 0.526506\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447395; batch adversarial loss: 0.552889\n",
      "epoch 66; iter: 0; batch classifier loss: 0.388889; batch adversarial loss: 0.539929\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442285; batch adversarial loss: 0.610354\n",
      "epoch 68; iter: 0; batch classifier loss: 0.347695; batch adversarial loss: 0.542444\n",
      "epoch 69; iter: 0; batch classifier loss: 0.348676; batch adversarial loss: 0.519172\n",
      "epoch 70; iter: 0; batch classifier loss: 0.371224; batch adversarial loss: 0.499121\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378809; batch adversarial loss: 0.580015\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457459; batch adversarial loss: 0.497249\n",
      "epoch 73; iter: 0; batch classifier loss: 0.406054; batch adversarial loss: 0.517039\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419722; batch adversarial loss: 0.543992\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380424; batch adversarial loss: 0.533395\n",
      "epoch 76; iter: 0; batch classifier loss: 0.315216; batch adversarial loss: 0.561855\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424148; batch adversarial loss: 0.478998\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441260; batch adversarial loss: 0.580988\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370263; batch adversarial loss: 0.636834\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387162; batch adversarial loss: 0.562433\n",
      "epoch 81; iter: 0; batch classifier loss: 0.341696; batch adversarial loss: 0.553924\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406970; batch adversarial loss: 0.545516\n",
      "epoch 83; iter: 0; batch classifier loss: 0.480430; batch adversarial loss: 0.573100\n",
      "epoch 84; iter: 0; batch classifier loss: 0.337288; batch adversarial loss: 0.666248\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344705; batch adversarial loss: 0.590812\n",
      "epoch 86; iter: 0; batch classifier loss: 0.385127; batch adversarial loss: 0.525113\n",
      "epoch 87; iter: 0; batch classifier loss: 0.334682; batch adversarial loss: 0.450376\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385408; batch adversarial loss: 0.526211\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413290; batch adversarial loss: 0.610097\n",
      "epoch 90; iter: 0; batch classifier loss: 0.309437; batch adversarial loss: 0.498409\n",
      "epoch 91; iter: 0; batch classifier loss: 0.311959; batch adversarial loss: 0.574172\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368436; batch adversarial loss: 0.544190\n",
      "epoch 93; iter: 0; batch classifier loss: 0.360737; batch adversarial loss: 0.551904\n",
      "epoch 94; iter: 0; batch classifier loss: 0.395578; batch adversarial loss: 0.543659\n",
      "epoch 95; iter: 0; batch classifier loss: 0.330953; batch adversarial loss: 0.497398\n",
      "epoch 96; iter: 0; batch classifier loss: 0.459554; batch adversarial loss: 0.524963\n",
      "epoch 97; iter: 0; batch classifier loss: 0.322793; batch adversarial loss: 0.543473\n",
      "epoch 98; iter: 0; batch classifier loss: 0.333472; batch adversarial loss: 0.572366\n",
      "epoch 99; iter: 0; batch classifier loss: 0.476982; batch adversarial loss: 0.523908\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439055; batch adversarial loss: 0.545122\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379142; batch adversarial loss: 0.469745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.325529; batch adversarial loss: 0.563579\n",
      "epoch 103; iter: 0; batch classifier loss: 0.318701; batch adversarial loss: 0.543344\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350112; batch adversarial loss: 0.516817\n",
      "epoch 105; iter: 0; batch classifier loss: 0.282462; batch adversarial loss: 0.534481\n",
      "epoch 106; iter: 0; batch classifier loss: 0.322788; batch adversarial loss: 0.497931\n",
      "epoch 107; iter: 0; batch classifier loss: 0.444846; batch adversarial loss: 0.515851\n",
      "epoch 108; iter: 0; batch classifier loss: 0.350022; batch adversarial loss: 0.591449\n",
      "epoch 109; iter: 0; batch classifier loss: 0.439200; batch adversarial loss: 0.574213\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375988; batch adversarial loss: 0.608899\n",
      "epoch 111; iter: 0; batch classifier loss: 0.342537; batch adversarial loss: 0.572426\n",
      "epoch 112; iter: 0; batch classifier loss: 0.343874; batch adversarial loss: 0.497946\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377383; batch adversarial loss: 0.555053\n",
      "epoch 114; iter: 0; batch classifier loss: 0.341341; batch adversarial loss: 0.478516\n",
      "epoch 115; iter: 0; batch classifier loss: 0.459109; batch adversarial loss: 0.572135\n",
      "epoch 116; iter: 0; batch classifier loss: 0.383685; batch adversarial loss: 0.524565\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371769; batch adversarial loss: 0.527544\n",
      "epoch 118; iter: 0; batch classifier loss: 0.414030; batch adversarial loss: 0.554439\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348464; batch adversarial loss: 0.515742\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422270; batch adversarial loss: 0.516552\n",
      "epoch 121; iter: 0; batch classifier loss: 0.295784; batch adversarial loss: 0.533690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.366607; batch adversarial loss: 0.619508\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339076; batch adversarial loss: 0.526429\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365162; batch adversarial loss: 0.618451\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329201; batch adversarial loss: 0.505850\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359967; batch adversarial loss: 0.571282\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383176; batch adversarial loss: 0.600084\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366083; batch adversarial loss: 0.572041\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370642; batch adversarial loss: 0.524788\n",
      "epoch 130; iter: 0; batch classifier loss: 0.305973; batch adversarial loss: 0.562248\n",
      "epoch 131; iter: 0; batch classifier loss: 0.334045; batch adversarial loss: 0.573693\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381063; batch adversarial loss: 0.506027\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357616; batch adversarial loss: 0.562583\n",
      "epoch 134; iter: 0; batch classifier loss: 0.342393; batch adversarial loss: 0.497566\n",
      "epoch 135; iter: 0; batch classifier loss: 0.416595; batch adversarial loss: 0.554839\n",
      "epoch 136; iter: 0; batch classifier loss: 0.297360; batch adversarial loss: 0.592137\n",
      "epoch 137; iter: 0; batch classifier loss: 0.346284; batch adversarial loss: 0.544039\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318357; batch adversarial loss: 0.619869\n",
      "epoch 139; iter: 0; batch classifier loss: 0.303174; batch adversarial loss: 0.591532\n",
      "epoch 140; iter: 0; batch classifier loss: 0.458108; batch adversarial loss: 0.555233\n",
      "epoch 141; iter: 0; batch classifier loss: 0.435925; batch adversarial loss: 0.534475\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339244; batch adversarial loss: 0.498285\n",
      "epoch 143; iter: 0; batch classifier loss: 0.419834; batch adversarial loss: 0.553483\n",
      "epoch 144; iter: 0; batch classifier loss: 0.453838; batch adversarial loss: 0.524983\n",
      "epoch 145; iter: 0; batch classifier loss: 0.420077; batch adversarial loss: 0.527954\n",
      "epoch 146; iter: 0; batch classifier loss: 0.267525; batch adversarial loss: 0.460915\n",
      "epoch 147; iter: 0; batch classifier loss: 0.317984; batch adversarial loss: 0.561722\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349039; batch adversarial loss: 0.515922\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353808; batch adversarial loss: 0.564191\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377277; batch adversarial loss: 0.517027\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373266; batch adversarial loss: 0.506898\n",
      "epoch 152; iter: 0; batch classifier loss: 0.329647; batch adversarial loss: 0.469531\n",
      "epoch 153; iter: 0; batch classifier loss: 0.306131; batch adversarial loss: 0.544376\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335215; batch adversarial loss: 0.563717\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397413; batch adversarial loss: 0.592289\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377455; batch adversarial loss: 0.571769\n",
      "epoch 157; iter: 0; batch classifier loss: 0.357403; batch adversarial loss: 0.582429\n",
      "epoch 158; iter: 0; batch classifier loss: 0.299521; batch adversarial loss: 0.515023\n",
      "epoch 159; iter: 0; batch classifier loss: 0.274573; batch adversarial loss: 0.479680\n",
      "epoch 160; iter: 0; batch classifier loss: 0.338407; batch adversarial loss: 0.553470\n",
      "epoch 161; iter: 0; batch classifier loss: 0.307456; batch adversarial loss: 0.432588\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365602; batch adversarial loss: 0.610213\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349215; batch adversarial loss: 0.600667\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334314; batch adversarial loss: 0.610337\n",
      "epoch 165; iter: 0; batch classifier loss: 0.270943; batch adversarial loss: 0.563105\n",
      "epoch 166; iter: 0; batch classifier loss: 0.305492; batch adversarial loss: 0.544066\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379231; batch adversarial loss: 0.600475\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322755; batch adversarial loss: 0.580748\n",
      "epoch 169; iter: 0; batch classifier loss: 0.274099; batch adversarial loss: 0.601226\n",
      "epoch 170; iter: 0; batch classifier loss: 0.294612; batch adversarial loss: 0.535802\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349791; batch adversarial loss: 0.543994\n",
      "epoch 172; iter: 0; batch classifier loss: 0.251793; batch adversarial loss: 0.571204\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338872; batch adversarial loss: 0.479116\n",
      "epoch 174; iter: 0; batch classifier loss: 0.280567; batch adversarial loss: 0.487926\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351952; batch adversarial loss: 0.460084\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316185; batch adversarial loss: 0.601256\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374221; batch adversarial loss: 0.573104\n",
      "epoch 178; iter: 0; batch classifier loss: 0.341680; batch adversarial loss: 0.553868\n",
      "epoch 179; iter: 0; batch classifier loss: 0.353523; batch adversarial loss: 0.563076\n",
      "epoch 180; iter: 0; batch classifier loss: 0.319207; batch adversarial loss: 0.459923\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376352; batch adversarial loss: 0.544180\n",
      "epoch 182; iter: 0; batch classifier loss: 0.353987; batch adversarial loss: 0.451478\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395755; batch adversarial loss: 0.562547\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346835; batch adversarial loss: 0.563060\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365329; batch adversarial loss: 0.563322\n",
      "epoch 186; iter: 0; batch classifier loss: 0.314549; batch adversarial loss: 0.572172\n",
      "epoch 187; iter: 0; batch classifier loss: 0.314987; batch adversarial loss: 0.516529\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375305; batch adversarial loss: 0.563189\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358159; batch adversarial loss: 0.554604\n",
      "epoch 190; iter: 0; batch classifier loss: 0.429694; batch adversarial loss: 0.450591\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322233; batch adversarial loss: 0.470100\n",
      "epoch 192; iter: 0; batch classifier loss: 0.304065; batch adversarial loss: 0.534386\n",
      "epoch 193; iter: 0; batch classifier loss: 0.358639; batch adversarial loss: 0.581920\n",
      "epoch 194; iter: 0; batch classifier loss: 0.378566; batch adversarial loss: 0.534644\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323176; batch adversarial loss: 0.535117\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347081; batch adversarial loss: 0.479204\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339700; batch adversarial loss: 0.562631\n",
      "epoch 198; iter: 0; batch classifier loss: 0.345838; batch adversarial loss: 0.580928\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381771; batch adversarial loss: 0.572190\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716229; batch adversarial loss: 0.725966\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601334; batch adversarial loss: 0.682589\n",
      "epoch 2; iter: 0; batch classifier loss: 0.560615; batch adversarial loss: 0.602405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578790; batch adversarial loss: 0.699189\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546964; batch adversarial loss: 0.676491\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551091; batch adversarial loss: 0.613772\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580027; batch adversarial loss: 0.598025\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567151; batch adversarial loss: 0.586824\n",
      "epoch 8; iter: 0; batch classifier loss: 0.563389; batch adversarial loss: 0.556018\n",
      "epoch 9; iter: 0; batch classifier loss: 0.593595; batch adversarial loss: 0.580722\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494461; batch adversarial loss: 0.630374\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481698; batch adversarial loss: 0.596368\n",
      "epoch 12; iter: 0; batch classifier loss: 0.474906; batch adversarial loss: 0.552513\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527804; batch adversarial loss: 0.591058\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513134; batch adversarial loss: 0.573308\n",
      "epoch 15; iter: 0; batch classifier loss: 0.590331; batch adversarial loss: 0.500473\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471116; batch adversarial loss: 0.583576\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465209; batch adversarial loss: 0.529350\n",
      "epoch 18; iter: 0; batch classifier loss: 0.481936; batch adversarial loss: 0.543188\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470369; batch adversarial loss: 0.511572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.469596; batch adversarial loss: 0.583993\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502468; batch adversarial loss: 0.551924\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464111; batch adversarial loss: 0.463268\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519424; batch adversarial loss: 0.575692\n",
      "epoch 24; iter: 0; batch classifier loss: 0.437538; batch adversarial loss: 0.626577\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431730; batch adversarial loss: 0.558293\n",
      "epoch 26; iter: 0; batch classifier loss: 0.542575; batch adversarial loss: 0.542370\n",
      "epoch 27; iter: 0; batch classifier loss: 0.435203; batch adversarial loss: 0.534551\n",
      "epoch 28; iter: 0; batch classifier loss: 0.361207; batch adversarial loss: 0.634343\n",
      "epoch 29; iter: 0; batch classifier loss: 0.449691; batch adversarial loss: 0.505315\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488043; batch adversarial loss: 0.545599\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470672; batch adversarial loss: 0.509766\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497058; batch adversarial loss: 0.486199\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438746; batch adversarial loss: 0.548840\n",
      "epoch 34; iter: 0; batch classifier loss: 0.403882; batch adversarial loss: 0.578099\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419577; batch adversarial loss: 0.521595\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441719; batch adversarial loss: 0.481824\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458774; batch adversarial loss: 0.513223\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481520; batch adversarial loss: 0.560532\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445267; batch adversarial loss: 0.616916\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477075; batch adversarial loss: 0.557137\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453773; batch adversarial loss: 0.512109\n",
      "epoch 42; iter: 0; batch classifier loss: 0.486174; batch adversarial loss: 0.554318\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441620; batch adversarial loss: 0.521648\n",
      "epoch 44; iter: 0; batch classifier loss: 0.368209; batch adversarial loss: 0.519352\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418938; batch adversarial loss: 0.607784\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446530; batch adversarial loss: 0.544560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490842; batch adversarial loss: 0.544729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495054; batch adversarial loss: 0.500232\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430284; batch adversarial loss: 0.509524\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469584; batch adversarial loss: 0.525831\n",
      "epoch 51; iter: 0; batch classifier loss: 0.477100; batch adversarial loss: 0.481185\n",
      "epoch 52; iter: 0; batch classifier loss: 0.376262; batch adversarial loss: 0.571741\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414028; batch adversarial loss: 0.516172\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419986; batch adversarial loss: 0.608765\n",
      "epoch 55; iter: 0; batch classifier loss: 0.424561; batch adversarial loss: 0.468162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413500; batch adversarial loss: 0.458963\n",
      "epoch 57; iter: 0; batch classifier loss: 0.447423; batch adversarial loss: 0.508160\n",
      "epoch 58; iter: 0; batch classifier loss: 0.432257; batch adversarial loss: 0.535403\n",
      "epoch 59; iter: 0; batch classifier loss: 0.479408; batch adversarial loss: 0.582191\n",
      "epoch 60; iter: 0; batch classifier loss: 0.361995; batch adversarial loss: 0.490567\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386924; batch adversarial loss: 0.571355\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448736; batch adversarial loss: 0.544527\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450092; batch adversarial loss: 0.589710\n",
      "epoch 64; iter: 0; batch classifier loss: 0.451678; batch adversarial loss: 0.589373\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362608; batch adversarial loss: 0.481049\n",
      "epoch 66; iter: 0; batch classifier loss: 0.394233; batch adversarial loss: 0.544248\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363808; batch adversarial loss: 0.544574\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445626; batch adversarial loss: 0.517551\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430099; batch adversarial loss: 0.618217\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387050; batch adversarial loss: 0.590907\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386383; batch adversarial loss: 0.581244\n",
      "epoch 72; iter: 0; batch classifier loss: 0.451042; batch adversarial loss: 0.607557\n",
      "epoch 73; iter: 0; batch classifier loss: 0.329433; batch adversarial loss: 0.516713\n",
      "epoch 74; iter: 0; batch classifier loss: 0.477972; batch adversarial loss: 0.569051\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384123; batch adversarial loss: 0.545739\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370001; batch adversarial loss: 0.515175\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402416; batch adversarial loss: 0.554687\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413977; batch adversarial loss: 0.560676\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462140; batch adversarial loss: 0.558854\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365193; batch adversarial loss: 0.541894\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358487; batch adversarial loss: 0.588796\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353244; batch adversarial loss: 0.635407\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369777; batch adversarial loss: 0.573484\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402050; batch adversarial loss: 0.470896\n",
      "epoch 85; iter: 0; batch classifier loss: 0.417672; batch adversarial loss: 0.536751\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416263; batch adversarial loss: 0.525801\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380034; batch adversarial loss: 0.543166\n",
      "epoch 88; iter: 0; batch classifier loss: 0.353853; batch adversarial loss: 0.526470\n",
      "epoch 89; iter: 0; batch classifier loss: 0.312883; batch adversarial loss: 0.591433\n",
      "epoch 90; iter: 0; batch classifier loss: 0.389885; batch adversarial loss: 0.571932\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382641; batch adversarial loss: 0.637492\n",
      "epoch 92; iter: 0; batch classifier loss: 0.483145; batch adversarial loss: 0.524254\n",
      "epoch 93; iter: 0; batch classifier loss: 0.346563; batch adversarial loss: 0.518402\n",
      "epoch 94; iter: 0; batch classifier loss: 0.428398; batch adversarial loss: 0.535576\n",
      "epoch 95; iter: 0; batch classifier loss: 0.308965; batch adversarial loss: 0.599594\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384568; batch adversarial loss: 0.544278\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358130; batch adversarial loss: 0.488786\n",
      "epoch 98; iter: 0; batch classifier loss: 0.336659; batch adversarial loss: 0.536708\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424583; batch adversarial loss: 0.580576\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397890; batch adversarial loss: 0.583140\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391503; batch adversarial loss: 0.562980\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407539; batch adversarial loss: 0.507203\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383065; batch adversarial loss: 0.572506\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400940; batch adversarial loss: 0.498746\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424756; batch adversarial loss: 0.535301\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331336; batch adversarial loss: 0.500552\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380891; batch adversarial loss: 0.516451\n",
      "epoch 108; iter: 0; batch classifier loss: 0.322223; batch adversarial loss: 0.499159\n",
      "epoch 109; iter: 0; batch classifier loss: 0.450421; batch adversarial loss: 0.488240\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369837; batch adversarial loss: 0.561925\n",
      "epoch 111; iter: 0; batch classifier loss: 0.339521; batch adversarial loss: 0.563307\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405979; batch adversarial loss: 0.582489\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391521; batch adversarial loss: 0.488880\n",
      "epoch 114; iter: 0; batch classifier loss: 0.421480; batch adversarial loss: 0.515623\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373535; batch adversarial loss: 0.570715\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390280; batch adversarial loss: 0.542569\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378176; batch adversarial loss: 0.576848\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358090; batch adversarial loss: 0.552928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.431349; batch adversarial loss: 0.590392\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350203; batch adversarial loss: 0.507141\n",
      "epoch 121; iter: 0; batch classifier loss: 0.415377; batch adversarial loss: 0.563750\n",
      "epoch 122; iter: 0; batch classifier loss: 0.325850; batch adversarial loss: 0.459018\n",
      "epoch 123; iter: 0; batch classifier loss: 0.289488; batch adversarial loss: 0.543005\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380238; batch adversarial loss: 0.591292\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349269; batch adversarial loss: 0.591040\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403586; batch adversarial loss: 0.497414\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366735; batch adversarial loss: 0.526838\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346938; batch adversarial loss: 0.490973\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319433; batch adversarial loss: 0.609473\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373198; batch adversarial loss: 0.515540\n",
      "epoch 131; iter: 0; batch classifier loss: 0.320879; batch adversarial loss: 0.620791\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413468; batch adversarial loss: 0.620888\n",
      "epoch 133; iter: 0; batch classifier loss: 0.315933; batch adversarial loss: 0.423514\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366197; batch adversarial loss: 0.590671\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378984; batch adversarial loss: 0.627158\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386854; batch adversarial loss: 0.590862\n",
      "epoch 137; iter: 0; batch classifier loss: 0.397936; batch adversarial loss: 0.515136\n",
      "epoch 138; iter: 0; batch classifier loss: 0.425482; batch adversarial loss: 0.507825\n",
      "epoch 139; iter: 0; batch classifier loss: 0.323709; batch adversarial loss: 0.515920\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376884; batch adversarial loss: 0.514810\n",
      "epoch 141; iter: 0; batch classifier loss: 0.335834; batch adversarial loss: 0.619559\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380674; batch adversarial loss: 0.553521\n",
      "epoch 143; iter: 0; batch classifier loss: 0.422842; batch adversarial loss: 0.543001\n",
      "epoch 144; iter: 0; batch classifier loss: 0.326712; batch adversarial loss: 0.507663\n",
      "epoch 145; iter: 0; batch classifier loss: 0.421449; batch adversarial loss: 0.575568\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327329; batch adversarial loss: 0.514895\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368936; batch adversarial loss: 0.497595\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379041; batch adversarial loss: 0.553765\n",
      "epoch 149; iter: 0; batch classifier loss: 0.324666; batch adversarial loss: 0.507547\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340066; batch adversarial loss: 0.554478\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340028; batch adversarial loss: 0.451277\n",
      "epoch 152; iter: 0; batch classifier loss: 0.483467; batch adversarial loss: 0.544371\n",
      "epoch 153; iter: 0; batch classifier loss: 0.449349; batch adversarial loss: 0.535764\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412880; batch adversarial loss: 0.517734\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374965; batch adversarial loss: 0.553115\n",
      "epoch 156; iter: 0; batch classifier loss: 0.364066; batch adversarial loss: 0.509037\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349239; batch adversarial loss: 0.598887\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323906; batch adversarial loss: 0.526194\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407073; batch adversarial loss: 0.517318\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300787; batch adversarial loss: 0.544793\n",
      "epoch 161; iter: 0; batch classifier loss: 0.407751; batch adversarial loss: 0.434794\n",
      "epoch 162; iter: 0; batch classifier loss: 0.280962; batch adversarial loss: 0.534243\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353319; batch adversarial loss: 0.526186\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386066; batch adversarial loss: 0.553063\n",
      "epoch 165; iter: 0; batch classifier loss: 0.309968; batch adversarial loss: 0.526429\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324608; batch adversarial loss: 0.496284\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347090; batch adversarial loss: 0.544827\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378004; batch adversarial loss: 0.553580\n",
      "epoch 169; iter: 0; batch classifier loss: 0.298608; batch adversarial loss: 0.525512\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330967; batch adversarial loss: 0.598048\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357748; batch adversarial loss: 0.554251\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331719; batch adversarial loss: 0.490880\n",
      "epoch 173; iter: 0; batch classifier loss: 0.335123; batch adversarial loss: 0.599498\n",
      "epoch 174; iter: 0; batch classifier loss: 0.431618; batch adversarial loss: 0.610062\n",
      "epoch 175; iter: 0; batch classifier loss: 0.420273; batch adversarial loss: 0.588572\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400931; batch adversarial loss: 0.536281\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329678; batch adversarial loss: 0.610500\n",
      "epoch 178; iter: 0; batch classifier loss: 0.379984; batch adversarial loss: 0.516442\n",
      "epoch 179; iter: 0; batch classifier loss: 0.421151; batch adversarial loss: 0.559947\n",
      "epoch 180; iter: 0; batch classifier loss: 0.462692; batch adversarial loss: 0.638086\n",
      "epoch 181; iter: 0; batch classifier loss: 0.451359; batch adversarial loss: 0.690143\n",
      "epoch 182; iter: 0; batch classifier loss: 0.477571; batch adversarial loss: 0.464751\n",
      "epoch 183; iter: 0; batch classifier loss: 0.400791; batch adversarial loss: 0.580523\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379305; batch adversarial loss: 0.531682\n",
      "epoch 185; iter: 0; batch classifier loss: 0.359849; batch adversarial loss: 0.515458\n",
      "epoch 186; iter: 0; batch classifier loss: 0.305186; batch adversarial loss: 0.517395\n",
      "epoch 187; iter: 0; batch classifier loss: 0.249184; batch adversarial loss: 0.500427\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396664; batch adversarial loss: 0.574377\n",
      "epoch 189; iter: 0; batch classifier loss: 0.388942; batch adversarial loss: 0.517677\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349787; batch adversarial loss: 0.534397\n",
      "epoch 191; iter: 0; batch classifier loss: 0.342877; batch adversarial loss: 0.599135\n",
      "epoch 192; iter: 0; batch classifier loss: 0.408061; batch adversarial loss: 0.533015\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307375; batch adversarial loss: 0.525639\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350136; batch adversarial loss: 0.590357\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392291; batch adversarial loss: 0.507767\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394878; batch adversarial loss: 0.626185\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324262; batch adversarial loss: 0.607980\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341951; batch adversarial loss: 0.571554\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385569; batch adversarial loss: 0.571915\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707977; batch adversarial loss: 0.813754\n",
      "epoch 1; iter: 0; batch classifier loss: 0.832749; batch adversarial loss: 0.867852\n",
      "epoch 2; iter: 0; batch classifier loss: 0.863309; batch adversarial loss: 0.799468\n",
      "epoch 3; iter: 0; batch classifier loss: 0.890552; batch adversarial loss: 0.748886\n",
      "epoch 4; iter: 0; batch classifier loss: 0.646839; batch adversarial loss: 0.662270\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555875; batch adversarial loss: 0.621057\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532436; batch adversarial loss: 0.616920\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580007; batch adversarial loss: 0.583002\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588610; batch adversarial loss: 0.651970\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484895; batch adversarial loss: 0.602125\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571623; batch adversarial loss: 0.601677\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544053; batch adversarial loss: 0.623042\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571803; batch adversarial loss: 0.518354\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448842; batch adversarial loss: 0.505678\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497245; batch adversarial loss: 0.569903\n",
      "epoch 15; iter: 0; batch classifier loss: 0.518988; batch adversarial loss: 0.506994\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482753; batch adversarial loss: 0.581681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.506290; batch adversarial loss: 0.578290\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471745; batch adversarial loss: 0.569540\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496916; batch adversarial loss: 0.596935\n",
      "epoch 20; iter: 0; batch classifier loss: 0.497089; batch adversarial loss: 0.549549\n",
      "epoch 21; iter: 0; batch classifier loss: 0.552855; batch adversarial loss: 0.582232\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498386; batch adversarial loss: 0.553297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497112; batch adversarial loss: 0.569647\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476649; batch adversarial loss: 0.555573\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516816; batch adversarial loss: 0.591005\n",
      "epoch 26; iter: 0; batch classifier loss: 0.550092; batch adversarial loss: 0.532706\n",
      "epoch 27; iter: 0; batch classifier loss: 0.538324; batch adversarial loss: 0.559428\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434852; batch adversarial loss: 0.533357\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464719; batch adversarial loss: 0.607524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.383142; batch adversarial loss: 0.565049\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429473; batch adversarial loss: 0.482784\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485783; batch adversarial loss: 0.538775\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519052; batch adversarial loss: 0.608219\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474071; batch adversarial loss: 0.585825\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521957; batch adversarial loss: 0.558075\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458586; batch adversarial loss: 0.551721\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459896; batch adversarial loss: 0.633341\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475431; batch adversarial loss: 0.535626\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417294; batch adversarial loss: 0.525423\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451559; batch adversarial loss: 0.516198\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460295; batch adversarial loss: 0.507679\n",
      "epoch 42; iter: 0; batch classifier loss: 0.503418; batch adversarial loss: 0.553338\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419411; batch adversarial loss: 0.543193\n",
      "epoch 44; iter: 0; batch classifier loss: 0.497052; batch adversarial loss: 0.573812\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424787; batch adversarial loss: 0.482335\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433067; batch adversarial loss: 0.500142\n",
      "epoch 47; iter: 0; batch classifier loss: 0.387041; batch adversarial loss: 0.491831\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405042; batch adversarial loss: 0.607694\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414629; batch adversarial loss: 0.572426\n",
      "epoch 50; iter: 0; batch classifier loss: 0.477993; batch adversarial loss: 0.589735\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490218; batch adversarial loss: 0.590124\n",
      "epoch 52; iter: 0; batch classifier loss: 0.506705; batch adversarial loss: 0.570659\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400403; batch adversarial loss: 0.508647\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406280; batch adversarial loss: 0.580489\n",
      "epoch 55; iter: 0; batch classifier loss: 0.347184; batch adversarial loss: 0.587574\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463747; batch adversarial loss: 0.553316\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466928; batch adversarial loss: 0.479759\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422814; batch adversarial loss: 0.562692\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424874; batch adversarial loss: 0.588626\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450667; batch adversarial loss: 0.568746\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413299; batch adversarial loss: 0.606795\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428568; batch adversarial loss: 0.571106\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417533; batch adversarial loss: 0.553763\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429988; batch adversarial loss: 0.536854\n",
      "epoch 65; iter: 0; batch classifier loss: 0.461688; batch adversarial loss: 0.617887\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382578; batch adversarial loss: 0.532346\n",
      "epoch 67; iter: 0; batch classifier loss: 0.440527; batch adversarial loss: 0.489990\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393141; batch adversarial loss: 0.526671\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442428; batch adversarial loss: 0.580414\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461742; batch adversarial loss: 0.567788\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426917; batch adversarial loss: 0.571375\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401264; batch adversarial loss: 0.537852\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446022; batch adversarial loss: 0.536640\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359131; batch adversarial loss: 0.582986\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364415; batch adversarial loss: 0.514503\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408021; batch adversarial loss: 0.499856\n",
      "epoch 77; iter: 0; batch classifier loss: 0.462303; batch adversarial loss: 0.545117\n",
      "epoch 78; iter: 0; batch classifier loss: 0.429577; batch adversarial loss: 0.588576\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410134; batch adversarial loss: 0.563572\n",
      "epoch 80; iter: 0; batch classifier loss: 0.445494; batch adversarial loss: 0.592226\n",
      "epoch 81; iter: 0; batch classifier loss: 0.338261; batch adversarial loss: 0.544871\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356815; batch adversarial loss: 0.537599\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414825; batch adversarial loss: 0.561801\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406305; batch adversarial loss: 0.533194\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404895; batch adversarial loss: 0.519324\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368539; batch adversarial loss: 0.588766\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368498; batch adversarial loss: 0.551886\n",
      "epoch 88; iter: 0; batch classifier loss: 0.457536; batch adversarial loss: 0.522305\n",
      "epoch 89; iter: 0; batch classifier loss: 0.506074; batch adversarial loss: 0.561029\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394911; batch adversarial loss: 0.515712\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384999; batch adversarial loss: 0.582519\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404451; batch adversarial loss: 0.507096\n",
      "epoch 93; iter: 0; batch classifier loss: 0.382123; batch adversarial loss: 0.522301\n",
      "epoch 94; iter: 0; batch classifier loss: 0.467345; batch adversarial loss: 0.515508\n",
      "epoch 95; iter: 0; batch classifier loss: 0.390601; batch adversarial loss: 0.511238\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420688; batch adversarial loss: 0.491998\n",
      "epoch 97; iter: 0; batch classifier loss: 0.327691; batch adversarial loss: 0.528303\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396915; batch adversarial loss: 0.564802\n",
      "epoch 99; iter: 0; batch classifier loss: 0.337474; batch adversarial loss: 0.544114\n",
      "epoch 100; iter: 0; batch classifier loss: 0.353421; batch adversarial loss: 0.491477\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407845; batch adversarial loss: 0.576217\n",
      "epoch 102; iter: 0; batch classifier loss: 0.439040; batch adversarial loss: 0.583248\n",
      "epoch 103; iter: 0; batch classifier loss: 0.311262; batch adversarial loss: 0.498694\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428477; batch adversarial loss: 0.592068\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362454; batch adversarial loss: 0.532068\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352313; batch adversarial loss: 0.638323\n",
      "epoch 107; iter: 0; batch classifier loss: 0.299117; batch adversarial loss: 0.525880\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390880; batch adversarial loss: 0.555384\n",
      "epoch 109; iter: 0; batch classifier loss: 0.463908; batch adversarial loss: 0.554169\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377110; batch adversarial loss: 0.517735\n",
      "epoch 111; iter: 0; batch classifier loss: 0.373792; batch adversarial loss: 0.538101\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370206; batch adversarial loss: 0.651343\n",
      "epoch 113; iter: 0; batch classifier loss: 0.322021; batch adversarial loss: 0.571825\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349323; batch adversarial loss: 0.480825\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388020; batch adversarial loss: 0.564910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.320994; batch adversarial loss: 0.463272\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381564; batch adversarial loss: 0.480232\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368160; batch adversarial loss: 0.542866\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323744; batch adversarial loss: 0.571166\n",
      "epoch 120; iter: 0; batch classifier loss: 0.412211; batch adversarial loss: 0.534995\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341914; batch adversarial loss: 0.479487\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386931; batch adversarial loss: 0.540682\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336738; batch adversarial loss: 0.485108\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401257; batch adversarial loss: 0.567072\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359619; batch adversarial loss: 0.555251\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334880; batch adversarial loss: 0.566710\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329739; batch adversarial loss: 0.621430\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432795; batch adversarial loss: 0.554697\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354245; batch adversarial loss: 0.607919\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358493; batch adversarial loss: 0.561434\n",
      "epoch 131; iter: 0; batch classifier loss: 0.461505; batch adversarial loss: 0.543620\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335039; batch adversarial loss: 0.558247\n",
      "epoch 133; iter: 0; batch classifier loss: 0.381154; batch adversarial loss: 0.528551\n",
      "epoch 134; iter: 0; batch classifier loss: 0.380962; batch adversarial loss: 0.611828\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381454; batch adversarial loss: 0.576640\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340173; batch adversarial loss: 0.445463\n",
      "epoch 137; iter: 0; batch classifier loss: 0.345855; batch adversarial loss: 0.527147\n",
      "epoch 138; iter: 0; batch classifier loss: 0.330804; batch adversarial loss: 0.498756\n",
      "epoch 139; iter: 0; batch classifier loss: 0.325786; batch adversarial loss: 0.554102\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367568; batch adversarial loss: 0.526215\n",
      "epoch 141; iter: 0; batch classifier loss: 0.317641; batch adversarial loss: 0.491698\n",
      "epoch 142; iter: 0; batch classifier loss: 0.401598; batch adversarial loss: 0.538369\n",
      "epoch 143; iter: 0; batch classifier loss: 0.318937; batch adversarial loss: 0.492821\n",
      "epoch 144; iter: 0; batch classifier loss: 0.275409; batch adversarial loss: 0.466798\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335133; batch adversarial loss: 0.480463\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347942; batch adversarial loss: 0.500174\n",
      "epoch 147; iter: 0; batch classifier loss: 0.419985; batch adversarial loss: 0.528275\n",
      "epoch 148; iter: 0; batch classifier loss: 0.322010; batch adversarial loss: 0.562329\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368660; batch adversarial loss: 0.544419\n",
      "epoch 150; iter: 0; batch classifier loss: 0.295574; batch adversarial loss: 0.527648\n",
      "epoch 151; iter: 0; batch classifier loss: 0.389455; batch adversarial loss: 0.489049\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331851; batch adversarial loss: 0.509052\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349438; batch adversarial loss: 0.506120\n",
      "epoch 154; iter: 0; batch classifier loss: 0.336610; batch adversarial loss: 0.535230\n",
      "epoch 155; iter: 0; batch classifier loss: 0.338574; batch adversarial loss: 0.643376\n",
      "epoch 156; iter: 0; batch classifier loss: 0.405396; batch adversarial loss: 0.542980\n",
      "epoch 157; iter: 0; batch classifier loss: 0.391887; batch adversarial loss: 0.582172\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396101; batch adversarial loss: 0.466142\n",
      "epoch 159; iter: 0; batch classifier loss: 0.279889; batch adversarial loss: 0.555946\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342748; batch adversarial loss: 0.524692\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354953; batch adversarial loss: 0.590024\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373311; batch adversarial loss: 0.490858\n",
      "epoch 163; iter: 0; batch classifier loss: 0.329221; batch adversarial loss: 0.563233\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368933; batch adversarial loss: 0.583395\n",
      "epoch 165; iter: 0; batch classifier loss: 0.376527; batch adversarial loss: 0.603754\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346002; batch adversarial loss: 0.555202\n",
      "epoch 167; iter: 0; batch classifier loss: 0.386352; batch adversarial loss: 0.559467\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317186; batch adversarial loss: 0.600810\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405690; batch adversarial loss: 0.470015\n",
      "epoch 170; iter: 0; batch classifier loss: 0.478847; batch adversarial loss: 0.566093\n",
      "epoch 171; iter: 0; batch classifier loss: 0.386868; batch adversarial loss: 0.533231\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326865; batch adversarial loss: 0.544659\n",
      "epoch 173; iter: 0; batch classifier loss: 0.311104; batch adversarial loss: 0.552574\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376061; batch adversarial loss: 0.496661\n",
      "epoch 175; iter: 0; batch classifier loss: 0.295367; batch adversarial loss: 0.554659\n",
      "epoch 176; iter: 0; batch classifier loss: 0.294690; batch adversarial loss: 0.585282\n",
      "epoch 177; iter: 0; batch classifier loss: 0.471022; batch adversarial loss: 0.522895\n",
      "epoch 178; iter: 0; batch classifier loss: 0.286159; batch adversarial loss: 0.539302\n",
      "epoch 179; iter: 0; batch classifier loss: 0.292450; batch adversarial loss: 0.540952\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338240; batch adversarial loss: 0.554886\n",
      "epoch 181; iter: 0; batch classifier loss: 0.380029; batch adversarial loss: 0.517013\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358981; batch adversarial loss: 0.543217\n",
      "epoch 183; iter: 0; batch classifier loss: 0.363322; batch adversarial loss: 0.553413\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356573; batch adversarial loss: 0.588297\n",
      "epoch 185; iter: 0; batch classifier loss: 0.453040; batch adversarial loss: 0.549296\n",
      "epoch 186; iter: 0; batch classifier loss: 0.354724; batch adversarial loss: 0.525463\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334283; batch adversarial loss: 0.556368\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348373; batch adversarial loss: 0.495521\n",
      "epoch 189; iter: 0; batch classifier loss: 0.419226; batch adversarial loss: 0.500618\n",
      "epoch 190; iter: 0; batch classifier loss: 0.401488; batch adversarial loss: 0.555014\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360647; batch adversarial loss: 0.517673\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357457; batch adversarial loss: 0.508287\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329437; batch adversarial loss: 0.477037\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360480; batch adversarial loss: 0.553100\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362962; batch adversarial loss: 0.578466\n",
      "epoch 196; iter: 0; batch classifier loss: 0.402059; batch adversarial loss: 0.477282\n",
      "epoch 197; iter: 0; batch classifier loss: 0.409499; batch adversarial loss: 0.535027\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319319; batch adversarial loss: 0.546947\n",
      "epoch 199; iter: 0; batch classifier loss: 0.310707; batch adversarial loss: 0.443367\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680001; batch adversarial loss: 0.868725\n",
      "epoch 1; iter: 0; batch classifier loss: 0.760158; batch adversarial loss: 1.105053\n",
      "epoch 2; iter: 0; batch classifier loss: 0.943013; batch adversarial loss: 1.087058\n",
      "epoch 3; iter: 0; batch classifier loss: 0.872414; batch adversarial loss: 1.005538\n",
      "epoch 4; iter: 0; batch classifier loss: 0.828371; batch adversarial loss: 0.945502\n",
      "epoch 5; iter: 0; batch classifier loss: 0.760348; batch adversarial loss: 0.820359\n",
      "epoch 6; iter: 0; batch classifier loss: 0.748227; batch adversarial loss: 0.748852\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592109; batch adversarial loss: 0.690014\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551927; batch adversarial loss: 0.658372\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573259; batch adversarial loss: 0.635516\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521171; batch adversarial loss: 0.618838\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516529; batch adversarial loss: 0.601474\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496874; batch adversarial loss: 0.615442\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515243; batch adversarial loss: 0.571991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.509617; batch adversarial loss: 0.584666\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569277; batch adversarial loss: 0.584134\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534178; batch adversarial loss: 0.597784\n",
      "epoch 17; iter: 0; batch classifier loss: 0.558320; batch adversarial loss: 0.536787\n",
      "epoch 18; iter: 0; batch classifier loss: 0.596242; batch adversarial loss: 0.596788\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510149; batch adversarial loss: 0.558536\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490314; batch adversarial loss: 0.590362\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514178; batch adversarial loss: 0.615458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.546317; batch adversarial loss: 0.518409\n",
      "epoch 23; iter: 0; batch classifier loss: 0.573755; batch adversarial loss: 0.560408\n",
      "epoch 24; iter: 0; batch classifier loss: 0.545456; batch adversarial loss: 0.574363\n",
      "epoch 25; iter: 0; batch classifier loss: 0.553143; batch adversarial loss: 0.569856\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446495; batch adversarial loss: 0.557191\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537149; batch adversarial loss: 0.529581\n",
      "epoch 28; iter: 0; batch classifier loss: 0.417615; batch adversarial loss: 0.544582\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501558; batch adversarial loss: 0.599071\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470306; batch adversarial loss: 0.574629\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517781; batch adversarial loss: 0.622313\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468388; batch adversarial loss: 0.530767\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404253; batch adversarial loss: 0.562033\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484999; batch adversarial loss: 0.574865\n",
      "epoch 35; iter: 0; batch classifier loss: 0.552150; batch adversarial loss: 0.599428\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447926; batch adversarial loss: 0.557033\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436339; batch adversarial loss: 0.531022\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467502; batch adversarial loss: 0.579160\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424986; batch adversarial loss: 0.493534\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476070; batch adversarial loss: 0.616416\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472369; batch adversarial loss: 0.531771\n",
      "epoch 42; iter: 0; batch classifier loss: 0.525589; batch adversarial loss: 0.555202\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445795; batch adversarial loss: 0.564007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457520; batch adversarial loss: 0.598601\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400528; batch adversarial loss: 0.561704\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378503; batch adversarial loss: 0.520767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.402511; batch adversarial loss: 0.530029\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443799; batch adversarial loss: 0.555239\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450537; batch adversarial loss: 0.505979\n",
      "epoch 50; iter: 0; batch classifier loss: 0.376484; batch adversarial loss: 0.560364\n",
      "epoch 51; iter: 0; batch classifier loss: 0.369771; batch adversarial loss: 0.572550\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434186; batch adversarial loss: 0.573177\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399239; batch adversarial loss: 0.571643\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406936; batch adversarial loss: 0.649163\n",
      "epoch 55; iter: 0; batch classifier loss: 0.347752; batch adversarial loss: 0.517308\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468842; batch adversarial loss: 0.609115\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370043; batch adversarial loss: 0.604639\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388645; batch adversarial loss: 0.526747\n",
      "epoch 59; iter: 0; batch classifier loss: 0.359674; batch adversarial loss: 0.566046\n",
      "epoch 60; iter: 0; batch classifier loss: 0.453612; batch adversarial loss: 0.510391\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426359; batch adversarial loss: 0.552862\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378177; batch adversarial loss: 0.639753\n",
      "epoch 63; iter: 0; batch classifier loss: 0.501280; batch adversarial loss: 0.554404\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422149; batch adversarial loss: 0.615102\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362966; batch adversarial loss: 0.492243\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460751; batch adversarial loss: 0.590835\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381107; batch adversarial loss: 0.519302\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425189; batch adversarial loss: 0.545234\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426324; batch adversarial loss: 0.492735\n",
      "epoch 70; iter: 0; batch classifier loss: 0.529947; batch adversarial loss: 0.544886\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416732; batch adversarial loss: 0.606544\n",
      "epoch 72; iter: 0; batch classifier loss: 0.360176; batch adversarial loss: 0.500902\n",
      "epoch 73; iter: 0; batch classifier loss: 0.357700; batch adversarial loss: 0.596023\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397211; batch adversarial loss: 0.492715\n",
      "epoch 75; iter: 0; batch classifier loss: 0.347852; batch adversarial loss: 0.492353\n",
      "epoch 76; iter: 0; batch classifier loss: 0.356777; batch adversarial loss: 0.605472\n",
      "epoch 77; iter: 0; batch classifier loss: 0.469407; batch adversarial loss: 0.522058\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389410; batch adversarial loss: 0.546396\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386073; batch adversarial loss: 0.589296\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420975; batch adversarial loss: 0.641652\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414371; batch adversarial loss: 0.624809\n",
      "epoch 82; iter: 0; batch classifier loss: 0.323179; batch adversarial loss: 0.530401\n",
      "epoch 83; iter: 0; batch classifier loss: 0.459988; batch adversarial loss: 0.529696\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406767; batch adversarial loss: 0.533639\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373797; batch adversarial loss: 0.587528\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369085; batch adversarial loss: 0.540130\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418169; batch adversarial loss: 0.543972\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423588; batch adversarial loss: 0.525532\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334201; batch adversarial loss: 0.588026\n",
      "epoch 90; iter: 0; batch classifier loss: 0.352821; batch adversarial loss: 0.527717\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354077; batch adversarial loss: 0.551410\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370462; batch adversarial loss: 0.535453\n",
      "epoch 93; iter: 0; batch classifier loss: 0.334437; batch adversarial loss: 0.569862\n",
      "epoch 94; iter: 0; batch classifier loss: 0.350628; batch adversarial loss: 0.571768\n",
      "epoch 95; iter: 0; batch classifier loss: 0.376313; batch adversarial loss: 0.554120\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387752; batch adversarial loss: 0.561269\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436198; batch adversarial loss: 0.641249\n",
      "epoch 98; iter: 0; batch classifier loss: 0.344743; batch adversarial loss: 0.562362\n",
      "epoch 99; iter: 0; batch classifier loss: 0.283992; batch adversarial loss: 0.553628\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417234; batch adversarial loss: 0.510178\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370769; batch adversarial loss: 0.501479\n",
      "epoch 102; iter: 0; batch classifier loss: 0.300506; batch adversarial loss: 0.579442\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361528; batch adversarial loss: 0.596639\n",
      "epoch 104; iter: 0; batch classifier loss: 0.320037; batch adversarial loss: 0.631731\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418350; batch adversarial loss: 0.589450\n",
      "epoch 106; iter: 0; batch classifier loss: 0.346034; batch adversarial loss: 0.586964\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363238; batch adversarial loss: 0.498862\n",
      "epoch 108; iter: 0; batch classifier loss: 0.330094; batch adversarial loss: 0.561068\n",
      "epoch 109; iter: 0; batch classifier loss: 0.343980; batch adversarial loss: 0.505824\n",
      "epoch 110; iter: 0; batch classifier loss: 0.406937; batch adversarial loss: 0.457660\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409025; batch adversarial loss: 0.575245\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396461; batch adversarial loss: 0.582354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.411498; batch adversarial loss: 0.534951\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359616; batch adversarial loss: 0.604693\n",
      "epoch 115; iter: 0; batch classifier loss: 0.319329; batch adversarial loss: 0.561725\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368785; batch adversarial loss: 0.577872\n",
      "epoch 117; iter: 0; batch classifier loss: 0.310698; batch adversarial loss: 0.554915\n",
      "epoch 118; iter: 0; batch classifier loss: 0.306911; batch adversarial loss: 0.598372\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352387; batch adversarial loss: 0.529428\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407197; batch adversarial loss: 0.521104\n",
      "epoch 121; iter: 0; batch classifier loss: 0.338119; batch adversarial loss: 0.588025\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330206; batch adversarial loss: 0.578837\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350363; batch adversarial loss: 0.571191\n",
      "epoch 124; iter: 0; batch classifier loss: 0.411095; batch adversarial loss: 0.501364\n",
      "epoch 125; iter: 0; batch classifier loss: 0.314264; batch adversarial loss: 0.510582\n",
      "epoch 126; iter: 0; batch classifier loss: 0.408966; batch adversarial loss: 0.510626\n",
      "epoch 127; iter: 0; batch classifier loss: 0.313774; batch adversarial loss: 0.572295\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346462; batch adversarial loss: 0.527959\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379443; batch adversarial loss: 0.475744\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380243; batch adversarial loss: 0.604899\n",
      "epoch 131; iter: 0; batch classifier loss: 0.448320; batch adversarial loss: 0.545855\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349826; batch adversarial loss: 0.606263\n",
      "epoch 133; iter: 0; batch classifier loss: 0.292005; batch adversarial loss: 0.518827\n",
      "epoch 134; iter: 0; batch classifier loss: 0.309509; batch adversarial loss: 0.659598\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413536; batch adversarial loss: 0.613737\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339879; batch adversarial loss: 0.501477\n",
      "epoch 137; iter: 0; batch classifier loss: 0.330377; batch adversarial loss: 0.561831\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358349; batch adversarial loss: 0.519973\n",
      "epoch 139; iter: 0; batch classifier loss: 0.315423; batch adversarial loss: 0.571035\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378555; batch adversarial loss: 0.623425\n",
      "epoch 141; iter: 0; batch classifier loss: 0.306858; batch adversarial loss: 0.553909\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389722; batch adversarial loss: 0.596822\n",
      "epoch 143; iter: 0; batch classifier loss: 0.372464; batch adversarial loss: 0.588849\n",
      "epoch 144; iter: 0; batch classifier loss: 0.289883; batch adversarial loss: 0.536495\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390214; batch adversarial loss: 0.544770\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352173; batch adversarial loss: 0.632381\n",
      "epoch 147; iter: 0; batch classifier loss: 0.324503; batch adversarial loss: 0.554099\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331695; batch adversarial loss: 0.580404\n",
      "epoch 149; iter: 0; batch classifier loss: 0.474910; batch adversarial loss: 0.536704\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311264; batch adversarial loss: 0.509789\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322320; batch adversarial loss: 0.615119\n",
      "epoch 152; iter: 0; batch classifier loss: 0.316614; batch adversarial loss: 0.579759\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388780; batch adversarial loss: 0.562655\n",
      "epoch 154; iter: 0; batch classifier loss: 0.423260; batch adversarial loss: 0.501512\n",
      "epoch 155; iter: 0; batch classifier loss: 0.421969; batch adversarial loss: 0.519273\n",
      "epoch 156; iter: 0; batch classifier loss: 0.303763; batch adversarial loss: 0.501261\n",
      "epoch 157; iter: 0; batch classifier loss: 0.436780; batch adversarial loss: 0.622795\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363114; batch adversarial loss: 0.578797\n",
      "epoch 159; iter: 0; batch classifier loss: 0.292391; batch adversarial loss: 0.518613\n",
      "epoch 160; iter: 0; batch classifier loss: 0.482055; batch adversarial loss: 0.458303\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367982; batch adversarial loss: 0.536754\n",
      "epoch 162; iter: 0; batch classifier loss: 0.346981; batch adversarial loss: 0.570757\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403274; batch adversarial loss: 0.606331\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355207; batch adversarial loss: 0.562341\n",
      "epoch 165; iter: 0; batch classifier loss: 0.402957; batch adversarial loss: 0.588049\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347727; batch adversarial loss: 0.587734\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387496; batch adversarial loss: 0.579509\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333934; batch adversarial loss: 0.518240\n",
      "epoch 169; iter: 0; batch classifier loss: 0.389785; batch adversarial loss: 0.579632\n",
      "epoch 170; iter: 0; batch classifier loss: 0.295394; batch adversarial loss: 0.562340\n",
      "epoch 171; iter: 0; batch classifier loss: 0.422780; batch adversarial loss: 0.500689\n",
      "epoch 172; iter: 0; batch classifier loss: 0.390721; batch adversarial loss: 0.675037\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340465; batch adversarial loss: 0.553560\n",
      "epoch 174; iter: 0; batch classifier loss: 0.445456; batch adversarial loss: 0.605631\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326369; batch adversarial loss: 0.596543\n",
      "epoch 176; iter: 0; batch classifier loss: 0.342880; batch adversarial loss: 0.554246\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363080; batch adversarial loss: 0.589413\n",
      "epoch 178; iter: 0; batch classifier loss: 0.385887; batch adversarial loss: 0.597323\n",
      "epoch 179; iter: 0; batch classifier loss: 0.420137; batch adversarial loss: 0.571248\n",
      "epoch 180; iter: 0; batch classifier loss: 0.425424; batch adversarial loss: 0.535980\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395854; batch adversarial loss: 0.613901\n",
      "epoch 182; iter: 0; batch classifier loss: 0.347422; batch adversarial loss: 0.482566\n",
      "epoch 183; iter: 0; batch classifier loss: 0.286423; batch adversarial loss: 0.562092\n",
      "epoch 184; iter: 0; batch classifier loss: 0.405535; batch adversarial loss: 0.632146\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362939; batch adversarial loss: 0.536554\n",
      "epoch 186; iter: 0; batch classifier loss: 0.427173; batch adversarial loss: 0.579820\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359417; batch adversarial loss: 0.642248\n",
      "epoch 188; iter: 0; batch classifier loss: 0.360956; batch adversarial loss: 0.553018\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340567; batch adversarial loss: 0.553709\n",
      "epoch 190; iter: 0; batch classifier loss: 0.356802; batch adversarial loss: 0.518556\n",
      "epoch 191; iter: 0; batch classifier loss: 0.288098; batch adversarial loss: 0.510305\n",
      "epoch 192; iter: 0; batch classifier loss: 0.408027; batch adversarial loss: 0.623467\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332932; batch adversarial loss: 0.475081\n",
      "epoch 194; iter: 0; batch classifier loss: 0.311643; batch adversarial loss: 0.588224\n",
      "epoch 195; iter: 0; batch classifier loss: 0.318053; batch adversarial loss: 0.571506\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301999; batch adversarial loss: 0.527447\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377353; batch adversarial loss: 0.570726\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389736; batch adversarial loss: 0.518691\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331733; batch adversarial loss: 0.553722\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693492; batch adversarial loss: 0.639450\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603963; batch adversarial loss: 0.662234\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615226; batch adversarial loss: 0.641119\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557425; batch adversarial loss: 0.623030\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569264; batch adversarial loss: 0.632142\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583892; batch adversarial loss: 0.575968\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494374; batch adversarial loss: 0.613178\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555363; batch adversarial loss: 0.530172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561385; batch adversarial loss: 0.628720\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535457; batch adversarial loss: 0.564684\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562616; batch adversarial loss: 0.567154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.543276; batch adversarial loss: 0.598472\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598289; batch adversarial loss: 0.564023\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547452; batch adversarial loss: 0.559841\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560364; batch adversarial loss: 0.533765\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500231; batch adversarial loss: 0.543120\n",
      "epoch 16; iter: 0; batch classifier loss: 0.588757; batch adversarial loss: 0.562814\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535989; batch adversarial loss: 0.565338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471483; batch adversarial loss: 0.553601\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482237; batch adversarial loss: 0.479879\n",
      "epoch 20; iter: 0; batch classifier loss: 0.553887; batch adversarial loss: 0.550821\n",
      "epoch 21; iter: 0; batch classifier loss: 0.533053; batch adversarial loss: 0.601040\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454722; batch adversarial loss: 0.541779\n",
      "epoch 23; iter: 0; batch classifier loss: 0.401641; batch adversarial loss: 0.485257\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527927; batch adversarial loss: 0.541019\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510479; batch adversarial loss: 0.578236\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424943; batch adversarial loss: 0.528347\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491213; batch adversarial loss: 0.545937\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514236; batch adversarial loss: 0.511652\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386241; batch adversarial loss: 0.579480\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459697; batch adversarial loss: 0.501753\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435835; batch adversarial loss: 0.535958\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454077; batch adversarial loss: 0.562784\n",
      "epoch 33; iter: 0; batch classifier loss: 0.539066; batch adversarial loss: 0.562369\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480016; batch adversarial loss: 0.588960\n",
      "epoch 35; iter: 0; batch classifier loss: 0.495253; batch adversarial loss: 0.544657\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458642; batch adversarial loss: 0.472591\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458569; batch adversarial loss: 0.607532\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438177; batch adversarial loss: 0.488845\n",
      "epoch 39; iter: 0; batch classifier loss: 0.528829; batch adversarial loss: 0.525799\n",
      "epoch 40; iter: 0; batch classifier loss: 0.502318; batch adversarial loss: 0.619082\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475282; batch adversarial loss: 0.517002\n",
      "epoch 42; iter: 0; batch classifier loss: 0.516764; batch adversarial loss: 0.527988\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398520; batch adversarial loss: 0.505720\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429627; batch adversarial loss: 0.506952\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385804; batch adversarial loss: 0.546322\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434176; batch adversarial loss: 0.552312\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475638; batch adversarial loss: 0.591153\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409475; batch adversarial loss: 0.608294\n",
      "epoch 49; iter: 0; batch classifier loss: 0.361005; batch adversarial loss: 0.526949\n",
      "epoch 50; iter: 0; batch classifier loss: 0.355283; batch adversarial loss: 0.543193\n",
      "epoch 51; iter: 0; batch classifier loss: 0.472224; batch adversarial loss: 0.526016\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427272; batch adversarial loss: 0.526360\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412676; batch adversarial loss: 0.563434\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424476; batch adversarial loss: 0.546370\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431675; batch adversarial loss: 0.563520\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403421; batch adversarial loss: 0.510928\n",
      "epoch 57; iter: 0; batch classifier loss: 0.418376; batch adversarial loss: 0.564836\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411612; batch adversarial loss: 0.545310\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387531; batch adversarial loss: 0.543879\n",
      "epoch 60; iter: 0; batch classifier loss: 0.369431; batch adversarial loss: 0.536538\n",
      "epoch 61; iter: 0; batch classifier loss: 0.484022; batch adversarial loss: 0.552778\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446917; batch adversarial loss: 0.500138\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383065; batch adversarial loss: 0.589808\n",
      "epoch 64; iter: 0; batch classifier loss: 0.462750; batch adversarial loss: 0.562195\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411964; batch adversarial loss: 0.554922\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422883; batch adversarial loss: 0.536232\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388916; batch adversarial loss: 0.645548\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460108; batch adversarial loss: 0.472814\n",
      "epoch 69; iter: 0; batch classifier loss: 0.380569; batch adversarial loss: 0.577854\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402331; batch adversarial loss: 0.536140\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407735; batch adversarial loss: 0.547131\n",
      "epoch 72; iter: 0; batch classifier loss: 0.425028; batch adversarial loss: 0.526156\n",
      "epoch 73; iter: 0; batch classifier loss: 0.460493; batch adversarial loss: 0.542806\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457802; batch adversarial loss: 0.499641\n",
      "epoch 75; iter: 0; batch classifier loss: 0.439901; batch adversarial loss: 0.552611\n",
      "epoch 76; iter: 0; batch classifier loss: 0.492064; batch adversarial loss: 0.543302\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412987; batch adversarial loss: 0.579487\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415382; batch adversarial loss: 0.480243\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419278; batch adversarial loss: 0.543009\n",
      "epoch 80; iter: 0; batch classifier loss: 0.458541; batch adversarial loss: 0.534013\n",
      "epoch 81; iter: 0; batch classifier loss: 0.322536; batch adversarial loss: 0.556167\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407170; batch adversarial loss: 0.598905\n",
      "epoch 83; iter: 0; batch classifier loss: 0.475908; batch adversarial loss: 0.516226\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449634; batch adversarial loss: 0.543354\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416805; batch adversarial loss: 0.520025\n",
      "epoch 86; iter: 0; batch classifier loss: 0.473623; batch adversarial loss: 0.500422\n",
      "epoch 87; iter: 0; batch classifier loss: 0.313511; batch adversarial loss: 0.552280\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391002; batch adversarial loss: 0.537086\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380542; batch adversarial loss: 0.543807\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393169; batch adversarial loss: 0.555087\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405046; batch adversarial loss: 0.512480\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408347; batch adversarial loss: 0.515625\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420279; batch adversarial loss: 0.600189\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383925; batch adversarial loss: 0.498634\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362123; batch adversarial loss: 0.508521\n",
      "epoch 96; iter: 0; batch classifier loss: 0.467762; batch adversarial loss: 0.509959\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418218; batch adversarial loss: 0.552836\n",
      "epoch 98; iter: 0; batch classifier loss: 0.338858; batch adversarial loss: 0.487968\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375036; batch adversarial loss: 0.499669\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368603; batch adversarial loss: 0.593877\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367206; batch adversarial loss: 0.514387\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400470; batch adversarial loss: 0.454188\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364467; batch adversarial loss: 0.577128\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397855; batch adversarial loss: 0.544475\n",
      "epoch 105; iter: 0; batch classifier loss: 0.377701; batch adversarial loss: 0.524068\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335459; batch adversarial loss: 0.564083\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393721; batch adversarial loss: 0.508112\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387809; batch adversarial loss: 0.544565\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381593; batch adversarial loss: 0.584296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.330194; batch adversarial loss: 0.552894\n",
      "epoch 111; iter: 0; batch classifier loss: 0.331513; batch adversarial loss: 0.569318\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339308; batch adversarial loss: 0.422570\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347147; batch adversarial loss: 0.461624\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384301; batch adversarial loss: 0.536206\n",
      "epoch 115; iter: 0; batch classifier loss: 0.288469; batch adversarial loss: 0.545208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351321; batch adversarial loss: 0.582308\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393954; batch adversarial loss: 0.541519\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395516; batch adversarial loss: 0.524046\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370689; batch adversarial loss: 0.554041\n",
      "epoch 120; iter: 0; batch classifier loss: 0.498802; batch adversarial loss: 0.508257\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420452; batch adversarial loss: 0.609327\n",
      "epoch 122; iter: 0; batch classifier loss: 0.420954; batch adversarial loss: 0.532853\n",
      "epoch 123; iter: 0; batch classifier loss: 0.326778; batch adversarial loss: 0.500726\n",
      "epoch 124; iter: 0; batch classifier loss: 0.351843; batch adversarial loss: 0.582839\n",
      "epoch 125; iter: 0; batch classifier loss: 0.381812; batch adversarial loss: 0.495837\n",
      "epoch 126; iter: 0; batch classifier loss: 0.448062; batch adversarial loss: 0.565025\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408966; batch adversarial loss: 0.488631\n",
      "epoch 128; iter: 0; batch classifier loss: 0.459001; batch adversarial loss: 0.495394\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367381; batch adversarial loss: 0.564728\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386320; batch adversarial loss: 0.516662\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373396; batch adversarial loss: 0.595607\n",
      "epoch 132; iter: 0; batch classifier loss: 0.362719; batch adversarial loss: 0.545562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.365551; batch adversarial loss: 0.523341\n",
      "epoch 134; iter: 0; batch classifier loss: 0.408286; batch adversarial loss: 0.598986\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382840; batch adversarial loss: 0.515907\n",
      "epoch 136; iter: 0; batch classifier loss: 0.318626; batch adversarial loss: 0.563926\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332109; batch adversarial loss: 0.479741\n",
      "epoch 138; iter: 0; batch classifier loss: 0.465717; batch adversarial loss: 0.525769\n",
      "epoch 139; iter: 0; batch classifier loss: 0.507032; batch adversarial loss: 0.499924\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341729; batch adversarial loss: 0.502324\n",
      "epoch 141; iter: 0; batch classifier loss: 0.308271; batch adversarial loss: 0.563505\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381756; batch adversarial loss: 0.507736\n",
      "epoch 143; iter: 0; batch classifier loss: 0.416340; batch adversarial loss: 0.553934\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348308; batch adversarial loss: 0.524839\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379342; batch adversarial loss: 0.533736\n",
      "epoch 146; iter: 0; batch classifier loss: 0.415986; batch adversarial loss: 0.580598\n",
      "epoch 147; iter: 0; batch classifier loss: 0.364172; batch adversarial loss: 0.610359\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341480; batch adversarial loss: 0.637832\n",
      "epoch 149; iter: 0; batch classifier loss: 0.413651; batch adversarial loss: 0.607570\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409235; batch adversarial loss: 0.480779\n",
      "epoch 151; iter: 0; batch classifier loss: 0.414218; batch adversarial loss: 0.479196\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374847; batch adversarial loss: 0.589869\n",
      "epoch 153; iter: 0; batch classifier loss: 0.359399; batch adversarial loss: 0.561422\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390657; batch adversarial loss: 0.512419\n",
      "epoch 155; iter: 0; batch classifier loss: 0.236448; batch adversarial loss: 0.546298\n",
      "epoch 156; iter: 0; batch classifier loss: 0.343713; batch adversarial loss: 0.570243\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371672; batch adversarial loss: 0.509360\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353817; batch adversarial loss: 0.489095\n",
      "epoch 159; iter: 0; batch classifier loss: 0.412546; batch adversarial loss: 0.575161\n",
      "epoch 160; iter: 0; batch classifier loss: 0.418688; batch adversarial loss: 0.516233\n",
      "epoch 161; iter: 0; batch classifier loss: 0.393301; batch adversarial loss: 0.498194\n",
      "epoch 162; iter: 0; batch classifier loss: 0.466871; batch adversarial loss: 0.638971\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362815; batch adversarial loss: 0.490148\n",
      "epoch 164; iter: 0; batch classifier loss: 0.321855; batch adversarial loss: 0.519470\n",
      "epoch 165; iter: 0; batch classifier loss: 0.421624; batch adversarial loss: 0.570124\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370315; batch adversarial loss: 0.487859\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324163; batch adversarial loss: 0.548267\n",
      "epoch 168; iter: 0; batch classifier loss: 0.433082; batch adversarial loss: 0.572354\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381097; batch adversarial loss: 0.521521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.320274; batch adversarial loss: 0.588666\n",
      "epoch 171; iter: 0; batch classifier loss: 0.433583; batch adversarial loss: 0.515213\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391179; batch adversarial loss: 0.609068\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359203; batch adversarial loss: 0.506010\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393599; batch adversarial loss: 0.487361\n",
      "epoch 175; iter: 0; batch classifier loss: 0.408795; batch adversarial loss: 0.535993\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346237; batch adversarial loss: 0.562708\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324540; batch adversarial loss: 0.536756\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314361; batch adversarial loss: 0.579493\n",
      "epoch 179; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.459447\n",
      "epoch 180; iter: 0; batch classifier loss: 0.410667; batch adversarial loss: 0.534034\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410421; batch adversarial loss: 0.506832\n",
      "epoch 182; iter: 0; batch classifier loss: 0.392633; batch adversarial loss: 0.526442\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341634; batch adversarial loss: 0.582049\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378008; batch adversarial loss: 0.498213\n",
      "epoch 185; iter: 0; batch classifier loss: 0.401549; batch adversarial loss: 0.561260\n",
      "epoch 186; iter: 0; batch classifier loss: 0.322953; batch adversarial loss: 0.584098\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376702; batch adversarial loss: 0.591615\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348769; batch adversarial loss: 0.481048\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379448; batch adversarial loss: 0.591623\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386356; batch adversarial loss: 0.582440\n",
      "epoch 191; iter: 0; batch classifier loss: 0.394190; batch adversarial loss: 0.507747\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336602; batch adversarial loss: 0.552702\n",
      "epoch 193; iter: 0; batch classifier loss: 0.386250; batch adversarial loss: 0.506473\n",
      "epoch 194; iter: 0; batch classifier loss: 0.455996; batch adversarial loss: 0.523748\n",
      "epoch 195; iter: 0; batch classifier loss: 0.458318; batch adversarial loss: 0.497160\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392398; batch adversarial loss: 0.589819\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396069; batch adversarial loss: 0.663596\n",
      "epoch 198; iter: 0; batch classifier loss: 0.276822; batch adversarial loss: 0.505542\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338755; batch adversarial loss: 0.582892\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734133; batch adversarial loss: 0.752180\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632661; batch adversarial loss: 0.711079\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587702; batch adversarial loss: 0.679625\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591640; batch adversarial loss: 0.651854\n",
      "epoch 4; iter: 0; batch classifier loss: 0.608794; batch adversarial loss: 0.646405\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607548; batch adversarial loss: 0.601965\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492453; batch adversarial loss: 0.597998\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527203; batch adversarial loss: 0.558570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.516158; batch adversarial loss: 0.565520\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556493; batch adversarial loss: 0.561600\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518876; batch adversarial loss: 0.570887\n",
      "epoch 11; iter: 0; batch classifier loss: 0.660557; batch adversarial loss: 0.553271\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501774; batch adversarial loss: 0.568066\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540170; batch adversarial loss: 0.498494\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533287; batch adversarial loss: 0.606204\n",
      "epoch 15; iter: 0; batch classifier loss: 0.559938; batch adversarial loss: 0.533555\n",
      "epoch 16; iter: 0; batch classifier loss: 0.557949; batch adversarial loss: 0.570167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.558109; batch adversarial loss: 0.584504\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505493; batch adversarial loss: 0.560110\n",
      "epoch 19; iter: 0; batch classifier loss: 0.604516; batch adversarial loss: 0.498796\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572152; batch adversarial loss: 0.581948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487814; batch adversarial loss: 0.495382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.508223; batch adversarial loss: 0.582557\n",
      "epoch 23; iter: 0; batch classifier loss: 0.570127; batch adversarial loss: 0.536568\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524184; batch adversarial loss: 0.563824\n",
      "epoch 25; iter: 0; batch classifier loss: 0.529008; batch adversarial loss: 0.571762\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463536; batch adversarial loss: 0.580982\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494061; batch adversarial loss: 0.499604\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507430; batch adversarial loss: 0.553656\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474519; batch adversarial loss: 0.489899\n",
      "epoch 30; iter: 0; batch classifier loss: 0.494834; batch adversarial loss: 0.569926\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440175; batch adversarial loss: 0.528642\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400927; batch adversarial loss: 0.554555\n",
      "epoch 33; iter: 0; batch classifier loss: 0.418750; batch adversarial loss: 0.597474\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509498; batch adversarial loss: 0.528025\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456046; batch adversarial loss: 0.599119\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439354; batch adversarial loss: 0.562401\n",
      "epoch 37; iter: 0; batch classifier loss: 0.433816; batch adversarial loss: 0.595516\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425975; batch adversarial loss: 0.564688\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439384; batch adversarial loss: 0.544977\n",
      "epoch 40; iter: 0; batch classifier loss: 0.489329; batch adversarial loss: 0.582035\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377124; batch adversarial loss: 0.563529\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398003; batch adversarial loss: 0.552284\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464588; batch adversarial loss: 0.525004\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438625; batch adversarial loss: 0.562045\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449098; batch adversarial loss: 0.499571\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452233; batch adversarial loss: 0.608596\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469069; batch adversarial loss: 0.543868\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433351; batch adversarial loss: 0.590748\n",
      "epoch 49; iter: 0; batch classifier loss: 0.454849; batch adversarial loss: 0.563211\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449439; batch adversarial loss: 0.590607\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390932; batch adversarial loss: 0.637505\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462912; batch adversarial loss: 0.581229\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388894; batch adversarial loss: 0.499409\n",
      "epoch 54; iter: 0; batch classifier loss: 0.488007; batch adversarial loss: 0.683435\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422828; batch adversarial loss: 0.591670\n",
      "epoch 56; iter: 0; batch classifier loss: 0.471560; batch adversarial loss: 0.535838\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454708; batch adversarial loss: 0.543405\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450804; batch adversarial loss: 0.489863\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420028; batch adversarial loss: 0.534868\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406453; batch adversarial loss: 0.588941\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402627; batch adversarial loss: 0.516909\n",
      "epoch 62; iter: 0; batch classifier loss: 0.320513; batch adversarial loss: 0.505545\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454752; batch adversarial loss: 0.534840\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454877; batch adversarial loss: 0.638568\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442490; batch adversarial loss: 0.610797\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423295; batch adversarial loss: 0.563718\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399084; batch adversarial loss: 0.451598\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422913; batch adversarial loss: 0.507630\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414266; batch adversarial loss: 0.545226\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467549; batch adversarial loss: 0.469773\n",
      "epoch 71; iter: 0; batch classifier loss: 0.458323; batch adversarial loss: 0.469736\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415499; batch adversarial loss: 0.469101\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421125; batch adversarial loss: 0.562772\n",
      "epoch 74; iter: 0; batch classifier loss: 0.341856; batch adversarial loss: 0.507500\n",
      "epoch 75; iter: 0; batch classifier loss: 0.462704; batch adversarial loss: 0.480874\n",
      "epoch 76; iter: 0; batch classifier loss: 0.433209; batch adversarial loss: 0.524797\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355611; batch adversarial loss: 0.516519\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371982; batch adversarial loss: 0.488733\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374587; batch adversarial loss: 0.563841\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427220; batch adversarial loss: 0.599856\n",
      "epoch 81; iter: 0; batch classifier loss: 0.350812; batch adversarial loss: 0.562442\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342917; batch adversarial loss: 0.563619\n",
      "epoch 83; iter: 0; batch classifier loss: 0.344836; batch adversarial loss: 0.461003\n",
      "epoch 84; iter: 0; batch classifier loss: 0.484308; batch adversarial loss: 0.581222\n",
      "epoch 85; iter: 0; batch classifier loss: 0.458719; batch adversarial loss: 0.498430\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440493; batch adversarial loss: 0.544544\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397793; batch adversarial loss: 0.544447\n",
      "epoch 88; iter: 0; batch classifier loss: 0.327232; batch adversarial loss: 0.619751\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395030; batch adversarial loss: 0.609740\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403233; batch adversarial loss: 0.479823\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394408; batch adversarial loss: 0.572405\n",
      "epoch 92; iter: 0; batch classifier loss: 0.345078; batch adversarial loss: 0.563376\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402669; batch adversarial loss: 0.517709\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378849; batch adversarial loss: 0.497436\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420643; batch adversarial loss: 0.526556\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372982; batch adversarial loss: 0.516931\n",
      "epoch 97; iter: 0; batch classifier loss: 0.470689; batch adversarial loss: 0.536492\n",
      "epoch 98; iter: 0; batch classifier loss: 0.455036; batch adversarial loss: 0.497710\n",
      "epoch 99; iter: 0; batch classifier loss: 0.481691; batch adversarial loss: 0.581734\n",
      "epoch 100; iter: 0; batch classifier loss: 0.429555; batch adversarial loss: 0.497751\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352895; batch adversarial loss: 0.535870\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357383; batch adversarial loss: 0.507689\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414798; batch adversarial loss: 0.600039\n",
      "epoch 104; iter: 0; batch classifier loss: 0.304556; batch adversarial loss: 0.573466\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417884; batch adversarial loss: 0.536467\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386175; batch adversarial loss: 0.600075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.428486; batch adversarial loss: 0.536570\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411268; batch adversarial loss: 0.654672\n",
      "epoch 109; iter: 0; batch classifier loss: 0.336046; batch adversarial loss: 0.599203\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383308; batch adversarial loss: 0.536197\n",
      "epoch 111; iter: 0; batch classifier loss: 0.432527; batch adversarial loss: 0.628276\n",
      "epoch 112; iter: 0; batch classifier loss: 0.303490; batch adversarial loss: 0.543576\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377460; batch adversarial loss: 0.478655\n",
      "epoch 114; iter: 0; batch classifier loss: 0.453788; batch adversarial loss: 0.562746\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411755; batch adversarial loss: 0.506196\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364608; batch adversarial loss: 0.562620\n",
      "epoch 117; iter: 0; batch classifier loss: 0.423544; batch adversarial loss: 0.535712\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340670; batch adversarial loss: 0.525751\n",
      "epoch 119; iter: 0; batch classifier loss: 0.298471; batch adversarial loss: 0.563232\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350038; batch adversarial loss: 0.498127\n",
      "epoch 121; iter: 0; batch classifier loss: 0.459913; batch adversarial loss: 0.581183\n",
      "epoch 122; iter: 0; batch classifier loss: 0.435731; batch adversarial loss: 0.553602\n",
      "epoch 123; iter: 0; batch classifier loss: 0.345087; batch adversarial loss: 0.563823\n",
      "epoch 124; iter: 0; batch classifier loss: 0.350304; batch adversarial loss: 0.478526\n",
      "epoch 125; iter: 0; batch classifier loss: 0.445401; batch adversarial loss: 0.581354\n",
      "epoch 126; iter: 0; batch classifier loss: 0.284947; batch adversarial loss: 0.507600\n",
      "epoch 127; iter: 0; batch classifier loss: 0.398983; batch adversarial loss: 0.545634\n",
      "epoch 128; iter: 0; batch classifier loss: 0.445896; batch adversarial loss: 0.554196\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319797; batch adversarial loss: 0.572451\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421204; batch adversarial loss: 0.461778\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400777; batch adversarial loss: 0.591518\n",
      "epoch 132; iter: 0; batch classifier loss: 0.405495; batch adversarial loss: 0.497854\n",
      "epoch 133; iter: 0; batch classifier loss: 0.442497; batch adversarial loss: 0.582894\n",
      "epoch 134; iter: 0; batch classifier loss: 0.405220; batch adversarial loss: 0.470312\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397616; batch adversarial loss: 0.609777\n",
      "epoch 136; iter: 0; batch classifier loss: 0.429015; batch adversarial loss: 0.609924\n",
      "epoch 137; iter: 0; batch classifier loss: 0.394517; batch adversarial loss: 0.628169\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341000; batch adversarial loss: 0.516482\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381502; batch adversarial loss: 0.535594\n",
      "epoch 140; iter: 0; batch classifier loss: 0.316829; batch adversarial loss: 0.553522\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380410; batch adversarial loss: 0.499479\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400153; batch adversarial loss: 0.527433\n",
      "epoch 143; iter: 0; batch classifier loss: 0.403283; batch adversarial loss: 0.461432\n",
      "epoch 144; iter: 0; batch classifier loss: 0.469431; batch adversarial loss: 0.497548\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353948; batch adversarial loss: 0.544002\n",
      "epoch 146; iter: 0; batch classifier loss: 0.320970; batch adversarial loss: 0.506908\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359133; batch adversarial loss: 0.627605\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365034; batch adversarial loss: 0.562941\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347639; batch adversarial loss: 0.571226\n",
      "epoch 150; iter: 0; batch classifier loss: 0.445778; batch adversarial loss: 0.544597\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326995; batch adversarial loss: 0.573087\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357349; batch adversarial loss: 0.545701\n",
      "epoch 153; iter: 0; batch classifier loss: 0.512952; batch adversarial loss: 0.600461\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319582; batch adversarial loss: 0.563249\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355763; batch adversarial loss: 0.516908\n",
      "epoch 156; iter: 0; batch classifier loss: 0.425071; batch adversarial loss: 0.552595\n",
      "epoch 157; iter: 0; batch classifier loss: 0.378426; batch adversarial loss: 0.497851\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356325; batch adversarial loss: 0.572172\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370020; batch adversarial loss: 0.525562\n",
      "epoch 160; iter: 0; batch classifier loss: 0.416566; batch adversarial loss: 0.553145\n",
      "epoch 161; iter: 0; batch classifier loss: 0.431650; batch adversarial loss: 0.582471\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361235; batch adversarial loss: 0.526278\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356864; batch adversarial loss: 0.637287\n",
      "epoch 164; iter: 0; batch classifier loss: 0.469508; batch adversarial loss: 0.507857\n",
      "epoch 165; iter: 0; batch classifier loss: 0.337244; batch adversarial loss: 0.516126\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376177; batch adversarial loss: 0.563029\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382610; batch adversarial loss: 0.562327\n",
      "epoch 168; iter: 0; batch classifier loss: 0.292034; batch adversarial loss: 0.553580\n",
      "epoch 169; iter: 0; batch classifier loss: 0.317164; batch adversarial loss: 0.535975\n",
      "epoch 170; iter: 0; batch classifier loss: 0.402069; batch adversarial loss: 0.544262\n",
      "epoch 171; iter: 0; batch classifier loss: 0.405283; batch adversarial loss: 0.599958\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363176; batch adversarial loss: 0.618277\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375943; batch adversarial loss: 0.488909\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325625; batch adversarial loss: 0.526009\n",
      "epoch 175; iter: 0; batch classifier loss: 0.324579; batch adversarial loss: 0.526126\n",
      "epoch 176; iter: 0; batch classifier loss: 0.337530; batch adversarial loss: 0.553681\n",
      "epoch 177; iter: 0; batch classifier loss: 0.401270; batch adversarial loss: 0.581755\n",
      "epoch 178; iter: 0; batch classifier loss: 0.277638; batch adversarial loss: 0.618575\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344428; batch adversarial loss: 0.507963\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334908; batch adversarial loss: 0.544856\n",
      "epoch 181; iter: 0; batch classifier loss: 0.390226; batch adversarial loss: 0.609834\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387778; batch adversarial loss: 0.460957\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330163; batch adversarial loss: 0.553795\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380231; batch adversarial loss: 0.507177\n",
      "epoch 185; iter: 0; batch classifier loss: 0.275323; batch adversarial loss: 0.553451\n",
      "epoch 186; iter: 0; batch classifier loss: 0.302549; batch adversarial loss: 0.600779\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345042; batch adversarial loss: 0.600461\n",
      "epoch 188; iter: 0; batch classifier loss: 0.305998; batch adversarial loss: 0.534408\n",
      "epoch 189; iter: 0; batch classifier loss: 0.426904; batch adversarial loss: 0.506926\n",
      "epoch 190; iter: 0; batch classifier loss: 0.426485; batch adversarial loss: 0.590802\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346497; batch adversarial loss: 0.590559\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332785; batch adversarial loss: 0.488035\n",
      "epoch 193; iter: 0; batch classifier loss: 0.297275; batch adversarial loss: 0.535766\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344441; batch adversarial loss: 0.553609\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338601; batch adversarial loss: 0.525186\n",
      "epoch 196; iter: 0; batch classifier loss: 0.333968; batch adversarial loss: 0.581561\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370880; batch adversarial loss: 0.553276\n",
      "epoch 198; iter: 0; batch classifier loss: 0.391895; batch adversarial loss: 0.609434\n",
      "epoch 199; iter: 0; batch classifier loss: 0.475976; batch adversarial loss: 0.525081\n",
      "epoch 0; iter: 0; batch classifier loss: 0.800990; batch adversarial loss: 0.711482\n",
      "epoch 1; iter: 0; batch classifier loss: 0.659424; batch adversarial loss: 0.692353\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595453; batch adversarial loss: 0.652507\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581603; batch adversarial loss: 0.623505\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586875; batch adversarial loss: 0.617448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.626685; batch adversarial loss: 0.583672\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557641; batch adversarial loss: 0.591219\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507642; batch adversarial loss: 0.597541\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557006; batch adversarial loss: 0.551558\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541957; batch adversarial loss: 0.526392\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556398; batch adversarial loss: 0.590947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508527; batch adversarial loss: 0.545381\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543613; batch adversarial loss: 0.599556\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499060; batch adversarial loss: 0.598358\n",
      "epoch 14; iter: 0; batch classifier loss: 0.614076; batch adversarial loss: 0.549209\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526510; batch adversarial loss: 0.569993\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508039; batch adversarial loss: 0.591004\n",
      "epoch 17; iter: 0; batch classifier loss: 0.538606; batch adversarial loss: 0.555130\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491431; batch adversarial loss: 0.636508\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530197; batch adversarial loss: 0.604964\n",
      "epoch 20; iter: 0; batch classifier loss: 0.611940; batch adversarial loss: 0.596646\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516859; batch adversarial loss: 0.555844\n",
      "epoch 22; iter: 0; batch classifier loss: 0.558078; batch adversarial loss: 0.651889\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418625; batch adversarial loss: 0.569807\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490202; batch adversarial loss: 0.605078\n",
      "epoch 25; iter: 0; batch classifier loss: 0.572473; batch adversarial loss: 0.516736\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448747; batch adversarial loss: 0.551910\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491702; batch adversarial loss: 0.523807\n",
      "epoch 28; iter: 0; batch classifier loss: 0.504310; batch adversarial loss: 0.561518\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456883; batch adversarial loss: 0.480536\n",
      "epoch 30; iter: 0; batch classifier loss: 0.447222; batch adversarial loss: 0.545963\n",
      "epoch 31; iter: 0; batch classifier loss: 0.520674; batch adversarial loss: 0.486425\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478082; batch adversarial loss: 0.554270\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425768; batch adversarial loss: 0.518210\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436514; batch adversarial loss: 0.537783\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441349; batch adversarial loss: 0.652763\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466009; batch adversarial loss: 0.627758\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473000; batch adversarial loss: 0.509381\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497559; batch adversarial loss: 0.494426\n",
      "epoch 39; iter: 0; batch classifier loss: 0.505813; batch adversarial loss: 0.452703\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522663; batch adversarial loss: 0.588986\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481204; batch adversarial loss: 0.523899\n",
      "epoch 42; iter: 0; batch classifier loss: 0.375774; batch adversarial loss: 0.569274\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403354; batch adversarial loss: 0.543763\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434774; batch adversarial loss: 0.587257\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467667; batch adversarial loss: 0.507991\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438184; batch adversarial loss: 0.477863\n",
      "epoch 47; iter: 0; batch classifier loss: 0.474502; batch adversarial loss: 0.538654\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468271; batch adversarial loss: 0.518266\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457951; batch adversarial loss: 0.519752\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472307; batch adversarial loss: 0.592258\n",
      "epoch 51; iter: 0; batch classifier loss: 0.389145; batch adversarial loss: 0.482695\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391101; batch adversarial loss: 0.528603\n",
      "epoch 53; iter: 0; batch classifier loss: 0.468036; batch adversarial loss: 0.588249\n",
      "epoch 54; iter: 0; batch classifier loss: 0.457644; batch adversarial loss: 0.588155\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430490; batch adversarial loss: 0.619036\n",
      "epoch 56; iter: 0; batch classifier loss: 0.492943; batch adversarial loss: 0.561637\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432320; batch adversarial loss: 0.526383\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378654; batch adversarial loss: 0.452941\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462308; batch adversarial loss: 0.559291\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393720; batch adversarial loss: 0.525428\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416928; batch adversarial loss: 0.583597\n",
      "epoch 62; iter: 0; batch classifier loss: 0.402250; batch adversarial loss: 0.544596\n",
      "epoch 63; iter: 0; batch classifier loss: 0.486086; batch adversarial loss: 0.505277\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420672; batch adversarial loss: 0.489812\n",
      "epoch 65; iter: 0; batch classifier loss: 0.351396; batch adversarial loss: 0.557040\n",
      "epoch 66; iter: 0; batch classifier loss: 0.394483; batch adversarial loss: 0.556150\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401625; batch adversarial loss: 0.589252\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405707; batch adversarial loss: 0.526528\n",
      "epoch 69; iter: 0; batch classifier loss: 0.489641; batch adversarial loss: 0.527200\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392007; batch adversarial loss: 0.545281\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373375; batch adversarial loss: 0.508125\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429377; batch adversarial loss: 0.491037\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393173; batch adversarial loss: 0.553925\n",
      "epoch 74; iter: 0; batch classifier loss: 0.434906; batch adversarial loss: 0.609340\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404016; batch adversarial loss: 0.507080\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408222; batch adversarial loss: 0.535865\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379529; batch adversarial loss: 0.525765\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409788; batch adversarial loss: 0.546836\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382308; batch adversarial loss: 0.610399\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419106; batch adversarial loss: 0.616782\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384193; batch adversarial loss: 0.412871\n",
      "epoch 82; iter: 0; batch classifier loss: 0.479461; batch adversarial loss: 0.561538\n",
      "epoch 83; iter: 0; batch classifier loss: 0.335891; batch adversarial loss: 0.581026\n",
      "epoch 84; iter: 0; batch classifier loss: 0.425129; batch adversarial loss: 0.561645\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427909; batch adversarial loss: 0.481078\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401732; batch adversarial loss: 0.490778\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387444; batch adversarial loss: 0.562932\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379390; batch adversarial loss: 0.562583\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398597; batch adversarial loss: 0.507534\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387734; batch adversarial loss: 0.526347\n",
      "epoch 91; iter: 0; batch classifier loss: 0.455395; batch adversarial loss: 0.608247\n",
      "epoch 92; iter: 0; batch classifier loss: 0.298914; batch adversarial loss: 0.487893\n",
      "epoch 93; iter: 0; batch classifier loss: 0.351089; batch adversarial loss: 0.517805\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363623; batch adversarial loss: 0.553959\n",
      "epoch 95; iter: 0; batch classifier loss: 0.448212; batch adversarial loss: 0.544400\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392246; batch adversarial loss: 0.628207\n",
      "epoch 97; iter: 0; batch classifier loss: 0.335483; batch adversarial loss: 0.580526\n",
      "epoch 98; iter: 0; batch classifier loss: 0.360796; batch adversarial loss: 0.684155\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425917; batch adversarial loss: 0.505963\n",
      "epoch 100; iter: 0; batch classifier loss: 0.436692; batch adversarial loss: 0.544833\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324567; batch adversarial loss: 0.517297\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376472; batch adversarial loss: 0.487293\n",
      "epoch 103; iter: 0; batch classifier loss: 0.355563; batch adversarial loss: 0.636700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.409544; batch adversarial loss: 0.589140\n",
      "epoch 105; iter: 0; batch classifier loss: 0.458785; batch adversarial loss: 0.562721\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386415; batch adversarial loss: 0.551664\n",
      "epoch 107; iter: 0; batch classifier loss: 0.416398; batch adversarial loss: 0.562322\n",
      "epoch 108; iter: 0; batch classifier loss: 0.339805; batch adversarial loss: 0.608881\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367827; batch adversarial loss: 0.570610\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351764; batch adversarial loss: 0.491175\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365580; batch adversarial loss: 0.635506\n",
      "epoch 112; iter: 0; batch classifier loss: 0.345332; batch adversarial loss: 0.527119\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355760; batch adversarial loss: 0.544876\n",
      "epoch 114; iter: 0; batch classifier loss: 0.302082; batch adversarial loss: 0.528307\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372155; batch adversarial loss: 0.615989\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343138; batch adversarial loss: 0.579458\n",
      "epoch 117; iter: 0; batch classifier loss: 0.474181; batch adversarial loss: 0.478700\n",
      "epoch 118; iter: 0; batch classifier loss: 0.346888; batch adversarial loss: 0.581997\n",
      "epoch 119; iter: 0; batch classifier loss: 0.445129; batch adversarial loss: 0.505832\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381983; batch adversarial loss: 0.582174\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393909; batch adversarial loss: 0.517809\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392287; batch adversarial loss: 0.552653\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343380; batch adversarial loss: 0.510624\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369866; batch adversarial loss: 0.544632\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362599; batch adversarial loss: 0.553681\n",
      "epoch 126; iter: 0; batch classifier loss: 0.335354; batch adversarial loss: 0.572078\n",
      "epoch 127; iter: 0; batch classifier loss: 0.476280; batch adversarial loss: 0.517957\n",
      "epoch 128; iter: 0; batch classifier loss: 0.311811; batch adversarial loss: 0.644386\n",
      "epoch 129; iter: 0; batch classifier loss: 0.408757; batch adversarial loss: 0.525467\n",
      "epoch 130; iter: 0; batch classifier loss: 0.420319; batch adversarial loss: 0.487986\n",
      "epoch 131; iter: 0; batch classifier loss: 0.283311; batch adversarial loss: 0.489660\n",
      "epoch 132; iter: 0; batch classifier loss: 0.412281; batch adversarial loss: 0.583817\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398045; batch adversarial loss: 0.490882\n",
      "epoch 134; iter: 0; batch classifier loss: 0.407651; batch adversarial loss: 0.526190\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373360; batch adversarial loss: 0.515618\n",
      "epoch 136; iter: 0; batch classifier loss: 0.374718; batch adversarial loss: 0.491819\n",
      "epoch 137; iter: 0; batch classifier loss: 0.433585; batch adversarial loss: 0.470249\n",
      "epoch 138; iter: 0; batch classifier loss: 0.402527; batch adversarial loss: 0.544451\n",
      "epoch 139; iter: 0; batch classifier loss: 0.531393; batch adversarial loss: 0.526023\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309025; batch adversarial loss: 0.525212\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337548; batch adversarial loss: 0.515776\n",
      "epoch 142; iter: 0; batch classifier loss: 0.404347; batch adversarial loss: 0.598567\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386460; batch adversarial loss: 0.608300\n",
      "epoch 144; iter: 0; batch classifier loss: 0.402469; batch adversarial loss: 0.560878\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367253; batch adversarial loss: 0.536063\n",
      "epoch 146; iter: 0; batch classifier loss: 0.310915; batch adversarial loss: 0.564436\n",
      "epoch 147; iter: 0; batch classifier loss: 0.366116; batch adversarial loss: 0.508255\n",
      "epoch 148; iter: 0; batch classifier loss: 0.352119; batch adversarial loss: 0.488748\n",
      "epoch 149; iter: 0; batch classifier loss: 0.291388; batch adversarial loss: 0.544200\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363427; batch adversarial loss: 0.473102\n",
      "epoch 151; iter: 0; batch classifier loss: 0.307826; batch adversarial loss: 0.564066\n",
      "epoch 152; iter: 0; batch classifier loss: 0.337278; batch adversarial loss: 0.544339\n",
      "epoch 153; iter: 0; batch classifier loss: 0.377875; batch adversarial loss: 0.554063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.302168; batch adversarial loss: 0.573916\n",
      "epoch 155; iter: 0; batch classifier loss: 0.309772; batch adversarial loss: 0.479144\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330356; batch adversarial loss: 0.599820\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370206; batch adversarial loss: 0.544059\n",
      "epoch 158; iter: 0; batch classifier loss: 0.300960; batch adversarial loss: 0.589045\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332760; batch adversarial loss: 0.508407\n",
      "epoch 160; iter: 0; batch classifier loss: 0.415093; batch adversarial loss: 0.525349\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368229; batch adversarial loss: 0.525764\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355071; batch adversarial loss: 0.561892\n",
      "epoch 163; iter: 0; batch classifier loss: 0.368020; batch adversarial loss: 0.581580\n",
      "epoch 164; iter: 0; batch classifier loss: 0.411851; batch adversarial loss: 0.554158\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339122; batch adversarial loss: 0.570711\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334768; batch adversarial loss: 0.498684\n",
      "epoch 167; iter: 0; batch classifier loss: 0.517637; batch adversarial loss: 0.525838\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366662; batch adversarial loss: 0.507885\n",
      "epoch 169; iter: 0; batch classifier loss: 0.374207; batch adversarial loss: 0.488863\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352650; batch adversarial loss: 0.543936\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355447; batch adversarial loss: 0.534247\n",
      "epoch 172; iter: 0; batch classifier loss: 0.428919; batch adversarial loss: 0.527117\n",
      "epoch 173; iter: 0; batch classifier loss: 0.348147; batch adversarial loss: 0.516728\n",
      "epoch 174; iter: 0; batch classifier loss: 0.349507; batch adversarial loss: 0.487830\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328015; batch adversarial loss: 0.526353\n",
      "epoch 176; iter: 0; batch classifier loss: 0.436634; batch adversarial loss: 0.589775\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356364; batch adversarial loss: 0.579729\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391448; batch adversarial loss: 0.544850\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343275; batch adversarial loss: 0.554205\n",
      "epoch 180; iter: 0; batch classifier loss: 0.456917; batch adversarial loss: 0.543627\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364159; batch adversarial loss: 0.563434\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408509; batch adversarial loss: 0.525326\n",
      "epoch 183; iter: 0; batch classifier loss: 0.414547; batch adversarial loss: 0.517636\n",
      "epoch 184; iter: 0; batch classifier loss: 0.395843; batch adversarial loss: 0.545136\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356097; batch adversarial loss: 0.546283\n",
      "epoch 186; iter: 0; batch classifier loss: 0.316917; batch adversarial loss: 0.535133\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336696; batch adversarial loss: 0.591957\n",
      "epoch 188; iter: 0; batch classifier loss: 0.270650; batch adversarial loss: 0.480060\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383161; batch adversarial loss: 0.619606\n",
      "epoch 190; iter: 0; batch classifier loss: 0.373581; batch adversarial loss: 0.600883\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389805; batch adversarial loss: 0.535665\n",
      "epoch 192; iter: 0; batch classifier loss: 0.391401; batch adversarial loss: 0.591488\n",
      "epoch 193; iter: 0; batch classifier loss: 0.281170; batch adversarial loss: 0.626549\n",
      "epoch 194; iter: 0; batch classifier loss: 0.355587; batch adversarial loss: 0.507232\n",
      "epoch 195; iter: 0; batch classifier loss: 0.402792; batch adversarial loss: 0.498998\n",
      "epoch 196; iter: 0; batch classifier loss: 0.420775; batch adversarial loss: 0.553812\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353286; batch adversarial loss: 0.562824\n",
      "epoch 198; iter: 0; batch classifier loss: 0.344840; batch adversarial loss: 0.498437\n",
      "epoch 199; iter: 0; batch classifier loss: 0.361733; batch adversarial loss: 0.517887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.654258; batch adversarial loss: 0.675261\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586319; batch adversarial loss: 0.644588\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547514; batch adversarial loss: 0.650968\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609890; batch adversarial loss: 0.635376\n",
      "epoch 4; iter: 0; batch classifier loss: 0.632254; batch adversarial loss: 0.623054\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509657; batch adversarial loss: 0.658355\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501915; batch adversarial loss: 0.609643\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584984; batch adversarial loss: 0.626400\n",
      "epoch 8; iter: 0; batch classifier loss: 0.635573; batch adversarial loss: 0.605348\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488681; batch adversarial loss: 0.594521\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572271; batch adversarial loss: 0.598858\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473103; batch adversarial loss: 0.562607\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509880; batch adversarial loss: 0.545840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515573; batch adversarial loss: 0.579001\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516428; batch adversarial loss: 0.560062\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569942; batch adversarial loss: 0.582873\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454177; batch adversarial loss: 0.573695\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517197; batch adversarial loss: 0.556756\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429165; batch adversarial loss: 0.497333\n",
      "epoch 19; iter: 0; batch classifier loss: 0.493260; batch adversarial loss: 0.563028\n",
      "epoch 20; iter: 0; batch classifier loss: 0.537031; batch adversarial loss: 0.590426\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509290; batch adversarial loss: 0.510177\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529867; batch adversarial loss: 0.577264\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439523; batch adversarial loss: 0.629782\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453270; batch adversarial loss: 0.489457\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484636; batch adversarial loss: 0.580399\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460974; batch adversarial loss: 0.525315\n",
      "epoch 27; iter: 0; batch classifier loss: 0.456146; batch adversarial loss: 0.618541\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433126; batch adversarial loss: 0.605111\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438756; batch adversarial loss: 0.638885\n",
      "epoch 30; iter: 0; batch classifier loss: 0.445469; batch adversarial loss: 0.572087\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472452; batch adversarial loss: 0.565234\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431485; batch adversarial loss: 0.539923\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443078; batch adversarial loss: 0.555300\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437861; batch adversarial loss: 0.528887\n",
      "epoch 35; iter: 0; batch classifier loss: 0.401670; batch adversarial loss: 0.539311\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478567; batch adversarial loss: 0.523852\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452882; batch adversarial loss: 0.497418\n",
      "epoch 38; iter: 0; batch classifier loss: 0.500194; batch adversarial loss: 0.550242\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477864; batch adversarial loss: 0.497051\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437054; batch adversarial loss: 0.486009\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430789; batch adversarial loss: 0.523675\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416175; batch adversarial loss: 0.514311\n",
      "epoch 43; iter: 0; batch classifier loss: 0.392296; batch adversarial loss: 0.598399\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501345; batch adversarial loss: 0.515792\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421533; batch adversarial loss: 0.573404\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377784; batch adversarial loss: 0.566405\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420555; batch adversarial loss: 0.615552\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370392; batch adversarial loss: 0.551942\n",
      "epoch 49; iter: 0; batch classifier loss: 0.368494; batch adversarial loss: 0.602555\n",
      "epoch 50; iter: 0; batch classifier loss: 0.335952; batch adversarial loss: 0.574730\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462536; batch adversarial loss: 0.576089\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420042; batch adversarial loss: 0.544292\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399342; batch adversarial loss: 0.577580\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430871; batch adversarial loss: 0.508155\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406056; batch adversarial loss: 0.492135\n",
      "epoch 56; iter: 0; batch classifier loss: 0.340792; batch adversarial loss: 0.600008\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411779; batch adversarial loss: 0.515877\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391944; batch adversarial loss: 0.567652\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378933; batch adversarial loss: 0.550497\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423696; batch adversarial loss: 0.483744\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389697; batch adversarial loss: 0.540091\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399554; batch adversarial loss: 0.523918\n",
      "epoch 63; iter: 0; batch classifier loss: 0.481814; batch adversarial loss: 0.587550\n",
      "epoch 64; iter: 0; batch classifier loss: 0.373608; batch adversarial loss: 0.572735\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436969; batch adversarial loss: 0.511992\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389257; batch adversarial loss: 0.595461\n",
      "epoch 67; iter: 0; batch classifier loss: 0.368056; batch adversarial loss: 0.458027\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415687; batch adversarial loss: 0.564160\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361185; batch adversarial loss: 0.583027\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384037; batch adversarial loss: 0.557754\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386463; batch adversarial loss: 0.501200\n",
      "epoch 72; iter: 0; batch classifier loss: 0.345453; batch adversarial loss: 0.595198\n",
      "epoch 73; iter: 0; batch classifier loss: 0.353961; batch adversarial loss: 0.619847\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374852; batch adversarial loss: 0.602460\n",
      "epoch 75; iter: 0; batch classifier loss: 0.305264; batch adversarial loss: 0.610042\n",
      "epoch 76; iter: 0; batch classifier loss: 0.437252; batch adversarial loss: 0.526543\n",
      "epoch 77; iter: 0; batch classifier loss: 0.428118; batch adversarial loss: 0.539402\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379523; batch adversarial loss: 0.515426\n",
      "epoch 79; iter: 0; batch classifier loss: 0.451308; batch adversarial loss: 0.555310\n",
      "epoch 80; iter: 0; batch classifier loss: 0.341217; batch adversarial loss: 0.499743\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418798; batch adversarial loss: 0.580453\n",
      "epoch 82; iter: 0; batch classifier loss: 0.339461; batch adversarial loss: 0.568228\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405315; batch adversarial loss: 0.591088\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376277; batch adversarial loss: 0.471820\n",
      "epoch 85; iter: 0; batch classifier loss: 0.439099; batch adversarial loss: 0.535809\n",
      "epoch 86; iter: 0; batch classifier loss: 0.471489; batch adversarial loss: 0.526799\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416750; batch adversarial loss: 0.571408\n",
      "epoch 88; iter: 0; batch classifier loss: 0.370084; batch adversarial loss: 0.491915\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417148; batch adversarial loss: 0.498041\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374995; batch adversarial loss: 0.499289\n",
      "epoch 91; iter: 0; batch classifier loss: 0.321562; batch adversarial loss: 0.559184\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377303; batch adversarial loss: 0.553967\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342605; batch adversarial loss: 0.501844\n",
      "epoch 94; iter: 0; batch classifier loss: 0.346934; batch adversarial loss: 0.548393\n",
      "epoch 95; iter: 0; batch classifier loss: 0.371983; batch adversarial loss: 0.432977\n",
      "epoch 96; iter: 0; batch classifier loss: 0.337171; batch adversarial loss: 0.568033\n",
      "epoch 97; iter: 0; batch classifier loss: 0.380663; batch adversarial loss: 0.491422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.347713; batch adversarial loss: 0.620405\n",
      "epoch 99; iter: 0; batch classifier loss: 0.437722; batch adversarial loss: 0.535359\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400007; batch adversarial loss: 0.479418\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406519; batch adversarial loss: 0.609180\n",
      "epoch 102; iter: 0; batch classifier loss: 0.383316; batch adversarial loss: 0.516771\n",
      "epoch 103; iter: 0; batch classifier loss: 0.314807; batch adversarial loss: 0.617936\n",
      "epoch 104; iter: 0; batch classifier loss: 0.322935; batch adversarial loss: 0.533763\n",
      "epoch 105; iter: 0; batch classifier loss: 0.345551; batch adversarial loss: 0.496277\n",
      "epoch 106; iter: 0; batch classifier loss: 0.447440; batch adversarial loss: 0.566132\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319611; batch adversarial loss: 0.571516\n",
      "epoch 108; iter: 0; batch classifier loss: 0.368925; batch adversarial loss: 0.565755\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356030; batch adversarial loss: 0.504036\n",
      "epoch 110; iter: 0; batch classifier loss: 0.335919; batch adversarial loss: 0.553837\n",
      "epoch 111; iter: 0; batch classifier loss: 0.310799; batch adversarial loss: 0.537088\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357720; batch adversarial loss: 0.589158\n",
      "epoch 113; iter: 0; batch classifier loss: 0.309512; batch adversarial loss: 0.532663\n",
      "epoch 114; iter: 0; batch classifier loss: 0.466642; batch adversarial loss: 0.543540\n",
      "epoch 115; iter: 0; batch classifier loss: 0.413350; batch adversarial loss: 0.523280\n",
      "epoch 116; iter: 0; batch classifier loss: 0.337318; batch adversarial loss: 0.479150\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351394; batch adversarial loss: 0.533530\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398624; batch adversarial loss: 0.517875\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382438; batch adversarial loss: 0.506972\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382939; batch adversarial loss: 0.534154\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382337; batch adversarial loss: 0.551764\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378504; batch adversarial loss: 0.564753\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339808; batch adversarial loss: 0.595988\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372779; batch adversarial loss: 0.562718\n",
      "epoch 125; iter: 0; batch classifier loss: 0.421845; batch adversarial loss: 0.581455\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354525; batch adversarial loss: 0.532861\n",
      "epoch 127; iter: 0; batch classifier loss: 0.325028; batch adversarial loss: 0.515614\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367182; batch adversarial loss: 0.558108\n",
      "epoch 129; iter: 0; batch classifier loss: 0.323371; batch adversarial loss: 0.593106\n",
      "epoch 130; iter: 0; batch classifier loss: 0.347161; batch adversarial loss: 0.443600\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374248; batch adversarial loss: 0.542045\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360718; batch adversarial loss: 0.525440\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341503; batch adversarial loss: 0.557513\n",
      "epoch 134; iter: 0; batch classifier loss: 0.330104; batch adversarial loss: 0.549518\n",
      "epoch 135; iter: 0; batch classifier loss: 0.383962; batch adversarial loss: 0.543896\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363151; batch adversarial loss: 0.495540\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332057; batch adversarial loss: 0.549793\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388767; batch adversarial loss: 0.591963\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356694; batch adversarial loss: 0.525174\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375415; batch adversarial loss: 0.551432\n",
      "epoch 141; iter: 0; batch classifier loss: 0.419322; batch adversarial loss: 0.543526\n",
      "epoch 142; iter: 0; batch classifier loss: 0.332095; batch adversarial loss: 0.481021\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383158; batch adversarial loss: 0.598102\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339577; batch adversarial loss: 0.550994\n",
      "epoch 145; iter: 0; batch classifier loss: 0.326495; batch adversarial loss: 0.607268\n",
      "epoch 146; iter: 0; batch classifier loss: 0.337521; batch adversarial loss: 0.586556\n",
      "epoch 147; iter: 0; batch classifier loss: 0.386013; batch adversarial loss: 0.570417\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357154; batch adversarial loss: 0.546753\n",
      "epoch 149; iter: 0; batch classifier loss: 0.372333; batch adversarial loss: 0.571787\n",
      "epoch 150; iter: 0; batch classifier loss: 0.397698; batch adversarial loss: 0.594454\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347616; batch adversarial loss: 0.555830\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342957; batch adversarial loss: 0.563397\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430552; batch adversarial loss: 0.534451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.314582; batch adversarial loss: 0.510939\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317371; batch adversarial loss: 0.571595\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378839; batch adversarial loss: 0.563663\n",
      "epoch 157; iter: 0; batch classifier loss: 0.291948; batch adversarial loss: 0.503111\n",
      "epoch 158; iter: 0; batch classifier loss: 0.459183; batch adversarial loss: 0.516737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333118; batch adversarial loss: 0.508451\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372862; batch adversarial loss: 0.544299\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354402; batch adversarial loss: 0.552449\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387880; batch adversarial loss: 0.524772\n",
      "epoch 163; iter: 0; batch classifier loss: 0.376356; batch adversarial loss: 0.581097\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348046; batch adversarial loss: 0.506050\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365094; batch adversarial loss: 0.582232\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350488; batch adversarial loss: 0.533400\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367248; batch adversarial loss: 0.653341\n",
      "epoch 168; iter: 0; batch classifier loss: 0.394713; batch adversarial loss: 0.497441\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382527; batch adversarial loss: 0.553786\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366114; batch adversarial loss: 0.536198\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394116; batch adversarial loss: 0.597497\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346517; batch adversarial loss: 0.544315\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350844; batch adversarial loss: 0.555892\n",
      "epoch 174; iter: 0; batch classifier loss: 0.424676; batch adversarial loss: 0.552560\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362198; batch adversarial loss: 0.554617\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332735; batch adversarial loss: 0.545383\n",
      "epoch 177; iter: 0; batch classifier loss: 0.436127; batch adversarial loss: 0.590352\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353894; batch adversarial loss: 0.618866\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392944; batch adversarial loss: 0.553223\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378089; batch adversarial loss: 0.472719\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383705; batch adversarial loss: 0.597515\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379123; batch adversarial loss: 0.608890\n",
      "epoch 183; iter: 0; batch classifier loss: 0.362554; batch adversarial loss: 0.587563\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389670; batch adversarial loss: 0.488612\n",
      "epoch 185; iter: 0; batch classifier loss: 0.327396; batch adversarial loss: 0.563246\n",
      "epoch 186; iter: 0; batch classifier loss: 0.300277; batch adversarial loss: 0.516719\n",
      "epoch 187; iter: 0; batch classifier loss: 0.314642; batch adversarial loss: 0.580909\n",
      "epoch 188; iter: 0; batch classifier loss: 0.477372; batch adversarial loss: 0.571242\n",
      "epoch 189; iter: 0; batch classifier loss: 0.273738; batch adversarial loss: 0.609245\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385181; batch adversarial loss: 0.583990\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331128; batch adversarial loss: 0.543879\n",
      "epoch 192; iter: 0; batch classifier loss: 0.291258; batch adversarial loss: 0.472233\n",
      "epoch 193; iter: 0; batch classifier loss: 0.311091; batch adversarial loss: 0.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.334013; batch adversarial loss: 0.614676\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336218; batch adversarial loss: 0.569363\n",
      "epoch 196; iter: 0; batch classifier loss: 0.388189; batch adversarial loss: 0.564140\n",
      "epoch 197; iter: 0; batch classifier loss: 0.374826; batch adversarial loss: 0.536845\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361735; batch adversarial loss: 0.562847\n",
      "epoch 199; iter: 0; batch classifier loss: 0.322118; batch adversarial loss: 0.589278\n",
      "epoch 0; iter: 0; batch classifier loss: 0.765585; batch adversarial loss: 1.003173\n",
      "epoch 1; iter: 0; batch classifier loss: 0.865209; batch adversarial loss: 1.140319\n",
      "epoch 2; iter: 0; batch classifier loss: 1.010743; batch adversarial loss: 1.112330\n",
      "epoch 3; iter: 0; batch classifier loss: 1.096932; batch adversarial loss: 1.025002\n",
      "epoch 4; iter: 0; batch classifier loss: 1.153851; batch adversarial loss: 0.943371\n",
      "epoch 5; iter: 0; batch classifier loss: 1.198856; batch adversarial loss: 0.873430\n",
      "epoch 6; iter: 0; batch classifier loss: 1.010973; batch adversarial loss: 0.796985\n",
      "epoch 7; iter: 0; batch classifier loss: 1.107720; batch adversarial loss: 0.756417\n",
      "epoch 8; iter: 0; batch classifier loss: 0.974491; batch adversarial loss: 0.729561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.730420; batch adversarial loss: 0.631834\n",
      "epoch 10; iter: 0; batch classifier loss: 0.652906; batch adversarial loss: 0.630772\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538677; batch adversarial loss: 0.594424\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496508; batch adversarial loss: 0.587244\n",
      "epoch 13; iter: 0; batch classifier loss: 0.523835; batch adversarial loss: 0.588288\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497293; batch adversarial loss: 0.565617\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493319; batch adversarial loss: 0.582939\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547892; batch adversarial loss: 0.567976\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512847; batch adversarial loss: 0.535345\n",
      "epoch 18; iter: 0; batch classifier loss: 0.560624; batch adversarial loss: 0.512540\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541850; batch adversarial loss: 0.545604\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484983; batch adversarial loss: 0.623143\n",
      "epoch 21; iter: 0; batch classifier loss: 0.472994; batch adversarial loss: 0.607216\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465296; batch adversarial loss: 0.540841\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502570; batch adversarial loss: 0.491870\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519984; batch adversarial loss: 0.593253\n",
      "epoch 25; iter: 0; batch classifier loss: 0.507457; batch adversarial loss: 0.573489\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466342; batch adversarial loss: 0.502184\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466268; batch adversarial loss: 0.575143\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468430; batch adversarial loss: 0.540140\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447134; batch adversarial loss: 0.570086\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415213; batch adversarial loss: 0.531982\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477146; batch adversarial loss: 0.575320\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409568; batch adversarial loss: 0.548152\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460779; batch adversarial loss: 0.509640\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423607; batch adversarial loss: 0.587726\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445070; batch adversarial loss: 0.536629\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503242; batch adversarial loss: 0.578980\n",
      "epoch 37; iter: 0; batch classifier loss: 0.517462; batch adversarial loss: 0.563190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458358; batch adversarial loss: 0.588659\n",
      "epoch 39; iter: 0; batch classifier loss: 0.416129; batch adversarial loss: 0.533641\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398150; batch adversarial loss: 0.555886\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397093; batch adversarial loss: 0.523433\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425087; batch adversarial loss: 0.544648\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443875; batch adversarial loss: 0.596546\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369256; batch adversarial loss: 0.524910\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407002; batch adversarial loss: 0.477045\n",
      "epoch 46; iter: 0; batch classifier loss: 0.525853; batch adversarial loss: 0.546181\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383288; batch adversarial loss: 0.610987\n",
      "epoch 48; iter: 0; batch classifier loss: 0.475061; batch adversarial loss: 0.591050\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400198; batch adversarial loss: 0.506194\n",
      "epoch 50; iter: 0; batch classifier loss: 0.427732; batch adversarial loss: 0.508065\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427972; batch adversarial loss: 0.520304\n",
      "epoch 52; iter: 0; batch classifier loss: 0.492819; batch adversarial loss: 0.538413\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417329; batch adversarial loss: 0.472946\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410832; batch adversarial loss: 0.605167\n",
      "epoch 55; iter: 0; batch classifier loss: 0.350592; batch adversarial loss: 0.510258\n",
      "epoch 56; iter: 0; batch classifier loss: 0.387935; batch adversarial loss: 0.617397\n",
      "epoch 57; iter: 0; batch classifier loss: 0.371184; batch adversarial loss: 0.562234\n",
      "epoch 58; iter: 0; batch classifier loss: 0.449044; batch adversarial loss: 0.554495\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441126; batch adversarial loss: 0.517075\n",
      "epoch 60; iter: 0; batch classifier loss: 0.518189; batch adversarial loss: 0.571951\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428252; batch adversarial loss: 0.580205\n",
      "epoch 62; iter: 0; batch classifier loss: 0.343601; batch adversarial loss: 0.545392\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409583; batch adversarial loss: 0.518403\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386875; batch adversarial loss: 0.545189\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383724; batch adversarial loss: 0.598338\n",
      "epoch 66; iter: 0; batch classifier loss: 0.376217; batch adversarial loss: 0.589333\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406053; batch adversarial loss: 0.544137\n",
      "epoch 68; iter: 0; batch classifier loss: 0.352252; batch adversarial loss: 0.544174\n",
      "epoch 69; iter: 0; batch classifier loss: 0.391890; batch adversarial loss: 0.517658\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397894; batch adversarial loss: 0.571318\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411529; batch adversarial loss: 0.554020\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365423; batch adversarial loss: 0.527047\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367263; batch adversarial loss: 0.615847\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412525; batch adversarial loss: 0.617169\n",
      "epoch 75; iter: 0; batch classifier loss: 0.304484; batch adversarial loss: 0.589816\n",
      "epoch 76; iter: 0; batch classifier loss: 0.417670; batch adversarial loss: 0.607908\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405974; batch adversarial loss: 0.526811\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400869; batch adversarial loss: 0.525843\n",
      "epoch 79; iter: 0; batch classifier loss: 0.316462; batch adversarial loss: 0.545780\n",
      "epoch 80; iter: 0; batch classifier loss: 0.302285; batch adversarial loss: 0.580180\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373135; batch adversarial loss: 0.632012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398035; batch adversarial loss: 0.517244\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370766; batch adversarial loss: 0.518986\n",
      "epoch 84; iter: 0; batch classifier loss: 0.414872; batch adversarial loss: 0.499454\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409815; batch adversarial loss: 0.563248\n",
      "epoch 86; iter: 0; batch classifier loss: 0.315664; batch adversarial loss: 0.555172\n",
      "epoch 87; iter: 0; batch classifier loss: 0.290261; batch adversarial loss: 0.561887\n",
      "epoch 88; iter: 0; batch classifier loss: 0.350332; batch adversarial loss: 0.525628\n",
      "epoch 89; iter: 0; batch classifier loss: 0.361208; batch adversarial loss: 0.527379\n",
      "epoch 90; iter: 0; batch classifier loss: 0.380282; batch adversarial loss: 0.615389\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390563; batch adversarial loss: 0.589910\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374374; batch adversarial loss: 0.546527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.413857; batch adversarial loss: 0.481732\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365632; batch adversarial loss: 0.552452\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387750; batch adversarial loss: 0.552754\n",
      "epoch 96; iter: 0; batch classifier loss: 0.467397; batch adversarial loss: 0.598861\n",
      "epoch 97; iter: 0; batch classifier loss: 0.432169; batch adversarial loss: 0.479610\n",
      "epoch 98; iter: 0; batch classifier loss: 0.330334; batch adversarial loss: 0.580767\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369729; batch adversarial loss: 0.525769\n",
      "epoch 100; iter: 0; batch classifier loss: 0.371282; batch adversarial loss: 0.528410\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384307; batch adversarial loss: 0.525928\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377429; batch adversarial loss: 0.607818\n",
      "epoch 103; iter: 0; batch classifier loss: 0.330664; batch adversarial loss: 0.535534\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372266; batch adversarial loss: 0.537520\n",
      "epoch 105; iter: 0; batch classifier loss: 0.286381; batch adversarial loss: 0.570306\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389183; batch adversarial loss: 0.525657\n",
      "epoch 107; iter: 0; batch classifier loss: 0.383819; batch adversarial loss: 0.599830\n",
      "epoch 108; iter: 0; batch classifier loss: 0.447564; batch adversarial loss: 0.509231\n",
      "epoch 109; iter: 0; batch classifier loss: 0.340605; batch adversarial loss: 0.510396\n",
      "epoch 110; iter: 0; batch classifier loss: 0.333661; batch adversarial loss: 0.605468\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372793; batch adversarial loss: 0.509818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361452; batch adversarial loss: 0.545066\n",
      "epoch 113; iter: 0; batch classifier loss: 0.372333; batch adversarial loss: 0.505776\n",
      "epoch 114; iter: 0; batch classifier loss: 0.315345; batch adversarial loss: 0.537629\n",
      "epoch 115; iter: 0; batch classifier loss: 0.335438; batch adversarial loss: 0.541159\n",
      "epoch 116; iter: 0; batch classifier loss: 0.340398; batch adversarial loss: 0.598743\n",
      "epoch 117; iter: 0; batch classifier loss: 0.421033; batch adversarial loss: 0.596447\n",
      "epoch 118; iter: 0; batch classifier loss: 0.282041; batch adversarial loss: 0.564768\n",
      "epoch 119; iter: 0; batch classifier loss: 0.260880; batch adversarial loss: 0.534812\n",
      "epoch 120; iter: 0; batch classifier loss: 0.357884; batch adversarial loss: 0.535683\n",
      "epoch 121; iter: 0; batch classifier loss: 0.322231; batch adversarial loss: 0.544153\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345783; batch adversarial loss: 0.528137\n",
      "epoch 123; iter: 0; batch classifier loss: 0.318716; batch adversarial loss: 0.570912\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337088; batch adversarial loss: 0.535596\n",
      "epoch 125; iter: 0; batch classifier loss: 0.314284; batch adversarial loss: 0.533889\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338877; batch adversarial loss: 0.587677\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382654; batch adversarial loss: 0.499864\n",
      "epoch 128; iter: 0; batch classifier loss: 0.311599; batch adversarial loss: 0.582097\n",
      "epoch 129; iter: 0; batch classifier loss: 0.314202; batch adversarial loss: 0.551454\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348824; batch adversarial loss: 0.598251\n",
      "epoch 131; iter: 0; batch classifier loss: 0.311269; batch adversarial loss: 0.472493\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323385; batch adversarial loss: 0.533939\n",
      "epoch 133; iter: 0; batch classifier loss: 0.299031; batch adversarial loss: 0.607546\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374650; batch adversarial loss: 0.493590\n",
      "epoch 135; iter: 0; batch classifier loss: 0.316197; batch adversarial loss: 0.579784\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404448; batch adversarial loss: 0.552337\n",
      "epoch 137; iter: 0; batch classifier loss: 0.279469; batch adversarial loss: 0.516715\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320697; batch adversarial loss: 0.633063\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360066; batch adversarial loss: 0.525453\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364732; batch adversarial loss: 0.501462\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371188; batch adversarial loss: 0.537120\n",
      "epoch 142; iter: 0; batch classifier loss: 0.314750; batch adversarial loss: 0.622141\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383402; batch adversarial loss: 0.572788\n",
      "epoch 144; iter: 0; batch classifier loss: 0.251862; batch adversarial loss: 0.585901\n",
      "epoch 145; iter: 0; batch classifier loss: 0.400891; batch adversarial loss: 0.437715\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383978; batch adversarial loss: 0.608901\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397528; batch adversarial loss: 0.517554\n",
      "epoch 148; iter: 0; batch classifier loss: 0.387042; batch adversarial loss: 0.582988\n",
      "epoch 149; iter: 0; batch classifier loss: 0.299699; batch adversarial loss: 0.517442\n",
      "epoch 150; iter: 0; batch classifier loss: 0.401380; batch adversarial loss: 0.473861\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370086; batch adversarial loss: 0.653172\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336618; batch adversarial loss: 0.526130\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389624; batch adversarial loss: 0.595492\n",
      "epoch 154; iter: 0; batch classifier loss: 0.296793; batch adversarial loss: 0.542975\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347260; batch adversarial loss: 0.571649\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314163; batch adversarial loss: 0.571409\n",
      "epoch 157; iter: 0; batch classifier loss: 0.395470; batch adversarial loss: 0.564741\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392660; batch adversarial loss: 0.534874\n",
      "epoch 159; iter: 0; batch classifier loss: 0.403365; batch adversarial loss: 0.536765\n",
      "epoch 160; iter: 0; batch classifier loss: 0.312897; batch adversarial loss: 0.614675\n",
      "epoch 161; iter: 0; batch classifier loss: 0.270403; batch adversarial loss: 0.607535\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334338; batch adversarial loss: 0.510974\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340538; batch adversarial loss: 0.625684\n",
      "epoch 164; iter: 0; batch classifier loss: 0.349351; batch adversarial loss: 0.526401\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369998; batch adversarial loss: 0.553925\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339806; batch adversarial loss: 0.589444\n",
      "epoch 167; iter: 0; batch classifier loss: 0.314567; batch adversarial loss: 0.552256\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348303; batch adversarial loss: 0.454859\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363420; batch adversarial loss: 0.660661\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297611; batch adversarial loss: 0.507642\n",
      "epoch 171; iter: 0; batch classifier loss: 0.289589; batch adversarial loss: 0.616373\n",
      "epoch 172; iter: 0; batch classifier loss: 0.257328; batch adversarial loss: 0.626103\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361123; batch adversarial loss: 0.524893\n",
      "epoch 174; iter: 0; batch classifier loss: 0.314751; batch adversarial loss: 0.534770\n",
      "epoch 175; iter: 0; batch classifier loss: 0.262735; batch adversarial loss: 0.579531\n",
      "epoch 176; iter: 0; batch classifier loss: 0.286868; batch adversarial loss: 0.533746\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330074; batch adversarial loss: 0.509613\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330556; batch adversarial loss: 0.528558\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334552; batch adversarial loss: 0.581272\n",
      "epoch 180; iter: 0; batch classifier loss: 0.289146; batch adversarial loss: 0.567237\n",
      "epoch 181; iter: 0; batch classifier loss: 0.274129; batch adversarial loss: 0.489776\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341510; batch adversarial loss: 0.553144\n",
      "epoch 183; iter: 0; batch classifier loss: 0.283030; batch adversarial loss: 0.536386\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384694; batch adversarial loss: 0.626595\n",
      "epoch 185; iter: 0; batch classifier loss: 0.274336; batch adversarial loss: 0.570469\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346194; batch adversarial loss: 0.578936\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326505; batch adversarial loss: 0.600287\n",
      "epoch 188; iter: 0; batch classifier loss: 0.291716; batch adversarial loss: 0.551891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.256552; batch adversarial loss: 0.551087\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297794; batch adversarial loss: 0.534101\n",
      "epoch 191; iter: 0; batch classifier loss: 0.383881; batch adversarial loss: 0.545204\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334994; batch adversarial loss: 0.572776\n",
      "epoch 193; iter: 0; batch classifier loss: 0.354988; batch adversarial loss: 0.536730\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353755; batch adversarial loss: 0.599374\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335079; batch adversarial loss: 0.510195\n",
      "epoch 196; iter: 0; batch classifier loss: 0.308116; batch adversarial loss: 0.498208\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361493; batch adversarial loss: 0.583285\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306072; batch adversarial loss: 0.600414\n",
      "epoch 199; iter: 0; batch classifier loss: 0.483819; batch adversarial loss: 0.590168\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735150; batch adversarial loss: 0.693914\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591007; batch adversarial loss: 0.670627\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585590; batch adversarial loss: 0.636017\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597188; batch adversarial loss: 0.633454\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619646; batch adversarial loss: 0.624004\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528655; batch adversarial loss: 0.594275\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590146; batch adversarial loss: 0.617370\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556287; batch adversarial loss: 0.552114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611265; batch adversarial loss: 0.564494\n",
      "epoch 9; iter: 0; batch classifier loss: 0.489080; batch adversarial loss: 0.543835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499365; batch adversarial loss: 0.583745\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520981; batch adversarial loss: 0.554944\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495004; batch adversarial loss: 0.555835\n",
      "epoch 13; iter: 0; batch classifier loss: 0.608407; batch adversarial loss: 0.585429\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472466; batch adversarial loss: 0.576988\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492956; batch adversarial loss: 0.551987\n",
      "epoch 16; iter: 0; batch classifier loss: 0.441974; batch adversarial loss: 0.498566\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459619; batch adversarial loss: 0.552124\n",
      "epoch 18; iter: 0; batch classifier loss: 0.461323; batch adversarial loss: 0.611420\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497783; batch adversarial loss: 0.641739\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469045; batch adversarial loss: 0.553757\n",
      "epoch 21; iter: 0; batch classifier loss: 0.553165; batch adversarial loss: 0.597032\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506637; batch adversarial loss: 0.578387\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477225; batch adversarial loss: 0.536809\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484386; batch adversarial loss: 0.546766\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466339; batch adversarial loss: 0.548673\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485332; batch adversarial loss: 0.574661\n",
      "epoch 27; iter: 0; batch classifier loss: 0.492430; batch adversarial loss: 0.526926\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455443; batch adversarial loss: 0.539928\n",
      "epoch 29; iter: 0; batch classifier loss: 0.378040; batch adversarial loss: 0.563844\n",
      "epoch 30; iter: 0; batch classifier loss: 0.573086; batch adversarial loss: 0.572313\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458406; batch adversarial loss: 0.530082\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434775; batch adversarial loss: 0.546627\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440905; batch adversarial loss: 0.560707\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417174; batch adversarial loss: 0.562646\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479112; batch adversarial loss: 0.588679\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468653; batch adversarial loss: 0.509875\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439242; batch adversarial loss: 0.499675\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435362; batch adversarial loss: 0.562887\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482215; batch adversarial loss: 0.527275\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467864; batch adversarial loss: 0.570551\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424711; batch adversarial loss: 0.579544\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410945; batch adversarial loss: 0.500491\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401765; batch adversarial loss: 0.508868\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424229; batch adversarial loss: 0.545445\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421634; batch adversarial loss: 0.517347\n",
      "epoch 46; iter: 0; batch classifier loss: 0.573195; batch adversarial loss: 0.526630\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431008; batch adversarial loss: 0.481479\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435375; batch adversarial loss: 0.544852\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434805; batch adversarial loss: 0.499490\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459855; batch adversarial loss: 0.517447\n",
      "epoch 51; iter: 0; batch classifier loss: 0.488996; batch adversarial loss: 0.535654\n",
      "epoch 52; iter: 0; batch classifier loss: 0.394458; batch adversarial loss: 0.526516\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431806; batch adversarial loss: 0.535541\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439248; batch adversarial loss: 0.544565\n",
      "epoch 55; iter: 0; batch classifier loss: 0.509202; batch adversarial loss: 0.571800\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420353; batch adversarial loss: 0.553666\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421533; batch adversarial loss: 0.580730\n",
      "epoch 58; iter: 0; batch classifier loss: 0.379181; batch adversarial loss: 0.562637\n",
      "epoch 59; iter: 0; batch classifier loss: 0.489614; batch adversarial loss: 0.499162\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437302; batch adversarial loss: 0.508215\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404838; batch adversarial loss: 0.499057\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422769; batch adversarial loss: 0.535256\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398254; batch adversarial loss: 0.644806\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466528; batch adversarial loss: 0.452294\n",
      "epoch 65; iter: 0; batch classifier loss: 0.434661; batch adversarial loss: 0.525970\n",
      "epoch 66; iter: 0; batch classifier loss: 0.355003; batch adversarial loss: 0.581400\n",
      "epoch 67; iter: 0; batch classifier loss: 0.473527; batch adversarial loss: 0.517319\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411785; batch adversarial loss: 0.444442\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361010; batch adversarial loss: 0.562696\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413989; batch adversarial loss: 0.580182\n",
      "epoch 71; iter: 0; batch classifier loss: 0.454874; batch adversarial loss: 0.480893\n",
      "epoch 72; iter: 0; batch classifier loss: 0.362209; batch adversarial loss: 0.498893\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409790; batch adversarial loss: 0.516608\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423237; batch adversarial loss: 0.545209\n",
      "epoch 75; iter: 0; batch classifier loss: 0.351119; batch adversarial loss: 0.590780\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413515; batch adversarial loss: 0.563129\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423780; batch adversarial loss: 0.516866\n",
      "epoch 78; iter: 0; batch classifier loss: 0.442585; batch adversarial loss: 0.553799\n",
      "epoch 79; iter: 0; batch classifier loss: 0.364605; batch adversarial loss: 0.463701\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385486; batch adversarial loss: 0.580775\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424854; batch adversarial loss: 0.490043\n",
      "epoch 82; iter: 0; batch classifier loss: 0.425771; batch adversarial loss: 0.508649\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404156; batch adversarial loss: 0.535017\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419052; batch adversarial loss: 0.544565\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419052; batch adversarial loss: 0.581599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.407383; batch adversarial loss: 0.553439\n",
      "epoch 87; iter: 0; batch classifier loss: 0.450519; batch adversarial loss: 0.545033\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372894; batch adversarial loss: 0.535607\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402381; batch adversarial loss: 0.544500\n",
      "epoch 90; iter: 0; batch classifier loss: 0.433175; batch adversarial loss: 0.490202\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397550; batch adversarial loss: 0.516968\n",
      "epoch 92; iter: 0; batch classifier loss: 0.338896; batch adversarial loss: 0.453635\n",
      "epoch 93; iter: 0; batch classifier loss: 0.324660; batch adversarial loss: 0.481009\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368877; batch adversarial loss: 0.508331\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344481; batch adversarial loss: 0.508642\n",
      "epoch 96; iter: 0; batch classifier loss: 0.435910; batch adversarial loss: 0.526496\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371046; batch adversarial loss: 0.589908\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389112; batch adversarial loss: 0.599395\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407010; batch adversarial loss: 0.553615\n",
      "epoch 100; iter: 0; batch classifier loss: 0.395705; batch adversarial loss: 0.535981\n",
      "epoch 101; iter: 0; batch classifier loss: 0.410366; batch adversarial loss: 0.590129\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365306; batch adversarial loss: 0.499004\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426031; batch adversarial loss: 0.562830\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383244; batch adversarial loss: 0.608188\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389393; batch adversarial loss: 0.508165\n",
      "epoch 106; iter: 0; batch classifier loss: 0.439020; batch adversarial loss: 0.489957\n",
      "epoch 107; iter: 0; batch classifier loss: 0.342729; batch adversarial loss: 0.489757\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393758; batch adversarial loss: 0.535123\n",
      "epoch 109; iter: 0; batch classifier loss: 0.330164; batch adversarial loss: 0.626556\n",
      "epoch 110; iter: 0; batch classifier loss: 0.420820; batch adversarial loss: 0.644954\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375369; batch adversarial loss: 0.472005\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347529; batch adversarial loss: 0.562580\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418639; batch adversarial loss: 0.563086\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346220; batch adversarial loss: 0.553502\n",
      "epoch 115; iter: 0; batch classifier loss: 0.397744; batch adversarial loss: 0.562810\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346479; batch adversarial loss: 0.535435\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369043; batch adversarial loss: 0.580713\n",
      "epoch 118; iter: 0; batch classifier loss: 0.438749; batch adversarial loss: 0.553263\n",
      "epoch 119; iter: 0; batch classifier loss: 0.426369; batch adversarial loss: 0.581002\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374586; batch adversarial loss: 0.517209\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380641; batch adversarial loss: 0.490055\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382058; batch adversarial loss: 0.562561\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394815; batch adversarial loss: 0.517025\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418588; batch adversarial loss: 0.580821\n",
      "epoch 125; iter: 0; batch classifier loss: 0.347229; batch adversarial loss: 0.471923\n",
      "epoch 126; iter: 0; batch classifier loss: 0.345412; batch adversarial loss: 0.626019\n",
      "epoch 127; iter: 0; batch classifier loss: 0.301279; batch adversarial loss: 0.508428\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351458; batch adversarial loss: 0.526367\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393485; batch adversarial loss: 0.489772\n",
      "epoch 130; iter: 0; batch classifier loss: 0.419916; batch adversarial loss: 0.598710\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340844; batch adversarial loss: 0.526296\n",
      "epoch 132; iter: 0; batch classifier loss: 0.430604; batch adversarial loss: 0.544552\n",
      "epoch 133; iter: 0; batch classifier loss: 0.406137; batch adversarial loss: 0.544803\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366013; batch adversarial loss: 0.562767\n",
      "epoch 135; iter: 0; batch classifier loss: 0.477061; batch adversarial loss: 0.589854\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411018; batch adversarial loss: 0.516899\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389714; batch adversarial loss: 0.491095\n",
      "epoch 138; iter: 0; batch classifier loss: 0.440537; batch adversarial loss: 0.553008\n",
      "epoch 139; iter: 0; batch classifier loss: 0.351836; batch adversarial loss: 0.562661\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335523; batch adversarial loss: 0.662075\n",
      "epoch 141; iter: 0; batch classifier loss: 0.372174; batch adversarial loss: 0.553617\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367411; batch adversarial loss: 0.544524\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389416; batch adversarial loss: 0.617530\n",
      "epoch 144; iter: 0; batch classifier loss: 0.383252; batch adversarial loss: 0.544529\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380955; batch adversarial loss: 0.562906\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360341; batch adversarial loss: 0.553732\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347139; batch adversarial loss: 0.526543\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312076; batch adversarial loss: 0.544880\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415510; batch adversarial loss: 0.580757\n",
      "epoch 150; iter: 0; batch classifier loss: 0.378466; batch adversarial loss: 0.580816\n",
      "epoch 151; iter: 0; batch classifier loss: 0.423143; batch adversarial loss: 0.508227\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365876; batch adversarial loss: 0.472136\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364848; batch adversarial loss: 0.544979\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395725; batch adversarial loss: 0.526548\n",
      "epoch 155; iter: 0; batch classifier loss: 0.442288; batch adversarial loss: 0.553731\n",
      "epoch 156; iter: 0; batch classifier loss: 0.311520; batch adversarial loss: 0.544891\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344342; batch adversarial loss: 0.453444\n",
      "epoch 158; iter: 0; batch classifier loss: 0.449469; batch adversarial loss: 0.499000\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353401; batch adversarial loss: 0.608368\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375246; batch adversarial loss: 0.490248\n",
      "epoch 161; iter: 0; batch classifier loss: 0.434874; batch adversarial loss: 0.490045\n",
      "epoch 162; iter: 0; batch classifier loss: 0.362667; batch adversarial loss: 0.508033\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356977; batch adversarial loss: 0.580763\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397162; batch adversarial loss: 0.589701\n",
      "epoch 165; iter: 0; batch classifier loss: 0.423043; batch adversarial loss: 0.562819\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359315; batch adversarial loss: 0.544564\n",
      "epoch 167; iter: 0; batch classifier loss: 0.325796; batch adversarial loss: 0.517259\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377810; batch adversarial loss: 0.544475\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324133; batch adversarial loss: 0.644355\n",
      "epoch 170; iter: 0; batch classifier loss: 0.269844; batch adversarial loss: 0.626056\n",
      "epoch 171; iter: 0; batch classifier loss: 0.436454; batch adversarial loss: 0.580736\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378686; batch adversarial loss: 0.480194\n",
      "epoch 173; iter: 0; batch classifier loss: 0.293897; batch adversarial loss: 0.534879\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341524; batch adversarial loss: 0.552906\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400601; batch adversarial loss: 0.490339\n",
      "epoch 176; iter: 0; batch classifier loss: 0.373460; batch adversarial loss: 0.481532\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324083; batch adversarial loss: 0.481504\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389737; batch adversarial loss: 0.517439\n",
      "epoch 179; iter: 0; batch classifier loss: 0.363030; batch adversarial loss: 0.535630\n",
      "epoch 180; iter: 0; batch classifier loss: 0.306397; batch adversarial loss: 0.535426\n",
      "epoch 181; iter: 0; batch classifier loss: 0.326610; batch adversarial loss: 0.544622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.381939; batch adversarial loss: 0.553552\n",
      "epoch 183; iter: 0; batch classifier loss: 0.339723; batch adversarial loss: 0.652428\n",
      "epoch 184; iter: 0; batch classifier loss: 0.434066; batch adversarial loss: 0.498822\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330152; batch adversarial loss: 0.535462\n",
      "epoch 186; iter: 0; batch classifier loss: 0.291578; batch adversarial loss: 0.581118\n",
      "epoch 187; iter: 0; batch classifier loss: 0.391470; batch adversarial loss: 0.571631\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334605; batch adversarial loss: 0.590109\n",
      "epoch 189; iter: 0; batch classifier loss: 0.416098; batch adversarial loss: 0.544476\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366210; batch adversarial loss: 0.489632\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374447; batch adversarial loss: 0.598765\n",
      "epoch 192; iter: 0; batch classifier loss: 0.269092; batch adversarial loss: 0.499074\n",
      "epoch 193; iter: 0; batch classifier loss: 0.255669; batch adversarial loss: 0.589730\n",
      "epoch 194; iter: 0; batch classifier loss: 0.409753; batch adversarial loss: 0.562787\n",
      "epoch 195; iter: 0; batch classifier loss: 0.355211; batch adversarial loss: 0.508327\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351426; batch adversarial loss: 0.517277\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366733; batch adversarial loss: 0.535335\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350075; batch adversarial loss: 0.580838\n",
      "epoch 199; iter: 0; batch classifier loss: 0.416601; batch adversarial loss: 0.562992\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad081a37",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d71374d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENT_SEEDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configs for an experiment iteration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m exp_iter_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m experiment_seed \u001b[38;5;241m=\u001b[39m \u001b[43mEXPERIMENT_SEEDS\u001b[49m[exp_iter_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m tuned_params_filenames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m tuned_params_df_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_fairness_interventions_exp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                       FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, tuned_params_filename)\n\u001b[1;32m      8\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m tuned_params_filename \u001b[38;5;129;01min\u001b[39;00m tuned_params_filenames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EXPERIMENT_SEEDS' is not defined"
     ]
    }
   ],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e1be877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5645c6009d3b48d29619a238bc476502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 200, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c0277603884950a0c35cc9dcc3f539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137564e8e0d4fcbbbfaaf03d73e170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30ab3dbbfe4acb8557a8c1e2d6556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a36e32d08b44c1b01ae496881c6b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29566f",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735a5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b357cf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a789184",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c52dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffd2af81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6992b60",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ceef26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf7aaefd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95401044",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e629ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d2b5af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9015dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
