{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34965764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4293d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62d87ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116a9c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce9c216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce19cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d60f9",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a7652d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSPublicCoverageDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a5e5a",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2a9770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_pubcov'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_CA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854721bc",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9248b643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b8f1df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "028db0d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bf843ff8-62e9-4aac-83bc-d805e3299fdc\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e4b1d",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d988c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>ESR</th>\n",
       "      <th>ST</th>\n",
       "      <th>FER</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL MAR SEX DIS ESP CIT MIG MIL ANC NATIVITY DEAR DEYE DREM ESR ST FER  \\\n",
       "0   19   5   1   2   0   1   3   4   1        1    2    2    2   6  6   0   \n",
       "1   16   5   1   2   0   3   3   4   4        1    2    2    2   1  6   0   \n",
       "2   13   5   2   2   1   1   1   0   2        1    2    2    2   6  6   2   \n",
       "3   20   1   2   2   0   4   1   4   1        2    2    2    2   6  6   2   \n",
       "4   16   1   2   2   0   4   1   4   1        2    2    2    2   6  6   0   \n",
       "\n",
       "  RAC1P  AGEP   PINCP  \n",
       "0     1    21  3150.0  \n",
       "1     9    18  1600.0  \n",
       "2     1    16     0.0  \n",
       "3     8    43     0.0  \n",
       "4     6    54     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSPublicCoverageDataset(state=['CA'], year=2018, with_nulls=False,\n",
    "                                       subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3d56a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144c2bc",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb7494",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d028c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ee53d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': '84eeb5f0-4ebe-4d9f-94ef-53ae302c2264'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0774252fc3d84263b3f1952d6646e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afb71fcf4f547769fec45358ef2d8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81e93a7c9ca4b759124ebae6b6a39d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2024-01-08 14:47:02.022905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706076; batch adversarial loss: 0.692046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528616; batch adversarial loss: 0.690824\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437058; batch adversarial loss: 0.641205\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374626; batch adversarial loss: 0.591401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.578531\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362062; batch adversarial loss: 0.540871\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253209; batch adversarial loss: 0.536458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249384; batch adversarial loss: 0.510654\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222574; batch adversarial loss: 0.526174\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231929; batch adversarial loss: 0.544187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269365; batch adversarial loss: 0.530938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.269131; batch adversarial loss: 0.499622\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209271; batch adversarial loss: 0.500838\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232830; batch adversarial loss: 0.522906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200820; batch adversarial loss: 0.444583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175221; batch adversarial loss: 0.468809\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195260; batch adversarial loss: 0.487876\n",
      "epoch 17; iter: 0; batch classifier loss: 0.108377; batch adversarial loss: 0.462686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.154744; batch adversarial loss: 0.465643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.114956; batch adversarial loss: 0.518928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185771; batch adversarial loss: 0.457848\n",
      "epoch 21; iter: 0; batch classifier loss: 0.114915; batch adversarial loss: 0.514133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.135782; batch adversarial loss: 0.513373\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134654; batch adversarial loss: 0.569677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175153; batch adversarial loss: 0.454520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180932; batch adversarial loss: 0.524089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194350; batch adversarial loss: 0.554577\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175350; batch adversarial loss: 0.572550\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203875; batch adversarial loss: 0.621340\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220782; batch adversarial loss: 0.584977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192389; batch adversarial loss: 0.494302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166049; batch adversarial loss: 0.488495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181273; batch adversarial loss: 0.477612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197128; batch adversarial loss: 0.508084\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233774; batch adversarial loss: 0.480641\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171880; batch adversarial loss: 0.430034\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272469; batch adversarial loss: 0.529935\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227646; batch adversarial loss: 0.448445\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163945; batch adversarial loss: 0.406804\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079406; batch adversarial loss: 0.448137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091811; batch adversarial loss: 0.446052\n",
      "epoch 41; iter: 0; batch classifier loss: 0.067578; batch adversarial loss: 0.525227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.059282; batch adversarial loss: 0.496629\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104444; batch adversarial loss: 0.455580\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119299; batch adversarial loss: 0.454710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076554; batch adversarial loss: 0.489845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086420; batch adversarial loss: 0.475786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.067454; batch adversarial loss: 0.383989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099616; batch adversarial loss: 0.504962\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129307; batch adversarial loss: 0.369170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074693; batch adversarial loss: 0.344991\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073794; batch adversarial loss: 0.533122\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101932; batch adversarial loss: 0.551938\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079983; batch adversarial loss: 0.460136\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074297; batch adversarial loss: 0.473660\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119616; batch adversarial loss: 0.417397\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096468; batch adversarial loss: 0.344682\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112178; batch adversarial loss: 0.483005\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097981; batch adversarial loss: 0.495853\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082937; batch adversarial loss: 0.485810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061327; batch adversarial loss: 0.522080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090307; batch adversarial loss: 0.448743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047843; batch adversarial loss: 0.452977\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065588; batch adversarial loss: 0.387373\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098521; batch adversarial loss: 0.422866\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058718; batch adversarial loss: 0.489143\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089657; batch adversarial loss: 0.364338\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069073; batch adversarial loss: 0.508808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079268; batch adversarial loss: 0.435710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075794; batch adversarial loss: 0.451353\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103014; batch adversarial loss: 0.524944\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079265; batch adversarial loss: 0.458990\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054589; batch adversarial loss: 0.416570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067984; batch adversarial loss: 0.571959\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075297; batch adversarial loss: 0.431452\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071271; batch adversarial loss: 0.468172\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070982; batch adversarial loss: 0.451261\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076285; batch adversarial loss: 0.433854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062035; batch adversarial loss: 0.504788\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075761; batch adversarial loss: 0.467174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098143; batch adversarial loss: 0.505237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084273; batch adversarial loss: 0.357909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071487; batch adversarial loss: 0.473864\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121158; batch adversarial loss: 0.486395\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.409071\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065818; batch adversarial loss: 0.503372\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082517; batch adversarial loss: 0.587905\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111101; batch adversarial loss: 0.466063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055440; batch adversarial loss: 0.564533\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089993; batch adversarial loss: 0.390280\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082860; batch adversarial loss: 0.463198\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047112; batch adversarial loss: 0.537224\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101391; batch adversarial loss: 0.538014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.131220; batch adversarial loss: 0.459360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.109573; batch adversarial loss: 0.465781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054340; batch adversarial loss: 0.397680\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.495775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062126; batch adversarial loss: 0.498909\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.431311\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102993; batch adversarial loss: 0.376494\n",
      "epoch 100; iter: 0; batch classifier loss: 0.102044; batch adversarial loss: 0.357074\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054333; batch adversarial loss: 0.467210\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054543; batch adversarial loss: 0.427762\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034367; batch adversarial loss: 0.450090\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065666; batch adversarial loss: 0.440686\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081424; batch adversarial loss: 0.314604\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067678; batch adversarial loss: 0.510275\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063083; batch adversarial loss: 0.474941\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019212; batch adversarial loss: 0.407522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034522; batch adversarial loss: 0.409571\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058404; batch adversarial loss: 0.502819\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040291; batch adversarial loss: 0.444476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042527; batch adversarial loss: 0.447824\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053517; batch adversarial loss: 0.419865\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054878; batch adversarial loss: 0.463392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053708; batch adversarial loss: 0.508642\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035963; batch adversarial loss: 0.455745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072132; batch adversarial loss: 0.499220\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043367; batch adversarial loss: 0.420356\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048310; batch adversarial loss: 0.492525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074792; batch adversarial loss: 0.405318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050102; batch adversarial loss: 0.584632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066402; batch adversarial loss: 0.514826\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.436852\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040002; batch adversarial loss: 0.377582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017416; batch adversarial loss: 0.497774\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071384; batch adversarial loss: 0.499982\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037890; batch adversarial loss: 0.466903\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.433337\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043349; batch adversarial loss: 0.491828\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017410; batch adversarial loss: 0.436271\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050517; batch adversarial loss: 0.450991\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047536; batch adversarial loss: 0.512238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013396; batch adversarial loss: 0.419450\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069495; batch adversarial loss: 0.453873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.442644\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.452397\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046000; batch adversarial loss: 0.442586\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029759; batch adversarial loss: 0.361690\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037082; batch adversarial loss: 0.530520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061619; batch adversarial loss: 0.476281\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027611; batch adversarial loss: 0.463160\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048353; batch adversarial loss: 0.430123\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.542561\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014643; batch adversarial loss: 0.402583\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040828; batch adversarial loss: 0.458558\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052981; batch adversarial loss: 0.499904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052879; batch adversarial loss: 0.468605\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.437735\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013094; batch adversarial loss: 0.392392\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054930; batch adversarial loss: 0.392228\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033070; batch adversarial loss: 0.429573\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013686; batch adversarial loss: 0.480302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025517; batch adversarial loss: 0.474301\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026941; batch adversarial loss: 0.397288\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021937; batch adversarial loss: 0.382238\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.386828\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029149; batch adversarial loss: 0.362087\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032100; batch adversarial loss: 0.514566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026255; batch adversarial loss: 0.514117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030920; batch adversarial loss: 0.367334\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015507; batch adversarial loss: 0.385345\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041188; batch adversarial loss: 0.557631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038723; batch adversarial loss: 0.467234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024678; batch adversarial loss: 0.458803\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.389683\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.340316\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030933; batch adversarial loss: 0.488713\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017171; batch adversarial loss: 0.493203\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040985; batch adversarial loss: 0.462638\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028517; batch adversarial loss: 0.418939\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026486; batch adversarial loss: 0.536990\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020521; batch adversarial loss: 0.486689\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030953; batch adversarial loss: 0.454736\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006511; batch adversarial loss: 0.437390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016025; batch adversarial loss: 0.431013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023440; batch adversarial loss: 0.506947\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.402723\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.441069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010429; batch adversarial loss: 0.496293\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021091; batch adversarial loss: 0.415183\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021063; batch adversarial loss: 0.424210\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.479177\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011231; batch adversarial loss: 0.444569\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027491; batch adversarial loss: 0.465693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033915; batch adversarial loss: 0.559489\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023120; batch adversarial loss: 0.453808\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012470; batch adversarial loss: 0.402795\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028664; batch adversarial loss: 0.427348\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041508; batch adversarial loss: 0.460209\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026672; batch adversarial loss: 0.323445\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039655; batch adversarial loss: 0.390811\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015852; batch adversarial loss: 0.466843\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035564; batch adversarial loss: 0.504015\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008910; batch adversarial loss: 0.485968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056930; batch adversarial loss: 0.580673\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.370200\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.446720\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041652; batch adversarial loss: 0.417590\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012187; batch adversarial loss: 0.526439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:38.105341: W tensorflow/c/c_api.cc:304] Operation '{name:'04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:784 op device:{requested: '', assigned: ''} def:{{{node 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706066; batch adversarial loss: 0.736104\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530403; batch adversarial loss: 0.678148\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459406; batch adversarial loss: 0.631632\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410012; batch adversarial loss: 0.603996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406459; batch adversarial loss: 0.622275\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.592824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326480; batch adversarial loss: 0.557714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264814; batch adversarial loss: 0.563979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309007; batch adversarial loss: 0.561000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337536; batch adversarial loss: 0.511946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358785; batch adversarial loss: 0.497081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326900; batch adversarial loss: 0.521918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282505; batch adversarial loss: 0.507427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.319482; batch adversarial loss: 0.490685\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297245; batch adversarial loss: 0.530186\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348114; batch adversarial loss: 0.492884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315601; batch adversarial loss: 0.543774\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353514; batch adversarial loss: 0.479612\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284691; batch adversarial loss: 0.557426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321636; batch adversarial loss: 0.461743\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313884; batch adversarial loss: 0.535758\n",
      "epoch 21; iter: 0; batch classifier loss: 0.354032; batch adversarial loss: 0.452499\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307755; batch adversarial loss: 0.462012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.481600\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280347; batch adversarial loss: 0.487124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349690; batch adversarial loss: 0.456283\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296061; batch adversarial loss: 0.497201\n",
      "epoch 27; iter: 0; batch classifier loss: 0.333900; batch adversarial loss: 0.465661\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244060; batch adversarial loss: 0.450193\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281684; batch adversarial loss: 0.416492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234843; batch adversarial loss: 0.482024\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302185; batch adversarial loss: 0.407197\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187466; batch adversarial loss: 0.474231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230678; batch adversarial loss: 0.523563\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241098; batch adversarial loss: 0.496128\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299920; batch adversarial loss: 0.424774\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261082; batch adversarial loss: 0.428908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260111; batch adversarial loss: 0.474318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.284937; batch adversarial loss: 0.372036\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288252; batch adversarial loss: 0.389466\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252943; batch adversarial loss: 0.422020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203067; batch adversarial loss: 0.377419\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247434; batch adversarial loss: 0.503243\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251894; batch adversarial loss: 0.407028\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323468; batch adversarial loss: 0.434153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.277021; batch adversarial loss: 0.421189\n",
      "epoch 46; iter: 0; batch classifier loss: 0.304496; batch adversarial loss: 0.501504\n",
      "epoch 47; iter: 0; batch classifier loss: 0.246984; batch adversarial loss: 0.447492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231022; batch adversarial loss: 0.519735\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179348; batch adversarial loss: 0.410107\n",
      "epoch 50; iter: 0; batch classifier loss: 0.257322; batch adversarial loss: 0.496071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.267536; batch adversarial loss: 0.423316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.341285; batch adversarial loss: 0.459359\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095520; batch adversarial loss: 0.458750\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116211; batch adversarial loss: 0.434297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125691; batch adversarial loss: 0.351374\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099187; batch adversarial loss: 0.398515\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078252; batch adversarial loss: 0.323342\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138991; batch adversarial loss: 0.535808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090362; batch adversarial loss: 0.529794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081609; batch adversarial loss: 0.375216\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114897; batch adversarial loss: 0.478639\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108687; batch adversarial loss: 0.408623\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104107; batch adversarial loss: 0.481544\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044141; batch adversarial loss: 0.368196\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082003; batch adversarial loss: 0.465862\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105736; batch adversarial loss: 0.443595\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073735; batch adversarial loss: 0.489333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060975; batch adversarial loss: 0.436080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.429296\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049926; batch adversarial loss: 0.365259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083830; batch adversarial loss: 0.494927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074709; batch adversarial loss: 0.461633\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111192; batch adversarial loss: 0.433871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039334; batch adversarial loss: 0.515788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071055; batch adversarial loss: 0.406289\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082684; batch adversarial loss: 0.357580\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067315; batch adversarial loss: 0.511623\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069397; batch adversarial loss: 0.385906\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075082; batch adversarial loss: 0.456910\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048823; batch adversarial loss: 0.406157\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081523; batch adversarial loss: 0.411017\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091294; batch adversarial loss: 0.499160\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064026; batch adversarial loss: 0.350682\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042356; batch adversarial loss: 0.517212\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.350081\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035308; batch adversarial loss: 0.443477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076340; batch adversarial loss: 0.374428\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040681; batch adversarial loss: 0.407967\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102669; batch adversarial loss: 0.389595\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099464; batch adversarial loss: 0.437800\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056865; batch adversarial loss: 0.437627\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041417; batch adversarial loss: 0.460328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036856; batch adversarial loss: 0.436436\n",
      "epoch 94; iter: 0; batch classifier loss: 0.021777; batch adversarial loss: 0.363280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105770; batch adversarial loss: 0.378147\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056142; batch adversarial loss: 0.399404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037050; batch adversarial loss: 0.386856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067514; batch adversarial loss: 0.414906\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097396; batch adversarial loss: 0.436210\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066562; batch adversarial loss: 0.466013\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042754; batch adversarial loss: 0.375284\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046262; batch adversarial loss: 0.387627\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060422; batch adversarial loss: 0.400367\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047418; batch adversarial loss: 0.438297\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084870; batch adversarial loss: 0.451563\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083724; batch adversarial loss: 0.437510\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024412; batch adversarial loss: 0.500079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077510; batch adversarial loss: 0.362601\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072262; batch adversarial loss: 0.485094\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028390; batch adversarial loss: 0.414303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066319; batch adversarial loss: 0.512818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047636; batch adversarial loss: 0.424238\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041746; batch adversarial loss: 0.410702\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.448275\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.529532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065540; batch adversarial loss: 0.429329\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055839; batch adversarial loss: 0.436495\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044993; batch adversarial loss: 0.402658\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073519; batch adversarial loss: 0.378357\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068609; batch adversarial loss: 0.464458\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.518541\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059184; batch adversarial loss: 0.345951\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.421292\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041276; batch adversarial loss: 0.383915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049520; batch adversarial loss: 0.421313\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.363910\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040973; batch adversarial loss: 0.449873\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032641; batch adversarial loss: 0.476491\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039640; batch adversarial loss: 0.436265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.083309; batch adversarial loss: 0.409344\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066746; batch adversarial loss: 0.464579\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066838; batch adversarial loss: 0.375523\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060657; batch adversarial loss: 0.382825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.450408\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059749; batch adversarial loss: 0.403990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054896; batch adversarial loss: 0.450985\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.574739\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065396; batch adversarial loss: 0.398369\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.476669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028837; batch adversarial loss: 0.481624\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049655; batch adversarial loss: 0.499269\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049504; batch adversarial loss: 0.316459\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070289; batch adversarial loss: 0.535042\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039829; batch adversarial loss: 0.366865\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046085; batch adversarial loss: 0.375202\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.446702\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044651; batch adversarial loss: 0.384226\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049078; batch adversarial loss: 0.387665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039845; batch adversarial loss: 0.441024\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.414215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038650; batch adversarial loss: 0.382847\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031766; batch adversarial loss: 0.458061\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022421; batch adversarial loss: 0.437063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039472; batch adversarial loss: 0.480207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034906; batch adversarial loss: 0.514492\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.377841\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028500; batch adversarial loss: 0.396452\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034823; batch adversarial loss: 0.453429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033487; batch adversarial loss: 0.445524\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044612; batch adversarial loss: 0.459001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017963; batch adversarial loss: 0.343711\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052142; batch adversarial loss: 0.403664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.421914\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032402; batch adversarial loss: 0.472692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.418011\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.452449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017184; batch adversarial loss: 0.458858\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.402869\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.471132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020083; batch adversarial loss: 0.480702\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014721; batch adversarial loss: 0.471981\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034698; batch adversarial loss: 0.427563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026398; batch adversarial loss: 0.372757\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016702; batch adversarial loss: 0.371487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039552; batch adversarial loss: 0.394009\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031724; batch adversarial loss: 0.377999\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029643; batch adversarial loss: 0.450269\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.445277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026109; batch adversarial loss: 0.446072\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049046; batch adversarial loss: 0.375977\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025078; batch adversarial loss: 0.362209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031550; batch adversarial loss: 0.392815\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027878; batch adversarial loss: 0.382241\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027336; batch adversarial loss: 0.445629\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022268; batch adversarial loss: 0.451700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025109; batch adversarial loss: 0.451593\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.427051\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013901; batch adversarial loss: 0.616939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016848; batch adversarial loss: 0.451149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016180; batch adversarial loss: 0.478983\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.362182\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.432742\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021960; batch adversarial loss: 0.409336\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023780; batch adversarial loss: 0.408788\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013846; batch adversarial loss: 0.398356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.364331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007561; batch adversarial loss: 0.454264\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007466; batch adversarial loss: 0.421940\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035742; batch adversarial loss: 0.398075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:13.265192: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:1591 op device:{requested: '', assigned: ''} def:{{{node 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688129; batch adversarial loss: 0.582458\n",
      "epoch 1; iter: 0; batch classifier loss: 0.418286; batch adversarial loss: 0.582047\n",
      "epoch 2; iter: 0; batch classifier loss: 0.525055; batch adversarial loss: 0.583817\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428255; batch adversarial loss: 0.520912\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349640; batch adversarial loss: 0.566984\n",
      "epoch 5; iter: 0; batch classifier loss: 0.340495; batch adversarial loss: 0.611152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.408788; batch adversarial loss: 0.555860\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.536746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377252; batch adversarial loss: 0.547035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416875; batch adversarial loss: 0.571816\n",
      "epoch 10; iter: 0; batch classifier loss: 0.458405; batch adversarial loss: 0.447826\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361180; batch adversarial loss: 0.517236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285615; batch adversarial loss: 0.506002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346196; batch adversarial loss: 0.575380\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283920; batch adversarial loss: 0.515648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200360; batch adversarial loss: 0.501168\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243708; batch adversarial loss: 0.432575\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178450; batch adversarial loss: 0.420903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254595; batch adversarial loss: 0.438466\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257026; batch adversarial loss: 0.496501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178530; batch adversarial loss: 0.502721\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232064; batch adversarial loss: 0.468430\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189602; batch adversarial loss: 0.435759\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213089; batch adversarial loss: 0.513310\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195573; batch adversarial loss: 0.461283\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202941; batch adversarial loss: 0.458565\n",
      "epoch 26; iter: 0; batch classifier loss: 0.216715; batch adversarial loss: 0.509816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226038; batch adversarial loss: 0.503132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185449; batch adversarial loss: 0.474548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197551; batch adversarial loss: 0.513540\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198968; batch adversarial loss: 0.444631\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178431; batch adversarial loss: 0.418701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165924; batch adversarial loss: 0.471863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200710; batch adversarial loss: 0.389130\n",
      "epoch 34; iter: 0; batch classifier loss: 0.215499; batch adversarial loss: 0.398050\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148965; batch adversarial loss: 0.436479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.196180; batch adversarial loss: 0.435999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219984; batch adversarial loss: 0.414746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.253643; batch adversarial loss: 0.502879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148975; batch adversarial loss: 0.460152\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182249; batch adversarial loss: 0.430215\n",
      "epoch 41; iter: 0; batch classifier loss: 0.212471; batch adversarial loss: 0.516455\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204900; batch adversarial loss: 0.486186\n",
      "epoch 43; iter: 0; batch classifier loss: 0.273834; batch adversarial loss: 0.370007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.184662; batch adversarial loss: 0.446620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211863; batch adversarial loss: 0.532505\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246754; batch adversarial loss: 0.378046\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.432995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.217221; batch adversarial loss: 0.504403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199260; batch adversarial loss: 0.494291\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225734; batch adversarial loss: 0.469332\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280469; batch adversarial loss: 0.450357\n",
      "epoch 52; iter: 0; batch classifier loss: 0.256328; batch adversarial loss: 0.400179\n",
      "epoch 53; iter: 0; batch classifier loss: 0.235736; batch adversarial loss: 0.472313\n",
      "epoch 54; iter: 0; batch classifier loss: 0.268841; batch adversarial loss: 0.423809\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215488; batch adversarial loss: 0.494381\n",
      "epoch 56; iter: 0; batch classifier loss: 0.156838; batch adversarial loss: 0.493873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067571; batch adversarial loss: 0.446264\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103650; batch adversarial loss: 0.479958\n",
      "epoch 59; iter: 0; batch classifier loss: 0.080905; batch adversarial loss: 0.476880\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087581; batch adversarial loss: 0.438387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.057121; batch adversarial loss: 0.527533\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069701; batch adversarial loss: 0.451979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092830; batch adversarial loss: 0.408839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179970; batch adversarial loss: 0.439693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190992; batch adversarial loss: 0.491628\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146571; batch adversarial loss: 0.574472\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124498; batch adversarial loss: 0.413266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.170022; batch adversarial loss: 0.442749\n",
      "epoch 69; iter: 0; batch classifier loss: 0.124150; batch adversarial loss: 0.469246\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086658; batch adversarial loss: 0.446183\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097854; batch adversarial loss: 0.510166\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098005; batch adversarial loss: 0.506230\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103036; batch adversarial loss: 0.476823\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119643; batch adversarial loss: 0.513143\n",
      "epoch 75; iter: 0; batch classifier loss: 0.154620; batch adversarial loss: 0.419525\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.417197\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090060; batch adversarial loss: 0.433126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108649; batch adversarial loss: 0.491992\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072665; batch adversarial loss: 0.427414\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078432; batch adversarial loss: 0.416684\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081628; batch adversarial loss: 0.618467\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081460; batch adversarial loss: 0.451962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083842; batch adversarial loss: 0.409290\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065025; batch adversarial loss: 0.527774\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076811; batch adversarial loss: 0.395808\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080542; batch adversarial loss: 0.426802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035755; batch adversarial loss: 0.457259\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075089; batch adversarial loss: 0.522649\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073160; batch adversarial loss: 0.524856\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075504; batch adversarial loss: 0.454985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082712; batch adversarial loss: 0.468551\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081159; batch adversarial loss: 0.424298\n",
      "epoch 93; iter: 0; batch classifier loss: 0.105341; batch adversarial loss: 0.483678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103236; batch adversarial loss: 0.413750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056362; batch adversarial loss: 0.477983\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096910; batch adversarial loss: 0.419712\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088785; batch adversarial loss: 0.338753\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056480; batch adversarial loss: 0.493365\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078842; batch adversarial loss: 0.472535\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045361; batch adversarial loss: 0.404357\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062635; batch adversarial loss: 0.445790\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078453; batch adversarial loss: 0.472064\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038869; batch adversarial loss: 0.438187\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047181; batch adversarial loss: 0.479073\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052053; batch adversarial loss: 0.491621\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031616; batch adversarial loss: 0.548412\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.448620\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058622; batch adversarial loss: 0.465527\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.452133\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038677; batch adversarial loss: 0.402920\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019532; batch adversarial loss: 0.465544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056462; batch adversarial loss: 0.441909\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072204; batch adversarial loss: 0.602850\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029742; batch adversarial loss: 0.479939\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050471; batch adversarial loss: 0.433319\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060567; batch adversarial loss: 0.398176\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047180; batch adversarial loss: 0.439185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029035; batch adversarial loss: 0.418488\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033030; batch adversarial loss: 0.450658\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051230; batch adversarial loss: 0.409980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034502; batch adversarial loss: 0.483479\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066685; batch adversarial loss: 0.415055\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036303; batch adversarial loss: 0.464543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.493312\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030684; batch adversarial loss: 0.400999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023634; batch adversarial loss: 0.445230\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032854; batch adversarial loss: 0.453296\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026536; batch adversarial loss: 0.507458\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.440097\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.370093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036277; batch adversarial loss: 0.417342\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029931; batch adversarial loss: 0.464351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032374; batch adversarial loss: 0.545062\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.349027\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016774; batch adversarial loss: 0.495524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030935; batch adversarial loss: 0.449530\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.456351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013323; batch adversarial loss: 0.456658\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030194; batch adversarial loss: 0.510743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021454; batch adversarial loss: 0.356752\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028846; batch adversarial loss: 0.352905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023706; batch adversarial loss: 0.536787\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019686; batch adversarial loss: 0.470078\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041820; batch adversarial loss: 0.487558\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011119; batch adversarial loss: 0.483874\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030574; batch adversarial loss: 0.457222\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024936; batch adversarial loss: 0.558170\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022186; batch adversarial loss: 0.372945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027140; batch adversarial loss: 0.432468\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023059; batch adversarial loss: 0.319447\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041326; batch adversarial loss: 0.445123\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013528; batch adversarial loss: 0.437946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017250; batch adversarial loss: 0.482155\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012327; batch adversarial loss: 0.448138\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026185; batch adversarial loss: 0.413030\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040082; batch adversarial loss: 0.496351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021876; batch adversarial loss: 0.453756\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029481; batch adversarial loss: 0.465553\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004143; batch adversarial loss: 0.414448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013102; batch adversarial loss: 0.464395\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008841; batch adversarial loss: 0.449652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009041; batch adversarial loss: 0.577473\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012078; batch adversarial loss: 0.431391\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005280; batch adversarial loss: 0.348936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022938; batch adversarial loss: 0.531446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007558; batch adversarial loss: 0.368732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007948; batch adversarial loss: 0.418823\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011378; batch adversarial loss: 0.462137\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012475; batch adversarial loss: 0.522107\n",
      "epoch 170; iter: 0; batch classifier loss: 0.089205; batch adversarial loss: 0.425102\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013193; batch adversarial loss: 0.438883\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.464129\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016692; batch adversarial loss: 0.464161\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014131; batch adversarial loss: 0.416692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019746; batch adversarial loss: 0.454887\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003722; batch adversarial loss: 0.416714\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009313; batch adversarial loss: 0.439547\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013868; batch adversarial loss: 0.486130\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022029; batch adversarial loss: 0.498505\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008864; batch adversarial loss: 0.420729\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038184; batch adversarial loss: 0.417415\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031390; batch adversarial loss: 0.408334\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026545; batch adversarial loss: 0.569768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006229; batch adversarial loss: 0.342425\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011448; batch adversarial loss: 0.482688\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023002; batch adversarial loss: 0.445266\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004066; batch adversarial loss: 0.428464\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003665; batch adversarial loss: 0.430902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027354; batch adversarial loss: 0.399141\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005157; batch adversarial loss: 0.474395\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.400792\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050361; batch adversarial loss: 0.441677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012426; batch adversarial loss: 0.475218\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006026; batch adversarial loss: 0.468294\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008955; batch adversarial loss: 0.498031\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012578; batch adversarial loss: 0.443660\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005842; batch adversarial loss: 0.529499\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009330; batch adversarial loss: 0.451309\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.396820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:49.999533: W tensorflow/c/c_api.cc:304] Operation '{name:'04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:2398 op device:{requested: '', assigned: ''} def:{{{node 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.709423; batch adversarial loss: 0.826485\n",
      "epoch 1; iter: 0; batch classifier loss: 0.589269; batch adversarial loss: 0.774333\n",
      "epoch 2; iter: 0; batch classifier loss: 0.757826; batch adversarial loss: 0.757554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651808; batch adversarial loss: 0.683050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559073; batch adversarial loss: 0.616526\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383718; batch adversarial loss: 0.587390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361682; batch adversarial loss: 0.608442\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300812; batch adversarial loss: 0.533616\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428041; batch adversarial loss: 0.522132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334713; batch adversarial loss: 0.554177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337976; batch adversarial loss: 0.478305\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403465; batch adversarial loss: 0.537060\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316303; batch adversarial loss: 0.511609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331920; batch adversarial loss: 0.503228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314666; batch adversarial loss: 0.467400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338908; batch adversarial loss: 0.471192\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334456; batch adversarial loss: 0.463481\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237582; batch adversarial loss: 0.487386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243639; batch adversarial loss: 0.559268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223562; batch adversarial loss: 0.497359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289271; batch adversarial loss: 0.560765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308990; batch adversarial loss: 0.482442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294239; batch adversarial loss: 0.508942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245820; batch adversarial loss: 0.469365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199940; batch adversarial loss: 0.491858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237852; batch adversarial loss: 0.483418\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248950; batch adversarial loss: 0.494269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215890; batch adversarial loss: 0.493594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.219729; batch adversarial loss: 0.477457\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219291; batch adversarial loss: 0.576004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205509; batch adversarial loss: 0.407661\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229055; batch adversarial loss: 0.420588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231041; batch adversarial loss: 0.436854\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188074; batch adversarial loss: 0.454388\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252571; batch adversarial loss: 0.415374\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175120; batch adversarial loss: 0.415148\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156770; batch adversarial loss: 0.482264\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153350; batch adversarial loss: 0.431682\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211564; batch adversarial loss: 0.467146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260667; batch adversarial loss: 0.425384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224133; batch adversarial loss: 0.424066\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186538; batch adversarial loss: 0.481687\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217674; batch adversarial loss: 0.570059\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.480069\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287237; batch adversarial loss: 0.476578\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318581; batch adversarial loss: 0.362229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227443; batch adversarial loss: 0.465089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194799; batch adversarial loss: 0.446107\n",
      "epoch 48; iter: 0; batch classifier loss: 0.306833; batch adversarial loss: 0.507393\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202465; batch adversarial loss: 0.537706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223188; batch adversarial loss: 0.423028\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225845; batch adversarial loss: 0.447576\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155381; batch adversarial loss: 0.486634\n",
      "epoch 53; iter: 0; batch classifier loss: 0.203742; batch adversarial loss: 0.445566\n",
      "epoch 54; iter: 0; batch classifier loss: 0.250815; batch adversarial loss: 0.460954\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182396; batch adversarial loss: 0.564597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.178321; batch adversarial loss: 0.466417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135660; batch adversarial loss: 0.492085\n",
      "epoch 58; iter: 0; batch classifier loss: 0.227268; batch adversarial loss: 0.379017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185556; batch adversarial loss: 0.459743\n",
      "epoch 60; iter: 0; batch classifier loss: 0.153740; batch adversarial loss: 0.510053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155630; batch adversarial loss: 0.541576\n",
      "epoch 62; iter: 0; batch classifier loss: 0.116137; batch adversarial loss: 0.521728\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178817; batch adversarial loss: 0.517786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213310; batch adversarial loss: 0.396766\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174103; batch adversarial loss: 0.519237\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168989; batch adversarial loss: 0.469374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171487; batch adversarial loss: 0.438444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227675; batch adversarial loss: 0.382676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129285; batch adversarial loss: 0.448061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153188; batch adversarial loss: 0.513892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189201; batch adversarial loss: 0.483813\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143782; batch adversarial loss: 0.399117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.194640; batch adversarial loss: 0.492915\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222503; batch adversarial loss: 0.506290\n",
      "epoch 75; iter: 0; batch classifier loss: 0.192905; batch adversarial loss: 0.444399\n",
      "epoch 76; iter: 0; batch classifier loss: 0.185618; batch adversarial loss: 0.465811\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102490; batch adversarial loss: 0.387088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.260674; batch adversarial loss: 0.397151\n",
      "epoch 79; iter: 0; batch classifier loss: 0.162815; batch adversarial loss: 0.474389\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195085; batch adversarial loss: 0.410728\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132135; batch adversarial loss: 0.481101\n",
      "epoch 82; iter: 0; batch classifier loss: 0.157003; batch adversarial loss: 0.405431\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114738; batch adversarial loss: 0.472957\n",
      "epoch 84; iter: 0; batch classifier loss: 0.124425; batch adversarial loss: 0.469340\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133828; batch adversarial loss: 0.459536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.127560; batch adversarial loss: 0.468921\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106405; batch adversarial loss: 0.604421\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144443; batch adversarial loss: 0.520639\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117262; batch adversarial loss: 0.506146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087750; batch adversarial loss: 0.443731\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113289; batch adversarial loss: 0.463015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128436; batch adversarial loss: 0.406349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095744; batch adversarial loss: 0.532681\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072927; batch adversarial loss: 0.510598\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050717; batch adversarial loss: 0.512368\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103528; batch adversarial loss: 0.485659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055867; batch adversarial loss: 0.489014\n",
      "epoch 98; iter: 0; batch classifier loss: 0.119304; batch adversarial loss: 0.409256\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058918; batch adversarial loss: 0.356944\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078266; batch adversarial loss: 0.489582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100184; batch adversarial loss: 0.437631\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.432486\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076005; batch adversarial loss: 0.420993\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023383; batch adversarial loss: 0.489630\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.427848\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057579; batch adversarial loss: 0.446779\n",
      "epoch 107; iter: 0; batch classifier loss: 0.016594; batch adversarial loss: 0.571494\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043061; batch adversarial loss: 0.435629\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.449064\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052646; batch adversarial loss: 0.429082\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064466; batch adversarial loss: 0.544246\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.414706\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.438979\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041520; batch adversarial loss: 0.450136\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039195; batch adversarial loss: 0.526165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046723; batch adversarial loss: 0.487179\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028024; batch adversarial loss: 0.413543\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043546; batch adversarial loss: 0.430986\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042654; batch adversarial loss: 0.482377\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038959; batch adversarial loss: 0.380076\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046653; batch adversarial loss: 0.495118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015794; batch adversarial loss: 0.513909\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023094; batch adversarial loss: 0.336286\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063677; batch adversarial loss: 0.488526\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023231; batch adversarial loss: 0.407590\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.499945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025814; batch adversarial loss: 0.477885\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016976; batch adversarial loss: 0.424454\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.436375\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017588; batch adversarial loss: 0.497257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035290; batch adversarial loss: 0.445353\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025357; batch adversarial loss: 0.495507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023691; batch adversarial loss: 0.398855\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032709; batch adversarial loss: 0.477906\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012807; batch adversarial loss: 0.425623\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030065; batch adversarial loss: 0.464185\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041319; batch adversarial loss: 0.495098\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036601; batch adversarial loss: 0.409268\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009201; batch adversarial loss: 0.415366\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010369; batch adversarial loss: 0.548791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.535071\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036020; batch adversarial loss: 0.589606\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015933; batch adversarial loss: 0.460440\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012548; batch adversarial loss: 0.467244\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013664; batch adversarial loss: 0.545864\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026615; batch adversarial loss: 0.433055\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026677; batch adversarial loss: 0.394158\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015726; batch adversarial loss: 0.499501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.500811\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023914; batch adversarial loss: 0.507878\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023069; batch adversarial loss: 0.444022\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015060; batch adversarial loss: 0.406906\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021294; batch adversarial loss: 0.431451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029299; batch adversarial loss: 0.384312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.425266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010244; batch adversarial loss: 0.462371\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013574; batch adversarial loss: 0.496028\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.442006\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011610; batch adversarial loss: 0.426134\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005939; batch adversarial loss: 0.502678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007833; batch adversarial loss: 0.470883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020268; batch adversarial loss: 0.378876\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024588; batch adversarial loss: 0.436137\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023924; batch adversarial loss: 0.466352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030063; batch adversarial loss: 0.400956\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022583; batch adversarial loss: 0.604907\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008819; batch adversarial loss: 0.359732\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005808; batch adversarial loss: 0.514479\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026108; batch adversarial loss: 0.435591\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022649; batch adversarial loss: 0.438637\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025742; batch adversarial loss: 0.494849\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024279; batch adversarial loss: 0.371164\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011350; batch adversarial loss: 0.457860\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007689; batch adversarial loss: 0.433103\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013153; batch adversarial loss: 0.531247\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007330; batch adversarial loss: 0.419843\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012984; batch adversarial loss: 0.491824\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013910; batch adversarial loss: 0.441699\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.515906\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031273; batch adversarial loss: 0.458018\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039369; batch adversarial loss: 0.432972\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.494271\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028760; batch adversarial loss: 0.477630\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003358; batch adversarial loss: 0.410230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008431; batch adversarial loss: 0.415887\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012250; batch adversarial loss: 0.528063\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018286; batch adversarial loss: 0.525953\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012842; batch adversarial loss: 0.436430\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.486868\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016325; batch adversarial loss: 0.362743\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025971; batch adversarial loss: 0.450625\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002842; batch adversarial loss: 0.520413\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014467; batch adversarial loss: 0.450268\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011491; batch adversarial loss: 0.497005\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.466075\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.474331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.001744; batch adversarial loss: 0.376615\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002974; batch adversarial loss: 0.495768\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006627; batch adversarial loss: 0.450932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:49:25.594013: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:3205 op device:{requested: '', assigned: ''} def:{{{node 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.683073; batch adversarial loss: 0.620856\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440653; batch adversarial loss: 0.621911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365344; batch adversarial loss: 0.600834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300769; batch adversarial loss: 0.601682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.272899; batch adversarial loss: 0.534356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387933; batch adversarial loss: 0.513569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376173; batch adversarial loss: 0.530133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.561520\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275634; batch adversarial loss: 0.532561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282988; batch adversarial loss: 0.506175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250687; batch adversarial loss: 0.404790\n",
      "epoch 11; iter: 0; batch classifier loss: 0.310366; batch adversarial loss: 0.531628\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267975; batch adversarial loss: 0.560586\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340264; batch adversarial loss: 0.544327\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312451; batch adversarial loss: 0.493957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489029; batch adversarial loss: 0.491952\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488049; batch adversarial loss: 0.555351\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559185; batch adversarial loss: 0.456053\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281974; batch adversarial loss: 0.509155\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237257; batch adversarial loss: 0.485235\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170045; batch adversarial loss: 0.451948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208757; batch adversarial loss: 0.488383\n",
      "epoch 22; iter: 0; batch classifier loss: 0.176183; batch adversarial loss: 0.451187\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195614; batch adversarial loss: 0.419134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246046; batch adversarial loss: 0.445964\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174144; batch adversarial loss: 0.449422\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182457; batch adversarial loss: 0.482860\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198129; batch adversarial loss: 0.478548\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212512; batch adversarial loss: 0.394042\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183227; batch adversarial loss: 0.388321\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174824; batch adversarial loss: 0.420980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156038; batch adversarial loss: 0.456845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223948; batch adversarial loss: 0.470265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105976; batch adversarial loss: 0.556003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142961; batch adversarial loss: 0.437921\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196068; batch adversarial loss: 0.411923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141115; batch adversarial loss: 0.470426\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165741; batch adversarial loss: 0.353729\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152037; batch adversarial loss: 0.526223\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099027; batch adversarial loss: 0.464474\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110921; batch adversarial loss: 0.452975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089708; batch adversarial loss: 0.475388\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117443; batch adversarial loss: 0.463111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081043; batch adversarial loss: 0.560608\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120436; batch adversarial loss: 0.472981\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098060; batch adversarial loss: 0.487844\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127252; batch adversarial loss: 0.368227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.155660; batch adversarial loss: 0.397125\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104707; batch adversarial loss: 0.495177\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094743; batch adversarial loss: 0.437039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128758; batch adversarial loss: 0.367638\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070209; batch adversarial loss: 0.419098\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121524; batch adversarial loss: 0.511020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109622; batch adversarial loss: 0.444450\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133209; batch adversarial loss: 0.376170\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119858; batch adversarial loss: 0.415048\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084955; batch adversarial loss: 0.505013\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079445; batch adversarial loss: 0.437708\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173282; batch adversarial loss: 0.451169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167735; batch adversarial loss: 0.457671\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118800; batch adversarial loss: 0.457323\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104539; batch adversarial loss: 0.457290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104589; batch adversarial loss: 0.386224\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178848; batch adversarial loss: 0.489418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118512; batch adversarial loss: 0.493791\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118857; batch adversarial loss: 0.426787\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088094; batch adversarial loss: 0.422159\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094197; batch adversarial loss: 0.431979\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094664; batch adversarial loss: 0.475427\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085103; batch adversarial loss: 0.465173\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144985; batch adversarial loss: 0.411650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137528; batch adversarial loss: 0.399713\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100343; batch adversarial loss: 0.345952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114244; batch adversarial loss: 0.513249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079822; batch adversarial loss: 0.488730\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163532; batch adversarial loss: 0.430517\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106552; batch adversarial loss: 0.413256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108928; batch adversarial loss: 0.469671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072789; batch adversarial loss: 0.419774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080087; batch adversarial loss: 0.451439\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133886; batch adversarial loss: 0.384145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108813; batch adversarial loss: 0.489638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127258; batch adversarial loss: 0.392087\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086930; batch adversarial loss: 0.473320\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.472512\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095781; batch adversarial loss: 0.449457\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.437829\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079782; batch adversarial loss: 0.453353\n",
      "epoch 88; iter: 0; batch classifier loss: 0.143531; batch adversarial loss: 0.466258\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069261; batch adversarial loss: 0.354200\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052139; batch adversarial loss: 0.470479\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062476; batch adversarial loss: 0.541695\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082710; batch adversarial loss: 0.480140\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.473447\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075548; batch adversarial loss: 0.447946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058477; batch adversarial loss: 0.426762\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065355; batch adversarial loss: 0.453171\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046726; batch adversarial loss: 0.335832\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053453; batch adversarial loss: 0.476380\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073238; batch adversarial loss: 0.586781\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.427228\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042540; batch adversarial loss: 0.432745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071360; batch adversarial loss: 0.362941\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093896; batch adversarial loss: 0.463941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057524; batch adversarial loss: 0.437521\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051401; batch adversarial loss: 0.405707\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054419; batch adversarial loss: 0.473556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065696; batch adversarial loss: 0.484608\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038128; batch adversarial loss: 0.450714\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050737; batch adversarial loss: 0.470143\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064994; batch adversarial loss: 0.515462\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064557; batch adversarial loss: 0.451665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038048; batch adversarial loss: 0.495670\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069824; batch adversarial loss: 0.392696\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035725; batch adversarial loss: 0.484216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044866; batch adversarial loss: 0.430529\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073175; batch adversarial loss: 0.408202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.107425; batch adversarial loss: 0.540736\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043385; batch adversarial loss: 0.383689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049156; batch adversarial loss: 0.482229\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043849; batch adversarial loss: 0.469089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058626; batch adversarial loss: 0.445064\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015754; batch adversarial loss: 0.330612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045682; batch adversarial loss: 0.485688\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033378; batch adversarial loss: 0.408941\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061630; batch adversarial loss: 0.451863\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019002; batch adversarial loss: 0.464778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026591; batch adversarial loss: 0.464596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028328; batch adversarial loss: 0.404924\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.422667\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.410978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.448252\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026199; batch adversarial loss: 0.412464\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039348; batch adversarial loss: 0.566884\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051199; batch adversarial loss: 0.374595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029727; batch adversarial loss: 0.502335\n",
      "epoch 136; iter: 0; batch classifier loss: 0.086487; batch adversarial loss: 0.358220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060143; batch adversarial loss: 0.515063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053990; batch adversarial loss: 0.432021\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022910; batch adversarial loss: 0.428206\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.459213\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.467816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042714; batch adversarial loss: 0.384554\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043146; batch adversarial loss: 0.339316\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024966; batch adversarial loss: 0.508985\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020702; batch adversarial loss: 0.497956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026609; batch adversarial loss: 0.396169\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042491; batch adversarial loss: 0.516891\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.594180\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040416; batch adversarial loss: 0.530106\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020989; batch adversarial loss: 0.460259\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008401; batch adversarial loss: 0.446931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014468; batch adversarial loss: 0.462676\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.427720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.067858; batch adversarial loss: 0.356513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.426754\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.408194\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024619; batch adversarial loss: 0.531720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044226; batch adversarial loss: 0.399916\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024355; batch adversarial loss: 0.398681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020534; batch adversarial loss: 0.469875\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043514; batch adversarial loss: 0.437727\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.424770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024601; batch adversarial loss: 0.405221\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023990; batch adversarial loss: 0.350152\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040421; batch adversarial loss: 0.382282\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045091; batch adversarial loss: 0.472792\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046813; batch adversarial loss: 0.379816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026784; batch adversarial loss: 0.394039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021587; batch adversarial loss: 0.414904\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.413440\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013882; batch adversarial loss: 0.478051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.448272\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.448238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.065883; batch adversarial loss: 0.425081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040838; batch adversarial loss: 0.481297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018787; batch adversarial loss: 0.461707\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051299; batch adversarial loss: 0.391626\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021155; batch adversarial loss: 0.433748\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028798; batch adversarial loss: 0.413467\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019515; batch adversarial loss: 0.445502\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012136; batch adversarial loss: 0.463219\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021031; batch adversarial loss: 0.507201\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012701; batch adversarial loss: 0.405407\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036952; batch adversarial loss: 0.458699\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013958; batch adversarial loss: 0.426156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.356023\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017771; batch adversarial loss: 0.448996\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058177; batch adversarial loss: 0.411220\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014598; batch adversarial loss: 0.374938\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023809; batch adversarial loss: 0.396063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017848; batch adversarial loss: 0.529327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005764; batch adversarial loss: 0.395014\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005059; batch adversarial loss: 0.442585\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016724; batch adversarial loss: 0.405878\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024334; batch adversarial loss: 0.359202\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006897; batch adversarial loss: 0.479158\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007722; batch adversarial loss: 0.473242\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028269; batch adversarial loss: 0.322968\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031228; batch adversarial loss: 0.561645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:50:02.788655: W tensorflow/c/c_api.cc:304] Operation '{name:'04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:4012 op device:{requested: '', assigned: ''} def:{{{node 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688715; batch adversarial loss: 0.983039\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628121; batch adversarial loss: 1.100539\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900819; batch adversarial loss: 1.126426\n",
      "epoch 3; iter: 0; batch classifier loss: 1.017392; batch adversarial loss: 1.014833\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997079; batch adversarial loss: 0.934127\n",
      "epoch 5; iter: 0; batch classifier loss: 0.972972; batch adversarial loss: 0.840362\n",
      "epoch 6; iter: 0; batch classifier loss: 1.035811; batch adversarial loss: 0.765038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.989932; batch adversarial loss: 0.694059\n",
      "epoch 8; iter: 0; batch classifier loss: 1.016223; batch adversarial loss: 0.648634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.816278; batch adversarial loss: 0.583646\n",
      "epoch 10; iter: 0; batch classifier loss: 0.814806; batch adversarial loss: 0.581283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388503; batch adversarial loss: 0.534007\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460209; batch adversarial loss: 0.522313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363631; batch adversarial loss: 0.483172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334066; batch adversarial loss: 0.538998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330832; batch adversarial loss: 0.503753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335103; batch adversarial loss: 0.460181\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217084; batch adversarial loss: 0.449338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222560; batch adversarial loss: 0.452156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.253071; batch adversarial loss: 0.532440\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192251; batch adversarial loss: 0.515274\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195617; batch adversarial loss: 0.457270\n",
      "epoch 22; iter: 0; batch classifier loss: 0.116874; batch adversarial loss: 0.416551\n",
      "epoch 23; iter: 0; batch classifier loss: 0.110665; batch adversarial loss: 0.418451\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130526; batch adversarial loss: 0.442453\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148387; batch adversarial loss: 0.546933\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121442; batch adversarial loss: 0.433987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.104637; batch adversarial loss: 0.486104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.091559; batch adversarial loss: 0.451715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.084214; batch adversarial loss: 0.447392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.066105; batch adversarial loss: 0.413685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.391311\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114118; batch adversarial loss: 0.363025\n",
      "epoch 33; iter: 0; batch classifier loss: 0.084376; batch adversarial loss: 0.496647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109469; batch adversarial loss: 0.473723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130510; batch adversarial loss: 0.433919\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102940; batch adversarial loss: 0.484450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109572; batch adversarial loss: 0.418393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.059485; batch adversarial loss: 0.538812\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107677; batch adversarial loss: 0.465860\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131476; batch adversarial loss: 0.472353\n",
      "epoch 41; iter: 0; batch classifier loss: 0.057669; batch adversarial loss: 0.450761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.082112; batch adversarial loss: 0.501039\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063107; batch adversarial loss: 0.426068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101416; batch adversarial loss: 0.474336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090052; batch adversarial loss: 0.427132\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081061; batch adversarial loss: 0.443573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100561; batch adversarial loss: 0.462411\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082665; batch adversarial loss: 0.528099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080586; batch adversarial loss: 0.463851\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074351; batch adversarial loss: 0.467955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065128; batch adversarial loss: 0.363463\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065074; batch adversarial loss: 0.505935\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062227; batch adversarial loss: 0.450037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082096; batch adversarial loss: 0.483712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098301; batch adversarial loss: 0.472368\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066021; batch adversarial loss: 0.470020\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061266; batch adversarial loss: 0.469520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091018; batch adversarial loss: 0.460826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088777; batch adversarial loss: 0.368837\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072266; batch adversarial loss: 0.417231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088821; batch adversarial loss: 0.371266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084045; batch adversarial loss: 0.388032\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099800; batch adversarial loss: 0.480330\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070695; batch adversarial loss: 0.464629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050034; batch adversarial loss: 0.461426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091146; batch adversarial loss: 0.408800\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106377; batch adversarial loss: 0.504875\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043170; batch adversarial loss: 0.464844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072073; batch adversarial loss: 0.433548\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.480371\n",
      "epoch 71; iter: 0; batch classifier loss: 0.057055; batch adversarial loss: 0.423309\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088492; batch adversarial loss: 0.363886\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047265; batch adversarial loss: 0.382111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040557; batch adversarial loss: 0.378222\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.436483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047782; batch adversarial loss: 0.469712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045663; batch adversarial loss: 0.431864\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059991; batch adversarial loss: 0.420678\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064905; batch adversarial loss: 0.493314\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.376153\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050206; batch adversarial loss: 0.409281\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046113; batch adversarial loss: 0.467115\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035233; batch adversarial loss: 0.469703\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029775; batch adversarial loss: 0.505177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042924; batch adversarial loss: 0.485360\n",
      "epoch 86; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.443047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.547391\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.348584\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.445219\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048613; batch adversarial loss: 0.498932\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028670; batch adversarial loss: 0.392131\n",
      "epoch 92; iter: 0; batch classifier loss: 0.024187; batch adversarial loss: 0.528975\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032129; batch adversarial loss: 0.476735\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033969; batch adversarial loss: 0.491378\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.406544\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035445; batch adversarial loss: 0.499140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063905; batch adversarial loss: 0.452456\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056222; batch adversarial loss: 0.370576\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046255; batch adversarial loss: 0.461843\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.526640\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037838; batch adversarial loss: 0.428831\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029502; batch adversarial loss: 0.517934\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036693; batch adversarial loss: 0.479803\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033586; batch adversarial loss: 0.462126\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022528; batch adversarial loss: 0.480492\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051269; batch adversarial loss: 0.390230\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025912; batch adversarial loss: 0.428924\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042159; batch adversarial loss: 0.443559\n",
      "epoch 109; iter: 0; batch classifier loss: 0.021290; batch adversarial loss: 0.487578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023505; batch adversarial loss: 0.492512\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017535; batch adversarial loss: 0.410937\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025621; batch adversarial loss: 0.450347\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038833; batch adversarial loss: 0.396705\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033631; batch adversarial loss: 0.478048\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033618; batch adversarial loss: 0.445996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021869; batch adversarial loss: 0.450988\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025700; batch adversarial loss: 0.489628\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052874; batch adversarial loss: 0.503270\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044407; batch adversarial loss: 0.487963\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.468673\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042812; batch adversarial loss: 0.489505\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.412301\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036888; batch adversarial loss: 0.312297\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036261; batch adversarial loss: 0.461313\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038236; batch adversarial loss: 0.519647\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039189; batch adversarial loss: 0.494202\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035679; batch adversarial loss: 0.501105\n",
      "epoch 128; iter: 0; batch classifier loss: 0.010645; batch adversarial loss: 0.499304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018803; batch adversarial loss: 0.537932\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061528; batch adversarial loss: 0.496497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.009915; batch adversarial loss: 0.458411\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034905; batch adversarial loss: 0.429200\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.538931\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020050; batch adversarial loss: 0.378343\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036235; batch adversarial loss: 0.495071\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033578; batch adversarial loss: 0.513097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042364; batch adversarial loss: 0.465550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021714; batch adversarial loss: 0.450820\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014111; batch adversarial loss: 0.409608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017977; batch adversarial loss: 0.388635\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023161; batch adversarial loss: 0.446668\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048083; batch adversarial loss: 0.429200\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025612; batch adversarial loss: 0.396818\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.315482\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024941; batch adversarial loss: 0.376494\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041394; batch adversarial loss: 0.386173\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024354; batch adversarial loss: 0.495191\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014848; batch adversarial loss: 0.530843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.405986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053988; batch adversarial loss: 0.362676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024418; batch adversarial loss: 0.431975\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030281; batch adversarial loss: 0.427211\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.485753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040641; batch adversarial loss: 0.496311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024292; batch adversarial loss: 0.391502\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.431918\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.478216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.474453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026862; batch adversarial loss: 0.497809\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.467878\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010025; batch adversarial loss: 0.482063\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.359276\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006330; batch adversarial loss: 0.433474\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029055; batch adversarial loss: 0.578649\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.478374\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024393; batch adversarial loss: 0.476705\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022079; batch adversarial loss: 0.578530\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017073; batch adversarial loss: 0.552534\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013898; batch adversarial loss: 0.532417\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012398; batch adversarial loss: 0.422551\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012326; batch adversarial loss: 0.436369\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031451; batch adversarial loss: 0.428115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020282; batch adversarial loss: 0.416464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021471; batch adversarial loss: 0.379303\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009096; batch adversarial loss: 0.368390\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041444; batch adversarial loss: 0.411759\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008289; batch adversarial loss: 0.522269\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b80bd",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159becbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff43f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb933b4632f547a3ba8301fd5364c345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fe8f8b2384482bacdbfb5f813ffc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce3377f82a7496e821f1474f8b313b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.792746; batch adversarial loss: 1.005012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.949620; batch adversarial loss: 1.258500\n",
      "epoch 2; iter: 0; batch classifier loss: 1.028043; batch adversarial loss: 1.144422\n",
      "epoch 3; iter: 0; batch classifier loss: 1.045848; batch adversarial loss: 1.075771\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997219; batch adversarial loss: 0.978551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.916257; batch adversarial loss: 0.886703\n",
      "epoch 6; iter: 0; batch classifier loss: 0.807742; batch adversarial loss: 0.777476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.756174; batch adversarial loss: 0.765084\n",
      "epoch 8; iter: 0; batch classifier loss: 0.751323; batch adversarial loss: 0.715508\n",
      "epoch 9; iter: 0; batch classifier loss: 0.661528; batch adversarial loss: 0.746465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532497; batch adversarial loss: 0.583311\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556063; batch adversarial loss: 0.609865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509892; batch adversarial loss: 0.630546\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474373; batch adversarial loss: 0.588323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566039; batch adversarial loss: 0.598633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544423; batch adversarial loss: 0.595941\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478303; batch adversarial loss: 0.716907\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506884; batch adversarial loss: 0.531912\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484061; batch adversarial loss: 0.641703\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484366; batch adversarial loss: 0.609042\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496752; batch adversarial loss: 0.581835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515339; batch adversarial loss: 0.610445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452971; batch adversarial loss: 0.628669\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4b07f",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117cc096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9ad196b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a9b30",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb144d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eab5bc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df98c4b",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d949048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24c00e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:57:45 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e688e62cc53746f78db4dbb68669cf6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:57:45 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 8104,   580,  8954,  6500,  5436,  3490,  1621, 11610,  7067,\n",
      "            10637,   767, 10997,  6202,  4468,  8440, 10810, 11409,  3682,\n",
      "            12856, 14104],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 8104,   580,  8954,  6500,  5436,  3490,  1621, 11610,  7067,\n",
      "            10637,   767, 10997,  6202,  4468,  8440, 10810, 11409,  3682,\n",
      "            12856, 14104],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154edc79d7344df98051d9abca62cde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1489c3f347df424e995c808bd8e4817a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.684145; batch adversarial loss: 0.644539\n",
      "epoch 1; iter: 0; batch classifier loss: 0.580058; batch adversarial loss: 0.653906\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578750; batch adversarial loss: 0.647689\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616405; batch adversarial loss: 0.643259\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615069; batch adversarial loss: 0.663510\n",
      "epoch 5; iter: 0; batch classifier loss: 0.504996; batch adversarial loss: 0.650209\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537448; batch adversarial loss: 0.576787\n",
      "epoch 7; iter: 0; batch classifier loss: 0.619461; batch adversarial loss: 0.596909\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570439; batch adversarial loss: 0.583552\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580571; batch adversarial loss: 0.549997\n",
      "epoch 10; iter: 0; batch classifier loss: 0.654022; batch adversarial loss: 0.621231\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522804; batch adversarial loss: 0.551754\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569841; batch adversarial loss: 0.611424\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534823; batch adversarial loss: 0.581751\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563823; batch adversarial loss: 0.596233\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488606; batch adversarial loss: 0.529958\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487285; batch adversarial loss: 0.510018\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547271; batch adversarial loss: 0.604399\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514399; batch adversarial loss: 0.539079\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459594; batch adversarial loss: 0.600295\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507103; batch adversarial loss: 0.587754\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474855; batch adversarial loss: 0.562192\n",
      "epoch 22; iter: 0; batch classifier loss: 0.421078; batch adversarial loss: 0.561047\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464985; batch adversarial loss: 0.551694\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514564; batch adversarial loss: 0.587713\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471627; batch adversarial loss: 0.555751\n",
      "epoch 26; iter: 0; batch classifier loss: 0.538778; batch adversarial loss: 0.510410\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437191; batch adversarial loss: 0.539595\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487250; batch adversarial loss: 0.569435\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436576; batch adversarial loss: 0.442948\n",
      "epoch 30; iter: 0; batch classifier loss: 0.564676; batch adversarial loss: 0.594124\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499919; batch adversarial loss: 0.520501\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445908; batch adversarial loss: 0.500041\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452469; batch adversarial loss: 0.519268\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437218; batch adversarial loss: 0.599063\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395438; batch adversarial loss: 0.545652\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472219; batch adversarial loss: 0.538418\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457658; batch adversarial loss: 0.530456\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469619; batch adversarial loss: 0.561532\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452642; batch adversarial loss: 0.574340\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453942; batch adversarial loss: 0.589493\n",
      "epoch 41; iter: 0; batch classifier loss: 0.387493; batch adversarial loss: 0.590729\n",
      "epoch 42; iter: 0; batch classifier loss: 0.361763; batch adversarial loss: 0.500250\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434870; batch adversarial loss: 0.526207\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481584; batch adversarial loss: 0.546064\n",
      "epoch 45; iter: 0; batch classifier loss: 0.366183; batch adversarial loss: 0.553646\n",
      "epoch 46; iter: 0; batch classifier loss: 0.449387; batch adversarial loss: 0.553693\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438119; batch adversarial loss: 0.508561\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468639; batch adversarial loss: 0.527083\n",
      "epoch 49; iter: 0; batch classifier loss: 0.370619; batch adversarial loss: 0.625829\n",
      "epoch 50; iter: 0; batch classifier loss: 0.377330; batch adversarial loss: 0.534810\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418830; batch adversarial loss: 0.442030\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476223; batch adversarial loss: 0.588247\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437313; batch adversarial loss: 0.509228\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394976; batch adversarial loss: 0.535860\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462886; batch adversarial loss: 0.514853\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449684; batch adversarial loss: 0.520567\n",
      "epoch 57; iter: 0; batch classifier loss: 0.485800; batch adversarial loss: 0.570635\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411129; batch adversarial loss: 0.523014\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421979; batch adversarial loss: 0.552572\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444884; batch adversarial loss: 0.585996\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414251; batch adversarial loss: 0.527787\n",
      "epoch 62; iter: 0; batch classifier loss: 0.497535; batch adversarial loss: 0.628730\n",
      "epoch 63; iter: 0; batch classifier loss: 0.451090; batch adversarial loss: 0.461024\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407785; batch adversarial loss: 0.538503\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457818; batch adversarial loss: 0.577998\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423371; batch adversarial loss: 0.590593\n",
      "epoch 67; iter: 0; batch classifier loss: 0.424587; batch adversarial loss: 0.609577\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394042; batch adversarial loss: 0.579333\n",
      "epoch 69; iter: 0; batch classifier loss: 0.483168; batch adversarial loss: 0.595201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393103; batch adversarial loss: 0.563812\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416869; batch adversarial loss: 0.593443\n",
      "epoch 72; iter: 0; batch classifier loss: 0.353643; batch adversarial loss: 0.521308\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442756; batch adversarial loss: 0.624958\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364847; batch adversarial loss: 0.561488\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416375; batch adversarial loss: 0.555444\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418912; batch adversarial loss: 0.560933\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345011; batch adversarial loss: 0.562853\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402243; batch adversarial loss: 0.571597\n",
      "epoch 79; iter: 0; batch classifier loss: 0.461469; batch adversarial loss: 0.491167\n",
      "epoch 80; iter: 0; batch classifier loss: 0.391600; batch adversarial loss: 0.572667\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410525; batch adversarial loss: 0.622903\n",
      "epoch 82; iter: 0; batch classifier loss: 0.334545; batch adversarial loss: 0.555460\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356439; batch adversarial loss: 0.509878\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402892; batch adversarial loss: 0.526538\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399193; batch adversarial loss: 0.543951\n",
      "epoch 86; iter: 0; batch classifier loss: 0.438160; batch adversarial loss: 0.598305\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366900; batch adversarial loss: 0.525770\n",
      "epoch 88; iter: 0; batch classifier loss: 0.446631; batch adversarial loss: 0.561790\n",
      "epoch 89; iter: 0; batch classifier loss: 0.442388; batch adversarial loss: 0.544550\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413627; batch adversarial loss: 0.553834\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432951; batch adversarial loss: 0.481554\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413419; batch adversarial loss: 0.553298\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366986; batch adversarial loss: 0.518982\n",
      "epoch 94; iter: 0; batch classifier loss: 0.367569; batch adversarial loss: 0.508123\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357039; batch adversarial loss: 0.588992\n",
      "epoch 96; iter: 0; batch classifier loss: 0.378002; batch adversarial loss: 0.563846\n",
      "epoch 97; iter: 0; batch classifier loss: 0.447806; batch adversarial loss: 0.571470\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416253; batch adversarial loss: 0.570655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.374843; batch adversarial loss: 0.536721\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423472; batch adversarial loss: 0.606275\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396619; batch adversarial loss: 0.581402\n",
      "epoch 102; iter: 0; batch classifier loss: 0.311355; batch adversarial loss: 0.562154\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416523; batch adversarial loss: 0.598707\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386251; batch adversarial loss: 0.554057\n",
      "epoch 105; iter: 0; batch classifier loss: 0.447931; batch adversarial loss: 0.490939\n",
      "epoch 106; iter: 0; batch classifier loss: 0.478180; batch adversarial loss: 0.534667\n",
      "epoch 107; iter: 0; batch classifier loss: 0.422878; batch adversarial loss: 0.508767\n",
      "epoch 108; iter: 0; batch classifier loss: 0.412333; batch adversarial loss: 0.562843\n",
      "epoch 109; iter: 0; batch classifier loss: 0.422472; batch adversarial loss: 0.546776\n",
      "epoch 110; iter: 0; batch classifier loss: 0.380171; batch adversarial loss: 0.544610\n",
      "epoch 111; iter: 0; batch classifier loss: 0.431562; batch adversarial loss: 0.506888\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365664; batch adversarial loss: 0.543469\n",
      "epoch 113; iter: 0; batch classifier loss: 0.334431; batch adversarial loss: 0.563318\n",
      "epoch 114; iter: 0; batch classifier loss: 0.387050; batch adversarial loss: 0.527427\n",
      "epoch 115; iter: 0; batch classifier loss: 0.365166; batch adversarial loss: 0.462909\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370353; batch adversarial loss: 0.535441\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339334; batch adversarial loss: 0.554151\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351566; batch adversarial loss: 0.517769\n",
      "epoch 119; iter: 0; batch classifier loss: 0.403489; batch adversarial loss: 0.453312\n",
      "epoch 120; iter: 0; batch classifier loss: 0.465286; batch adversarial loss: 0.589204\n",
      "epoch 121; iter: 0; batch classifier loss: 0.427189; batch adversarial loss: 0.562948\n",
      "epoch 122; iter: 0; batch classifier loss: 0.443773; batch adversarial loss: 0.562859\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375850; batch adversarial loss: 0.499398\n",
      "epoch 124; iter: 0; batch classifier loss: 0.333864; batch adversarial loss: 0.608431\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373840; batch adversarial loss: 0.498691\n",
      "epoch 126; iter: 0; batch classifier loss: 0.315772; batch adversarial loss: 0.544919\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352789; batch adversarial loss: 0.589759\n",
      "epoch 128; iter: 0; batch classifier loss: 0.398204; batch adversarial loss: 0.516969\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336887; batch adversarial loss: 0.489161\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385049; batch adversarial loss: 0.581055\n",
      "epoch 131; iter: 0; batch classifier loss: 0.369487; batch adversarial loss: 0.571776\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360365; batch adversarial loss: 0.481114\n",
      "epoch 133; iter: 0; batch classifier loss: 0.422459; batch adversarial loss: 0.598756\n",
      "epoch 134; iter: 0; batch classifier loss: 0.317923; batch adversarial loss: 0.554811\n",
      "epoch 135; iter: 0; batch classifier loss: 0.261409; batch adversarial loss: 0.516763\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360613; batch adversarial loss: 0.497788\n",
      "epoch 137; iter: 0; batch classifier loss: 0.355487; batch adversarial loss: 0.506726\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382027; batch adversarial loss: 0.570422\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362157; batch adversarial loss: 0.580647\n",
      "epoch 140; iter: 0; batch classifier loss: 0.370035; batch adversarial loss: 0.553716\n",
      "epoch 141; iter: 0; batch classifier loss: 0.298350; batch adversarial loss: 0.561180\n",
      "epoch 142; iter: 0; batch classifier loss: 0.394061; batch adversarial loss: 0.589854\n",
      "epoch 143; iter: 0; batch classifier loss: 0.402712; batch adversarial loss: 0.516765\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312477; batch adversarial loss: 0.562028\n",
      "epoch 145; iter: 0; batch classifier loss: 0.308486; batch adversarial loss: 0.546082\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345375; batch adversarial loss: 0.615713\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388052; batch adversarial loss: 0.498441\n",
      "epoch 148; iter: 0; batch classifier loss: 0.311229; batch adversarial loss: 0.589482\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362896; batch adversarial loss: 0.590172\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326965; batch adversarial loss: 0.553480\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417953; batch adversarial loss: 0.534815\n",
      "epoch 152; iter: 0; batch classifier loss: 0.434732; batch adversarial loss: 0.464404\n",
      "epoch 153; iter: 0; batch classifier loss: 0.434892; batch adversarial loss: 0.616992\n",
      "epoch 154; iter: 0; batch classifier loss: 0.286109; batch adversarial loss: 0.518062\n",
      "epoch 155; iter: 0; batch classifier loss: 0.320532; batch adversarial loss: 0.608536\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344303; batch adversarial loss: 0.562711\n",
      "epoch 157; iter: 0; batch classifier loss: 0.390355; batch adversarial loss: 0.543731\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346289; batch adversarial loss: 0.571811\n",
      "epoch 159; iter: 0; batch classifier loss: 0.320144; batch adversarial loss: 0.590782\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365000; batch adversarial loss: 0.544484\n",
      "epoch 161; iter: 0; batch classifier loss: 0.438104; batch adversarial loss: 0.552934\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371426; batch adversarial loss: 0.544543\n",
      "epoch 163; iter: 0; batch classifier loss: 0.352476; batch adversarial loss: 0.481679\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414421; batch adversarial loss: 0.590306\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377417; batch adversarial loss: 0.562822\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354470; batch adversarial loss: 0.498079\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360597; batch adversarial loss: 0.608157\n",
      "epoch 168; iter: 0; batch classifier loss: 0.316184; batch adversarial loss: 0.534483\n",
      "epoch 169; iter: 0; batch classifier loss: 0.449007; batch adversarial loss: 0.572141\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366484; batch adversarial loss: 0.479677\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381585; batch adversarial loss: 0.535965\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341493; batch adversarial loss: 0.489978\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349357; batch adversarial loss: 0.535429\n",
      "epoch 174; iter: 0; batch classifier loss: 0.388254; batch adversarial loss: 0.480601\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376720; batch adversarial loss: 0.544695\n",
      "epoch 176; iter: 0; batch classifier loss: 0.463316; batch adversarial loss: 0.571906\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355774; batch adversarial loss: 0.544180\n",
      "epoch 178; iter: 0; batch classifier loss: 0.496351; batch adversarial loss: 0.553644\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383786; batch adversarial loss: 0.563217\n",
      "epoch 180; iter: 0; batch classifier loss: 0.313739; batch adversarial loss: 0.598734\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358069; batch adversarial loss: 0.543975\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383366; batch adversarial loss: 0.517455\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371873; batch adversarial loss: 0.517178\n",
      "epoch 184; iter: 0; batch classifier loss: 0.278878; batch adversarial loss: 0.544366\n",
      "epoch 185; iter: 0; batch classifier loss: 0.307613; batch adversarial loss: 0.580031\n",
      "epoch 186; iter: 0; batch classifier loss: 0.354245; batch adversarial loss: 0.516627\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319814; batch adversarial loss: 0.516920\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366738; batch adversarial loss: 0.526273\n",
      "epoch 189; iter: 0; batch classifier loss: 0.408187; batch adversarial loss: 0.580956\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380959; batch adversarial loss: 0.490634\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346507; batch adversarial loss: 0.507938\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404703; batch adversarial loss: 0.552790\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330689; batch adversarial loss: 0.526916\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372970; batch adversarial loss: 0.654237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.271704; batch adversarial loss: 0.535049\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301217; batch adversarial loss: 0.545321\n",
      "epoch 197; iter: 0; batch classifier loss: 0.406387; batch adversarial loss: 0.527256\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329312; batch adversarial loss: 0.590383\n",
      "epoch 199; iter: 0; batch classifier loss: 0.373179; batch adversarial loss: 0.480962\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741490; batch adversarial loss: 0.993059\n",
      "epoch 1; iter: 0; batch classifier loss: 0.938762; batch adversarial loss: 1.098047\n",
      "epoch 2; iter: 0; batch classifier loss: 0.989741; batch adversarial loss: 1.046515\n",
      "epoch 3; iter: 0; batch classifier loss: 1.064086; batch adversarial loss: 0.978995\n",
      "epoch 4; iter: 0; batch classifier loss: 1.027467; batch adversarial loss: 0.893376\n",
      "epoch 5; iter: 0; batch classifier loss: 1.196196; batch adversarial loss: 0.861883\n",
      "epoch 6; iter: 0; batch classifier loss: 0.975744; batch adversarial loss: 0.767299\n",
      "epoch 7; iter: 0; batch classifier loss: 0.827731; batch adversarial loss: 0.705094\n",
      "epoch 8; iter: 0; batch classifier loss: 0.789424; batch adversarial loss: 0.694155\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586251; batch adversarial loss: 0.607213\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555443; batch adversarial loss: 0.575154\n",
      "epoch 11; iter: 0; batch classifier loss: 0.598974; batch adversarial loss: 0.584942\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515480; batch adversarial loss: 0.576971\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481475; batch adversarial loss: 0.562630\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535715; batch adversarial loss: 0.563065\n",
      "epoch 15; iter: 0; batch classifier loss: 0.457572; batch adversarial loss: 0.616743\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445008; batch adversarial loss: 0.577273\n",
      "epoch 17; iter: 0; batch classifier loss: 0.551791; batch adversarial loss: 0.535709\n",
      "epoch 18; iter: 0; batch classifier loss: 0.439515; batch adversarial loss: 0.566444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492408; batch adversarial loss: 0.563352\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489881; batch adversarial loss: 0.618796\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516754; batch adversarial loss: 0.575808\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474781; batch adversarial loss: 0.577855\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452192; batch adversarial loss: 0.605448\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479216; batch adversarial loss: 0.543152\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493840; batch adversarial loss: 0.610312\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413370; batch adversarial loss: 0.512667\n",
      "epoch 27; iter: 0; batch classifier loss: 0.530739; batch adversarial loss: 0.614631\n",
      "epoch 28; iter: 0; batch classifier loss: 0.537389; batch adversarial loss: 0.556585\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482580; batch adversarial loss: 0.534050\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480204; batch adversarial loss: 0.550356\n",
      "epoch 31; iter: 0; batch classifier loss: 0.530823; batch adversarial loss: 0.522303\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498929; batch adversarial loss: 0.627926\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430514; batch adversarial loss: 0.620102\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457723; batch adversarial loss: 0.637040\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434004; batch adversarial loss: 0.581070\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480025; batch adversarial loss: 0.521955\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416459; batch adversarial loss: 0.579790\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474834; batch adversarial loss: 0.494610\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471723; batch adversarial loss: 0.589392\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398790; batch adversarial loss: 0.588333\n",
      "epoch 41; iter: 0; batch classifier loss: 0.399543; batch adversarial loss: 0.494965\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402317; batch adversarial loss: 0.591864\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484628; batch adversarial loss: 0.572620\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401519; batch adversarial loss: 0.503573\n",
      "epoch 45; iter: 0; batch classifier loss: 0.530289; batch adversarial loss: 0.506128\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458640; batch adversarial loss: 0.495464\n",
      "epoch 47; iter: 0; batch classifier loss: 0.372585; batch adversarial loss: 0.582213\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417959; batch adversarial loss: 0.513952\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385435; batch adversarial loss: 0.537665\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403761; batch adversarial loss: 0.530051\n",
      "epoch 51; iter: 0; batch classifier loss: 0.388183; batch adversarial loss: 0.525074\n",
      "epoch 52; iter: 0; batch classifier loss: 0.394541; batch adversarial loss: 0.485453\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444698; batch adversarial loss: 0.578429\n",
      "epoch 54; iter: 0; batch classifier loss: 0.319309; batch adversarial loss: 0.511705\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421063; batch adversarial loss: 0.565536\n",
      "epoch 56; iter: 0; batch classifier loss: 0.328148; batch adversarial loss: 0.524805\n",
      "epoch 57; iter: 0; batch classifier loss: 0.458966; batch adversarial loss: 0.537162\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402067; batch adversarial loss: 0.545296\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371207; batch adversarial loss: 0.554329\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356038; batch adversarial loss: 0.525539\n",
      "epoch 61; iter: 0; batch classifier loss: 0.362567; batch adversarial loss: 0.462368\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416033; batch adversarial loss: 0.508141\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454354; batch adversarial loss: 0.669107\n",
      "epoch 64; iter: 0; batch classifier loss: 0.392406; batch adversarial loss: 0.470310\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426976; batch adversarial loss: 0.573339\n",
      "epoch 66; iter: 0; batch classifier loss: 0.353248; batch adversarial loss: 0.598148\n",
      "epoch 67; iter: 0; batch classifier loss: 0.438447; batch adversarial loss: 0.536569\n",
      "epoch 68; iter: 0; batch classifier loss: 0.464914; batch adversarial loss: 0.534911\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438029; batch adversarial loss: 0.592583\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402304; batch adversarial loss: 0.572307\n",
      "epoch 71; iter: 0; batch classifier loss: 0.355950; batch adversarial loss: 0.568832\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355441; batch adversarial loss: 0.562755\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380884; batch adversarial loss: 0.579687\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441233; batch adversarial loss: 0.455332\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354557; batch adversarial loss: 0.562603\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398538; batch adversarial loss: 0.562916\n",
      "epoch 77; iter: 0; batch classifier loss: 0.352336; batch adversarial loss: 0.634115\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391201; batch adversarial loss: 0.527119\n",
      "epoch 79; iter: 0; batch classifier loss: 0.344623; batch adversarial loss: 0.588984\n",
      "epoch 80; iter: 0; batch classifier loss: 0.338331; batch adversarial loss: 0.490292\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406364; batch adversarial loss: 0.516567\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385237; batch adversarial loss: 0.551962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423675; batch adversarial loss: 0.534661\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389846; batch adversarial loss: 0.609588\n",
      "epoch 85; iter: 0; batch classifier loss: 0.454723; batch adversarial loss: 0.481610\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383442; batch adversarial loss: 0.572428\n",
      "epoch 87; iter: 0; batch classifier loss: 0.353268; batch adversarial loss: 0.580050\n",
      "epoch 88; iter: 0; batch classifier loss: 0.349643; batch adversarial loss: 0.480789\n",
      "epoch 89; iter: 0; batch classifier loss: 0.351707; batch adversarial loss: 0.473603\n",
      "epoch 90; iter: 0; batch classifier loss: 0.459985; batch adversarial loss: 0.516686\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389944; batch adversarial loss: 0.610041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.302593; batch adversarial loss: 0.507499\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431562; batch adversarial loss: 0.590530\n",
      "epoch 94; iter: 0; batch classifier loss: 0.326829; batch adversarial loss: 0.472079\n",
      "epoch 95; iter: 0; batch classifier loss: 0.289661; batch adversarial loss: 0.571453\n",
      "epoch 96; iter: 0; batch classifier loss: 0.446774; batch adversarial loss: 0.526690\n",
      "epoch 97; iter: 0; batch classifier loss: 0.314728; batch adversarial loss: 0.546105\n",
      "epoch 98; iter: 0; batch classifier loss: 0.302844; batch adversarial loss: 0.572612\n",
      "epoch 99; iter: 0; batch classifier loss: 0.343228; batch adversarial loss: 0.472556\n",
      "epoch 100; iter: 0; batch classifier loss: 0.334766; batch adversarial loss: 0.462868\n",
      "epoch 101; iter: 0; batch classifier loss: 0.325876; batch adversarial loss: 0.590416\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330087; batch adversarial loss: 0.527740\n",
      "epoch 103; iter: 0; batch classifier loss: 0.325456; batch adversarial loss: 0.543446\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409067; batch adversarial loss: 0.517650\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378341; batch adversarial loss: 0.517381\n",
      "epoch 106; iter: 0; batch classifier loss: 0.340769; batch adversarial loss: 0.588947\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358851; batch adversarial loss: 0.553546\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401132; batch adversarial loss: 0.581550\n",
      "epoch 109; iter: 0; batch classifier loss: 0.338505; batch adversarial loss: 0.589819\n",
      "epoch 110; iter: 0; batch classifier loss: 0.288867; batch adversarial loss: 0.543993\n",
      "epoch 111; iter: 0; batch classifier loss: 0.425383; batch adversarial loss: 0.497708\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353122; batch adversarial loss: 0.509640\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357840; batch adversarial loss: 0.436575\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410454; batch adversarial loss: 0.463108\n",
      "epoch 115; iter: 0; batch classifier loss: 0.410178; batch adversarial loss: 0.516805\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323016; batch adversarial loss: 0.552467\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338316; batch adversarial loss: 0.580187\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335229; batch adversarial loss: 0.570906\n",
      "epoch 119; iter: 0; batch classifier loss: 0.407093; batch adversarial loss: 0.473541\n",
      "epoch 120; iter: 0; batch classifier loss: 0.329627; batch adversarial loss: 0.609453\n",
      "epoch 121; iter: 0; batch classifier loss: 0.342675; batch adversarial loss: 0.581064\n",
      "epoch 122; iter: 0; batch classifier loss: 0.314693; batch adversarial loss: 0.526738\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395740; batch adversarial loss: 0.571102\n",
      "epoch 124; iter: 0; batch classifier loss: 0.306401; batch adversarial loss: 0.616540\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349398; batch adversarial loss: 0.552801\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376826; batch adversarial loss: 0.515306\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374690; batch adversarial loss: 0.526938\n",
      "epoch 128; iter: 0; batch classifier loss: 0.345224; batch adversarial loss: 0.581126\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401385; batch adversarial loss: 0.534467\n",
      "epoch 130; iter: 0; batch classifier loss: 0.350667; batch adversarial loss: 0.572367\n",
      "epoch 131; iter: 0; batch classifier loss: 0.223069; batch adversarial loss: 0.535900\n",
      "epoch 132; iter: 0; batch classifier loss: 0.284115; batch adversarial loss: 0.625154\n",
      "epoch 133; iter: 0; batch classifier loss: 0.310266; batch adversarial loss: 0.535418\n",
      "epoch 134; iter: 0; batch classifier loss: 0.268783; batch adversarial loss: 0.515943\n",
      "epoch 135; iter: 0; batch classifier loss: 0.307882; batch adversarial loss: 0.508326\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361939; batch adversarial loss: 0.479784\n",
      "epoch 137; iter: 0; batch classifier loss: 0.309131; batch adversarial loss: 0.550981\n",
      "epoch 138; iter: 0; batch classifier loss: 0.371570; batch adversarial loss: 0.599497\n",
      "epoch 139; iter: 0; batch classifier loss: 0.274716; batch adversarial loss: 0.507726\n",
      "epoch 140; iter: 0; batch classifier loss: 0.314768; batch adversarial loss: 0.597941\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377065; batch adversarial loss: 0.516940\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368266; batch adversarial loss: 0.579209\n",
      "epoch 143; iter: 0; batch classifier loss: 0.319315; batch adversarial loss: 0.526660\n",
      "epoch 144; iter: 0; batch classifier loss: 0.373570; batch adversarial loss: 0.534340\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331550; batch adversarial loss: 0.608266\n",
      "epoch 146; iter: 0; batch classifier loss: 0.364011; batch adversarial loss: 0.519020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347105; batch adversarial loss: 0.589432\n",
      "epoch 148; iter: 0; batch classifier loss: 0.271777; batch adversarial loss: 0.608972\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378805; batch adversarial loss: 0.562727\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344259; batch adversarial loss: 0.606284\n",
      "epoch 151; iter: 0; batch classifier loss: 0.298022; batch adversarial loss: 0.564227\n",
      "epoch 152; iter: 0; batch classifier loss: 0.412956; batch adversarial loss: 0.481209\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336627; batch adversarial loss: 0.644050\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346218; batch adversarial loss: 0.526374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358583; batch adversarial loss: 0.562379\n",
      "epoch 156; iter: 0; batch classifier loss: 0.318754; batch adversarial loss: 0.535349\n",
      "epoch 157; iter: 0; batch classifier loss: 0.293420; batch adversarial loss: 0.598083\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334680; batch adversarial loss: 0.608465\n",
      "epoch 159; iter: 0; batch classifier loss: 0.384704; batch adversarial loss: 0.553500\n",
      "epoch 160; iter: 0; batch classifier loss: 0.311162; batch adversarial loss: 0.517465\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392507; batch adversarial loss: 0.489968\n",
      "epoch 162; iter: 0; batch classifier loss: 0.280020; batch adversarial loss: 0.653248\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335539; batch adversarial loss: 0.453695\n",
      "epoch 164; iter: 0; batch classifier loss: 0.343291; batch adversarial loss: 0.489681\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348261; batch adversarial loss: 0.635591\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331913; batch adversarial loss: 0.527523\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334366; batch adversarial loss: 0.554628\n",
      "epoch 168; iter: 0; batch classifier loss: 0.285486; batch adversarial loss: 0.581044\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353083; batch adversarial loss: 0.553896\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344293; batch adversarial loss: 0.544964\n",
      "epoch 171; iter: 0; batch classifier loss: 0.278902; batch adversarial loss: 0.518507\n",
      "epoch 172; iter: 0; batch classifier loss: 0.307464; batch adversarial loss: 0.634400\n",
      "epoch 173; iter: 0; batch classifier loss: 0.275834; batch adversarial loss: 0.554522\n",
      "epoch 174; iter: 0; batch classifier loss: 0.333113; batch adversarial loss: 0.616609\n",
      "epoch 175; iter: 0; batch classifier loss: 0.305659; batch adversarial loss: 0.544924\n",
      "epoch 176; iter: 0; batch classifier loss: 0.331448; batch adversarial loss: 0.554081\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337261; batch adversarial loss: 0.572287\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344108; batch adversarial loss: 0.571570\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344846; batch adversarial loss: 0.589742\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333476; batch adversarial loss: 0.535814\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331050; batch adversarial loss: 0.545015\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334006; batch adversarial loss: 0.471452\n",
      "epoch 183; iter: 0; batch classifier loss: 0.322726; batch adversarial loss: 0.489414\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358662; batch adversarial loss: 0.625921\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320498; batch adversarial loss: 0.599442\n",
      "epoch 186; iter: 0; batch classifier loss: 0.296916; batch adversarial loss: 0.534418\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322804; batch adversarial loss: 0.544554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.285753; batch adversarial loss: 0.544355\n",
      "epoch 189; iter: 0; batch classifier loss: 0.266314; batch adversarial loss: 0.589360\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306162; batch adversarial loss: 0.616392\n",
      "epoch 191; iter: 0; batch classifier loss: 0.252200; batch adversarial loss: 0.571396\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317981; batch adversarial loss: 0.435016\n",
      "epoch 193; iter: 0; batch classifier loss: 0.276790; batch adversarial loss: 0.607137\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332923; batch adversarial loss: 0.572646\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312689; batch adversarial loss: 0.652805\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349293; batch adversarial loss: 0.580643\n",
      "epoch 197; iter: 0; batch classifier loss: 0.263458; batch adversarial loss: 0.526011\n",
      "epoch 198; iter: 0; batch classifier loss: 0.283320; batch adversarial loss: 0.552034\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333179; batch adversarial loss: 0.535353\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741384; batch adversarial loss: 0.888209\n",
      "epoch 1; iter: 0; batch classifier loss: 0.780102; batch adversarial loss: 0.884265\n",
      "epoch 2; iter: 0; batch classifier loss: 0.895702; batch adversarial loss: 0.857190\n",
      "epoch 3; iter: 0; batch classifier loss: 0.835783; batch adversarial loss: 0.787073\n",
      "epoch 4; iter: 0; batch classifier loss: 0.823965; batch adversarial loss: 0.722031\n",
      "epoch 5; iter: 0; batch classifier loss: 0.918131; batch adversarial loss: 0.680461\n",
      "epoch 6; iter: 0; batch classifier loss: 0.996331; batch adversarial loss: 0.635768\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591796; batch adversarial loss: 0.617828\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575748; batch adversarial loss: 0.584426\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574572; batch adversarial loss: 0.598816\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544554; batch adversarial loss: 0.604086\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537864; batch adversarial loss: 0.603945\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476439; batch adversarial loss: 0.640607\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517016; batch adversarial loss: 0.571820\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541933; batch adversarial loss: 0.596442\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508581; batch adversarial loss: 0.522886\n",
      "epoch 16; iter: 0; batch classifier loss: 0.607294; batch adversarial loss: 0.548536\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466000; batch adversarial loss: 0.627320\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498243; batch adversarial loss: 0.584111\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461576; batch adversarial loss: 0.562039\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428864; batch adversarial loss: 0.604304\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491966; batch adversarial loss: 0.522233\n",
      "epoch 22; iter: 0; batch classifier loss: 0.536024; batch adversarial loss: 0.602995\n",
      "epoch 23; iter: 0; batch classifier loss: 0.560741; batch adversarial loss: 0.574874\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480483; batch adversarial loss: 0.560245\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527172; batch adversarial loss: 0.561078\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511919; batch adversarial loss: 0.538730\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482481; batch adversarial loss: 0.521230\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485800; batch adversarial loss: 0.497248\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494268; batch adversarial loss: 0.545667\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441708; batch adversarial loss: 0.644908\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448271; batch adversarial loss: 0.545372\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467623; batch adversarial loss: 0.571229\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453262; batch adversarial loss: 0.554624\n",
      "epoch 34; iter: 0; batch classifier loss: 0.520278; batch adversarial loss: 0.533496\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440923; batch adversarial loss: 0.610870\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485326; batch adversarial loss: 0.581242\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495961; batch adversarial loss: 0.495344\n",
      "epoch 38; iter: 0; batch classifier loss: 0.456487; batch adversarial loss: 0.560529\n",
      "epoch 39; iter: 0; batch classifier loss: 0.533519; batch adversarial loss: 0.495373\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439984; batch adversarial loss: 0.561613\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475402; batch adversarial loss: 0.544293\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453200; batch adversarial loss: 0.526048\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451567; batch adversarial loss: 0.589172\n",
      "epoch 44; iter: 0; batch classifier loss: 0.372744; batch adversarial loss: 0.576636\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489535; batch adversarial loss: 0.611387\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462326; batch adversarial loss: 0.509802\n",
      "epoch 47; iter: 0; batch classifier loss: 0.362868; batch adversarial loss: 0.528011\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453665; batch adversarial loss: 0.564618\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466764; batch adversarial loss: 0.523828\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471233; batch adversarial loss: 0.589266\n",
      "epoch 51; iter: 0; batch classifier loss: 0.473712; batch adversarial loss: 0.633322\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401343; batch adversarial loss: 0.571683\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406042; batch adversarial loss: 0.552898\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439042; batch adversarial loss: 0.623428\n",
      "epoch 55; iter: 0; batch classifier loss: 0.469959; batch adversarial loss: 0.553689\n",
      "epoch 56; iter: 0; batch classifier loss: 0.500647; batch adversarial loss: 0.562699\n",
      "epoch 57; iter: 0; batch classifier loss: 0.337281; batch adversarial loss: 0.482992\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452253; batch adversarial loss: 0.544415\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387765; batch adversarial loss: 0.499466\n",
      "epoch 60; iter: 0; batch classifier loss: 0.433511; batch adversarial loss: 0.517762\n",
      "epoch 61; iter: 0; batch classifier loss: 0.360924; batch adversarial loss: 0.526949\n",
      "epoch 62; iter: 0; batch classifier loss: 0.469500; batch adversarial loss: 0.571261\n",
      "epoch 63; iter: 0; batch classifier loss: 0.342942; batch adversarial loss: 0.545765\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384350; batch adversarial loss: 0.535374\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455095; batch adversarial loss: 0.526703\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401608; batch adversarial loss: 0.570962\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374053; batch adversarial loss: 0.545021\n",
      "epoch 68; iter: 0; batch classifier loss: 0.446033; batch adversarial loss: 0.526512\n",
      "epoch 69; iter: 0; batch classifier loss: 0.455141; batch adversarial loss: 0.616495\n",
      "epoch 70; iter: 0; batch classifier loss: 0.481714; batch adversarial loss: 0.508744\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407467; batch adversarial loss: 0.518046\n",
      "epoch 72; iter: 0; batch classifier loss: 0.328819; batch adversarial loss: 0.535590\n",
      "epoch 73; iter: 0; batch classifier loss: 0.347286; batch adversarial loss: 0.544680\n",
      "epoch 74; iter: 0; batch classifier loss: 0.362346; batch adversarial loss: 0.553500\n",
      "epoch 75; iter: 0; batch classifier loss: 0.339543; batch adversarial loss: 0.472180\n",
      "epoch 76; iter: 0; batch classifier loss: 0.332720; batch adversarial loss: 0.525780\n",
      "epoch 77; iter: 0; batch classifier loss: 0.334587; batch adversarial loss: 0.570880\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401597; batch adversarial loss: 0.488521\n",
      "epoch 79; iter: 0; batch classifier loss: 0.360646; batch adversarial loss: 0.533513\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367842; batch adversarial loss: 0.588355\n",
      "epoch 81; iter: 0; batch classifier loss: 0.345319; batch adversarial loss: 0.593751\n",
      "epoch 82; iter: 0; batch classifier loss: 0.296510; batch adversarial loss: 0.576046\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345513; batch adversarial loss: 0.567841\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419981; batch adversarial loss: 0.628276\n",
      "epoch 85; iter: 0; batch classifier loss: 0.362361; batch adversarial loss: 0.623532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.361500; batch adversarial loss: 0.525016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.380679; batch adversarial loss: 0.503671\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368284; batch adversarial loss: 0.509514\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428633; batch adversarial loss: 0.540747\n",
      "epoch 90; iter: 0; batch classifier loss: 0.495360; batch adversarial loss: 0.541135\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363124; batch adversarial loss: 0.602953\n",
      "epoch 92; iter: 0; batch classifier loss: 0.490863; batch adversarial loss: 0.497834\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349737; batch adversarial loss: 0.519489\n",
      "epoch 94; iter: 0; batch classifier loss: 0.306081; batch adversarial loss: 0.595828\n",
      "epoch 95; iter: 0; batch classifier loss: 0.369363; batch adversarial loss: 0.579324\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347959; batch adversarial loss: 0.519249\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377831; batch adversarial loss: 0.523978\n",
      "epoch 98; iter: 0; batch classifier loss: 0.423198; batch adversarial loss: 0.545340\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366673; batch adversarial loss: 0.532563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.354288; batch adversarial loss: 0.581218\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398946; batch adversarial loss: 0.555643\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330617; batch adversarial loss: 0.644872\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388252; batch adversarial loss: 0.580797\n",
      "epoch 104; iter: 0; batch classifier loss: 0.405328; batch adversarial loss: 0.517002\n",
      "epoch 105; iter: 0; batch classifier loss: 0.297853; batch adversarial loss: 0.570116\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366453; batch adversarial loss: 0.487080\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396446; batch adversarial loss: 0.601098\n",
      "epoch 108; iter: 0; batch classifier loss: 0.312477; batch adversarial loss: 0.537574\n",
      "epoch 109; iter: 0; batch classifier loss: 0.325212; batch adversarial loss: 0.544618\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378952; batch adversarial loss: 0.580435\n",
      "epoch 111; iter: 0; batch classifier loss: 0.350374; batch adversarial loss: 0.563064\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339709; batch adversarial loss: 0.543979\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328258; batch adversarial loss: 0.533634\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382284; batch adversarial loss: 0.543406\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372868; batch adversarial loss: 0.543953\n",
      "epoch 116; iter: 0; batch classifier loss: 0.443358; batch adversarial loss: 0.595104\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340777; batch adversarial loss: 0.509224\n",
      "epoch 118; iter: 0; batch classifier loss: 0.307998; batch adversarial loss: 0.632748\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334820; batch adversarial loss: 0.653320\n",
      "epoch 120; iter: 0; batch classifier loss: 0.436375; batch adversarial loss: 0.595843\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351317; batch adversarial loss: 0.534655\n",
      "epoch 122; iter: 0; batch classifier loss: 0.306972; batch adversarial loss: 0.539276\n",
      "epoch 123; iter: 0; batch classifier loss: 0.315960; batch adversarial loss: 0.543668\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391764; batch adversarial loss: 0.521361\n",
      "epoch 125; iter: 0; batch classifier loss: 0.276458; batch adversarial loss: 0.527138\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394610; batch adversarial loss: 0.503865\n",
      "epoch 127; iter: 0; batch classifier loss: 0.339086; batch adversarial loss: 0.473144\n",
      "epoch 128; iter: 0; batch classifier loss: 0.416416; batch adversarial loss: 0.473535\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342048; batch adversarial loss: 0.572466\n",
      "epoch 130; iter: 0; batch classifier loss: 0.381061; batch adversarial loss: 0.528178\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326184; batch adversarial loss: 0.492041\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370139; batch adversarial loss: 0.546275\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374978; batch adversarial loss: 0.533031\n",
      "epoch 134; iter: 0; batch classifier loss: 0.297866; batch adversarial loss: 0.545328\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395638; batch adversarial loss: 0.603512\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328991; batch adversarial loss: 0.490980\n",
      "epoch 137; iter: 0; batch classifier loss: 0.300091; batch adversarial loss: 0.616692\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414882; batch adversarial loss: 0.607081\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378991; batch adversarial loss: 0.517413\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365340; batch adversarial loss: 0.559773\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358464; batch adversarial loss: 0.582252\n",
      "epoch 142; iter: 0; batch classifier loss: 0.300626; batch adversarial loss: 0.545432\n",
      "epoch 143; iter: 0; batch classifier loss: 0.314315; batch adversarial loss: 0.671668\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354185; batch adversarial loss: 0.560507\n",
      "epoch 145; iter: 0; batch classifier loss: 0.315539; batch adversarial loss: 0.477971\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329930; batch adversarial loss: 0.506152\n",
      "epoch 147; iter: 0; batch classifier loss: 0.328372; batch adversarial loss: 0.632983\n",
      "epoch 148; iter: 0; batch classifier loss: 0.423744; batch adversarial loss: 0.563625\n",
      "epoch 149; iter: 0; batch classifier loss: 0.385069; batch adversarial loss: 0.541552\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353542; batch adversarial loss: 0.544638\n",
      "epoch 151; iter: 0; batch classifier loss: 0.303411; batch adversarial loss: 0.542342\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386540; batch adversarial loss: 0.596588\n",
      "epoch 153; iter: 0; batch classifier loss: 0.453817; batch adversarial loss: 0.562533\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298248; batch adversarial loss: 0.589063\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340727; batch adversarial loss: 0.499552\n",
      "epoch 156; iter: 0; batch classifier loss: 0.288349; batch adversarial loss: 0.552753\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334371; batch adversarial loss: 0.562305\n",
      "epoch 158; iter: 0; batch classifier loss: 0.411170; batch adversarial loss: 0.596409\n",
      "epoch 159; iter: 0; batch classifier loss: 0.293383; batch adversarial loss: 0.553177\n",
      "epoch 160; iter: 0; batch classifier loss: 0.297977; batch adversarial loss: 0.481166\n",
      "epoch 161; iter: 0; batch classifier loss: 0.336818; batch adversarial loss: 0.618977\n",
      "epoch 162; iter: 0; batch classifier loss: 0.303196; batch adversarial loss: 0.444454\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319223; batch adversarial loss: 0.572142\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409973; batch adversarial loss: 0.590051\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339937; batch adversarial loss: 0.518454\n",
      "epoch 166; iter: 0; batch classifier loss: 0.291262; batch adversarial loss: 0.535615\n",
      "epoch 167; iter: 0; batch classifier loss: 0.269936; batch adversarial loss: 0.537922\n",
      "epoch 168; iter: 0; batch classifier loss: 0.413615; batch adversarial loss: 0.561915\n",
      "epoch 169; iter: 0; batch classifier loss: 0.309595; batch adversarial loss: 0.609695\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364556; batch adversarial loss: 0.629241\n",
      "epoch 171; iter: 0; batch classifier loss: 0.273432; batch adversarial loss: 0.571060\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326665; batch adversarial loss: 0.570226\n",
      "epoch 173; iter: 0; batch classifier loss: 0.278437; batch adversarial loss: 0.617626\n",
      "epoch 174; iter: 0; batch classifier loss: 0.330342; batch adversarial loss: 0.619937\n",
      "epoch 175; iter: 0; batch classifier loss: 0.333931; batch adversarial loss: 0.574414\n",
      "epoch 176; iter: 0; batch classifier loss: 0.322535; batch adversarial loss: 0.589276\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372294; batch adversarial loss: 0.580807\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330454; batch adversarial loss: 0.536030\n",
      "epoch 179; iter: 0; batch classifier loss: 0.408347; batch adversarial loss: 0.595286\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327149; batch adversarial loss: 0.555438\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355368; batch adversarial loss: 0.623498\n",
      "epoch 182; iter: 0; batch classifier loss: 0.331267; batch adversarial loss: 0.497276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.280459; batch adversarial loss: 0.544148\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385956; batch adversarial loss: 0.608219\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326329; batch adversarial loss: 0.598553\n",
      "epoch 186; iter: 0; batch classifier loss: 0.284218; batch adversarial loss: 0.570743\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345542; batch adversarial loss: 0.589569\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373391; batch adversarial loss: 0.499918\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355361; batch adversarial loss: 0.547883\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361775; batch adversarial loss: 0.570302\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386985; batch adversarial loss: 0.587535\n",
      "epoch 192; iter: 0; batch classifier loss: 0.300855; batch adversarial loss: 0.522940\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338557; batch adversarial loss: 0.491974\n",
      "epoch 194; iter: 0; batch classifier loss: 0.286132; batch adversarial loss: 0.571723\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342461; batch adversarial loss: 0.653991\n",
      "epoch 196; iter: 0; batch classifier loss: 0.292867; batch adversarial loss: 0.493715\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312279; batch adversarial loss: 0.505777\n",
      "epoch 198; iter: 0; batch classifier loss: 0.265913; batch adversarial loss: 0.634080\n",
      "epoch 199; iter: 0; batch classifier loss: 0.344967; batch adversarial loss: 0.509076\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724099; batch adversarial loss: 0.578383\n",
      "epoch 1; iter: 0; batch classifier loss: 0.545768; batch adversarial loss: 0.642948\n",
      "epoch 2; iter: 0; batch classifier loss: 0.584618; batch adversarial loss: 0.616202\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578074; batch adversarial loss: 0.637326\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531430; batch adversarial loss: 0.602104\n",
      "epoch 5; iter: 0; batch classifier loss: 0.609462; batch adversarial loss: 0.629167\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572613; batch adversarial loss: 0.649643\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565867; batch adversarial loss: 0.643826\n",
      "epoch 8; iter: 0; batch classifier loss: 0.614064; batch adversarial loss: 0.634846\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573060; batch adversarial loss: 0.632082\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546866; batch adversarial loss: 0.539385\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554691; batch adversarial loss: 0.567572\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509349; batch adversarial loss: 0.542158\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503525; batch adversarial loss: 0.594501\n",
      "epoch 14; iter: 0; batch classifier loss: 0.468880; batch adversarial loss: 0.544049\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475174; batch adversarial loss: 0.572272\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534683; batch adversarial loss: 0.543952\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470997; batch adversarial loss: 0.553324\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454160; batch adversarial loss: 0.456521\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486655; batch adversarial loss: 0.538257\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490488; batch adversarial loss: 0.578005\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521414; batch adversarial loss: 0.519053\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530453; batch adversarial loss: 0.558203\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443406; batch adversarial loss: 0.563059\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421189; batch adversarial loss: 0.565281\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462433; batch adversarial loss: 0.538067\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490910; batch adversarial loss: 0.614672\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460642; batch adversarial loss: 0.517381\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470990; batch adversarial loss: 0.516927\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483945; batch adversarial loss: 0.534808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441932; batch adversarial loss: 0.453885\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488016; batch adversarial loss: 0.494520\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439464; batch adversarial loss: 0.617644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474411; batch adversarial loss: 0.498305\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415177; batch adversarial loss: 0.619537\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455057; batch adversarial loss: 0.485423\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424762; batch adversarial loss: 0.507692\n",
      "epoch 37; iter: 0; batch classifier loss: 0.502463; batch adversarial loss: 0.636464\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449632; batch adversarial loss: 0.533371\n",
      "epoch 39; iter: 0; batch classifier loss: 0.528843; batch adversarial loss: 0.555747\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422283; batch adversarial loss: 0.557622\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416937; batch adversarial loss: 0.526693\n",
      "epoch 42; iter: 0; batch classifier loss: 0.473854; batch adversarial loss: 0.634142\n",
      "epoch 43; iter: 0; batch classifier loss: 0.389026; batch adversarial loss: 0.614194\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414287; batch adversarial loss: 0.531084\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467511; batch adversarial loss: 0.508478\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392701; batch adversarial loss: 0.603908\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437031; batch adversarial loss: 0.522179\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412745; batch adversarial loss: 0.514567\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429937; batch adversarial loss: 0.504663\n",
      "epoch 50; iter: 0; batch classifier loss: 0.486273; batch adversarial loss: 0.544514\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423721; batch adversarial loss: 0.606597\n",
      "epoch 52; iter: 0; batch classifier loss: 0.367348; batch adversarial loss: 0.491068\n",
      "epoch 53; iter: 0; batch classifier loss: 0.484171; batch adversarial loss: 0.517922\n",
      "epoch 54; iter: 0; batch classifier loss: 0.491324; batch adversarial loss: 0.478987\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382629; batch adversarial loss: 0.580274\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456825; batch adversarial loss: 0.471881\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374279; batch adversarial loss: 0.509344\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430773; batch adversarial loss: 0.535895\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466376; batch adversarial loss: 0.508241\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425946; batch adversarial loss: 0.454878\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416374; batch adversarial loss: 0.552069\n",
      "epoch 62; iter: 0; batch classifier loss: 0.337348; batch adversarial loss: 0.571974\n",
      "epoch 63; iter: 0; batch classifier loss: 0.389529; batch adversarial loss: 0.525420\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365127; batch adversarial loss: 0.560193\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432458; batch adversarial loss: 0.636233\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403979; batch adversarial loss: 0.618019\n",
      "epoch 67; iter: 0; batch classifier loss: 0.350522; batch adversarial loss: 0.506628\n",
      "epoch 68; iter: 0; batch classifier loss: 0.459949; batch adversarial loss: 0.533849\n",
      "epoch 69; iter: 0; batch classifier loss: 0.346522; batch adversarial loss: 0.571079\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422706; batch adversarial loss: 0.543100\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438283; batch adversarial loss: 0.553518\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365269; batch adversarial loss: 0.536373\n",
      "epoch 73; iter: 0; batch classifier loss: 0.435085; batch adversarial loss: 0.561426\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424407; batch adversarial loss: 0.500616\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386138; batch adversarial loss: 0.601331\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398939; batch adversarial loss: 0.573351\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433897; batch adversarial loss: 0.537554\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438679; batch adversarial loss: 0.544684\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392140; batch adversarial loss: 0.580463\n",
      "epoch 80; iter: 0; batch classifier loss: 0.493157; batch adversarial loss: 0.580993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.393526; batch adversarial loss: 0.571495\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422148; batch adversarial loss: 0.545547\n",
      "epoch 83; iter: 0; batch classifier loss: 0.474452; batch adversarial loss: 0.516746\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381664; batch adversarial loss: 0.636706\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377250; batch adversarial loss: 0.552641\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367360; batch adversarial loss: 0.570848\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363896; batch adversarial loss: 0.619592\n",
      "epoch 88; iter: 0; batch classifier loss: 0.410269; batch adversarial loss: 0.599925\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350742; batch adversarial loss: 0.507358\n",
      "epoch 90; iter: 0; batch classifier loss: 0.341605; batch adversarial loss: 0.626920\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395094; batch adversarial loss: 0.553092\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384166; batch adversarial loss: 0.534811\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369843; batch adversarial loss: 0.507584\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377809; batch adversarial loss: 0.562169\n",
      "epoch 95; iter: 0; batch classifier loss: 0.285331; batch adversarial loss: 0.581292\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381906; batch adversarial loss: 0.562213\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346748; batch adversarial loss: 0.525621\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385046; batch adversarial loss: 0.599179\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378393; batch adversarial loss: 0.470490\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390013; batch adversarial loss: 0.571572\n",
      "epoch 101; iter: 0; batch classifier loss: 0.339312; batch adversarial loss: 0.535437\n",
      "epoch 102; iter: 0; batch classifier loss: 0.298787; batch adversarial loss: 0.627639\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373843; batch adversarial loss: 0.468339\n",
      "epoch 104; iter: 0; batch classifier loss: 0.401678; batch adversarial loss: 0.513382\n",
      "epoch 105; iter: 0; batch classifier loss: 0.341756; batch adversarial loss: 0.578036\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365235; batch adversarial loss: 0.562899\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362741; batch adversarial loss: 0.619108\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362099; batch adversarial loss: 0.552739\n",
      "epoch 109; iter: 0; batch classifier loss: 0.339466; batch adversarial loss: 0.585838\n",
      "epoch 110; iter: 0; batch classifier loss: 0.449135; batch adversarial loss: 0.500517\n",
      "epoch 111; iter: 0; batch classifier loss: 0.302347; batch adversarial loss: 0.561615\n",
      "epoch 112; iter: 0; batch classifier loss: 0.350178; batch adversarial loss: 0.501679\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373784; batch adversarial loss: 0.610542\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373304; batch adversarial loss: 0.506415\n",
      "epoch 115; iter: 0; batch classifier loss: 0.337103; batch adversarial loss: 0.545478\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405235; batch adversarial loss: 0.599458\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368750; batch adversarial loss: 0.490009\n",
      "epoch 118; iter: 0; batch classifier loss: 0.460313; batch adversarial loss: 0.544387\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399725; batch adversarial loss: 0.507138\n",
      "epoch 120; iter: 0; batch classifier loss: 0.402128; batch adversarial loss: 0.579670\n",
      "epoch 121; iter: 0; batch classifier loss: 0.314929; batch adversarial loss: 0.426648\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351506; batch adversarial loss: 0.508107\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414317; batch adversarial loss: 0.572116\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371664; batch adversarial loss: 0.535803\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326577; batch adversarial loss: 0.562943\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403342; batch adversarial loss: 0.471372\n",
      "epoch 127; iter: 0; batch classifier loss: 0.345845; batch adversarial loss: 0.571802\n",
      "epoch 128; iter: 0; batch classifier loss: 0.347862; batch adversarial loss: 0.571829\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347418; batch adversarial loss: 0.553201\n",
      "epoch 130; iter: 0; batch classifier loss: 0.409851; batch adversarial loss: 0.499048\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349299; batch adversarial loss: 0.489356\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402675; batch adversarial loss: 0.516748\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355386; batch adversarial loss: 0.562563\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399786; batch adversarial loss: 0.507568\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388484; batch adversarial loss: 0.562276\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336888; batch adversarial loss: 0.600179\n",
      "epoch 137; iter: 0; batch classifier loss: 0.253155; batch adversarial loss: 0.507655\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376208; batch adversarial loss: 0.534738\n",
      "epoch 139; iter: 0; batch classifier loss: 0.380239; batch adversarial loss: 0.601915\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373009; batch adversarial loss: 0.497523\n",
      "epoch 141; iter: 0; batch classifier loss: 0.309728; batch adversarial loss: 0.571485\n",
      "epoch 142; iter: 0; batch classifier loss: 0.310145; batch adversarial loss: 0.595749\n",
      "epoch 143; iter: 0; batch classifier loss: 0.290814; batch adversarial loss: 0.507896\n",
      "epoch 144; iter: 0; batch classifier loss: 0.391959; batch adversarial loss: 0.476538\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327040; batch adversarial loss: 0.496106\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368013; batch adversarial loss: 0.563125\n",
      "epoch 147; iter: 0; batch classifier loss: 0.292145; batch adversarial loss: 0.562973\n",
      "epoch 148; iter: 0; batch classifier loss: 0.361679; batch adversarial loss: 0.518770\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355676; batch adversarial loss: 0.526723\n",
      "epoch 150; iter: 0; batch classifier loss: 0.433777; batch adversarial loss: 0.617005\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379649; batch adversarial loss: 0.518019\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368287; batch adversarial loss: 0.533077\n",
      "epoch 153; iter: 0; batch classifier loss: 0.378718; batch adversarial loss: 0.588840\n",
      "epoch 154; iter: 0; batch classifier loss: 0.364224; batch adversarial loss: 0.600339\n",
      "epoch 155; iter: 0; batch classifier loss: 0.416434; batch adversarial loss: 0.489888\n",
      "epoch 156; iter: 0; batch classifier loss: 0.353138; batch adversarial loss: 0.508524\n",
      "epoch 157; iter: 0; batch classifier loss: 0.391485; batch adversarial loss: 0.609656\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378228; batch adversarial loss: 0.555292\n",
      "epoch 159; iter: 0; batch classifier loss: 0.444346; batch adversarial loss: 0.498689\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373780; batch adversarial loss: 0.498551\n",
      "epoch 161; iter: 0; batch classifier loss: 0.324139; batch adversarial loss: 0.527032\n",
      "epoch 162; iter: 0; batch classifier loss: 0.308240; batch adversarial loss: 0.536986\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354375; batch adversarial loss: 0.645134\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372992; batch adversarial loss: 0.534754\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373295; batch adversarial loss: 0.527166\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331277; batch adversarial loss: 0.462381\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335002; batch adversarial loss: 0.489082\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349490; batch adversarial loss: 0.489348\n",
      "epoch 169; iter: 0; batch classifier loss: 0.306756; batch adversarial loss: 0.617656\n",
      "epoch 170; iter: 0; batch classifier loss: 0.332874; batch adversarial loss: 0.554255\n",
      "epoch 171; iter: 0; batch classifier loss: 0.259913; batch adversarial loss: 0.580418\n",
      "epoch 172; iter: 0; batch classifier loss: 0.291010; batch adversarial loss: 0.571729\n",
      "epoch 173; iter: 0; batch classifier loss: 0.319191; batch adversarial loss: 0.562788\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356678; batch adversarial loss: 0.571950\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331046; batch adversarial loss: 0.462681\n",
      "epoch 176; iter: 0; batch classifier loss: 0.418059; batch adversarial loss: 0.517055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.351795; batch adversarial loss: 0.535690\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371537; batch adversarial loss: 0.590238\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384370; batch adversarial loss: 0.544980\n",
      "epoch 180; iter: 0; batch classifier loss: 0.325744; batch adversarial loss: 0.590606\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363804; batch adversarial loss: 0.572474\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374143; batch adversarial loss: 0.535086\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323758; batch adversarial loss: 0.544498\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313922; batch adversarial loss: 0.553569\n",
      "epoch 185; iter: 0; batch classifier loss: 0.325368; batch adversarial loss: 0.543940\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312221; batch adversarial loss: 0.516596\n",
      "epoch 187; iter: 0; batch classifier loss: 0.441071; batch adversarial loss: 0.516692\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366416; batch adversarial loss: 0.543840\n",
      "epoch 189; iter: 0; batch classifier loss: 0.403650; batch adversarial loss: 0.562041\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339550; batch adversarial loss: 0.562622\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338155; batch adversarial loss: 0.489518\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315028; batch adversarial loss: 0.562974\n",
      "epoch 193; iter: 0; batch classifier loss: 0.421781; batch adversarial loss: 0.582498\n",
      "epoch 194; iter: 0; batch classifier loss: 0.279890; batch adversarial loss: 0.571740\n",
      "epoch 195; iter: 0; batch classifier loss: 0.445116; batch adversarial loss: 0.553584\n",
      "epoch 196; iter: 0; batch classifier loss: 0.375146; batch adversarial loss: 0.544815\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323311; batch adversarial loss: 0.571748\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369094; batch adversarial loss: 0.526848\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355800; batch adversarial loss: 0.608339\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665920; batch adversarial loss: 0.743433\n",
      "epoch 1; iter: 0; batch classifier loss: 0.679978; batch adversarial loss: 0.743138\n",
      "epoch 2; iter: 0; batch classifier loss: 0.758852; batch adversarial loss: 0.695203\n",
      "epoch 3; iter: 0; batch classifier loss: 0.663690; batch adversarial loss: 0.643278\n",
      "epoch 4; iter: 0; batch classifier loss: 0.533636; batch adversarial loss: 0.602681\n",
      "epoch 5; iter: 0; batch classifier loss: 0.615839; batch adversarial loss: 0.630663\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533432; batch adversarial loss: 0.625949\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527673; batch adversarial loss: 0.597077\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574199; batch adversarial loss: 0.584854\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455446; batch adversarial loss: 0.566500\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518241; batch adversarial loss: 0.588957\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544340; batch adversarial loss: 0.617257\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412122; batch adversarial loss: 0.523683\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508470; batch adversarial loss: 0.513506\n",
      "epoch 14; iter: 0; batch classifier loss: 0.492469; batch adversarial loss: 0.565489\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505018; batch adversarial loss: 0.550884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523033; batch adversarial loss: 0.537945\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487464; batch adversarial loss: 0.552698\n",
      "epoch 18; iter: 0; batch classifier loss: 0.445115; batch adversarial loss: 0.479987\n",
      "epoch 19; iter: 0; batch classifier loss: 0.585216; batch adversarial loss: 0.533532\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474498; batch adversarial loss: 0.581854\n",
      "epoch 21; iter: 0; batch classifier loss: 0.416473; batch adversarial loss: 0.481223\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447423; batch adversarial loss: 0.576577\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443679; batch adversarial loss: 0.511324\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463584; batch adversarial loss: 0.609710\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455071; batch adversarial loss: 0.498412\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434014; batch adversarial loss: 0.587961\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473909; batch adversarial loss: 0.534378\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481421; batch adversarial loss: 0.529063\n",
      "epoch 29; iter: 0; batch classifier loss: 0.427620; batch adversarial loss: 0.477976\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437773; batch adversarial loss: 0.476126\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500895; batch adversarial loss: 0.595332\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423227; batch adversarial loss: 0.461674\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476858; batch adversarial loss: 0.594572\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471169; batch adversarial loss: 0.537656\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446686; batch adversarial loss: 0.540650\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490200; batch adversarial loss: 0.530485\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470763; batch adversarial loss: 0.571492\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455047; batch adversarial loss: 0.546341\n",
      "epoch 39; iter: 0; batch classifier loss: 0.529988; batch adversarial loss: 0.608479\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466219; batch adversarial loss: 0.592619\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398311; batch adversarial loss: 0.510297\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501031; batch adversarial loss: 0.543675\n",
      "epoch 43; iter: 0; batch classifier loss: 0.548193; batch adversarial loss: 0.573275\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462848; batch adversarial loss: 0.552833\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425992; batch adversarial loss: 0.490333\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401455; batch adversarial loss: 0.566763\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430178; batch adversarial loss: 0.643474\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401701; batch adversarial loss: 0.480683\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398512; batch adversarial loss: 0.484480\n",
      "epoch 50; iter: 0; batch classifier loss: 0.456595; batch adversarial loss: 0.514534\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437927; batch adversarial loss: 0.535957\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452507; batch adversarial loss: 0.491491\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439137; batch adversarial loss: 0.490731\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446254; batch adversarial loss: 0.544361\n",
      "epoch 55; iter: 0; batch classifier loss: 0.340384; batch adversarial loss: 0.571405\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399065; batch adversarial loss: 0.625332\n",
      "epoch 57; iter: 0; batch classifier loss: 0.346925; batch adversarial loss: 0.517461\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420275; batch adversarial loss: 0.445393\n",
      "epoch 59; iter: 0; batch classifier loss: 0.480690; batch adversarial loss: 0.526004\n",
      "epoch 60; iter: 0; batch classifier loss: 0.413421; batch adversarial loss: 0.489670\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413288; batch adversarial loss: 0.508388\n",
      "epoch 62; iter: 0; batch classifier loss: 0.355262; batch adversarial loss: 0.535687\n",
      "epoch 63; iter: 0; batch classifier loss: 0.325459; batch adversarial loss: 0.608671\n",
      "epoch 64; iter: 0; batch classifier loss: 0.433102; batch adversarial loss: 0.609014\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443323; batch adversarial loss: 0.544680\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416119; batch adversarial loss: 0.590524\n",
      "epoch 67; iter: 0; batch classifier loss: 0.393079; batch adversarial loss: 0.526030\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439922; batch adversarial loss: 0.597109\n",
      "epoch 69; iter: 0; batch classifier loss: 0.466709; batch adversarial loss: 0.554171\n",
      "epoch 70; iter: 0; batch classifier loss: 0.515047; batch adversarial loss: 0.623422\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400566; batch adversarial loss: 0.511242\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386726; batch adversarial loss: 0.562904\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408321; batch adversarial loss: 0.526646\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363867; batch adversarial loss: 0.558237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.442714; batch adversarial loss: 0.631953\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388377; batch adversarial loss: 0.497633\n",
      "epoch 77; iter: 0; batch classifier loss: 0.496599; batch adversarial loss: 0.491321\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457225; batch adversarial loss: 0.483046\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422465; batch adversarial loss: 0.555553\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419217; batch adversarial loss: 0.510226\n",
      "epoch 81; iter: 0; batch classifier loss: 0.474941; batch adversarial loss: 0.590618\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385304; batch adversarial loss: 0.499378\n",
      "epoch 83; iter: 0; batch classifier loss: 0.452916; batch adversarial loss: 0.463634\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426819; batch adversarial loss: 0.598339\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378293; batch adversarial loss: 0.472450\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402087; batch adversarial loss: 0.551977\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418592; batch adversarial loss: 0.562069\n",
      "epoch 88; iter: 0; batch classifier loss: 0.361687; batch adversarial loss: 0.500802\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396701; batch adversarial loss: 0.590836\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435138; batch adversarial loss: 0.578441\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334231; batch adversarial loss: 0.609955\n",
      "epoch 92; iter: 0; batch classifier loss: 0.361278; batch adversarial loss: 0.527427\n",
      "epoch 93; iter: 0; batch classifier loss: 0.451513; batch adversarial loss: 0.567087\n",
      "epoch 94; iter: 0; batch classifier loss: 0.364211; batch adversarial loss: 0.579964\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446153; batch adversarial loss: 0.612547\n",
      "epoch 96; iter: 0; batch classifier loss: 0.481519; batch adversarial loss: 0.507270\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350275; batch adversarial loss: 0.581931\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387277; batch adversarial loss: 0.508243\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402593; batch adversarial loss: 0.562709\n",
      "epoch 100; iter: 0; batch classifier loss: 0.419735; batch adversarial loss: 0.618322\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382740; batch adversarial loss: 0.535378\n",
      "epoch 102; iter: 0; batch classifier loss: 0.384820; batch adversarial loss: 0.526320\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337096; batch adversarial loss: 0.543388\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409463; batch adversarial loss: 0.487691\n",
      "epoch 105; iter: 0; batch classifier loss: 0.321321; batch adversarial loss: 0.570820\n",
      "epoch 106; iter: 0; batch classifier loss: 0.428986; batch adversarial loss: 0.452290\n",
      "epoch 107; iter: 0; batch classifier loss: 0.604331; batch adversarial loss: 0.501029\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401581; batch adversarial loss: 0.472159\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364771; batch adversarial loss: 0.519095\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343692; batch adversarial loss: 0.544883\n",
      "epoch 111; iter: 0; batch classifier loss: 0.400835; batch adversarial loss: 0.532636\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405881; batch adversarial loss: 0.602042\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401533; batch adversarial loss: 0.551798\n",
      "epoch 114; iter: 0; batch classifier loss: 0.399781; batch adversarial loss: 0.467225\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382889; batch adversarial loss: 0.537890\n",
      "epoch 116; iter: 0; batch classifier loss: 0.399443; batch adversarial loss: 0.580687\n",
      "epoch 117; iter: 0; batch classifier loss: 0.431976; batch adversarial loss: 0.619236\n",
      "epoch 118; iter: 0; batch classifier loss: 0.424901; batch adversarial loss: 0.600055\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387118; batch adversarial loss: 0.550795\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415076; batch adversarial loss: 0.452060\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412993; batch adversarial loss: 0.561784\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356333; batch adversarial loss: 0.542774\n",
      "epoch 123; iter: 0; batch classifier loss: 0.391817; batch adversarial loss: 0.536497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402412; batch adversarial loss: 0.535805\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326447; batch adversarial loss: 0.554515\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374894; batch adversarial loss: 0.571199\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358566; batch adversarial loss: 0.516233\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375486; batch adversarial loss: 0.452819\n",
      "epoch 129; iter: 0; batch classifier loss: 0.382333; batch adversarial loss: 0.534390\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382973; batch adversarial loss: 0.481432\n",
      "epoch 131; iter: 0; batch classifier loss: 0.417524; batch adversarial loss: 0.516656\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359747; batch adversarial loss: 0.526142\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335453; batch adversarial loss: 0.617032\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383813; batch adversarial loss: 0.472502\n",
      "epoch 135; iter: 0; batch classifier loss: 0.419403; batch adversarial loss: 0.589304\n",
      "epoch 136; iter: 0; batch classifier loss: 0.412756; batch adversarial loss: 0.536780\n",
      "epoch 137; iter: 0; batch classifier loss: 0.447617; batch adversarial loss: 0.478250\n",
      "epoch 138; iter: 0; batch classifier loss: 0.426906; batch adversarial loss: 0.647671\n",
      "epoch 139; iter: 0; batch classifier loss: 0.450028; batch adversarial loss: 0.533582\n",
      "epoch 140; iter: 0; batch classifier loss: 0.306541; batch adversarial loss: 0.517180\n",
      "epoch 141; iter: 0; batch classifier loss: 0.392096; batch adversarial loss: 0.562528\n",
      "epoch 142; iter: 0; batch classifier loss: 0.433034; batch adversarial loss: 0.583350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.296431; batch adversarial loss: 0.543809\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365688; batch adversarial loss: 0.505767\n",
      "epoch 145; iter: 0; batch classifier loss: 0.314296; batch adversarial loss: 0.504753\n",
      "epoch 146; iter: 0; batch classifier loss: 0.403534; batch adversarial loss: 0.525285\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393310; batch adversarial loss: 0.564194\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363361; batch adversarial loss: 0.609339\n",
      "epoch 149; iter: 0; batch classifier loss: 0.478815; batch adversarial loss: 0.564261\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358579; batch adversarial loss: 0.507319\n",
      "epoch 151; iter: 0; batch classifier loss: 0.410769; batch adversarial loss: 0.545220\n",
      "epoch 152; iter: 0; batch classifier loss: 0.399715; batch adversarial loss: 0.526286\n",
      "epoch 153; iter: 0; batch classifier loss: 0.410175; batch adversarial loss: 0.560761\n",
      "epoch 154; iter: 0; batch classifier loss: 0.436288; batch adversarial loss: 0.498515\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334799; batch adversarial loss: 0.553994\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399752; batch adversarial loss: 0.480493\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350292; batch adversarial loss: 0.625998\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345542; batch adversarial loss: 0.561839\n",
      "epoch 159; iter: 0; batch classifier loss: 0.306779; batch adversarial loss: 0.572285\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363046; batch adversarial loss: 0.517911\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333071; batch adversarial loss: 0.480683\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347390; batch adversarial loss: 0.563794\n",
      "epoch 163; iter: 0; batch classifier loss: 0.405988; batch adversarial loss: 0.626738\n",
      "epoch 164; iter: 0; batch classifier loss: 0.318615; batch adversarial loss: 0.488866\n",
      "epoch 165; iter: 0; batch classifier loss: 0.412398; batch adversarial loss: 0.554064\n",
      "epoch 166; iter: 0; batch classifier loss: 0.368053; batch adversarial loss: 0.479577\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319622; batch adversarial loss: 0.563234\n",
      "epoch 168; iter: 0; batch classifier loss: 0.371979; batch adversarial loss: 0.607190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360910; batch adversarial loss: 0.570995\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380126; batch adversarial loss: 0.544278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.344306; batch adversarial loss: 0.544625\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377459; batch adversarial loss: 0.598714\n",
      "epoch 173; iter: 0; batch classifier loss: 0.400035; batch adversarial loss: 0.553903\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369913; batch adversarial loss: 0.598591\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326988; batch adversarial loss: 0.560324\n",
      "epoch 176; iter: 0; batch classifier loss: 0.326135; batch adversarial loss: 0.597665\n",
      "epoch 177; iter: 0; batch classifier loss: 0.280191; batch adversarial loss: 0.554641\n",
      "epoch 178; iter: 0; batch classifier loss: 0.408739; batch adversarial loss: 0.545937\n",
      "epoch 179; iter: 0; batch classifier loss: 0.410126; batch adversarial loss: 0.545596\n",
      "epoch 180; iter: 0; batch classifier loss: 0.312683; batch adversarial loss: 0.515552\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349305; batch adversarial loss: 0.581340\n",
      "epoch 182; iter: 0; batch classifier loss: 0.299123; batch adversarial loss: 0.514597\n",
      "epoch 183; iter: 0; batch classifier loss: 0.374594; batch adversarial loss: 0.505705\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309598; batch adversarial loss: 0.524211\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333981; batch adversarial loss: 0.588352\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383613; batch adversarial loss: 0.552494\n",
      "epoch 187; iter: 0; batch classifier loss: 0.354852; batch adversarial loss: 0.571117\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374650; batch adversarial loss: 0.526239\n",
      "epoch 189; iter: 0; batch classifier loss: 0.342753; batch adversarial loss: 0.580739\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349246; batch adversarial loss: 0.535978\n",
      "epoch 191; iter: 0; batch classifier loss: 0.415673; batch adversarial loss: 0.514453\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333908; batch adversarial loss: 0.589515\n",
      "epoch 193; iter: 0; batch classifier loss: 0.380928; batch adversarial loss: 0.597804\n",
      "epoch 194; iter: 0; batch classifier loss: 0.492634; batch adversarial loss: 0.506831\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365866; batch adversarial loss: 0.591396\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378006; batch adversarial loss: 0.540832\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315989; batch adversarial loss: 0.472155\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309484; batch adversarial loss: 0.469331\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388517; batch adversarial loss: 0.536401\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716220; batch adversarial loss: 0.618819\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583608; batch adversarial loss: 0.660804\n",
      "epoch 2; iter: 0; batch classifier loss: 0.557001; batch adversarial loss: 0.635812\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550634; batch adversarial loss: 0.641913\n",
      "epoch 4; iter: 0; batch classifier loss: 0.651407; batch adversarial loss: 0.628059\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552003; batch adversarial loss: 0.623768\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593362; batch adversarial loss: 0.611229\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564241; batch adversarial loss: 0.585176\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513332; batch adversarial loss: 0.631461\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506410; batch adversarial loss: 0.626835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.583515; batch adversarial loss: 0.641547\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456482; batch adversarial loss: 0.600273\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502137; batch adversarial loss: 0.571852\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527901; batch adversarial loss: 0.561177\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514313; batch adversarial loss: 0.593444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504934; batch adversarial loss: 0.563508\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452329; batch adversarial loss: 0.503187\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485171; batch adversarial loss: 0.540687\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468131; batch adversarial loss: 0.520248\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480881; batch adversarial loss: 0.474526\n",
      "epoch 20; iter: 0; batch classifier loss: 0.501223; batch adversarial loss: 0.559324\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538834; batch adversarial loss: 0.535332\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492001; batch adversarial loss: 0.571945\n",
      "epoch 23; iter: 0; batch classifier loss: 0.533627; batch adversarial loss: 0.528386\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456270; batch adversarial loss: 0.499875\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509898; batch adversarial loss: 0.570440\n",
      "epoch 26; iter: 0; batch classifier loss: 0.429253; batch adversarial loss: 0.541068\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475256; batch adversarial loss: 0.650321\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488546; batch adversarial loss: 0.565444\n",
      "epoch 29; iter: 0; batch classifier loss: 0.531654; batch adversarial loss: 0.472415\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463127; batch adversarial loss: 0.517828\n",
      "epoch 31; iter: 0; batch classifier loss: 0.547393; batch adversarial loss: 0.492611\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452703; batch adversarial loss: 0.463763\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441625; batch adversarial loss: 0.508186\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452384; batch adversarial loss: 0.552857\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482310; batch adversarial loss: 0.598086\n",
      "epoch 36; iter: 0; batch classifier loss: 0.423825; batch adversarial loss: 0.526770\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430348; batch adversarial loss: 0.581349\n",
      "epoch 38; iter: 0; batch classifier loss: 0.515790; batch adversarial loss: 0.516906\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450991; batch adversarial loss: 0.628348\n",
      "epoch 40; iter: 0; batch classifier loss: 0.386046; batch adversarial loss: 0.562884\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421703; batch adversarial loss: 0.533942\n",
      "epoch 42; iter: 0; batch classifier loss: 0.500746; batch adversarial loss: 0.524233\n",
      "epoch 43; iter: 0; batch classifier loss: 0.416692; batch adversarial loss: 0.602393\n",
      "epoch 44; iter: 0; batch classifier loss: 0.452371; batch adversarial loss: 0.525221\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436981; batch adversarial loss: 0.498033\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417600; batch adversarial loss: 0.573970\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401075; batch adversarial loss: 0.562325\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449894; batch adversarial loss: 0.505721\n",
      "epoch 49; iter: 0; batch classifier loss: 0.521877; batch adversarial loss: 0.574163\n",
      "epoch 50; iter: 0; batch classifier loss: 0.452512; batch adversarial loss: 0.543599\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404842; batch adversarial loss: 0.478036\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451678; batch adversarial loss: 0.553847\n",
      "epoch 53; iter: 0; batch classifier loss: 0.478650; batch adversarial loss: 0.498584\n",
      "epoch 54; iter: 0; batch classifier loss: 0.378596; batch adversarial loss: 0.534259\n",
      "epoch 55; iter: 0; batch classifier loss: 0.343496; batch adversarial loss: 0.553369\n",
      "epoch 56; iter: 0; batch classifier loss: 0.516727; batch adversarial loss: 0.516145\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445422; batch adversarial loss: 0.505702\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404895; batch adversarial loss: 0.572044\n",
      "epoch 59; iter: 0; batch classifier loss: 0.481717; batch adversarial loss: 0.470881\n",
      "epoch 60; iter: 0; batch classifier loss: 0.332470; batch adversarial loss: 0.563642\n",
      "epoch 61; iter: 0; batch classifier loss: 0.548508; batch adversarial loss: 0.507989\n",
      "epoch 62; iter: 0; batch classifier loss: 0.455160; batch adversarial loss: 0.471333\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401511; batch adversarial loss: 0.552880\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463809; batch adversarial loss: 0.581980\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402884; batch adversarial loss: 0.432925\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415058; batch adversarial loss: 0.638021\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434178; batch adversarial loss: 0.553980\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389993; batch adversarial loss: 0.580954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.400379; batch adversarial loss: 0.543859\n",
      "epoch 70; iter: 0; batch classifier loss: 0.460012; batch adversarial loss: 0.534338\n",
      "epoch 71; iter: 0; batch classifier loss: 0.455999; batch adversarial loss: 0.487616\n",
      "epoch 72; iter: 0; batch classifier loss: 0.472831; batch adversarial loss: 0.573584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.352579; batch adversarial loss: 0.563253\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399980; batch adversarial loss: 0.562985\n",
      "epoch 75; iter: 0; batch classifier loss: 0.442729; batch adversarial loss: 0.561996\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390644; batch adversarial loss: 0.497588\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401467; batch adversarial loss: 0.553675\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447989; batch adversarial loss: 0.545568\n",
      "epoch 79; iter: 0; batch classifier loss: 0.467738; batch adversarial loss: 0.554482\n",
      "epoch 80; iter: 0; batch classifier loss: 0.342148; batch adversarial loss: 0.544420\n",
      "epoch 81; iter: 0; batch classifier loss: 0.326231; batch adversarial loss: 0.497651\n",
      "epoch 82; iter: 0; batch classifier loss: 0.378505; batch adversarial loss: 0.581183\n",
      "epoch 83; iter: 0; batch classifier loss: 0.337932; batch adversarial loss: 0.563586\n",
      "epoch 84; iter: 0; batch classifier loss: 0.339051; batch adversarial loss: 0.657699\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347010; batch adversarial loss: 0.506987\n",
      "epoch 86; iter: 0; batch classifier loss: 0.331164; batch adversarial loss: 0.544085\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377126; batch adversarial loss: 0.582919\n",
      "epoch 88; iter: 0; batch classifier loss: 0.390580; batch adversarial loss: 0.506058\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406051; batch adversarial loss: 0.628776\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363441; batch adversarial loss: 0.517039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.448078; batch adversarial loss: 0.573253\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406286; batch adversarial loss: 0.535018\n",
      "epoch 93; iter: 0; batch classifier loss: 0.416862; batch adversarial loss: 0.591400\n",
      "epoch 94; iter: 0; batch classifier loss: 0.444910; batch adversarial loss: 0.543661\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365898; batch adversarial loss: 0.461058\n",
      "epoch 96; iter: 0; batch classifier loss: 0.406536; batch adversarial loss: 0.573997\n",
      "epoch 97; iter: 0; batch classifier loss: 0.319410; batch adversarial loss: 0.516169\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372138; batch adversarial loss: 0.497694\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419007; batch adversarial loss: 0.544379\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361151; batch adversarial loss: 0.488113\n",
      "epoch 101; iter: 0; batch classifier loss: 0.459361; batch adversarial loss: 0.591546\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410618; batch adversarial loss: 0.498080\n",
      "epoch 103; iter: 0; batch classifier loss: 0.333209; batch adversarial loss: 0.611186\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384340; batch adversarial loss: 0.563119\n",
      "epoch 105; iter: 0; batch classifier loss: 0.323066; batch adversarial loss: 0.525974\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379645; batch adversarial loss: 0.506784\n",
      "epoch 107; iter: 0; batch classifier loss: 0.432000; batch adversarial loss: 0.563931\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420968; batch adversarial loss: 0.468700\n",
      "epoch 109; iter: 0; batch classifier loss: 0.436806; batch adversarial loss: 0.525672\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391673; batch adversarial loss: 0.458917\n",
      "epoch 111; iter: 0; batch classifier loss: 0.441894; batch adversarial loss: 0.553491\n",
      "epoch 112; iter: 0; batch classifier loss: 0.418629; batch adversarial loss: 0.459458\n",
      "epoch 113; iter: 0; batch classifier loss: 0.342286; batch adversarial loss: 0.506154\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405415; batch adversarial loss: 0.460601\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374870; batch adversarial loss: 0.544461\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375331; batch adversarial loss: 0.563809\n",
      "epoch 117; iter: 0; batch classifier loss: 0.304392; batch adversarial loss: 0.590536\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384361; batch adversarial loss: 0.525721\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425052; batch adversarial loss: 0.590802\n",
      "epoch 120; iter: 0; batch classifier loss: 0.323289; batch adversarial loss: 0.535130\n",
      "epoch 121; iter: 0; batch classifier loss: 0.422317; batch adversarial loss: 0.507527\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372435; batch adversarial loss: 0.562483\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375593; batch adversarial loss: 0.506974\n",
      "epoch 124; iter: 0; batch classifier loss: 0.355121; batch adversarial loss: 0.620585\n",
      "epoch 125; iter: 0; batch classifier loss: 0.426509; batch adversarial loss: 0.611137\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359474; batch adversarial loss: 0.600962\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396469; batch adversarial loss: 0.525606\n",
      "epoch 128; iter: 0; batch classifier loss: 0.391680; batch adversarial loss: 0.574666\n",
      "epoch 129; iter: 0; batch classifier loss: 0.306819; batch adversarial loss: 0.535414\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389338; batch adversarial loss: 0.553941\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345269; batch adversarial loss: 0.582625\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390841; batch adversarial loss: 0.619235\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391504; batch adversarial loss: 0.608266\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397200; batch adversarial loss: 0.554012\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375290; batch adversarial loss: 0.536341\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375979; batch adversarial loss: 0.554019\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424595; batch adversarial loss: 0.542805\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373423; batch adversarial loss: 0.581805\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389022; batch adversarial loss: 0.498164\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352468; batch adversarial loss: 0.507299\n",
      "epoch 141; iter: 0; batch classifier loss: 0.362873; batch adversarial loss: 0.562911\n",
      "epoch 142; iter: 0; batch classifier loss: 0.311622; batch adversarial loss: 0.478267\n",
      "epoch 143; iter: 0; batch classifier loss: 0.456207; batch adversarial loss: 0.477542\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356277; batch adversarial loss: 0.507156\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327561; batch adversarial loss: 0.581383\n",
      "epoch 146; iter: 0; batch classifier loss: 0.419143; batch adversarial loss: 0.460530\n",
      "epoch 147; iter: 0; batch classifier loss: 0.348800; batch adversarial loss: 0.507071\n",
      "epoch 148; iter: 0; batch classifier loss: 0.406938; batch adversarial loss: 0.544688\n",
      "epoch 149; iter: 0; batch classifier loss: 0.409359; batch adversarial loss: 0.609458\n",
      "epoch 150; iter: 0; batch classifier loss: 0.387357; batch adversarial loss: 0.469089\n",
      "epoch 151; iter: 0; batch classifier loss: 0.471536; batch adversarial loss: 0.583026\n",
      "epoch 152; iter: 0; batch classifier loss: 0.401431; batch adversarial loss: 0.469022\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320977; batch adversarial loss: 0.533988\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354053; batch adversarial loss: 0.581180\n",
      "epoch 155; iter: 0; batch classifier loss: 0.390304; batch adversarial loss: 0.582266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.426161; batch adversarial loss: 0.525936\n",
      "epoch 157; iter: 0; batch classifier loss: 0.390404; batch adversarial loss: 0.525324\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384026; batch adversarial loss: 0.506159\n",
      "epoch 159; iter: 0; batch classifier loss: 0.413384; batch adversarial loss: 0.554230\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370545; batch adversarial loss: 0.535280\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411996; batch adversarial loss: 0.543856\n",
      "epoch 162; iter: 0; batch classifier loss: 0.414167; batch adversarial loss: 0.497582\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362969; batch adversarial loss: 0.478482\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360481; batch adversarial loss: 0.592120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.316284; batch adversarial loss: 0.544446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.449393; batch adversarial loss: 0.544036\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323722; batch adversarial loss: 0.619989\n",
      "epoch 168; iter: 0; batch classifier loss: 0.424517; batch adversarial loss: 0.516093\n",
      "epoch 169; iter: 0; batch classifier loss: 0.331661; batch adversarial loss: 0.572661\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379952; batch adversarial loss: 0.582537\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392247; batch adversarial loss: 0.553494\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342995; batch adversarial loss: 0.526415\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301933; batch adversarial loss: 0.543835\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351231; batch adversarial loss: 0.516406\n",
      "epoch 175; iter: 0; batch classifier loss: 0.410653; batch adversarial loss: 0.582408\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353700; batch adversarial loss: 0.563765\n",
      "epoch 177; iter: 0; batch classifier loss: 0.414512; batch adversarial loss: 0.543760\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326784; batch adversarial loss: 0.544678\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380440; batch adversarial loss: 0.470249\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352353; batch adversarial loss: 0.581814\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322440; batch adversarial loss: 0.572647\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352810; batch adversarial loss: 0.507180\n",
      "epoch 183; iter: 0; batch classifier loss: 0.317021; batch adversarial loss: 0.581903\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337283; batch adversarial loss: 0.515248\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320651; batch adversarial loss: 0.564824\n",
      "epoch 186; iter: 0; batch classifier loss: 0.344391; batch adversarial loss: 0.459994\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372367; batch adversarial loss: 0.563141\n",
      "epoch 188; iter: 0; batch classifier loss: 0.416207; batch adversarial loss: 0.488162\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381538; batch adversarial loss: 0.618430\n",
      "epoch 190; iter: 0; batch classifier loss: 0.318784; batch adversarial loss: 0.553620\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350238; batch adversarial loss: 0.564179\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367872; batch adversarial loss: 0.496985\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360725; batch adversarial loss: 0.553452\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385662; batch adversarial loss: 0.572114\n",
      "epoch 195; iter: 0; batch classifier loss: 0.416167; batch adversarial loss: 0.583078\n",
      "epoch 196; iter: 0; batch classifier loss: 0.380590; batch adversarial loss: 0.460147\n",
      "epoch 197; iter: 0; batch classifier loss: 0.397816; batch adversarial loss: 0.526188\n",
      "epoch 198; iter: 0; batch classifier loss: 0.346471; batch adversarial loss: 0.610499\n",
      "epoch 199; iter: 0; batch classifier loss: 0.336187; batch adversarial loss: 0.581775\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675335; batch adversarial loss: 0.632824\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585988; batch adversarial loss: 0.604393\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630462; batch adversarial loss: 0.599429\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569826; batch adversarial loss: 0.681205\n",
      "epoch 4; iter: 0; batch classifier loss: 0.664521; batch adversarial loss: 0.661507\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582631; batch adversarial loss: 0.649875\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588502; batch adversarial loss: 0.692724\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566412; batch adversarial loss: 0.609818\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541241; batch adversarial loss: 0.638260\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566428; batch adversarial loss: 0.565088\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549482; batch adversarial loss: 0.582821\n",
      "epoch 11; iter: 0; batch classifier loss: 0.623417; batch adversarial loss: 0.614741\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553132; batch adversarial loss: 0.571837\n",
      "epoch 13; iter: 0; batch classifier loss: 0.594550; batch adversarial loss: 0.569470\n",
      "epoch 14; iter: 0; batch classifier loss: 0.580965; batch adversarial loss: 0.531022\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548013; batch adversarial loss: 0.607020\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506467; batch adversarial loss: 0.545790\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496416; batch adversarial loss: 0.580656\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488256; batch adversarial loss: 0.498419\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517182; batch adversarial loss: 0.582671\n",
      "epoch 20; iter: 0; batch classifier loss: 0.560294; batch adversarial loss: 0.592848\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491050; batch adversarial loss: 0.528816\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484844; batch adversarial loss: 0.561958\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479820; batch adversarial loss: 0.529109\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528001; batch adversarial loss: 0.557937\n",
      "epoch 25; iter: 0; batch classifier loss: 0.544163; batch adversarial loss: 0.555766\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469966; batch adversarial loss: 0.524726\n",
      "epoch 27; iter: 0; batch classifier loss: 0.514628; batch adversarial loss: 0.504033\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468183; batch adversarial loss: 0.557278\n",
      "epoch 29; iter: 0; batch classifier loss: 0.518150; batch adversarial loss: 0.473115\n",
      "epoch 30; iter: 0; batch classifier loss: 0.451788; batch adversarial loss: 0.590764\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457872; batch adversarial loss: 0.619032\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484226; batch adversarial loss: 0.514532\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507499; batch adversarial loss: 0.548269\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511019; batch adversarial loss: 0.543169\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412062; batch adversarial loss: 0.473616\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432950; batch adversarial loss: 0.585026\n",
      "epoch 37; iter: 0; batch classifier loss: 0.501024; batch adversarial loss: 0.514805\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427465; batch adversarial loss: 0.497504\n",
      "epoch 39; iter: 0; batch classifier loss: 0.486640; batch adversarial loss: 0.564383\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463990; batch adversarial loss: 0.676163\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426622; batch adversarial loss: 0.511374\n",
      "epoch 42; iter: 0; batch classifier loss: 0.550210; batch adversarial loss: 0.574236\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480717; batch adversarial loss: 0.525517\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488605; batch adversarial loss: 0.517521\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419418; batch adversarial loss: 0.579250\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443007; batch adversarial loss: 0.554257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.448499; batch adversarial loss: 0.514393\n",
      "epoch 48; iter: 0; batch classifier loss: 0.368982; batch adversarial loss: 0.590370\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399833; batch adversarial loss: 0.507434\n",
      "epoch 50; iter: 0; batch classifier loss: 0.476026; batch adversarial loss: 0.528924\n",
      "epoch 51; iter: 0; batch classifier loss: 0.355938; batch adversarial loss: 0.608174\n",
      "epoch 52; iter: 0; batch classifier loss: 0.474713; batch adversarial loss: 0.488127\n",
      "epoch 53; iter: 0; batch classifier loss: 0.394094; batch adversarial loss: 0.523814\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431311; batch adversarial loss: 0.499403\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468119; batch adversarial loss: 0.649683\n",
      "epoch 56; iter: 0; batch classifier loss: 0.529682; batch adversarial loss: 0.482264\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443133; batch adversarial loss: 0.573247\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411923; batch adversarial loss: 0.619839\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466250; batch adversarial loss: 0.544465\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432336; batch adversarial loss: 0.534536\n",
      "epoch 61; iter: 0; batch classifier loss: 0.478200; batch adversarial loss: 0.462796\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386301; batch adversarial loss: 0.580789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.501685; batch adversarial loss: 0.580512\n",
      "epoch 64; iter: 0; batch classifier loss: 0.471376; batch adversarial loss: 0.526273\n",
      "epoch 65; iter: 0; batch classifier loss: 0.509499; batch adversarial loss: 0.634764\n",
      "epoch 66; iter: 0; batch classifier loss: 0.371383; batch adversarial loss: 0.569341\n",
      "epoch 67; iter: 0; batch classifier loss: 0.521920; batch adversarial loss: 0.562621\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401939; batch adversarial loss: 0.535536\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400701; batch adversarial loss: 0.558957\n",
      "epoch 70; iter: 0; batch classifier loss: 0.328225; batch adversarial loss: 0.563799\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365263; batch adversarial loss: 0.551794\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392330; batch adversarial loss: 0.521561\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375508; batch adversarial loss: 0.569750\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426372; batch adversarial loss: 0.672928\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430957; batch adversarial loss: 0.543309\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415509; batch adversarial loss: 0.571890\n",
      "epoch 77; iter: 0; batch classifier loss: 0.467946; batch adversarial loss: 0.478963\n",
      "epoch 78; iter: 0; batch classifier loss: 0.425992; batch adversarial loss: 0.526367\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413091; batch adversarial loss: 0.570171\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399273; batch adversarial loss: 0.680967\n",
      "epoch 81; iter: 0; batch classifier loss: 0.460334; batch adversarial loss: 0.571452\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394176; batch adversarial loss: 0.499389\n",
      "epoch 83; iter: 0; batch classifier loss: 0.445064; batch adversarial loss: 0.525397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412124; batch adversarial loss: 0.552107\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403463; batch adversarial loss: 0.584304\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369090; batch adversarial loss: 0.487101\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429724; batch adversarial loss: 0.505171\n",
      "epoch 88; iter: 0; batch classifier loss: 0.470256; batch adversarial loss: 0.472422\n",
      "epoch 89; iter: 0; batch classifier loss: 0.418929; batch adversarial loss: 0.485897\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364868; batch adversarial loss: 0.546901\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395862; batch adversarial loss: 0.433733\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410236; batch adversarial loss: 0.537033\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342924; batch adversarial loss: 0.571508\n",
      "epoch 94; iter: 0; batch classifier loss: 0.288800; batch adversarial loss: 0.599349\n",
      "epoch 95; iter: 0; batch classifier loss: 0.311608; batch adversarial loss: 0.490449\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336422; batch adversarial loss: 0.571390\n",
      "epoch 97; iter: 0; batch classifier loss: 0.337202; batch adversarial loss: 0.562734\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394053; batch adversarial loss: 0.590376\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367129; batch adversarial loss: 0.506273\n",
      "epoch 100; iter: 0; batch classifier loss: 0.405165; batch adversarial loss: 0.610768\n",
      "epoch 101; iter: 0; batch classifier loss: 0.341563; batch adversarial loss: 0.525194\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350488; batch adversarial loss: 0.637317\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366305; batch adversarial loss: 0.461354\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423528; batch adversarial loss: 0.544345\n",
      "epoch 105; iter: 0; batch classifier loss: 0.454313; batch adversarial loss: 0.479438\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365971; batch adversarial loss: 0.555884\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400644; batch adversarial loss: 0.515065\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377339; batch adversarial loss: 0.566464\n",
      "epoch 109; iter: 0; batch classifier loss: 0.436156; batch adversarial loss: 0.489489\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350406; batch adversarial loss: 0.599485\n",
      "epoch 111; iter: 0; batch classifier loss: 0.466638; batch adversarial loss: 0.554144\n",
      "epoch 112; iter: 0; batch classifier loss: 0.433736; batch adversarial loss: 0.623862\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415216; batch adversarial loss: 0.490574\n",
      "epoch 114; iter: 0; batch classifier loss: 0.321586; batch adversarial loss: 0.507227\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379245; batch adversarial loss: 0.552258\n",
      "epoch 116; iter: 0; batch classifier loss: 0.378073; batch adversarial loss: 0.618049\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360388; batch adversarial loss: 0.482018\n",
      "epoch 118; iter: 0; batch classifier loss: 0.344432; batch adversarial loss: 0.497885\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348293; batch adversarial loss: 0.498465\n",
      "epoch 120; iter: 0; batch classifier loss: 0.316025; batch adversarial loss: 0.607724\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383202; batch adversarial loss: 0.559361\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367090; batch adversarial loss: 0.574767\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360202; batch adversarial loss: 0.523978\n",
      "epoch 124; iter: 0; batch classifier loss: 0.383649; batch adversarial loss: 0.581583\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382125; batch adversarial loss: 0.480050\n",
      "epoch 126; iter: 0; batch classifier loss: 0.426139; batch adversarial loss: 0.480790\n",
      "epoch 127; iter: 0; batch classifier loss: 0.375103; batch adversarial loss: 0.528538\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392748; batch adversarial loss: 0.600671\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377312; batch adversarial loss: 0.535596\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414080; batch adversarial loss: 0.462092\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373569; batch adversarial loss: 0.508302\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357377; batch adversarial loss: 0.488105\n",
      "epoch 133; iter: 0; batch classifier loss: 0.404147; batch adversarial loss: 0.545398\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396446; batch adversarial loss: 0.625337\n",
      "epoch 135; iter: 0; batch classifier loss: 0.435524; batch adversarial loss: 0.490129\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382794; batch adversarial loss: 0.553669\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376129; batch adversarial loss: 0.489227\n",
      "epoch 138; iter: 0; batch classifier loss: 0.455988; batch adversarial loss: 0.517427\n",
      "epoch 139; iter: 0; batch classifier loss: 0.312664; batch adversarial loss: 0.561077\n",
      "epoch 140; iter: 0; batch classifier loss: 0.434512; batch adversarial loss: 0.518360\n",
      "epoch 141; iter: 0; batch classifier loss: 0.420333; batch adversarial loss: 0.543103\n",
      "epoch 142; iter: 0; batch classifier loss: 0.422917; batch adversarial loss: 0.563497\n",
      "epoch 143; iter: 0; batch classifier loss: 0.319232; batch adversarial loss: 0.615415\n",
      "epoch 144; iter: 0; batch classifier loss: 0.435350; batch adversarial loss: 0.602447\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376653; batch adversarial loss: 0.508038\n",
      "epoch 146; iter: 0; batch classifier loss: 0.354450; batch adversarial loss: 0.526079\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368235; batch adversarial loss: 0.627570\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345726; batch adversarial loss: 0.570631\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384406; batch adversarial loss: 0.498041\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361203; batch adversarial loss: 0.610802\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310577; batch adversarial loss: 0.500393\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378327; batch adversarial loss: 0.533796\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376749; batch adversarial loss: 0.549798\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342422; batch adversarial loss: 0.535771\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350974; batch adversarial loss: 0.524841\n",
      "epoch 156; iter: 0; batch classifier loss: 0.290229; batch adversarial loss: 0.561055\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349548; batch adversarial loss: 0.579191\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382450; batch adversarial loss: 0.519157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.368432; batch adversarial loss: 0.517546\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344671; batch adversarial loss: 0.545263\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370842; batch adversarial loss: 0.580878\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312757; batch adversarial loss: 0.471161\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336627; batch adversarial loss: 0.614747\n",
      "epoch 164; iter: 0; batch classifier loss: 0.441156; batch adversarial loss: 0.572480\n",
      "epoch 165; iter: 0; batch classifier loss: 0.297145; batch adversarial loss: 0.563867\n",
      "epoch 166; iter: 0; batch classifier loss: 0.415024; batch adversarial loss: 0.498573\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321415; batch adversarial loss: 0.590496\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361214; batch adversarial loss: 0.498417\n",
      "epoch 169; iter: 0; batch classifier loss: 0.448421; batch adversarial loss: 0.544791\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360733; batch adversarial loss: 0.501741\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351990; batch adversarial loss: 0.500298\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341163; batch adversarial loss: 0.500715\n",
      "epoch 173; iter: 0; batch classifier loss: 0.390749; batch adversarial loss: 0.642465\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372132; batch adversarial loss: 0.527153\n",
      "epoch 175; iter: 0; batch classifier loss: 0.371911; batch adversarial loss: 0.559353\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328566; batch adversarial loss: 0.543249\n",
      "epoch 177; iter: 0; batch classifier loss: 0.407466; batch adversarial loss: 0.518383\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416912; batch adversarial loss: 0.497888\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407973; batch adversarial loss: 0.507919\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358684; batch adversarial loss: 0.572552\n",
      "epoch 181; iter: 0; batch classifier loss: 0.406504; batch adversarial loss: 0.563462\n",
      "epoch 182; iter: 0; batch classifier loss: 0.330482; batch adversarial loss: 0.554564\n",
      "epoch 183; iter: 0; batch classifier loss: 0.284017; batch adversarial loss: 0.573263\n",
      "epoch 184; iter: 0; batch classifier loss: 0.396149; batch adversarial loss: 0.498270\n",
      "epoch 185; iter: 0; batch classifier loss: 0.413147; batch adversarial loss: 0.571816\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379188; batch adversarial loss: 0.520370\n",
      "epoch 187; iter: 0; batch classifier loss: 0.290647; batch adversarial loss: 0.616261\n",
      "epoch 188; iter: 0; batch classifier loss: 0.397580; batch adversarial loss: 0.553959\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355372; batch adversarial loss: 0.572604\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384829; batch adversarial loss: 0.563977\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359686; batch adversarial loss: 0.505953\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339365; batch adversarial loss: 0.589648\n",
      "epoch 193; iter: 0; batch classifier loss: 0.326079; batch adversarial loss: 0.536227\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340388; batch adversarial loss: 0.588906\n",
      "epoch 195; iter: 0; batch classifier loss: 0.389463; batch adversarial loss: 0.544507\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339851; batch adversarial loss: 0.590706\n",
      "epoch 197; iter: 0; batch classifier loss: 0.428307; batch adversarial loss: 0.470650\n",
      "epoch 198; iter: 0; batch classifier loss: 0.325402; batch adversarial loss: 0.518593\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387407; batch adversarial loss: 0.526795\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642432; batch adversarial loss: 0.793107\n",
      "epoch 1; iter: 0; batch classifier loss: 0.854374; batch adversarial loss: 1.049733\n",
      "epoch 2; iter: 0; batch classifier loss: 0.922111; batch adversarial loss: 0.992559\n",
      "epoch 3; iter: 0; batch classifier loss: 0.983356; batch adversarial loss: 0.969657\n",
      "epoch 4; iter: 0; batch classifier loss: 0.858093; batch adversarial loss: 0.855086\n",
      "epoch 5; iter: 0; batch classifier loss: 0.784875; batch adversarial loss: 0.721817\n",
      "epoch 6; iter: 0; batch classifier loss: 0.657289; batch adversarial loss: 0.679147\n",
      "epoch 7; iter: 0; batch classifier loss: 0.673718; batch adversarial loss: 0.658026\n",
      "epoch 8; iter: 0; batch classifier loss: 0.598322; batch adversarial loss: 0.636148\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503721; batch adversarial loss: 0.641858\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532708; batch adversarial loss: 0.616983\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517701; batch adversarial loss: 0.619166\n",
      "epoch 12; iter: 0; batch classifier loss: 0.615022; batch adversarial loss: 0.582408\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519344; batch adversarial loss: 0.628530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499511; batch adversarial loss: 0.533682\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471342; batch adversarial loss: 0.599244\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526855; batch adversarial loss: 0.587662\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552157; batch adversarial loss: 0.529015\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477502; batch adversarial loss: 0.526481\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499301; batch adversarial loss: 0.571268\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485708; batch adversarial loss: 0.591278\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530733; batch adversarial loss: 0.585070\n",
      "epoch 22; iter: 0; batch classifier loss: 0.405849; batch adversarial loss: 0.583594\n",
      "epoch 23; iter: 0; batch classifier loss: 0.545413; batch adversarial loss: 0.530818\n",
      "epoch 24; iter: 0; batch classifier loss: 0.530974; batch adversarial loss: 0.585662\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438143; batch adversarial loss: 0.631805\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462346; batch adversarial loss: 0.555622\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509110; batch adversarial loss: 0.580892\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457027; batch adversarial loss: 0.559118\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476219; batch adversarial loss: 0.546005\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488144; batch adversarial loss: 0.523734\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489404; batch adversarial loss: 0.514400\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488590; batch adversarial loss: 0.508349\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433325; batch adversarial loss: 0.590338\n",
      "epoch 34; iter: 0; batch classifier loss: 0.505749; batch adversarial loss: 0.479085\n",
      "epoch 35; iter: 0; batch classifier loss: 0.526434; batch adversarial loss: 0.544550\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434701; batch adversarial loss: 0.637665\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407390; batch adversarial loss: 0.578895\n",
      "epoch 38; iter: 0; batch classifier loss: 0.487668; batch adversarial loss: 0.490947\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459370; batch adversarial loss: 0.686961\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448006; batch adversarial loss: 0.618617\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446543; batch adversarial loss: 0.561225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505856; batch adversarial loss: 0.524118\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407893; batch adversarial loss: 0.576824\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473095; batch adversarial loss: 0.605208\n",
      "epoch 45; iter: 0; batch classifier loss: 0.497776; batch adversarial loss: 0.547490\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407095; batch adversarial loss: 0.586605\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467107; batch adversarial loss: 0.567129\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423283; batch adversarial loss: 0.550769\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445932; batch adversarial loss: 0.453975\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465880; batch adversarial loss: 0.515334\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423004; batch adversarial loss: 0.531911\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423881; batch adversarial loss: 0.585782\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374608; batch adversarial loss: 0.535032\n",
      "epoch 54; iter: 0; batch classifier loss: 0.486641; batch adversarial loss: 0.464379\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440142; batch adversarial loss: 0.583817\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414731; batch adversarial loss: 0.480271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.434451; batch adversarial loss: 0.501552\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463838; batch adversarial loss: 0.601026\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441082; batch adversarial loss: 0.556086\n",
      "epoch 60; iter: 0; batch classifier loss: 0.345173; batch adversarial loss: 0.526137\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439682; batch adversarial loss: 0.525321\n",
      "epoch 62; iter: 0; batch classifier loss: 0.465332; batch adversarial loss: 0.579361\n",
      "epoch 63; iter: 0; batch classifier loss: 0.345657; batch adversarial loss: 0.469332\n",
      "epoch 64; iter: 0; batch classifier loss: 0.484771; batch adversarial loss: 0.597494\n",
      "epoch 65; iter: 0; batch classifier loss: 0.298084; batch adversarial loss: 0.478349\n",
      "epoch 66; iter: 0; batch classifier loss: 0.482457; batch adversarial loss: 0.534284\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416367; batch adversarial loss: 0.569120\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403654; batch adversarial loss: 0.546849\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403433; batch adversarial loss: 0.499285\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433184; batch adversarial loss: 0.506777\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404214; batch adversarial loss: 0.597969\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404089; batch adversarial loss: 0.597983\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422267; batch adversarial loss: 0.573447\n",
      "epoch 74; iter: 0; batch classifier loss: 0.322218; batch adversarial loss: 0.491160\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447967; batch adversarial loss: 0.601518\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392259; batch adversarial loss: 0.545556\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360919; batch adversarial loss: 0.543311\n",
      "epoch 78; iter: 0; batch classifier loss: 0.495766; batch adversarial loss: 0.572652\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405222; batch adversarial loss: 0.535829\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395901; batch adversarial loss: 0.636779\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405770; batch adversarial loss: 0.581273\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408128; batch adversarial loss: 0.535990\n",
      "epoch 83; iter: 0; batch classifier loss: 0.484913; batch adversarial loss: 0.608745\n",
      "epoch 84; iter: 0; batch classifier loss: 0.466953; batch adversarial loss: 0.461669\n",
      "epoch 85; iter: 0; batch classifier loss: 0.481103; batch adversarial loss: 0.517301\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390592; batch adversarial loss: 0.525586\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368270; batch adversarial loss: 0.553466\n",
      "epoch 88; iter: 0; batch classifier loss: 0.364879; batch adversarial loss: 0.505808\n",
      "epoch 89; iter: 0; batch classifier loss: 0.354398; batch adversarial loss: 0.401608\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390575; batch adversarial loss: 0.541871\n",
      "epoch 91; iter: 0; batch classifier loss: 0.415001; batch adversarial loss: 0.582941\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378899; batch adversarial loss: 0.627266\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455153; batch adversarial loss: 0.534613\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348524; batch adversarial loss: 0.601690\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368487; batch adversarial loss: 0.507677\n",
      "epoch 96; iter: 0; batch classifier loss: 0.324808; batch adversarial loss: 0.554681\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399386; batch adversarial loss: 0.593806\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418131; batch adversarial loss: 0.599651\n",
      "epoch 99; iter: 0; batch classifier loss: 0.394530; batch adversarial loss: 0.545246\n",
      "epoch 100; iter: 0; batch classifier loss: 0.414865; batch adversarial loss: 0.527713\n",
      "epoch 101; iter: 0; batch classifier loss: 0.423545; batch adversarial loss: 0.553117\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382630; batch adversarial loss: 0.572512\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358691; batch adversarial loss: 0.488578\n",
      "epoch 104; iter: 0; batch classifier loss: 0.356658; batch adversarial loss: 0.545033\n",
      "epoch 105; iter: 0; batch classifier loss: 0.330995; batch adversarial loss: 0.572721\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370109; batch adversarial loss: 0.559540\n",
      "epoch 107; iter: 0; batch classifier loss: 0.442970; batch adversarial loss: 0.573129\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353090; batch adversarial loss: 0.638240\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410300; batch adversarial loss: 0.562625\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371449; batch adversarial loss: 0.443958\n",
      "epoch 111; iter: 0; batch classifier loss: 0.346171; batch adversarial loss: 0.554337\n",
      "epoch 112; iter: 0; batch classifier loss: 0.320843; batch adversarial loss: 0.499066\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343891; batch adversarial loss: 0.517874\n",
      "epoch 114; iter: 0; batch classifier loss: 0.334457; batch adversarial loss: 0.590713\n",
      "epoch 115; iter: 0; batch classifier loss: 0.334173; batch adversarial loss: 0.516742\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381488; batch adversarial loss: 0.561730\n",
      "epoch 117; iter: 0; batch classifier loss: 0.307363; batch adversarial loss: 0.591074\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355718; batch adversarial loss: 0.534957\n",
      "epoch 119; iter: 0; batch classifier loss: 0.426562; batch adversarial loss: 0.572912\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401143; batch adversarial loss: 0.525423\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382413; batch adversarial loss: 0.423944\n",
      "epoch 122; iter: 0; batch classifier loss: 0.331983; batch adversarial loss: 0.526189\n",
      "epoch 123; iter: 0; batch classifier loss: 0.412393; batch adversarial loss: 0.592613\n",
      "epoch 124; iter: 0; batch classifier loss: 0.321517; batch adversarial loss: 0.524584\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409389; batch adversarial loss: 0.573163\n",
      "epoch 126; iter: 0; batch classifier loss: 0.326740; batch adversarial loss: 0.507354\n",
      "epoch 127; iter: 0; batch classifier loss: 0.420674; batch adversarial loss: 0.497817\n",
      "epoch 128; iter: 0; batch classifier loss: 0.412361; batch adversarial loss: 0.563959\n",
      "epoch 129; iter: 0; batch classifier loss: 0.318471; batch adversarial loss: 0.535049\n",
      "epoch 130; iter: 0; batch classifier loss: 0.333736; batch adversarial loss: 0.507948\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353806; batch adversarial loss: 0.590089\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392119; batch adversarial loss: 0.544333\n",
      "epoch 133; iter: 0; batch classifier loss: 0.359195; batch adversarial loss: 0.563206\n",
      "epoch 134; iter: 0; batch classifier loss: 0.353601; batch adversarial loss: 0.571991\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385035; batch adversarial loss: 0.516706\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383923; batch adversarial loss: 0.572034\n",
      "epoch 137; iter: 0; batch classifier loss: 0.360872; batch adversarial loss: 0.562931\n",
      "epoch 138; iter: 0; batch classifier loss: 0.427700; batch adversarial loss: 0.535723\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402045; batch adversarial loss: 0.470954\n",
      "epoch 140; iter: 0; batch classifier loss: 0.440720; batch adversarial loss: 0.572776\n",
      "epoch 141; iter: 0; batch classifier loss: 0.425644; batch adversarial loss: 0.545170\n",
      "epoch 142; iter: 0; batch classifier loss: 0.329838; batch adversarial loss: 0.581650\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414722; batch adversarial loss: 0.627859\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351046; batch adversarial loss: 0.535082\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383646; batch adversarial loss: 0.572392\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404501; batch adversarial loss: 0.581311\n",
      "epoch 147; iter: 0; batch classifier loss: 0.302134; batch adversarial loss: 0.563027\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374470; batch adversarial loss: 0.488351\n",
      "epoch 149; iter: 0; batch classifier loss: 0.364612; batch adversarial loss: 0.507035\n",
      "epoch 150; iter: 0; batch classifier loss: 0.318429; batch adversarial loss: 0.525432\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327399; batch adversarial loss: 0.508016\n",
      "epoch 152; iter: 0; batch classifier loss: 0.411795; batch adversarial loss: 0.535184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.390652; batch adversarial loss: 0.608370\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381891; batch adversarial loss: 0.619041\n",
      "epoch 155; iter: 0; batch classifier loss: 0.331516; batch adversarial loss: 0.562739\n",
      "epoch 156; iter: 0; batch classifier loss: 0.322148; batch adversarial loss: 0.544815\n",
      "epoch 157; iter: 0; batch classifier loss: 0.339750; batch adversarial loss: 0.525909\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342891; batch adversarial loss: 0.544496\n",
      "epoch 159; iter: 0; batch classifier loss: 0.327285; batch adversarial loss: 0.572126\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353687; batch adversarial loss: 0.544449\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345376; batch adversarial loss: 0.572725\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370333; batch adversarial loss: 0.654840\n",
      "epoch 163; iter: 0; batch classifier loss: 0.437063; batch adversarial loss: 0.516964\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348825; batch adversarial loss: 0.498159\n",
      "epoch 165; iter: 0; batch classifier loss: 0.282318; batch adversarial loss: 0.535341\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351787; batch adversarial loss: 0.544797\n",
      "epoch 167; iter: 0; batch classifier loss: 0.275266; batch adversarial loss: 0.479840\n",
      "epoch 168; iter: 0; batch classifier loss: 0.285659; batch adversarial loss: 0.507679\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360277; batch adversarial loss: 0.526094\n",
      "epoch 170; iter: 0; batch classifier loss: 0.268287; batch adversarial loss: 0.553821\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335727; batch adversarial loss: 0.627917\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328809; batch adversarial loss: 0.489184\n",
      "epoch 173; iter: 0; batch classifier loss: 0.420693; batch adversarial loss: 0.507605\n",
      "epoch 174; iter: 0; batch classifier loss: 0.382785; batch adversarial loss: 0.563013\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335167; batch adversarial loss: 0.554117\n",
      "epoch 176; iter: 0; batch classifier loss: 0.484098; batch adversarial loss: 0.525971\n",
      "epoch 177; iter: 0; batch classifier loss: 0.364112; batch adversarial loss: 0.562883\n",
      "epoch 178; iter: 0; batch classifier loss: 0.303493; batch adversarial loss: 0.470658\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329965; batch adversarial loss: 0.516525\n",
      "epoch 180; iter: 0; batch classifier loss: 0.439660; batch adversarial loss: 0.525905\n",
      "epoch 181; iter: 0; batch classifier loss: 0.474612; batch adversarial loss: 0.544198\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349242; batch adversarial loss: 0.618598\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346616; batch adversarial loss: 0.497712\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344668; batch adversarial loss: 0.526047\n",
      "epoch 185; iter: 0; batch classifier loss: 0.413805; batch adversarial loss: 0.553926\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330091; batch adversarial loss: 0.600423\n",
      "epoch 187; iter: 0; batch classifier loss: 0.404567; batch adversarial loss: 0.599740\n",
      "epoch 188; iter: 0; batch classifier loss: 0.370222; batch adversarial loss: 0.516845\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335774; batch adversarial loss: 0.497973\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332466; batch adversarial loss: 0.508003\n",
      "epoch 191; iter: 0; batch classifier loss: 0.413707; batch adversarial loss: 0.562853\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339324; batch adversarial loss: 0.507319\n",
      "epoch 193; iter: 0; batch classifier loss: 0.302365; batch adversarial loss: 0.526038\n",
      "epoch 194; iter: 0; batch classifier loss: 0.328410; batch adversarial loss: 0.498410\n",
      "epoch 195; iter: 0; batch classifier loss: 0.373056; batch adversarial loss: 0.424027\n",
      "epoch 196; iter: 0; batch classifier loss: 0.291481; batch adversarial loss: 0.562841\n",
      "epoch 197; iter: 0; batch classifier loss: 0.289859; batch adversarial loss: 0.553794\n",
      "epoch 198; iter: 0; batch classifier loss: 0.373322; batch adversarial loss: 0.562754\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309949; batch adversarial loss: 0.553943\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695729; batch adversarial loss: 0.624965\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627146; batch adversarial loss: 0.673132\n",
      "epoch 2; iter: 0; batch classifier loss: 0.439465; batch adversarial loss: 0.665753\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617941; batch adversarial loss: 0.620879\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584114; batch adversarial loss: 0.619355\n",
      "epoch 5; iter: 0; batch classifier loss: 0.487396; batch adversarial loss: 0.610652\n",
      "epoch 6; iter: 0; batch classifier loss: 0.530519; batch adversarial loss: 0.593176\n",
      "epoch 7; iter: 0; batch classifier loss: 0.460795; batch adversarial loss: 0.630690\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512659; batch adversarial loss: 0.571926\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488579; batch adversarial loss: 0.563848\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493664; batch adversarial loss: 0.562660\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525946; batch adversarial loss: 0.573926\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461955; batch adversarial loss: 0.580888\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482071; batch adversarial loss: 0.609931\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464817; batch adversarial loss: 0.596668\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503121; batch adversarial loss: 0.492548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513323; batch adversarial loss: 0.533216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.428068; batch adversarial loss: 0.565814\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446973; batch adversarial loss: 0.588689\n",
      "epoch 19; iter: 0; batch classifier loss: 0.467312; batch adversarial loss: 0.504458\n",
      "epoch 20; iter: 0; batch classifier loss: 0.537173; batch adversarial loss: 0.622345\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460192; batch adversarial loss: 0.548224\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516644; batch adversarial loss: 0.554319\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468642; batch adversarial loss: 0.537195\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490628; batch adversarial loss: 0.530869\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485681; batch adversarial loss: 0.565961\n",
      "epoch 26; iter: 0; batch classifier loss: 0.525128; batch adversarial loss: 0.509473\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424505; batch adversarial loss: 0.576856\n",
      "epoch 28; iter: 0; batch classifier loss: 0.537500; batch adversarial loss: 0.540122\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467977; batch adversarial loss: 0.541969\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469330; batch adversarial loss: 0.544402\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506624; batch adversarial loss: 0.503166\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517410; batch adversarial loss: 0.592259\n",
      "epoch 33; iter: 0; batch classifier loss: 0.419128; batch adversarial loss: 0.512002\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420316; batch adversarial loss: 0.530467\n",
      "epoch 35; iter: 0; batch classifier loss: 0.417465; batch adversarial loss: 0.538343\n",
      "epoch 36; iter: 0; batch classifier loss: 0.524146; batch adversarial loss: 0.566869\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459996; batch adversarial loss: 0.517472\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478600; batch adversarial loss: 0.528178\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436169; batch adversarial loss: 0.518560\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419828; batch adversarial loss: 0.534439\n",
      "epoch 41; iter: 0; batch classifier loss: 0.502475; batch adversarial loss: 0.514873\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419236; batch adversarial loss: 0.537971\n",
      "epoch 43; iter: 0; batch classifier loss: 0.417866; batch adversarial loss: 0.564774\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484842; batch adversarial loss: 0.523353\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438254; batch adversarial loss: 0.554672\n",
      "epoch 46; iter: 0; batch classifier loss: 0.463253; batch adversarial loss: 0.575223\n",
      "epoch 47; iter: 0; batch classifier loss: 0.379938; batch adversarial loss: 0.523620\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451074; batch adversarial loss: 0.507789\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438721; batch adversarial loss: 0.477930\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472110; batch adversarial loss: 0.525397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.440795; batch adversarial loss: 0.487027\n",
      "epoch 52; iter: 0; batch classifier loss: 0.428654; batch adversarial loss: 0.581995\n",
      "epoch 53; iter: 0; batch classifier loss: 0.426999; batch adversarial loss: 0.543108\n",
      "epoch 54; iter: 0; batch classifier loss: 0.343852; batch adversarial loss: 0.573144\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417735; batch adversarial loss: 0.543326\n",
      "epoch 56; iter: 0; batch classifier loss: 0.485899; batch adversarial loss: 0.570945\n",
      "epoch 57; iter: 0; batch classifier loss: 0.464065; batch adversarial loss: 0.582123\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388140; batch adversarial loss: 0.545565\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384594; batch adversarial loss: 0.510477\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385068; batch adversarial loss: 0.543600\n",
      "epoch 61; iter: 0; batch classifier loss: 0.473225; batch adversarial loss: 0.516657\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441413; batch adversarial loss: 0.516403\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378645; batch adversarial loss: 0.627878\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489895; batch adversarial loss: 0.505078\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430628; batch adversarial loss: 0.640397\n",
      "epoch 66; iter: 0; batch classifier loss: 0.362899; batch adversarial loss: 0.599062\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394963; batch adversarial loss: 0.515600\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400806; batch adversarial loss: 0.468884\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442652; batch adversarial loss: 0.486567\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402315; batch adversarial loss: 0.545307\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369664; batch adversarial loss: 0.570472\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377495; batch adversarial loss: 0.617698\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441222; batch adversarial loss: 0.505335\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416609; batch adversarial loss: 0.553604\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421857; batch adversarial loss: 0.554528\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404892; batch adversarial loss: 0.543389\n",
      "epoch 77; iter: 0; batch classifier loss: 0.466389; batch adversarial loss: 0.502929\n",
      "epoch 78; iter: 0; batch classifier loss: 0.451439; batch adversarial loss: 0.553288\n",
      "epoch 79; iter: 0; batch classifier loss: 0.449079; batch adversarial loss: 0.573605\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385996; batch adversarial loss: 0.581833\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443133; batch adversarial loss: 0.534061\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422883; batch adversarial loss: 0.592119\n",
      "epoch 83; iter: 0; batch classifier loss: 0.349228; batch adversarial loss: 0.535021\n",
      "epoch 84; iter: 0; batch classifier loss: 0.351195; batch adversarial loss: 0.580836\n",
      "epoch 85; iter: 0; batch classifier loss: 0.357226; batch adversarial loss: 0.494748\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428484; batch adversarial loss: 0.496160\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364813; batch adversarial loss: 0.544001\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348206; batch adversarial loss: 0.564975\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383605; batch adversarial loss: 0.561688\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340158; batch adversarial loss: 0.495069\n",
      "epoch 91; iter: 0; batch classifier loss: 0.448610; batch adversarial loss: 0.592568\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367695; batch adversarial loss: 0.533474\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371562; batch adversarial loss: 0.496738\n",
      "epoch 94; iter: 0; batch classifier loss: 0.439062; batch adversarial loss: 0.573754\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384896; batch adversarial loss: 0.514782\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399787; batch adversarial loss: 0.584027\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365715; batch adversarial loss: 0.544611\n",
      "epoch 98; iter: 0; batch classifier loss: 0.422982; batch adversarial loss: 0.562401\n",
      "epoch 99; iter: 0; batch classifier loss: 0.445017; batch adversarial loss: 0.496858\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394741; batch adversarial loss: 0.582051\n",
      "epoch 101; iter: 0; batch classifier loss: 0.429564; batch adversarial loss: 0.545814\n",
      "epoch 102; iter: 0; batch classifier loss: 0.354862; batch adversarial loss: 0.589319\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404965; batch adversarial loss: 0.562030\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415694; batch adversarial loss: 0.497442\n",
      "epoch 105; iter: 0; batch classifier loss: 0.463823; batch adversarial loss: 0.489358\n",
      "epoch 106; iter: 0; batch classifier loss: 0.283454; batch adversarial loss: 0.467769\n",
      "epoch 107; iter: 0; batch classifier loss: 0.466285; batch adversarial loss: 0.496488\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387462; batch adversarial loss: 0.609607\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384453; batch adversarial loss: 0.563848\n",
      "epoch 110; iter: 0; batch classifier loss: 0.459708; batch adversarial loss: 0.553161\n",
      "epoch 111; iter: 0; batch classifier loss: 0.425446; batch adversarial loss: 0.554323\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392893; batch adversarial loss: 0.543883\n",
      "epoch 113; iter: 0; batch classifier loss: 0.326241; batch adversarial loss: 0.542834\n",
      "epoch 114; iter: 0; batch classifier loss: 0.353879; batch adversarial loss: 0.632018\n",
      "epoch 115; iter: 0; batch classifier loss: 0.437099; batch adversarial loss: 0.552298\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401368; batch adversarial loss: 0.565012\n",
      "epoch 117; iter: 0; batch classifier loss: 0.427475; batch adversarial loss: 0.497362\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381379; batch adversarial loss: 0.565126\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402944; batch adversarial loss: 0.543591\n",
      "epoch 120; iter: 0; batch classifier loss: 0.403196; batch adversarial loss: 0.666367\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369037; batch adversarial loss: 0.581288\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391277; batch adversarial loss: 0.496658\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370388; batch adversarial loss: 0.485737\n",
      "epoch 124; iter: 0; batch classifier loss: 0.547532; batch adversarial loss: 0.572577\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402142; batch adversarial loss: 0.505163\n",
      "epoch 126; iter: 0; batch classifier loss: 0.388169; batch adversarial loss: 0.545171\n",
      "epoch 127; iter: 0; batch classifier loss: 0.476268; batch adversarial loss: 0.517396\n",
      "epoch 128; iter: 0; batch classifier loss: 0.270962; batch adversarial loss: 0.581295\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380970; batch adversarial loss: 0.451465\n",
      "epoch 130; iter: 0; batch classifier loss: 0.433524; batch adversarial loss: 0.489025\n",
      "epoch 131; iter: 0; batch classifier loss: 0.474486; batch adversarial loss: 0.563753\n",
      "epoch 132; iter: 0; batch classifier loss: 0.368427; batch adversarial loss: 0.450058\n",
      "epoch 133; iter: 0; batch classifier loss: 0.409774; batch adversarial loss: 0.440491\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358247; batch adversarial loss: 0.544831\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400894; batch adversarial loss: 0.506640\n",
      "epoch 136; iter: 0; batch classifier loss: 0.290959; batch adversarial loss: 0.484866\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424582; batch adversarial loss: 0.515940\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388035; batch adversarial loss: 0.580099\n",
      "epoch 139; iter: 0; batch classifier loss: 0.351574; batch adversarial loss: 0.507065\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358917; batch adversarial loss: 0.544716\n",
      "epoch 141; iter: 0; batch classifier loss: 0.376861; batch adversarial loss: 0.553391\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371860; batch adversarial loss: 0.507856\n",
      "epoch 143; iter: 0; batch classifier loss: 0.445311; batch adversarial loss: 0.507756\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362829; batch adversarial loss: 0.488231\n",
      "epoch 145; iter: 0; batch classifier loss: 0.309622; batch adversarial loss: 0.628327\n",
      "epoch 146; iter: 0; batch classifier loss: 0.467799; batch adversarial loss: 0.553983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.316573; batch adversarial loss: 0.497284\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323974; batch adversarial loss: 0.581907\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343641; batch adversarial loss: 0.535017\n",
      "epoch 150; iter: 0; batch classifier loss: 0.401131; batch adversarial loss: 0.563267\n",
      "epoch 151; iter: 0; batch classifier loss: 0.389660; batch adversarial loss: 0.535150\n",
      "epoch 152; iter: 0; batch classifier loss: 0.327948; batch adversarial loss: 0.535486\n",
      "epoch 153; iter: 0; batch classifier loss: 0.305333; batch adversarial loss: 0.544839\n",
      "epoch 154; iter: 0; batch classifier loss: 0.303434; batch adversarial loss: 0.543569\n",
      "epoch 155; iter: 0; batch classifier loss: 0.422210; batch adversarial loss: 0.487545\n",
      "epoch 156; iter: 0; batch classifier loss: 0.432732; batch adversarial loss: 0.526239\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375875; batch adversarial loss: 0.535503\n",
      "epoch 158; iter: 0; batch classifier loss: 0.348969; batch adversarial loss: 0.544683\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390728; batch adversarial loss: 0.516353\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377101; batch adversarial loss: 0.525466\n",
      "epoch 161; iter: 0; batch classifier loss: 0.443193; batch adversarial loss: 0.506458\n",
      "epoch 162; iter: 0; batch classifier loss: 0.399968; batch adversarial loss: 0.534240\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392443; batch adversarial loss: 0.631141\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346946; batch adversarial loss: 0.544321\n",
      "epoch 165; iter: 0; batch classifier loss: 0.422520; batch adversarial loss: 0.562768\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356577; batch adversarial loss: 0.534203\n",
      "epoch 167; iter: 0; batch classifier loss: 0.435694; batch adversarial loss: 0.496117\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353240; batch adversarial loss: 0.554059\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355993; batch adversarial loss: 0.666291\n",
      "epoch 170; iter: 0; batch classifier loss: 0.445391; batch adversarial loss: 0.575610\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388840; batch adversarial loss: 0.555878\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346173; batch adversarial loss: 0.493712\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340195; batch adversarial loss: 0.517310\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387953; batch adversarial loss: 0.499589\n",
      "epoch 175; iter: 0; batch classifier loss: 0.412163; batch adversarial loss: 0.545419\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329641; batch adversarial loss: 0.600039\n",
      "epoch 177; iter: 0; batch classifier loss: 0.348718; batch adversarial loss: 0.620032\n",
      "epoch 178; iter: 0; batch classifier loss: 0.349777; batch adversarial loss: 0.516103\n",
      "epoch 179; iter: 0; batch classifier loss: 0.373262; batch adversarial loss: 0.592228\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358867; batch adversarial loss: 0.553661\n",
      "epoch 181; iter: 0; batch classifier loss: 0.276973; batch adversarial loss: 0.563047\n",
      "epoch 182; iter: 0; batch classifier loss: 0.325643; batch adversarial loss: 0.498067\n",
      "epoch 183; iter: 0; batch classifier loss: 0.350761; batch adversarial loss: 0.488640\n",
      "epoch 184; iter: 0; batch classifier loss: 0.424266; batch adversarial loss: 0.553766\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387745; batch adversarial loss: 0.544806\n",
      "epoch 186; iter: 0; batch classifier loss: 0.322926; batch adversarial loss: 0.582164\n",
      "epoch 187; iter: 0; batch classifier loss: 0.398390; batch adversarial loss: 0.572805\n",
      "epoch 188; iter: 0; batch classifier loss: 0.344989; batch adversarial loss: 0.532892\n",
      "epoch 189; iter: 0; batch classifier loss: 0.279272; batch adversarial loss: 0.553871\n",
      "epoch 190; iter: 0; batch classifier loss: 0.413202; batch adversarial loss: 0.572449\n",
      "epoch 191; iter: 0; batch classifier loss: 0.415790; batch adversarial loss: 0.535205\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404643; batch adversarial loss: 0.544563\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362962; batch adversarial loss: 0.573172\n",
      "epoch 194; iter: 0; batch classifier loss: 0.303893; batch adversarial loss: 0.565391\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350448; batch adversarial loss: 0.610155\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359839; batch adversarial loss: 0.525390\n",
      "epoch 197; iter: 0; batch classifier loss: 0.403454; batch adversarial loss: 0.507780\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369035; batch adversarial loss: 0.543654\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339077; batch adversarial loss: 0.525768\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667842; batch adversarial loss: 0.703111\n",
      "epoch 1; iter: 0; batch classifier loss: 0.617952; batch adversarial loss: 0.664992\n",
      "epoch 2; iter: 0; batch classifier loss: 0.564315; batch adversarial loss: 0.640401\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588319; batch adversarial loss: 0.640736\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532977; batch adversarial loss: 0.610820\n",
      "epoch 5; iter: 0; batch classifier loss: 0.460510; batch adversarial loss: 0.606739\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564659; batch adversarial loss: 0.575073\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535744; batch adversarial loss: 0.610022\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571011; batch adversarial loss: 0.547034\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508243; batch adversarial loss: 0.632873\n",
      "epoch 10; iter: 0; batch classifier loss: 0.600648; batch adversarial loss: 0.549487\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505394; batch adversarial loss: 0.557783\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495069; batch adversarial loss: 0.603152\n",
      "epoch 13; iter: 0; batch classifier loss: 0.562118; batch adversarial loss: 0.566694\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535249; batch adversarial loss: 0.593890\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563241; batch adversarial loss: 0.551943\n",
      "epoch 16; iter: 0; batch classifier loss: 0.434628; batch adversarial loss: 0.561302\n",
      "epoch 17; iter: 0; batch classifier loss: 0.502258; batch adversarial loss: 0.537470\n",
      "epoch 18; iter: 0; batch classifier loss: 0.445139; batch adversarial loss: 0.582563\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443981; batch adversarial loss: 0.526202\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539036; batch adversarial loss: 0.541462\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431372; batch adversarial loss: 0.514031\n",
      "epoch 22; iter: 0; batch classifier loss: 0.557032; batch adversarial loss: 0.572700\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513613; batch adversarial loss: 0.608759\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506774; batch adversarial loss: 0.618413\n",
      "epoch 25; iter: 0; batch classifier loss: 0.522823; batch adversarial loss: 0.522898\n",
      "epoch 26; iter: 0; batch classifier loss: 0.526240; batch adversarial loss: 0.513370\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490161; batch adversarial loss: 0.546828\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462582; batch adversarial loss: 0.561447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509653; batch adversarial loss: 0.528134\n",
      "epoch 30; iter: 0; batch classifier loss: 0.518396; batch adversarial loss: 0.588568\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466837; batch adversarial loss: 0.518706\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494479; batch adversarial loss: 0.540058\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452355; batch adversarial loss: 0.506627\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496797; batch adversarial loss: 0.554316\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440549; batch adversarial loss: 0.592115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452142; batch adversarial loss: 0.587353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469675; batch adversarial loss: 0.482147\n",
      "epoch 38; iter: 0; batch classifier loss: 0.533953; batch adversarial loss: 0.544495\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447945; batch adversarial loss: 0.573154\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447176; batch adversarial loss: 0.459795\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499774; batch adversarial loss: 0.573674\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477228; batch adversarial loss: 0.538585\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446901; batch adversarial loss: 0.507167\n",
      "epoch 44; iter: 0; batch classifier loss: 0.479766; batch adversarial loss: 0.518598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.452249; batch adversarial loss: 0.561013\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471354; batch adversarial loss: 0.546899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471106; batch adversarial loss: 0.528667\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456013; batch adversarial loss: 0.574635\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487984; batch adversarial loss: 0.555026\n",
      "epoch 50; iter: 0; batch classifier loss: 0.379340; batch adversarial loss: 0.553158\n",
      "epoch 51; iter: 0; batch classifier loss: 0.451173; batch adversarial loss: 0.553118\n",
      "epoch 52; iter: 0; batch classifier loss: 0.483429; batch adversarial loss: 0.480163\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386105; batch adversarial loss: 0.572368\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412672; batch adversarial loss: 0.534330\n",
      "epoch 55; iter: 0; batch classifier loss: 0.474347; batch adversarial loss: 0.609471\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436990; batch adversarial loss: 0.531971\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389224; batch adversarial loss: 0.560047\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422369; batch adversarial loss: 0.574354\n",
      "epoch 59; iter: 0; batch classifier loss: 0.523015; batch adversarial loss: 0.553861\n",
      "epoch 60; iter: 0; batch classifier loss: 0.479723; batch adversarial loss: 0.498149\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436646; batch adversarial loss: 0.524408\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432756; batch adversarial loss: 0.505770\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430918; batch adversarial loss: 0.497622\n",
      "epoch 64; iter: 0; batch classifier loss: 0.496705; batch adversarial loss: 0.562350\n",
      "epoch 65; iter: 0; batch classifier loss: 0.349212; batch adversarial loss: 0.571259\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384991; batch adversarial loss: 0.583267\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431104; batch adversarial loss: 0.442350\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399988; batch adversarial loss: 0.571682\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375417; batch adversarial loss: 0.600173\n",
      "epoch 70; iter: 0; batch classifier loss: 0.435960; batch adversarial loss: 0.498954\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404577; batch adversarial loss: 0.555476\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418838; batch adversarial loss: 0.556878\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426629; batch adversarial loss: 0.525123\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392706; batch adversarial loss: 0.517628\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412206; batch adversarial loss: 0.555558\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414040; batch adversarial loss: 0.609036\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437984; batch adversarial loss: 0.527482\n",
      "epoch 78; iter: 0; batch classifier loss: 0.429884; batch adversarial loss: 0.498757\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429413; batch adversarial loss: 0.619623\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378146; batch adversarial loss: 0.496921\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415051; batch adversarial loss: 0.617664\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401794; batch adversarial loss: 0.570296\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414900; batch adversarial loss: 0.553336\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388947; batch adversarial loss: 0.524403\n",
      "epoch 85; iter: 0; batch classifier loss: 0.331706; batch adversarial loss: 0.515787\n",
      "epoch 86; iter: 0; batch classifier loss: 0.521503; batch adversarial loss: 0.450491\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363487; batch adversarial loss: 0.552613\n",
      "epoch 88; iter: 0; batch classifier loss: 0.409450; batch adversarial loss: 0.524853\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380382; batch adversarial loss: 0.524202\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419730; batch adversarial loss: 0.602513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.424745; batch adversarial loss: 0.579364\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405623; batch adversarial loss: 0.512427\n",
      "epoch 93; iter: 0; batch classifier loss: 0.440026; batch adversarial loss: 0.457881\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387443; batch adversarial loss: 0.573781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398115; batch adversarial loss: 0.455639\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374104; batch adversarial loss: 0.548294\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400465; batch adversarial loss: 0.599525\n",
      "epoch 98; iter: 0; batch classifier loss: 0.315207; batch adversarial loss: 0.536431\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385398; batch adversarial loss: 0.538200\n",
      "epoch 100; iter: 0; batch classifier loss: 0.354973; batch adversarial loss: 0.560441\n",
      "epoch 101; iter: 0; batch classifier loss: 0.349664; batch adversarial loss: 0.563742\n",
      "epoch 102; iter: 0; batch classifier loss: 0.404409; batch adversarial loss: 0.462461\n",
      "epoch 103; iter: 0; batch classifier loss: 0.410341; batch adversarial loss: 0.498555\n",
      "epoch 104; iter: 0; batch classifier loss: 0.401984; batch adversarial loss: 0.553699\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408104; batch adversarial loss: 0.524160\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384829; batch adversarial loss: 0.607222\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378321; batch adversarial loss: 0.468803\n",
      "epoch 108; iter: 0; batch classifier loss: 0.490222; batch adversarial loss: 0.519003\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403758; batch adversarial loss: 0.505665\n",
      "epoch 110; iter: 0; batch classifier loss: 0.319710; batch adversarial loss: 0.525977\n",
      "epoch 111; iter: 0; batch classifier loss: 0.333669; batch adversarial loss: 0.572037\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391059; batch adversarial loss: 0.590713\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401418; batch adversarial loss: 0.487650\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368667; batch adversarial loss: 0.555166\n",
      "epoch 115; iter: 0; batch classifier loss: 0.288668; batch adversarial loss: 0.490139\n",
      "epoch 116; iter: 0; batch classifier loss: 0.432180; batch adversarial loss: 0.545390\n",
      "epoch 117; iter: 0; batch classifier loss: 0.314392; batch adversarial loss: 0.645284\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401093; batch adversarial loss: 0.590935\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423568; batch adversarial loss: 0.442347\n",
      "epoch 120; iter: 0; batch classifier loss: 0.355150; batch adversarial loss: 0.572975\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371789; batch adversarial loss: 0.505883\n",
      "epoch 122; iter: 0; batch classifier loss: 0.342741; batch adversarial loss: 0.505645\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349973; batch adversarial loss: 0.552946\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368972; batch adversarial loss: 0.534841\n",
      "epoch 125; iter: 0; batch classifier loss: 0.310557; batch adversarial loss: 0.562620\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380632; batch adversarial loss: 0.469654\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388904; batch adversarial loss: 0.580731\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343190; batch adversarial loss: 0.514363\n",
      "epoch 129; iter: 0; batch classifier loss: 0.353210; batch adversarial loss: 0.542997\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388095; batch adversarial loss: 0.536407\n",
      "epoch 131; iter: 0; batch classifier loss: 0.396993; batch adversarial loss: 0.524875\n",
      "epoch 132; iter: 0; batch classifier loss: 0.337062; batch adversarial loss: 0.552860\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386731; batch adversarial loss: 0.516533\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379413; batch adversarial loss: 0.561361\n",
      "epoch 135; iter: 0; batch classifier loss: 0.379799; batch adversarial loss: 0.591779\n",
      "epoch 136; iter: 0; batch classifier loss: 0.356318; batch adversarial loss: 0.551471\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383669; batch adversarial loss: 0.515694\n",
      "epoch 138; iter: 0; batch classifier loss: 0.430911; batch adversarial loss: 0.487962\n",
      "epoch 139; iter: 0; batch classifier loss: 0.446448; batch adversarial loss: 0.562199\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365467; batch adversarial loss: 0.544882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.290204; batch adversarial loss: 0.536100\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363070; batch adversarial loss: 0.561989\n",
      "epoch 143; iter: 0; batch classifier loss: 0.426913; batch adversarial loss: 0.441162\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327094; batch adversarial loss: 0.564595\n",
      "epoch 145; iter: 0; batch classifier loss: 0.457911; batch adversarial loss: 0.498143\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399763; batch adversarial loss: 0.496976\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362351; batch adversarial loss: 0.525123\n",
      "epoch 148; iter: 0; batch classifier loss: 0.437604; batch adversarial loss: 0.572247\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349012; batch adversarial loss: 0.516510\n",
      "epoch 150; iter: 0; batch classifier loss: 0.272753; batch adversarial loss: 0.599853\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349334; batch adversarial loss: 0.497384\n",
      "epoch 152; iter: 0; batch classifier loss: 0.327177; batch adversarial loss: 0.498793\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372953; batch adversarial loss: 0.571116\n",
      "epoch 154; iter: 0; batch classifier loss: 0.391694; batch adversarial loss: 0.526692\n",
      "epoch 155; iter: 0; batch classifier loss: 0.375801; batch adversarial loss: 0.571887\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339905; batch adversarial loss: 0.431646\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341043; batch adversarial loss: 0.553951\n",
      "epoch 158; iter: 0; batch classifier loss: 0.349539; batch adversarial loss: 0.517090\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383762; batch adversarial loss: 0.507960\n",
      "epoch 160; iter: 0; batch classifier loss: 0.327487; batch adversarial loss: 0.534103\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341029; batch adversarial loss: 0.600613\n",
      "epoch 162; iter: 0; batch classifier loss: 0.458184; batch adversarial loss: 0.610365\n",
      "epoch 163; iter: 0; batch classifier loss: 0.357969; batch adversarial loss: 0.609959\n",
      "epoch 164; iter: 0; batch classifier loss: 0.461382; batch adversarial loss: 0.563588\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385694; batch adversarial loss: 0.439520\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373156; batch adversarial loss: 0.610078\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356419; batch adversarial loss: 0.562829\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308563; batch adversarial loss: 0.600847\n",
      "epoch 169; iter: 0; batch classifier loss: 0.319145; batch adversarial loss: 0.525809\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318131; batch adversarial loss: 0.534137\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374293; batch adversarial loss: 0.496791\n",
      "epoch 172; iter: 0; batch classifier loss: 0.304666; batch adversarial loss: 0.554698\n",
      "epoch 173; iter: 0; batch classifier loss: 0.391145; batch adversarial loss: 0.570803\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339847; batch adversarial loss: 0.544319\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335675; batch adversarial loss: 0.451262\n",
      "epoch 176; iter: 0; batch classifier loss: 0.324609; batch adversarial loss: 0.534505\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391048; batch adversarial loss: 0.440303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333282; batch adversarial loss: 0.497594\n",
      "epoch 179; iter: 0; batch classifier loss: 0.477370; batch adversarial loss: 0.553229\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369334; batch adversarial loss: 0.552064\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334260; batch adversarial loss: 0.582087\n",
      "epoch 182; iter: 0; batch classifier loss: 0.288300; batch adversarial loss: 0.553773\n",
      "epoch 183; iter: 0; batch classifier loss: 0.433841; batch adversarial loss: 0.451563\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384537; batch adversarial loss: 0.490100\n",
      "epoch 185; iter: 0; batch classifier loss: 0.409531; batch adversarial loss: 0.517143\n",
      "epoch 186; iter: 0; batch classifier loss: 0.265193; batch adversarial loss: 0.525552\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373097; batch adversarial loss: 0.485595\n",
      "epoch 188; iter: 0; batch classifier loss: 0.312975; batch adversarial loss: 0.543741\n",
      "epoch 189; iter: 0; batch classifier loss: 0.259040; batch adversarial loss: 0.497243\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361622; batch adversarial loss: 0.526749\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377045; batch adversarial loss: 0.508794\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381130; batch adversarial loss: 0.572507\n",
      "epoch 193; iter: 0; batch classifier loss: 0.423876; batch adversarial loss: 0.518590\n",
      "epoch 194; iter: 0; batch classifier loss: 0.400968; batch adversarial loss: 0.560721\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381116; batch adversarial loss: 0.601072\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334138; batch adversarial loss: 0.553503\n",
      "epoch 197; iter: 0; batch classifier loss: 0.378108; batch adversarial loss: 0.508630\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365038; batch adversarial loss: 0.591610\n",
      "epoch 199; iter: 0; batch classifier loss: 0.336896; batch adversarial loss: 0.433408\n",
      "epoch 0; iter: 0; batch classifier loss: 0.804964; batch adversarial loss: 0.648640\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619298; batch adversarial loss: 0.629547\n",
      "epoch 2; iter: 0; batch classifier loss: 0.549250; batch adversarial loss: 0.633367\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559584; batch adversarial loss: 0.592713\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498297; batch adversarial loss: 0.607901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509602; batch adversarial loss: 0.587087\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588059; batch adversarial loss: 0.602814\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528979; batch adversarial loss: 0.595286\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596496; batch adversarial loss: 0.572942\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634286; batch adversarial loss: 0.577281\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568258; batch adversarial loss: 0.561476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541857; batch adversarial loss: 0.547670\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504541; batch adversarial loss: 0.589550\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505616; batch adversarial loss: 0.552605\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544761; batch adversarial loss: 0.584385\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488485; batch adversarial loss: 0.523582\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454376; batch adversarial loss: 0.617460\n",
      "epoch 17; iter: 0; batch classifier loss: 0.468460; batch adversarial loss: 0.460249\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483811; batch adversarial loss: 0.542311\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508049; batch adversarial loss: 0.582926\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519434; batch adversarial loss: 0.506750\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469011; batch adversarial loss: 0.537910\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462230; batch adversarial loss: 0.573725\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439172; batch adversarial loss: 0.571731\n",
      "epoch 24; iter: 0; batch classifier loss: 0.551213; batch adversarial loss: 0.541574\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480232; batch adversarial loss: 0.480270\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492120; batch adversarial loss: 0.565009\n",
      "epoch 27; iter: 0; batch classifier loss: 0.514068; batch adversarial loss: 0.562185\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499938; batch adversarial loss: 0.513429\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488661; batch adversarial loss: 0.573352\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453483; batch adversarial loss: 0.561955\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457989; batch adversarial loss: 0.509523\n",
      "epoch 32; iter: 0; batch classifier loss: 0.399439; batch adversarial loss: 0.516987\n",
      "epoch 33; iter: 0; batch classifier loss: 0.397647; batch adversarial loss: 0.636225\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488388; batch adversarial loss: 0.555457\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459798; batch adversarial loss: 0.600180\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432075; batch adversarial loss: 0.580117\n",
      "epoch 37; iter: 0; batch classifier loss: 0.568853; batch adversarial loss: 0.544802\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445686; batch adversarial loss: 0.546105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.489883; batch adversarial loss: 0.536543\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423048; batch adversarial loss: 0.545515\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417246; batch adversarial loss: 0.460418\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453029; batch adversarial loss: 0.491451\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465264; batch adversarial loss: 0.545085\n",
      "epoch 44; iter: 0; batch classifier loss: 0.541699; batch adversarial loss: 0.488437\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438118; batch adversarial loss: 0.590623\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425722; batch adversarial loss: 0.574297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473909; batch adversarial loss: 0.552779\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464505; batch adversarial loss: 0.580807\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503994; batch adversarial loss: 0.480440\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431174; batch adversarial loss: 0.507582\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418182; batch adversarial loss: 0.488304\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460534; batch adversarial loss: 0.580914\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436264; batch adversarial loss: 0.535054\n",
      "epoch 54; iter: 0; batch classifier loss: 0.471136; batch adversarial loss: 0.498293\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393294; batch adversarial loss: 0.582669\n",
      "epoch 56; iter: 0; batch classifier loss: 0.400581; batch adversarial loss: 0.571983\n",
      "epoch 57; iter: 0; batch classifier loss: 0.380434; batch adversarial loss: 0.554382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413829; batch adversarial loss: 0.600594\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421841; batch adversarial loss: 0.554307\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443672; batch adversarial loss: 0.535321\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397832; batch adversarial loss: 0.554071\n",
      "epoch 62; iter: 0; batch classifier loss: 0.458098; batch adversarial loss: 0.497639\n",
      "epoch 63; iter: 0; batch classifier loss: 0.344717; batch adversarial loss: 0.516259\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369779; batch adversarial loss: 0.601531\n",
      "epoch 65; iter: 0; batch classifier loss: 0.486819; batch adversarial loss: 0.460169\n",
      "epoch 66; iter: 0; batch classifier loss: 0.530826; batch adversarial loss: 0.525750\n",
      "epoch 67; iter: 0; batch classifier loss: 0.415399; batch adversarial loss: 0.497665\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393962; batch adversarial loss: 0.562840\n",
      "epoch 69; iter: 0; batch classifier loss: 0.380653; batch adversarial loss: 0.553783\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412659; batch adversarial loss: 0.563691\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391736; batch adversarial loss: 0.543895\n",
      "epoch 72; iter: 0; batch classifier loss: 0.449090; batch adversarial loss: 0.554106\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396355; batch adversarial loss: 0.544502\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405953; batch adversarial loss: 0.553484\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438840; batch adversarial loss: 0.460196\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397863; batch adversarial loss: 0.478719\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383990; batch adversarial loss: 0.479012\n",
      "epoch 78; iter: 0; batch classifier loss: 0.461192; batch adversarial loss: 0.591060\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368541; batch adversarial loss: 0.581624\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420697; batch adversarial loss: 0.507449\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361249; batch adversarial loss: 0.516067\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356008; batch adversarial loss: 0.562961\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374694; batch adversarial loss: 0.638656\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416057; batch adversarial loss: 0.507082\n",
      "epoch 85; iter: 0; batch classifier loss: 0.345068; batch adversarial loss: 0.516529\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401909; batch adversarial loss: 0.535362\n",
      "epoch 87; iter: 0; batch classifier loss: 0.446249; batch adversarial loss: 0.506992\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392512; batch adversarial loss: 0.572660\n",
      "epoch 89; iter: 0; batch classifier loss: 0.443230; batch adversarial loss: 0.582426\n",
      "epoch 90; iter: 0; batch classifier loss: 0.338824; batch adversarial loss: 0.610589\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414380; batch adversarial loss: 0.525568\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354766; batch adversarial loss: 0.516420\n",
      "epoch 93; iter: 0; batch classifier loss: 0.415519; batch adversarial loss: 0.591956\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368014; batch adversarial loss: 0.583381\n",
      "epoch 95; iter: 0; batch classifier loss: 0.479303; batch adversarial loss: 0.601959\n",
      "epoch 96; iter: 0; batch classifier loss: 0.406100; batch adversarial loss: 0.497170\n",
      "epoch 97; iter: 0; batch classifier loss: 0.333701; batch adversarial loss: 0.478685\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395386; batch adversarial loss: 0.534643\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399390; batch adversarial loss: 0.532576\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439377; batch adversarial loss: 0.506649\n",
      "epoch 101; iter: 0; batch classifier loss: 0.464172; batch adversarial loss: 0.500316\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345422; batch adversarial loss: 0.512856\n",
      "epoch 103; iter: 0; batch classifier loss: 0.405889; batch adversarial loss: 0.610690\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409863; batch adversarial loss: 0.557933\n",
      "epoch 105; iter: 0; batch classifier loss: 0.465268; batch adversarial loss: 0.433770\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391643; batch adversarial loss: 0.532276\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358847; batch adversarial loss: 0.571743\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369609; batch adversarial loss: 0.545983\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357333; batch adversarial loss: 0.529214\n",
      "epoch 110; iter: 0; batch classifier loss: 0.443819; batch adversarial loss: 0.582829\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384486; batch adversarial loss: 0.499223\n",
      "epoch 112; iter: 0; batch classifier loss: 0.420434; batch adversarial loss: 0.573483\n",
      "epoch 113; iter: 0; batch classifier loss: 0.361281; batch adversarial loss: 0.519261\n",
      "epoch 114; iter: 0; batch classifier loss: 0.390915; batch adversarial loss: 0.536115\n",
      "epoch 115; iter: 0; batch classifier loss: 0.310782; batch adversarial loss: 0.600582\n",
      "epoch 116; iter: 0; batch classifier loss: 0.386875; batch adversarial loss: 0.562971\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411927; batch adversarial loss: 0.516554\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398750; batch adversarial loss: 0.535021\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410435; batch adversarial loss: 0.553841\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380981; batch adversarial loss: 0.535452\n",
      "epoch 121; iter: 0; batch classifier loss: 0.423075; batch adversarial loss: 0.515671\n",
      "epoch 122; iter: 0; batch classifier loss: 0.338230; batch adversarial loss: 0.592361\n",
      "epoch 123; iter: 0; batch classifier loss: 0.407433; batch adversarial loss: 0.564777\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360941; batch adversarial loss: 0.591185\n",
      "epoch 125; iter: 0; batch classifier loss: 0.325512; batch adversarial loss: 0.516905\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403808; batch adversarial loss: 0.560511\n",
      "epoch 127; iter: 0; batch classifier loss: 0.400755; batch adversarial loss: 0.589484\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415997; batch adversarial loss: 0.541922\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380309; batch adversarial loss: 0.573522\n",
      "epoch 130; iter: 0; batch classifier loss: 0.347931; batch adversarial loss: 0.431400\n",
      "epoch 131; iter: 0; batch classifier loss: 0.281821; batch adversarial loss: 0.544772\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389971; batch adversarial loss: 0.579653\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372494; batch adversarial loss: 0.495768\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379058; batch adversarial loss: 0.525753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.369345; batch adversarial loss: 0.591717\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387390; batch adversarial loss: 0.526806\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372238; batch adversarial loss: 0.527276\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366161; batch adversarial loss: 0.487711\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397244; batch adversarial loss: 0.488677\n",
      "epoch 140; iter: 0; batch classifier loss: 0.423907; batch adversarial loss: 0.535767\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343802; batch adversarial loss: 0.543695\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358924; batch adversarial loss: 0.592126\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356812; batch adversarial loss: 0.547039\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415514; batch adversarial loss: 0.497574\n",
      "epoch 145; iter: 0; batch classifier loss: 0.455424; batch adversarial loss: 0.574353\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358357; batch adversarial loss: 0.553261\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391525; batch adversarial loss: 0.563633\n",
      "epoch 148; iter: 0; batch classifier loss: 0.377759; batch adversarial loss: 0.515025\n",
      "epoch 149; iter: 0; batch classifier loss: 0.318685; batch adversarial loss: 0.564082\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367683; batch adversarial loss: 0.450412\n",
      "epoch 151; iter: 0; batch classifier loss: 0.445903; batch adversarial loss: 0.468841\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336259; batch adversarial loss: 0.552006\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365839; batch adversarial loss: 0.611674\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384606; batch adversarial loss: 0.469356\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371487; batch adversarial loss: 0.459869\n",
      "epoch 156; iter: 0; batch classifier loss: 0.319354; batch adversarial loss: 0.582231\n",
      "epoch 157; iter: 0; batch classifier loss: 0.382885; batch adversarial loss: 0.479613\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354218; batch adversarial loss: 0.546324\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391237; batch adversarial loss: 0.554248\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353671; batch adversarial loss: 0.573693\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370439; batch adversarial loss: 0.525872\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313850; batch adversarial loss: 0.553731\n",
      "epoch 163; iter: 0; batch classifier loss: 0.310696; batch adversarial loss: 0.581289\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356424; batch adversarial loss: 0.545337\n",
      "epoch 165; iter: 0; batch classifier loss: 0.409557; batch adversarial loss: 0.525786\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388749; batch adversarial loss: 0.498097\n",
      "epoch 167; iter: 0; batch classifier loss: 0.413750; batch adversarial loss: 0.487400\n",
      "epoch 168; iter: 0; batch classifier loss: 0.402700; batch adversarial loss: 0.581141\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385054; batch adversarial loss: 0.581125\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385404; batch adversarial loss: 0.554317\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401593; batch adversarial loss: 0.487828\n",
      "epoch 172; iter: 0; batch classifier loss: 0.435839; batch adversarial loss: 0.603870\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377403; batch adversarial loss: 0.591399\n",
      "epoch 174; iter: 0; batch classifier loss: 0.401453; batch adversarial loss: 0.498028\n",
      "epoch 175; iter: 0; batch classifier loss: 0.327664; batch adversarial loss: 0.553704\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349230; batch adversarial loss: 0.555038\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340312; batch adversarial loss: 0.497540\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340791; batch adversarial loss: 0.525063\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368883; batch adversarial loss: 0.507215\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352037; batch adversarial loss: 0.602272\n",
      "epoch 181; iter: 0; batch classifier loss: 0.389645; batch adversarial loss: 0.451536\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355747; batch adversarial loss: 0.495373\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352691; batch adversarial loss: 0.592007\n",
      "epoch 184; iter: 0; batch classifier loss: 0.367077; batch adversarial loss: 0.583413\n",
      "epoch 185; iter: 0; batch classifier loss: 0.307434; batch adversarial loss: 0.440791\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349797; batch adversarial loss: 0.600273\n",
      "epoch 187; iter: 0; batch classifier loss: 0.349247; batch adversarial loss: 0.527002\n",
      "epoch 188; iter: 0; batch classifier loss: 0.428535; batch adversarial loss: 0.507499\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350292; batch adversarial loss: 0.517786\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336975; batch adversarial loss: 0.627676\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372120; batch adversarial loss: 0.525581\n",
      "epoch 192; iter: 0; batch classifier loss: 0.385431; batch adversarial loss: 0.647356\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362532; batch adversarial loss: 0.517200\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332987; batch adversarial loss: 0.581162\n",
      "epoch 195; iter: 0; batch classifier loss: 0.345905; batch adversarial loss: 0.581535\n",
      "epoch 196; iter: 0; batch classifier loss: 0.348313; batch adversarial loss: 0.570668\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350727; batch adversarial loss: 0.515822\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323538; batch adversarial loss: 0.555300\n",
      "epoch 199; iter: 0; batch classifier loss: 0.404450; batch adversarial loss: 0.544572\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727367; batch adversarial loss: 0.531005\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597454; batch adversarial loss: 0.639594\n",
      "epoch 2; iter: 0; batch classifier loss: 0.661581; batch adversarial loss: 0.705335\n",
      "epoch 3; iter: 0; batch classifier loss: 0.688153; batch adversarial loss: 0.686332\n",
      "epoch 4; iter: 0; batch classifier loss: 0.624757; batch adversarial loss: 0.692726\n",
      "epoch 5; iter: 0; batch classifier loss: 0.622472; batch adversarial loss: 0.598756\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568486; batch adversarial loss: 0.622062\n",
      "epoch 7; iter: 0; batch classifier loss: 0.590120; batch adversarial loss: 0.662382\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505681; batch adversarial loss: 0.656306\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461223; batch adversarial loss: 0.581357\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564900; batch adversarial loss: 0.617050\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586606; batch adversarial loss: 0.598894\n",
      "epoch 12; iter: 0; batch classifier loss: 0.595355; batch adversarial loss: 0.578015\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533130; batch adversarial loss: 0.620542\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499387; batch adversarial loss: 0.539065\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498525; batch adversarial loss: 0.572255\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543561; batch adversarial loss: 0.560618\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513990; batch adversarial loss: 0.524107\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502840; batch adversarial loss: 0.548174\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485534; batch adversarial loss: 0.524804\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527504; batch adversarial loss: 0.587950\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487847; batch adversarial loss: 0.562908\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489308; batch adversarial loss: 0.579217\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466370; batch adversarial loss: 0.439429\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486612; batch adversarial loss: 0.554705\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532489; batch adversarial loss: 0.584600\n",
      "epoch 26; iter: 0; batch classifier loss: 0.454193; batch adversarial loss: 0.575227\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425095; batch adversarial loss: 0.490325\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523610; batch adversarial loss: 0.522265\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477800; batch adversarial loss: 0.513036\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474290; batch adversarial loss: 0.514457\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466066; batch adversarial loss: 0.521606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.415049; batch adversarial loss: 0.539416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406997; batch adversarial loss: 0.557151\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466444; batch adversarial loss: 0.567154\n",
      "epoch 35; iter: 0; batch classifier loss: 0.554082; batch adversarial loss: 0.517735\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438939; batch adversarial loss: 0.524592\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497865; batch adversarial loss: 0.492858\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432605; batch adversarial loss: 0.602838\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482866; batch adversarial loss: 0.518521\n",
      "epoch 40; iter: 0; batch classifier loss: 0.499835; batch adversarial loss: 0.508313\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463804; batch adversarial loss: 0.536905\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411835; batch adversarial loss: 0.446206\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401279; batch adversarial loss: 0.499318\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410133; batch adversarial loss: 0.554238\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439384; batch adversarial loss: 0.569976\n",
      "epoch 46; iter: 0; batch classifier loss: 0.463860; batch adversarial loss: 0.556794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410314; batch adversarial loss: 0.556092\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447858; batch adversarial loss: 0.525798\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424569; batch adversarial loss: 0.480097\n",
      "epoch 50; iter: 0; batch classifier loss: 0.517712; batch adversarial loss: 0.599916\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417231; batch adversarial loss: 0.561365\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389106; batch adversarial loss: 0.505590\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452279; batch adversarial loss: 0.526321\n",
      "epoch 54; iter: 0; batch classifier loss: 0.494521; batch adversarial loss: 0.527869\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430173; batch adversarial loss: 0.535803\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433705; batch adversarial loss: 0.522344\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450748; batch adversarial loss: 0.534814\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469261; batch adversarial loss: 0.525519\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357174; batch adversarial loss: 0.597232\n",
      "epoch 60; iter: 0; batch classifier loss: 0.507730; batch adversarial loss: 0.598014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468895; batch adversarial loss: 0.555084\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446138; batch adversarial loss: 0.516479\n",
      "epoch 63; iter: 0; batch classifier loss: 0.485779; batch adversarial loss: 0.509661\n",
      "epoch 64; iter: 0; batch classifier loss: 0.433477; batch adversarial loss: 0.553693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455642; batch adversarial loss: 0.461356\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382366; batch adversarial loss: 0.553559\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406652; batch adversarial loss: 0.507977\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427110; batch adversarial loss: 0.462622\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386498; batch adversarial loss: 0.680079\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388126; batch adversarial loss: 0.526058\n",
      "epoch 71; iter: 0; batch classifier loss: 0.362475; batch adversarial loss: 0.507175\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410675; batch adversarial loss: 0.515882\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403818; batch adversarial loss: 0.481941\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444312; batch adversarial loss: 0.498130\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398924; batch adversarial loss: 0.599201\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380072; batch adversarial loss: 0.564891\n",
      "epoch 77; iter: 0; batch classifier loss: 0.453953; batch adversarial loss: 0.507091\n",
      "epoch 78; iter: 0; batch classifier loss: 0.384713; batch adversarial loss: 0.609701\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430886; batch adversarial loss: 0.581958\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455240; batch adversarial loss: 0.472604\n",
      "epoch 81; iter: 0; batch classifier loss: 0.354335; batch adversarial loss: 0.534733\n",
      "epoch 82; iter: 0; batch classifier loss: 0.511859; batch adversarial loss: 0.516785\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386230; batch adversarial loss: 0.573858\n",
      "epoch 84; iter: 0; batch classifier loss: 0.338708; batch adversarial loss: 0.481537\n",
      "epoch 85; iter: 0; batch classifier loss: 0.440040; batch adversarial loss: 0.573375\n",
      "epoch 86; iter: 0; batch classifier loss: 0.442406; batch adversarial loss: 0.542745\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410698; batch adversarial loss: 0.592249\n",
      "epoch 88; iter: 0; batch classifier loss: 0.443320; batch adversarial loss: 0.581326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366243; batch adversarial loss: 0.467045\n",
      "epoch 90; iter: 0; batch classifier loss: 0.276910; batch adversarial loss: 0.611850\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349791; batch adversarial loss: 0.534392\n",
      "epoch 92; iter: 0; batch classifier loss: 0.342359; batch adversarial loss: 0.596385\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357168; batch adversarial loss: 0.525169\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435951; batch adversarial loss: 0.461918\n",
      "epoch 95; iter: 0; batch classifier loss: 0.465257; batch adversarial loss: 0.552593\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384519; batch adversarial loss: 0.553347\n",
      "epoch 97; iter: 0; batch classifier loss: 0.326751; batch adversarial loss: 0.610374\n",
      "epoch 98; iter: 0; batch classifier loss: 0.335743; batch adversarial loss: 0.518765\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403809; batch adversarial loss: 0.497159\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367937; batch adversarial loss: 0.598694\n",
      "epoch 101; iter: 0; batch classifier loss: 0.456991; batch adversarial loss: 0.580524\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345899; batch adversarial loss: 0.535290\n",
      "epoch 103; iter: 0; batch classifier loss: 0.423462; batch adversarial loss: 0.454219\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413386; batch adversarial loss: 0.527330\n",
      "epoch 105; iter: 0; batch classifier loss: 0.328782; batch adversarial loss: 0.525586\n",
      "epoch 106; iter: 0; batch classifier loss: 0.420926; batch adversarial loss: 0.551403\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388001; batch adversarial loss: 0.555243\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420631; batch adversarial loss: 0.536364\n",
      "epoch 109; iter: 0; batch classifier loss: 0.354071; batch adversarial loss: 0.553435\n",
      "epoch 110; iter: 0; batch classifier loss: 0.418567; batch adversarial loss: 0.541977\n",
      "epoch 111; iter: 0; batch classifier loss: 0.325090; batch adversarial loss: 0.511167\n",
      "epoch 112; iter: 0; batch classifier loss: 0.456397; batch adversarial loss: 0.488845\n",
      "epoch 113; iter: 0; batch classifier loss: 0.430854; batch adversarial loss: 0.535139\n",
      "epoch 114; iter: 0; batch classifier loss: 0.441756; batch adversarial loss: 0.544640\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336987; batch adversarial loss: 0.580243\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359181; batch adversarial loss: 0.451844\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358591; batch adversarial loss: 0.570732\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386783; batch adversarial loss: 0.535906\n",
      "epoch 119; iter: 0; batch classifier loss: 0.407048; batch adversarial loss: 0.591138\n",
      "epoch 120; iter: 0; batch classifier loss: 0.421167; batch adversarial loss: 0.499000\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341119; batch adversarial loss: 0.562254\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391903; batch adversarial loss: 0.518781\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399468; batch adversarial loss: 0.534133\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374232; batch adversarial loss: 0.517214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389197; batch adversarial loss: 0.534422\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362457; batch adversarial loss: 0.514897\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390926; batch adversarial loss: 0.562045\n",
      "epoch 128; iter: 0; batch classifier loss: 0.406957; batch adversarial loss: 0.574260\n",
      "epoch 129; iter: 0; batch classifier loss: 0.400291; batch adversarial loss: 0.582099\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346304; batch adversarial loss: 0.498149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.459056; batch adversarial loss: 0.534847\n",
      "epoch 132; iter: 0; batch classifier loss: 0.375157; batch adversarial loss: 0.535622\n",
      "epoch 133; iter: 0; batch classifier loss: 0.380007; batch adversarial loss: 0.505905\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367339; batch adversarial loss: 0.635154\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420262; batch adversarial loss: 0.528086\n",
      "epoch 136; iter: 0; batch classifier loss: 0.458751; batch adversarial loss: 0.572566\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377623; batch adversarial loss: 0.553739\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335377; batch adversarial loss: 0.479830\n",
      "epoch 139; iter: 0; batch classifier loss: 0.340674; batch adversarial loss: 0.498963\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349483; batch adversarial loss: 0.581346\n",
      "epoch 141; iter: 0; batch classifier loss: 0.407652; batch adversarial loss: 0.535965\n",
      "epoch 142; iter: 0; batch classifier loss: 0.413876; batch adversarial loss: 0.664654\n",
      "epoch 143; iter: 0; batch classifier loss: 0.418724; batch adversarial loss: 0.535311\n",
      "epoch 144; iter: 0; batch classifier loss: 0.460676; batch adversarial loss: 0.600063\n",
      "epoch 145; iter: 0; batch classifier loss: 0.315567; batch adversarial loss: 0.554718\n",
      "epoch 146; iter: 0; batch classifier loss: 0.417679; batch adversarial loss: 0.599497\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334989; batch adversarial loss: 0.507734\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356001; batch adversarial loss: 0.489204\n",
      "epoch 149; iter: 0; batch classifier loss: 0.310289; batch adversarial loss: 0.506375\n",
      "epoch 150; iter: 0; batch classifier loss: 0.327123; batch adversarial loss: 0.515068\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368651; batch adversarial loss: 0.534339\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336722; batch adversarial loss: 0.516405\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372669; batch adversarial loss: 0.554460\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382477; batch adversarial loss: 0.561015\n",
      "epoch 155; iter: 0; batch classifier loss: 0.442226; batch adversarial loss: 0.461461\n",
      "epoch 156; iter: 0; batch classifier loss: 0.411687; batch adversarial loss: 0.581027\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350375; batch adversarial loss: 0.507429\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392251; batch adversarial loss: 0.544559\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415207; batch adversarial loss: 0.507792\n",
      "epoch 160; iter: 0; batch classifier loss: 0.378507; batch adversarial loss: 0.562316\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347797; batch adversarial loss: 0.571867\n",
      "epoch 162; iter: 0; batch classifier loss: 0.448407; batch adversarial loss: 0.543552\n",
      "epoch 163; iter: 0; batch classifier loss: 0.407412; batch adversarial loss: 0.497960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350808; batch adversarial loss: 0.554187\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315205; batch adversarial loss: 0.601268\n",
      "epoch 166; iter: 0; batch classifier loss: 0.410553; batch adversarial loss: 0.490257\n",
      "epoch 167; iter: 0; batch classifier loss: 0.298908; batch adversarial loss: 0.599568\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338369; batch adversarial loss: 0.618768\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344359; batch adversarial loss: 0.498142\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322579; batch adversarial loss: 0.590205\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420067; batch adversarial loss: 0.525158\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318429; batch adversarial loss: 0.479587\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337600; batch adversarial loss: 0.554096\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350245; batch adversarial loss: 0.627903\n",
      "epoch 175; iter: 0; batch classifier loss: 0.358247; batch adversarial loss: 0.554120\n",
      "epoch 176; iter: 0; batch classifier loss: 0.331127; batch adversarial loss: 0.507190\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369006; batch adversarial loss: 0.536246\n",
      "epoch 178; iter: 0; batch classifier loss: 0.397585; batch adversarial loss: 0.553179\n",
      "epoch 179; iter: 0; batch classifier loss: 0.371614; batch adversarial loss: 0.543306\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376702; batch adversarial loss: 0.618610\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370681; batch adversarial loss: 0.499443\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368784; batch adversarial loss: 0.497513\n",
      "epoch 183; iter: 0; batch classifier loss: 0.301955; batch adversarial loss: 0.572426\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397945; batch adversarial loss: 0.526415\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356689; batch adversarial loss: 0.516868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383431; batch adversarial loss: 0.487281\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351784; batch adversarial loss: 0.516472\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358608; batch adversarial loss: 0.507948\n",
      "epoch 189; iter: 0; batch classifier loss: 0.410071; batch adversarial loss: 0.517042\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384588; batch adversarial loss: 0.479059\n",
      "epoch 191; iter: 0; batch classifier loss: 0.312664; batch adversarial loss: 0.545595\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356136; batch adversarial loss: 0.497683\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361623; batch adversarial loss: 0.543047\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384013; batch adversarial loss: 0.525696\n",
      "epoch 195; iter: 0; batch classifier loss: 0.412105; batch adversarial loss: 0.563170\n",
      "epoch 196; iter: 0; batch classifier loss: 0.407236; batch adversarial loss: 0.545416\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370075; batch adversarial loss: 0.618132\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403731; batch adversarial loss: 0.515847\n",
      "epoch 199; iter: 0; batch classifier loss: 0.415898; batch adversarial loss: 0.600111\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741085; batch adversarial loss: 0.633005\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591384; batch adversarial loss: 0.647924\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551574; batch adversarial loss: 0.662196\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563255; batch adversarial loss: 0.622970\n",
      "epoch 4; iter: 0; batch classifier loss: 0.476448; batch adversarial loss: 0.606852\n",
      "epoch 5; iter: 0; batch classifier loss: 0.506527; batch adversarial loss: 0.607450\n",
      "epoch 6; iter: 0; batch classifier loss: 0.471190; batch adversarial loss: 0.615835\n",
      "epoch 7; iter: 0; batch classifier loss: 0.610823; batch adversarial loss: 0.603779\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478567; batch adversarial loss: 0.521958\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535704; batch adversarial loss: 0.581460\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531845; batch adversarial loss: 0.583416\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531963; batch adversarial loss: 0.550668\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554596; batch adversarial loss: 0.600112\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514470; batch adversarial loss: 0.552712\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506989; batch adversarial loss: 0.588684\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542759; batch adversarial loss: 0.611020\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472077; batch adversarial loss: 0.523832\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532478; batch adversarial loss: 0.599220\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543142; batch adversarial loss: 0.548662\n",
      "epoch 19; iter: 0; batch classifier loss: 0.529985; batch adversarial loss: 0.586431\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510446; batch adversarial loss: 0.546688\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498499; batch adversarial loss: 0.571673\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452239; batch adversarial loss: 0.521372\n",
      "epoch 23; iter: 0; batch classifier loss: 0.548995; batch adversarial loss: 0.526955\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526803; batch adversarial loss: 0.596060\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443659; batch adversarial loss: 0.518508\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512184; batch adversarial loss: 0.689319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.460618; batch adversarial loss: 0.505306\n",
      "epoch 28; iter: 0; batch classifier loss: 0.443423; batch adversarial loss: 0.526073\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508232; batch adversarial loss: 0.518219\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453816; batch adversarial loss: 0.579217\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441977; batch adversarial loss: 0.579414\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438161; batch adversarial loss: 0.524111\n",
      "epoch 33; iter: 0; batch classifier loss: 0.508478; batch adversarial loss: 0.596340\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458869; batch adversarial loss: 0.614499\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427500; batch adversarial loss: 0.477309\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460866; batch adversarial loss: 0.590891\n",
      "epoch 37; iter: 0; batch classifier loss: 0.508590; batch adversarial loss: 0.487483\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422128; batch adversarial loss: 0.561778\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452796; batch adversarial loss: 0.605799\n",
      "epoch 40; iter: 0; batch classifier loss: 0.377349; batch adversarial loss: 0.573602\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437715; batch adversarial loss: 0.553207\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466197; batch adversarial loss: 0.589016\n",
      "epoch 43; iter: 0; batch classifier loss: 0.487020; batch adversarial loss: 0.632205\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409467; batch adversarial loss: 0.492890\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433425; batch adversarial loss: 0.595844\n",
      "epoch 46; iter: 0; batch classifier loss: 0.504810; batch adversarial loss: 0.466266\n",
      "epoch 47; iter: 0; batch classifier loss: 0.507576; batch adversarial loss: 0.641799\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429077; batch adversarial loss: 0.604114\n",
      "epoch 49; iter: 0; batch classifier loss: 0.505442; batch adversarial loss: 0.562074\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415068; batch adversarial loss: 0.426802\n",
      "epoch 51; iter: 0; batch classifier loss: 0.551350; batch adversarial loss: 0.519161\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461653; batch adversarial loss: 0.543700\n",
      "epoch 53; iter: 0; batch classifier loss: 0.469270; batch adversarial loss: 0.556269\n",
      "epoch 54; iter: 0; batch classifier loss: 0.486601; batch adversarial loss: 0.589645\n",
      "epoch 55; iter: 0; batch classifier loss: 0.484665; batch adversarial loss: 0.504565\n",
      "epoch 56; iter: 0; batch classifier loss: 0.508477; batch adversarial loss: 0.604091\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427489; batch adversarial loss: 0.553494\n",
      "epoch 58; iter: 0; batch classifier loss: 0.371448; batch adversarial loss: 0.591570\n",
      "epoch 59; iter: 0; batch classifier loss: 0.484596; batch adversarial loss: 0.569602\n",
      "epoch 60; iter: 0; batch classifier loss: 0.469989; batch adversarial loss: 0.432750\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407897; batch adversarial loss: 0.562996\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379337; batch adversarial loss: 0.518263\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422420; batch adversarial loss: 0.547481\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424756; batch adversarial loss: 0.487287\n",
      "epoch 65; iter: 0; batch classifier loss: 0.364789; batch adversarial loss: 0.520611\n",
      "epoch 66; iter: 0; batch classifier loss: 0.440458; batch adversarial loss: 0.552393\n",
      "epoch 67; iter: 0; batch classifier loss: 0.432628; batch adversarial loss: 0.522143\n",
      "epoch 68; iter: 0; batch classifier loss: 0.357185; batch adversarial loss: 0.499299\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439495; batch adversarial loss: 0.480016\n",
      "epoch 70; iter: 0; batch classifier loss: 0.466716; batch adversarial loss: 0.566848\n",
      "epoch 71; iter: 0; batch classifier loss: 0.538567; batch adversarial loss: 0.525222\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434045; batch adversarial loss: 0.631491\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442970; batch adversarial loss: 0.483952\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382149; batch adversarial loss: 0.487825\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373240; batch adversarial loss: 0.638977\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459435; batch adversarial loss: 0.542577\n",
      "epoch 77; iter: 0; batch classifier loss: 0.431731; batch adversarial loss: 0.602955\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377894; batch adversarial loss: 0.478937\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399324; batch adversarial loss: 0.521857\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365389; batch adversarial loss: 0.517350\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410929; batch adversarial loss: 0.543788\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410034; batch adversarial loss: 0.617249\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397891; batch adversarial loss: 0.515288\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395404; batch adversarial loss: 0.618690\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414967; batch adversarial loss: 0.598803\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419591; batch adversarial loss: 0.568597\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410324; batch adversarial loss: 0.573587\n",
      "epoch 88; iter: 0; batch classifier loss: 0.431168; batch adversarial loss: 0.481728\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355817; batch adversarial loss: 0.648182\n",
      "epoch 90; iter: 0; batch classifier loss: 0.259182; batch adversarial loss: 0.515755\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367185; batch adversarial loss: 0.503897\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374071; batch adversarial loss: 0.670758\n",
      "epoch 93; iter: 0; batch classifier loss: 0.313443; batch adversarial loss: 0.500942\n",
      "epoch 94; iter: 0; batch classifier loss: 0.451048; batch adversarial loss: 0.556492\n",
      "epoch 95; iter: 0; batch classifier loss: 0.316974; batch adversarial loss: 0.561590\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387819; batch adversarial loss: 0.608655\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361683; batch adversarial loss: 0.542882\n",
      "epoch 98; iter: 0; batch classifier loss: 0.449114; batch adversarial loss: 0.543475\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400769; batch adversarial loss: 0.519744\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389672; batch adversarial loss: 0.657304\n",
      "epoch 101; iter: 0; batch classifier loss: 0.510839; batch adversarial loss: 0.506205\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382816; batch adversarial loss: 0.555619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.392820; batch adversarial loss: 0.562170\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371586; batch adversarial loss: 0.613075\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347063; batch adversarial loss: 0.536453\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376687; batch adversarial loss: 0.572723\n",
      "epoch 107; iter: 0; batch classifier loss: 0.443941; batch adversarial loss: 0.561538\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369497; batch adversarial loss: 0.552214\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355722; batch adversarial loss: 0.515530\n",
      "epoch 110; iter: 0; batch classifier loss: 0.393930; batch adversarial loss: 0.518695\n",
      "epoch 111; iter: 0; batch classifier loss: 0.491350; batch adversarial loss: 0.525067\n",
      "epoch 112; iter: 0; batch classifier loss: 0.404952; batch adversarial loss: 0.536661\n",
      "epoch 113; iter: 0; batch classifier loss: 0.403656; batch adversarial loss: 0.469138\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344003; batch adversarial loss: 0.607645\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383903; batch adversarial loss: 0.583085\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339822; batch adversarial loss: 0.535849\n",
      "epoch 117; iter: 0; batch classifier loss: 0.317514; batch adversarial loss: 0.534932\n",
      "epoch 118; iter: 0; batch classifier loss: 0.448255; batch adversarial loss: 0.524785\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363394; batch adversarial loss: 0.549149\n",
      "epoch 120; iter: 0; batch classifier loss: 0.414211; batch adversarial loss: 0.643858\n",
      "epoch 121; iter: 0; batch classifier loss: 0.493371; batch adversarial loss: 0.588389\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351076; batch adversarial loss: 0.580601\n",
      "epoch 123; iter: 0; batch classifier loss: 0.447079; batch adversarial loss: 0.542988\n",
      "epoch 124; iter: 0; batch classifier loss: 0.428556; batch adversarial loss: 0.496304\n",
      "epoch 125; iter: 0; batch classifier loss: 0.405622; batch adversarial loss: 0.542428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.349624; batch adversarial loss: 0.527586\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391968; batch adversarial loss: 0.516706\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368089; batch adversarial loss: 0.554629\n",
      "epoch 129; iter: 0; batch classifier loss: 0.384125; batch adversarial loss: 0.621580\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346540; batch adversarial loss: 0.602896\n",
      "epoch 131; iter: 0; batch classifier loss: 0.563741; batch adversarial loss: 0.618768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388224; batch adversarial loss: 0.497704\n",
      "epoch 133; iter: 0; batch classifier loss: 0.465125; batch adversarial loss: 0.600578\n",
      "epoch 134; iter: 0; batch classifier loss: 0.256775; batch adversarial loss: 0.610100\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338792; batch adversarial loss: 0.569005\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410732; batch adversarial loss: 0.553527\n",
      "epoch 137; iter: 0; batch classifier loss: 0.416990; batch adversarial loss: 0.564525\n",
      "epoch 138; iter: 0; batch classifier loss: 0.372441; batch adversarial loss: 0.479456\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373348; batch adversarial loss: 0.523567\n",
      "epoch 140; iter: 0; batch classifier loss: 0.437807; batch adversarial loss: 0.527069\n",
      "epoch 141; iter: 0; batch classifier loss: 0.511975; batch adversarial loss: 0.478117\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397521; batch adversarial loss: 0.581486\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334052; batch adversarial loss: 0.536599\n",
      "epoch 144; iter: 0; batch classifier loss: 0.403847; batch adversarial loss: 0.589805\n",
      "epoch 145; iter: 0; batch classifier loss: 0.420232; batch adversarial loss: 0.517360\n",
      "epoch 146; iter: 0; batch classifier loss: 0.355607; batch adversarial loss: 0.577737\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374045; batch adversarial loss: 0.582814\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417527; batch adversarial loss: 0.527991\n",
      "epoch 149; iter: 0; batch classifier loss: 0.413278; batch adversarial loss: 0.520752\n",
      "epoch 150; iter: 0; batch classifier loss: 0.328104; batch adversarial loss: 0.580663\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432410; batch adversarial loss: 0.601580\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349573; batch adversarial loss: 0.515531\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374754; batch adversarial loss: 0.480676\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346822; batch adversarial loss: 0.543962\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376440; batch adversarial loss: 0.552631\n",
      "epoch 156; iter: 0; batch classifier loss: 0.250369; batch adversarial loss: 0.516325\n",
      "epoch 157; iter: 0; batch classifier loss: 0.348605; batch adversarial loss: 0.552763\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368655; batch adversarial loss: 0.580125\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290112; batch adversarial loss: 0.479199\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382155; batch adversarial loss: 0.471685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410118; batch adversarial loss: 0.552622\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412522; batch adversarial loss: 0.579194\n",
      "epoch 163; iter: 0; batch classifier loss: 0.441163; batch adversarial loss: 0.573563\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375640; batch adversarial loss: 0.478965\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318709; batch adversarial loss: 0.583977\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372848; batch adversarial loss: 0.583580\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359313; batch adversarial loss: 0.451693\n",
      "epoch 168; iter: 0; batch classifier loss: 0.412652; batch adversarial loss: 0.626898\n",
      "epoch 169; iter: 0; batch classifier loss: 0.310406; batch adversarial loss: 0.571141\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336996; batch adversarial loss: 0.524486\n",
      "epoch 171; iter: 0; batch classifier loss: 0.328616; batch adversarial loss: 0.498974\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374426; batch adversarial loss: 0.468567\n",
      "epoch 173; iter: 0; batch classifier loss: 0.433794; batch adversarial loss: 0.566896\n",
      "epoch 174; iter: 0; batch classifier loss: 0.333749; batch adversarial loss: 0.521707\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392014; batch adversarial loss: 0.571762\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332000; batch adversarial loss: 0.443449\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396397; batch adversarial loss: 0.656715\n",
      "epoch 178; iter: 0; batch classifier loss: 0.321166; batch adversarial loss: 0.543511\n",
      "epoch 179; iter: 0; batch classifier loss: 0.450849; batch adversarial loss: 0.491826\n",
      "epoch 180; iter: 0; batch classifier loss: 0.428372; batch adversarial loss: 0.627140\n",
      "epoch 181; iter: 0; batch classifier loss: 0.430762; batch adversarial loss: 0.526691\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342260; batch adversarial loss: 0.554860\n",
      "epoch 183; iter: 0; batch classifier loss: 0.304857; batch adversarial loss: 0.533900\n",
      "epoch 184; iter: 0; batch classifier loss: 0.314743; batch adversarial loss: 0.505542\n",
      "epoch 185; iter: 0; batch classifier loss: 0.479203; batch adversarial loss: 0.551736\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389041; batch adversarial loss: 0.542839\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336066; batch adversarial loss: 0.535606\n",
      "epoch 188; iter: 0; batch classifier loss: 0.354187; batch adversarial loss: 0.532896\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292084; batch adversarial loss: 0.526257\n",
      "epoch 190; iter: 0; batch classifier loss: 0.408868; batch adversarial loss: 0.535414\n",
      "epoch 191; iter: 0; batch classifier loss: 0.425985; batch adversarial loss: 0.614758\n",
      "epoch 192; iter: 0; batch classifier loss: 0.310209; batch adversarial loss: 0.497609\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343365; batch adversarial loss: 0.588445\n",
      "epoch 194; iter: 0; batch classifier loss: 0.428135; batch adversarial loss: 0.571689\n",
      "epoch 195; iter: 0; batch classifier loss: 0.415490; batch adversarial loss: 0.462293\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351466; batch adversarial loss: 0.441201\n",
      "epoch 197; iter: 0; batch classifier loss: 0.434425; batch adversarial loss: 0.564176\n",
      "epoch 198; iter: 0; batch classifier loss: 0.410833; batch adversarial loss: 0.619151\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388096; batch adversarial loss: 0.516373\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708483; batch adversarial loss: 0.567765\n",
      "epoch 1; iter: 0; batch classifier loss: 0.665185; batch adversarial loss: 0.619836\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591835; batch adversarial loss: 0.647722\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542863; batch adversarial loss: 0.633707\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584078; batch adversarial loss: 0.650831\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531756; batch adversarial loss: 0.614935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593549; batch adversarial loss: 0.634653\n",
      "epoch 7; iter: 0; batch classifier loss: 0.620027; batch adversarial loss: 0.716648\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541747; batch adversarial loss: 0.634848\n",
      "epoch 9; iter: 0; batch classifier loss: 0.642037; batch adversarial loss: 0.626408\n",
      "epoch 10; iter: 0; batch classifier loss: 0.619318; batch adversarial loss: 0.624732\n",
      "epoch 11; iter: 0; batch classifier loss: 0.500065; batch adversarial loss: 0.635993\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590004; batch adversarial loss: 0.581087\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573776; batch adversarial loss: 0.571344\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510212; batch adversarial loss: 0.578504\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468819; batch adversarial loss: 0.569511\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527665; batch adversarial loss: 0.505850\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486945; batch adversarial loss: 0.559304\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483685; batch adversarial loss: 0.566908\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476809; batch adversarial loss: 0.611001\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474523; batch adversarial loss: 0.483942\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538947; batch adversarial loss: 0.495428\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469349; batch adversarial loss: 0.529157\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474785; batch adversarial loss: 0.555131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.502636; batch adversarial loss: 0.548027\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516145; batch adversarial loss: 0.577816\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505273; batch adversarial loss: 0.485062\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440294; batch adversarial loss: 0.420678\n",
      "epoch 28; iter: 0; batch classifier loss: 0.476506; batch adversarial loss: 0.561985\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497190; batch adversarial loss: 0.583030\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453506; batch adversarial loss: 0.597118\n",
      "epoch 31; iter: 0; batch classifier loss: 0.386950; batch adversarial loss: 0.525615\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464467; batch adversarial loss: 0.535037\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442594; batch adversarial loss: 0.483921\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432436; batch adversarial loss: 0.552427\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499249; batch adversarial loss: 0.617416\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494465; batch adversarial loss: 0.525070\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429124; batch adversarial loss: 0.507334\n",
      "epoch 38; iter: 0; batch classifier loss: 0.477155; batch adversarial loss: 0.517002\n",
      "epoch 39; iter: 0; batch classifier loss: 0.408399; batch adversarial loss: 0.619221\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396510; batch adversarial loss: 0.599409\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410287; batch adversarial loss: 0.525952\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415458; batch adversarial loss: 0.488126\n",
      "epoch 43; iter: 0; batch classifier loss: 0.516052; batch adversarial loss: 0.469157\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444765; batch adversarial loss: 0.564096\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442369; batch adversarial loss: 0.459978\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451668; batch adversarial loss: 0.593122\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413352; batch adversarial loss: 0.572179\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491188; batch adversarial loss: 0.460558\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422281; batch adversarial loss: 0.497760\n",
      "epoch 50; iter: 0; batch classifier loss: 0.540041; batch adversarial loss: 0.655270\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471922; batch adversarial loss: 0.562352\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464736; batch adversarial loss: 0.601836\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430408; batch adversarial loss: 0.536114\n",
      "epoch 54; iter: 0; batch classifier loss: 0.534960; batch adversarial loss: 0.544702\n",
      "epoch 55; iter: 0; batch classifier loss: 0.456634; batch adversarial loss: 0.580662\n",
      "epoch 56; iter: 0; batch classifier loss: 0.508397; batch adversarial loss: 0.571720\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459851; batch adversarial loss: 0.442786\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441329; batch adversarial loss: 0.554060\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432242; batch adversarial loss: 0.516831\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410353; batch adversarial loss: 0.562945\n",
      "epoch 61; iter: 0; batch classifier loss: 0.378970; batch adversarial loss: 0.525314\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401562; batch adversarial loss: 0.460474\n",
      "epoch 63; iter: 0; batch classifier loss: 0.373860; batch adversarial loss: 0.498351\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413256; batch adversarial loss: 0.554035\n",
      "epoch 65; iter: 0; batch classifier loss: 0.488258; batch adversarial loss: 0.507138\n",
      "epoch 66; iter: 0; batch classifier loss: 0.489837; batch adversarial loss: 0.516856\n",
      "epoch 67; iter: 0; batch classifier loss: 0.370936; batch adversarial loss: 0.525220\n",
      "epoch 68; iter: 0; batch classifier loss: 0.462168; batch adversarial loss: 0.609400\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405833; batch adversarial loss: 0.506825\n",
      "epoch 70; iter: 0; batch classifier loss: 0.336848; batch adversarial loss: 0.562820\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405578; batch adversarial loss: 0.507118\n",
      "epoch 72; iter: 0; batch classifier loss: 0.345953; batch adversarial loss: 0.553501\n",
      "epoch 73; iter: 0; batch classifier loss: 0.458428; batch adversarial loss: 0.515729\n",
      "epoch 74; iter: 0; batch classifier loss: 0.273659; batch adversarial loss: 0.591307\n",
      "epoch 75; iter: 0; batch classifier loss: 0.475685; batch adversarial loss: 0.517123\n",
      "epoch 76; iter: 0; batch classifier loss: 0.426197; batch adversarial loss: 0.602094\n",
      "epoch 77; iter: 0; batch classifier loss: 0.344040; batch adversarial loss: 0.553307\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389322; batch adversarial loss: 0.543166\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375292; batch adversarial loss: 0.590997\n",
      "epoch 80; iter: 0; batch classifier loss: 0.511360; batch adversarial loss: 0.517183\n",
      "epoch 81; iter: 0; batch classifier loss: 0.454619; batch adversarial loss: 0.582031\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381585; batch adversarial loss: 0.553490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.452924; batch adversarial loss: 0.581526\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444227; batch adversarial loss: 0.517681\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409233; batch adversarial loss: 0.479618\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394655; batch adversarial loss: 0.544247\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404835; batch adversarial loss: 0.581928\n",
      "epoch 88; iter: 0; batch classifier loss: 0.398076; batch adversarial loss: 0.479039\n",
      "epoch 89; iter: 0; batch classifier loss: 0.440932; batch adversarial loss: 0.535229\n",
      "epoch 90; iter: 0; batch classifier loss: 0.372563; batch adversarial loss: 0.572511\n",
      "epoch 91; iter: 0; batch classifier loss: 0.435241; batch adversarial loss: 0.497933\n",
      "epoch 92; iter: 0; batch classifier loss: 0.380357; batch adversarial loss: 0.488335\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384991; batch adversarial loss: 0.517313\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426527; batch adversarial loss: 0.470029\n",
      "epoch 95; iter: 0; batch classifier loss: 0.354042; batch adversarial loss: 0.535664\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403593; batch adversarial loss: 0.536153\n",
      "epoch 97; iter: 0; batch classifier loss: 0.264398; batch adversarial loss: 0.601618\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385300; batch adversarial loss: 0.460349\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376195; batch adversarial loss: 0.544625\n",
      "epoch 100; iter: 0; batch classifier loss: 0.379918; batch adversarial loss: 0.561533\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391838; batch adversarial loss: 0.489251\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392727; batch adversarial loss: 0.553436\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412694; batch adversarial loss: 0.507383\n",
      "epoch 104; iter: 0; batch classifier loss: 0.317912; batch adversarial loss: 0.450796\n",
      "epoch 105; iter: 0; batch classifier loss: 0.428072; batch adversarial loss: 0.516556\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402015; batch adversarial loss: 0.470007\n",
      "epoch 107; iter: 0; batch classifier loss: 0.471854; batch adversarial loss: 0.516950\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363566; batch adversarial loss: 0.554392\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337566; batch adversarial loss: 0.516765\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344835; batch adversarial loss: 0.592220\n",
      "epoch 111; iter: 0; batch classifier loss: 0.424564; batch adversarial loss: 0.581379\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372131; batch adversarial loss: 0.517122\n",
      "epoch 113; iter: 0; batch classifier loss: 0.372915; batch adversarial loss: 0.563501\n",
      "epoch 114; iter: 0; batch classifier loss: 0.446427; batch adversarial loss: 0.535317\n",
      "epoch 115; iter: 0; batch classifier loss: 0.440066; batch adversarial loss: 0.498567\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355950; batch adversarial loss: 0.506705\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337170; batch adversarial loss: 0.544952\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356533; batch adversarial loss: 0.507063\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375034; batch adversarial loss: 0.535229\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383105; batch adversarial loss: 0.506952\n",
      "epoch 121; iter: 0; batch classifier loss: 0.359869; batch adversarial loss: 0.563695\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367176; batch adversarial loss: 0.479337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.412176; batch adversarial loss: 0.497445\n",
      "epoch 124; iter: 0; batch classifier loss: 0.468239; batch adversarial loss: 0.553376\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404499; batch adversarial loss: 0.536874\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368266; batch adversarial loss: 0.581767\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360657; batch adversarial loss: 0.507869\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348452; batch adversarial loss: 0.460622\n",
      "epoch 129; iter: 0; batch classifier loss: 0.353749; batch adversarial loss: 0.571858\n",
      "epoch 130; iter: 0; batch classifier loss: 0.305892; batch adversarial loss: 0.516107\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399113; batch adversarial loss: 0.544083\n",
      "epoch 132; iter: 0; batch classifier loss: 0.417214; batch adversarial loss: 0.580347\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386379; batch adversarial loss: 0.554380\n",
      "epoch 134; iter: 0; batch classifier loss: 0.426869; batch adversarial loss: 0.543594\n",
      "epoch 135; iter: 0; batch classifier loss: 0.412246; batch adversarial loss: 0.421599\n",
      "epoch 136; iter: 0; batch classifier loss: 0.306511; batch adversarial loss: 0.506764\n",
      "epoch 137; iter: 0; batch classifier loss: 0.313986; batch adversarial loss: 0.525218\n",
      "epoch 138; iter: 0; batch classifier loss: 0.385644; batch adversarial loss: 0.525458\n",
      "epoch 139; iter: 0; batch classifier loss: 0.442831; batch adversarial loss: 0.526887\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377822; batch adversarial loss: 0.499475\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371122; batch adversarial loss: 0.480257\n",
      "epoch 142; iter: 0; batch classifier loss: 0.419805; batch adversarial loss: 0.544067\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369577; batch adversarial loss: 0.571174\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409520; batch adversarial loss: 0.469327\n",
      "epoch 145; iter: 0; batch classifier loss: 0.296738; batch adversarial loss: 0.470391\n",
      "epoch 146; iter: 0; batch classifier loss: 0.428817; batch adversarial loss: 0.525615\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368761; batch adversarial loss: 0.646812\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395101; batch adversarial loss: 0.488679\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317112; batch adversarial loss: 0.526406\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354500; batch adversarial loss: 0.524600\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392939; batch adversarial loss: 0.545333\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360697; batch adversarial loss: 0.590245\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386153; batch adversarial loss: 0.516250\n",
      "epoch 154; iter: 0; batch classifier loss: 0.288769; batch adversarial loss: 0.515699\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377660; batch adversarial loss: 0.515626\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340359; batch adversarial loss: 0.553658\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376370; batch adversarial loss: 0.516487\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323157; batch adversarial loss: 0.536412\n",
      "epoch 159; iter: 0; batch classifier loss: 0.397854; batch adversarial loss: 0.563260\n",
      "epoch 160; iter: 0; batch classifier loss: 0.303907; batch adversarial loss: 0.515607\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374513; batch adversarial loss: 0.534437\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328309; batch adversarial loss: 0.526879\n",
      "epoch 163; iter: 0; batch classifier loss: 0.310145; batch adversarial loss: 0.526323\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340736; batch adversarial loss: 0.507556\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371942; batch adversarial loss: 0.572946\n",
      "epoch 166; iter: 0; batch classifier loss: 0.402302; batch adversarial loss: 0.554325\n",
      "epoch 167; iter: 0; batch classifier loss: 0.385728; batch adversarial loss: 0.610739\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322157; batch adversarial loss: 0.555149\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351857; batch adversarial loss: 0.525637\n",
      "epoch 170; iter: 0; batch classifier loss: 0.358662; batch adversarial loss: 0.571646\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349426; batch adversarial loss: 0.667030\n",
      "epoch 172; iter: 0; batch classifier loss: 0.356004; batch adversarial loss: 0.581462\n",
      "epoch 173; iter: 0; batch classifier loss: 0.327413; batch adversarial loss: 0.518515\n",
      "epoch 174; iter: 0; batch classifier loss: 0.431559; batch adversarial loss: 0.582553\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329816; batch adversarial loss: 0.534779\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354450; batch adversarial loss: 0.545317\n",
      "epoch 177; iter: 0; batch classifier loss: 0.311641; batch adversarial loss: 0.571718\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350202; batch adversarial loss: 0.518141\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394482; batch adversarial loss: 0.554582\n",
      "epoch 180; iter: 0; batch classifier loss: 0.299150; batch adversarial loss: 0.515946\n",
      "epoch 181; iter: 0; batch classifier loss: 0.351206; batch adversarial loss: 0.535564\n",
      "epoch 182; iter: 0; batch classifier loss: 0.331188; batch adversarial loss: 0.535322\n",
      "epoch 183; iter: 0; batch classifier loss: 0.329040; batch adversarial loss: 0.506819\n",
      "epoch 184; iter: 0; batch classifier loss: 0.276518; batch adversarial loss: 0.591272\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361218; batch adversarial loss: 0.544814\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392611; batch adversarial loss: 0.553799\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364064; batch adversarial loss: 0.526523\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311917; batch adversarial loss: 0.572047\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352390; batch adversarial loss: 0.516477\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342940; batch adversarial loss: 0.571026\n",
      "epoch 191; iter: 0; batch classifier loss: 0.461074; batch adversarial loss: 0.553619\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344308; batch adversarial loss: 0.479359\n",
      "epoch 193; iter: 0; batch classifier loss: 0.387327; batch adversarial loss: 0.516900\n",
      "epoch 194; iter: 0; batch classifier loss: 0.378356; batch adversarial loss: 0.545024\n",
      "epoch 195; iter: 0; batch classifier loss: 0.414713; batch adversarial loss: 0.460202\n",
      "epoch 196; iter: 0; batch classifier loss: 0.325296; batch adversarial loss: 0.507013\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368299; batch adversarial loss: 0.506482\n",
      "epoch 198; iter: 0; batch classifier loss: 0.436558; batch adversarial loss: 0.528261\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355241; batch adversarial loss: 0.607543\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663944; batch adversarial loss: 0.936876\n",
      "epoch 1; iter: 0; batch classifier loss: 0.905313; batch adversarial loss: 1.476395\n",
      "epoch 2; iter: 0; batch classifier loss: 1.120108; batch adversarial loss: 1.449566\n",
      "epoch 3; iter: 0; batch classifier loss: 1.072906; batch adversarial loss: 1.311737\n",
      "epoch 4; iter: 0; batch classifier loss: 1.186576; batch adversarial loss: 1.249881\n",
      "epoch 5; iter: 0; batch classifier loss: 1.111201; batch adversarial loss: 1.121887\n",
      "epoch 6; iter: 0; batch classifier loss: 1.362984; batch adversarial loss: 1.026466\n",
      "epoch 7; iter: 0; batch classifier loss: 1.210824; batch adversarial loss: 0.948372\n",
      "epoch 8; iter: 0; batch classifier loss: 1.204377; batch adversarial loss: 0.863850\n",
      "epoch 9; iter: 0; batch classifier loss: 1.175330; batch adversarial loss: 0.799527\n",
      "epoch 10; iter: 0; batch classifier loss: 0.985034; batch adversarial loss: 0.782154\n",
      "epoch 11; iter: 0; batch classifier loss: 1.080071; batch adversarial loss: 0.699419\n",
      "epoch 12; iter: 0; batch classifier loss: 0.926029; batch adversarial loss: 0.640125\n",
      "epoch 13; iter: 0; batch classifier loss: 0.817978; batch adversarial loss: 0.600353\n",
      "epoch 14; iter: 0; batch classifier loss: 0.714632; batch adversarial loss: 0.591025\n",
      "epoch 15; iter: 0; batch classifier loss: 0.611499; batch adversarial loss: 0.558861\n",
      "epoch 16; iter: 0; batch classifier loss: 0.566185; batch adversarial loss: 0.590074\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541060; batch adversarial loss: 0.554120\n",
      "epoch 18; iter: 0; batch classifier loss: 0.438535; batch adversarial loss: 0.552005\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518364; batch adversarial loss: 0.540801\n",
      "epoch 20; iter: 0; batch classifier loss: 0.549566; batch adversarial loss: 0.625903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.554769; batch adversarial loss: 0.540151\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522192; batch adversarial loss: 0.609060\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518297; batch adversarial loss: 0.517849\n",
      "epoch 24; iter: 0; batch classifier loss: 0.525879; batch adversarial loss: 0.558062\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452384; batch adversarial loss: 0.625019\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413459; batch adversarial loss: 0.571636\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457515; batch adversarial loss: 0.489093\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523923; batch adversarial loss: 0.602809\n",
      "epoch 29; iter: 0; batch classifier loss: 0.554056; batch adversarial loss: 0.533016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.544650; batch adversarial loss: 0.540445\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469630; batch adversarial loss: 0.507503\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494377; batch adversarial loss: 0.554991\n",
      "epoch 33; iter: 0; batch classifier loss: 0.531502; batch adversarial loss: 0.513002\n",
      "epoch 34; iter: 0; batch classifier loss: 0.516026; batch adversarial loss: 0.661732\n",
      "epoch 35; iter: 0; batch classifier loss: 0.480430; batch adversarial loss: 0.570848\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440777; batch adversarial loss: 0.585886\n",
      "epoch 37; iter: 0; batch classifier loss: 0.490413; batch adversarial loss: 0.475526\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473382; batch adversarial loss: 0.613522\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430512; batch adversarial loss: 0.543675\n",
      "epoch 40; iter: 0; batch classifier loss: 0.438875; batch adversarial loss: 0.542956\n",
      "epoch 41; iter: 0; batch classifier loss: 0.533863; batch adversarial loss: 0.550358\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418570; batch adversarial loss: 0.562278\n",
      "epoch 43; iter: 0; batch classifier loss: 0.531362; batch adversarial loss: 0.603390\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398268; batch adversarial loss: 0.541808\n",
      "epoch 45; iter: 0; batch classifier loss: 0.402615; batch adversarial loss: 0.576266\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408691; batch adversarial loss: 0.543488\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433689; batch adversarial loss: 0.522115\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509427; batch adversarial loss: 0.534192\n",
      "epoch 49; iter: 0; batch classifier loss: 0.493151; batch adversarial loss: 0.557747\n",
      "epoch 50; iter: 0; batch classifier loss: 0.474816; batch adversarial loss: 0.522613\n",
      "epoch 51; iter: 0; batch classifier loss: 0.365203; batch adversarial loss: 0.539883\n",
      "epoch 52; iter: 0; batch classifier loss: 0.453741; batch adversarial loss: 0.470220\n",
      "epoch 53; iter: 0; batch classifier loss: 0.373292; batch adversarial loss: 0.543317\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451582; batch adversarial loss: 0.576347\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450977; batch adversarial loss: 0.450896\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399412; batch adversarial loss: 0.649804\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414322; batch adversarial loss: 0.541928\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403156; batch adversarial loss: 0.532344\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433773; batch adversarial loss: 0.516071\n",
      "epoch 60; iter: 0; batch classifier loss: 0.466013; batch adversarial loss: 0.554748\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430842; batch adversarial loss: 0.579392\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450980; batch adversarial loss: 0.475222\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436230; batch adversarial loss: 0.548956\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403435; batch adversarial loss: 0.571430\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413734; batch adversarial loss: 0.519520\n",
      "epoch 66; iter: 0; batch classifier loss: 0.450444; batch adversarial loss: 0.635262\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384047; batch adversarial loss: 0.555270\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392601; batch adversarial loss: 0.553549\n",
      "epoch 69; iter: 0; batch classifier loss: 0.385605; batch adversarial loss: 0.617377\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403550; batch adversarial loss: 0.525306\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417238; batch adversarial loss: 0.625914\n",
      "epoch 72; iter: 0; batch classifier loss: 0.338856; batch adversarial loss: 0.590626\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401989; batch adversarial loss: 0.463577\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408507; batch adversarial loss: 0.562405\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429381; batch adversarial loss: 0.589628\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421276; batch adversarial loss: 0.526423\n",
      "epoch 77; iter: 0; batch classifier loss: 0.348303; batch adversarial loss: 0.527298\n",
      "epoch 78; iter: 0; batch classifier loss: 0.481957; batch adversarial loss: 0.535985\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439093; batch adversarial loss: 0.454868\n",
      "epoch 80; iter: 0; batch classifier loss: 0.350971; batch adversarial loss: 0.518946\n",
      "epoch 81; iter: 0; batch classifier loss: 0.448574; batch adversarial loss: 0.518171\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393409; batch adversarial loss: 0.563149\n",
      "epoch 83; iter: 0; batch classifier loss: 0.342143; batch adversarial loss: 0.499891\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412233; batch adversarial loss: 0.625423\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367795; batch adversarial loss: 0.688570\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413443; batch adversarial loss: 0.508163\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433841; batch adversarial loss: 0.553629\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340345; batch adversarial loss: 0.535284\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371797; batch adversarial loss: 0.626532\n",
      "epoch 90; iter: 0; batch classifier loss: 0.354248; batch adversarial loss: 0.553695\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363794; batch adversarial loss: 0.535578\n",
      "epoch 92; iter: 0; batch classifier loss: 0.313517; batch adversarial loss: 0.618415\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375166; batch adversarial loss: 0.599199\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356694; batch adversarial loss: 0.508280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.341690; batch adversarial loss: 0.544055\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430915; batch adversarial loss: 0.553943\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386888; batch adversarial loss: 0.554544\n",
      "epoch 98; iter: 0; batch classifier loss: 0.407805; batch adversarial loss: 0.581083\n",
      "epoch 99; iter: 0; batch classifier loss: 0.448101; batch adversarial loss: 0.507810\n",
      "epoch 100; iter: 0; batch classifier loss: 0.344855; batch adversarial loss: 0.534929\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376673; batch adversarial loss: 0.572208\n",
      "epoch 102; iter: 0; batch classifier loss: 0.311186; batch adversarial loss: 0.544702\n",
      "epoch 103; iter: 0; batch classifier loss: 0.456038; batch adversarial loss: 0.498552\n",
      "epoch 104; iter: 0; batch classifier loss: 0.306059; batch adversarial loss: 0.562933\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368676; batch adversarial loss: 0.535328\n",
      "epoch 106; iter: 0; batch classifier loss: 0.416188; batch adversarial loss: 0.553819\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353105; batch adversarial loss: 0.490417\n",
      "epoch 108; iter: 0; batch classifier loss: 0.324883; batch adversarial loss: 0.562877\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367930; batch adversarial loss: 0.471434\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343186; batch adversarial loss: 0.480053\n",
      "epoch 111; iter: 0; batch classifier loss: 0.292669; batch adversarial loss: 0.489191\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365158; batch adversarial loss: 0.498939\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333492; batch adversarial loss: 0.607949\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329711; batch adversarial loss: 0.489621\n",
      "epoch 115; iter: 0; batch classifier loss: 0.304634; batch adversarial loss: 0.535506\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394181; batch adversarial loss: 0.590112\n",
      "epoch 117; iter: 0; batch classifier loss: 0.446343; batch adversarial loss: 0.535939\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347333; batch adversarial loss: 0.526369\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370254; batch adversarial loss: 0.508393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.325297; batch adversarial loss: 0.535548\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390145; batch adversarial loss: 0.517374\n",
      "epoch 122; iter: 0; batch classifier loss: 0.316415; batch adversarial loss: 0.571609\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366931; batch adversarial loss: 0.489071\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326397; batch adversarial loss: 0.636321\n",
      "epoch 125; iter: 0; batch classifier loss: 0.318773; batch adversarial loss: 0.553950\n",
      "epoch 126; iter: 0; batch classifier loss: 0.343374; batch adversarial loss: 0.526391\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389250; batch adversarial loss: 0.535572\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402951; batch adversarial loss: 0.553562\n",
      "epoch 129; iter: 0; batch classifier loss: 0.400679; batch adversarial loss: 0.489305\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366503; batch adversarial loss: 0.553678\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368220; batch adversarial loss: 0.553813\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421469; batch adversarial loss: 0.590534\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385670; batch adversarial loss: 0.534686\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400208; batch adversarial loss: 0.499056\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362598; batch adversarial loss: 0.515951\n",
      "epoch 136; iter: 0; batch classifier loss: 0.398587; batch adversarial loss: 0.635336\n",
      "epoch 137; iter: 0; batch classifier loss: 0.404358; batch adversarial loss: 0.536715\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403711; batch adversarial loss: 0.432140\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381037; batch adversarial loss: 0.620580\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356159; batch adversarial loss: 0.448120\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323383; batch adversarial loss: 0.569776\n",
      "epoch 142; iter: 0; batch classifier loss: 0.337460; batch adversarial loss: 0.567498\n",
      "epoch 143; iter: 0; batch classifier loss: 0.310580; batch adversarial loss: 0.560370\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357042; batch adversarial loss: 0.577683\n",
      "epoch 145; iter: 0; batch classifier loss: 0.325933; batch adversarial loss: 0.606311\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379393; batch adversarial loss: 0.577790\n",
      "epoch 147; iter: 0; batch classifier loss: 0.302811; batch adversarial loss: 0.530993\n",
      "epoch 148; iter: 0; batch classifier loss: 0.333836; batch adversarial loss: 0.542930\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373766; batch adversarial loss: 0.657465\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330664; batch adversarial loss: 0.543135\n",
      "epoch 151; iter: 0; batch classifier loss: 0.297442; batch adversarial loss: 0.563233\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377577; batch adversarial loss: 0.664010\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385735; batch adversarial loss: 0.451563\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397587; batch adversarial loss: 0.489928\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366253; batch adversarial loss: 0.491279\n",
      "epoch 156; iter: 0; batch classifier loss: 0.338691; batch adversarial loss: 0.516843\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366532; batch adversarial loss: 0.451686\n",
      "epoch 158; iter: 0; batch classifier loss: 0.312337; batch adversarial loss: 0.543033\n",
      "epoch 159; iter: 0; batch classifier loss: 0.287376; batch adversarial loss: 0.567278\n",
      "epoch 160; iter: 0; batch classifier loss: 0.258569; batch adversarial loss: 0.555236\n",
      "epoch 161; iter: 0; batch classifier loss: 0.300184; batch adversarial loss: 0.544137\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306615; batch adversarial loss: 0.524349\n",
      "epoch 163; iter: 0; batch classifier loss: 0.300866; batch adversarial loss: 0.527946\n",
      "epoch 164; iter: 0; batch classifier loss: 0.294659; batch adversarial loss: 0.561460\n",
      "epoch 165; iter: 0; batch classifier loss: 0.336043; batch adversarial loss: 0.553482\n",
      "epoch 166; iter: 0; batch classifier loss: 0.416086; batch adversarial loss: 0.557035\n",
      "epoch 167; iter: 0; batch classifier loss: 0.339454; batch adversarial loss: 0.527785\n",
      "epoch 168; iter: 0; batch classifier loss: 0.285160; batch adversarial loss: 0.512884\n",
      "epoch 169; iter: 0; batch classifier loss: 0.276623; batch adversarial loss: 0.559389\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337358; batch adversarial loss: 0.558586\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342470; batch adversarial loss: 0.508595\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345202; batch adversarial loss: 0.526297\n",
      "epoch 173; iter: 0; batch classifier loss: 0.282376; batch adversarial loss: 0.499825\n",
      "epoch 174; iter: 0; batch classifier loss: 0.278744; batch adversarial loss: 0.545568\n",
      "epoch 175; iter: 0; batch classifier loss: 0.300174; batch adversarial loss: 0.486446\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369211; batch adversarial loss: 0.539737\n",
      "epoch 177; iter: 0; batch classifier loss: 0.275615; batch adversarial loss: 0.631399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.319876; batch adversarial loss: 0.559690\n",
      "epoch 179; iter: 0; batch classifier loss: 0.319428; batch adversarial loss: 0.542832\n",
      "epoch 180; iter: 0; batch classifier loss: 0.270893; batch adversarial loss: 0.588406\n",
      "epoch 181; iter: 0; batch classifier loss: 0.398103; batch adversarial loss: 0.522114\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383499; batch adversarial loss: 0.611471\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367993; batch adversarial loss: 0.557462\n",
      "epoch 184; iter: 0; batch classifier loss: 0.390516; batch adversarial loss: 0.520643\n",
      "epoch 185; iter: 0; batch classifier loss: 0.382762; batch adversarial loss: 0.477434\n",
      "epoch 186; iter: 0; batch classifier loss: 0.292906; batch adversarial loss: 0.562232\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358209; batch adversarial loss: 0.571146\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324764; batch adversarial loss: 0.543260\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328569; batch adversarial loss: 0.661053\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365390; batch adversarial loss: 0.595427\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347460; batch adversarial loss: 0.503416\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401542; batch adversarial loss: 0.491077\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348725; batch adversarial loss: 0.637613\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342784; batch adversarial loss: 0.570777\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349488; batch adversarial loss: 0.426864\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321308; batch adversarial loss: 0.454682\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370530; batch adversarial loss: 0.555919\n",
      "epoch 198; iter: 0; batch classifier loss: 0.314756; batch adversarial loss: 0.523649\n",
      "epoch 199; iter: 0; batch classifier loss: 0.343720; batch adversarial loss: 0.585980\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686317; batch adversarial loss: 0.610235\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578393; batch adversarial loss: 0.659036\n",
      "epoch 2; iter: 0; batch classifier loss: 0.548042; batch adversarial loss: 0.638386\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555704; batch adversarial loss: 0.639597\n",
      "epoch 4; iter: 0; batch classifier loss: 0.530630; batch adversarial loss: 0.641374\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570604; batch adversarial loss: 0.686312\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548035; batch adversarial loss: 0.628785\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537409; batch adversarial loss: 0.568155\n",
      "epoch 8; iter: 0; batch classifier loss: 0.565184; batch adversarial loss: 0.610759\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562711; batch adversarial loss: 0.611959\n",
      "epoch 10; iter: 0; batch classifier loss: 0.583242; batch adversarial loss: 0.596377\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555579; batch adversarial loss: 0.585340\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489636; batch adversarial loss: 0.612728\n",
      "epoch 13; iter: 0; batch classifier loss: 0.459854; batch adversarial loss: 0.533318\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522753; batch adversarial loss: 0.581829\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516598; batch adversarial loss: 0.569913\n",
      "epoch 16; iter: 0; batch classifier loss: 0.624786; batch adversarial loss: 0.510278\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521878; batch adversarial loss: 0.533071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.562752; batch adversarial loss: 0.571699\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497400; batch adversarial loss: 0.601571\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512706; batch adversarial loss: 0.547504\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482558; batch adversarial loss: 0.581017\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496701; batch adversarial loss: 0.592822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472258; batch adversarial loss: 0.561336\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468456; batch adversarial loss: 0.545640\n",
      "epoch 25; iter: 0; batch classifier loss: 0.477329; batch adversarial loss: 0.610247\n",
      "epoch 26; iter: 0; batch classifier loss: 0.403280; batch adversarial loss: 0.554486\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466660; batch adversarial loss: 0.523659\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516855; batch adversarial loss: 0.554725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.539596; batch adversarial loss: 0.639040\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483267; batch adversarial loss: 0.571089\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454912; batch adversarial loss: 0.565475\n",
      "epoch 32; iter: 0; batch classifier loss: 0.381252; batch adversarial loss: 0.548111\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464924; batch adversarial loss: 0.526917\n",
      "epoch 34; iter: 0; batch classifier loss: 0.541938; batch adversarial loss: 0.525267\n",
      "epoch 35; iter: 0; batch classifier loss: 0.530324; batch adversarial loss: 0.584969\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468593; batch adversarial loss: 0.627080\n",
      "epoch 37; iter: 0; batch classifier loss: 0.515729; batch adversarial loss: 0.471033\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431129; batch adversarial loss: 0.568755\n",
      "epoch 39; iter: 0; batch classifier loss: 0.515002; batch adversarial loss: 0.577125\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464487; batch adversarial loss: 0.468163\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483926; batch adversarial loss: 0.531979\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471029; batch adversarial loss: 0.515551\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412299; batch adversarial loss: 0.462254\n",
      "epoch 44; iter: 0; batch classifier loss: 0.366345; batch adversarial loss: 0.585202\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440546; batch adversarial loss: 0.492598\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419124; batch adversarial loss: 0.481599\n",
      "epoch 47; iter: 0; batch classifier loss: 0.397417; batch adversarial loss: 0.520256\n",
      "epoch 48; iter: 0; batch classifier loss: 0.499119; batch adversarial loss: 0.534190\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476534; batch adversarial loss: 0.627809\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451503; batch adversarial loss: 0.450247\n",
      "epoch 51; iter: 0; batch classifier loss: 0.479885; batch adversarial loss: 0.484503\n",
      "epoch 52; iter: 0; batch classifier loss: 0.373365; batch adversarial loss: 0.553511\n",
      "epoch 53; iter: 0; batch classifier loss: 0.362062; batch adversarial loss: 0.460852\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453929; batch adversarial loss: 0.618191\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404881; batch adversarial loss: 0.536052\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443098; batch adversarial loss: 0.635233\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424231; batch adversarial loss: 0.472073\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421276; batch adversarial loss: 0.526240\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449173; batch adversarial loss: 0.472877\n",
      "epoch 60; iter: 0; batch classifier loss: 0.419517; batch adversarial loss: 0.600482\n",
      "epoch 61; iter: 0; batch classifier loss: 0.456313; batch adversarial loss: 0.588579\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400117; batch adversarial loss: 0.535724\n",
      "epoch 63; iter: 0; batch classifier loss: 0.356553; batch adversarial loss: 0.598537\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358646; batch adversarial loss: 0.551902\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412181; batch adversarial loss: 0.562075\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449688; batch adversarial loss: 0.552261\n",
      "epoch 67; iter: 0; batch classifier loss: 0.427193; batch adversarial loss: 0.591393\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418955; batch adversarial loss: 0.516039\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392825; batch adversarial loss: 0.527476\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451251; batch adversarial loss: 0.556563\n",
      "epoch 71; iter: 0; batch classifier loss: 0.379879; batch adversarial loss: 0.541590\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402860; batch adversarial loss: 0.599557\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392514; batch adversarial loss: 0.553372\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412938; batch adversarial loss: 0.543383\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422523; batch adversarial loss: 0.592660\n",
      "epoch 76; iter: 0; batch classifier loss: 0.497531; batch adversarial loss: 0.608754\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351475; batch adversarial loss: 0.556230\n",
      "epoch 78; iter: 0; batch classifier loss: 0.470278; batch adversarial loss: 0.517418\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387872; batch adversarial loss: 0.528819\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402030; batch adversarial loss: 0.532979\n",
      "epoch 81; iter: 0; batch classifier loss: 0.441227; batch adversarial loss: 0.541400\n",
      "epoch 82; iter: 0; batch classifier loss: 0.438367; batch adversarial loss: 0.572738\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423411; batch adversarial loss: 0.572840\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437391; batch adversarial loss: 0.589399\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361530; batch adversarial loss: 0.554618\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419966; batch adversarial loss: 0.552457\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416698; batch adversarial loss: 0.518623\n",
      "epoch 88; iter: 0; batch classifier loss: 0.444170; batch adversarial loss: 0.563331\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396480; batch adversarial loss: 0.601139\n",
      "epoch 90; iter: 0; batch classifier loss: 0.436752; batch adversarial loss: 0.499929\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410051; batch adversarial loss: 0.618057\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400110; batch adversarial loss: 0.510217\n",
      "epoch 93; iter: 0; batch classifier loss: 0.355651; batch adversarial loss: 0.607922\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365447; batch adversarial loss: 0.535488\n",
      "epoch 95; iter: 0; batch classifier loss: 0.350265; batch adversarial loss: 0.590963\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398208; batch adversarial loss: 0.608673\n",
      "epoch 97; iter: 0; batch classifier loss: 0.459922; batch adversarial loss: 0.562922\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439346; batch adversarial loss: 0.498943\n",
      "epoch 99; iter: 0; batch classifier loss: 0.444414; batch adversarial loss: 0.489307\n",
      "epoch 100; iter: 0; batch classifier loss: 0.469972; batch adversarial loss: 0.506612\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397165; batch adversarial loss: 0.635530\n",
      "epoch 102; iter: 0; batch classifier loss: 0.427613; batch adversarial loss: 0.526438\n",
      "epoch 103; iter: 0; batch classifier loss: 0.351458; batch adversarial loss: 0.488600\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399112; batch adversarial loss: 0.598968\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384204; batch adversarial loss: 0.481690\n",
      "epoch 106; iter: 0; batch classifier loss: 0.452854; batch adversarial loss: 0.509346\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371469; batch adversarial loss: 0.544682\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400839; batch adversarial loss: 0.515994\n",
      "epoch 109; iter: 0; batch classifier loss: 0.321745; batch adversarial loss: 0.480195\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353276; batch adversarial loss: 0.505992\n",
      "epoch 111; iter: 0; batch classifier loss: 0.397638; batch adversarial loss: 0.624549\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402266; batch adversarial loss: 0.589800\n",
      "epoch 113; iter: 0; batch classifier loss: 0.425492; batch adversarial loss: 0.581656\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340181; batch adversarial loss: 0.562960\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367084; batch adversarial loss: 0.507223\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377501; batch adversarial loss: 0.528396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.456809; batch adversarial loss: 0.526074\n",
      "epoch 118; iter: 0; batch classifier loss: 0.388265; batch adversarial loss: 0.517234\n",
      "epoch 119; iter: 0; batch classifier loss: 0.458934; batch adversarial loss: 0.525192\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378302; batch adversarial loss: 0.536181\n",
      "epoch 121; iter: 0; batch classifier loss: 0.416313; batch adversarial loss: 0.416737\n",
      "epoch 122; iter: 0; batch classifier loss: 0.450444; batch adversarial loss: 0.555661\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408640; batch adversarial loss: 0.571825\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405393; batch adversarial loss: 0.572151\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367969; batch adversarial loss: 0.542812\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373010; batch adversarial loss: 0.525759\n",
      "epoch 127; iter: 0; batch classifier loss: 0.411056; batch adversarial loss: 0.536504\n",
      "epoch 128; iter: 0; batch classifier loss: 0.429149; batch adversarial loss: 0.580669\n",
      "epoch 129; iter: 0; batch classifier loss: 0.371188; batch adversarial loss: 0.469738\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364014; batch adversarial loss: 0.534250\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400271; batch adversarial loss: 0.507519\n",
      "epoch 132; iter: 0; batch classifier loss: 0.410921; batch adversarial loss: 0.519669\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387545; batch adversarial loss: 0.555412\n",
      "epoch 134; iter: 0; batch classifier loss: 0.336884; batch adversarial loss: 0.451681\n",
      "epoch 135; iter: 0; batch classifier loss: 0.439919; batch adversarial loss: 0.571942\n",
      "epoch 136; iter: 0; batch classifier loss: 0.390644; batch adversarial loss: 0.536483\n",
      "epoch 137; iter: 0; batch classifier loss: 0.395325; batch adversarial loss: 0.525770\n",
      "epoch 138; iter: 0; batch classifier loss: 0.420432; batch adversarial loss: 0.498468\n",
      "epoch 139; iter: 0; batch classifier loss: 0.317244; batch adversarial loss: 0.507446\n",
      "epoch 140; iter: 0; batch classifier loss: 0.463048; batch adversarial loss: 0.608970\n",
      "epoch 141; iter: 0; batch classifier loss: 0.327605; batch adversarial loss: 0.481359\n",
      "epoch 142; iter: 0; batch classifier loss: 0.473965; batch adversarial loss: 0.463477\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334588; batch adversarial loss: 0.555275\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405666; batch adversarial loss: 0.583890\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403214; batch adversarial loss: 0.607863\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358706; batch adversarial loss: 0.519363\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344493; batch adversarial loss: 0.526280\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391927; batch adversarial loss: 0.554051\n",
      "epoch 149; iter: 0; batch classifier loss: 0.423168; batch adversarial loss: 0.543917\n",
      "epoch 150; iter: 0; batch classifier loss: 0.348865; batch adversarial loss: 0.509318\n",
      "epoch 151; iter: 0; batch classifier loss: 0.369485; batch adversarial loss: 0.489826\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377732; batch adversarial loss: 0.552449\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360099; batch adversarial loss: 0.588687\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344892; batch adversarial loss: 0.517482\n",
      "epoch 155; iter: 0; batch classifier loss: 0.335179; batch adversarial loss: 0.525250\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348244; batch adversarial loss: 0.571712\n",
      "epoch 157; iter: 0; batch classifier loss: 0.436692; batch adversarial loss: 0.515521\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355844; batch adversarial loss: 0.527948\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362446; batch adversarial loss: 0.573356\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363324; batch adversarial loss: 0.561339\n",
      "epoch 161; iter: 0; batch classifier loss: 0.426757; batch adversarial loss: 0.489874\n",
      "epoch 162; iter: 0; batch classifier loss: 0.417277; batch adversarial loss: 0.496544\n",
      "epoch 163; iter: 0; batch classifier loss: 0.439922; batch adversarial loss: 0.543532\n",
      "epoch 164; iter: 0; batch classifier loss: 0.383538; batch adversarial loss: 0.525575\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386157; batch adversarial loss: 0.607441\n",
      "epoch 166; iter: 0; batch classifier loss: 0.427450; batch adversarial loss: 0.518594\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390273; batch adversarial loss: 0.544479\n",
      "epoch 168; iter: 0; batch classifier loss: 0.438444; batch adversarial loss: 0.536182\n",
      "epoch 169; iter: 0; batch classifier loss: 0.364196; batch adversarial loss: 0.508144\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353807; batch adversarial loss: 0.564005\n",
      "epoch 171; iter: 0; batch classifier loss: 0.404374; batch adversarial loss: 0.588550\n",
      "epoch 172; iter: 0; batch classifier loss: 0.412381; batch adversarial loss: 0.543990\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355894; batch adversarial loss: 0.533747\n",
      "epoch 174; iter: 0; batch classifier loss: 0.320781; batch adversarial loss: 0.598448\n",
      "epoch 175; iter: 0; batch classifier loss: 0.454298; batch adversarial loss: 0.594115\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360754; batch adversarial loss: 0.462362\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356729; batch adversarial loss: 0.525874\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331798; batch adversarial loss: 0.526163\n",
      "epoch 179; iter: 0; batch classifier loss: 0.398274; batch adversarial loss: 0.527644\n",
      "epoch 180; iter: 0; batch classifier loss: 0.286107; batch adversarial loss: 0.543334\n",
      "epoch 181; iter: 0; batch classifier loss: 0.438297; batch adversarial loss: 0.499711\n",
      "epoch 182; iter: 0; batch classifier loss: 0.311633; batch adversarial loss: 0.574853\n",
      "epoch 183; iter: 0; batch classifier loss: 0.296849; batch adversarial loss: 0.517544\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309970; batch adversarial loss: 0.556396\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326136; batch adversarial loss: 0.461988\n",
      "epoch 186; iter: 0; batch classifier loss: 0.380266; batch adversarial loss: 0.552980\n",
      "epoch 187; iter: 0; batch classifier loss: 0.403706; batch adversarial loss: 0.524816\n",
      "epoch 188; iter: 0; batch classifier loss: 0.410504; batch adversarial loss: 0.589904\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361656; batch adversarial loss: 0.563543\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322624; batch adversarial loss: 0.654495\n",
      "epoch 191; iter: 0; batch classifier loss: 0.349485; batch adversarial loss: 0.581801\n",
      "epoch 192; iter: 0; batch classifier loss: 0.354584; batch adversarial loss: 0.489681\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313500; batch adversarial loss: 0.570475\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362862; batch adversarial loss: 0.616223\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349217; batch adversarial loss: 0.563064\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335812; batch adversarial loss: 0.507774\n",
      "epoch 197; iter: 0; batch classifier loss: 0.299496; batch adversarial loss: 0.553597\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387131; batch adversarial loss: 0.554868\n",
      "epoch 199; iter: 0; batch classifier loss: 0.317128; batch adversarial loss: 0.499979\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687712; batch adversarial loss: 0.786952\n",
      "epoch 1; iter: 0; batch classifier loss: 0.645690; batch adversarial loss: 0.750204\n",
      "epoch 2; iter: 0; batch classifier loss: 0.635703; batch adversarial loss: 0.699542\n",
      "epoch 3; iter: 0; batch classifier loss: 0.488020; batch adversarial loss: 0.697329\n",
      "epoch 4; iter: 0; batch classifier loss: 0.512349; batch adversarial loss: 0.657227\n",
      "epoch 5; iter: 0; batch classifier loss: 0.542159; batch adversarial loss: 0.654791\n",
      "epoch 6; iter: 0; batch classifier loss: 0.456484; batch adversarial loss: 0.625416\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458112; batch adversarial loss: 0.610487\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546182; batch adversarial loss: 0.596400\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529043; batch adversarial loss: 0.583292\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506840; batch adversarial loss: 0.545861\n",
      "epoch 11; iter: 0; batch classifier loss: 0.487900; batch adversarial loss: 0.557182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527364; batch adversarial loss: 0.530982\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491718; batch adversarial loss: 0.519116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.505690; batch adversarial loss: 0.638227\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537163; batch adversarial loss: 0.503884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489267; batch adversarial loss: 0.568373\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535007; batch adversarial loss: 0.617136\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523077; batch adversarial loss: 0.614515\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490220; batch adversarial loss: 0.573246\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468980; batch adversarial loss: 0.504139\n",
      "epoch 21; iter: 0; batch classifier loss: 0.472099; batch adversarial loss: 0.585992\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479686; batch adversarial loss: 0.605391\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538755; batch adversarial loss: 0.590578\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503649; batch adversarial loss: 0.550293\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446562; batch adversarial loss: 0.604961\n",
      "epoch 26; iter: 0; batch classifier loss: 0.417657; batch adversarial loss: 0.539167\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475725; batch adversarial loss: 0.530557\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454668; batch adversarial loss: 0.598355\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448666; batch adversarial loss: 0.488155\n",
      "epoch 30; iter: 0; batch classifier loss: 0.519780; batch adversarial loss: 0.584660\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472893; batch adversarial loss: 0.577308\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510635; batch adversarial loss: 0.619871\n",
      "epoch 33; iter: 0; batch classifier loss: 0.335185; batch adversarial loss: 0.513877\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456549; batch adversarial loss: 0.476830\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447259; batch adversarial loss: 0.527431\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494446; batch adversarial loss: 0.580370\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418370; batch adversarial loss: 0.615927\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432590; batch adversarial loss: 0.590732\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386503; batch adversarial loss: 0.481696\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416098; batch adversarial loss: 0.535671\n",
      "epoch 41; iter: 0; batch classifier loss: 0.406405; batch adversarial loss: 0.625530\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407708; batch adversarial loss: 0.571474\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375185; batch adversarial loss: 0.536053\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437197; batch adversarial loss: 0.535513\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461252; batch adversarial loss: 0.516843\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372333; batch adversarial loss: 0.553401\n",
      "epoch 47; iter: 0; batch classifier loss: 0.339005; batch adversarial loss: 0.488818\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404037; batch adversarial loss: 0.488993\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390818; batch adversarial loss: 0.506590\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374521; batch adversarial loss: 0.535420\n",
      "epoch 51; iter: 0; batch classifier loss: 0.489687; batch adversarial loss: 0.535683\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386686; batch adversarial loss: 0.525125\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414838; batch adversarial loss: 0.602062\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419641; batch adversarial loss: 0.544214\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476714; batch adversarial loss: 0.554926\n",
      "epoch 56; iter: 0; batch classifier loss: 0.337417; batch adversarial loss: 0.573295\n",
      "epoch 57; iter: 0; batch classifier loss: 0.364741; batch adversarial loss: 0.611385\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466531; batch adversarial loss: 0.525505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.390781; batch adversarial loss: 0.507642\n",
      "epoch 60; iter: 0; batch classifier loss: 0.355864; batch adversarial loss: 0.648526\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408517; batch adversarial loss: 0.506487\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401414; batch adversarial loss: 0.563458\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388042; batch adversarial loss: 0.486985\n",
      "epoch 64; iter: 0; batch classifier loss: 0.346425; batch adversarial loss: 0.563749\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412876; batch adversarial loss: 0.563920\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385623; batch adversarial loss: 0.516762\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414731; batch adversarial loss: 0.647911\n",
      "epoch 68; iter: 0; batch classifier loss: 0.471175; batch adversarial loss: 0.515849\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427512; batch adversarial loss: 0.592080\n",
      "epoch 70; iter: 0; batch classifier loss: 0.458420; batch adversarial loss: 0.573058\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358017; batch adversarial loss: 0.535071\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442895; batch adversarial loss: 0.544538\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369232; batch adversarial loss: 0.516756\n",
      "epoch 74; iter: 0; batch classifier loss: 0.468334; batch adversarial loss: 0.582386\n",
      "epoch 75; iter: 0; batch classifier loss: 0.450896; batch adversarial loss: 0.544705\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377572; batch adversarial loss: 0.545681\n",
      "epoch 77; iter: 0; batch classifier loss: 0.450358; batch adversarial loss: 0.582898\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437274; batch adversarial loss: 0.525000\n",
      "epoch 79; iter: 0; batch classifier loss: 0.467377; batch adversarial loss: 0.487360\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422937; batch adversarial loss: 0.601672\n",
      "epoch 81; iter: 0; batch classifier loss: 0.464201; batch adversarial loss: 0.506659\n",
      "epoch 82; iter: 0; batch classifier loss: 0.292640; batch adversarial loss: 0.534849\n",
      "epoch 83; iter: 0; batch classifier loss: 0.432418; batch adversarial loss: 0.525805\n",
      "epoch 84; iter: 0; batch classifier loss: 0.274199; batch adversarial loss: 0.506763\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376202; batch adversarial loss: 0.534897\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344548; batch adversarial loss: 0.525698\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387780; batch adversarial loss: 0.488274\n",
      "epoch 88; iter: 0; batch classifier loss: 0.295363; batch adversarial loss: 0.431393\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422909; batch adversarial loss: 0.497191\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384392; batch adversarial loss: 0.525690\n",
      "epoch 91; iter: 0; batch classifier loss: 0.338166; batch adversarial loss: 0.544450\n",
      "epoch 92; iter: 0; batch classifier loss: 0.433293; batch adversarial loss: 0.544671\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368441; batch adversarial loss: 0.439620\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390540; batch adversarial loss: 0.496752\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425608; batch adversarial loss: 0.468274\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443543; batch adversarial loss: 0.430305\n",
      "epoch 97; iter: 0; batch classifier loss: 0.329534; batch adversarial loss: 0.506479\n",
      "epoch 98; iter: 0; batch classifier loss: 0.344337; batch adversarial loss: 0.554053\n",
      "epoch 99; iter: 0; batch classifier loss: 0.343677; batch adversarial loss: 0.506598\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389636; batch adversarial loss: 0.525635\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384806; batch adversarial loss: 0.439257\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397092; batch adversarial loss: 0.573055\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399369; batch adversarial loss: 0.400854\n",
      "epoch 104; iter: 0; batch classifier loss: 0.342228; batch adversarial loss: 0.496792\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352007; batch adversarial loss: 0.583516\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354742; batch adversarial loss: 0.477988\n",
      "epoch 107; iter: 0; batch classifier loss: 0.424067; batch adversarial loss: 0.544867\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369525; batch adversarial loss: 0.431541\n",
      "epoch 109; iter: 0; batch classifier loss: 0.399594; batch adversarial loss: 0.572884\n",
      "epoch 110; iter: 0; batch classifier loss: 0.293950; batch adversarial loss: 0.572683\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367625; batch adversarial loss: 0.572775\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371705; batch adversarial loss: 0.562981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.379998; batch adversarial loss: 0.554329\n",
      "epoch 114; iter: 0; batch classifier loss: 0.324531; batch adversarial loss: 0.581912\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372303; batch adversarial loss: 0.459344\n",
      "epoch 116; iter: 0; batch classifier loss: 0.477417; batch adversarial loss: 0.545433\n",
      "epoch 117; iter: 0; batch classifier loss: 0.458539; batch adversarial loss: 0.478387\n",
      "epoch 118; iter: 0; batch classifier loss: 0.326291; batch adversarial loss: 0.515859\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380967; batch adversarial loss: 0.516100\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354592; batch adversarial loss: 0.487222\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394707; batch adversarial loss: 0.506702\n",
      "epoch 122; iter: 0; batch classifier loss: 0.416855; batch adversarial loss: 0.582985\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349199; batch adversarial loss: 0.535566\n",
      "epoch 124; iter: 0; batch classifier loss: 0.440366; batch adversarial loss: 0.496880\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350550; batch adversarial loss: 0.545082\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403515; batch adversarial loss: 0.554138\n",
      "epoch 127; iter: 0; batch classifier loss: 0.439089; batch adversarial loss: 0.563510\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368992; batch adversarial loss: 0.563406\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394084; batch adversarial loss: 0.563799\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356960; batch adversarial loss: 0.535017\n",
      "epoch 131; iter: 0; batch classifier loss: 0.377725; batch adversarial loss: 0.544834\n",
      "epoch 132; iter: 0; batch classifier loss: 0.433442; batch adversarial loss: 0.620601\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410733; batch adversarial loss: 0.516222\n",
      "epoch 134; iter: 0; batch classifier loss: 0.465205; batch adversarial loss: 0.516606\n",
      "epoch 135; iter: 0; batch classifier loss: 0.405436; batch adversarial loss: 0.440550\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336369; batch adversarial loss: 0.506823\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376514; batch adversarial loss: 0.497461\n",
      "epoch 138; iter: 0; batch classifier loss: 0.311454; batch adversarial loss: 0.563491\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350673; batch adversarial loss: 0.515316\n",
      "epoch 140; iter: 0; batch classifier loss: 0.322932; batch adversarial loss: 0.534539\n",
      "epoch 141; iter: 0; batch classifier loss: 0.260368; batch adversarial loss: 0.497707\n",
      "epoch 142; iter: 0; batch classifier loss: 0.422505; batch adversarial loss: 0.572632\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388246; batch adversarial loss: 0.538244\n",
      "epoch 144; iter: 0; batch classifier loss: 0.304902; batch adversarial loss: 0.553943\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369177; batch adversarial loss: 0.669730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329545; batch adversarial loss: 0.527117\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383947; batch adversarial loss: 0.544936\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343513; batch adversarial loss: 0.622198\n",
      "epoch 149; iter: 0; batch classifier loss: 0.333249; batch adversarial loss: 0.563862\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351820; batch adversarial loss: 0.448541\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375930; batch adversarial loss: 0.448797\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388871; batch adversarial loss: 0.573757\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366314; batch adversarial loss: 0.592308\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361907; batch adversarial loss: 0.545055\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380886; batch adversarial loss: 0.477042\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317908; batch adversarial loss: 0.545373\n",
      "epoch 157; iter: 0; batch classifier loss: 0.442201; batch adversarial loss: 0.544687\n",
      "epoch 158; iter: 0; batch classifier loss: 0.444042; batch adversarial loss: 0.563825\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341686; batch adversarial loss: 0.496554\n",
      "epoch 160; iter: 0; batch classifier loss: 0.297119; batch adversarial loss: 0.534732\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350467; batch adversarial loss: 0.601534\n",
      "epoch 162; iter: 0; batch classifier loss: 0.335727; batch adversarial loss: 0.553654\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326294; batch adversarial loss: 0.563644\n",
      "epoch 164; iter: 0; batch classifier loss: 0.404043; batch adversarial loss: 0.582406\n",
      "epoch 165; iter: 0; batch classifier loss: 0.336946; batch adversarial loss: 0.563430\n",
      "epoch 166; iter: 0; batch classifier loss: 0.379861; batch adversarial loss: 0.592819\n",
      "epoch 167; iter: 0; batch classifier loss: 0.361289; batch adversarial loss: 0.497288\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370722; batch adversarial loss: 0.602340\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352967; batch adversarial loss: 0.477741\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354990; batch adversarial loss: 0.544037\n",
      "epoch 171; iter: 0; batch classifier loss: 0.310865; batch adversarial loss: 0.572354\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345066; batch adversarial loss: 0.526750\n",
      "epoch 173; iter: 0; batch classifier loss: 0.426217; batch adversarial loss: 0.592081\n",
      "epoch 174; iter: 0; batch classifier loss: 0.292774; batch adversarial loss: 0.611239\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363804; batch adversarial loss: 0.544445\n",
      "epoch 176; iter: 0; batch classifier loss: 0.418393; batch adversarial loss: 0.477824\n",
      "epoch 177; iter: 0; batch classifier loss: 0.409006; batch adversarial loss: 0.524733\n",
      "epoch 178; iter: 0; batch classifier loss: 0.341268; batch adversarial loss: 0.535252\n",
      "epoch 179; iter: 0; batch classifier loss: 0.313299; batch adversarial loss: 0.525877\n",
      "epoch 180; iter: 0; batch classifier loss: 0.408199; batch adversarial loss: 0.525614\n",
      "epoch 181; iter: 0; batch classifier loss: 0.406446; batch adversarial loss: 0.488246\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340841; batch adversarial loss: 0.554465\n",
      "epoch 183; iter: 0; batch classifier loss: 0.365071; batch adversarial loss: 0.563209\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363559; batch adversarial loss: 0.478395\n",
      "epoch 185; iter: 0; batch classifier loss: 0.302198; batch adversarial loss: 0.535493\n",
      "epoch 186; iter: 0; batch classifier loss: 0.419472; batch adversarial loss: 0.591150\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345904; batch adversarial loss: 0.535482\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336666; batch adversarial loss: 0.535508\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362867; batch adversarial loss: 0.611259\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333690; batch adversarial loss: 0.563119\n",
      "epoch 191; iter: 0; batch classifier loss: 0.315093; batch adversarial loss: 0.563559\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363444; batch adversarial loss: 0.611443\n",
      "epoch 193; iter: 0; batch classifier loss: 0.381859; batch adversarial loss: 0.534914\n",
      "epoch 194; iter: 0; batch classifier loss: 0.277967; batch adversarial loss: 0.545122\n",
      "epoch 195; iter: 0; batch classifier loss: 0.320930; batch adversarial loss: 0.516325\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400835; batch adversarial loss: 0.554763\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335634; batch adversarial loss: 0.573033\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323505; batch adversarial loss: 0.563620\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338133; batch adversarial loss: 0.459099\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697309; batch adversarial loss: 0.644604\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560136; batch adversarial loss: 0.651352\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572972; batch adversarial loss: 0.655770\n",
      "epoch 3; iter: 0; batch classifier loss: 0.620108; batch adversarial loss: 0.623594\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574054; batch adversarial loss: 0.673158\n",
      "epoch 5; iter: 0; batch classifier loss: 0.639008; batch adversarial loss: 0.661178\n",
      "epoch 6; iter: 0; batch classifier loss: 0.485370; batch adversarial loss: 0.594654\n",
      "epoch 7; iter: 0; batch classifier loss: 0.445053; batch adversarial loss: 0.636231\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522705; batch adversarial loss: 0.585525\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575200; batch adversarial loss: 0.604463\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561695; batch adversarial loss: 0.559324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.563549; batch adversarial loss: 0.545789\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598661; batch adversarial loss: 0.557903\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486483; batch adversarial loss: 0.578735\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498239; batch adversarial loss: 0.589219\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478144; batch adversarial loss: 0.571178\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508405; batch adversarial loss: 0.524987\n",
      "epoch 17; iter: 0; batch classifier loss: 0.561141; batch adversarial loss: 0.573188\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541565; batch adversarial loss: 0.580480\n",
      "epoch 19; iter: 0; batch classifier loss: 0.450022; batch adversarial loss: 0.549224\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437931; batch adversarial loss: 0.540680\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479637; batch adversarial loss: 0.547378\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482981; batch adversarial loss: 0.554163\n",
      "epoch 23; iter: 0; batch classifier loss: 0.410584; batch adversarial loss: 0.508091\n",
      "epoch 24; iter: 0; batch classifier loss: 0.429450; batch adversarial loss: 0.482493\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488325; batch adversarial loss: 0.536913\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522697; batch adversarial loss: 0.535842\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478407; batch adversarial loss: 0.468377\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402717; batch adversarial loss: 0.484916\n",
      "epoch 29; iter: 0; batch classifier loss: 0.392496; batch adversarial loss: 0.527080\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482706; batch adversarial loss: 0.516294\n",
      "epoch 31; iter: 0; batch classifier loss: 0.379712; batch adversarial loss: 0.553873\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462722; batch adversarial loss: 0.519561\n",
      "epoch 33; iter: 0; batch classifier loss: 0.551148; batch adversarial loss: 0.545942\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453151; batch adversarial loss: 0.501696\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521938; batch adversarial loss: 0.444299\n",
      "epoch 36; iter: 0; batch classifier loss: 0.384073; batch adversarial loss: 0.491028\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477168; batch adversarial loss: 0.553594\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445588; batch adversarial loss: 0.534026\n",
      "epoch 39; iter: 0; batch classifier loss: 0.556854; batch adversarial loss: 0.478272\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486325; batch adversarial loss: 0.590187\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428904; batch adversarial loss: 0.518262\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423923; batch adversarial loss: 0.563071\n",
      "epoch 43; iter: 0; batch classifier loss: 0.494465; batch adversarial loss: 0.546078\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424455; batch adversarial loss: 0.489089\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394921; batch adversarial loss: 0.508459\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425057; batch adversarial loss: 0.507606\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418945; batch adversarial loss: 0.534738\n",
      "epoch 48; iter: 0; batch classifier loss: 0.350254; batch adversarial loss: 0.553617\n",
      "epoch 49; iter: 0; batch classifier loss: 0.461530; batch adversarial loss: 0.460747\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386166; batch adversarial loss: 0.497893\n",
      "epoch 51; iter: 0; batch classifier loss: 0.484612; batch adversarial loss: 0.620193\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399460; batch adversarial loss: 0.526259\n",
      "epoch 53; iter: 0; batch classifier loss: 0.426602; batch adversarial loss: 0.562685\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430744; batch adversarial loss: 0.590812\n",
      "epoch 55; iter: 0; batch classifier loss: 0.348894; batch adversarial loss: 0.508019\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425064; batch adversarial loss: 0.469575\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424797; batch adversarial loss: 0.544851\n",
      "epoch 58; iter: 0; batch classifier loss: 0.457382; batch adversarial loss: 0.535234\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458947; batch adversarial loss: 0.534787\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436850; batch adversarial loss: 0.507992\n",
      "epoch 61; iter: 0; batch classifier loss: 0.390531; batch adversarial loss: 0.535445\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442221; batch adversarial loss: 0.488412\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442620; batch adversarial loss: 0.553524\n",
      "epoch 64; iter: 0; batch classifier loss: 0.487462; batch adversarial loss: 0.600148\n",
      "epoch 65; iter: 0; batch classifier loss: 0.479856; batch adversarial loss: 0.553965\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426107; batch adversarial loss: 0.534761\n",
      "epoch 67; iter: 0; batch classifier loss: 0.454426; batch adversarial loss: 0.469782\n",
      "epoch 68; iter: 0; batch classifier loss: 0.454523; batch adversarial loss: 0.489005\n",
      "epoch 69; iter: 0; batch classifier loss: 0.508728; batch adversarial loss: 0.628835\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434187; batch adversarial loss: 0.563209\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380936; batch adversarial loss: 0.525925\n",
      "epoch 72; iter: 0; batch classifier loss: 0.486801; batch adversarial loss: 0.544159\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393394; batch adversarial loss: 0.535556\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383632; batch adversarial loss: 0.545109\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395155; batch adversarial loss: 0.535474\n",
      "epoch 76; iter: 0; batch classifier loss: 0.425700; batch adversarial loss: 0.572226\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385079; batch adversarial loss: 0.470382\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427940; batch adversarial loss: 0.535216\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429722; batch adversarial loss: 0.544216\n",
      "epoch 80; iter: 0; batch classifier loss: 0.396356; batch adversarial loss: 0.534892\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386766; batch adversarial loss: 0.507379\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353136; batch adversarial loss: 0.656056\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376851; batch adversarial loss: 0.591353\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415362; batch adversarial loss: 0.553877\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392796; batch adversarial loss: 0.460372\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379134; batch adversarial loss: 0.497533\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406901; batch adversarial loss: 0.647091\n",
      "epoch 88; iter: 0; batch classifier loss: 0.434581; batch adversarial loss: 0.609828\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413915; batch adversarial loss: 0.488794\n",
      "epoch 90; iter: 0; batch classifier loss: 0.406882; batch adversarial loss: 0.442600\n",
      "epoch 91; iter: 0; batch classifier loss: 0.435107; batch adversarial loss: 0.544487\n",
      "epoch 92; iter: 0; batch classifier loss: 0.457506; batch adversarial loss: 0.535296\n",
      "epoch 93; iter: 0; batch classifier loss: 0.345048; batch adversarial loss: 0.470029\n",
      "epoch 94; iter: 0; batch classifier loss: 0.442026; batch adversarial loss: 0.535307\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393337; batch adversarial loss: 0.534811\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419072; batch adversarial loss: 0.572491\n",
      "epoch 97; iter: 0; batch classifier loss: 0.470041; batch adversarial loss: 0.534632\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384154; batch adversarial loss: 0.553934\n",
      "epoch 99; iter: 0; batch classifier loss: 0.372908; batch adversarial loss: 0.495542\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355799; batch adversarial loss: 0.554199\n",
      "epoch 101; iter: 0; batch classifier loss: 0.458816; batch adversarial loss: 0.545280\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426369; batch adversarial loss: 0.533978\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373250; batch adversarial loss: 0.639997\n",
      "epoch 104; iter: 0; batch classifier loss: 0.429373; batch adversarial loss: 0.479395\n",
      "epoch 105; iter: 0; batch classifier loss: 0.399650; batch adversarial loss: 0.526871\n",
      "epoch 106; iter: 0; batch classifier loss: 0.449192; batch adversarial loss: 0.618392\n",
      "epoch 107; iter: 0; batch classifier loss: 0.461018; batch adversarial loss: 0.591114\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420768; batch adversarial loss: 0.534813\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356842; batch adversarial loss: 0.498376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.380503; batch adversarial loss: 0.535966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433495; batch adversarial loss: 0.553769\n",
      "epoch 112; iter: 0; batch classifier loss: 0.324263; batch adversarial loss: 0.498537\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391125; batch adversarial loss: 0.553713\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385211; batch adversarial loss: 0.489016\n",
      "epoch 115; iter: 0; batch classifier loss: 0.359017; batch adversarial loss: 0.553437\n",
      "epoch 116; iter: 0; batch classifier loss: 0.439971; batch adversarial loss: 0.553760\n",
      "epoch 117; iter: 0; batch classifier loss: 0.520656; batch adversarial loss: 0.507077\n",
      "epoch 118; iter: 0; batch classifier loss: 0.466468; batch adversarial loss: 0.506895\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402328; batch adversarial loss: 0.506971\n",
      "epoch 120; iter: 0; batch classifier loss: 0.430397; batch adversarial loss: 0.526468\n",
      "epoch 121; iter: 0; batch classifier loss: 0.429814; batch adversarial loss: 0.516237\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382302; batch adversarial loss: 0.526143\n",
      "epoch 123; iter: 0; batch classifier loss: 0.330642; batch adversarial loss: 0.525985\n",
      "epoch 124; iter: 0; batch classifier loss: 0.485500; batch adversarial loss: 0.497694\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402836; batch adversarial loss: 0.553888\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400604; batch adversarial loss: 0.553400\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378249; batch adversarial loss: 0.450485\n",
      "epoch 128; iter: 0; batch classifier loss: 0.448412; batch adversarial loss: 0.553618\n",
      "epoch 129; iter: 0; batch classifier loss: 0.435123; batch adversarial loss: 0.525989\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373383; batch adversarial loss: 0.544730\n",
      "epoch 131; iter: 0; batch classifier loss: 0.376594; batch adversarial loss: 0.535286\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389674; batch adversarial loss: 0.581422\n",
      "epoch 133; iter: 0; batch classifier loss: 0.401039; batch adversarial loss: 0.469689\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329829; batch adversarial loss: 0.553794\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370692; batch adversarial loss: 0.489013\n",
      "epoch 136; iter: 0; batch classifier loss: 0.323903; batch adversarial loss: 0.618615\n",
      "epoch 137; iter: 0; batch classifier loss: 0.365657; batch adversarial loss: 0.526232\n",
      "epoch 138; iter: 0; batch classifier loss: 0.351422; batch adversarial loss: 0.432810\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342863; batch adversarial loss: 0.655720\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381947; batch adversarial loss: 0.516837\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391710; batch adversarial loss: 0.526086\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400054; batch adversarial loss: 0.544600\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322574; batch adversarial loss: 0.553797\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352268; batch adversarial loss: 0.637500\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405338; batch adversarial loss: 0.544561\n",
      "epoch 146; iter: 0; batch classifier loss: 0.301719; batch adversarial loss: 0.535095\n",
      "epoch 147; iter: 0; batch classifier loss: 0.512782; batch adversarial loss: 0.581437\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350540; batch adversarial loss: 0.646818\n",
      "epoch 149; iter: 0; batch classifier loss: 0.429435; batch adversarial loss: 0.600292\n",
      "epoch 150; iter: 0; batch classifier loss: 0.419997; batch adversarial loss: 0.564076\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350893; batch adversarial loss: 0.647297\n",
      "epoch 152; iter: 0; batch classifier loss: 0.399063; batch adversarial loss: 0.572701\n",
      "epoch 153; iter: 0; batch classifier loss: 0.410315; batch adversarial loss: 0.507160\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319805; batch adversarial loss: 0.488659\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342495; batch adversarial loss: 0.591038\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374295; batch adversarial loss: 0.507283\n",
      "epoch 157; iter: 0; batch classifier loss: 0.390359; batch adversarial loss: 0.544428\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338915; batch adversarial loss: 0.563030\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363744; batch adversarial loss: 0.498109\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321755; batch adversarial loss: 0.618744\n",
      "epoch 161; iter: 0; batch classifier loss: 0.384657; batch adversarial loss: 0.535316\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397684; batch adversarial loss: 0.506313\n",
      "epoch 163; iter: 0; batch classifier loss: 0.415800; batch adversarial loss: 0.507215\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392470; batch adversarial loss: 0.525551\n",
      "epoch 165; iter: 0; batch classifier loss: 0.300279; batch adversarial loss: 0.553563\n",
      "epoch 166; iter: 0; batch classifier loss: 0.424906; batch adversarial loss: 0.563992\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366487; batch adversarial loss: 0.451789\n",
      "epoch 168; iter: 0; batch classifier loss: 0.374509; batch adversarial loss: 0.544489\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368471; batch adversarial loss: 0.488841\n",
      "epoch 170; iter: 0; batch classifier loss: 0.356711; batch adversarial loss: 0.516488\n",
      "epoch 171; iter: 0; batch classifier loss: 0.429734; batch adversarial loss: 0.535249\n",
      "epoch 172; iter: 0; batch classifier loss: 0.435990; batch adversarial loss: 0.572314\n",
      "epoch 173; iter: 0; batch classifier loss: 0.393989; batch adversarial loss: 0.600233\n",
      "epoch 174; iter: 0; batch classifier loss: 0.316795; batch adversarial loss: 0.544476\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369229; batch adversarial loss: 0.470173\n",
      "epoch 176; iter: 0; batch classifier loss: 0.424800; batch adversarial loss: 0.525918\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305988; batch adversarial loss: 0.535279\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361690; batch adversarial loss: 0.479643\n",
      "epoch 179; iter: 0; batch classifier loss: 0.375857; batch adversarial loss: 0.563110\n",
      "epoch 180; iter: 0; batch classifier loss: 0.410356; batch adversarial loss: 0.544589\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344343; batch adversarial loss: 0.572586\n",
      "epoch 182; iter: 0; batch classifier loss: 0.395559; batch adversarial loss: 0.581510\n",
      "epoch 183; iter: 0; batch classifier loss: 0.392566; batch adversarial loss: 0.498246\n",
      "epoch 184; iter: 0; batch classifier loss: 0.351502; batch adversarial loss: 0.572324\n",
      "epoch 185; iter: 0; batch classifier loss: 0.388561; batch adversarial loss: 0.553878\n",
      "epoch 186; iter: 0; batch classifier loss: 0.393405; batch adversarial loss: 0.619470\n",
      "epoch 187; iter: 0; batch classifier loss: 0.406861; batch adversarial loss: 0.516615\n",
      "epoch 188; iter: 0; batch classifier loss: 0.488837; batch adversarial loss: 0.553848\n",
      "epoch 189; iter: 0; batch classifier loss: 0.416286; batch adversarial loss: 0.572813\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364248; batch adversarial loss: 0.525169\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331756; batch adversarial loss: 0.525656\n",
      "epoch 192; iter: 0; batch classifier loss: 0.386006; batch adversarial loss: 0.601145\n",
      "epoch 193; iter: 0; batch classifier loss: 0.357777; batch adversarial loss: 0.507022\n",
      "epoch 194; iter: 0; batch classifier loss: 0.422492; batch adversarial loss: 0.582180\n",
      "epoch 195; iter: 0; batch classifier loss: 0.409299; batch adversarial loss: 0.507083\n",
      "epoch 196; iter: 0; batch classifier loss: 0.388441; batch adversarial loss: 0.497521\n",
      "epoch 197; iter: 0; batch classifier loss: 0.331923; batch adversarial loss: 0.572898\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352939; batch adversarial loss: 0.541939\n",
      "epoch 199; iter: 0; batch classifier loss: 0.401143; batch adversarial loss: 0.563406\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680974; batch adversarial loss: 0.915311\n",
      "epoch 1; iter: 0; batch classifier loss: 0.911987; batch adversarial loss: 1.309527\n",
      "epoch 2; iter: 0; batch classifier loss: 1.161541; batch adversarial loss: 1.281254\n",
      "epoch 3; iter: 0; batch classifier loss: 1.191736; batch adversarial loss: 1.173774\n",
      "epoch 4; iter: 0; batch classifier loss: 1.162514; batch adversarial loss: 1.066267\n",
      "epoch 5; iter: 0; batch classifier loss: 1.154725; batch adversarial loss: 0.993933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 1.122141; batch adversarial loss: 0.907657\n",
      "epoch 7; iter: 0; batch classifier loss: 1.274038; batch adversarial loss: 0.860000\n",
      "epoch 8; iter: 0; batch classifier loss: 0.986001; batch adversarial loss: 0.774110\n",
      "epoch 9; iter: 0; batch classifier loss: 0.985263; batch adversarial loss: 0.747231\n",
      "epoch 10; iter: 0; batch classifier loss: 0.826593; batch adversarial loss: 0.695480\n",
      "epoch 11; iter: 0; batch classifier loss: 0.776956; batch adversarial loss: 0.609748\n",
      "epoch 12; iter: 0; batch classifier loss: 0.639346; batch adversarial loss: 0.578651\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573603; batch adversarial loss: 0.640034\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558095; batch adversarial loss: 0.571585\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553205; batch adversarial loss: 0.585145\n",
      "epoch 16; iter: 0; batch classifier loss: 0.581637; batch adversarial loss: 0.589969\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531282; batch adversarial loss: 0.545970\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465666; batch adversarial loss: 0.584985\n",
      "epoch 19; iter: 0; batch classifier loss: 0.467058; batch adversarial loss: 0.574867\n",
      "epoch 20; iter: 0; batch classifier loss: 0.544269; batch adversarial loss: 0.566590\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514245; batch adversarial loss: 0.544194\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480359; batch adversarial loss: 0.548305\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497535; batch adversarial loss: 0.628114\n",
      "epoch 24; iter: 0; batch classifier loss: 0.450924; batch adversarial loss: 0.527067\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443835; batch adversarial loss: 0.534962\n",
      "epoch 26; iter: 0; batch classifier loss: 0.436892; batch adversarial loss: 0.527210\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464937; batch adversarial loss: 0.565834\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516264; batch adversarial loss: 0.589448\n",
      "epoch 29; iter: 0; batch classifier loss: 0.423465; batch adversarial loss: 0.520016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504916; batch adversarial loss: 0.571132\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454950; batch adversarial loss: 0.489547\n",
      "epoch 32; iter: 0; batch classifier loss: 0.524572; batch adversarial loss: 0.489520\n",
      "epoch 33; iter: 0; batch classifier loss: 0.396941; batch adversarial loss: 0.584786\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462038; batch adversarial loss: 0.612342\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425190; batch adversarial loss: 0.473388\n",
      "epoch 36; iter: 0; batch classifier loss: 0.413894; batch adversarial loss: 0.591390\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462730; batch adversarial loss: 0.489333\n",
      "epoch 38; iter: 0; batch classifier loss: 0.423800; batch adversarial loss: 0.569993\n",
      "epoch 39; iter: 0; batch classifier loss: 0.520591; batch adversarial loss: 0.476865\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435347; batch adversarial loss: 0.556032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473274; batch adversarial loss: 0.465082\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467157; batch adversarial loss: 0.585476\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431745; batch adversarial loss: 0.524190\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446686; batch adversarial loss: 0.618445\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437882; batch adversarial loss: 0.558874\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448374; batch adversarial loss: 0.531732\n",
      "epoch 47; iter: 0; batch classifier loss: 0.500908; batch adversarial loss: 0.553876\n",
      "epoch 48; iter: 0; batch classifier loss: 0.352544; batch adversarial loss: 0.467223\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462217; batch adversarial loss: 0.546619\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453770; batch adversarial loss: 0.553515\n",
      "epoch 51; iter: 0; batch classifier loss: 0.512495; batch adversarial loss: 0.544203\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410544; batch adversarial loss: 0.563750\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417283; batch adversarial loss: 0.538380\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384420; batch adversarial loss: 0.491973\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476390; batch adversarial loss: 0.501836\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412956; batch adversarial loss: 0.498129\n",
      "epoch 57; iter: 0; batch classifier loss: 0.452802; batch adversarial loss: 0.572655\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463107; batch adversarial loss: 0.581923\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422816; batch adversarial loss: 0.562199\n",
      "epoch 60; iter: 0; batch classifier loss: 0.495685; batch adversarial loss: 0.561750\n",
      "epoch 61; iter: 0; batch classifier loss: 0.482247; batch adversarial loss: 0.518264\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453443; batch adversarial loss: 0.525347\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414363; batch adversarial loss: 0.544525\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426660; batch adversarial loss: 0.498089\n",
      "epoch 65; iter: 0; batch classifier loss: 0.584707; batch adversarial loss: 0.571829\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378724; batch adversarial loss: 0.535857\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380152; batch adversarial loss: 0.572332\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412227; batch adversarial loss: 0.516148\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401919; batch adversarial loss: 0.562500\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353059; batch adversarial loss: 0.562754\n",
      "epoch 71; iter: 0; batch classifier loss: 0.329397; batch adversarial loss: 0.591065\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438689; batch adversarial loss: 0.497515\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425112; batch adversarial loss: 0.559310\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406024; batch adversarial loss: 0.563787\n",
      "epoch 75; iter: 0; batch classifier loss: 0.470604; batch adversarial loss: 0.616949\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415992; batch adversarial loss: 0.506513\n",
      "epoch 77; iter: 0; batch classifier loss: 0.460247; batch adversarial loss: 0.607205\n",
      "epoch 78; iter: 0; batch classifier loss: 0.450476; batch adversarial loss: 0.553495\n",
      "epoch 79; iter: 0; batch classifier loss: 0.423251; batch adversarial loss: 0.613873\n",
      "epoch 80; iter: 0; batch classifier loss: 0.397756; batch adversarial loss: 0.563376\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384560; batch adversarial loss: 0.452201\n",
      "epoch 82; iter: 0; batch classifier loss: 0.402581; batch adversarial loss: 0.563896\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397203; batch adversarial loss: 0.534565\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395681; batch adversarial loss: 0.553138\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383203; batch adversarial loss: 0.480971\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401038; batch adversarial loss: 0.563817\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396197; batch adversarial loss: 0.553749\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414196; batch adversarial loss: 0.497260\n",
      "epoch 89; iter: 0; batch classifier loss: 0.442741; batch adversarial loss: 0.617957\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344653; batch adversarial loss: 0.509212\n",
      "epoch 91; iter: 0; batch classifier loss: 0.457883; batch adversarial loss: 0.554370\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387568; batch adversarial loss: 0.489137\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402165; batch adversarial loss: 0.560683\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431306; batch adversarial loss: 0.609497\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387758; batch adversarial loss: 0.573094\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390487; batch adversarial loss: 0.534169\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371391; batch adversarial loss: 0.498178\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358243; batch adversarial loss: 0.534656\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368362; batch adversarial loss: 0.542695\n",
      "epoch 100; iter: 0; batch classifier loss: 0.333387; batch adversarial loss: 0.488355\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356095; batch adversarial loss: 0.561602\n",
      "epoch 102; iter: 0; batch classifier loss: 0.354601; batch adversarial loss: 0.559308\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391391; batch adversarial loss: 0.546894\n",
      "epoch 104; iter: 0; batch classifier loss: 0.411765; batch adversarial loss: 0.620950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.378551; batch adversarial loss: 0.598989\n",
      "epoch 106; iter: 0; batch classifier loss: 0.446409; batch adversarial loss: 0.505811\n",
      "epoch 107; iter: 0; batch classifier loss: 0.419596; batch adversarial loss: 0.486468\n",
      "epoch 108; iter: 0; batch classifier loss: 0.291046; batch adversarial loss: 0.569386\n",
      "epoch 109; iter: 0; batch classifier loss: 0.468632; batch adversarial loss: 0.518843\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349127; batch adversarial loss: 0.570800\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380348; batch adversarial loss: 0.543362\n",
      "epoch 112; iter: 0; batch classifier loss: 0.328198; batch adversarial loss: 0.584984\n",
      "epoch 113; iter: 0; batch classifier loss: 0.455408; batch adversarial loss: 0.517072\n",
      "epoch 114; iter: 0; batch classifier loss: 0.408180; batch adversarial loss: 0.430632\n",
      "epoch 115; iter: 0; batch classifier loss: 0.395389; batch adversarial loss: 0.496696\n",
      "epoch 116; iter: 0; batch classifier loss: 0.337224; batch adversarial loss: 0.641531\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370996; batch adversarial loss: 0.529157\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357518; batch adversarial loss: 0.544493\n",
      "epoch 119; iter: 0; batch classifier loss: 0.273861; batch adversarial loss: 0.544484\n",
      "epoch 120; iter: 0; batch classifier loss: 0.322145; batch adversarial loss: 0.429168\n",
      "epoch 121; iter: 0; batch classifier loss: 0.411782; batch adversarial loss: 0.586607\n",
      "epoch 122; iter: 0; batch classifier loss: 0.320386; batch adversarial loss: 0.598203\n",
      "epoch 123; iter: 0; batch classifier loss: 0.330335; batch adversarial loss: 0.534098\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360725; batch adversarial loss: 0.535906\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344924; batch adversarial loss: 0.572273\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354117; batch adversarial loss: 0.564526\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419957; batch adversarial loss: 0.569897\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360175; batch adversarial loss: 0.522495\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378642; batch adversarial loss: 0.609284\n",
      "epoch 130; iter: 0; batch classifier loss: 0.335988; batch adversarial loss: 0.590495\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407685; batch adversarial loss: 0.542312\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355102; batch adversarial loss: 0.530429\n",
      "epoch 133; iter: 0; batch classifier loss: 0.422497; batch adversarial loss: 0.600778\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368154; batch adversarial loss: 0.571887\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366531; batch adversarial loss: 0.489423\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334783; batch adversarial loss: 0.524569\n",
      "epoch 137; iter: 0; batch classifier loss: 0.269763; batch adversarial loss: 0.536896\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382783; batch adversarial loss: 0.462241\n",
      "epoch 139; iter: 0; batch classifier loss: 0.417471; batch adversarial loss: 0.565392\n",
      "epoch 140; iter: 0; batch classifier loss: 0.339539; batch adversarial loss: 0.597796\n",
      "epoch 141; iter: 0; batch classifier loss: 0.340947; batch adversarial loss: 0.550938\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379406; batch adversarial loss: 0.578180\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371403; batch adversarial loss: 0.602424\n",
      "epoch 144; iter: 0; batch classifier loss: 0.300883; batch adversarial loss: 0.470693\n",
      "epoch 145; iter: 0; batch classifier loss: 0.292870; batch adversarial loss: 0.563741\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376691; batch adversarial loss: 0.572594\n",
      "epoch 147; iter: 0; batch classifier loss: 0.312836; batch adversarial loss: 0.536105\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351391; batch adversarial loss: 0.490383\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362651; batch adversarial loss: 0.549051\n",
      "epoch 150; iter: 0; batch classifier loss: 0.220117; batch adversarial loss: 0.533860\n",
      "epoch 151; iter: 0; batch classifier loss: 0.393325; batch adversarial loss: 0.527287\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386926; batch adversarial loss: 0.562491\n",
      "epoch 153; iter: 0; batch classifier loss: 0.312708; batch adversarial loss: 0.608465\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377316; batch adversarial loss: 0.585774\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337437; batch adversarial loss: 0.488415\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387224; batch adversarial loss: 0.523231\n",
      "epoch 157; iter: 0; batch classifier loss: 0.439731; batch adversarial loss: 0.573593\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366295; batch adversarial loss: 0.617684\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342016; batch adversarial loss: 0.573991\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358077; batch adversarial loss: 0.558809\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335913; batch adversarial loss: 0.470582\n",
      "epoch 162; iter: 0; batch classifier loss: 0.458797; batch adversarial loss: 0.442625\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335198; batch adversarial loss: 0.524089\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371001; batch adversarial loss: 0.506043\n",
      "epoch 165; iter: 0; batch classifier loss: 0.289311; batch adversarial loss: 0.482367\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366410; batch adversarial loss: 0.488950\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347014; batch adversarial loss: 0.540806\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306284; batch adversarial loss: 0.588080\n",
      "epoch 169; iter: 0; batch classifier loss: 0.300854; batch adversarial loss: 0.544096\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342538; batch adversarial loss: 0.617553\n",
      "epoch 171; iter: 0; batch classifier loss: 0.397860; batch adversarial loss: 0.568375\n",
      "epoch 172; iter: 0; batch classifier loss: 0.432924; batch adversarial loss: 0.518212\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387537; batch adversarial loss: 0.516923\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334932; batch adversarial loss: 0.543385\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352663; batch adversarial loss: 0.564864\n",
      "epoch 176; iter: 0; batch classifier loss: 0.323635; batch adversarial loss: 0.522767\n",
      "epoch 177; iter: 0; batch classifier loss: 0.320981; batch adversarial loss: 0.590046\n",
      "epoch 178; iter: 0; batch classifier loss: 0.319273; batch adversarial loss: 0.508158\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279702; batch adversarial loss: 0.576083\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362140; batch adversarial loss: 0.565033\n",
      "epoch 181; iter: 0; batch classifier loss: 0.306610; batch adversarial loss: 0.565871\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322206; batch adversarial loss: 0.524412\n",
      "epoch 183; iter: 0; batch classifier loss: 0.340405; batch adversarial loss: 0.473452\n",
      "epoch 184; iter: 0; batch classifier loss: 0.408857; batch adversarial loss: 0.555119\n",
      "epoch 185; iter: 0; batch classifier loss: 0.293403; batch adversarial loss: 0.559110\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309978; batch adversarial loss: 0.488792\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374023; batch adversarial loss: 0.516592\n",
      "epoch 188; iter: 0; batch classifier loss: 0.287908; batch adversarial loss: 0.581601\n",
      "epoch 189; iter: 0; batch classifier loss: 0.301568; batch adversarial loss: 0.561660\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366417; batch adversarial loss: 0.591349\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336168; batch adversarial loss: 0.536051\n",
      "epoch 192; iter: 0; batch classifier loss: 0.350750; batch adversarial loss: 0.602830\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364622; batch adversarial loss: 0.524001\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350825; batch adversarial loss: 0.486488\n",
      "epoch 195; iter: 0; batch classifier loss: 0.298000; batch adversarial loss: 0.505725\n",
      "epoch 196; iter: 0; batch classifier loss: 0.322082; batch adversarial loss: 0.519478\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396537; batch adversarial loss: 0.458649\n",
      "epoch 198; iter: 0; batch classifier loss: 0.310575; batch adversarial loss: 0.551572\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319422; batch adversarial loss: 0.555527\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658612; batch adversarial loss: 0.716144\n",
      "epoch 1; iter: 0; batch classifier loss: 0.683965; batch adversarial loss: 0.694858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.604753; batch adversarial loss: 0.655734\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566360; batch adversarial loss: 0.632665\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582692; batch adversarial loss: 0.631651\n",
      "epoch 5; iter: 0; batch classifier loss: 0.523107; batch adversarial loss: 0.604755\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534115; batch adversarial loss: 0.601690\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552545; batch adversarial loss: 0.587189\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551879; batch adversarial loss: 0.606270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564789; batch adversarial loss: 0.588685\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540034; batch adversarial loss: 0.619773\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543662; batch adversarial loss: 0.603115\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550689; batch adversarial loss: 0.581166\n",
      "epoch 13; iter: 0; batch classifier loss: 0.468447; batch adversarial loss: 0.557036\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511980; batch adversarial loss: 0.565975\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477770; batch adversarial loss: 0.587135\n",
      "epoch 16; iter: 0; batch classifier loss: 0.461519; batch adversarial loss: 0.607760\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497706; batch adversarial loss: 0.532360\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512101; batch adversarial loss: 0.558749\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456586; batch adversarial loss: 0.579801\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491649; batch adversarial loss: 0.557596\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488411; batch adversarial loss: 0.541651\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431595; batch adversarial loss: 0.539343\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547047; batch adversarial loss: 0.456531\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468712; batch adversarial loss: 0.474795\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453481; batch adversarial loss: 0.557551\n",
      "epoch 26; iter: 0; batch classifier loss: 0.441914; batch adversarial loss: 0.522072\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450992; batch adversarial loss: 0.586093\n",
      "epoch 28; iter: 0; batch classifier loss: 0.520337; batch adversarial loss: 0.545014\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456881; batch adversarial loss: 0.520316\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452810; batch adversarial loss: 0.578328\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445862; batch adversarial loss: 0.438042\n",
      "epoch 32; iter: 0; batch classifier loss: 0.447774; batch adversarial loss: 0.609814\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405212; batch adversarial loss: 0.496864\n",
      "epoch 34; iter: 0; batch classifier loss: 0.493654; batch adversarial loss: 0.525023\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504033; batch adversarial loss: 0.568602\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452838; batch adversarial loss: 0.538346\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420089; batch adversarial loss: 0.539688\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480784; batch adversarial loss: 0.572787\n",
      "epoch 39; iter: 0; batch classifier loss: 0.372350; batch adversarial loss: 0.536891\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474117; batch adversarial loss: 0.491799\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475926; batch adversarial loss: 0.580358\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445495; batch adversarial loss: 0.528667\n",
      "epoch 43; iter: 0; batch classifier loss: 0.428344; batch adversarial loss: 0.499242\n",
      "epoch 44; iter: 0; batch classifier loss: 0.345038; batch adversarial loss: 0.478313\n",
      "epoch 45; iter: 0; batch classifier loss: 0.474067; batch adversarial loss: 0.600159\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500914; batch adversarial loss: 0.547238\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436611; batch adversarial loss: 0.461961\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495122; batch adversarial loss: 0.590323\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457961; batch adversarial loss: 0.470916\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390094; batch adversarial loss: 0.485059\n",
      "epoch 51; iter: 0; batch classifier loss: 0.514001; batch adversarial loss: 0.602910\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461960; batch adversarial loss: 0.544786\n",
      "epoch 53; iter: 0; batch classifier loss: 0.377891; batch adversarial loss: 0.501068\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433688; batch adversarial loss: 0.526906\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387652; batch adversarial loss: 0.534230\n",
      "epoch 56; iter: 0; batch classifier loss: 0.460134; batch adversarial loss: 0.465514\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443731; batch adversarial loss: 0.516108\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429354; batch adversarial loss: 0.518773\n",
      "epoch 59; iter: 0; batch classifier loss: 0.470316; batch adversarial loss: 0.517214\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450372; batch adversarial loss: 0.599260\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445793; batch adversarial loss: 0.574121\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401162; batch adversarial loss: 0.542858\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378558; batch adversarial loss: 0.738056\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466865; batch adversarial loss: 0.560746\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374888; batch adversarial loss: 0.564104\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423436; batch adversarial loss: 0.525776\n",
      "epoch 67; iter: 0; batch classifier loss: 0.424605; batch adversarial loss: 0.609164\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400236; batch adversarial loss: 0.606195\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430714; batch adversarial loss: 0.565393\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407435; batch adversarial loss: 0.553970\n",
      "epoch 71; iter: 0; batch classifier loss: 0.348696; batch adversarial loss: 0.498109\n",
      "epoch 72; iter: 0; batch classifier loss: 0.464351; batch adversarial loss: 0.522226\n",
      "epoch 73; iter: 0; batch classifier loss: 0.507451; batch adversarial loss: 0.504482\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411259; batch adversarial loss: 0.516051\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379177; batch adversarial loss: 0.546020\n",
      "epoch 76; iter: 0; batch classifier loss: 0.307767; batch adversarial loss: 0.537840\n",
      "epoch 77; iter: 0; batch classifier loss: 0.369451; batch adversarial loss: 0.574217\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402925; batch adversarial loss: 0.498490\n",
      "epoch 79; iter: 0; batch classifier loss: 0.502255; batch adversarial loss: 0.589054\n",
      "epoch 80; iter: 0; batch classifier loss: 0.318262; batch adversarial loss: 0.516676\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410907; batch adversarial loss: 0.525130\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361346; batch adversarial loss: 0.479177\n",
      "epoch 83; iter: 0; batch classifier loss: 0.327650; batch adversarial loss: 0.537803\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416636; batch adversarial loss: 0.524277\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378325; batch adversarial loss: 0.541307\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368494; batch adversarial loss: 0.551109\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360750; batch adversarial loss: 0.536192\n",
      "epoch 88; iter: 0; batch classifier loss: 0.312600; batch adversarial loss: 0.601209\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383557; batch adversarial loss: 0.573830\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373823; batch adversarial loss: 0.478289\n",
      "epoch 91; iter: 0; batch classifier loss: 0.451410; batch adversarial loss: 0.425028\n",
      "epoch 92; iter: 0; batch classifier loss: 0.322301; batch adversarial loss: 0.624533\n",
      "epoch 93; iter: 0; batch classifier loss: 0.401328; batch adversarial loss: 0.577590\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368735; batch adversarial loss: 0.514467\n",
      "epoch 95; iter: 0; batch classifier loss: 0.342037; batch adversarial loss: 0.580393\n",
      "epoch 96; iter: 0; batch classifier loss: 0.320560; batch adversarial loss: 0.609405\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372669; batch adversarial loss: 0.615659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.480031; batch adversarial loss: 0.506881\n",
      "epoch 99; iter: 0; batch classifier loss: 0.387559; batch adversarial loss: 0.561191\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374431; batch adversarial loss: 0.564214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.477570; batch adversarial loss: 0.560386\n",
      "epoch 102; iter: 0; batch classifier loss: 0.353595; batch adversarial loss: 0.474256\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362197; batch adversarial loss: 0.489131\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384497; batch adversarial loss: 0.543811\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406944; batch adversarial loss: 0.547827\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397482; batch adversarial loss: 0.622260\n",
      "epoch 107; iter: 0; batch classifier loss: 0.416556; batch adversarial loss: 0.534883\n",
      "epoch 108; iter: 0; batch classifier loss: 0.466672; batch adversarial loss: 0.571558\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391006; batch adversarial loss: 0.500242\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389270; batch adversarial loss: 0.580536\n",
      "epoch 111; iter: 0; batch classifier loss: 0.371699; batch adversarial loss: 0.477205\n",
      "epoch 112; iter: 0; batch classifier loss: 0.390820; batch adversarial loss: 0.514957\n",
      "epoch 113; iter: 0; batch classifier loss: 0.429478; batch adversarial loss: 0.608015\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344745; batch adversarial loss: 0.587033\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366606; batch adversarial loss: 0.504060\n",
      "epoch 116; iter: 0; batch classifier loss: 0.340825; batch adversarial loss: 0.504956\n",
      "epoch 117; iter: 0; batch classifier loss: 0.344938; batch adversarial loss: 0.461335\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381260; batch adversarial loss: 0.485611\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392378; batch adversarial loss: 0.552704\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373543; batch adversarial loss: 0.505479\n",
      "epoch 121; iter: 0; batch classifier loss: 0.427600; batch adversarial loss: 0.521379\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345123; batch adversarial loss: 0.573697\n",
      "epoch 123; iter: 0; batch classifier loss: 0.420364; batch adversarial loss: 0.504042\n",
      "epoch 124; iter: 0; batch classifier loss: 0.416202; batch adversarial loss: 0.543144\n",
      "epoch 125; iter: 0; batch classifier loss: 0.298802; batch adversarial loss: 0.526990\n",
      "epoch 126; iter: 0; batch classifier loss: 0.299488; batch adversarial loss: 0.553545\n",
      "epoch 127; iter: 0; batch classifier loss: 0.458393; batch adversarial loss: 0.480285\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329100; batch adversarial loss: 0.554495\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348590; batch adversarial loss: 0.552282\n",
      "epoch 130; iter: 0; batch classifier loss: 0.317080; batch adversarial loss: 0.518344\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351397; batch adversarial loss: 0.589878\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403160; batch adversarial loss: 0.620371\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364543; batch adversarial loss: 0.535832\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351283; batch adversarial loss: 0.638384\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343198; batch adversarial loss: 0.489357\n",
      "epoch 136; iter: 0; batch classifier loss: 0.331400; batch adversarial loss: 0.554883\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377736; batch adversarial loss: 0.556362\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388070; batch adversarial loss: 0.656449\n",
      "epoch 139; iter: 0; batch classifier loss: 0.329261; batch adversarial loss: 0.521623\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358062; batch adversarial loss: 0.515638\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403627; batch adversarial loss: 0.496052\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355751; batch adversarial loss: 0.498594\n",
      "epoch 143; iter: 0; batch classifier loss: 0.335026; batch adversarial loss: 0.510890\n",
      "epoch 144; iter: 0; batch classifier loss: 0.410699; batch adversarial loss: 0.542339\n",
      "epoch 145; iter: 0; batch classifier loss: 0.370124; batch adversarial loss: 0.494494\n",
      "epoch 146; iter: 0; batch classifier loss: 0.461692; batch adversarial loss: 0.634394\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340875; batch adversarial loss: 0.562062\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357896; batch adversarial loss: 0.498914\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347543; batch adversarial loss: 0.490390\n",
      "epoch 150; iter: 0; batch classifier loss: 0.332837; batch adversarial loss: 0.579248\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361503; batch adversarial loss: 0.491722\n",
      "epoch 152; iter: 0; batch classifier loss: 0.322149; batch adversarial loss: 0.499104\n",
      "epoch 153; iter: 0; batch classifier loss: 0.409893; batch adversarial loss: 0.510549\n",
      "epoch 154; iter: 0; batch classifier loss: 0.391819; batch adversarial loss: 0.565683\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380207; batch adversarial loss: 0.527686\n",
      "epoch 156; iter: 0; batch classifier loss: 0.393972; batch adversarial loss: 0.516841\n",
      "epoch 157; iter: 0; batch classifier loss: 0.408311; batch adversarial loss: 0.589189\n",
      "epoch 158; iter: 0; batch classifier loss: 0.393180; batch adversarial loss: 0.542747\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361680; batch adversarial loss: 0.516611\n",
      "epoch 160; iter: 0; batch classifier loss: 0.307061; batch adversarial loss: 0.545158\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362163; batch adversarial loss: 0.533269\n",
      "epoch 162; iter: 0; batch classifier loss: 0.442795; batch adversarial loss: 0.560579\n",
      "epoch 163; iter: 0; batch classifier loss: 0.467224; batch adversarial loss: 0.481113\n",
      "epoch 164; iter: 0; batch classifier loss: 0.457020; batch adversarial loss: 0.490704\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342551; batch adversarial loss: 0.516975\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353394; batch adversarial loss: 0.561987\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382882; batch adversarial loss: 0.579014\n",
      "epoch 168; iter: 0; batch classifier loss: 0.325249; batch adversarial loss: 0.544187\n",
      "epoch 169; iter: 0; batch classifier loss: 0.346255; batch adversarial loss: 0.480257\n",
      "epoch 170; iter: 0; batch classifier loss: 0.308832; batch adversarial loss: 0.553373\n",
      "epoch 171; iter: 0; batch classifier loss: 0.417000; batch adversarial loss: 0.534946\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362431; batch adversarial loss: 0.590077\n",
      "epoch 173; iter: 0; batch classifier loss: 0.453257; batch adversarial loss: 0.546073\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369819; batch adversarial loss: 0.451294\n",
      "epoch 175; iter: 0; batch classifier loss: 0.321439; batch adversarial loss: 0.560976\n",
      "epoch 176; iter: 0; batch classifier loss: 0.246754; batch adversarial loss: 0.600740\n",
      "epoch 177; iter: 0; batch classifier loss: 0.295750; batch adversarial loss: 0.525243\n",
      "epoch 178; iter: 0; batch classifier loss: 0.341932; batch adversarial loss: 0.647809\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355760; batch adversarial loss: 0.536234\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388416; batch adversarial loss: 0.581781\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420053; batch adversarial loss: 0.607866\n",
      "epoch 182; iter: 0; batch classifier loss: 0.304701; batch adversarial loss: 0.531997\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396667; batch adversarial loss: 0.473405\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360347; batch adversarial loss: 0.555125\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367098; batch adversarial loss: 0.506188\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343203; batch adversarial loss: 0.486127\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317903; batch adversarial loss: 0.543672\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383309; batch adversarial loss: 0.644844\n",
      "epoch 189; iter: 0; batch classifier loss: 0.425422; batch adversarial loss: 0.508349\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340004; batch adversarial loss: 0.518516\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389889; batch adversarial loss: 0.534484\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334475; batch adversarial loss: 0.487885\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350913; batch adversarial loss: 0.550129\n",
      "epoch 194; iter: 0; batch classifier loss: 0.423169; batch adversarial loss: 0.561866\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349394; batch adversarial loss: 0.574166\n",
      "epoch 196; iter: 0; batch classifier loss: 0.365876; batch adversarial loss: 0.554375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.353293; batch adversarial loss: 0.506350\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334183; batch adversarial loss: 0.517028\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355826; batch adversarial loss: 0.573352\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671065; batch adversarial loss: 0.640074\n",
      "epoch 1; iter: 0; batch classifier loss: 0.612492; batch adversarial loss: 0.639393\n",
      "epoch 2; iter: 0; batch classifier loss: 0.513877; batch adversarial loss: 0.599114\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543233; batch adversarial loss: 0.606767\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520343; batch adversarial loss: 0.684642\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607933; batch adversarial loss: 0.635946\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582868; batch adversarial loss: 0.636468\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555929; batch adversarial loss: 0.641132\n",
      "epoch 8; iter: 0; batch classifier loss: 0.643661; batch adversarial loss: 0.648639\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541097; batch adversarial loss: 0.584285\n",
      "epoch 10; iter: 0; batch classifier loss: 0.600396; batch adversarial loss: 0.565398\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560539; batch adversarial loss: 0.563851\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542824; batch adversarial loss: 0.580439\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527137; batch adversarial loss: 0.508759\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534244; batch adversarial loss: 0.581825\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496977; batch adversarial loss: 0.618061\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499860; batch adversarial loss: 0.553173\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524255; batch adversarial loss: 0.544434\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502902; batch adversarial loss: 0.525699\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513189; batch adversarial loss: 0.551401\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450614; batch adversarial loss: 0.531840\n",
      "epoch 21; iter: 0; batch classifier loss: 0.465289; batch adversarial loss: 0.588358\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509597; batch adversarial loss: 0.605673\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531641; batch adversarial loss: 0.524502\n",
      "epoch 24; iter: 0; batch classifier loss: 0.407957; batch adversarial loss: 0.600052\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555707; batch adversarial loss: 0.485008\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471271; batch adversarial loss: 0.511600\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443156; batch adversarial loss: 0.598654\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491430; batch adversarial loss: 0.531528\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441680; batch adversarial loss: 0.501808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467950; batch adversarial loss: 0.571354\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366371; batch adversarial loss: 0.516116\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453749; batch adversarial loss: 0.479562\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406521; batch adversarial loss: 0.488578\n",
      "epoch 34; iter: 0; batch classifier loss: 0.541604; batch adversarial loss: 0.591909\n",
      "epoch 35; iter: 0; batch classifier loss: 0.409294; batch adversarial loss: 0.497952\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484078; batch adversarial loss: 0.589505\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472737; batch adversarial loss: 0.469961\n",
      "epoch 38; iter: 0; batch classifier loss: 0.500908; batch adversarial loss: 0.505421\n",
      "epoch 39; iter: 0; batch classifier loss: 0.526420; batch adversarial loss: 0.536216\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471022; batch adversarial loss: 0.535097\n",
      "epoch 41; iter: 0; batch classifier loss: 0.506368; batch adversarial loss: 0.533287\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454174; batch adversarial loss: 0.573536\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475732; batch adversarial loss: 0.532693\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428905; batch adversarial loss: 0.605194\n",
      "epoch 45; iter: 0; batch classifier loss: 0.494208; batch adversarial loss: 0.468327\n",
      "epoch 46; iter: 0; batch classifier loss: 0.513855; batch adversarial loss: 0.515338\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444350; batch adversarial loss: 0.562671\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415601; batch adversarial loss: 0.467039\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458784; batch adversarial loss: 0.526495\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418639; batch adversarial loss: 0.487940\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462770; batch adversarial loss: 0.516194\n",
      "epoch 52; iter: 0; batch classifier loss: 0.465223; batch adversarial loss: 0.611226\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400259; batch adversarial loss: 0.507248\n",
      "epoch 54; iter: 0; batch classifier loss: 0.358380; batch adversarial loss: 0.582198\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483929; batch adversarial loss: 0.506354\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393312; batch adversarial loss: 0.506518\n",
      "epoch 57; iter: 0; batch classifier loss: 0.501032; batch adversarial loss: 0.525539\n",
      "epoch 58; iter: 0; batch classifier loss: 0.479602; batch adversarial loss: 0.573230\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445690; batch adversarial loss: 0.544828\n",
      "epoch 60; iter: 0; batch classifier loss: 0.400466; batch adversarial loss: 0.496040\n",
      "epoch 61; iter: 0; batch classifier loss: 0.359779; batch adversarial loss: 0.516291\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446121; batch adversarial loss: 0.467983\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433761; batch adversarial loss: 0.525067\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411100; batch adversarial loss: 0.535130\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425436; batch adversarial loss: 0.553916\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437938; batch adversarial loss: 0.515913\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412339; batch adversarial loss: 0.554740\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460653; batch adversarial loss: 0.535599\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411941; batch adversarial loss: 0.496463\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388514; batch adversarial loss: 0.573901\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402827; batch adversarial loss: 0.544673\n",
      "epoch 72; iter: 0; batch classifier loss: 0.545231; batch adversarial loss: 0.525630\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437759; batch adversarial loss: 0.592835\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356815; batch adversarial loss: 0.602214\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409089; batch adversarial loss: 0.486808\n",
      "epoch 76; iter: 0; batch classifier loss: 0.417878; batch adversarial loss: 0.544700\n",
      "epoch 77; iter: 0; batch classifier loss: 0.451764; batch adversarial loss: 0.496334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.467895; batch adversarial loss: 0.544420\n",
      "epoch 79; iter: 0; batch classifier loss: 0.338860; batch adversarial loss: 0.640436\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436666; batch adversarial loss: 0.544629\n",
      "epoch 81; iter: 0; batch classifier loss: 0.457841; batch adversarial loss: 0.544522\n",
      "epoch 82; iter: 0; batch classifier loss: 0.441723; batch adversarial loss: 0.544699\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421043; batch adversarial loss: 0.563426\n",
      "epoch 84; iter: 0; batch classifier loss: 0.361039; batch adversarial loss: 0.477230\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406072; batch adversarial loss: 0.535244\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415018; batch adversarial loss: 0.496313\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369995; batch adversarial loss: 0.554237\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417518; batch adversarial loss: 0.630847\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388317; batch adversarial loss: 0.650307\n",
      "epoch 90; iter: 0; batch classifier loss: 0.382867; batch adversarial loss: 0.495900\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400938; batch adversarial loss: 0.562555\n",
      "epoch 92; iter: 0; batch classifier loss: 0.528883; batch adversarial loss: 0.583206\n",
      "epoch 93; iter: 0; batch classifier loss: 0.432139; batch adversarial loss: 0.535156\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452068; batch adversarial loss: 0.573381\n",
      "epoch 95; iter: 0; batch classifier loss: 0.493769; batch adversarial loss: 0.495637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.362290; batch adversarial loss: 0.458190\n",
      "epoch 97; iter: 0; batch classifier loss: 0.454884; batch adversarial loss: 0.506256\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386440; batch adversarial loss: 0.546051\n",
      "epoch 99; iter: 0; batch classifier loss: 0.457731; batch adversarial loss: 0.506493\n",
      "epoch 100; iter: 0; batch classifier loss: 0.449889; batch adversarial loss: 0.447492\n",
      "epoch 101; iter: 0; batch classifier loss: 0.410132; batch adversarial loss: 0.534998\n",
      "epoch 102; iter: 0; batch classifier loss: 0.404687; batch adversarial loss: 0.535045\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397753; batch adversarial loss: 0.574266\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341100; batch adversarial loss: 0.564340\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409883; batch adversarial loss: 0.564000\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441132; batch adversarial loss: 0.506092\n",
      "epoch 107; iter: 0; batch classifier loss: 0.426754; batch adversarial loss: 0.545025\n",
      "epoch 108; iter: 0; batch classifier loss: 0.394689; batch adversarial loss: 0.563974\n",
      "epoch 109; iter: 0; batch classifier loss: 0.326879; batch adversarial loss: 0.477052\n",
      "epoch 110; iter: 0; batch classifier loss: 0.427055; batch adversarial loss: 0.506367\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376538; batch adversarial loss: 0.583774\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370632; batch adversarial loss: 0.583825\n",
      "epoch 113; iter: 0; batch classifier loss: 0.416512; batch adversarial loss: 0.592939\n",
      "epoch 114; iter: 0; batch classifier loss: 0.407574; batch adversarial loss: 0.526050\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405277; batch adversarial loss: 0.496540\n",
      "epoch 116; iter: 0; batch classifier loss: 0.504751; batch adversarial loss: 0.535069\n",
      "epoch 117; iter: 0; batch classifier loss: 0.430921; batch adversarial loss: 0.554171\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401058; batch adversarial loss: 0.563867\n",
      "epoch 119; iter: 0; batch classifier loss: 0.437486; batch adversarial loss: 0.564351\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383017; batch adversarial loss: 0.535270\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366428; batch adversarial loss: 0.525194\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421009; batch adversarial loss: 0.582848\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414124; batch adversarial loss: 0.525826\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365886; batch adversarial loss: 0.506770\n",
      "epoch 125; iter: 0; batch classifier loss: 0.514749; batch adversarial loss: 0.535273\n",
      "epoch 126; iter: 0; batch classifier loss: 0.397209; batch adversarial loss: 0.573925\n",
      "epoch 127; iter: 0; batch classifier loss: 0.300515; batch adversarial loss: 0.506013\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411472; batch adversarial loss: 0.660801\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388016; batch adversarial loss: 0.563869\n",
      "epoch 130; iter: 0; batch classifier loss: 0.434343; batch adversarial loss: 0.544967\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375643; batch adversarial loss: 0.535931\n",
      "epoch 132; iter: 0; batch classifier loss: 0.307283; batch adversarial loss: 0.611949\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367293; batch adversarial loss: 0.612380\n",
      "epoch 134; iter: 0; batch classifier loss: 0.491153; batch adversarial loss: 0.601785\n",
      "epoch 135; iter: 0; batch classifier loss: 0.423756; batch adversarial loss: 0.525628\n",
      "epoch 136; iter: 0; batch classifier loss: 0.428969; batch adversarial loss: 0.515737\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352393; batch adversarial loss: 0.525557\n",
      "epoch 138; iter: 0; batch classifier loss: 0.452705; batch adversarial loss: 0.486900\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362999; batch adversarial loss: 0.554045\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349495; batch adversarial loss: 0.525106\n",
      "epoch 141; iter: 0; batch classifier loss: 0.488018; batch adversarial loss: 0.525617\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339296; batch adversarial loss: 0.535278\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370335; batch adversarial loss: 0.448547\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342772; batch adversarial loss: 0.458611\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412251; batch adversarial loss: 0.583468\n",
      "epoch 146; iter: 0; batch classifier loss: 0.392686; batch adversarial loss: 0.613137\n",
      "epoch 147; iter: 0; batch classifier loss: 0.331482; batch adversarial loss: 0.468129\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341815; batch adversarial loss: 0.525030\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339642; batch adversarial loss: 0.574119\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375916; batch adversarial loss: 0.476597\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408332; batch adversarial loss: 0.496332\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347277; batch adversarial loss: 0.554615\n",
      "epoch 153; iter: 0; batch classifier loss: 0.315124; batch adversarial loss: 0.487187\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402651; batch adversarial loss: 0.515911\n",
      "epoch 155; iter: 0; batch classifier loss: 0.428855; batch adversarial loss: 0.525723\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401990; batch adversarial loss: 0.516207\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377568; batch adversarial loss: 0.536047\n",
      "epoch 158; iter: 0; batch classifier loss: 0.316910; batch adversarial loss: 0.535170\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350068; batch adversarial loss: 0.554461\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386051; batch adversarial loss: 0.506791\n",
      "epoch 161; iter: 0; batch classifier loss: 0.446519; batch adversarial loss: 0.611800\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343652; batch adversarial loss: 0.555193\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342756; batch adversarial loss: 0.496444\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360363; batch adversarial loss: 0.506058\n",
      "epoch 165; iter: 0; batch classifier loss: 0.402177; batch adversarial loss: 0.583617\n",
      "epoch 166; iter: 0; batch classifier loss: 0.427744; batch adversarial loss: 0.457937\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364154; batch adversarial loss: 0.574046\n",
      "epoch 168; iter: 0; batch classifier loss: 0.286734; batch adversarial loss: 0.515733\n",
      "epoch 169; iter: 0; batch classifier loss: 0.383227; batch adversarial loss: 0.622214\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380319; batch adversarial loss: 0.467416\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383220; batch adversarial loss: 0.467547\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397401; batch adversarial loss: 0.525825\n",
      "epoch 173; iter: 0; batch classifier loss: 0.411811; batch adversarial loss: 0.555227\n",
      "epoch 174; iter: 0; batch classifier loss: 0.304765; batch adversarial loss: 0.534997\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351136; batch adversarial loss: 0.554589\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372250; batch adversarial loss: 0.496497\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381533; batch adversarial loss: 0.545194\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336571; batch adversarial loss: 0.563851\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298125; batch adversarial loss: 0.592953\n",
      "epoch 180; iter: 0; batch classifier loss: 0.383745; batch adversarial loss: 0.602590\n",
      "epoch 181; iter: 0; batch classifier loss: 0.313931; batch adversarial loss: 0.554265\n",
      "epoch 182; iter: 0; batch classifier loss: 0.332404; batch adversarial loss: 0.496568\n",
      "epoch 183; iter: 0; batch classifier loss: 0.444678; batch adversarial loss: 0.515780\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335556; batch adversarial loss: 0.573994\n",
      "epoch 185; iter: 0; batch classifier loss: 0.442390; batch adversarial loss: 0.495729\n",
      "epoch 186; iter: 0; batch classifier loss: 0.408023; batch adversarial loss: 0.574327\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332881; batch adversarial loss: 0.544404\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368474; batch adversarial loss: 0.526053\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351776; batch adversarial loss: 0.573846\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357007; batch adversarial loss: 0.622105\n",
      "epoch 191; iter: 0; batch classifier loss: 0.391964; batch adversarial loss: 0.506400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.375188; batch adversarial loss: 0.525527\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390324; batch adversarial loss: 0.515962\n",
      "epoch 194; iter: 0; batch classifier loss: 0.346671; batch adversarial loss: 0.563450\n",
      "epoch 195; iter: 0; batch classifier loss: 0.412853; batch adversarial loss: 0.515669\n",
      "epoch 196; iter: 0; batch classifier loss: 0.286615; batch adversarial loss: 0.428867\n",
      "epoch 197; iter: 0; batch classifier loss: 0.416780; batch adversarial loss: 0.535217\n",
      "epoch 198; iter: 0; batch classifier loss: 0.388435; batch adversarial loss: 0.515955\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387846; batch adversarial loss: 0.525644\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739404; batch adversarial loss: 0.599827\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603392; batch adversarial loss: 0.629798\n",
      "epoch 2; iter: 0; batch classifier loss: 0.620311; batch adversarial loss: 0.658025\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593614; batch adversarial loss: 0.648287\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588621; batch adversarial loss: 0.621884\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574697; batch adversarial loss: 0.619623\n",
      "epoch 6; iter: 0; batch classifier loss: 0.725720; batch adversarial loss: 0.569449\n",
      "epoch 7; iter: 0; batch classifier loss: 0.614801; batch adversarial loss: 0.646081\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533616; batch adversarial loss: 0.553030\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512554; batch adversarial loss: 0.620928\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558003; batch adversarial loss: 0.597510\n",
      "epoch 11; iter: 0; batch classifier loss: 0.629380; batch adversarial loss: 0.636158\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507263; batch adversarial loss: 0.585861\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518350; batch adversarial loss: 0.563356\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518302; batch adversarial loss: 0.583020\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508493; batch adversarial loss: 0.573399\n",
      "epoch 16; iter: 0; batch classifier loss: 0.474993; batch adversarial loss: 0.581350\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557833; batch adversarial loss: 0.590199\n",
      "epoch 18; iter: 0; batch classifier loss: 0.457269; batch adversarial loss: 0.556543\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490755; batch adversarial loss: 0.587686\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510962; batch adversarial loss: 0.566377\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462374; batch adversarial loss: 0.524446\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519788; batch adversarial loss: 0.511486\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452883; batch adversarial loss: 0.560342\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547302; batch adversarial loss: 0.539410\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453664; batch adversarial loss: 0.563909\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438287; batch adversarial loss: 0.597188\n",
      "epoch 27; iter: 0; batch classifier loss: 0.527844; batch adversarial loss: 0.518198\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402121; batch adversarial loss: 0.556088\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439372; batch adversarial loss: 0.553362\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513375; batch adversarial loss: 0.565015\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469111; batch adversarial loss: 0.555868\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438904; batch adversarial loss: 0.554019\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445826; batch adversarial loss: 0.518822\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476435; batch adversarial loss: 0.535192\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478166; batch adversarial loss: 0.605929\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414815; batch adversarial loss: 0.617743\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428886; batch adversarial loss: 0.579445\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461048; batch adversarial loss: 0.553575\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445649; batch adversarial loss: 0.596883\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457202; batch adversarial loss: 0.580084\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443163; batch adversarial loss: 0.588974\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414507; batch adversarial loss: 0.479628\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453459; batch adversarial loss: 0.616834\n",
      "epoch 44; iter: 0; batch classifier loss: 0.425229; batch adversarial loss: 0.523943\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416719; batch adversarial loss: 0.543743\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454322; batch adversarial loss: 0.525762\n",
      "epoch 47; iter: 0; batch classifier loss: 0.508217; batch adversarial loss: 0.489018\n",
      "epoch 48; iter: 0; batch classifier loss: 0.463437; batch adversarial loss: 0.507688\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444313; batch adversarial loss: 0.593785\n",
      "epoch 50; iter: 0; batch classifier loss: 0.351522; batch adversarial loss: 0.553416\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432157; batch adversarial loss: 0.572026\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445805; batch adversarial loss: 0.515747\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403246; batch adversarial loss: 0.563542\n",
      "epoch 54; iter: 0; batch classifier loss: 0.373162; batch adversarial loss: 0.471325\n",
      "epoch 55; iter: 0; batch classifier loss: 0.337402; batch adversarial loss: 0.534570\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416340; batch adversarial loss: 0.625838\n",
      "epoch 57; iter: 0; batch classifier loss: 0.477734; batch adversarial loss: 0.580951\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472620; batch adversarial loss: 0.553465\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435322; batch adversarial loss: 0.571007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.352645; batch adversarial loss: 0.535370\n",
      "epoch 61; iter: 0; batch classifier loss: 0.495501; batch adversarial loss: 0.580878\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436594; batch adversarial loss: 0.644999\n",
      "epoch 63; iter: 0; batch classifier loss: 0.437092; batch adversarial loss: 0.518030\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387784; batch adversarial loss: 0.535596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413778; batch adversarial loss: 0.607843\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422381; batch adversarial loss: 0.544074\n",
      "epoch 67; iter: 0; batch classifier loss: 0.541265; batch adversarial loss: 0.664751\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380417; batch adversarial loss: 0.488768\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401734; batch adversarial loss: 0.499294\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455014; batch adversarial loss: 0.582282\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431833; batch adversarial loss: 0.516784\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390337; batch adversarial loss: 0.526089\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423785; batch adversarial loss: 0.461719\n",
      "epoch 74; iter: 0; batch classifier loss: 0.369691; batch adversarial loss: 0.544860\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386694; batch adversarial loss: 0.517427\n",
      "epoch 76; iter: 0; batch classifier loss: 0.433794; batch adversarial loss: 0.508395\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436172; batch adversarial loss: 0.543531\n",
      "epoch 78; iter: 0; batch classifier loss: 0.418064; batch adversarial loss: 0.481243\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378508; batch adversarial loss: 0.554116\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411542; batch adversarial loss: 0.546880\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356938; batch adversarial loss: 0.580663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435564; batch adversarial loss: 0.432554\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371486; batch adversarial loss: 0.553502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398267; batch adversarial loss: 0.453071\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382757; batch adversarial loss: 0.608336\n",
      "epoch 86; iter: 0; batch classifier loss: 0.393923; batch adversarial loss: 0.572414\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378657; batch adversarial loss: 0.535876\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389815; batch adversarial loss: 0.508573\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355506; batch adversarial loss: 0.517357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.395773; batch adversarial loss: 0.500039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394824; batch adversarial loss: 0.498877\n",
      "epoch 92; iter: 0; batch classifier loss: 0.446633; batch adversarial loss: 0.553848\n",
      "epoch 93; iter: 0; batch classifier loss: 0.343234; batch adversarial loss: 0.498454\n",
      "epoch 94; iter: 0; batch classifier loss: 0.341464; batch adversarial loss: 0.590521\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431805; batch adversarial loss: 0.581617\n",
      "epoch 96; iter: 0; batch classifier loss: 0.484498; batch adversarial loss: 0.535210\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404456; batch adversarial loss: 0.626763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388611; batch adversarial loss: 0.562206\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384012; batch adversarial loss: 0.554054\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388734; batch adversarial loss: 0.599265\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402491; batch adversarial loss: 0.499130\n",
      "epoch 102; iter: 0; batch classifier loss: 0.333994; batch adversarial loss: 0.535333\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360861; batch adversarial loss: 0.480128\n",
      "epoch 104; iter: 0; batch classifier loss: 0.382963; batch adversarial loss: 0.525819\n",
      "epoch 105; iter: 0; batch classifier loss: 0.298658; batch adversarial loss: 0.534788\n",
      "epoch 106; iter: 0; batch classifier loss: 0.332032; batch adversarial loss: 0.497882\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348739; batch adversarial loss: 0.599486\n",
      "epoch 108; iter: 0; batch classifier loss: 0.459633; batch adversarial loss: 0.499781\n",
      "epoch 109; iter: 0; batch classifier loss: 0.408732; batch adversarial loss: 0.571866\n",
      "epoch 110; iter: 0; batch classifier loss: 0.330462; batch adversarial loss: 0.544283\n",
      "epoch 111; iter: 0; batch classifier loss: 0.422983; batch adversarial loss: 0.562774\n",
      "epoch 112; iter: 0; batch classifier loss: 0.344934; batch adversarial loss: 0.554646\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379714; batch adversarial loss: 0.469995\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382303; batch adversarial loss: 0.434904\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417245; batch adversarial loss: 0.553528\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364490; batch adversarial loss: 0.554109\n",
      "epoch 117; iter: 0; batch classifier loss: 0.433844; batch adversarial loss: 0.635697\n",
      "epoch 118; iter: 0; batch classifier loss: 0.435329; batch adversarial loss: 0.534411\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383766; batch adversarial loss: 0.598507\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356232; batch adversarial loss: 0.572565\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346577; batch adversarial loss: 0.516321\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397446; batch adversarial loss: 0.580941\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399114; batch adversarial loss: 0.462610\n",
      "epoch 124; iter: 0; batch classifier loss: 0.314273; batch adversarial loss: 0.507635\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404161; batch adversarial loss: 0.498983\n",
      "epoch 126; iter: 0; batch classifier loss: 0.389390; batch adversarial loss: 0.590315\n",
      "epoch 127; iter: 0; batch classifier loss: 0.324409; batch adversarial loss: 0.544679\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373318; batch adversarial loss: 0.535415\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374188; batch adversarial loss: 0.553522\n",
      "epoch 130; iter: 0; batch classifier loss: 0.422506; batch adversarial loss: 0.562966\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383766; batch adversarial loss: 0.480461\n",
      "epoch 132; iter: 0; batch classifier loss: 0.374431; batch adversarial loss: 0.535277\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334423; batch adversarial loss: 0.526179\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403023; batch adversarial loss: 0.626605\n",
      "epoch 135; iter: 0; batch classifier loss: 0.359171; batch adversarial loss: 0.635453\n",
      "epoch 136; iter: 0; batch classifier loss: 0.423690; batch adversarial loss: 0.498941\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401577; batch adversarial loss: 0.535066\n",
      "epoch 138; iter: 0; batch classifier loss: 0.329022; batch adversarial loss: 0.507085\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313565; batch adversarial loss: 0.553468\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335037; batch adversarial loss: 0.498049\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343194; batch adversarial loss: 0.572504\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363512; batch adversarial loss: 0.572827\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348129; batch adversarial loss: 0.564227\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390735; batch adversarial loss: 0.674488\n",
      "epoch 145; iter: 0; batch classifier loss: 0.330763; batch adversarial loss: 0.589329\n",
      "epoch 146; iter: 0; batch classifier loss: 0.397795; batch adversarial loss: 0.490224\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345646; batch adversarial loss: 0.590345\n",
      "epoch 148; iter: 0; batch classifier loss: 0.444475; batch adversarial loss: 0.554581\n",
      "epoch 149; iter: 0; batch classifier loss: 0.409071; batch adversarial loss: 0.526599\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392626; batch adversarial loss: 0.597784\n",
      "epoch 151; iter: 0; batch classifier loss: 0.423107; batch adversarial loss: 0.562862\n",
      "epoch 152; iter: 0; batch classifier loss: 0.381599; batch adversarial loss: 0.553407\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348305; batch adversarial loss: 0.543222\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370336; batch adversarial loss: 0.489984\n",
      "epoch 155; iter: 0; batch classifier loss: 0.332337; batch adversarial loss: 0.516392\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349010; batch adversarial loss: 0.498940\n",
      "epoch 157; iter: 0; batch classifier loss: 0.418559; batch adversarial loss: 0.507957\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375069; batch adversarial loss: 0.490767\n",
      "epoch 159; iter: 0; batch classifier loss: 0.364126; batch adversarial loss: 0.508625\n",
      "epoch 160; iter: 0; batch classifier loss: 0.399461; batch adversarial loss: 0.508472\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346765; batch adversarial loss: 0.544651\n",
      "epoch 162; iter: 0; batch classifier loss: 0.362200; batch adversarial loss: 0.643969\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336934; batch adversarial loss: 0.627017\n",
      "epoch 164; iter: 0; batch classifier loss: 0.280099; batch adversarial loss: 0.500038\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397620; batch adversarial loss: 0.562029\n",
      "epoch 166; iter: 0; batch classifier loss: 0.300261; batch adversarial loss: 0.535395\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364151; batch adversarial loss: 0.562913\n",
      "epoch 168; iter: 0; batch classifier loss: 0.309832; batch adversarial loss: 0.598848\n",
      "epoch 169; iter: 0; batch classifier loss: 0.346263; batch adversarial loss: 0.535398\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374142; batch adversarial loss: 0.508166\n",
      "epoch 171; iter: 0; batch classifier loss: 0.400429; batch adversarial loss: 0.589748\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385345; batch adversarial loss: 0.571710\n",
      "epoch 173; iter: 0; batch classifier loss: 0.420297; batch adversarial loss: 0.608035\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387381; batch adversarial loss: 0.589888\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328966; batch adversarial loss: 0.617706\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310016; batch adversarial loss: 0.608605\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381952; batch adversarial loss: 0.508009\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351912; batch adversarial loss: 0.581054\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386720; batch adversarial loss: 0.599375\n",
      "epoch 180; iter: 0; batch classifier loss: 0.442862; batch adversarial loss: 0.480638\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361898; batch adversarial loss: 0.571923\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389204; batch adversarial loss: 0.498925\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382737; batch adversarial loss: 0.562771\n",
      "epoch 184; iter: 0; batch classifier loss: 0.405604; batch adversarial loss: 0.489802\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397824; batch adversarial loss: 0.617479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.333160; batch adversarial loss: 0.517139\n",
      "epoch 187; iter: 0; batch classifier loss: 0.392225; batch adversarial loss: 0.508081\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346735; batch adversarial loss: 0.516848\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377494; batch adversarial loss: 0.526149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.334849; batch adversarial loss: 0.599089\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347972; batch adversarial loss: 0.581547\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363486; batch adversarial loss: 0.580486\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327909; batch adversarial loss: 0.581404\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.581494\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379164; batch adversarial loss: 0.562299\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351511; batch adversarial loss: 0.572053\n",
      "epoch 197; iter: 0; batch classifier loss: 0.307756; batch adversarial loss: 0.608281\n",
      "epoch 198; iter: 0; batch classifier loss: 0.252677; batch adversarial loss: 0.608106\n",
      "epoch 199; iter: 0; batch classifier loss: 0.372040; batch adversarial loss: 0.553458\n",
      "epoch 0; iter: 0; batch classifier loss: 0.751705; batch adversarial loss: 0.567909\n",
      "epoch 1; iter: 0; batch classifier loss: 0.673567; batch adversarial loss: 0.636775\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575872; batch adversarial loss: 0.664981\n",
      "epoch 3; iter: 0; batch classifier loss: 0.626569; batch adversarial loss: 0.730017\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568551; batch adversarial loss: 0.613422\n",
      "epoch 5; iter: 0; batch classifier loss: 0.609224; batch adversarial loss: 0.668546\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544484; batch adversarial loss: 0.684393\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556166; batch adversarial loss: 0.627762\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570991; batch adversarial loss: 0.645815\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563802; batch adversarial loss: 0.577594\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521688; batch adversarial loss: 0.598229\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470748; batch adversarial loss: 0.586016\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538962; batch adversarial loss: 0.594366\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555224; batch adversarial loss: 0.548346\n",
      "epoch 14; iter: 0; batch classifier loss: 0.445085; batch adversarial loss: 0.623233\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570725; batch adversarial loss: 0.578959\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540051; batch adversarial loss: 0.586813\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520686; batch adversarial loss: 0.520700\n",
      "epoch 18; iter: 0; batch classifier loss: 0.581257; batch adversarial loss: 0.543360\n",
      "epoch 19; iter: 0; batch classifier loss: 0.454098; batch adversarial loss: 0.558190\n",
      "epoch 20; iter: 0; batch classifier loss: 0.458215; batch adversarial loss: 0.601817\n",
      "epoch 21; iter: 0; batch classifier loss: 0.465836; batch adversarial loss: 0.508246\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464418; batch adversarial loss: 0.567832\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460851; batch adversarial loss: 0.591174\n",
      "epoch 24; iter: 0; batch classifier loss: 0.449067; batch adversarial loss: 0.597041\n",
      "epoch 25; iter: 0; batch classifier loss: 0.477507; batch adversarial loss: 0.626124\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485186; batch adversarial loss: 0.572067\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439030; batch adversarial loss: 0.566881\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513444; batch adversarial loss: 0.512252\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468159; batch adversarial loss: 0.557612\n",
      "epoch 30; iter: 0; batch classifier loss: 0.523919; batch adversarial loss: 0.542405\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414443; batch adversarial loss: 0.560800\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470742; batch adversarial loss: 0.503633\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468302; batch adversarial loss: 0.557256\n",
      "epoch 34; iter: 0; batch classifier loss: 0.562096; batch adversarial loss: 0.543520\n",
      "epoch 35; iter: 0; batch classifier loss: 0.494148; batch adversarial loss: 0.580168\n",
      "epoch 36; iter: 0; batch classifier loss: 0.593470; batch adversarial loss: 0.474986\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445942; batch adversarial loss: 0.544779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.383029; batch adversarial loss: 0.544281\n",
      "epoch 39; iter: 0; batch classifier loss: 0.412354; batch adversarial loss: 0.534423\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404478; batch adversarial loss: 0.542946\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483235; batch adversarial loss: 0.589441\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490708; batch adversarial loss: 0.562969\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477474; batch adversarial loss: 0.590112\n",
      "epoch 44; iter: 0; batch classifier loss: 0.503647; batch adversarial loss: 0.552849\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403125; batch adversarial loss: 0.508362\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471676; batch adversarial loss: 0.491018\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478368; batch adversarial loss: 0.544606\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442562; batch adversarial loss: 0.571614\n",
      "epoch 49; iter: 0; batch classifier loss: 0.481089; batch adversarial loss: 0.598876\n",
      "epoch 50; iter: 0; batch classifier loss: 0.363196; batch adversarial loss: 0.625925\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434251; batch adversarial loss: 0.589180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.463100; batch adversarial loss: 0.535037\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431832; batch adversarial loss: 0.562525\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440308; batch adversarial loss: 0.553315\n",
      "epoch 55; iter: 0; batch classifier loss: 0.516878; batch adversarial loss: 0.579441\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454842; batch adversarial loss: 0.526956\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392358; batch adversarial loss: 0.678156\n",
      "epoch 58; iter: 0; batch classifier loss: 0.412750; batch adversarial loss: 0.536150\n",
      "epoch 59; iter: 0; batch classifier loss: 0.497400; batch adversarial loss: 0.544561\n",
      "epoch 60; iter: 0; batch classifier loss: 0.503973; batch adversarial loss: 0.517617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424404; batch adversarial loss: 0.616196\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436913; batch adversarial loss: 0.571389\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432918; batch adversarial loss: 0.544485\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413798; batch adversarial loss: 0.544379\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432113; batch adversarial loss: 0.517372\n",
      "epoch 66; iter: 0; batch classifier loss: 0.482979; batch adversarial loss: 0.544780\n",
      "epoch 67; iter: 0; batch classifier loss: 0.463358; batch adversarial loss: 0.535778\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430201; batch adversarial loss: 0.535791\n",
      "epoch 69; iter: 0; batch classifier loss: 0.343631; batch adversarial loss: 0.570797\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445346; batch adversarial loss: 0.544151\n",
      "epoch 71; iter: 0; batch classifier loss: 0.506863; batch adversarial loss: 0.563672\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430458; batch adversarial loss: 0.473100\n",
      "epoch 73; iter: 0; batch classifier loss: 0.457834; batch adversarial loss: 0.563711\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437589; batch adversarial loss: 0.642125\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422578; batch adversarial loss: 0.474587\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397967; batch adversarial loss: 0.590178\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391531; batch adversarial loss: 0.544457\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416481; batch adversarial loss: 0.544704\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387738; batch adversarial loss: 0.534462\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437392; batch adversarial loss: 0.545534\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386418; batch adversarial loss: 0.533848\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395597; batch adversarial loss: 0.626905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.405769; batch adversarial loss: 0.520397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368970; batch adversarial loss: 0.489612\n",
      "epoch 85; iter: 0; batch classifier loss: 0.379141; batch adversarial loss: 0.662168\n",
      "epoch 86; iter: 0; batch classifier loss: 0.341381; batch adversarial loss: 0.497542\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347467; batch adversarial loss: 0.498494\n",
      "epoch 88; iter: 0; batch classifier loss: 0.452918; batch adversarial loss: 0.534359\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427085; batch adversarial loss: 0.489288\n",
      "epoch 90; iter: 0; batch classifier loss: 0.379531; batch adversarial loss: 0.598949\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377260; batch adversarial loss: 0.540101\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418643; batch adversarial loss: 0.553376\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381220; batch adversarial loss: 0.541787\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422890; batch adversarial loss: 0.567538\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430499; batch adversarial loss: 0.474417\n",
      "epoch 96; iter: 0; batch classifier loss: 0.311276; batch adversarial loss: 0.483439\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378405; batch adversarial loss: 0.565921\n",
      "epoch 98; iter: 0; batch classifier loss: 0.441349; batch adversarial loss: 0.581786\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385719; batch adversarial loss: 0.597818\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401097; batch adversarial loss: 0.482512\n",
      "epoch 101; iter: 0; batch classifier loss: 0.378923; batch adversarial loss: 0.492668\n",
      "epoch 102; iter: 0; batch classifier loss: 0.403521; batch adversarial loss: 0.500920\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411964; batch adversarial loss: 0.570051\n",
      "epoch 104; iter: 0; batch classifier loss: 0.427078; batch adversarial loss: 0.544466\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394013; batch adversarial loss: 0.632260\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382953; batch adversarial loss: 0.590470\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374819; batch adversarial loss: 0.552840\n",
      "epoch 108; iter: 0; batch classifier loss: 0.425600; batch adversarial loss: 0.519623\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370165; batch adversarial loss: 0.579443\n",
      "epoch 110; iter: 0; batch classifier loss: 0.306552; batch adversarial loss: 0.571365\n",
      "epoch 111; iter: 0; batch classifier loss: 0.410730; batch adversarial loss: 0.526777\n",
      "epoch 112; iter: 0; batch classifier loss: 0.320216; batch adversarial loss: 0.544577\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413844; batch adversarial loss: 0.543935\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422912; batch adversarial loss: 0.589149\n",
      "epoch 115; iter: 0; batch classifier loss: 0.330815; batch adversarial loss: 0.490669\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390213; batch adversarial loss: 0.562089\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406568; batch adversarial loss: 0.571443\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367802; batch adversarial loss: 0.571704\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399496; batch adversarial loss: 0.509427\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413215; batch adversarial loss: 0.598179\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406564; batch adversarial loss: 0.553407\n",
      "epoch 122; iter: 0; batch classifier loss: 0.422343; batch adversarial loss: 0.589976\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331882; batch adversarial loss: 0.580668\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386387; batch adversarial loss: 0.588676\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392708; batch adversarial loss: 0.534099\n",
      "epoch 126; iter: 0; batch classifier loss: 0.411936; batch adversarial loss: 0.437687\n",
      "epoch 127; iter: 0; batch classifier loss: 0.402746; batch adversarial loss: 0.545564\n",
      "epoch 128; iter: 0; batch classifier loss: 0.416931; batch adversarial loss: 0.554103\n",
      "epoch 129; iter: 0; batch classifier loss: 0.383007; batch adversarial loss: 0.641934\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376603; batch adversarial loss: 0.517517\n",
      "epoch 131; iter: 0; batch classifier loss: 0.404120; batch adversarial loss: 0.553246\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358364; batch adversarial loss: 0.589984\n",
      "epoch 133; iter: 0; batch classifier loss: 0.327229; batch adversarial loss: 0.499919\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381483; batch adversarial loss: 0.552461\n",
      "epoch 135; iter: 0; batch classifier loss: 0.407775; batch adversarial loss: 0.517065\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364421; batch adversarial loss: 0.651116\n",
      "epoch 137; iter: 0; batch classifier loss: 0.437918; batch adversarial loss: 0.534954\n",
      "epoch 138; iter: 0; batch classifier loss: 0.352789; batch adversarial loss: 0.482474\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408187; batch adversarial loss: 0.517689\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365588; batch adversarial loss: 0.553888\n",
      "epoch 141; iter: 0; batch classifier loss: 0.482383; batch adversarial loss: 0.510478\n",
      "epoch 142; iter: 0; batch classifier loss: 0.281903; batch adversarial loss: 0.500609\n",
      "epoch 143; iter: 0; batch classifier loss: 0.324725; batch adversarial loss: 0.580807\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348972; batch adversarial loss: 0.537145\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383482; batch adversarial loss: 0.624662\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379475; batch adversarial loss: 0.615497\n",
      "epoch 147; iter: 0; batch classifier loss: 0.367348; batch adversarial loss: 0.580461\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358316; batch adversarial loss: 0.500704\n",
      "epoch 149; iter: 0; batch classifier loss: 0.421982; batch adversarial loss: 0.600032\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372320; batch adversarial loss: 0.456627\n",
      "epoch 151; iter: 0; batch classifier loss: 0.456014; batch adversarial loss: 0.544728\n",
      "epoch 152; iter: 0; batch classifier loss: 0.284015; batch adversarial loss: 0.501070\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353312; batch adversarial loss: 0.517883\n",
      "epoch 154; iter: 0; batch classifier loss: 0.415456; batch adversarial loss: 0.518341\n",
      "epoch 155; iter: 0; batch classifier loss: 0.402574; batch adversarial loss: 0.482674\n",
      "epoch 156; iter: 0; batch classifier loss: 0.379782; batch adversarial loss: 0.518408\n",
      "epoch 157; iter: 0; batch classifier loss: 0.406814; batch adversarial loss: 0.499824\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361662; batch adversarial loss: 0.553429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388324; batch adversarial loss: 0.571449\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372620; batch adversarial loss: 0.570414\n",
      "epoch 161; iter: 0; batch classifier loss: 0.435183; batch adversarial loss: 0.579802\n",
      "epoch 162; iter: 0; batch classifier loss: 0.398096; batch adversarial loss: 0.598418\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344881; batch adversarial loss: 0.544382\n",
      "epoch 164; iter: 0; batch classifier loss: 0.306252; batch adversarial loss: 0.535385\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405449; batch adversarial loss: 0.570930\n",
      "epoch 166; iter: 0; batch classifier loss: 0.390350; batch adversarial loss: 0.536525\n",
      "epoch 167; iter: 0; batch classifier loss: 0.410209; batch adversarial loss: 0.582221\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395010; batch adversarial loss: 0.482438\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381832; batch adversarial loss: 0.518054\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374231; batch adversarial loss: 0.581329\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344020; batch adversarial loss: 0.579946\n",
      "epoch 172; iter: 0; batch classifier loss: 0.430503; batch adversarial loss: 0.536118\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343376; batch adversarial loss: 0.544465\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393933; batch adversarial loss: 0.545315\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383930; batch adversarial loss: 0.588365\n",
      "epoch 176; iter: 0; batch classifier loss: 0.427141; batch adversarial loss: 0.525782\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337809; batch adversarial loss: 0.526178\n",
      "epoch 178; iter: 0; batch classifier loss: 0.327507; batch adversarial loss: 0.526422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.342552; batch adversarial loss: 0.562988\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315022; batch adversarial loss: 0.535783\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331530; batch adversarial loss: 0.615603\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344479; batch adversarial loss: 0.509772\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371307; batch adversarial loss: 0.527589\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358855; batch adversarial loss: 0.615157\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379198; batch adversarial loss: 0.598977\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315139; batch adversarial loss: 0.517874\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356960; batch adversarial loss: 0.518056\n",
      "epoch 188; iter: 0; batch classifier loss: 0.417177; batch adversarial loss: 0.553863\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364899; batch adversarial loss: 0.526659\n",
      "epoch 190; iter: 0; batch classifier loss: 0.410663; batch adversarial loss: 0.509169\n",
      "epoch 191; iter: 0; batch classifier loss: 0.408685; batch adversarial loss: 0.571578\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355430; batch adversarial loss: 0.517754\n",
      "epoch 193; iter: 0; batch classifier loss: 0.322575; batch adversarial loss: 0.526972\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372707; batch adversarial loss: 0.562615\n",
      "epoch 195; iter: 0; batch classifier loss: 0.429965; batch adversarial loss: 0.633014\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334291; batch adversarial loss: 0.598174\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320713; batch adversarial loss: 0.508693\n",
      "epoch 198; iter: 0; batch classifier loss: 0.330715; batch adversarial loss: 0.562055\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396192; batch adversarial loss: 0.508401\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692928; batch adversarial loss: 0.731605\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559048; batch adversarial loss: 0.693025\n",
      "epoch 2; iter: 0; batch classifier loss: 0.657897; batch adversarial loss: 0.675519\n",
      "epoch 3; iter: 0; batch classifier loss: 0.480190; batch adversarial loss: 0.659042\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603297; batch adversarial loss: 0.636904\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549669; batch adversarial loss: 0.604123\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597938; batch adversarial loss: 0.591339\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578469; batch adversarial loss: 0.590287\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533828; batch adversarial loss: 0.558008\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537040; batch adversarial loss: 0.574102\n",
      "epoch 10; iter: 0; batch classifier loss: 0.454471; batch adversarial loss: 0.537981\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535730; batch adversarial loss: 0.573696\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489116; batch adversarial loss: 0.588288\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473966; batch adversarial loss: 0.591419\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498503; batch adversarial loss: 0.562525\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578087; batch adversarial loss: 0.529527\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505218; batch adversarial loss: 0.601067\n",
      "epoch 17; iter: 0; batch classifier loss: 0.600371; batch adversarial loss: 0.586351\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472941; batch adversarial loss: 0.552680\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550600; batch adversarial loss: 0.564936\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451531; batch adversarial loss: 0.497481\n",
      "epoch 21; iter: 0; batch classifier loss: 0.553244; batch adversarial loss: 0.561823\n",
      "epoch 22; iter: 0; batch classifier loss: 0.557480; batch adversarial loss: 0.586982\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445280; batch adversarial loss: 0.588677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.523094; batch adversarial loss: 0.562164\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518091; batch adversarial loss: 0.569633\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505267; batch adversarial loss: 0.568592\n",
      "epoch 27; iter: 0; batch classifier loss: 0.544455; batch adversarial loss: 0.588454\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452793; batch adversarial loss: 0.600994\n",
      "epoch 29; iter: 0; batch classifier loss: 0.427461; batch adversarial loss: 0.568636\n",
      "epoch 30; iter: 0; batch classifier loss: 0.524622; batch adversarial loss: 0.591954\n",
      "epoch 31; iter: 0; batch classifier loss: 0.450627; batch adversarial loss: 0.547470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444300; batch adversarial loss: 0.489610\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469343; batch adversarial loss: 0.543427\n",
      "epoch 34; iter: 0; batch classifier loss: 0.388068; batch adversarial loss: 0.586314\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443946; batch adversarial loss: 0.579618\n",
      "epoch 36; iter: 0; batch classifier loss: 0.488239; batch adversarial loss: 0.623237\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441616; batch adversarial loss: 0.528190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438394; batch adversarial loss: 0.518947\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415125; batch adversarial loss: 0.561013\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474300; batch adversarial loss: 0.510496\n",
      "epoch 41; iter: 0; batch classifier loss: 0.507095; batch adversarial loss: 0.569402\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469404; batch adversarial loss: 0.569499\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449167; batch adversarial loss: 0.544089\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445408; batch adversarial loss: 0.571260\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376844; batch adversarial loss: 0.552739\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418188; batch adversarial loss: 0.517271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.358941; batch adversarial loss: 0.509286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419403; batch adversarial loss: 0.631931\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394489; batch adversarial loss: 0.618273\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442502; batch adversarial loss: 0.563581\n",
      "epoch 51; iter: 0; batch classifier loss: 0.396714; batch adversarial loss: 0.543485\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429805; batch adversarial loss: 0.589184\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442971; batch adversarial loss: 0.598066\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437370; batch adversarial loss: 0.527000\n",
      "epoch 55; iter: 0; batch classifier loss: 0.438412; batch adversarial loss: 0.605828\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404255; batch adversarial loss: 0.562533\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448853; batch adversarial loss: 0.563103\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399405; batch adversarial loss: 0.519387\n",
      "epoch 59; iter: 0; batch classifier loss: 0.474904; batch adversarial loss: 0.552508\n",
      "epoch 60; iter: 0; batch classifier loss: 0.516143; batch adversarial loss: 0.545640\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411561; batch adversarial loss: 0.546047\n",
      "epoch 62; iter: 0; batch classifier loss: 0.469705; batch adversarial loss: 0.581377\n",
      "epoch 63; iter: 0; batch classifier loss: 0.344335; batch adversarial loss: 0.544774\n",
      "epoch 64; iter: 0; batch classifier loss: 0.374037; batch adversarial loss: 0.518971\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385600; batch adversarial loss: 0.562400\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443780; batch adversarial loss: 0.536838\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413513; batch adversarial loss: 0.589580\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442635; batch adversarial loss: 0.499861\n",
      "epoch 69; iter: 0; batch classifier loss: 0.351736; batch adversarial loss: 0.562517\n",
      "epoch 70; iter: 0; batch classifier loss: 0.437069; batch adversarial loss: 0.581565\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403109; batch adversarial loss: 0.516952\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411449; batch adversarial loss: 0.553591\n",
      "epoch 73; iter: 0; batch classifier loss: 0.337632; batch adversarial loss: 0.527540\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410716; batch adversarial loss: 0.580036\n",
      "epoch 75; iter: 0; batch classifier loss: 0.414098; batch adversarial loss: 0.538211\n",
      "epoch 76; iter: 0; batch classifier loss: 0.487044; batch adversarial loss: 0.526917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.453855; batch adversarial loss: 0.500761\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397554; batch adversarial loss: 0.553391\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437131; batch adversarial loss: 0.473623\n",
      "epoch 80; iter: 0; batch classifier loss: 0.450909; batch adversarial loss: 0.462181\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389042; batch adversarial loss: 0.554063\n",
      "epoch 82; iter: 0; batch classifier loss: 0.354244; batch adversarial loss: 0.573889\n",
      "epoch 83; iter: 0; batch classifier loss: 0.309020; batch adversarial loss: 0.493329\n",
      "epoch 84; iter: 0; batch classifier loss: 0.420331; batch adversarial loss: 0.588610\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376050; batch adversarial loss: 0.511099\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417244; batch adversarial loss: 0.508046\n",
      "epoch 87; iter: 0; batch classifier loss: 0.464546; batch adversarial loss: 0.562243\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402657; batch adversarial loss: 0.553236\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428028; batch adversarial loss: 0.570895\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411573; batch adversarial loss: 0.536326\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354521; batch adversarial loss: 0.597309\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355674; batch adversarial loss: 0.535553\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413942; batch adversarial loss: 0.545880\n",
      "epoch 94; iter: 0; batch classifier loss: 0.349236; batch adversarial loss: 0.535052\n",
      "epoch 95; iter: 0; batch classifier loss: 0.485382; batch adversarial loss: 0.544062\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391067; batch adversarial loss: 0.526181\n",
      "epoch 97; iter: 0; batch classifier loss: 0.468178; batch adversarial loss: 0.544217\n",
      "epoch 98; iter: 0; batch classifier loss: 0.360642; batch adversarial loss: 0.606485\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369140; batch adversarial loss: 0.544646\n",
      "epoch 100; iter: 0; batch classifier loss: 0.486380; batch adversarial loss: 0.544309\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376857; batch adversarial loss: 0.643072\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376013; batch adversarial loss: 0.607945\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360501; batch adversarial loss: 0.581883\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383403; batch adversarial loss: 0.598247\n",
      "epoch 105; iter: 0; batch classifier loss: 0.422311; batch adversarial loss: 0.525831\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382544; batch adversarial loss: 0.500928\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431676; batch adversarial loss: 0.596947\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407639; batch adversarial loss: 0.582484\n",
      "epoch 109; iter: 0; batch classifier loss: 0.521226; batch adversarial loss: 0.510131\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385619; batch adversarial loss: 0.562676\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405987; batch adversarial loss: 0.545176\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351031; batch adversarial loss: 0.554234\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381095; batch adversarial loss: 0.552746\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327882; batch adversarial loss: 0.560256\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412925; batch adversarial loss: 0.462194\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391805; batch adversarial loss: 0.508680\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368490; batch adversarial loss: 0.578895\n",
      "epoch 118; iter: 0; batch classifier loss: 0.321816; batch adversarial loss: 0.535010\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342257; batch adversarial loss: 0.561206\n",
      "epoch 120; iter: 0; batch classifier loss: 0.332816; batch adversarial loss: 0.561123\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369719; batch adversarial loss: 0.544531\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372025; batch adversarial loss: 0.498501\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369262; batch adversarial loss: 0.509392\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372461; batch adversarial loss: 0.562237\n",
      "epoch 125; iter: 0; batch classifier loss: 0.426780; batch adversarial loss: 0.642756\n",
      "epoch 126; iter: 0; batch classifier loss: 0.449563; batch adversarial loss: 0.482851\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368814; batch adversarial loss: 0.545007\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362512; batch adversarial loss: 0.491460\n",
      "epoch 129; iter: 0; batch classifier loss: 0.331720; batch adversarial loss: 0.490464\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341316; batch adversarial loss: 0.565020\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364837; batch adversarial loss: 0.533821\n",
      "epoch 132; iter: 0; batch classifier loss: 0.309578; batch adversarial loss: 0.571680\n",
      "epoch 133; iter: 0; batch classifier loss: 0.323415; batch adversarial loss: 0.501179\n",
      "epoch 134; iter: 0; batch classifier loss: 0.322931; batch adversarial loss: 0.579830\n",
      "epoch 135; iter: 0; batch classifier loss: 0.390680; batch adversarial loss: 0.556577\n",
      "epoch 136; iter: 0; batch classifier loss: 0.284406; batch adversarial loss: 0.553315\n",
      "epoch 137; iter: 0; batch classifier loss: 0.391119; batch adversarial loss: 0.572362\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386078; batch adversarial loss: 0.545075\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363111; batch adversarial loss: 0.500207\n",
      "epoch 140; iter: 0; batch classifier loss: 0.441621; batch adversarial loss: 0.526787\n",
      "epoch 141; iter: 0; batch classifier loss: 0.414590; batch adversarial loss: 0.607604\n",
      "epoch 142; iter: 0; batch classifier loss: 0.399826; batch adversarial loss: 0.518432\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352124; batch adversarial loss: 0.508054\n",
      "epoch 144; iter: 0; batch classifier loss: 0.294177; batch adversarial loss: 0.509823\n",
      "epoch 145; iter: 0; batch classifier loss: 0.438162; batch adversarial loss: 0.617426\n",
      "epoch 146; iter: 0; batch classifier loss: 0.458978; batch adversarial loss: 0.580126\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332353; batch adversarial loss: 0.464500\n",
      "epoch 148; iter: 0; batch classifier loss: 0.477729; batch adversarial loss: 0.535842\n",
      "epoch 149; iter: 0; batch classifier loss: 0.431370; batch adversarial loss: 0.580967\n",
      "epoch 150; iter: 0; batch classifier loss: 0.286901; batch adversarial loss: 0.561226\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348755; batch adversarial loss: 0.518454\n",
      "epoch 152; iter: 0; batch classifier loss: 0.406043; batch adversarial loss: 0.608350\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380873; batch adversarial loss: 0.553544\n",
      "epoch 154; iter: 0; batch classifier loss: 0.416603; batch adversarial loss: 0.597697\n",
      "epoch 155; iter: 0; batch classifier loss: 0.273907; batch adversarial loss: 0.536681\n",
      "epoch 156; iter: 0; batch classifier loss: 0.338749; batch adversarial loss: 0.553614\n",
      "epoch 157; iter: 0; batch classifier loss: 0.339163; batch adversarial loss: 0.537129\n",
      "epoch 158; iter: 0; batch classifier loss: 0.377533; batch adversarial loss: 0.579743\n",
      "epoch 159; iter: 0; batch classifier loss: 0.386440; batch adversarial loss: 0.562343\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335923; batch adversarial loss: 0.535944\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392965; batch adversarial loss: 0.650240\n",
      "epoch 162; iter: 0; batch classifier loss: 0.291177; batch adversarial loss: 0.518426\n",
      "epoch 163; iter: 0; batch classifier loss: 0.401041; batch adversarial loss: 0.534985\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360618; batch adversarial loss: 0.534953\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393694; batch adversarial loss: 0.509163\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347534; batch adversarial loss: 0.563819\n",
      "epoch 167; iter: 0; batch classifier loss: 0.377333; batch adversarial loss: 0.563061\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367659; batch adversarial loss: 0.582016\n",
      "epoch 169; iter: 0; batch classifier loss: 0.383120; batch adversarial loss: 0.536144\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380051; batch adversarial loss: 0.608035\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382917; batch adversarial loss: 0.533509\n",
      "epoch 172; iter: 0; batch classifier loss: 0.327404; batch adversarial loss: 0.599728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.356575; batch adversarial loss: 0.525754\n",
      "epoch 174; iter: 0; batch classifier loss: 0.354787; batch adversarial loss: 0.640647\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378638; batch adversarial loss: 0.582137\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413872; batch adversarial loss: 0.518703\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374819; batch adversarial loss: 0.591437\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364532; batch adversarial loss: 0.605477\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350977; batch adversarial loss: 0.517779\n",
      "epoch 180; iter: 0; batch classifier loss: 0.287625; batch adversarial loss: 0.525741\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410268; batch adversarial loss: 0.532976\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364397; batch adversarial loss: 0.527459\n",
      "epoch 183; iter: 0; batch classifier loss: 0.408939; batch adversarial loss: 0.526161\n",
      "epoch 184; iter: 0; batch classifier loss: 0.402161; batch adversarial loss: 0.607838\n",
      "epoch 185; iter: 0; batch classifier loss: 0.423915; batch adversarial loss: 0.561534\n",
      "epoch 186; iter: 0; batch classifier loss: 0.430016; batch adversarial loss: 0.507816\n",
      "epoch 187; iter: 0; batch classifier loss: 0.304842; batch adversarial loss: 0.581018\n",
      "epoch 188; iter: 0; batch classifier loss: 0.390787; batch adversarial loss: 0.517449\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323496; batch adversarial loss: 0.528357\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340214; batch adversarial loss: 0.554579\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306603; batch adversarial loss: 0.670009\n",
      "epoch 192; iter: 0; batch classifier loss: 0.377966; batch adversarial loss: 0.524578\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390506; batch adversarial loss: 0.538097\n",
      "epoch 194; iter: 0; batch classifier loss: 0.378954; batch adversarial loss: 0.571990\n",
      "epoch 195; iter: 0; batch classifier loss: 0.313586; batch adversarial loss: 0.578680\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354812; batch adversarial loss: 0.615094\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387288; batch adversarial loss: 0.561658\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360438; batch adversarial loss: 0.649742\n",
      "epoch 199; iter: 0; batch classifier loss: 0.336093; batch adversarial loss: 0.607890\n",
      "epoch 0; iter: 0; batch classifier loss: 0.856670; batch adversarial loss: 0.538504\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590613; batch adversarial loss: 0.615186\n",
      "epoch 2; iter: 0; batch classifier loss: 0.626706; batch adversarial loss: 0.659510\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586609; batch adversarial loss: 0.641597\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600233; batch adversarial loss: 0.651764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.565246; batch adversarial loss: 0.644963\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548307; batch adversarial loss: 0.629042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491825; batch adversarial loss: 0.678959\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575948; batch adversarial loss: 0.657714\n",
      "epoch 9; iter: 0; batch classifier loss: 0.659904; batch adversarial loss: 0.653388\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508517; batch adversarial loss: 0.556986\n",
      "epoch 11; iter: 0; batch classifier loss: 0.599597; batch adversarial loss: 0.651062\n",
      "epoch 12; iter: 0; batch classifier loss: 0.636095; batch adversarial loss: 0.552214\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578237; batch adversarial loss: 0.550058\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485465; batch adversarial loss: 0.564892\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481004; batch adversarial loss: 0.553952\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538023; batch adversarial loss: 0.492170\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517811; batch adversarial loss: 0.531462\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458768; batch adversarial loss: 0.498314\n",
      "epoch 19; iter: 0; batch classifier loss: 0.551751; batch adversarial loss: 0.566018\n",
      "epoch 20; iter: 0; batch classifier loss: 0.557766; batch adversarial loss: 0.500461\n",
      "epoch 21; iter: 0; batch classifier loss: 0.558272; batch adversarial loss: 0.484100\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465474; batch adversarial loss: 0.629456\n",
      "epoch 23; iter: 0; batch classifier loss: 0.469691; batch adversarial loss: 0.543467\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464267; batch adversarial loss: 0.584166\n",
      "epoch 25; iter: 0; batch classifier loss: 0.448728; batch adversarial loss: 0.562581\n",
      "epoch 26; iter: 0; batch classifier loss: 0.552586; batch adversarial loss: 0.556265\n",
      "epoch 27; iter: 0; batch classifier loss: 0.419852; batch adversarial loss: 0.519144\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433458; batch adversarial loss: 0.581071\n",
      "epoch 29; iter: 0; batch classifier loss: 0.412423; batch adversarial loss: 0.534720\n",
      "epoch 30; iter: 0; batch classifier loss: 0.509158; batch adversarial loss: 0.564234\n",
      "epoch 31; iter: 0; batch classifier loss: 0.415491; batch adversarial loss: 0.499281\n",
      "epoch 32; iter: 0; batch classifier loss: 0.411591; batch adversarial loss: 0.561547\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434143; batch adversarial loss: 0.533733\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445040; batch adversarial loss: 0.506861\n",
      "epoch 35; iter: 0; batch classifier loss: 0.414464; batch adversarial loss: 0.571654\n",
      "epoch 36; iter: 0; batch classifier loss: 0.493105; batch adversarial loss: 0.564958\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428394; batch adversarial loss: 0.487631\n",
      "epoch 38; iter: 0; batch classifier loss: 0.506643; batch adversarial loss: 0.479345\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467522; batch adversarial loss: 0.526185\n",
      "epoch 40; iter: 0; batch classifier loss: 0.387046; batch adversarial loss: 0.497995\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463690; batch adversarial loss: 0.572605\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448517; batch adversarial loss: 0.572480\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421465; batch adversarial loss: 0.497550\n",
      "epoch 44; iter: 0; batch classifier loss: 0.442736; batch adversarial loss: 0.544425\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485791; batch adversarial loss: 0.516513\n",
      "epoch 46; iter: 0; batch classifier loss: 0.490833; batch adversarial loss: 0.554214\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395744; batch adversarial loss: 0.601858\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417594; batch adversarial loss: 0.506133\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351241; batch adversarial loss: 0.506193\n",
      "epoch 50; iter: 0; batch classifier loss: 0.559689; batch adversarial loss: 0.591192\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448432; batch adversarial loss: 0.573197\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452974; batch adversarial loss: 0.474355\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359161; batch adversarial loss: 0.565873\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422779; batch adversarial loss: 0.592790\n",
      "epoch 55; iter: 0; batch classifier loss: 0.477427; batch adversarial loss: 0.526773\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442663; batch adversarial loss: 0.617330\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415978; batch adversarial loss: 0.507089\n",
      "epoch 58; iter: 0; batch classifier loss: 0.381790; batch adversarial loss: 0.516507\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417060; batch adversarial loss: 0.505713\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409460; batch adversarial loss: 0.592792\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383900; batch adversarial loss: 0.552033\n",
      "epoch 62; iter: 0; batch classifier loss: 0.511705; batch adversarial loss: 0.517654\n",
      "epoch 63; iter: 0; batch classifier loss: 0.356081; batch adversarial loss: 0.547405\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401705; batch adversarial loss: 0.553981\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448882; batch adversarial loss: 0.556395\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395849; batch adversarial loss: 0.554349\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434595; batch adversarial loss: 0.479098\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356861; batch adversarial loss: 0.592870\n",
      "epoch 69; iter: 0; batch classifier loss: 0.497844; batch adversarial loss: 0.506445\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446647; batch adversarial loss: 0.497562\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412448; batch adversarial loss: 0.602012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.433617; batch adversarial loss: 0.413866\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398076; batch adversarial loss: 0.545573\n",
      "epoch 74; iter: 0; batch classifier loss: 0.402078; batch adversarial loss: 0.536016\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397730; batch adversarial loss: 0.516747\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402803; batch adversarial loss: 0.591171\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435418; batch adversarial loss: 0.479065\n",
      "epoch 78; iter: 0; batch classifier loss: 0.434358; batch adversarial loss: 0.516632\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413695; batch adversarial loss: 0.543910\n",
      "epoch 80; iter: 0; batch classifier loss: 0.469264; batch adversarial loss: 0.459141\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371492; batch adversarial loss: 0.525524\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376499; batch adversarial loss: 0.536105\n",
      "epoch 83; iter: 0; batch classifier loss: 0.427001; batch adversarial loss: 0.536263\n",
      "epoch 84; iter: 0; batch classifier loss: 0.460779; batch adversarial loss: 0.496149\n",
      "epoch 85; iter: 0; batch classifier loss: 0.327714; batch adversarial loss: 0.553079\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383129; batch adversarial loss: 0.601460\n",
      "epoch 87; iter: 0; batch classifier loss: 0.337646; batch adversarial loss: 0.611154\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395604; batch adversarial loss: 0.505422\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413921; batch adversarial loss: 0.562553\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344936; batch adversarial loss: 0.572977\n",
      "epoch 91; iter: 0; batch classifier loss: 0.327478; batch adversarial loss: 0.583188\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393933; batch adversarial loss: 0.518456\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418477; batch adversarial loss: 0.554593\n",
      "epoch 94; iter: 0; batch classifier loss: 0.369958; batch adversarial loss: 0.569656\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362572; batch adversarial loss: 0.536034\n",
      "epoch 96; iter: 0; batch classifier loss: 0.424865; batch adversarial loss: 0.535175\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383861; batch adversarial loss: 0.468763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371357; batch adversarial loss: 0.542375\n",
      "epoch 99; iter: 0; batch classifier loss: 0.297761; batch adversarial loss: 0.580764\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386757; batch adversarial loss: 0.506723\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408454; batch adversarial loss: 0.602254\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402698; batch adversarial loss: 0.534860\n",
      "epoch 103; iter: 0; batch classifier loss: 0.329633; batch adversarial loss: 0.544706\n",
      "epoch 104; iter: 0; batch classifier loss: 0.333649; batch adversarial loss: 0.441459\n",
      "epoch 105; iter: 0; batch classifier loss: 0.348398; batch adversarial loss: 0.515697\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388162; batch adversarial loss: 0.562061\n",
      "epoch 107; iter: 0; batch classifier loss: 0.398009; batch adversarial loss: 0.592706\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404276; batch adversarial loss: 0.553824\n",
      "epoch 109; iter: 0; batch classifier loss: 0.300733; batch adversarial loss: 0.602232\n",
      "epoch 110; iter: 0; batch classifier loss: 0.439994; batch adversarial loss: 0.440744\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367033; batch adversarial loss: 0.562960\n",
      "epoch 112; iter: 0; batch classifier loss: 0.340982; batch adversarial loss: 0.601006\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377855; batch adversarial loss: 0.638781\n",
      "epoch 114; iter: 0; batch classifier loss: 0.371079; batch adversarial loss: 0.523414\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356541; batch adversarial loss: 0.552405\n",
      "epoch 116; iter: 0; batch classifier loss: 0.340022; batch adversarial loss: 0.552805\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358615; batch adversarial loss: 0.592024\n",
      "epoch 118; iter: 0; batch classifier loss: 0.436249; batch adversarial loss: 0.506235\n",
      "epoch 119; iter: 0; batch classifier loss: 0.305642; batch adversarial loss: 0.488558\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416278; batch adversarial loss: 0.499090\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362593; batch adversarial loss: 0.515393\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359980; batch adversarial loss: 0.619142\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362749; batch adversarial loss: 0.505407\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334214; batch adversarial loss: 0.630414\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362526; batch adversarial loss: 0.459036\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406246; batch adversarial loss: 0.526442\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334347; batch adversarial loss: 0.581211\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377719; batch adversarial loss: 0.488455\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343951; batch adversarial loss: 0.497491\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393965; batch adversarial loss: 0.450356\n",
      "epoch 131; iter: 0; batch classifier loss: 0.318160; batch adversarial loss: 0.478604\n",
      "epoch 132; iter: 0; batch classifier loss: 0.445930; batch adversarial loss: 0.630682\n",
      "epoch 133; iter: 0; batch classifier loss: 0.328528; batch adversarial loss: 0.526044\n",
      "epoch 134; iter: 0; batch classifier loss: 0.332945; batch adversarial loss: 0.592587\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375777; batch adversarial loss: 0.508573\n",
      "epoch 136; iter: 0; batch classifier loss: 0.390221; batch adversarial loss: 0.526328\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370989; batch adversarial loss: 0.505689\n",
      "epoch 138; iter: 0; batch classifier loss: 0.474498; batch adversarial loss: 0.506259\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355683; batch adversarial loss: 0.562891\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359318; batch adversarial loss: 0.552905\n",
      "epoch 141; iter: 0; batch classifier loss: 0.465182; batch adversarial loss: 0.571392\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340732; batch adversarial loss: 0.534577\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367097; batch adversarial loss: 0.600963\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347230; batch adversarial loss: 0.535940\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380220; batch adversarial loss: 0.535017\n",
      "epoch 146; iter: 0; batch classifier loss: 0.310419; batch adversarial loss: 0.543451\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355409; batch adversarial loss: 0.489147\n",
      "epoch 148; iter: 0; batch classifier loss: 0.324545; batch adversarial loss: 0.498037\n",
      "epoch 149; iter: 0; batch classifier loss: 0.434183; batch adversarial loss: 0.525447\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375980; batch adversarial loss: 0.528288\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390512; batch adversarial loss: 0.490058\n",
      "epoch 152; iter: 0; batch classifier loss: 0.328051; batch adversarial loss: 0.496767\n",
      "epoch 153; iter: 0; batch classifier loss: 0.420616; batch adversarial loss: 0.491003\n",
      "epoch 154; iter: 0; batch classifier loss: 0.433373; batch adversarial loss: 0.602535\n",
      "epoch 155; iter: 0; batch classifier loss: 0.272007; batch adversarial loss: 0.562858\n",
      "epoch 156; iter: 0; batch classifier loss: 0.300469; batch adversarial loss: 0.545658\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337629; batch adversarial loss: 0.545054\n",
      "epoch 158; iter: 0; batch classifier loss: 0.431423; batch adversarial loss: 0.553385\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277841; batch adversarial loss: 0.591456\n",
      "epoch 160; iter: 0; batch classifier loss: 0.383942; batch adversarial loss: 0.573215\n",
      "epoch 161; iter: 0; batch classifier loss: 0.394958; batch adversarial loss: 0.534803\n",
      "epoch 162; iter: 0; batch classifier loss: 0.481056; batch adversarial loss: 0.553580\n",
      "epoch 163; iter: 0; batch classifier loss: 0.401092; batch adversarial loss: 0.535926\n",
      "epoch 164; iter: 0; batch classifier loss: 0.302867; batch adversarial loss: 0.543258\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352385; batch adversarial loss: 0.477410\n",
      "epoch 166; iter: 0; batch classifier loss: 0.402612; batch adversarial loss: 0.441700\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376703; batch adversarial loss: 0.562701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.365307; batch adversarial loss: 0.543796\n",
      "epoch 169; iter: 0; batch classifier loss: 0.397545; batch adversarial loss: 0.477831\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360611; batch adversarial loss: 0.563498\n",
      "epoch 171; iter: 0; batch classifier loss: 0.441163; batch adversarial loss: 0.553615\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326341; batch adversarial loss: 0.525420\n",
      "epoch 173; iter: 0; batch classifier loss: 0.307272; batch adversarial loss: 0.563043\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341314; batch adversarial loss: 0.497253\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339888; batch adversarial loss: 0.601782\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370578; batch adversarial loss: 0.602309\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345485; batch adversarial loss: 0.534909\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360501; batch adversarial loss: 0.486690\n",
      "epoch 179; iter: 0; batch classifier loss: 0.314084; batch adversarial loss: 0.600474\n",
      "epoch 180; iter: 0; batch classifier loss: 0.365046; batch adversarial loss: 0.498182\n",
      "epoch 181; iter: 0; batch classifier loss: 0.368326; batch adversarial loss: 0.459489\n",
      "epoch 182; iter: 0; batch classifier loss: 0.319512; batch adversarial loss: 0.536190\n",
      "epoch 183; iter: 0; batch classifier loss: 0.437611; batch adversarial loss: 0.562491\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346014; batch adversarial loss: 0.524508\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356640; batch adversarial loss: 0.608675\n",
      "epoch 186; iter: 0; batch classifier loss: 0.370503; batch adversarial loss: 0.552850\n",
      "epoch 187; iter: 0; batch classifier loss: 0.425785; batch adversarial loss: 0.536108\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358640; batch adversarial loss: 0.600038\n",
      "epoch 189; iter: 0; batch classifier loss: 0.432385; batch adversarial loss: 0.554204\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358288; batch adversarial loss: 0.488597\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313987; batch adversarial loss: 0.534229\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371527; batch adversarial loss: 0.459659\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320480; batch adversarial loss: 0.420489\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304700; batch adversarial loss: 0.524785\n",
      "epoch 195; iter: 0; batch classifier loss: 0.388346; batch adversarial loss: 0.536176\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341539; batch adversarial loss: 0.553339\n",
      "epoch 197; iter: 0; batch classifier loss: 0.414431; batch adversarial loss: 0.533408\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375285; batch adversarial loss: 0.526762\n",
      "epoch 199; iter: 0; batch classifier loss: 0.293331; batch adversarial loss: 0.459859\n",
      "epoch 0; iter: 0; batch classifier loss: 0.779909; batch adversarial loss: 0.574420\n",
      "epoch 1; iter: 0; batch classifier loss: 0.558083; batch adversarial loss: 0.658722\n",
      "epoch 2; iter: 0; batch classifier loss: 0.523788; batch adversarial loss: 0.665343\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591470; batch adversarial loss: 0.672313\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571931; batch adversarial loss: 0.637601\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587560; batch adversarial loss: 0.699558\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525007; batch adversarial loss: 0.610693\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496541; batch adversarial loss: 0.582903\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572677; batch adversarial loss: 0.600018\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557769; batch adversarial loss: 0.645130\n",
      "epoch 10; iter: 0; batch classifier loss: 0.611627; batch adversarial loss: 0.600543\n",
      "epoch 11; iter: 0; batch classifier loss: 0.653129; batch adversarial loss: 0.555020\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507461; batch adversarial loss: 0.570723\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599462; batch adversarial loss: 0.560634\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533842; batch adversarial loss: 0.545206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500373; batch adversarial loss: 0.636708\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533898; batch adversarial loss: 0.557894\n",
      "epoch 17; iter: 0; batch classifier loss: 0.544598; batch adversarial loss: 0.541871\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442768; batch adversarial loss: 0.507505\n",
      "epoch 19; iter: 0; batch classifier loss: 0.559908; batch adversarial loss: 0.589880\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511375; batch adversarial loss: 0.595821\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478900; batch adversarial loss: 0.523683\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481526; batch adversarial loss: 0.560571\n",
      "epoch 23; iter: 0; batch classifier loss: 0.544840; batch adversarial loss: 0.563692\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479890; batch adversarial loss: 0.566534\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462842; batch adversarial loss: 0.565752\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463183; batch adversarial loss: 0.584429\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445144; batch adversarial loss: 0.571255\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455383; batch adversarial loss: 0.579561\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432145; batch adversarial loss: 0.505240\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422818; batch adversarial loss: 0.537282\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432135; batch adversarial loss: 0.541118\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453623; batch adversarial loss: 0.580247\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414295; batch adversarial loss: 0.586951\n",
      "epoch 34; iter: 0; batch classifier loss: 0.506045; batch adversarial loss: 0.552795\n",
      "epoch 35; iter: 0; batch classifier loss: 0.487067; batch adversarial loss: 0.581994\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440218; batch adversarial loss: 0.552889\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464612; batch adversarial loss: 0.464638\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466557; batch adversarial loss: 0.554071\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420530; batch adversarial loss: 0.543984\n",
      "epoch 40; iter: 0; batch classifier loss: 0.511589; batch adversarial loss: 0.597487\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382643; batch adversarial loss: 0.483218\n",
      "epoch 42; iter: 0; batch classifier loss: 0.397461; batch adversarial loss: 0.615430\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408786; batch adversarial loss: 0.545047\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404703; batch adversarial loss: 0.525235\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384610; batch adversarial loss: 0.578668\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444566; batch adversarial loss: 0.560021\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471627; batch adversarial loss: 0.570659\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437983; batch adversarial loss: 0.578719\n",
      "epoch 49; iter: 0; batch classifier loss: 0.316918; batch adversarial loss: 0.500148\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418597; batch adversarial loss: 0.648344\n",
      "epoch 51; iter: 0; batch classifier loss: 0.472699; batch adversarial loss: 0.519591\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405642; batch adversarial loss: 0.634214\n",
      "epoch 53; iter: 0; batch classifier loss: 0.382019; batch adversarial loss: 0.578053\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460344; batch adversarial loss: 0.567955\n",
      "epoch 55; iter: 0; batch classifier loss: 0.358665; batch adversarial loss: 0.555431\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421893; batch adversarial loss: 0.552581\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457601; batch adversarial loss: 0.598001\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442183; batch adversarial loss: 0.611791\n",
      "epoch 59; iter: 0; batch classifier loss: 0.343255; batch adversarial loss: 0.581023\n",
      "epoch 60; iter: 0; batch classifier loss: 0.517179; batch adversarial loss: 0.527981\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400186; batch adversarial loss: 0.552849\n",
      "epoch 62; iter: 0; batch classifier loss: 0.412630; batch adversarial loss: 0.570859\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420021; batch adversarial loss: 0.490252\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436343; batch adversarial loss: 0.528675\n",
      "epoch 65; iter: 0; batch classifier loss: 0.461706; batch adversarial loss: 0.429712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.453073; batch adversarial loss: 0.473140\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410890; batch adversarial loss: 0.521059\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427886; batch adversarial loss: 0.545866\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406961; batch adversarial loss: 0.509510\n",
      "epoch 70; iter: 0; batch classifier loss: 0.499150; batch adversarial loss: 0.547688\n",
      "epoch 71; iter: 0; batch classifier loss: 0.458285; batch adversarial loss: 0.513708\n",
      "epoch 72; iter: 0; batch classifier loss: 0.460273; batch adversarial loss: 0.554410\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373103; batch adversarial loss: 0.554736\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363680; batch adversarial loss: 0.554083\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389954; batch adversarial loss: 0.622321\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461461; batch adversarial loss: 0.545430\n",
      "epoch 77; iter: 0; batch classifier loss: 0.475678; batch adversarial loss: 0.562081\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378618; batch adversarial loss: 0.545255\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386799; batch adversarial loss: 0.527508\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451365; batch adversarial loss: 0.562271\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351081; batch adversarial loss: 0.606466\n",
      "epoch 82; iter: 0; batch classifier loss: 0.465712; batch adversarial loss: 0.526443\n",
      "epoch 83; iter: 0; batch classifier loss: 0.462609; batch adversarial loss: 0.527920\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415616; batch adversarial loss: 0.501194\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398178; batch adversarial loss: 0.543770\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378583; batch adversarial loss: 0.492050\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399095; batch adversarial loss: 0.553696\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415536; batch adversarial loss: 0.517815\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399274; batch adversarial loss: 0.553706\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417038; batch adversarial loss: 0.616678\n",
      "epoch 91; iter: 0; batch classifier loss: 0.353840; batch adversarial loss: 0.632870\n",
      "epoch 92; iter: 0; batch classifier loss: 0.459649; batch adversarial loss: 0.570090\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394666; batch adversarial loss: 0.508191\n",
      "epoch 94; iter: 0; batch classifier loss: 0.469876; batch adversarial loss: 0.518274\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398700; batch adversarial loss: 0.501381\n",
      "epoch 96; iter: 0; batch classifier loss: 0.318693; batch adversarial loss: 0.597375\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364192; batch adversarial loss: 0.534280\n",
      "epoch 98; iter: 0; batch classifier loss: 0.340435; batch adversarial loss: 0.602904\n",
      "epoch 99; iter: 0; batch classifier loss: 0.304781; batch adversarial loss: 0.555180\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388669; batch adversarial loss: 0.583642\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366130; batch adversarial loss: 0.569664\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391654; batch adversarial loss: 0.559876\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382689; batch adversarial loss: 0.507485\n",
      "epoch 104; iter: 0; batch classifier loss: 0.438559; batch adversarial loss: 0.547562\n",
      "epoch 105; iter: 0; batch classifier loss: 0.367766; batch adversarial loss: 0.542921\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376400; batch adversarial loss: 0.510034\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352627; batch adversarial loss: 0.609640\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380146; batch adversarial loss: 0.600122\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407507; batch adversarial loss: 0.484546\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369394; batch adversarial loss: 0.512484\n",
      "epoch 111; iter: 0; batch classifier loss: 0.390278; batch adversarial loss: 0.562156\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326740; batch adversarial loss: 0.570355\n",
      "epoch 113; iter: 0; batch classifier loss: 0.412159; batch adversarial loss: 0.580219\n",
      "epoch 114; iter: 0; batch classifier loss: 0.417353; batch adversarial loss: 0.562040\n",
      "epoch 115; iter: 0; batch classifier loss: 0.311104; batch adversarial loss: 0.588624\n",
      "epoch 116; iter: 0; batch classifier loss: 0.423691; batch adversarial loss: 0.588209\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396508; batch adversarial loss: 0.596672\n",
      "epoch 118; iter: 0; batch classifier loss: 0.408829; batch adversarial loss: 0.562704\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433351; batch adversarial loss: 0.475332\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330761; batch adversarial loss: 0.571629\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391360; batch adversarial loss: 0.580478\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355905; batch adversarial loss: 0.616167\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385587; batch adversarial loss: 0.527120\n",
      "epoch 124; iter: 0; batch classifier loss: 0.437844; batch adversarial loss: 0.615448\n",
      "epoch 125; iter: 0; batch classifier loss: 0.407179; batch adversarial loss: 0.651116\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366672; batch adversarial loss: 0.580056\n",
      "epoch 127; iter: 0; batch classifier loss: 0.421693; batch adversarial loss: 0.562856\n",
      "epoch 128; iter: 0; batch classifier loss: 0.292926; batch adversarial loss: 0.509526\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336511; batch adversarial loss: 0.519318\n",
      "epoch 130; iter: 0; batch classifier loss: 0.294546; batch adversarial loss: 0.580160\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379303; batch adversarial loss: 0.526466\n",
      "epoch 132; iter: 0; batch classifier loss: 0.305723; batch adversarial loss: 0.554855\n",
      "epoch 133; iter: 0; batch classifier loss: 0.307592; batch adversarial loss: 0.483374\n",
      "epoch 134; iter: 0; batch classifier loss: 0.434495; batch adversarial loss: 0.544974\n",
      "epoch 135; iter: 0; batch classifier loss: 0.328878; batch adversarial loss: 0.553364\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368412; batch adversarial loss: 0.553677\n",
      "epoch 137; iter: 0; batch classifier loss: 0.314493; batch adversarial loss: 0.545065\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344620; batch adversarial loss: 0.536244\n",
      "epoch 139; iter: 0; batch classifier loss: 0.445625; batch adversarial loss: 0.641240\n",
      "epoch 140; iter: 0; batch classifier loss: 0.398838; batch adversarial loss: 0.544497\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346900; batch adversarial loss: 0.474636\n",
      "epoch 142; iter: 0; batch classifier loss: 0.431513; batch adversarial loss: 0.588113\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394289; batch adversarial loss: 0.501116\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362436; batch adversarial loss: 0.580752\n",
      "epoch 145; iter: 0; batch classifier loss: 0.437131; batch adversarial loss: 0.614021\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349198; batch adversarial loss: 0.536105\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307453; batch adversarial loss: 0.589476\n",
      "epoch 148; iter: 0; batch classifier loss: 0.301593; batch adversarial loss: 0.563971\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400733; batch adversarial loss: 0.623614\n",
      "epoch 150; iter: 0; batch classifier loss: 0.432450; batch adversarial loss: 0.518052\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355664; batch adversarial loss: 0.535558\n",
      "epoch 152; iter: 0; batch classifier loss: 0.441377; batch adversarial loss: 0.546579\n",
      "epoch 153; iter: 0; batch classifier loss: 0.392798; batch adversarial loss: 0.554351\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397792; batch adversarial loss: 0.544977\n",
      "epoch 155; iter: 0; batch classifier loss: 0.384825; batch adversarial loss: 0.640465\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.465911\n",
      "epoch 157; iter: 0; batch classifier loss: 0.459951; batch adversarial loss: 0.580199\n",
      "epoch 158; iter: 0; batch classifier loss: 0.527059; batch adversarial loss: 0.562112\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383923; batch adversarial loss: 0.596679\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386283; batch adversarial loss: 0.526892\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343853; batch adversarial loss: 0.579906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.388227; batch adversarial loss: 0.544550\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373757; batch adversarial loss: 0.537118\n",
      "epoch 164; iter: 0; batch classifier loss: 0.314298; batch adversarial loss: 0.570956\n",
      "epoch 165; iter: 0; batch classifier loss: 0.308815; batch adversarial loss: 0.526634\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365241; batch adversarial loss: 0.562808\n",
      "epoch 167; iter: 0; batch classifier loss: 0.294457; batch adversarial loss: 0.536120\n",
      "epoch 168; iter: 0; batch classifier loss: 0.305450; batch adversarial loss: 0.536513\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337245; batch adversarial loss: 0.588381\n",
      "epoch 170; iter: 0; batch classifier loss: 0.399796; batch adversarial loss: 0.518248\n",
      "epoch 171; iter: 0; batch classifier loss: 0.403201; batch adversarial loss: 0.483711\n",
      "epoch 172; iter: 0; batch classifier loss: 0.445340; batch adversarial loss: 0.544710\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334614; batch adversarial loss: 0.473377\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348558; batch adversarial loss: 0.607949\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382388; batch adversarial loss: 0.499882\n",
      "epoch 176; iter: 0; batch classifier loss: 0.352942; batch adversarial loss: 0.613854\n",
      "epoch 177; iter: 0; batch classifier loss: 0.452180; batch adversarial loss: 0.564025\n",
      "epoch 178; iter: 0; batch classifier loss: 0.437335; batch adversarial loss: 0.536526\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349713; batch adversarial loss: 0.572169\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327287; batch adversarial loss: 0.537040\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367921; batch adversarial loss: 0.536575\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376944; batch adversarial loss: 0.570783\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354958; batch adversarial loss: 0.500703\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357923; batch adversarial loss: 0.562153\n",
      "epoch 185; iter: 0; batch classifier loss: 0.401636; batch adversarial loss: 0.509471\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414318; batch adversarial loss: 0.606022\n",
      "epoch 187; iter: 0; batch classifier loss: 0.411040; batch adversarial loss: 0.571431\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368148; batch adversarial loss: 0.526647\n",
      "epoch 189; iter: 0; batch classifier loss: 0.428041; batch adversarial loss: 0.518020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.307236; batch adversarial loss: 0.694451\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356389; batch adversarial loss: 0.597674\n",
      "epoch 192; iter: 0; batch classifier loss: 0.280010; batch adversarial loss: 0.535930\n",
      "epoch 193; iter: 0; batch classifier loss: 0.393543; batch adversarial loss: 0.465228\n",
      "epoch 194; iter: 0; batch classifier loss: 0.370761; batch adversarial loss: 0.517397\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376847; batch adversarial loss: 0.554019\n",
      "epoch 196; iter: 0; batch classifier loss: 0.495664; batch adversarial loss: 0.536642\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392967; batch adversarial loss: 0.484103\n",
      "epoch 198; iter: 0; batch classifier loss: 0.305541; batch adversarial loss: 0.509481\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338043; batch adversarial loss: 0.589348\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696469; batch adversarial loss: 0.885188\n",
      "epoch 1; iter: 0; batch classifier loss: 0.838632; batch adversarial loss: 1.063841\n",
      "epoch 2; iter: 0; batch classifier loss: 0.911394; batch adversarial loss: 0.996521\n",
      "epoch 3; iter: 0; batch classifier loss: 0.913480; batch adversarial loss: 0.917600\n",
      "epoch 4; iter: 0; batch classifier loss: 0.899161; batch adversarial loss: 0.893279\n",
      "epoch 5; iter: 0; batch classifier loss: 0.821341; batch adversarial loss: 0.799097\n",
      "epoch 6; iter: 0; batch classifier loss: 0.684975; batch adversarial loss: 0.695359\n",
      "epoch 7; iter: 0; batch classifier loss: 0.664679; batch adversarial loss: 0.736118\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569404; batch adversarial loss: 0.669715\n",
      "epoch 9; iter: 0; batch classifier loss: 0.632534; batch adversarial loss: 0.590460\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521165; batch adversarial loss: 0.595057\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530326; batch adversarial loss: 0.563507\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529113; batch adversarial loss: 0.555882\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570056; batch adversarial loss: 0.659996\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476545; batch adversarial loss: 0.578829\n",
      "epoch 15; iter: 0; batch classifier loss: 0.559167; batch adversarial loss: 0.679125\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545392; batch adversarial loss: 0.592039\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514876; batch adversarial loss: 0.579856\n",
      "epoch 18; iter: 0; batch classifier loss: 0.569515; batch adversarial loss: 0.577688\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507223; batch adversarial loss: 0.574646\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476944; batch adversarial loss: 0.517000\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496435; batch adversarial loss: 0.585087\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432876; batch adversarial loss: 0.613117\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471849; batch adversarial loss: 0.550415\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478265; batch adversarial loss: 0.486033\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492604; batch adversarial loss: 0.477029\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494285; batch adversarial loss: 0.644152\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477603; batch adversarial loss: 0.530538\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433766; batch adversarial loss: 0.613382\n",
      "epoch 29; iter: 0; batch classifier loss: 0.528042; batch adversarial loss: 0.573352\n",
      "epoch 30; iter: 0; batch classifier loss: 0.522819; batch adversarial loss: 0.549945\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507698; batch adversarial loss: 0.673465\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498383; batch adversarial loss: 0.551357\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494624; batch adversarial loss: 0.620527\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435837; batch adversarial loss: 0.485911\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489212; batch adversarial loss: 0.559872\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442751; batch adversarial loss: 0.475900\n",
      "epoch 37; iter: 0; batch classifier loss: 0.543836; batch adversarial loss: 0.620438\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451520; batch adversarial loss: 0.568005\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493886; batch adversarial loss: 0.610242\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459238; batch adversarial loss: 0.536649\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469625; batch adversarial loss: 0.478938\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378758; batch adversarial loss: 0.537723\n",
      "epoch 43; iter: 0; batch classifier loss: 0.487662; batch adversarial loss: 0.611856\n",
      "epoch 44; iter: 0; batch classifier loss: 0.517392; batch adversarial loss: 0.543218\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467275; batch adversarial loss: 0.588234\n",
      "epoch 46; iter: 0; batch classifier loss: 0.395013; batch adversarial loss: 0.584983\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426585; batch adversarial loss: 0.543648\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438892; batch adversarial loss: 0.542286\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404607; batch adversarial loss: 0.565210\n",
      "epoch 50; iter: 0; batch classifier loss: 0.369987; batch adversarial loss: 0.596730\n",
      "epoch 51; iter: 0; batch classifier loss: 0.474465; batch adversarial loss: 0.544094\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464605; batch adversarial loss: 0.640161\n",
      "epoch 53; iter: 0; batch classifier loss: 0.426055; batch adversarial loss: 0.601584\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408925; batch adversarial loss: 0.549898\n",
      "epoch 55; iter: 0; batch classifier loss: 0.373671; batch adversarial loss: 0.576089\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419720; batch adversarial loss: 0.551212\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445803; batch adversarial loss: 0.554846\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443475; batch adversarial loss: 0.454652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.395808; batch adversarial loss: 0.498739\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366441; batch adversarial loss: 0.559870\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432097; batch adversarial loss: 0.561906\n",
      "epoch 62; iter: 0; batch classifier loss: 0.389693; batch adversarial loss: 0.520347\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404155; batch adversarial loss: 0.551644\n",
      "epoch 64; iter: 0; batch classifier loss: 0.450467; batch adversarial loss: 0.613243\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441392; batch adversarial loss: 0.496835\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431963; batch adversarial loss: 0.552448\n",
      "epoch 67; iter: 0; batch classifier loss: 0.348549; batch adversarial loss: 0.491329\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404585; batch adversarial loss: 0.595091\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396559; batch adversarial loss: 0.517727\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387297; batch adversarial loss: 0.555284\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373808; batch adversarial loss: 0.537065\n",
      "epoch 72; iter: 0; batch classifier loss: 0.353769; batch adversarial loss: 0.553479\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414562; batch adversarial loss: 0.569261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.403830; batch adversarial loss: 0.555974\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409314; batch adversarial loss: 0.582698\n",
      "epoch 76; iter: 0; batch classifier loss: 0.432531; batch adversarial loss: 0.577386\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398565; batch adversarial loss: 0.486834\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362135; batch adversarial loss: 0.521423\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433919; batch adversarial loss: 0.532135\n",
      "epoch 80; iter: 0; batch classifier loss: 0.351196; batch adversarial loss: 0.618580\n",
      "epoch 81; iter: 0; batch classifier loss: 0.486205; batch adversarial loss: 0.541733\n",
      "epoch 82; iter: 0; batch classifier loss: 0.364433; batch adversarial loss: 0.509490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372465; batch adversarial loss: 0.517691\n",
      "epoch 84; iter: 0; batch classifier loss: 0.480881; batch adversarial loss: 0.564964\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416161; batch adversarial loss: 0.507419\n",
      "epoch 86; iter: 0; batch classifier loss: 0.349434; batch adversarial loss: 0.534189\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404615; batch adversarial loss: 0.544598\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440552; batch adversarial loss: 0.516834\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438629; batch adversarial loss: 0.544603\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376150; batch adversarial loss: 0.590328\n",
      "epoch 91; iter: 0; batch classifier loss: 0.470236; batch adversarial loss: 0.562827\n",
      "epoch 92; iter: 0; batch classifier loss: 0.322100; batch adversarial loss: 0.498897\n",
      "epoch 93; iter: 0; batch classifier loss: 0.321734; batch adversarial loss: 0.480815\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375480; batch adversarial loss: 0.544403\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322148; batch adversarial loss: 0.598718\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431812; batch adversarial loss: 0.506917\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376492; batch adversarial loss: 0.489777\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411369; batch adversarial loss: 0.544789\n",
      "epoch 99; iter: 0; batch classifier loss: 0.435264; batch adversarial loss: 0.517296\n",
      "epoch 100; iter: 0; batch classifier loss: 0.395573; batch adversarial loss: 0.583173\n",
      "epoch 101; iter: 0; batch classifier loss: 0.329060; batch adversarial loss: 0.589165\n",
      "epoch 102; iter: 0; batch classifier loss: 0.361649; batch adversarial loss: 0.499011\n",
      "epoch 103; iter: 0; batch classifier loss: 0.431082; batch adversarial loss: 0.581772\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352571; batch adversarial loss: 0.498517\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398342; batch adversarial loss: 0.610706\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345757; batch adversarial loss: 0.572518\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339415; batch adversarial loss: 0.507815\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380862; batch adversarial loss: 0.488829\n",
      "epoch 109; iter: 0; batch classifier loss: 0.341919; batch adversarial loss: 0.572670\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367015; batch adversarial loss: 0.516903\n",
      "epoch 111; iter: 0; batch classifier loss: 0.357309; batch adversarial loss: 0.553920\n",
      "epoch 112; iter: 0; batch classifier loss: 0.337524; batch adversarial loss: 0.554224\n",
      "epoch 113; iter: 0; batch classifier loss: 0.429094; batch adversarial loss: 0.554067\n",
      "epoch 114; iter: 0; batch classifier loss: 0.342671; batch adversarial loss: 0.516419\n",
      "epoch 115; iter: 0; batch classifier loss: 0.377190; batch adversarial loss: 0.525673\n",
      "epoch 116; iter: 0; batch classifier loss: 0.436764; batch adversarial loss: 0.600625\n",
      "epoch 117; iter: 0; batch classifier loss: 0.444010; batch adversarial loss: 0.535024\n",
      "epoch 118; iter: 0; batch classifier loss: 0.413886; batch adversarial loss: 0.525401\n",
      "epoch 119; iter: 0; batch classifier loss: 0.329525; batch adversarial loss: 0.581939\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371388; batch adversarial loss: 0.564575\n",
      "epoch 121; iter: 0; batch classifier loss: 0.372094; batch adversarial loss: 0.506398\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395136; batch adversarial loss: 0.564841\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396220; batch adversarial loss: 0.572299\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363860; batch adversarial loss: 0.582168\n",
      "epoch 125; iter: 0; batch classifier loss: 0.280774; batch adversarial loss: 0.571916\n",
      "epoch 126; iter: 0; batch classifier loss: 0.299674; batch adversarial loss: 0.572034\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382553; batch adversarial loss: 0.581628\n",
      "epoch 128; iter: 0; batch classifier loss: 0.407882; batch adversarial loss: 0.517397\n",
      "epoch 129; iter: 0; batch classifier loss: 0.285658; batch adversarial loss: 0.609030\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371405; batch adversarial loss: 0.554074\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328492; batch adversarial loss: 0.571701\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376130; batch adversarial loss: 0.572813\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302094; batch adversarial loss: 0.537496\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341367; batch adversarial loss: 0.489305\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334765; batch adversarial loss: 0.535552\n",
      "epoch 136; iter: 0; batch classifier loss: 0.310170; batch adversarial loss: 0.573538\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344739; batch adversarial loss: 0.535401\n",
      "epoch 138; iter: 0; batch classifier loss: 0.322372; batch adversarial loss: 0.582468\n",
      "epoch 139; iter: 0; batch classifier loss: 0.330637; batch adversarial loss: 0.553352\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391866; batch adversarial loss: 0.470426\n",
      "epoch 141; iter: 0; batch classifier loss: 0.430309; batch adversarial loss: 0.534936\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384423; batch adversarial loss: 0.507457\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363052; batch adversarial loss: 0.600191\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389390; batch adversarial loss: 0.526234\n",
      "epoch 145; iter: 0; batch classifier loss: 0.452926; batch adversarial loss: 0.535657\n",
      "epoch 146; iter: 0; batch classifier loss: 0.319644; batch adversarial loss: 0.544574\n",
      "epoch 147; iter: 0; batch classifier loss: 0.305803; batch adversarial loss: 0.581958\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392703; batch adversarial loss: 0.600236\n",
      "epoch 149; iter: 0; batch classifier loss: 0.286591; batch adversarial loss: 0.536028\n",
      "epoch 150; iter: 0; batch classifier loss: 0.302269; batch adversarial loss: 0.517255\n",
      "epoch 151; iter: 0; batch classifier loss: 0.443973; batch adversarial loss: 0.535269\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397170; batch adversarial loss: 0.581500\n",
      "epoch 153; iter: 0; batch classifier loss: 0.322999; batch adversarial loss: 0.507717\n",
      "epoch 154; iter: 0; batch classifier loss: 0.396265; batch adversarial loss: 0.673798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.311388; batch adversarial loss: 0.535099\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390207; batch adversarial loss: 0.618353\n",
      "epoch 157; iter: 0; batch classifier loss: 0.332315; batch adversarial loss: 0.516436\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362230; batch adversarial loss: 0.460825\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356564; batch adversarial loss: 0.534962\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323829; batch adversarial loss: 0.498928\n",
      "epoch 161; iter: 0; batch classifier loss: 0.265904; batch adversarial loss: 0.525919\n",
      "epoch 162; iter: 0; batch classifier loss: 0.295949; batch adversarial loss: 0.544444\n",
      "epoch 163; iter: 0; batch classifier loss: 0.436550; batch adversarial loss: 0.525870\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342380; batch adversarial loss: 0.498313\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346207; batch adversarial loss: 0.618839\n",
      "epoch 166; iter: 0; batch classifier loss: 0.391857; batch adversarial loss: 0.581713\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340636; batch adversarial loss: 0.498133\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323491; batch adversarial loss: 0.489599\n",
      "epoch 169; iter: 0; batch classifier loss: 0.331738; batch adversarial loss: 0.460837\n",
      "epoch 170; iter: 0; batch classifier loss: 0.306758; batch adversarial loss: 0.600767\n",
      "epoch 171; iter: 0; batch classifier loss: 0.281673; batch adversarial loss: 0.572327\n",
      "epoch 172; iter: 0; batch classifier loss: 0.481964; batch adversarial loss: 0.544614\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377403; batch adversarial loss: 0.544193\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357353; batch adversarial loss: 0.535416\n",
      "epoch 175; iter: 0; batch classifier loss: 0.298815; batch adversarial loss: 0.507383\n",
      "epoch 176; iter: 0; batch classifier loss: 0.407476; batch adversarial loss: 0.581156\n",
      "epoch 177; iter: 0; batch classifier loss: 0.386672; batch adversarial loss: 0.544809\n",
      "epoch 178; iter: 0; batch classifier loss: 0.412209; batch adversarial loss: 0.498163\n",
      "epoch 179; iter: 0; batch classifier loss: 0.359242; batch adversarial loss: 0.572752\n",
      "epoch 180; iter: 0; batch classifier loss: 0.257834; batch adversarial loss: 0.534833\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347349; batch adversarial loss: 0.562896\n",
      "epoch 182; iter: 0; batch classifier loss: 0.384914; batch adversarial loss: 0.479620\n",
      "epoch 183; iter: 0; batch classifier loss: 0.311134; batch adversarial loss: 0.563175\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317682; batch adversarial loss: 0.599985\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387610; batch adversarial loss: 0.488784\n",
      "epoch 186; iter: 0; batch classifier loss: 0.396303; batch adversarial loss: 0.544932\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339915; batch adversarial loss: 0.516979\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311107; batch adversarial loss: 0.581720\n",
      "epoch 189; iter: 0; batch classifier loss: 0.423045; batch adversarial loss: 0.489381\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321447; batch adversarial loss: 0.535130\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350619; batch adversarial loss: 0.544611\n",
      "epoch 192; iter: 0; batch classifier loss: 0.427998; batch adversarial loss: 0.525283\n",
      "epoch 193; iter: 0; batch classifier loss: 0.400272; batch adversarial loss: 0.544301\n",
      "epoch 194; iter: 0; batch classifier loss: 0.297069; batch adversarial loss: 0.564289\n",
      "epoch 195; iter: 0; batch classifier loss: 0.355695; batch adversarial loss: 0.452488\n",
      "epoch 196; iter: 0; batch classifier loss: 0.444777; batch adversarial loss: 0.535355\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344202; batch adversarial loss: 0.534979\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384599; batch adversarial loss: 0.581268\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329409; batch adversarial loss: 0.507433\n",
      "epoch 0; iter: 0; batch classifier loss: 0.767952; batch adversarial loss: 1.134182\n",
      "epoch 1; iter: 0; batch classifier loss: 0.857381; batch adversarial loss: 1.267239\n",
      "epoch 2; iter: 0; batch classifier loss: 0.998829; batch adversarial loss: 1.210414\n",
      "epoch 3; iter: 0; batch classifier loss: 1.025783; batch adversarial loss: 1.145511\n",
      "epoch 4; iter: 0; batch classifier loss: 1.308375; batch adversarial loss: 1.155339\n",
      "epoch 5; iter: 0; batch classifier loss: 1.146803; batch adversarial loss: 1.001454\n",
      "epoch 6; iter: 0; batch classifier loss: 1.023123; batch adversarial loss: 0.920075\n",
      "epoch 7; iter: 0; batch classifier loss: 0.997618; batch adversarial loss: 0.846191\n",
      "epoch 8; iter: 0; batch classifier loss: 0.916667; batch adversarial loss: 0.795411\n",
      "epoch 9; iter: 0; batch classifier loss: 0.794337; batch adversarial loss: 0.720344\n",
      "epoch 10; iter: 0; batch classifier loss: 0.675013; batch adversarial loss: 0.657183\n",
      "epoch 11; iter: 0; batch classifier loss: 0.629138; batch adversarial loss: 0.651179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.616113; batch adversarial loss: 0.592535\n",
      "epoch 13; iter: 0; batch classifier loss: 0.572540; batch adversarial loss: 0.594152\n",
      "epoch 14; iter: 0; batch classifier loss: 0.584585; batch adversarial loss: 0.599557\n",
      "epoch 15; iter: 0; batch classifier loss: 0.571984; batch adversarial loss: 0.543757\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507729; batch adversarial loss: 0.536136\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516867; batch adversarial loss: 0.577554\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539071; batch adversarial loss: 0.608391\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528138; batch adversarial loss: 0.591945\n",
      "epoch 20; iter: 0; batch classifier loss: 0.570193; batch adversarial loss: 0.672660\n",
      "epoch 21; iter: 0; batch classifier loss: 0.564516; batch adversarial loss: 0.582458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470163; batch adversarial loss: 0.556848\n",
      "epoch 23; iter: 0; batch classifier loss: 0.548267; batch adversarial loss: 0.549099\n",
      "epoch 24; iter: 0; batch classifier loss: 0.428673; batch adversarial loss: 0.560848\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496542; batch adversarial loss: 0.543595\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469293; batch adversarial loss: 0.534436\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511851; batch adversarial loss: 0.574482\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475320; batch adversarial loss: 0.522551\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497503; batch adversarial loss: 0.566648\n",
      "epoch 30; iter: 0; batch classifier loss: 0.516352; batch adversarial loss: 0.582209\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495995; batch adversarial loss: 0.562853\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513297; batch adversarial loss: 0.523269\n",
      "epoch 33; iter: 0; batch classifier loss: 0.470717; batch adversarial loss: 0.557987\n",
      "epoch 34; iter: 0; batch classifier loss: 0.527106; batch adversarial loss: 0.566840\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420078; batch adversarial loss: 0.524307\n",
      "epoch 36; iter: 0; batch classifier loss: 0.401567; batch adversarial loss: 0.581633\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489610; batch adversarial loss: 0.508089\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481494; batch adversarial loss: 0.596771\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432876; batch adversarial loss: 0.510109\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417131; batch adversarial loss: 0.489034\n",
      "epoch 41; iter: 0; batch classifier loss: 0.529640; batch adversarial loss: 0.486608\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502653; batch adversarial loss: 0.517570\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486970; batch adversarial loss: 0.477519\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485166; batch adversarial loss: 0.537429\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454617; batch adversarial loss: 0.536759\n",
      "epoch 46; iter: 0; batch classifier loss: 0.506119; batch adversarial loss: 0.525894\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452825; batch adversarial loss: 0.616026\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452068; batch adversarial loss: 0.560188\n",
      "epoch 49; iter: 0; batch classifier loss: 0.510415; batch adversarial loss: 0.589998\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439714; batch adversarial loss: 0.550358\n",
      "epoch 51; iter: 0; batch classifier loss: 0.485440; batch adversarial loss: 0.497992\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405008; batch adversarial loss: 0.566223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.457610; batch adversarial loss: 0.517954\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408867; batch adversarial loss: 0.481134\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412176; batch adversarial loss: 0.539484\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426906; batch adversarial loss: 0.661556\n",
      "epoch 57; iter: 0; batch classifier loss: 0.550963; batch adversarial loss: 0.460662\n",
      "epoch 58; iter: 0; batch classifier loss: 0.461052; batch adversarial loss: 0.599579\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369731; batch adversarial loss: 0.533689\n",
      "epoch 60; iter: 0; batch classifier loss: 0.467537; batch adversarial loss: 0.543725\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454798; batch adversarial loss: 0.546876\n",
      "epoch 62; iter: 0; batch classifier loss: 0.522679; batch adversarial loss: 0.466582\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435731; batch adversarial loss: 0.525098\n",
      "epoch 64; iter: 0; batch classifier loss: 0.347988; batch adversarial loss: 0.522018\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455211; batch adversarial loss: 0.569935\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428388; batch adversarial loss: 0.550919\n",
      "epoch 67; iter: 0; batch classifier loss: 0.480459; batch adversarial loss: 0.488796\n",
      "epoch 68; iter: 0; batch classifier loss: 0.354047; batch adversarial loss: 0.570252\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373284; batch adversarial loss: 0.561809\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434689; batch adversarial loss: 0.556095\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426221; batch adversarial loss: 0.581929\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422531; batch adversarial loss: 0.536256\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385819; batch adversarial loss: 0.489279\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410877; batch adversarial loss: 0.515128\n",
      "epoch 75; iter: 0; batch classifier loss: 0.460559; batch adversarial loss: 0.551058\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364277; batch adversarial loss: 0.590082\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407564; batch adversarial loss: 0.505991\n",
      "epoch 78; iter: 0; batch classifier loss: 0.430082; batch adversarial loss: 0.497493\n",
      "epoch 79; iter: 0; batch classifier loss: 0.441539; batch adversarial loss: 0.505357\n",
      "epoch 80; iter: 0; batch classifier loss: 0.377700; batch adversarial loss: 0.517384\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365910; batch adversarial loss: 0.546793\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403978; batch adversarial loss: 0.553936\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441405; batch adversarial loss: 0.530054\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368724; batch adversarial loss: 0.544026\n",
      "epoch 85; iter: 0; batch classifier loss: 0.442955; batch adversarial loss: 0.577231\n",
      "epoch 86; iter: 0; batch classifier loss: 0.429753; batch adversarial loss: 0.594387\n",
      "epoch 87; iter: 0; batch classifier loss: 0.359959; batch adversarial loss: 0.582225\n",
      "epoch 88; iter: 0; batch classifier loss: 0.505167; batch adversarial loss: 0.531888\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407005; batch adversarial loss: 0.597058\n",
      "epoch 90; iter: 0; batch classifier loss: 0.310775; batch adversarial loss: 0.542883\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386413; batch adversarial loss: 0.502347\n",
      "epoch 92; iter: 0; batch classifier loss: 0.465562; batch adversarial loss: 0.545159\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353250; batch adversarial loss: 0.544746\n",
      "epoch 94; iter: 0; batch classifier loss: 0.475086; batch adversarial loss: 0.546427\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398561; batch adversarial loss: 0.535519\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414997; batch adversarial loss: 0.555022\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404211; batch adversarial loss: 0.607684\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358269; batch adversarial loss: 0.504453\n",
      "epoch 99; iter: 0; batch classifier loss: 0.330241; batch adversarial loss: 0.590656\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404579; batch adversarial loss: 0.566389\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352668; batch adversarial loss: 0.593071\n",
      "epoch 102; iter: 0; batch classifier loss: 0.396311; batch adversarial loss: 0.505863\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375276; batch adversarial loss: 0.523523\n",
      "epoch 104; iter: 0; batch classifier loss: 0.336585; batch adversarial loss: 0.506285\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398943; batch adversarial loss: 0.500132\n",
      "epoch 106; iter: 0; batch classifier loss: 0.427368; batch adversarial loss: 0.545310\n",
      "epoch 107; iter: 0; batch classifier loss: 0.322347; batch adversarial loss: 0.509151\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396694; batch adversarial loss: 0.580757\n",
      "epoch 109; iter: 0; batch classifier loss: 0.445668; batch adversarial loss: 0.481640\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362403; batch adversarial loss: 0.499689\n",
      "epoch 111; iter: 0; batch classifier loss: 0.460478; batch adversarial loss: 0.562248\n",
      "epoch 112; iter: 0; batch classifier loss: 0.436168; batch adversarial loss: 0.572860\n",
      "epoch 113; iter: 0; batch classifier loss: 0.454012; batch adversarial loss: 0.580110\n",
      "epoch 114; iter: 0; batch classifier loss: 0.370923; batch adversarial loss: 0.517952\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358762; batch adversarial loss: 0.545045\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350494; batch adversarial loss: 0.526548\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382528; batch adversarial loss: 0.526805\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354282; batch adversarial loss: 0.525626\n",
      "epoch 119; iter: 0; batch classifier loss: 0.335384; batch adversarial loss: 0.515984\n",
      "epoch 120; iter: 0; batch classifier loss: 0.451134; batch adversarial loss: 0.533363\n",
      "epoch 121; iter: 0; batch classifier loss: 0.330316; batch adversarial loss: 0.574139\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392196; batch adversarial loss: 0.505763\n",
      "epoch 123; iter: 0; batch classifier loss: 0.303420; batch adversarial loss: 0.597349\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401674; batch adversarial loss: 0.619089\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377951; batch adversarial loss: 0.609497\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381893; batch adversarial loss: 0.599196\n",
      "epoch 127; iter: 0; batch classifier loss: 0.429393; batch adversarial loss: 0.480426\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389910; batch adversarial loss: 0.481266\n",
      "epoch 129; iter: 0; batch classifier loss: 0.449606; batch adversarial loss: 0.572012\n",
      "epoch 130; iter: 0; batch classifier loss: 0.351355; batch adversarial loss: 0.671523\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360053; batch adversarial loss: 0.536300\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334796; batch adversarial loss: 0.515906\n",
      "epoch 133; iter: 0; batch classifier loss: 0.415650; batch adversarial loss: 0.553701\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403502; batch adversarial loss: 0.580373\n",
      "epoch 135; iter: 0; batch classifier loss: 0.324759; batch adversarial loss: 0.534362\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332508; batch adversarial loss: 0.498211\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368500; batch adversarial loss: 0.526126\n",
      "epoch 138; iter: 0; batch classifier loss: 0.305362; batch adversarial loss: 0.646506\n",
      "epoch 139; iter: 0; batch classifier loss: 0.436861; batch adversarial loss: 0.526431\n",
      "epoch 140; iter: 0; batch classifier loss: 0.323435; batch adversarial loss: 0.571319\n",
      "epoch 141; iter: 0; batch classifier loss: 0.414883; batch adversarial loss: 0.507237\n",
      "epoch 142; iter: 0; batch classifier loss: 0.352686; batch adversarial loss: 0.580751\n",
      "epoch 143; iter: 0; batch classifier loss: 0.415866; batch adversarial loss: 0.562778\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336297; batch adversarial loss: 0.517008\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369351; batch adversarial loss: 0.553846\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350053; batch adversarial loss: 0.453477\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340438; batch adversarial loss: 0.517676\n",
      "epoch 148; iter: 0; batch classifier loss: 0.326836; batch adversarial loss: 0.517042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.405179; batch adversarial loss: 0.580872\n",
      "epoch 150; iter: 0; batch classifier loss: 0.252105; batch adversarial loss: 0.580844\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374028; batch adversarial loss: 0.580935\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350633; batch adversarial loss: 0.562135\n",
      "epoch 153; iter: 0; batch classifier loss: 0.286927; batch adversarial loss: 0.544829\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382652; batch adversarial loss: 0.499349\n",
      "epoch 155; iter: 0; batch classifier loss: 0.278328; batch adversarial loss: 0.562034\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341896; batch adversarial loss: 0.610484\n",
      "epoch 157; iter: 0; batch classifier loss: 0.428881; batch adversarial loss: 0.580673\n",
      "epoch 158; iter: 0; batch classifier loss: 0.270718; batch adversarial loss: 0.477972\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337395; batch adversarial loss: 0.534815\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351874; batch adversarial loss: 0.526126\n",
      "epoch 161; iter: 0; batch classifier loss: 0.301288; batch adversarial loss: 0.459379\n",
      "epoch 162; iter: 0; batch classifier loss: 0.341854; batch adversarial loss: 0.549827\n",
      "epoch 163; iter: 0; batch classifier loss: 0.293584; batch adversarial loss: 0.497291\n",
      "epoch 164; iter: 0; batch classifier loss: 0.303483; batch adversarial loss: 0.514406\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330164; batch adversarial loss: 0.581478\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357827; batch adversarial loss: 0.488754\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380097; batch adversarial loss: 0.469129\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373223; batch adversarial loss: 0.539690\n",
      "epoch 169; iter: 0; batch classifier loss: 0.293025; batch adversarial loss: 0.517637\n",
      "epoch 170; iter: 0; batch classifier loss: 0.347794; batch adversarial loss: 0.540336\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346382; batch adversarial loss: 0.501857\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385485; batch adversarial loss: 0.545507\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356133; batch adversarial loss: 0.554115\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326742; batch adversarial loss: 0.553174\n",
      "epoch 175; iter: 0; batch classifier loss: 0.347676; batch adversarial loss: 0.635300\n",
      "epoch 176; iter: 0; batch classifier loss: 0.430090; batch adversarial loss: 0.591315\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303690; batch adversarial loss: 0.516906\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350283; batch adversarial loss: 0.536584\n",
      "epoch 179; iter: 0; batch classifier loss: 0.280511; batch adversarial loss: 0.580930\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353839; batch adversarial loss: 0.552813\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349134; batch adversarial loss: 0.562922\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372233; batch adversarial loss: 0.497235\n",
      "epoch 183; iter: 0; batch classifier loss: 0.331152; batch adversarial loss: 0.570563\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362610; batch adversarial loss: 0.525766\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392964; batch adversarial loss: 0.489318\n",
      "epoch 186; iter: 0; batch classifier loss: 0.264738; batch adversarial loss: 0.471443\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389570; batch adversarial loss: 0.635051\n",
      "epoch 188; iter: 0; batch classifier loss: 0.288150; batch adversarial loss: 0.535568\n",
      "epoch 189; iter: 0; batch classifier loss: 0.457861; batch adversarial loss: 0.507365\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309679; batch adversarial loss: 0.553630\n",
      "epoch 191; iter: 0; batch classifier loss: 0.312439; batch adversarial loss: 0.507784\n",
      "epoch 192; iter: 0; batch classifier loss: 0.281626; batch adversarial loss: 0.590780\n",
      "epoch 193; iter: 0; batch classifier loss: 0.314832; batch adversarial loss: 0.506256\n",
      "epoch 194; iter: 0; batch classifier loss: 0.345792; batch adversarial loss: 0.635812\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359620; batch adversarial loss: 0.570188\n",
      "epoch 196; iter: 0; batch classifier loss: 0.286618; batch adversarial loss: 0.581978\n",
      "epoch 197; iter: 0; batch classifier loss: 0.331189; batch adversarial loss: 0.524393\n",
      "epoch 198; iter: 0; batch classifier loss: 0.320235; batch adversarial loss: 0.627109\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357025; batch adversarial loss: 0.545568\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672679; batch adversarial loss: 0.688612\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610836; batch adversarial loss: 0.642768\n",
      "epoch 2; iter: 0; batch classifier loss: 0.492533; batch adversarial loss: 0.645800\n",
      "epoch 3; iter: 0; batch classifier loss: 0.587735; batch adversarial loss: 0.631358\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565045; batch adversarial loss: 0.627237\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564658; batch adversarial loss: 0.617990\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564461; batch adversarial loss: 0.622053\n",
      "epoch 7; iter: 0; batch classifier loss: 0.585819; batch adversarial loss: 0.621421\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495970; batch adversarial loss: 0.593832\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521795; batch adversarial loss: 0.549908\n",
      "epoch 10; iter: 0; batch classifier loss: 0.586926; batch adversarial loss: 0.595835\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540574; batch adversarial loss: 0.576783\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530519; batch adversarial loss: 0.560581\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501892; batch adversarial loss: 0.636572\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448314; batch adversarial loss: 0.569030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523510; batch adversarial loss: 0.531208\n",
      "epoch 16; iter: 0; batch classifier loss: 0.449809; batch adversarial loss: 0.623359\n",
      "epoch 17; iter: 0; batch classifier loss: 0.502032; batch adversarial loss: 0.605894\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446938; batch adversarial loss: 0.550996\n",
      "epoch 19; iter: 0; batch classifier loss: 0.561431; batch adversarial loss: 0.635421\n",
      "epoch 20; iter: 0; batch classifier loss: 0.417698; batch adversarial loss: 0.611620\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512574; batch adversarial loss: 0.605937\n",
      "epoch 22; iter: 0; batch classifier loss: 0.444979; batch adversarial loss: 0.601241\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519212; batch adversarial loss: 0.537277\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467780; batch adversarial loss: 0.582945\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480466; batch adversarial loss: 0.546327\n",
      "epoch 26; iter: 0; batch classifier loss: 0.578261; batch adversarial loss: 0.523049\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475608; batch adversarial loss: 0.605606\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542526; batch adversarial loss: 0.544530\n",
      "epoch 29; iter: 0; batch classifier loss: 0.515495; batch adversarial loss: 0.570329\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485630; batch adversarial loss: 0.585799\n",
      "epoch 31; iter: 0; batch classifier loss: 0.556359; batch adversarial loss: 0.589754\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426804; batch adversarial loss: 0.508475\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448725; batch adversarial loss: 0.575265\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437994; batch adversarial loss: 0.522820\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405676; batch adversarial loss: 0.577346\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456463; batch adversarial loss: 0.555501\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445046; batch adversarial loss: 0.544522\n",
      "epoch 38; iter: 0; batch classifier loss: 0.391801; batch adversarial loss: 0.527352\n",
      "epoch 39; iter: 0; batch classifier loss: 0.346383; batch adversarial loss: 0.616358\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466007; batch adversarial loss: 0.664991\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471213; batch adversarial loss: 0.571390\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422819; batch adversarial loss: 0.537244\n",
      "epoch 43; iter: 0; batch classifier loss: 0.348085; batch adversarial loss: 0.579347\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407583; batch adversarial loss: 0.511032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.430182; batch adversarial loss: 0.570784\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433661; batch adversarial loss: 0.536549\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432550; batch adversarial loss: 0.527430\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426997; batch adversarial loss: 0.606531\n",
      "epoch 49; iter: 0; batch classifier loss: 0.489033; batch adversarial loss: 0.501196\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426341; batch adversarial loss: 0.579993\n",
      "epoch 51; iter: 0; batch classifier loss: 0.459510; batch adversarial loss: 0.571555\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445524; batch adversarial loss: 0.581721\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466836; batch adversarial loss: 0.572051\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416179; batch adversarial loss: 0.581437\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408112; batch adversarial loss: 0.563210\n",
      "epoch 56; iter: 0; batch classifier loss: 0.401900; batch adversarial loss: 0.553729\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461741; batch adversarial loss: 0.553688\n",
      "epoch 58; iter: 0; batch classifier loss: 0.381294; batch adversarial loss: 0.466488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371134; batch adversarial loss: 0.519310\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426402; batch adversarial loss: 0.570451\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409584; batch adversarial loss: 0.544835\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399469; batch adversarial loss: 0.535878\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395820; batch adversarial loss: 0.611097\n",
      "epoch 64; iter: 0; batch classifier loss: 0.392927; batch adversarial loss: 0.627049\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438576; batch adversarial loss: 0.597400\n",
      "epoch 66; iter: 0; batch classifier loss: 0.500405; batch adversarial loss: 0.500665\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395726; batch adversarial loss: 0.537233\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395017; batch adversarial loss: 0.606596\n",
      "epoch 69; iter: 0; batch classifier loss: 0.354233; batch adversarial loss: 0.565596\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374102; batch adversarial loss: 0.447744\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384106; batch adversarial loss: 0.590379\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408352; batch adversarial loss: 0.626779\n",
      "epoch 73; iter: 0; batch classifier loss: 0.356094; batch adversarial loss: 0.581030\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430122; batch adversarial loss: 0.536415\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398320; batch adversarial loss: 0.608161\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364090; batch adversarial loss: 0.491083\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382000; batch adversarial loss: 0.580788\n",
      "epoch 78; iter: 0; batch classifier loss: 0.412333; batch adversarial loss: 0.518245\n",
      "epoch 79; iter: 0; batch classifier loss: 0.355712; batch adversarial loss: 0.571181\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367171; batch adversarial loss: 0.598221\n",
      "epoch 81; iter: 0; batch classifier loss: 0.543069; batch adversarial loss: 0.580370\n",
      "epoch 82; iter: 0; batch classifier loss: 0.340716; batch adversarial loss: 0.562369\n",
      "epoch 83; iter: 0; batch classifier loss: 0.348463; batch adversarial loss: 0.491010\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429280; batch adversarial loss: 0.598514\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425519; batch adversarial loss: 0.579326\n",
      "epoch 86; iter: 0; batch classifier loss: 0.488111; batch adversarial loss: 0.589709\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393718; batch adversarial loss: 0.554160\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357502; batch adversarial loss: 0.518452\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409379; batch adversarial loss: 0.488851\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392893; batch adversarial loss: 0.563187\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397713; batch adversarial loss: 0.545698\n",
      "epoch 92; iter: 0; batch classifier loss: 0.499767; batch adversarial loss: 0.554111\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366511; batch adversarial loss: 0.553389\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424412; batch adversarial loss: 0.588550\n",
      "epoch 95; iter: 0; batch classifier loss: 0.376116; batch adversarial loss: 0.517865\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394556; batch adversarial loss: 0.597499\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399521; batch adversarial loss: 0.553625\n",
      "epoch 98; iter: 0; batch classifier loss: 0.322897; batch adversarial loss: 0.562281\n",
      "epoch 99; iter: 0; batch classifier loss: 0.433223; batch adversarial loss: 0.589139\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393574; batch adversarial loss: 0.527572\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344103; batch adversarial loss: 0.492611\n",
      "epoch 102; iter: 0; batch classifier loss: 0.436888; batch adversarial loss: 0.588570\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399983; batch adversarial loss: 0.571350\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365393; batch adversarial loss: 0.518573\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424863; batch adversarial loss: 0.544775\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384769; batch adversarial loss: 0.571401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.336441; batch adversarial loss: 0.527075\n",
      "epoch 108; iter: 0; batch classifier loss: 0.424923; batch adversarial loss: 0.500537\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374560; batch adversarial loss: 0.535883\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363752; batch adversarial loss: 0.615409\n",
      "epoch 111; iter: 0; batch classifier loss: 0.392551; batch adversarial loss: 0.509580\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364862; batch adversarial loss: 0.615348\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354043; batch adversarial loss: 0.518031\n",
      "epoch 114; iter: 0; batch classifier loss: 0.328393; batch adversarial loss: 0.552896\n",
      "epoch 115; iter: 0; batch classifier loss: 0.323620; batch adversarial loss: 0.580659\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402280; batch adversarial loss: 0.536269\n",
      "epoch 117; iter: 0; batch classifier loss: 0.324481; batch adversarial loss: 0.544935\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404023; batch adversarial loss: 0.543744\n",
      "epoch 119; iter: 0; batch classifier loss: 0.336334; batch adversarial loss: 0.571616\n",
      "epoch 120; iter: 0; batch classifier loss: 0.390609; batch adversarial loss: 0.546020\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392497; batch adversarial loss: 0.597782\n",
      "epoch 122; iter: 0; batch classifier loss: 0.357865; batch adversarial loss: 0.597767\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399078; batch adversarial loss: 0.615098\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392930; batch adversarial loss: 0.527627\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361201; batch adversarial loss: 0.527662\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359860; batch adversarial loss: 0.527168\n",
      "epoch 127; iter: 0; batch classifier loss: 0.398634; batch adversarial loss: 0.588640\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379172; batch adversarial loss: 0.483039\n",
      "epoch 129; iter: 0; batch classifier loss: 0.444413; batch adversarial loss: 0.597670\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391497; batch adversarial loss: 0.606424\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399569; batch adversarial loss: 0.580081\n",
      "epoch 132; iter: 0; batch classifier loss: 0.345775; batch adversarial loss: 0.544800\n",
      "epoch 133; iter: 0; batch classifier loss: 0.470587; batch adversarial loss: 0.579873\n",
      "epoch 134; iter: 0; batch classifier loss: 0.242338; batch adversarial loss: 0.544795\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385862; batch adversarial loss: 0.553582\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338332; batch adversarial loss: 0.535691\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376323; batch adversarial loss: 0.579418\n",
      "epoch 138; iter: 0; batch classifier loss: 0.284095; batch adversarial loss: 0.501140\n",
      "epoch 139; iter: 0; batch classifier loss: 0.306695; batch adversarial loss: 0.640797\n",
      "epoch 140; iter: 0; batch classifier loss: 0.424689; batch adversarial loss: 0.562472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.383061; batch adversarial loss: 0.517530\n",
      "epoch 142; iter: 0; batch classifier loss: 0.298231; batch adversarial loss: 0.598196\n",
      "epoch 143; iter: 0; batch classifier loss: 0.431117; batch adversarial loss: 0.623765\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376720; batch adversarial loss: 0.546032\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385539; batch adversarial loss: 0.559661\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350062; batch adversarial loss: 0.423026\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336294; batch adversarial loss: 0.587380\n",
      "epoch 148; iter: 0; batch classifier loss: 0.435910; batch adversarial loss: 0.537433\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384269; batch adversarial loss: 0.589055\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371937; batch adversarial loss: 0.509373\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347460; batch adversarial loss: 0.464294\n",
      "epoch 152; iter: 0; batch classifier loss: 0.318575; batch adversarial loss: 0.535580\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346509; batch adversarial loss: 0.544654\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354168; batch adversarial loss: 0.642180\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369087; batch adversarial loss: 0.482269\n",
      "epoch 156; iter: 0; batch classifier loss: 0.487983; batch adversarial loss: 0.605267\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340080; batch adversarial loss: 0.597324\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397603; batch adversarial loss: 0.482377\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398807; batch adversarial loss: 0.606914\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308846; batch adversarial loss: 0.553784\n",
      "epoch 161; iter: 0; batch classifier loss: 0.423842; batch adversarial loss: 0.544186\n",
      "epoch 162; iter: 0; batch classifier loss: 0.305163; batch adversarial loss: 0.482351\n",
      "epoch 163; iter: 0; batch classifier loss: 0.418083; batch adversarial loss: 0.571166\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339399; batch adversarial loss: 0.580663\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352472; batch adversarial loss: 0.482562\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370425; batch adversarial loss: 0.580327\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366845; batch adversarial loss: 0.598363\n",
      "epoch 168; iter: 0; batch classifier loss: 0.424906; batch adversarial loss: 0.579637\n",
      "epoch 169; iter: 0; batch classifier loss: 0.424356; batch adversarial loss: 0.597223\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362463; batch adversarial loss: 0.553381\n",
      "epoch 171; iter: 0; batch classifier loss: 0.377887; batch adversarial loss: 0.634025\n",
      "epoch 172; iter: 0; batch classifier loss: 0.393450; batch adversarial loss: 0.544803\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341301; batch adversarial loss: 0.546054\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341080; batch adversarial loss: 0.570731\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360705; batch adversarial loss: 0.510021\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388477; batch adversarial loss: 0.517799\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321343; batch adversarial loss: 0.500184\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364161; batch adversarial loss: 0.571830\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369269; batch adversarial loss: 0.518040\n",
      "epoch 180; iter: 0; batch classifier loss: 0.422482; batch adversarial loss: 0.526797\n",
      "epoch 181; iter: 0; batch classifier loss: 0.404481; batch adversarial loss: 0.544635\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402093; batch adversarial loss: 0.526867\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375931; batch adversarial loss: 0.544373\n",
      "epoch 184; iter: 0; batch classifier loss: 0.503568; batch adversarial loss: 0.580322\n",
      "epoch 185; iter: 0; batch classifier loss: 0.399585; batch adversarial loss: 0.571685\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377710; batch adversarial loss: 0.589209\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376305; batch adversarial loss: 0.615805\n",
      "epoch 188; iter: 0; batch classifier loss: 0.357610; batch adversarial loss: 0.598337\n",
      "epoch 189; iter: 0; batch classifier loss: 0.515012; batch adversarial loss: 0.526598\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345252; batch adversarial loss: 0.527143\n",
      "epoch 191; iter: 0; batch classifier loss: 0.369637; batch adversarial loss: 0.562339\n",
      "epoch 192; iter: 0; batch classifier loss: 0.391755; batch adversarial loss: 0.579744\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372643; batch adversarial loss: 0.589055\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341054; batch adversarial loss: 0.553685\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381286; batch adversarial loss: 0.473663\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360442; batch adversarial loss: 0.509475\n",
      "epoch 197; iter: 0; batch classifier loss: 0.302388; batch adversarial loss: 0.623785\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366181; batch adversarial loss: 0.606629\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397940; batch adversarial loss: 0.527820\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687570; batch adversarial loss: 0.649594\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578740; batch adversarial loss: 0.648005\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603573; batch adversarial loss: 0.642284\n",
      "epoch 3; iter: 0; batch classifier loss: 0.592511; batch adversarial loss: 0.605339\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513162; batch adversarial loss: 0.626322\n",
      "epoch 5; iter: 0; batch classifier loss: 0.464095; batch adversarial loss: 0.568370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579886; batch adversarial loss: 0.634228\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573115; batch adversarial loss: 0.612656\n",
      "epoch 8; iter: 0; batch classifier loss: 0.612228; batch adversarial loss: 0.643808\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500331; batch adversarial loss: 0.510688\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509146; batch adversarial loss: 0.563495\n",
      "epoch 11; iter: 0; batch classifier loss: 0.558923; batch adversarial loss: 0.551839\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506993; batch adversarial loss: 0.570112\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536744; batch adversarial loss: 0.567488\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509583; batch adversarial loss: 0.640119\n",
      "epoch 15; iter: 0; batch classifier loss: 0.402972; batch adversarial loss: 0.605696\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513955; batch adversarial loss: 0.586304\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508207; batch adversarial loss: 0.592200\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517623; batch adversarial loss: 0.552272\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506190; batch adversarial loss: 0.550353\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507050; batch adversarial loss: 0.556327\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481737; batch adversarial loss: 0.532886\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498108; batch adversarial loss: 0.550806\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499461; batch adversarial loss: 0.517080\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494517; batch adversarial loss: 0.434252\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484309; batch adversarial loss: 0.546881\n",
      "epoch 26; iter: 0; batch classifier loss: 0.417275; batch adversarial loss: 0.493818\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442273; batch adversarial loss: 0.543010\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432441; batch adversarial loss: 0.586715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422461; batch adversarial loss: 0.594175\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490572; batch adversarial loss: 0.480685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.419472; batch adversarial loss: 0.573502\n",
      "epoch 32; iter: 0; batch classifier loss: 0.418600; batch adversarial loss: 0.580216\n",
      "epoch 33; iter: 0; batch classifier loss: 0.493238; batch adversarial loss: 0.503495\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464648; batch adversarial loss: 0.549738\n",
      "epoch 35; iter: 0; batch classifier loss: 0.490082; batch adversarial loss: 0.613452\n",
      "epoch 36; iter: 0; batch classifier loss: 0.419347; batch adversarial loss: 0.508696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.506973; batch adversarial loss: 0.545906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.450499; batch adversarial loss: 0.559994\n",
      "epoch 39; iter: 0; batch classifier loss: 0.526109; batch adversarial loss: 0.609385\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393969; batch adversarial loss: 0.591373\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472050; batch adversarial loss: 0.521028\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462344; batch adversarial loss: 0.645765\n",
      "epoch 43; iter: 0; batch classifier loss: 0.381054; batch adversarial loss: 0.521978\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472583; batch adversarial loss: 0.491864\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395853; batch adversarial loss: 0.543977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424741; batch adversarial loss: 0.518143\n",
      "epoch 47; iter: 0; batch classifier loss: 0.497754; batch adversarial loss: 0.533343\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433742; batch adversarial loss: 0.481223\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420300; batch adversarial loss: 0.525560\n",
      "epoch 50; iter: 0; batch classifier loss: 0.344714; batch adversarial loss: 0.543594\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411292; batch adversarial loss: 0.542506\n",
      "epoch 52; iter: 0; batch classifier loss: 0.502958; batch adversarial loss: 0.573601\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395676; batch adversarial loss: 0.580557\n",
      "epoch 54; iter: 0; batch classifier loss: 0.436140; batch adversarial loss: 0.513319\n",
      "epoch 55; iter: 0; batch classifier loss: 0.488521; batch adversarial loss: 0.543308\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393049; batch adversarial loss: 0.508036\n",
      "epoch 57; iter: 0; batch classifier loss: 0.385635; batch adversarial loss: 0.452131\n",
      "epoch 58; iter: 0; batch classifier loss: 0.376465; batch adversarial loss: 0.582113\n",
      "epoch 59; iter: 0; batch classifier loss: 0.496389; batch adversarial loss: 0.536609\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432432; batch adversarial loss: 0.526238\n",
      "epoch 61; iter: 0; batch classifier loss: 0.390134; batch adversarial loss: 0.489421\n",
      "epoch 62; iter: 0; batch classifier loss: 0.458173; batch adversarial loss: 0.554625\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460045; batch adversarial loss: 0.508660\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422451; batch adversarial loss: 0.489194\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394127; batch adversarial loss: 0.664383\n",
      "epoch 66; iter: 0; batch classifier loss: 0.350493; batch adversarial loss: 0.618999\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417833; batch adversarial loss: 0.534160\n",
      "epoch 68; iter: 0; batch classifier loss: 0.414000; batch adversarial loss: 0.581222\n",
      "epoch 69; iter: 0; batch classifier loss: 0.385963; batch adversarial loss: 0.514718\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421513; batch adversarial loss: 0.600680\n",
      "epoch 71; iter: 0; batch classifier loss: 0.342118; batch adversarial loss: 0.608531\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419997; batch adversarial loss: 0.563654\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366806; batch adversarial loss: 0.571664\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404700; batch adversarial loss: 0.514521\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412192; batch adversarial loss: 0.514316\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368427; batch adversarial loss: 0.541596\n",
      "epoch 77; iter: 0; batch classifier loss: 0.499635; batch adversarial loss: 0.502248\n",
      "epoch 78; iter: 0; batch classifier loss: 0.436011; batch adversarial loss: 0.582563\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358034; batch adversarial loss: 0.474249\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431305; batch adversarial loss: 0.545430\n",
      "epoch 81; iter: 0; batch classifier loss: 0.442319; batch adversarial loss: 0.521711\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416699; batch adversarial loss: 0.611790\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392118; batch adversarial loss: 0.490025\n",
      "epoch 84; iter: 0; batch classifier loss: 0.428410; batch adversarial loss: 0.490014\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396169; batch adversarial loss: 0.601871\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427284; batch adversarial loss: 0.481198\n",
      "epoch 87; iter: 0; batch classifier loss: 0.448539; batch adversarial loss: 0.553745\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411356; batch adversarial loss: 0.526198\n",
      "epoch 89; iter: 0; batch classifier loss: 0.360283; batch adversarial loss: 0.563277\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419107; batch adversarial loss: 0.470354\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433887; batch adversarial loss: 0.498521\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381578; batch adversarial loss: 0.526289\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394354; batch adversarial loss: 0.581284\n",
      "epoch 94; iter: 0; batch classifier loss: 0.517929; batch adversarial loss: 0.581137\n",
      "epoch 95; iter: 0; batch classifier loss: 0.383416; batch adversarial loss: 0.534776\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389958; batch adversarial loss: 0.564726\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391362; batch adversarial loss: 0.488039\n",
      "epoch 98; iter: 0; batch classifier loss: 0.420353; batch adversarial loss: 0.554083\n",
      "epoch 99; iter: 0; batch classifier loss: 0.327330; batch adversarial loss: 0.526015\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358964; batch adversarial loss: 0.572154\n",
      "epoch 101; iter: 0; batch classifier loss: 0.419787; batch adversarial loss: 0.553602\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351445; batch adversarial loss: 0.535626\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379181; batch adversarial loss: 0.507006\n",
      "epoch 104; iter: 0; batch classifier loss: 0.338388; batch adversarial loss: 0.564187\n",
      "epoch 105; iter: 0; batch classifier loss: 0.450336; batch adversarial loss: 0.544008\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379540; batch adversarial loss: 0.618290\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355717; batch adversarial loss: 0.497541\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384151; batch adversarial loss: 0.535636\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359241; batch adversarial loss: 0.544760\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363556; batch adversarial loss: 0.525467\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418600; batch adversarial loss: 0.592748\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430972; batch adversarial loss: 0.571498\n",
      "epoch 113; iter: 0; batch classifier loss: 0.322784; batch adversarial loss: 0.505930\n",
      "epoch 114; iter: 0; batch classifier loss: 0.423422; batch adversarial loss: 0.488091\n",
      "epoch 115; iter: 0; batch classifier loss: 0.321694; batch adversarial loss: 0.533674\n",
      "epoch 116; iter: 0; batch classifier loss: 0.409417; batch adversarial loss: 0.486122\n",
      "epoch 117; iter: 0; batch classifier loss: 0.318831; batch adversarial loss: 0.469582\n",
      "epoch 118; iter: 0; batch classifier loss: 0.364537; batch adversarial loss: 0.546538\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366939; batch adversarial loss: 0.497502\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387565; batch adversarial loss: 0.608618\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347670; batch adversarial loss: 0.656446\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418149; batch adversarial loss: 0.571945\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414361; batch adversarial loss: 0.590142\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343362; batch adversarial loss: 0.599862\n",
      "epoch 125; iter: 0; batch classifier loss: 0.424068; batch adversarial loss: 0.497489\n",
      "epoch 126; iter: 0; batch classifier loss: 0.440960; batch adversarial loss: 0.554009\n",
      "epoch 127; iter: 0; batch classifier loss: 0.466188; batch adversarial loss: 0.479877\n",
      "epoch 128; iter: 0; batch classifier loss: 0.380673; batch adversarial loss: 0.572796\n",
      "epoch 129; iter: 0; batch classifier loss: 0.384641; batch adversarial loss: 0.516616\n",
      "epoch 130; iter: 0; batch classifier loss: 0.426274; batch adversarial loss: 0.469784\n",
      "epoch 131; iter: 0; batch classifier loss: 0.429241; batch adversarial loss: 0.515819\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392591; batch adversarial loss: 0.545227\n",
      "epoch 133; iter: 0; batch classifier loss: 0.309403; batch adversarial loss: 0.619646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.378619; batch adversarial loss: 0.562580\n",
      "epoch 135; iter: 0; batch classifier loss: 0.331445; batch adversarial loss: 0.515761\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401579; batch adversarial loss: 0.551938\n",
      "epoch 137; iter: 0; batch classifier loss: 0.409755; batch adversarial loss: 0.553365\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335512; batch adversarial loss: 0.610771\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362901; batch adversarial loss: 0.580668\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374285; batch adversarial loss: 0.554369\n",
      "epoch 141; iter: 0; batch classifier loss: 0.503172; batch adversarial loss: 0.471537\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339065; batch adversarial loss: 0.461199\n",
      "epoch 143; iter: 0; batch classifier loss: 0.332686; batch adversarial loss: 0.544842\n",
      "epoch 144; iter: 0; batch classifier loss: 0.454991; batch adversarial loss: 0.599366\n",
      "epoch 145; iter: 0; batch classifier loss: 0.446146; batch adversarial loss: 0.525956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378541; batch adversarial loss: 0.554063\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393956; batch adversarial loss: 0.544314\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386391; batch adversarial loss: 0.572487\n",
      "epoch 149; iter: 0; batch classifier loss: 0.324915; batch adversarial loss: 0.610716\n",
      "epoch 150; iter: 0; batch classifier loss: 0.410983; batch adversarial loss: 0.525903\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417647; batch adversarial loss: 0.582817\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372175; batch adversarial loss: 0.525505\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363771; batch adversarial loss: 0.515188\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358461; batch adversarial loss: 0.571832\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392970; batch adversarial loss: 0.573124\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328368; batch adversarial loss: 0.572564\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381321; batch adversarial loss: 0.525497\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382078; batch adversarial loss: 0.553434\n",
      "epoch 159; iter: 0; batch classifier loss: 0.397161; batch adversarial loss: 0.543515\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370051; batch adversarial loss: 0.535520\n",
      "epoch 161; iter: 0; batch classifier loss: 0.340181; batch adversarial loss: 0.581702\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400171; batch adversarial loss: 0.572093\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331458; batch adversarial loss: 0.581509\n",
      "epoch 164; iter: 0; batch classifier loss: 0.374550; batch adversarial loss: 0.563155\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377990; batch adversarial loss: 0.507435\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367736; batch adversarial loss: 0.441198\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376410; batch adversarial loss: 0.526320\n",
      "epoch 168; iter: 0; batch classifier loss: 0.391839; batch adversarial loss: 0.457530\n",
      "epoch 169; iter: 0; batch classifier loss: 0.296917; batch adversarial loss: 0.536616\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393350; batch adversarial loss: 0.600142\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340285; batch adversarial loss: 0.553510\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326844; batch adversarial loss: 0.488822\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330287; batch adversarial loss: 0.629924\n",
      "epoch 174; iter: 0; batch classifier loss: 0.293740; batch adversarial loss: 0.525624\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362677; batch adversarial loss: 0.562088\n",
      "epoch 176; iter: 0; batch classifier loss: 0.357333; batch adversarial loss: 0.591255\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381655; batch adversarial loss: 0.478313\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331303; batch adversarial loss: 0.618678\n",
      "epoch 179; iter: 0; batch classifier loss: 0.280353; batch adversarial loss: 0.583959\n",
      "epoch 180; iter: 0; batch classifier loss: 0.399561; batch adversarial loss: 0.534759\n",
      "epoch 181; iter: 0; batch classifier loss: 0.419282; batch adversarial loss: 0.563577\n",
      "epoch 182; iter: 0; batch classifier loss: 0.392246; batch adversarial loss: 0.572104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.329818; batch adversarial loss: 0.555702\n",
      "epoch 184; iter: 0; batch classifier loss: 0.407329; batch adversarial loss: 0.543448\n",
      "epoch 185; iter: 0; batch classifier loss: 0.325777; batch adversarial loss: 0.524282\n",
      "epoch 186; iter: 0; batch classifier loss: 0.360185; batch adversarial loss: 0.488257\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361947; batch adversarial loss: 0.514994\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328527; batch adversarial loss: 0.467519\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355185; batch adversarial loss: 0.627886\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359692; batch adversarial loss: 0.561388\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319246; batch adversarial loss: 0.469259\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361178; batch adversarial loss: 0.584318\n",
      "epoch 193; iter: 0; batch classifier loss: 0.429210; batch adversarial loss: 0.526219\n",
      "epoch 194; iter: 0; batch classifier loss: 0.448073; batch adversarial loss: 0.536516\n",
      "epoch 195; iter: 0; batch classifier loss: 0.352634; batch adversarial loss: 0.572523\n",
      "epoch 196; iter: 0; batch classifier loss: 0.303467; batch adversarial loss: 0.590874\n",
      "epoch 197; iter: 0; batch classifier loss: 0.331274; batch adversarial loss: 0.637028\n",
      "epoch 198; iter: 0; batch classifier loss: 0.407265; batch adversarial loss: 0.534981\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339194; batch adversarial loss: 0.545944\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708460; batch adversarial loss: 0.878440\n",
      "epoch 1; iter: 0; batch classifier loss: 0.658088; batch adversarial loss: 0.885769\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630552; batch adversarial loss: 0.802533\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603459; batch adversarial loss: 0.753259\n",
      "epoch 4; iter: 0; batch classifier loss: 0.645446; batch adversarial loss: 0.662872\n",
      "epoch 5; iter: 0; batch classifier loss: 0.675130; batch adversarial loss: 0.662984\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525612; batch adversarial loss: 0.626159\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567792; batch adversarial loss: 0.627151\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570919; batch adversarial loss: 0.609194\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548588; batch adversarial loss: 0.581133\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485407; batch adversarial loss: 0.635655\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518929; batch adversarial loss: 0.578401\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518583; batch adversarial loss: 0.614133\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535707; batch adversarial loss: 0.592532\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515396; batch adversarial loss: 0.590554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550996; batch adversarial loss: 0.607343\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445110; batch adversarial loss: 0.497648\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492165; batch adversarial loss: 0.502376\n",
      "epoch 18; iter: 0; batch classifier loss: 0.566271; batch adversarial loss: 0.601641\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474159; batch adversarial loss: 0.558949\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507392; batch adversarial loss: 0.519233\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491797; batch adversarial loss: 0.555169\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526604; batch adversarial loss: 0.579112\n",
      "epoch 23; iter: 0; batch classifier loss: 0.544685; batch adversarial loss: 0.537487\n",
      "epoch 24; iter: 0; batch classifier loss: 0.430416; batch adversarial loss: 0.544537\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499485; batch adversarial loss: 0.466817\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485864; batch adversarial loss: 0.614397\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505745; batch adversarial loss: 0.512503\n",
      "epoch 28; iter: 0; batch classifier loss: 0.411044; batch adversarial loss: 0.586599\n",
      "epoch 29; iter: 0; batch classifier loss: 0.556747; batch adversarial loss: 0.594314\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463225; batch adversarial loss: 0.643451\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477659; batch adversarial loss: 0.480624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.452006; batch adversarial loss: 0.515341\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462565; batch adversarial loss: 0.557059\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497333; batch adversarial loss: 0.635007\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483848; batch adversarial loss: 0.560736\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473021; batch adversarial loss: 0.572040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486199; batch adversarial loss: 0.557166\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457155; batch adversarial loss: 0.476008\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481470; batch adversarial loss: 0.580593\n",
      "epoch 40; iter: 0; batch classifier loss: 0.529492; batch adversarial loss: 0.534545\n",
      "epoch 41; iter: 0; batch classifier loss: 0.530532; batch adversarial loss: 0.545506\n",
      "epoch 42; iter: 0; batch classifier loss: 0.525721; batch adversarial loss: 0.607114\n",
      "epoch 43; iter: 0; batch classifier loss: 0.466672; batch adversarial loss: 0.503099\n",
      "epoch 44; iter: 0; batch classifier loss: 0.479498; batch adversarial loss: 0.492601\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404835; batch adversarial loss: 0.536251\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418327; batch adversarial loss: 0.498901\n",
      "epoch 47; iter: 0; batch classifier loss: 0.482173; batch adversarial loss: 0.528468\n",
      "epoch 48; iter: 0; batch classifier loss: 0.497580; batch adversarial loss: 0.553135\n",
      "epoch 49; iter: 0; batch classifier loss: 0.365005; batch adversarial loss: 0.582588\n",
      "epoch 50; iter: 0; batch classifier loss: 0.476589; batch adversarial loss: 0.624695\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424006; batch adversarial loss: 0.526994\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425686; batch adversarial loss: 0.563470\n",
      "epoch 53; iter: 0; batch classifier loss: 0.440381; batch adversarial loss: 0.581168\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439963; batch adversarial loss: 0.509035\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397405; batch adversarial loss: 0.589402\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416789; batch adversarial loss: 0.508412\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393776; batch adversarial loss: 0.553466\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434409; batch adversarial loss: 0.544653\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408255; batch adversarial loss: 0.517135\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363184; batch adversarial loss: 0.580856\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455192; batch adversarial loss: 0.571495\n",
      "epoch 62; iter: 0; batch classifier loss: 0.389128; batch adversarial loss: 0.572312\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403493; batch adversarial loss: 0.671182\n",
      "epoch 64; iter: 0; batch classifier loss: 0.399821; batch adversarial loss: 0.589329\n",
      "epoch 65; iter: 0; batch classifier loss: 0.504948; batch adversarial loss: 0.554653\n",
      "epoch 66; iter: 0; batch classifier loss: 0.477286; batch adversarial loss: 0.525931\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391496; batch adversarial loss: 0.544864\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412609; batch adversarial loss: 0.571851\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424696; batch adversarial loss: 0.579925\n",
      "epoch 70; iter: 0; batch classifier loss: 0.468301; batch adversarial loss: 0.564003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.357961; batch adversarial loss: 0.562607\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440506; batch adversarial loss: 0.553582\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400608; batch adversarial loss: 0.553750\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426022; batch adversarial loss: 0.544595\n",
      "epoch 75; iter: 0; batch classifier loss: 0.471539; batch adversarial loss: 0.535720\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384331; batch adversarial loss: 0.535811\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391827; batch adversarial loss: 0.597344\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457230; batch adversarial loss: 0.615978\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410765; batch adversarial loss: 0.588753\n",
      "epoch 80; iter: 0; batch classifier loss: 0.465506; batch adversarial loss: 0.562275\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419940; batch adversarial loss: 0.562103\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396608; batch adversarial loss: 0.544790\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410401; batch adversarial loss: 0.490148\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395278; batch adversarial loss: 0.534268\n",
      "epoch 85; iter: 0; batch classifier loss: 0.457995; batch adversarial loss: 0.561847\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365646; batch adversarial loss: 0.580934\n",
      "epoch 87; iter: 0; batch classifier loss: 0.415859; batch adversarial loss: 0.599997\n",
      "epoch 88; iter: 0; batch classifier loss: 0.305772; batch adversarial loss: 0.526930\n",
      "epoch 89; iter: 0; batch classifier loss: 0.465313; batch adversarial loss: 0.571421\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397473; batch adversarial loss: 0.490266\n",
      "epoch 91; iter: 0; batch classifier loss: 0.338179; batch adversarial loss: 0.535326\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365379; batch adversarial loss: 0.553672\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379615; batch adversarial loss: 0.525942\n",
      "epoch 94; iter: 0; batch classifier loss: 0.429985; batch adversarial loss: 0.562328\n",
      "epoch 95; iter: 0; batch classifier loss: 0.487032; batch adversarial loss: 0.570523\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416189; batch adversarial loss: 0.545524\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372518; batch adversarial loss: 0.627323\n",
      "epoch 98; iter: 0; batch classifier loss: 0.444355; batch adversarial loss: 0.582458\n",
      "epoch 99; iter: 0; batch classifier loss: 0.336766; batch adversarial loss: 0.627030\n",
      "epoch 100; iter: 0; batch classifier loss: 0.447473; batch adversarial loss: 0.634343\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385460; batch adversarial loss: 0.598682\n",
      "epoch 102; iter: 0; batch classifier loss: 0.501151; batch adversarial loss: 0.581689\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364735; batch adversarial loss: 0.525443\n",
      "epoch 104; iter: 0; batch classifier loss: 0.347571; batch adversarial loss: 0.507110\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395465; batch adversarial loss: 0.569843\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379704; batch adversarial loss: 0.563812\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348489; batch adversarial loss: 0.517778\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353888; batch adversarial loss: 0.544373\n",
      "epoch 109; iter: 0; batch classifier loss: 0.312015; batch adversarial loss: 0.552392\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351179; batch adversarial loss: 0.571071\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348161; batch adversarial loss: 0.563171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388103; batch adversarial loss: 0.526376\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391998; batch adversarial loss: 0.536310\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363726; batch adversarial loss: 0.516849\n",
      "epoch 115; iter: 0; batch classifier loss: 0.392941; batch adversarial loss: 0.607782\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412628; batch adversarial loss: 0.599417\n",
      "epoch 117; iter: 0; batch classifier loss: 0.443303; batch adversarial loss: 0.527460\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397828; batch adversarial loss: 0.499070\n",
      "epoch 119; iter: 0; batch classifier loss: 0.336546; batch adversarial loss: 0.590711\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386474; batch adversarial loss: 0.553172\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385201; batch adversarial loss: 0.525741\n",
      "epoch 122; iter: 0; batch classifier loss: 0.408605; batch adversarial loss: 0.500513\n",
      "epoch 123; iter: 0; batch classifier loss: 0.419686; batch adversarial loss: 0.652946\n",
      "epoch 124; iter: 0; batch classifier loss: 0.455648; batch adversarial loss: 0.562275\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384260; batch adversarial loss: 0.571806\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406137; batch adversarial loss: 0.599138\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384215; batch adversarial loss: 0.572349\n",
      "epoch 128; iter: 0; batch classifier loss: 0.423648; batch adversarial loss: 0.517115\n",
      "epoch 129; iter: 0; batch classifier loss: 0.404230; batch adversarial loss: 0.553817\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425695; batch adversarial loss: 0.491161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.376422; batch adversarial loss: 0.526455\n",
      "epoch 132; iter: 0; batch classifier loss: 0.410549; batch adversarial loss: 0.562363\n",
      "epoch 133; iter: 0; batch classifier loss: 0.333253; batch adversarial loss: 0.572676\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403166; batch adversarial loss: 0.553316\n",
      "epoch 135; iter: 0; batch classifier loss: 0.379189; batch adversarial loss: 0.482303\n",
      "epoch 136; iter: 0; batch classifier loss: 0.349727; batch adversarial loss: 0.507220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369648; batch adversarial loss: 0.580081\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344551; batch adversarial loss: 0.489757\n",
      "epoch 139; iter: 0; batch classifier loss: 0.447165; batch adversarial loss: 0.554070\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379241; batch adversarial loss: 0.599562\n",
      "epoch 141; iter: 0; batch classifier loss: 0.450023; batch adversarial loss: 0.525641\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379705; batch adversarial loss: 0.570511\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329981; batch adversarial loss: 0.489436\n",
      "epoch 144; iter: 0; batch classifier loss: 0.298933; batch adversarial loss: 0.499318\n",
      "epoch 145; iter: 0; batch classifier loss: 0.415029; batch adversarial loss: 0.572043\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382809; batch adversarial loss: 0.525679\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344857; batch adversarial loss: 0.608842\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330013; batch adversarial loss: 0.526879\n",
      "epoch 149; iter: 0; batch classifier loss: 0.312908; batch adversarial loss: 0.582183\n",
      "epoch 150; iter: 0; batch classifier loss: 0.431426; batch adversarial loss: 0.462422\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356070; batch adversarial loss: 0.553465\n",
      "epoch 152; iter: 0; batch classifier loss: 0.419484; batch adversarial loss: 0.517387\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376431; batch adversarial loss: 0.562563\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379506; batch adversarial loss: 0.553268\n",
      "epoch 155; iter: 0; batch classifier loss: 0.411117; batch adversarial loss: 0.544834\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337885; batch adversarial loss: 0.507751\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326039; batch adversarial loss: 0.553117\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329172; batch adversarial loss: 0.545499\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385267; batch adversarial loss: 0.509731\n",
      "epoch 160; iter: 0; batch classifier loss: 0.479902; batch adversarial loss: 0.590047\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347535; batch adversarial loss: 0.498977\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386337; batch adversarial loss: 0.572744\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354867; batch adversarial loss: 0.461998\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350763; batch adversarial loss: 0.588782\n",
      "epoch 165; iter: 0; batch classifier loss: 0.431365; batch adversarial loss: 0.526352\n",
      "epoch 166; iter: 0; batch classifier loss: 0.313547; batch adversarial loss: 0.445553\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358754; batch adversarial loss: 0.517276\n",
      "epoch 168; iter: 0; batch classifier loss: 0.411511; batch adversarial loss: 0.650579\n",
      "epoch 169; iter: 0; batch classifier loss: 0.345593; batch adversarial loss: 0.606824\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393244; batch adversarial loss: 0.572793\n",
      "epoch 171; iter: 0; batch classifier loss: 0.502690; batch adversarial loss: 0.572488\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377241; batch adversarial loss: 0.562029\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349863; batch adversarial loss: 0.563277\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350485; batch adversarial loss: 0.570210\n",
      "epoch 175; iter: 0; batch classifier loss: 0.370530; batch adversarial loss: 0.527851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.443716; batch adversarial loss: 0.537119\n",
      "epoch 177; iter: 0; batch classifier loss: 0.325897; batch adversarial loss: 0.600291\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332962; batch adversarial loss: 0.573290\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390067; batch adversarial loss: 0.525942\n",
      "epoch 180; iter: 0; batch classifier loss: 0.384750; batch adversarial loss: 0.508586\n",
      "epoch 181; iter: 0; batch classifier loss: 0.428990; batch adversarial loss: 0.507288\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368439; batch adversarial loss: 0.480685\n",
      "epoch 183; iter: 0; batch classifier loss: 0.424661; batch adversarial loss: 0.598391\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331306; batch adversarial loss: 0.489803\n",
      "epoch 185; iter: 0; batch classifier loss: 0.446075; batch adversarial loss: 0.507941\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371156; batch adversarial loss: 0.661924\n",
      "epoch 187; iter: 0; batch classifier loss: 0.290192; batch adversarial loss: 0.489666\n",
      "epoch 188; iter: 0; batch classifier loss: 0.402557; batch adversarial loss: 0.562433\n",
      "epoch 189; iter: 0; batch classifier loss: 0.316847; batch adversarial loss: 0.570346\n",
      "epoch 190; iter: 0; batch classifier loss: 0.434251; batch adversarial loss: 0.517730\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354558; batch adversarial loss: 0.536160\n",
      "epoch 192; iter: 0; batch classifier loss: 0.419002; batch adversarial loss: 0.544612\n",
      "epoch 193; iter: 0; batch classifier loss: 0.472919; batch adversarial loss: 0.545195\n",
      "epoch 194; iter: 0; batch classifier loss: 0.294401; batch adversarial loss: 0.535155\n",
      "epoch 195; iter: 0; batch classifier loss: 0.438422; batch adversarial loss: 0.571355\n",
      "epoch 196; iter: 0; batch classifier loss: 0.419825; batch adversarial loss: 0.598180\n",
      "epoch 197; iter: 0; batch classifier loss: 0.467189; batch adversarial loss: 0.535722\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393718; batch adversarial loss: 0.535036\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366346; batch adversarial loss: 0.589751\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713914; batch adversarial loss: 0.888319\n",
      "epoch 1; iter: 0; batch classifier loss: 0.868573; batch adversarial loss: 1.231788\n",
      "epoch 2; iter: 0; batch classifier loss: 0.934232; batch adversarial loss: 1.095858\n",
      "epoch 3; iter: 0; batch classifier loss: 0.883895; batch adversarial loss: 1.007604\n",
      "epoch 4; iter: 0; batch classifier loss: 0.847829; batch adversarial loss: 0.923163\n",
      "epoch 5; iter: 0; batch classifier loss: 0.763846; batch adversarial loss: 0.848090\n",
      "epoch 6; iter: 0; batch classifier loss: 0.731101; batch adversarial loss: 0.758903\n",
      "epoch 7; iter: 0; batch classifier loss: 0.634352; batch adversarial loss: 0.720253\n",
      "epoch 8; iter: 0; batch classifier loss: 0.548109; batch adversarial loss: 0.671164\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528348; batch adversarial loss: 0.637521\n",
      "epoch 10; iter: 0; batch classifier loss: 0.577389; batch adversarial loss: 0.619759\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565539; batch adversarial loss: 0.637113\n",
      "epoch 12; iter: 0; batch classifier loss: 0.587890; batch adversarial loss: 0.572891\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528157; batch adversarial loss: 0.645189\n",
      "epoch 14; iter: 0; batch classifier loss: 0.602019; batch adversarial loss: 0.593262\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494348; batch adversarial loss: 0.582926\n",
      "epoch 16; iter: 0; batch classifier loss: 0.577702; batch adversarial loss: 0.580226\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537886; batch adversarial loss: 0.572027\n",
      "epoch 18; iter: 0; batch classifier loss: 0.423143; batch adversarial loss: 0.565053\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492234; batch adversarial loss: 0.590670\n",
      "epoch 20; iter: 0; batch classifier loss: 0.417958; batch adversarial loss: 0.570314\n",
      "epoch 21; iter: 0; batch classifier loss: 0.440851; batch adversarial loss: 0.571182\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466823; batch adversarial loss: 0.591360\n",
      "epoch 23; iter: 0; batch classifier loss: 0.509971; batch adversarial loss: 0.615156\n",
      "epoch 24; iter: 0; batch classifier loss: 0.382832; batch adversarial loss: 0.525771\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432363; batch adversarial loss: 0.509400\n",
      "epoch 26; iter: 0; batch classifier loss: 0.547558; batch adversarial loss: 0.568580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.480579; batch adversarial loss: 0.619622\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419366; batch adversarial loss: 0.521365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492031; batch adversarial loss: 0.506729\n",
      "epoch 30; iter: 0; batch classifier loss: 0.553078; batch adversarial loss: 0.535786\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485162; batch adversarial loss: 0.634117\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493306; batch adversarial loss: 0.586252\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386827; batch adversarial loss: 0.520933\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474854; batch adversarial loss: 0.506983\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411892; batch adversarial loss: 0.554184\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473964; batch adversarial loss: 0.558691\n",
      "epoch 37; iter: 0; batch classifier loss: 0.516232; batch adversarial loss: 0.579966\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444571; batch adversarial loss: 0.487842\n",
      "epoch 39; iter: 0; batch classifier loss: 0.494239; batch adversarial loss: 0.546971\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406590; batch adversarial loss: 0.585283\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481912; batch adversarial loss: 0.590407\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483397; batch adversarial loss: 0.514849\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446147; batch adversarial loss: 0.664965\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400571; batch adversarial loss: 0.536600\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470409; batch adversarial loss: 0.545730\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426924; batch adversarial loss: 0.565415\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430848; batch adversarial loss: 0.526352\n",
      "epoch 48; iter: 0; batch classifier loss: 0.359511; batch adversarial loss: 0.551729\n",
      "epoch 49; iter: 0; batch classifier loss: 0.488391; batch adversarial loss: 0.546710\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401197; batch adversarial loss: 0.563196\n",
      "epoch 51; iter: 0; batch classifier loss: 0.407890; batch adversarial loss: 0.551773\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429246; batch adversarial loss: 0.652289\n",
      "epoch 53; iter: 0; batch classifier loss: 0.433342; batch adversarial loss: 0.527292\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449349; batch adversarial loss: 0.525147\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432588; batch adversarial loss: 0.510314\n",
      "epoch 56; iter: 0; batch classifier loss: 0.493096; batch adversarial loss: 0.452898\n",
      "epoch 57; iter: 0; batch classifier loss: 0.417631; batch adversarial loss: 0.555445\n",
      "epoch 58; iter: 0; batch classifier loss: 0.493873; batch adversarial loss: 0.563153\n",
      "epoch 59; iter: 0; batch classifier loss: 0.499108; batch adversarial loss: 0.525541\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377741; batch adversarial loss: 0.553866\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442503; batch adversarial loss: 0.498599\n",
      "epoch 62; iter: 0; batch classifier loss: 0.454535; batch adversarial loss: 0.611727\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433620; batch adversarial loss: 0.536072\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410038; batch adversarial loss: 0.518541\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435184; batch adversarial loss: 0.553277\n",
      "epoch 66; iter: 0; batch classifier loss: 0.364272; batch adversarial loss: 0.580874\n",
      "epoch 67; iter: 0; batch classifier loss: 0.335537; batch adversarial loss: 0.516923\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432630; batch adversarial loss: 0.509204\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438682; batch adversarial loss: 0.472454\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358475; batch adversarial loss: 0.507650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369533; batch adversarial loss: 0.490336\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386275; batch adversarial loss: 0.498676\n",
      "epoch 73; iter: 0; batch classifier loss: 0.416456; batch adversarial loss: 0.526163\n",
      "epoch 74; iter: 0; batch classifier loss: 0.455528; batch adversarial loss: 0.580068\n",
      "epoch 75; iter: 0; batch classifier loss: 0.342288; batch adversarial loss: 0.554137\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379723; batch adversarial loss: 0.535761\n",
      "epoch 77; iter: 0; batch classifier loss: 0.444065; batch adversarial loss: 0.545380\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390044; batch adversarial loss: 0.653798\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409359; batch adversarial loss: 0.607430\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420606; batch adversarial loss: 0.498422\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386968; batch adversarial loss: 0.617726\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446979; batch adversarial loss: 0.562793\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448284; batch adversarial loss: 0.545228\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429665; batch adversarial loss: 0.543352\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401127; batch adversarial loss: 0.554592\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411036; batch adversarial loss: 0.526926\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394764; batch adversarial loss: 0.533073\n",
      "epoch 88; iter: 0; batch classifier loss: 0.412135; batch adversarial loss: 0.561709\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383323; batch adversarial loss: 0.591553\n",
      "epoch 90; iter: 0; batch classifier loss: 0.309024; batch adversarial loss: 0.588474\n",
      "epoch 91; iter: 0; batch classifier loss: 0.519432; batch adversarial loss: 0.552883\n",
      "epoch 92; iter: 0; batch classifier loss: 0.330887; batch adversarial loss: 0.627493\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363823; batch adversarial loss: 0.508651\n",
      "epoch 94; iter: 0; batch classifier loss: 0.352173; batch adversarial loss: 0.473789\n",
      "epoch 95; iter: 0; batch classifier loss: 0.349890; batch adversarial loss: 0.526076\n",
      "epoch 96; iter: 0; batch classifier loss: 0.356680; batch adversarial loss: 0.572009\n",
      "epoch 97; iter: 0; batch classifier loss: 0.373287; batch adversarial loss: 0.499111\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379892; batch adversarial loss: 0.571473\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425695; batch adversarial loss: 0.516197\n",
      "epoch 100; iter: 0; batch classifier loss: 0.422124; batch adversarial loss: 0.527719\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360303; batch adversarial loss: 0.498283\n",
      "epoch 102; iter: 0; batch classifier loss: 0.318616; batch adversarial loss: 0.563049\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371589; batch adversarial loss: 0.580402\n",
      "epoch 104; iter: 0; batch classifier loss: 0.315072; batch adversarial loss: 0.527144\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351420; batch adversarial loss: 0.525828\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350953; batch adversarial loss: 0.562648\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396730; batch adversarial loss: 0.581187\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371308; batch adversarial loss: 0.553783\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388921; batch adversarial loss: 0.508443\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372075; batch adversarial loss: 0.508540\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348808; batch adversarial loss: 0.589770\n",
      "epoch 112; iter: 0; batch classifier loss: 0.313973; batch adversarial loss: 0.562714\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373657; batch adversarial loss: 0.553728\n",
      "epoch 114; iter: 0; batch classifier loss: 0.348914; batch adversarial loss: 0.553528\n",
      "epoch 115; iter: 0; batch classifier loss: 0.293211; batch adversarial loss: 0.499071\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345250; batch adversarial loss: 0.544576\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399843; batch adversarial loss: 0.526499\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417050; batch adversarial loss: 0.526399\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417303; batch adversarial loss: 0.589708\n",
      "epoch 120; iter: 0; batch classifier loss: 0.321496; batch adversarial loss: 0.580848\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379907; batch adversarial loss: 0.526183\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330873; batch adversarial loss: 0.535326\n",
      "epoch 123; iter: 0; batch classifier loss: 0.288704; batch adversarial loss: 0.535419\n",
      "epoch 124; iter: 0; batch classifier loss: 0.357001; batch adversarial loss: 0.517276\n",
      "epoch 125; iter: 0; batch classifier loss: 0.263588; batch adversarial loss: 0.526217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.346461; batch adversarial loss: 0.632936\n",
      "epoch 127; iter: 0; batch classifier loss: 0.445301; batch adversarial loss: 0.517672\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328914; batch adversarial loss: 0.526999\n",
      "epoch 129; iter: 0; batch classifier loss: 0.465582; batch adversarial loss: 0.545884\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376792; batch adversarial loss: 0.608230\n",
      "epoch 131; iter: 0; batch classifier loss: 0.295633; batch adversarial loss: 0.563078\n",
      "epoch 132; iter: 0; batch classifier loss: 0.273641; batch adversarial loss: 0.517365\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329027; batch adversarial loss: 0.553573\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368759; batch adversarial loss: 0.461774\n",
      "epoch 135; iter: 0; batch classifier loss: 0.332098; batch adversarial loss: 0.553844\n",
      "epoch 136; iter: 0; batch classifier loss: 0.319680; batch adversarial loss: 0.490093\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382850; batch adversarial loss: 0.526009\n",
      "epoch 138; iter: 0; batch classifier loss: 0.450934; batch adversarial loss: 0.553727\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352057; batch adversarial loss: 0.553604\n",
      "epoch 140; iter: 0; batch classifier loss: 0.398225; batch adversarial loss: 0.580752\n",
      "epoch 141; iter: 0; batch classifier loss: 0.338936; batch adversarial loss: 0.535463\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370032; batch adversarial loss: 0.563014\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379380; batch adversarial loss: 0.508352\n",
      "epoch 144; iter: 0; batch classifier loss: 0.325156; batch adversarial loss: 0.562848\n",
      "epoch 145; iter: 0; batch classifier loss: 0.316340; batch adversarial loss: 0.535446\n",
      "epoch 146; iter: 0; batch classifier loss: 0.337647; batch adversarial loss: 0.599421\n",
      "epoch 147; iter: 0; batch classifier loss: 0.417676; batch adversarial loss: 0.507923\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405544; batch adversarial loss: 0.489124\n",
      "epoch 149; iter: 0; batch classifier loss: 0.282390; batch adversarial loss: 0.527580\n",
      "epoch 150; iter: 0; batch classifier loss: 0.321765; batch adversarial loss: 0.516253\n",
      "epoch 151; iter: 0; batch classifier loss: 0.242122; batch adversarial loss: 0.644862\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370983; batch adversarial loss: 0.588180\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372764; batch adversarial loss: 0.627494\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397072; batch adversarial loss: 0.652987\n",
      "epoch 155; iter: 0; batch classifier loss: 0.290121; batch adversarial loss: 0.608269\n",
      "epoch 156; iter: 0; batch classifier loss: 0.342301; batch adversarial loss: 0.634982\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344443; batch adversarial loss: 0.490497\n",
      "epoch 158; iter: 0; batch classifier loss: 0.322069; batch adversarial loss: 0.536601\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393506; batch adversarial loss: 0.591015\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321925; batch adversarial loss: 0.572293\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343232; batch adversarial loss: 0.525883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.417786; batch adversarial loss: 0.517470\n",
      "epoch 163; iter: 0; batch classifier loss: 0.431016; batch adversarial loss: 0.553013\n",
      "epoch 164; iter: 0; batch classifier loss: 0.481595; batch adversarial loss: 0.636352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.431888; batch adversarial loss: 0.629179\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349622; batch adversarial loss: 0.556343\n",
      "epoch 167; iter: 0; batch classifier loss: 0.295541; batch adversarial loss: 0.552086\n",
      "epoch 168; iter: 0; batch classifier loss: 0.314592; batch adversarial loss: 0.554932\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357520; batch adversarial loss: 0.553538\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395796; batch adversarial loss: 0.518532\n",
      "epoch 171; iter: 0; batch classifier loss: 0.262086; batch adversarial loss: 0.507026\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364471; batch adversarial loss: 0.562305\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292826; batch adversarial loss: 0.500400\n",
      "epoch 174; iter: 0; batch classifier loss: 0.316248; batch adversarial loss: 0.509067\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365697; batch adversarial loss: 0.580664\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365861; batch adversarial loss: 0.462936\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384218; batch adversarial loss: 0.454469\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355279; batch adversarial loss: 0.571507\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346121; batch adversarial loss: 0.490358\n",
      "epoch 180; iter: 0; batch classifier loss: 0.345764; batch adversarial loss: 0.499319\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332203; batch adversarial loss: 0.535620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.253300; batch adversarial loss: 0.553431\n",
      "epoch 183; iter: 0; batch classifier loss: 0.360638; batch adversarial loss: 0.480468\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338690; batch adversarial loss: 0.507866\n",
      "epoch 185; iter: 0; batch classifier loss: 0.382201; batch adversarial loss: 0.544579\n",
      "epoch 186; iter: 0; batch classifier loss: 0.321064; batch adversarial loss: 0.535569\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393400; batch adversarial loss: 0.553632\n",
      "epoch 188; iter: 0; batch classifier loss: 0.286726; batch adversarial loss: 0.572453\n",
      "epoch 189; iter: 0; batch classifier loss: 0.353499; batch adversarial loss: 0.472221\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360296; batch adversarial loss: 0.544545\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362517; batch adversarial loss: 0.516922\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308897; batch adversarial loss: 0.599085\n",
      "epoch 193; iter: 0; batch classifier loss: 0.397834; batch adversarial loss: 0.635455\n",
      "epoch 194; iter: 0; batch classifier loss: 0.297345; batch adversarial loss: 0.553113\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346378; batch adversarial loss: 0.526439\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343073; batch adversarial loss: 0.562641\n",
      "epoch 197; iter: 0; batch classifier loss: 0.284190; batch adversarial loss: 0.571586\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352918; batch adversarial loss: 0.517342\n",
      "epoch 199; iter: 0; batch classifier loss: 0.290533; batch adversarial loss: 0.453854\n",
      "epoch 0; iter: 0; batch classifier loss: 0.797409; batch adversarial loss: 0.488775\n",
      "epoch 1; iter: 0; batch classifier loss: 0.676996; batch adversarial loss: 0.637027\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586546; batch adversarial loss: 0.610645\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582129; batch adversarial loss: 0.618634\n",
      "epoch 4; iter: 0; batch classifier loss: 0.512362; batch adversarial loss: 0.623771\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607911; batch adversarial loss: 0.648444\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612643; batch adversarial loss: 0.720859\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525141; batch adversarial loss: 0.625558\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571340; batch adversarial loss: 0.622429\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532471; batch adversarial loss: 0.573444\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552532; batch adversarial loss: 0.575697\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549757; batch adversarial loss: 0.589558\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518012; batch adversarial loss: 0.571773\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462501; batch adversarial loss: 0.578592\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475489; batch adversarial loss: 0.546676\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473087; batch adversarial loss: 0.579539\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490080; batch adversarial loss: 0.569931\n",
      "epoch 17; iter: 0; batch classifier loss: 0.452229; batch adversarial loss: 0.535106\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456502; batch adversarial loss: 0.513588\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480835; batch adversarial loss: 0.573278\n",
      "epoch 20; iter: 0; batch classifier loss: 0.442930; batch adversarial loss: 0.569879\n",
      "epoch 21; iter: 0; batch classifier loss: 0.555969; batch adversarial loss: 0.581344\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459117; batch adversarial loss: 0.564299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.502295; batch adversarial loss: 0.492459\n",
      "epoch 24; iter: 0; batch classifier loss: 0.504607; batch adversarial loss: 0.573397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484380; batch adversarial loss: 0.578746\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466686; batch adversarial loss: 0.511549\n",
      "epoch 27; iter: 0; batch classifier loss: 0.502188; batch adversarial loss: 0.614963\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491329; batch adversarial loss: 0.585917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456589; batch adversarial loss: 0.553194\n",
      "epoch 30; iter: 0; batch classifier loss: 0.407625; batch adversarial loss: 0.520742\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439279; batch adversarial loss: 0.523334\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414604; batch adversarial loss: 0.519856\n",
      "epoch 33; iter: 0; batch classifier loss: 0.515315; batch adversarial loss: 0.626740\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443255; batch adversarial loss: 0.620910\n",
      "epoch 35; iter: 0; batch classifier loss: 0.509858; batch adversarial loss: 0.518482\n",
      "epoch 36; iter: 0; batch classifier loss: 0.518556; batch adversarial loss: 0.453714\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428608; batch adversarial loss: 0.580689\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415934; batch adversarial loss: 0.515267\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436352; batch adversarial loss: 0.525632\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459118; batch adversarial loss: 0.620953\n",
      "epoch 41; iter: 0; batch classifier loss: 0.479766; batch adversarial loss: 0.608652\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429966; batch adversarial loss: 0.551461\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492836; batch adversarial loss: 0.525015\n",
      "epoch 44; iter: 0; batch classifier loss: 0.387144; batch adversarial loss: 0.524448\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414137; batch adversarial loss: 0.543947\n",
      "epoch 46; iter: 0; batch classifier loss: 0.532186; batch adversarial loss: 0.571590\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433572; batch adversarial loss: 0.553436\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431441; batch adversarial loss: 0.552794\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434204; batch adversarial loss: 0.556716\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434661; batch adversarial loss: 0.578467\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469883; batch adversarial loss: 0.543971\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430898; batch adversarial loss: 0.563247\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399216; batch adversarial loss: 0.545937\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394743; batch adversarial loss: 0.569325\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395575; batch adversarial loss: 0.569739\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403578; batch adversarial loss: 0.499057\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421328; batch adversarial loss: 0.480453\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438783; batch adversarial loss: 0.544847\n",
      "epoch 59; iter: 0; batch classifier loss: 0.450966; batch adversarial loss: 0.515721\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412963; batch adversarial loss: 0.591898\n",
      "epoch 61; iter: 0; batch classifier loss: 0.485285; batch adversarial loss: 0.526963\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398571; batch adversarial loss: 0.518654\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391667; batch adversarial loss: 0.598595\n",
      "epoch 64; iter: 0; batch classifier loss: 0.309058; batch adversarial loss: 0.519072\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389889; batch adversarial loss: 0.465476\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418571; batch adversarial loss: 0.589443\n",
      "epoch 67; iter: 0; batch classifier loss: 0.438749; batch adversarial loss: 0.544709\n",
      "epoch 68; iter: 0; batch classifier loss: 0.440041; batch adversarial loss: 0.579774\n",
      "epoch 69; iter: 0; batch classifier loss: 0.484563; batch adversarial loss: 0.616310\n",
      "epoch 70; iter: 0; batch classifier loss: 0.502608; batch adversarial loss: 0.553917\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436427; batch adversarial loss: 0.525308\n",
      "epoch 72; iter: 0; batch classifier loss: 0.439095; batch adversarial loss: 0.579780\n",
      "epoch 73; iter: 0; batch classifier loss: 0.349985; batch adversarial loss: 0.581942\n",
      "epoch 74; iter: 0; batch classifier loss: 0.409049; batch adversarial loss: 0.523373\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405381; batch adversarial loss: 0.544515\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414200; batch adversarial loss: 0.508920\n",
      "epoch 77; iter: 0; batch classifier loss: 0.377828; batch adversarial loss: 0.571642\n",
      "epoch 78; iter: 0; batch classifier loss: 0.388999; batch adversarial loss: 0.518643\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436033; batch adversarial loss: 0.526824\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363823; batch adversarial loss: 0.499798\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394970; batch adversarial loss: 0.552890\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422304; batch adversarial loss: 0.526413\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423796; batch adversarial loss: 0.507493\n",
      "epoch 84; iter: 0; batch classifier loss: 0.438663; batch adversarial loss: 0.544279\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369228; batch adversarial loss: 0.562356\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394684; batch adversarial loss: 0.443476\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364160; batch adversarial loss: 0.615408\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421544; batch adversarial loss: 0.535823\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376517; batch adversarial loss: 0.582350\n",
      "epoch 90; iter: 0; batch classifier loss: 0.486703; batch adversarial loss: 0.482082\n",
      "epoch 91; iter: 0; batch classifier loss: 0.306358; batch adversarial loss: 0.590528\n",
      "epoch 92; iter: 0; batch classifier loss: 0.332694; batch adversarial loss: 0.499723\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386537; batch adversarial loss: 0.571740\n",
      "epoch 94; iter: 0; batch classifier loss: 0.291132; batch adversarial loss: 0.634205\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364616; batch adversarial loss: 0.518767\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430442; batch adversarial loss: 0.571284\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360893; batch adversarial loss: 0.571582\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410238; batch adversarial loss: 0.525511\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382043; batch adversarial loss: 0.616795\n",
      "epoch 100; iter: 0; batch classifier loss: 0.314740; batch adversarial loss: 0.498518\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374077; batch adversarial loss: 0.535849\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342516; batch adversarial loss: 0.636460\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356137; batch adversarial loss: 0.542839\n",
      "epoch 104; iter: 0; batch classifier loss: 0.459944; batch adversarial loss: 0.600692\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396352; batch adversarial loss: 0.517134\n",
      "epoch 106; iter: 0; batch classifier loss: 0.361618; batch adversarial loss: 0.544396\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346907; batch adversarial loss: 0.527549\n",
      "epoch 108; iter: 0; batch classifier loss: 0.339491; batch adversarial loss: 0.544297\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400499; batch adversarial loss: 0.543351\n",
      "epoch 110; iter: 0; batch classifier loss: 0.364293; batch adversarial loss: 0.526164\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345004; batch adversarial loss: 0.573417\n",
      "epoch 112; iter: 0; batch classifier loss: 0.458353; batch adversarial loss: 0.552657\n",
      "epoch 113; iter: 0; batch classifier loss: 0.464930; batch adversarial loss: 0.527666\n",
      "epoch 114; iter: 0; batch classifier loss: 0.324912; batch adversarial loss: 0.599600\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380437; batch adversarial loss: 0.546244\n",
      "epoch 116; iter: 0; batch classifier loss: 0.411434; batch adversarial loss: 0.618137\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379466; batch adversarial loss: 0.508151\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342345; batch adversarial loss: 0.564560\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344469; batch adversarial loss: 0.551876\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399369; batch adversarial loss: 0.570773\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365803; batch adversarial loss: 0.633948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.320231; batch adversarial loss: 0.524649\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409864; batch adversarial loss: 0.572875\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363476; batch adversarial loss: 0.655090\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391216; batch adversarial loss: 0.580027\n",
      "epoch 126; iter: 0; batch classifier loss: 0.332956; batch adversarial loss: 0.508120\n",
      "epoch 127; iter: 0; batch classifier loss: 0.302469; batch adversarial loss: 0.499794\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395623; batch adversarial loss: 0.487720\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337341; batch adversarial loss: 0.543655\n",
      "epoch 130; iter: 0; batch classifier loss: 0.331533; batch adversarial loss: 0.513991\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384736; batch adversarial loss: 0.700311\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403470; batch adversarial loss: 0.516308\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364482; batch adversarial loss: 0.491494\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378815; batch adversarial loss: 0.562353\n",
      "epoch 135; iter: 0; batch classifier loss: 0.327031; batch adversarial loss: 0.516159\n",
      "epoch 136; iter: 0; batch classifier loss: 0.427555; batch adversarial loss: 0.572487\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385898; batch adversarial loss: 0.561300\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341090; batch adversarial loss: 0.546188\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389022; batch adversarial loss: 0.474160\n",
      "epoch 140; iter: 0; batch classifier loss: 0.382159; batch adversarial loss: 0.580572\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358707; batch adversarial loss: 0.535300\n",
      "epoch 142; iter: 0; batch classifier loss: 0.344844; batch adversarial loss: 0.570635\n",
      "epoch 143; iter: 0; batch classifier loss: 0.316458; batch adversarial loss: 0.518235\n",
      "epoch 144; iter: 0; batch classifier loss: 0.343986; batch adversarial loss: 0.589628\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342081; batch adversarial loss: 0.526640\n",
      "epoch 146; iter: 0; batch classifier loss: 0.310694; batch adversarial loss: 0.554428\n",
      "epoch 147; iter: 0; batch classifier loss: 0.341539; batch adversarial loss: 0.544913\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343562; batch adversarial loss: 0.553375\n",
      "epoch 149; iter: 0; batch classifier loss: 0.304017; batch adversarial loss: 0.543862\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421029; batch adversarial loss: 0.543994\n",
      "epoch 151; iter: 0; batch classifier loss: 0.358705; batch adversarial loss: 0.573055\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330617; batch adversarial loss: 0.536272\n",
      "epoch 153; iter: 0; batch classifier loss: 0.415248; batch adversarial loss: 0.627818\n",
      "epoch 154; iter: 0; batch classifier loss: 0.399056; batch adversarial loss: 0.570493\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307009; batch adversarial loss: 0.490498\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336667; batch adversarial loss: 0.471374\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334036; batch adversarial loss: 0.479458\n",
      "epoch 158; iter: 0; batch classifier loss: 0.413067; batch adversarial loss: 0.541533\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375296; batch adversarial loss: 0.632651\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319766; batch adversarial loss: 0.528095\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411941; batch adversarial loss: 0.662035\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366701; batch adversarial loss: 0.485638\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336475; batch adversarial loss: 0.555416\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339251; batch adversarial loss: 0.553173\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359603; batch adversarial loss: 0.545775\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322084; batch adversarial loss: 0.482927\n",
      "epoch 167; iter: 0; batch classifier loss: 0.291703; batch adversarial loss: 0.554487\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317958; batch adversarial loss: 0.516789\n",
      "epoch 169; iter: 0; batch classifier loss: 0.317745; batch adversarial loss: 0.510108\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367413; batch adversarial loss: 0.623280\n",
      "epoch 171; iter: 0; batch classifier loss: 0.325491; batch adversarial loss: 0.607302\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318760; batch adversarial loss: 0.517115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321657; batch adversarial loss: 0.517860\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366156; batch adversarial loss: 0.412945\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331901; batch adversarial loss: 0.526546\n",
      "epoch 176; iter: 0; batch classifier loss: 0.371708; batch adversarial loss: 0.562586\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347467; batch adversarial loss: 0.522941\n",
      "epoch 178; iter: 0; batch classifier loss: 0.349646; batch adversarial loss: 0.491681\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389338; batch adversarial loss: 0.591376\n",
      "epoch 180; iter: 0; batch classifier loss: 0.291252; batch adversarial loss: 0.607774\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367323; batch adversarial loss: 0.554482\n",
      "epoch 182; iter: 0; batch classifier loss: 0.298357; batch adversarial loss: 0.598487\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330543; batch adversarial loss: 0.580859\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404731; batch adversarial loss: 0.625701\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336148; batch adversarial loss: 0.562976\n",
      "epoch 186; iter: 0; batch classifier loss: 0.325101; batch adversarial loss: 0.579970\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341982; batch adversarial loss: 0.571757\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341314; batch adversarial loss: 0.489120\n",
      "epoch 189; iter: 0; batch classifier loss: 0.329192; batch adversarial loss: 0.562330\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312123; batch adversarial loss: 0.498347\n",
      "epoch 191; iter: 0; batch classifier loss: 0.401478; batch adversarial loss: 0.553411\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363432; batch adversarial loss: 0.545326\n",
      "epoch 193; iter: 0; batch classifier loss: 0.382850; batch adversarial loss: 0.527363\n",
      "epoch 194; iter: 0; batch classifier loss: 0.320739; batch adversarial loss: 0.552882\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323090; batch adversarial loss: 0.498017\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315892; batch adversarial loss: 0.507441\n",
      "epoch 197; iter: 0; batch classifier loss: 0.301752; batch adversarial loss: 0.579264\n",
      "epoch 198; iter: 0; batch classifier loss: 0.325196; batch adversarial loss: 0.453970\n",
      "epoch 199; iter: 0; batch classifier loss: 0.282777; batch adversarial loss: 0.525766\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735996; batch adversarial loss: 0.615689\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578443; batch adversarial loss: 0.640450\n",
      "epoch 2; iter: 0; batch classifier loss: 0.521044; batch adversarial loss: 0.654055\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586967; batch adversarial loss: 0.588624\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577560; batch adversarial loss: 0.621578\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561360; batch adversarial loss: 0.584998\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558193; batch adversarial loss: 0.585823\n",
      "epoch 7; iter: 0; batch classifier loss: 0.652011; batch adversarial loss: 0.614364\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580141; batch adversarial loss: 0.653510\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519196; batch adversarial loss: 0.627891\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516803; batch adversarial loss: 0.594503\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524753; batch adversarial loss: 0.580665\n",
      "epoch 12; iter: 0; batch classifier loss: 0.587256; batch adversarial loss: 0.533553\n",
      "epoch 13; iter: 0; batch classifier loss: 0.478405; batch adversarial loss: 0.533624\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521623; batch adversarial loss: 0.584410\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527791; batch adversarial loss: 0.591911\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527250; batch adversarial loss: 0.523257\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534153; batch adversarial loss: 0.498512\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501035; batch adversarial loss: 0.582423\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523098; batch adversarial loss: 0.546199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.478645; batch adversarial loss: 0.612763\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538092; batch adversarial loss: 0.505446\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487268; batch adversarial loss: 0.520195\n",
      "epoch 23; iter: 0; batch classifier loss: 0.566435; batch adversarial loss: 0.538270\n",
      "epoch 24; iter: 0; batch classifier loss: 0.504997; batch adversarial loss: 0.495625\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490084; batch adversarial loss: 0.607639\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485519; batch adversarial loss: 0.556657\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462923; batch adversarial loss: 0.542443\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402482; batch adversarial loss: 0.606928\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476425; batch adversarial loss: 0.530566\n",
      "epoch 30; iter: 0; batch classifier loss: 0.410877; batch adversarial loss: 0.556014\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497215; batch adversarial loss: 0.581152\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429752; batch adversarial loss: 0.508026\n",
      "epoch 33; iter: 0; batch classifier loss: 0.525151; batch adversarial loss: 0.541329\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436316; batch adversarial loss: 0.502229\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454271; batch adversarial loss: 0.498562\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447415; batch adversarial loss: 0.499563\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493389; batch adversarial loss: 0.454991\n",
      "epoch 38; iter: 0; batch classifier loss: 0.506254; batch adversarial loss: 0.551654\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501367; batch adversarial loss: 0.532759\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405517; batch adversarial loss: 0.552557\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448088; batch adversarial loss: 0.525430\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455464; batch adversarial loss: 0.553247\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463584; batch adversarial loss: 0.554717\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435143; batch adversarial loss: 0.564778\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394116; batch adversarial loss: 0.544394\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496412; batch adversarial loss: 0.509440\n",
      "epoch 47; iter: 0; batch classifier loss: 0.528835; batch adversarial loss: 0.606567\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410089; batch adversarial loss: 0.561596\n",
      "epoch 49; iter: 0; batch classifier loss: 0.529334; batch adversarial loss: 0.464154\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459857; batch adversarial loss: 0.579788\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455418; batch adversarial loss: 0.437232\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418625; batch adversarial loss: 0.498655\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431822; batch adversarial loss: 0.570504\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415595; batch adversarial loss: 0.497257\n",
      "epoch 55; iter: 0; batch classifier loss: 0.435487; batch adversarial loss: 0.635145\n",
      "epoch 56; iter: 0; batch classifier loss: 0.333515; batch adversarial loss: 0.498796\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374815; batch adversarial loss: 0.536039\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444899; batch adversarial loss: 0.562903\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418893; batch adversarial loss: 0.516688\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401715; batch adversarial loss: 0.550849\n",
      "epoch 61; iter: 0; batch classifier loss: 0.318921; batch adversarial loss: 0.546273\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436887; batch adversarial loss: 0.535751\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413691; batch adversarial loss: 0.574605\n",
      "epoch 64; iter: 0; batch classifier loss: 0.482479; batch adversarial loss: 0.535193\n",
      "epoch 65; iter: 0; batch classifier loss: 0.359102; batch adversarial loss: 0.555059\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407524; batch adversarial loss: 0.496759\n",
      "epoch 67; iter: 0; batch classifier loss: 0.487273; batch adversarial loss: 0.525908\n",
      "epoch 68; iter: 0; batch classifier loss: 0.466254; batch adversarial loss: 0.507148\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373628; batch adversarial loss: 0.516466\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384468; batch adversarial loss: 0.498108\n",
      "epoch 71; iter: 0; batch classifier loss: 0.421905; batch adversarial loss: 0.553678\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416140; batch adversarial loss: 0.554136\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431958; batch adversarial loss: 0.544547\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416058; batch adversarial loss: 0.506946\n",
      "epoch 75; iter: 0; batch classifier loss: 0.410804; batch adversarial loss: 0.535311\n",
      "epoch 76; iter: 0; batch classifier loss: 0.351699; batch adversarial loss: 0.572566\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419749; batch adversarial loss: 0.526333\n",
      "epoch 78; iter: 0; batch classifier loss: 0.452519; batch adversarial loss: 0.581714\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409315; batch adversarial loss: 0.479052\n",
      "epoch 80; iter: 0; batch classifier loss: 0.386805; batch adversarial loss: 0.525674\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400014; batch adversarial loss: 0.526016\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413917; batch adversarial loss: 0.544631\n",
      "epoch 83; iter: 0; batch classifier loss: 0.336335; batch adversarial loss: 0.470043\n",
      "epoch 84; iter: 0; batch classifier loss: 0.463699; batch adversarial loss: 0.470048\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434651; batch adversarial loss: 0.591090\n",
      "epoch 86; iter: 0; batch classifier loss: 0.530440; batch adversarial loss: 0.507305\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380842; batch adversarial loss: 0.600356\n",
      "epoch 88; iter: 0; batch classifier loss: 0.278681; batch adversarial loss: 0.591137\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362237; batch adversarial loss: 0.432270\n",
      "epoch 90; iter: 0; batch classifier loss: 0.521974; batch adversarial loss: 0.544288\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386963; batch adversarial loss: 0.497518\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402633; batch adversarial loss: 0.497058\n",
      "epoch 93; iter: 0; batch classifier loss: 0.423648; batch adversarial loss: 0.526647\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363489; batch adversarial loss: 0.507624\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357895; batch adversarial loss: 0.665623\n",
      "epoch 96; iter: 0; batch classifier loss: 0.463470; batch adversarial loss: 0.489099\n",
      "epoch 97; iter: 0; batch classifier loss: 0.457211; batch adversarial loss: 0.507787\n",
      "epoch 98; iter: 0; batch classifier loss: 0.322822; batch adversarial loss: 0.562688\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332662; batch adversarial loss: 0.535026\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374484; batch adversarial loss: 0.655953\n",
      "epoch 101; iter: 0; batch classifier loss: 0.378988; batch adversarial loss: 0.497155\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410013; batch adversarial loss: 0.572276\n",
      "epoch 103; iter: 0; batch classifier loss: 0.495464; batch adversarial loss: 0.506779\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348336; batch adversarial loss: 0.533657\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384120; batch adversarial loss: 0.543462\n",
      "epoch 106; iter: 0; batch classifier loss: 0.405963; batch adversarial loss: 0.619154\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413867; batch adversarial loss: 0.486826\n",
      "epoch 108; iter: 0; batch classifier loss: 0.451051; batch adversarial loss: 0.600616\n",
      "epoch 109; iter: 0; batch classifier loss: 0.455714; batch adversarial loss: 0.572206\n",
      "epoch 110; iter: 0; batch classifier loss: 0.404868; batch adversarial loss: 0.475293\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384000; batch adversarial loss: 0.590987\n",
      "epoch 112; iter: 0; batch classifier loss: 0.418711; batch adversarial loss: 0.610415\n",
      "epoch 113; iter: 0; batch classifier loss: 0.290052; batch adversarial loss: 0.536830\n",
      "epoch 114; iter: 0; batch classifier loss: 0.433141; batch adversarial loss: 0.612419\n",
      "epoch 115; iter: 0; batch classifier loss: 0.322926; batch adversarial loss: 0.495692\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392310; batch adversarial loss: 0.461281\n",
      "epoch 117; iter: 0; batch classifier loss: 0.422712; batch adversarial loss: 0.618911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.384701; batch adversarial loss: 0.652978\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388983; batch adversarial loss: 0.571620\n",
      "epoch 120; iter: 0; batch classifier loss: 0.390061; batch adversarial loss: 0.473443\n",
      "epoch 121; iter: 0; batch classifier loss: 0.414043; batch adversarial loss: 0.527363\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403604; batch adversarial loss: 0.665155\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423147; batch adversarial loss: 0.552098\n",
      "epoch 124; iter: 0; batch classifier loss: 0.292921; batch adversarial loss: 0.599378\n",
      "epoch 125; iter: 0; batch classifier loss: 0.364833; batch adversarial loss: 0.564251\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383240; batch adversarial loss: 0.563912\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419033; batch adversarial loss: 0.525614\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392012; batch adversarial loss: 0.573773\n",
      "epoch 129; iter: 0; batch classifier loss: 0.305450; batch adversarial loss: 0.507845\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384623; batch adversarial loss: 0.562062\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381947; batch adversarial loss: 0.479392\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370945; batch adversarial loss: 0.505859\n",
      "epoch 133; iter: 0; batch classifier loss: 0.360635; batch adversarial loss: 0.608992\n",
      "epoch 134; iter: 0; batch classifier loss: 0.441387; batch adversarial loss: 0.536013\n",
      "epoch 135; iter: 0; batch classifier loss: 0.333971; batch adversarial loss: 0.533656\n",
      "epoch 136; iter: 0; batch classifier loss: 0.472957; batch adversarial loss: 0.563774\n",
      "epoch 137; iter: 0; batch classifier loss: 0.361535; batch adversarial loss: 0.673906\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382106; batch adversarial loss: 0.535862\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344009; batch adversarial loss: 0.543638\n",
      "epoch 140; iter: 0; batch classifier loss: 0.350990; batch adversarial loss: 0.490480\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363783; batch adversarial loss: 0.591832\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346355; batch adversarial loss: 0.472154\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365541; batch adversarial loss: 0.610956\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384667; batch adversarial loss: 0.563759\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358359; batch adversarial loss: 0.607700\n",
      "epoch 146; iter: 0; batch classifier loss: 0.304734; batch adversarial loss: 0.600440\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350742; batch adversarial loss: 0.562400\n",
      "epoch 148; iter: 0; batch classifier loss: 0.457013; batch adversarial loss: 0.618258\n",
      "epoch 149; iter: 0; batch classifier loss: 0.311128; batch adversarial loss: 0.517409\n",
      "epoch 150; iter: 0; batch classifier loss: 0.403163; batch adversarial loss: 0.526057\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357780; batch adversarial loss: 0.619107\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333868; batch adversarial loss: 0.572340\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393331; batch adversarial loss: 0.553335\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321158; batch adversarial loss: 0.591341\n",
      "epoch 155; iter: 0; batch classifier loss: 0.399045; batch adversarial loss: 0.600138\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380851; batch adversarial loss: 0.590458\n",
      "epoch 157; iter: 0; batch classifier loss: 0.310530; batch adversarial loss: 0.507651\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337057; batch adversarial loss: 0.507703\n",
      "epoch 159; iter: 0; batch classifier loss: 0.320316; batch adversarial loss: 0.572086\n",
      "epoch 160; iter: 0; batch classifier loss: 0.338754; batch adversarial loss: 0.600399\n",
      "epoch 161; iter: 0; batch classifier loss: 0.332380; batch adversarial loss: 0.497405\n",
      "epoch 162; iter: 0; batch classifier loss: 0.374943; batch adversarial loss: 0.497721\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402825; batch adversarial loss: 0.581867\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353140; batch adversarial loss: 0.516586\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326315; batch adversarial loss: 0.562626\n",
      "epoch 166; iter: 0; batch classifier loss: 0.398850; batch adversarial loss: 0.478954\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337286; batch adversarial loss: 0.544823\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395384; batch adversarial loss: 0.563889\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376529; batch adversarial loss: 0.582578\n",
      "epoch 170; iter: 0; batch classifier loss: 0.289938; batch adversarial loss: 0.516014\n",
      "epoch 171; iter: 0; batch classifier loss: 0.379941; batch adversarial loss: 0.535146\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398876; batch adversarial loss: 0.516902\n",
      "epoch 173; iter: 0; batch classifier loss: 0.400529; batch adversarial loss: 0.573461\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381756; batch adversarial loss: 0.582022\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372072; batch adversarial loss: 0.563831\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329996; batch adversarial loss: 0.571469\n",
      "epoch 177; iter: 0; batch classifier loss: 0.313381; batch adversarial loss: 0.563737\n",
      "epoch 178; iter: 0; batch classifier loss: 0.407762; batch adversarial loss: 0.488685\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303285; batch adversarial loss: 0.516759\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362847; batch adversarial loss: 0.562906\n",
      "epoch 181; iter: 0; batch classifier loss: 0.388453; batch adversarial loss: 0.479555\n",
      "epoch 182; iter: 0; batch classifier loss: 0.414382; batch adversarial loss: 0.508106\n",
      "epoch 183; iter: 0; batch classifier loss: 0.350838; batch adversarial loss: 0.598996\n",
      "epoch 184; iter: 0; batch classifier loss: 0.453679; batch adversarial loss: 0.507447\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303047; batch adversarial loss: 0.506843\n",
      "epoch 186; iter: 0; batch classifier loss: 0.432158; batch adversarial loss: 0.554259\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356482; batch adversarial loss: 0.572653\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382624; batch adversarial loss: 0.497824\n",
      "epoch 189; iter: 0; batch classifier loss: 0.428532; batch adversarial loss: 0.579592\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342663; batch adversarial loss: 0.517912\n",
      "epoch 191; iter: 0; batch classifier loss: 0.436435; batch adversarial loss: 0.571529\n",
      "epoch 192; iter: 0; batch classifier loss: 0.386497; batch adversarial loss: 0.543646\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336901; batch adversarial loss: 0.449434\n",
      "epoch 194; iter: 0; batch classifier loss: 0.437920; batch adversarial loss: 0.592438\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381886; batch adversarial loss: 0.553642\n",
      "epoch 196; iter: 0; batch classifier loss: 0.410479; batch adversarial loss: 0.591706\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344235; batch adversarial loss: 0.498508\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361023; batch adversarial loss: 0.553953\n",
      "epoch 199; iter: 0; batch classifier loss: 0.404670; batch adversarial loss: 0.515047\n",
      "epoch 0; iter: 0; batch classifier loss: 0.783599; batch adversarial loss: 0.632730\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607829; batch adversarial loss: 0.652798\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647673; batch adversarial loss: 0.629129\n",
      "epoch 3; iter: 0; batch classifier loss: 0.529166; batch adversarial loss: 0.601667\n",
      "epoch 4; iter: 0; batch classifier loss: 0.551272; batch adversarial loss: 0.575859\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559070; batch adversarial loss: 0.564189\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535326; batch adversarial loss: 0.601588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534914; batch adversarial loss: 0.626881\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525920; batch adversarial loss: 0.582547\n",
      "epoch 9; iter: 0; batch classifier loss: 0.621338; batch adversarial loss: 0.603081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581543; batch adversarial loss: 0.608698\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537214; batch adversarial loss: 0.608820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532672; batch adversarial loss: 0.625136\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481769; batch adversarial loss: 0.547278\n",
      "epoch 14; iter: 0; batch classifier loss: 0.562685; batch adversarial loss: 0.543981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.532700; batch adversarial loss: 0.581389\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510756; batch adversarial loss: 0.522015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511291; batch adversarial loss: 0.580283\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548327; batch adversarial loss: 0.526283\n",
      "epoch 19; iter: 0; batch classifier loss: 0.539806; batch adversarial loss: 0.543301\n",
      "epoch 20; iter: 0; batch classifier loss: 0.535142; batch adversarial loss: 0.510546\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514146; batch adversarial loss: 0.516485\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440903; batch adversarial loss: 0.529375\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479533; batch adversarial loss: 0.563111\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487402; batch adversarial loss: 0.548857\n",
      "epoch 25; iter: 0; batch classifier loss: 0.539481; batch adversarial loss: 0.560580\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435455; batch adversarial loss: 0.575478\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439166; batch adversarial loss: 0.535452\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473961; batch adversarial loss: 0.540010\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520726; batch adversarial loss: 0.553950\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504211; batch adversarial loss: 0.520715\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483159; batch adversarial loss: 0.442442\n",
      "epoch 32; iter: 0; batch classifier loss: 0.515129; batch adversarial loss: 0.553406\n",
      "epoch 33; iter: 0; batch classifier loss: 0.491785; batch adversarial loss: 0.571541\n",
      "epoch 34; iter: 0; batch classifier loss: 0.514524; batch adversarial loss: 0.544687\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469524; batch adversarial loss: 0.562391\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459589; batch adversarial loss: 0.535823\n",
      "epoch 37; iter: 0; batch classifier loss: 0.537240; batch adversarial loss: 0.616447\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483713; batch adversarial loss: 0.562596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414960; batch adversarial loss: 0.525888\n",
      "epoch 40; iter: 0; batch classifier loss: 0.402275; batch adversarial loss: 0.571668\n",
      "epoch 41; iter: 0; batch classifier loss: 0.400962; batch adversarial loss: 0.552359\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459425; batch adversarial loss: 0.490926\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445973; batch adversarial loss: 0.533912\n",
      "epoch 44; iter: 0; batch classifier loss: 0.389791; batch adversarial loss: 0.515688\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471516; batch adversarial loss: 0.487502\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436737; batch adversarial loss: 0.544784\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434464; batch adversarial loss: 0.505711\n",
      "epoch 48; iter: 0; batch classifier loss: 0.496100; batch adversarial loss: 0.535993\n",
      "epoch 49; iter: 0; batch classifier loss: 0.426318; batch adversarial loss: 0.606705\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443955; batch adversarial loss: 0.607860\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421534; batch adversarial loss: 0.596455\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437437; batch adversarial loss: 0.507943\n",
      "epoch 53; iter: 0; batch classifier loss: 0.485427; batch adversarial loss: 0.562693\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442009; batch adversarial loss: 0.535627\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401714; batch adversarial loss: 0.556459\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447397; batch adversarial loss: 0.545599\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374437; batch adversarial loss: 0.544277\n",
      "epoch 58; iter: 0; batch classifier loss: 0.477876; batch adversarial loss: 0.526818\n",
      "epoch 59; iter: 0; batch classifier loss: 0.452755; batch adversarial loss: 0.621399\n",
      "epoch 60; iter: 0; batch classifier loss: 0.375153; batch adversarial loss: 0.601387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.390567; batch adversarial loss: 0.564452\n",
      "epoch 62; iter: 0; batch classifier loss: 0.371666; batch adversarial loss: 0.515934\n",
      "epoch 63; iter: 0; batch classifier loss: 0.495198; batch adversarial loss: 0.489807\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408869; batch adversarial loss: 0.526555\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439844; batch adversarial loss: 0.533594\n",
      "epoch 66; iter: 0; batch classifier loss: 0.376828; batch adversarial loss: 0.545511\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395187; batch adversarial loss: 0.469523\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439999; batch adversarial loss: 0.497249\n",
      "epoch 69; iter: 0; batch classifier loss: 0.506059; batch adversarial loss: 0.600784\n",
      "epoch 70; iter: 0; batch classifier loss: 0.470472; batch adversarial loss: 0.488197\n",
      "epoch 71; iter: 0; batch classifier loss: 0.441301; batch adversarial loss: 0.544488\n",
      "epoch 72; iter: 0; batch classifier loss: 0.454339; batch adversarial loss: 0.489310\n",
      "epoch 73; iter: 0; batch classifier loss: 0.362005; batch adversarial loss: 0.479565\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436689; batch adversarial loss: 0.489370\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356108; batch adversarial loss: 0.479879\n",
      "epoch 76; iter: 0; batch classifier loss: 0.401683; batch adversarial loss: 0.607585\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401732; batch adversarial loss: 0.532281\n",
      "epoch 78; iter: 0; batch classifier loss: 0.468396; batch adversarial loss: 0.554278\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436899; batch adversarial loss: 0.599668\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375913; batch adversarial loss: 0.477899\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406252; batch adversarial loss: 0.517560\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409573; batch adversarial loss: 0.489296\n",
      "epoch 83; iter: 0; batch classifier loss: 0.492452; batch adversarial loss: 0.525744\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393726; batch adversarial loss: 0.525831\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370629; batch adversarial loss: 0.553936\n",
      "epoch 86; iter: 0; batch classifier loss: 0.423529; batch adversarial loss: 0.572272\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420989; batch adversarial loss: 0.470767\n",
      "epoch 88; iter: 0; batch classifier loss: 0.457952; batch adversarial loss: 0.470108\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405892; batch adversarial loss: 0.544212\n",
      "epoch 90; iter: 0; batch classifier loss: 0.336693; batch adversarial loss: 0.588112\n",
      "epoch 91; iter: 0; batch classifier loss: 0.351232; batch adversarial loss: 0.561221\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397462; batch adversarial loss: 0.518830\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409329; batch adversarial loss: 0.507936\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385400; batch adversarial loss: 0.545000\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408792; batch adversarial loss: 0.468918\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367271; batch adversarial loss: 0.609669\n",
      "epoch 97; iter: 0; batch classifier loss: 0.442089; batch adversarial loss: 0.479591\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418069; batch adversarial loss: 0.591524\n",
      "epoch 99; iter: 0; batch classifier loss: 0.435682; batch adversarial loss: 0.497567\n",
      "epoch 100; iter: 0; batch classifier loss: 0.461216; batch adversarial loss: 0.534941\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335884; batch adversarial loss: 0.582038\n",
      "epoch 102; iter: 0; batch classifier loss: 0.395976; batch adversarial loss: 0.534604\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391875; batch adversarial loss: 0.553473\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428098; batch adversarial loss: 0.535164\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373864; batch adversarial loss: 0.535308\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397221; batch adversarial loss: 0.516303\n",
      "epoch 107; iter: 0; batch classifier loss: 0.450403; batch adversarial loss: 0.553846\n",
      "epoch 108; iter: 0; batch classifier loss: 0.389216; batch adversarial loss: 0.516339\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371901; batch adversarial loss: 0.563222\n",
      "epoch 110; iter: 0; batch classifier loss: 0.358094; batch adversarial loss: 0.608968\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405504; batch adversarial loss: 0.544963\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349459; batch adversarial loss: 0.536318\n",
      "epoch 113; iter: 0; batch classifier loss: 0.317513; batch adversarial loss: 0.562713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.374642; batch adversarial loss: 0.517897\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357831; batch adversarial loss: 0.600321\n",
      "epoch 116; iter: 0; batch classifier loss: 0.334276; batch adversarial loss: 0.535883\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368155; batch adversarial loss: 0.562618\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394477; batch adversarial loss: 0.562546\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378057; batch adversarial loss: 0.534946\n",
      "epoch 120; iter: 0; batch classifier loss: 0.397938; batch adversarial loss: 0.581503\n",
      "epoch 121; iter: 0; batch classifier loss: 0.337839; batch adversarial loss: 0.553590\n",
      "epoch 122; iter: 0; batch classifier loss: 0.408834; batch adversarial loss: 0.561195\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408729; batch adversarial loss: 0.544418\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382440; batch adversarial loss: 0.581870\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412305; batch adversarial loss: 0.646391\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360258; batch adversarial loss: 0.480170\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354792; batch adversarial loss: 0.627604\n",
      "epoch 128; iter: 0; batch classifier loss: 0.331197; batch adversarial loss: 0.507176\n",
      "epoch 129; iter: 0; batch classifier loss: 0.407581; batch adversarial loss: 0.516806\n",
      "epoch 130; iter: 0; batch classifier loss: 0.399565; batch adversarial loss: 0.535337\n",
      "epoch 131; iter: 0; batch classifier loss: 0.447611; batch adversarial loss: 0.525869\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329846; batch adversarial loss: 0.526269\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385435; batch adversarial loss: 0.488711\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378215; batch adversarial loss: 0.572295\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349841; batch adversarial loss: 0.590190\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397680; batch adversarial loss: 0.664593\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358732; batch adversarial loss: 0.534945\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335660; batch adversarial loss: 0.535241\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378772; batch adversarial loss: 0.516987\n",
      "epoch 140; iter: 0; batch classifier loss: 0.314964; batch adversarial loss: 0.479965\n",
      "epoch 141; iter: 0; batch classifier loss: 0.421028; batch adversarial loss: 0.544190\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318252; batch adversarial loss: 0.581778\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334235; batch adversarial loss: 0.609592\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352699; batch adversarial loss: 0.581416\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365063; batch adversarial loss: 0.590174\n",
      "epoch 146; iter: 0; batch classifier loss: 0.445874; batch adversarial loss: 0.609298\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410515; batch adversarial loss: 0.553894\n",
      "epoch 148; iter: 0; batch classifier loss: 0.399111; batch adversarial loss: 0.599904\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376695; batch adversarial loss: 0.608499\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356900; batch adversarial loss: 0.563192\n",
      "epoch 151; iter: 0; batch classifier loss: 0.400154; batch adversarial loss: 0.590321\n",
      "epoch 152; iter: 0; batch classifier loss: 0.401028; batch adversarial loss: 0.580924\n",
      "epoch 153; iter: 0; batch classifier loss: 0.373842; batch adversarial loss: 0.534951\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375551; batch adversarial loss: 0.581428\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355280; batch adversarial loss: 0.498011\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402859; batch adversarial loss: 0.544743\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369001; batch adversarial loss: 0.618407\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366842; batch adversarial loss: 0.627405\n",
      "epoch 159; iter: 0; batch classifier loss: 0.328428; batch adversarial loss: 0.544057\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381523; batch adversarial loss: 0.553881\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373774; batch adversarial loss: 0.609285\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394813; batch adversarial loss: 0.562988\n",
      "epoch 163; iter: 0; batch classifier loss: 0.295934; batch adversarial loss: 0.535073\n",
      "epoch 164; iter: 0; batch classifier loss: 0.367312; batch adversarial loss: 0.553692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398554; batch adversarial loss: 0.515913\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359670; batch adversarial loss: 0.489036\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394969; batch adversarial loss: 0.507654\n",
      "epoch 168; iter: 0; batch classifier loss: 0.396958; batch adversarial loss: 0.535656\n",
      "epoch 169; iter: 0; batch classifier loss: 0.453063; batch adversarial loss: 0.563267\n",
      "epoch 170; iter: 0; batch classifier loss: 0.424470; batch adversarial loss: 0.609004\n",
      "epoch 171; iter: 0; batch classifier loss: 0.434122; batch adversarial loss: 0.525893\n",
      "epoch 172; iter: 0; batch classifier loss: 0.429715; batch adversarial loss: 0.534821\n",
      "epoch 173; iter: 0; batch classifier loss: 0.439364; batch adversarial loss: 0.544172\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364945; batch adversarial loss: 0.544513\n",
      "epoch 175; iter: 0; batch classifier loss: 0.402319; batch adversarial loss: 0.600248\n",
      "epoch 176; iter: 0; batch classifier loss: 0.246778; batch adversarial loss: 0.600004\n",
      "epoch 177; iter: 0; batch classifier loss: 0.479540; batch adversarial loss: 0.553267\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351247; batch adversarial loss: 0.489011\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386376; batch adversarial loss: 0.479419\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358893; batch adversarial loss: 0.516329\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370021; batch adversarial loss: 0.461288\n",
      "epoch 182; iter: 0; batch classifier loss: 0.472312; batch adversarial loss: 0.535380\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367453; batch adversarial loss: 0.608997\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330383; batch adversarial loss: 0.489048\n",
      "epoch 185; iter: 0; batch classifier loss: 0.423838; batch adversarial loss: 0.479413\n",
      "epoch 186; iter: 0; batch classifier loss: 0.364450; batch adversarial loss: 0.516101\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350857; batch adversarial loss: 0.461303\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355213; batch adversarial loss: 0.489619\n",
      "epoch 189; iter: 0; batch classifier loss: 0.279268; batch adversarial loss: 0.571490\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327343; batch adversarial loss: 0.489688\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373792; batch adversarial loss: 0.590895\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355205; batch adversarial loss: 0.489012\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307681; batch adversarial loss: 0.544417\n",
      "epoch 194; iter: 0; batch classifier loss: 0.246950; batch adversarial loss: 0.526281\n",
      "epoch 195; iter: 0; batch classifier loss: 0.345480; batch adversarial loss: 0.563414\n",
      "epoch 196; iter: 0; batch classifier loss: 0.389164; batch adversarial loss: 0.498709\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336427; batch adversarial loss: 0.535029\n",
      "epoch 198; iter: 0; batch classifier loss: 0.380784; batch adversarial loss: 0.554652\n",
      "epoch 199; iter: 0; batch classifier loss: 0.256769; batch adversarial loss: 0.553850\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753330; batch adversarial loss: 0.640359\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583303; batch adversarial loss: 0.650635\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567946; batch adversarial loss: 0.625292\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558297; batch adversarial loss: 0.592931\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518600; batch adversarial loss: 0.588802\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586193; batch adversarial loss: 0.609931\n",
      "epoch 6; iter: 0; batch classifier loss: 0.530165; batch adversarial loss: 0.639199\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554555; batch adversarial loss: 0.614367\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588888; batch adversarial loss: 0.603214\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553681; batch adversarial loss: 0.608714\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592472; batch adversarial loss: 0.608760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.571076; batch adversarial loss: 0.587892\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504765; batch adversarial loss: 0.575739\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500143; batch adversarial loss: 0.595886\n",
      "epoch 14; iter: 0; batch classifier loss: 0.596858; batch adversarial loss: 0.546472\n",
      "epoch 15; iter: 0; batch classifier loss: 0.612462; batch adversarial loss: 0.591314\n",
      "epoch 16; iter: 0; batch classifier loss: 0.544578; batch adversarial loss: 0.599187\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479592; batch adversarial loss: 0.540517\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467532; batch adversarial loss: 0.575451\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518905; batch adversarial loss: 0.574882\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499390; batch adversarial loss: 0.587208\n",
      "epoch 21; iter: 0; batch classifier loss: 0.563117; batch adversarial loss: 0.535042\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507719; batch adversarial loss: 0.506231\n",
      "epoch 23; iter: 0; batch classifier loss: 0.567914; batch adversarial loss: 0.604467\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436713; batch adversarial loss: 0.528495\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496528; batch adversarial loss: 0.552783\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465492; batch adversarial loss: 0.520891\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432545; batch adversarial loss: 0.546077\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532885; batch adversarial loss: 0.578362\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483541; batch adversarial loss: 0.644415\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458978; batch adversarial loss: 0.530642\n",
      "epoch 31; iter: 0; batch classifier loss: 0.420295; batch adversarial loss: 0.496529\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460443; batch adversarial loss: 0.488284\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478882; batch adversarial loss: 0.554518\n",
      "epoch 34; iter: 0; batch classifier loss: 0.356759; batch adversarial loss: 0.581997\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438997; batch adversarial loss: 0.440485\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449017; batch adversarial loss: 0.614294\n",
      "epoch 37; iter: 0; batch classifier loss: 0.433635; batch adversarial loss: 0.605572\n",
      "epoch 38; iter: 0; batch classifier loss: 0.423012; batch adversarial loss: 0.556230\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440952; batch adversarial loss: 0.535838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.375663; batch adversarial loss: 0.616803\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415627; batch adversarial loss: 0.552470\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492586; batch adversarial loss: 0.488119\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397004; batch adversarial loss: 0.508519\n",
      "epoch 44; iter: 0; batch classifier loss: 0.480045; batch adversarial loss: 0.523036\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457290; batch adversarial loss: 0.649091\n",
      "epoch 46; iter: 0; batch classifier loss: 0.497315; batch adversarial loss: 0.514070\n",
      "epoch 47; iter: 0; batch classifier loss: 0.486399; batch adversarial loss: 0.506959\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445737; batch adversarial loss: 0.478813\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422896; batch adversarial loss: 0.616513\n",
      "epoch 50; iter: 0; batch classifier loss: 0.531859; batch adversarial loss: 0.532579\n",
      "epoch 51; iter: 0; batch classifier loss: 0.520269; batch adversarial loss: 0.561193\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409768; batch adversarial loss: 0.542586\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465907; batch adversarial loss: 0.537231\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473884; batch adversarial loss: 0.528179\n",
      "epoch 55; iter: 0; batch classifier loss: 0.461640; batch adversarial loss: 0.552095\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449059; batch adversarial loss: 0.451030\n",
      "epoch 57; iter: 0; batch classifier loss: 0.491113; batch adversarial loss: 0.531848\n",
      "epoch 58; iter: 0; batch classifier loss: 0.433497; batch adversarial loss: 0.535733\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384164; batch adversarial loss: 0.572718\n",
      "epoch 60; iter: 0; batch classifier loss: 0.490565; batch adversarial loss: 0.552409\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426745; batch adversarial loss: 0.489414\n",
      "epoch 62; iter: 0; batch classifier loss: 0.384915; batch adversarial loss: 0.570830\n",
      "epoch 63; iter: 0; batch classifier loss: 0.505788; batch adversarial loss: 0.608950\n",
      "epoch 64; iter: 0; batch classifier loss: 0.323198; batch adversarial loss: 0.562974\n",
      "epoch 65; iter: 0; batch classifier loss: 0.505765; batch adversarial loss: 0.534497\n",
      "epoch 66; iter: 0; batch classifier loss: 0.364746; batch adversarial loss: 0.514289\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431549; batch adversarial loss: 0.518176\n",
      "epoch 68; iter: 0; batch classifier loss: 0.330960; batch adversarial loss: 0.561186\n",
      "epoch 69; iter: 0; batch classifier loss: 0.473521; batch adversarial loss: 0.545788\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415654; batch adversarial loss: 0.517361\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411546; batch adversarial loss: 0.573579\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466305; batch adversarial loss: 0.616221\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376250; batch adversarial loss: 0.408249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383753; batch adversarial loss: 0.573626\n",
      "epoch 75; iter: 0; batch classifier loss: 0.451341; batch adversarial loss: 0.526558\n",
      "epoch 76; iter: 0; batch classifier loss: 0.374222; batch adversarial loss: 0.599831\n",
      "epoch 77; iter: 0; batch classifier loss: 0.363474; batch adversarial loss: 0.598035\n",
      "epoch 78; iter: 0; batch classifier loss: 0.388253; batch adversarial loss: 0.473384\n",
      "epoch 79; iter: 0; batch classifier loss: 0.459001; batch adversarial loss: 0.544560\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363523; batch adversarial loss: 0.433988\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415986; batch adversarial loss: 0.553755\n",
      "epoch 82; iter: 0; batch classifier loss: 0.432069; batch adversarial loss: 0.524457\n",
      "epoch 83; iter: 0; batch classifier loss: 0.446719; batch adversarial loss: 0.552402\n",
      "epoch 84; iter: 0; batch classifier loss: 0.361550; batch adversarial loss: 0.526110\n",
      "epoch 85; iter: 0; batch classifier loss: 0.498600; batch adversarial loss: 0.481830\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415642; batch adversarial loss: 0.506470\n",
      "epoch 87; iter: 0; batch classifier loss: 0.348952; batch adversarial loss: 0.544277\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391665; batch adversarial loss: 0.561735\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409770; batch adversarial loss: 0.543046\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428961; batch adversarial loss: 0.526623\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381503; batch adversarial loss: 0.505604\n",
      "epoch 92; iter: 0; batch classifier loss: 0.429668; batch adversarial loss: 0.573562\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429756; batch adversarial loss: 0.546306\n",
      "epoch 94; iter: 0; batch classifier loss: 0.344914; batch adversarial loss: 0.546381\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384687; batch adversarial loss: 0.498212\n",
      "epoch 96; iter: 0; batch classifier loss: 0.486041; batch adversarial loss: 0.489640\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420578; batch adversarial loss: 0.563108\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379540; batch adversarial loss: 0.634268\n",
      "epoch 99; iter: 0; batch classifier loss: 0.524151; batch adversarial loss: 0.499534\n",
      "epoch 100; iter: 0; batch classifier loss: 0.441233; batch adversarial loss: 0.562829\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411731; batch adversarial loss: 0.543858\n",
      "epoch 102; iter: 0; batch classifier loss: 0.452225; batch adversarial loss: 0.518727\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356758; batch adversarial loss: 0.489338\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366922; batch adversarial loss: 0.625839\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368258; batch adversarial loss: 0.526929\n",
      "epoch 106; iter: 0; batch classifier loss: 0.401478; batch adversarial loss: 0.534862\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368205; batch adversarial loss: 0.629208\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435859; batch adversarial loss: 0.534561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109; iter: 0; batch classifier loss: 0.374357; batch adversarial loss: 0.579225\n",
      "epoch 110; iter: 0; batch classifier loss: 0.331580; batch adversarial loss: 0.592963\n",
      "epoch 111; iter: 0; batch classifier loss: 0.360866; batch adversarial loss: 0.562241\n",
      "epoch 112; iter: 0; batch classifier loss: 0.313870; batch adversarial loss: 0.553165\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383045; batch adversarial loss: 0.509110\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372170; batch adversarial loss: 0.564192\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328894; batch adversarial loss: 0.535589\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392156; batch adversarial loss: 0.555330\n",
      "epoch 117; iter: 0; batch classifier loss: 0.468896; batch adversarial loss: 0.532018\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358463; batch adversarial loss: 0.637082\n",
      "epoch 119; iter: 0; batch classifier loss: 0.412291; batch adversarial loss: 0.490529\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354647; batch adversarial loss: 0.508327\n",
      "epoch 121; iter: 0; batch classifier loss: 0.413243; batch adversarial loss: 0.534944\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339631; batch adversarial loss: 0.544129\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409015; batch adversarial loss: 0.553487\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338673; batch adversarial loss: 0.543793\n",
      "epoch 125; iter: 0; batch classifier loss: 0.435417; batch adversarial loss: 0.589768\n",
      "epoch 126; iter: 0; batch classifier loss: 0.419822; batch adversarial loss: 0.579798\n",
      "epoch 127; iter: 0; batch classifier loss: 0.441353; batch adversarial loss: 0.495953\n",
      "epoch 128; iter: 0; batch classifier loss: 0.441235; batch adversarial loss: 0.459974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.357524; batch adversarial loss: 0.449801\n",
      "epoch 130; iter: 0; batch classifier loss: 0.325422; batch adversarial loss: 0.533101\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400856; batch adversarial loss: 0.545418\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330626; batch adversarial loss: 0.618325\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334970; batch adversarial loss: 0.544154\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354420; batch adversarial loss: 0.535824\n",
      "epoch 135; iter: 0; batch classifier loss: 0.447436; batch adversarial loss: 0.533669\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365916; batch adversarial loss: 0.507029\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329401; batch adversarial loss: 0.552367\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386878; batch adversarial loss: 0.524535\n",
      "epoch 139; iter: 0; batch classifier loss: 0.453994; batch adversarial loss: 0.509026\n",
      "epoch 140; iter: 0; batch classifier loss: 0.440238; batch adversarial loss: 0.499249\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339966; batch adversarial loss: 0.563215\n",
      "epoch 142; iter: 0; batch classifier loss: 0.365907; batch adversarial loss: 0.524755\n",
      "epoch 143; iter: 0; batch classifier loss: 0.486218; batch adversarial loss: 0.479333\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392082; batch adversarial loss: 0.527202\n",
      "epoch 145; iter: 0; batch classifier loss: 0.402432; batch adversarial loss: 0.490528\n",
      "epoch 146; iter: 0; batch classifier loss: 0.419008; batch adversarial loss: 0.626854\n",
      "epoch 147; iter: 0; batch classifier loss: 0.440681; batch adversarial loss: 0.544905\n",
      "epoch 148; iter: 0; batch classifier loss: 0.383236; batch adversarial loss: 0.526843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323644; batch adversarial loss: 0.562892\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361393; batch adversarial loss: 0.534697\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336577; batch adversarial loss: 0.582301\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376805; batch adversarial loss: 0.598542\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402147; batch adversarial loss: 0.598856\n",
      "epoch 154; iter: 0; batch classifier loss: 0.272530; batch adversarial loss: 0.573544\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350024; batch adversarial loss: 0.634923\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368814; batch adversarial loss: 0.587883\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331531; batch adversarial loss: 0.544754\n",
      "epoch 158; iter: 0; batch classifier loss: 0.357908; batch adversarial loss: 0.570222\n",
      "epoch 159; iter: 0; batch classifier loss: 0.436817; batch adversarial loss: 0.553249\n",
      "epoch 160; iter: 0; batch classifier loss: 0.392918; batch adversarial loss: 0.611028\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369952; batch adversarial loss: 0.544377\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329536; batch adversarial loss: 0.563278\n",
      "epoch 163; iter: 0; batch classifier loss: 0.270558; batch adversarial loss: 0.525982\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375971; batch adversarial loss: 0.582039\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362482; batch adversarial loss: 0.472167\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365505; batch adversarial loss: 0.527820\n",
      "epoch 167; iter: 0; batch classifier loss: 0.416145; batch adversarial loss: 0.644021\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390544; batch adversarial loss: 0.454277\n",
      "epoch 169; iter: 0; batch classifier loss: 0.295234; batch adversarial loss: 0.534198\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333624; batch adversarial loss: 0.562186\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320848; batch adversarial loss: 0.526009\n",
      "epoch 172; iter: 0; batch classifier loss: 0.408718; batch adversarial loss: 0.554768\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341130; batch adversarial loss: 0.570415\n",
      "epoch 174; iter: 0; batch classifier loss: 0.525882; batch adversarial loss: 0.574398\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356502; batch adversarial loss: 0.544443\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377587; batch adversarial loss: 0.499701\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306982; batch adversarial loss: 0.535030\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372941; batch adversarial loss: 0.553318\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368228; batch adversarial loss: 0.515948\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358940; batch adversarial loss: 0.590059\n",
      "epoch 181; iter: 0; batch classifier loss: 0.467700; batch adversarial loss: 0.479662\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378515; batch adversarial loss: 0.637525\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352712; batch adversarial loss: 0.570623\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372419; batch adversarial loss: 0.505563\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356832; batch adversarial loss: 0.591572\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341350; batch adversarial loss: 0.516804\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352836; batch adversarial loss: 0.600509\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328013; batch adversarial loss: 0.480297\n",
      "epoch 189; iter: 0; batch classifier loss: 0.482983; batch adversarial loss: 0.570810\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360009; batch adversarial loss: 0.457529\n",
      "epoch 191; iter: 0; batch classifier loss: 0.432865; batch adversarial loss: 0.536450\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389158; batch adversarial loss: 0.475863\n",
      "epoch 193; iter: 0; batch classifier loss: 0.315303; batch adversarial loss: 0.563136\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369339; batch adversarial loss: 0.503017\n",
      "epoch 195; iter: 0; batch classifier loss: 0.380429; batch adversarial loss: 0.533253\n",
      "epoch 196; iter: 0; batch classifier loss: 0.305479; batch adversarial loss: 0.522844\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326910; batch adversarial loss: 0.560320\n",
      "epoch 198; iter: 0; batch classifier loss: 0.314332; batch adversarial loss: 0.564347\n",
      "epoch 199; iter: 0; batch classifier loss: 0.462737; batch adversarial loss: 0.529978\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730864; batch adversarial loss: 0.825042\n",
      "epoch 1; iter: 0; batch classifier loss: 0.727110; batch adversarial loss: 0.870256\n",
      "epoch 2; iter: 0; batch classifier loss: 0.753259; batch adversarial loss: 0.820350\n",
      "epoch 3; iter: 0; batch classifier loss: 0.655782; batch adversarial loss: 0.741541\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634109; batch adversarial loss: 0.686400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.656358; batch adversarial loss: 0.629272\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539201; batch adversarial loss: 0.617217\n",
      "epoch 7; iter: 0; batch classifier loss: 0.576890; batch adversarial loss: 0.624156\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611301; batch adversarial loss: 0.630737\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602129; batch adversarial loss: 0.632644\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496085; batch adversarial loss: 0.604235\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509248; batch adversarial loss: 0.615220\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505614; batch adversarial loss: 0.578781\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497889; batch adversarial loss: 0.555649\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465263; batch adversarial loss: 0.615816\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474477; batch adversarial loss: 0.528732\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499725; batch adversarial loss: 0.559647\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504162; batch adversarial loss: 0.527695\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521364; batch adversarial loss: 0.498994\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501061; batch adversarial loss: 0.572309\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548936; batch adversarial loss: 0.543176\n",
      "epoch 21; iter: 0; batch classifier loss: 0.466422; batch adversarial loss: 0.492474\n",
      "epoch 22; iter: 0; batch classifier loss: 0.559732; batch adversarial loss: 0.440227\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492031; batch adversarial loss: 0.555227\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461223; batch adversarial loss: 0.507128\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438837; batch adversarial loss: 0.530993\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517893; batch adversarial loss: 0.573162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489072; batch adversarial loss: 0.563634\n",
      "epoch 28; iter: 0; batch classifier loss: 0.548715; batch adversarial loss: 0.460865\n",
      "epoch 29; iter: 0; batch classifier loss: 0.498358; batch adversarial loss: 0.557414\n",
      "epoch 30; iter: 0; batch classifier loss: 0.423727; batch adversarial loss: 0.530649\n",
      "epoch 31; iter: 0; batch classifier loss: 0.401836; batch adversarial loss: 0.529554\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529975; batch adversarial loss: 0.551971\n",
      "epoch 33; iter: 0; batch classifier loss: 0.413802; batch adversarial loss: 0.546288\n",
      "epoch 34; iter: 0; batch classifier loss: 0.514861; batch adversarial loss: 0.563383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478042; batch adversarial loss: 0.600463\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480475; batch adversarial loss: 0.480751\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428667; batch adversarial loss: 0.608072\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448640; batch adversarial loss: 0.533616\n",
      "epoch 39; iter: 0; batch classifier loss: 0.475307; batch adversarial loss: 0.503453\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418808; batch adversarial loss: 0.462468\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420849; batch adversarial loss: 0.610290\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431204; batch adversarial loss: 0.581824\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470657; batch adversarial loss: 0.472330\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423887; batch adversarial loss: 0.471487\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465411; batch adversarial loss: 0.516468\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374893; batch adversarial loss: 0.516751\n",
      "epoch 47; iter: 0; batch classifier loss: 0.507548; batch adversarial loss: 0.424168\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491425; batch adversarial loss: 0.600456\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455375; batch adversarial loss: 0.592010\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424626; batch adversarial loss: 0.601008\n",
      "epoch 51; iter: 0; batch classifier loss: 0.472258; batch adversarial loss: 0.526645\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409902; batch adversarial loss: 0.517587\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428681; batch adversarial loss: 0.450593\n",
      "epoch 54; iter: 0; batch classifier loss: 0.468642; batch adversarial loss: 0.544520\n",
      "epoch 55; iter: 0; batch classifier loss: 0.494173; batch adversarial loss: 0.459441\n",
      "epoch 56; iter: 0; batch classifier loss: 0.501144; batch adversarial loss: 0.478014\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429133; batch adversarial loss: 0.563201\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421329; batch adversarial loss: 0.610910\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444550; batch adversarial loss: 0.544633\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420234; batch adversarial loss: 0.496860\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458966; batch adversarial loss: 0.544632\n",
      "epoch 62; iter: 0; batch classifier loss: 0.339715; batch adversarial loss: 0.534946\n",
      "epoch 63; iter: 0; batch classifier loss: 0.522126; batch adversarial loss: 0.564147\n",
      "epoch 64; iter: 0; batch classifier loss: 0.487514; batch adversarial loss: 0.477428\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457085; batch adversarial loss: 0.525220\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377273; batch adversarial loss: 0.515581\n",
      "epoch 67; iter: 0; batch classifier loss: 0.529089; batch adversarial loss: 0.533615\n",
      "epoch 68; iter: 0; batch classifier loss: 0.456707; batch adversarial loss: 0.563546\n",
      "epoch 69; iter: 0; batch classifier loss: 0.510727; batch adversarial loss: 0.544896\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459027; batch adversarial loss: 0.526145\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393783; batch adversarial loss: 0.592441\n",
      "epoch 72; iter: 0; batch classifier loss: 0.476482; batch adversarial loss: 0.459251\n",
      "epoch 73; iter: 0; batch classifier loss: 0.406198; batch adversarial loss: 0.573195\n",
      "epoch 74; iter: 0; batch classifier loss: 0.402087; batch adversarial loss: 0.554151\n",
      "epoch 75; iter: 0; batch classifier loss: 0.323926; batch adversarial loss: 0.496882\n",
      "epoch 76; iter: 0; batch classifier loss: 0.435760; batch adversarial loss: 0.535110\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394176; batch adversarial loss: 0.602157\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438894; batch adversarial loss: 0.554300\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394723; batch adversarial loss: 0.496520\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409522; batch adversarial loss: 0.631314\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427405; batch adversarial loss: 0.544598\n",
      "epoch 82; iter: 0; batch classifier loss: 0.300728; batch adversarial loss: 0.497069\n",
      "epoch 83; iter: 0; batch classifier loss: 0.472138; batch adversarial loss: 0.544615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392838; batch adversarial loss: 0.544737\n",
      "epoch 85; iter: 0; batch classifier loss: 0.501588; batch adversarial loss: 0.544369\n",
      "epoch 86; iter: 0; batch classifier loss: 0.362844; batch adversarial loss: 0.573605\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455415; batch adversarial loss: 0.535178\n",
      "epoch 88; iter: 0; batch classifier loss: 0.522495; batch adversarial loss: 0.506381\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381357; batch adversarial loss: 0.535750\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425644; batch adversarial loss: 0.487391\n",
      "epoch 91; iter: 0; batch classifier loss: 0.449809; batch adversarial loss: 0.525071\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385699; batch adversarial loss: 0.515893\n",
      "epoch 93; iter: 0; batch classifier loss: 0.425882; batch adversarial loss: 0.525099\n",
      "epoch 94; iter: 0; batch classifier loss: 0.416665; batch adversarial loss: 0.486922\n",
      "epoch 95; iter: 0; batch classifier loss: 0.438415; batch adversarial loss: 0.592736\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358193; batch adversarial loss: 0.467900\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374670; batch adversarial loss: 0.563509\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379795; batch adversarial loss: 0.535294\n",
      "epoch 99; iter: 0; batch classifier loss: 0.325782; batch adversarial loss: 0.535048\n",
      "epoch 100; iter: 0; batch classifier loss: 0.468276; batch adversarial loss: 0.583222\n",
      "epoch 101; iter: 0; batch classifier loss: 0.451642; batch adversarial loss: 0.513728\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401715; batch adversarial loss: 0.553408\n",
      "epoch 103; iter: 0; batch classifier loss: 0.348230; batch adversarial loss: 0.514763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.406072; batch adversarial loss: 0.526467\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388715; batch adversarial loss: 0.468251\n",
      "epoch 106; iter: 0; batch classifier loss: 0.475974; batch adversarial loss: 0.498400\n",
      "epoch 107; iter: 0; batch classifier loss: 0.467295; batch adversarial loss: 0.573017\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336902; batch adversarial loss: 0.584008\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346281; batch adversarial loss: 0.488931\n",
      "epoch 110; iter: 0; batch classifier loss: 0.380803; batch adversarial loss: 0.487534\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409297; batch adversarial loss: 0.516566\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371090; batch adversarial loss: 0.553691\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363936; batch adversarial loss: 0.525891\n",
      "epoch 114; iter: 0; batch classifier loss: 0.480439; batch adversarial loss: 0.582452\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394913; batch adversarial loss: 0.507123\n",
      "epoch 116; iter: 0; batch classifier loss: 0.327847; batch adversarial loss: 0.534976\n",
      "epoch 117; iter: 0; batch classifier loss: 0.353379; batch adversarial loss: 0.525730\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404818; batch adversarial loss: 0.525499\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379402; batch adversarial loss: 0.448834\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366759; batch adversarial loss: 0.515888\n",
      "epoch 121; iter: 0; batch classifier loss: 0.410875; batch adversarial loss: 0.506358\n",
      "epoch 122; iter: 0; batch classifier loss: 0.412576; batch adversarial loss: 0.573620\n",
      "epoch 123; iter: 0; batch classifier loss: 0.324069; batch adversarial loss: 0.573331\n",
      "epoch 124; iter: 0; batch classifier loss: 0.318636; batch adversarial loss: 0.458384\n",
      "epoch 125; iter: 0; batch classifier loss: 0.291534; batch adversarial loss: 0.544294\n",
      "epoch 126; iter: 0; batch classifier loss: 0.332101; batch adversarial loss: 0.486844\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356186; batch adversarial loss: 0.505926\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372517; batch adversarial loss: 0.534697\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362688; batch adversarial loss: 0.486207\n",
      "epoch 130; iter: 0; batch classifier loss: 0.407770; batch adversarial loss: 0.467086\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326037; batch adversarial loss: 0.563554\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346794; batch adversarial loss: 0.515372\n",
      "epoch 133; iter: 0; batch classifier loss: 0.407593; batch adversarial loss: 0.543674\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333029; batch adversarial loss: 0.466781\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371225; batch adversarial loss: 0.528217\n",
      "epoch 136; iter: 0; batch classifier loss: 0.400950; batch adversarial loss: 0.478005\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343085; batch adversarial loss: 0.564395\n",
      "epoch 138; iter: 0; batch classifier loss: 0.323510; batch adversarial loss: 0.554697\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383880; batch adversarial loss: 0.508148\n",
      "epoch 140; iter: 0; batch classifier loss: 0.411195; batch adversarial loss: 0.492928\n",
      "epoch 141; iter: 0; batch classifier loss: 0.419441; batch adversarial loss: 0.525880\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363259; batch adversarial loss: 0.513994\n",
      "epoch 143; iter: 0; batch classifier loss: 0.444406; batch adversarial loss: 0.525151\n",
      "epoch 144; iter: 0; batch classifier loss: 0.306831; batch adversarial loss: 0.498629\n",
      "epoch 145; iter: 0; batch classifier loss: 0.433684; batch adversarial loss: 0.525433\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361312; batch adversarial loss: 0.485860\n",
      "epoch 147; iter: 0; batch classifier loss: 0.492496; batch adversarial loss: 0.564914\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389599; batch adversarial loss: 0.567720\n",
      "epoch 149; iter: 0; batch classifier loss: 0.446016; batch adversarial loss: 0.466384\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358872; batch adversarial loss: 0.564017\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348259; batch adversarial loss: 0.431120\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386865; batch adversarial loss: 0.592281\n",
      "epoch 153; iter: 0; batch classifier loss: 0.401320; batch adversarial loss: 0.545764\n",
      "epoch 154; iter: 0; batch classifier loss: 0.387353; batch adversarial loss: 0.505990\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317447; batch adversarial loss: 0.542819\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355344; batch adversarial loss: 0.563745\n",
      "epoch 157; iter: 0; batch classifier loss: 0.401283; batch adversarial loss: 0.591341\n",
      "epoch 158; iter: 0; batch classifier loss: 0.435986; batch adversarial loss: 0.610148\n",
      "epoch 159; iter: 0; batch classifier loss: 0.378338; batch adversarial loss: 0.565581\n",
      "epoch 160; iter: 0; batch classifier loss: 0.324001; batch adversarial loss: 0.469507\n",
      "epoch 161; iter: 0; batch classifier loss: 0.425016; batch adversarial loss: 0.517409\n",
      "epoch 162; iter: 0; batch classifier loss: 0.314164; batch adversarial loss: 0.479002\n",
      "epoch 163; iter: 0; batch classifier loss: 0.306614; batch adversarial loss: 0.582458\n",
      "epoch 164; iter: 0; batch classifier loss: 0.343822; batch adversarial loss: 0.544723\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379299; batch adversarial loss: 0.536154\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389030; batch adversarial loss: 0.468925\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348755; batch adversarial loss: 0.497137\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348994; batch adversarial loss: 0.497621\n",
      "epoch 169; iter: 0; batch classifier loss: 0.410272; batch adversarial loss: 0.563676\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346584; batch adversarial loss: 0.487903\n",
      "epoch 171; iter: 0; batch classifier loss: 0.377697; batch adversarial loss: 0.544406\n",
      "epoch 172; iter: 0; batch classifier loss: 0.426872; batch adversarial loss: 0.554253\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337828; batch adversarial loss: 0.573389\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338656; batch adversarial loss: 0.582808\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380454; batch adversarial loss: 0.573525\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349675; batch adversarial loss: 0.515798\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355211; batch adversarial loss: 0.535181\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383780; batch adversarial loss: 0.573200\n",
      "epoch 179; iter: 0; batch classifier loss: 0.443308; batch adversarial loss: 0.477526\n",
      "epoch 180; iter: 0; batch classifier loss: 0.361293; batch adversarial loss: 0.515660\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338822; batch adversarial loss: 0.563692\n",
      "epoch 182; iter: 0; batch classifier loss: 0.392627; batch adversarial loss: 0.640623\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338801; batch adversarial loss: 0.544650\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357276; batch adversarial loss: 0.525563\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397812; batch adversarial loss: 0.554281\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373968; batch adversarial loss: 0.477340\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376086; batch adversarial loss: 0.563969\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341545; batch adversarial loss: 0.611821\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344446; batch adversarial loss: 0.544554\n",
      "epoch 190; iter: 0; batch classifier loss: 0.381051; batch adversarial loss: 0.506220\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336137; batch adversarial loss: 0.582203\n",
      "epoch 192; iter: 0; batch classifier loss: 0.393528; batch adversarial loss: 0.573416\n",
      "epoch 193; iter: 0; batch classifier loss: 0.367591; batch adversarial loss: 0.525445\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362023; batch adversarial loss: 0.468196\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312379; batch adversarial loss: 0.524423\n",
      "epoch 196; iter: 0; batch classifier loss: 0.398852; batch adversarial loss: 0.602280\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329909; batch adversarial loss: 0.592412\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372815; batch adversarial loss: 0.506083\n",
      "epoch 199; iter: 0; batch classifier loss: 0.391266; batch adversarial loss: 0.563462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.871832; batch adversarial loss: 0.620167\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595965; batch adversarial loss: 0.700032\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604115; batch adversarial loss: 0.671798\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579060; batch adversarial loss: 0.626655\n",
      "epoch 4; iter: 0; batch classifier loss: 0.637750; batch adversarial loss: 0.619714\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595845; batch adversarial loss: 0.579026\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563375; batch adversarial loss: 0.587123\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582482; batch adversarial loss: 0.617964\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498560; batch adversarial loss: 0.563797\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571996; batch adversarial loss: 0.561207\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532045; batch adversarial loss: 0.573349\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506512; batch adversarial loss: 0.573318\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539001; batch adversarial loss: 0.604760\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495155; batch adversarial loss: 0.588899\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500439; batch adversarial loss: 0.602084\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473866; batch adversarial loss: 0.603622\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523908; batch adversarial loss: 0.582555\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532662; batch adversarial loss: 0.584029\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455540; batch adversarial loss: 0.594808\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508627; batch adversarial loss: 0.613525\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441036; batch adversarial loss: 0.566207\n",
      "epoch 21; iter: 0; batch classifier loss: 0.403663; batch adversarial loss: 0.573604\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497325; batch adversarial loss: 0.564337\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462484; batch adversarial loss: 0.572591\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477607; batch adversarial loss: 0.536029\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501619; batch adversarial loss: 0.517022\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474051; batch adversarial loss: 0.538157\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457733; batch adversarial loss: 0.585389\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474279; batch adversarial loss: 0.541640\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460794; batch adversarial loss: 0.604281\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488342; batch adversarial loss: 0.604452\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416719; batch adversarial loss: 0.544558\n",
      "epoch 32; iter: 0; batch classifier loss: 0.526979; batch adversarial loss: 0.554731\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432942; batch adversarial loss: 0.525136\n",
      "epoch 34; iter: 0; batch classifier loss: 0.372577; batch adversarial loss: 0.482401\n",
      "epoch 35; iter: 0; batch classifier loss: 0.431689; batch adversarial loss: 0.593598\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425872; batch adversarial loss: 0.553659\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394996; batch adversarial loss: 0.583625\n",
      "epoch 38; iter: 0; batch classifier loss: 0.477279; batch adversarial loss: 0.529441\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405151; batch adversarial loss: 0.539716\n",
      "epoch 40; iter: 0; batch classifier loss: 0.378413; batch adversarial loss: 0.521338\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486869; batch adversarial loss: 0.558486\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416277; batch adversarial loss: 0.600316\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431041; batch adversarial loss: 0.530576\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421214; batch adversarial loss: 0.565175\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454428; batch adversarial loss: 0.648327\n",
      "epoch 46; iter: 0; batch classifier loss: 0.373778; batch adversarial loss: 0.545726\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442174; batch adversarial loss: 0.542703\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484445; batch adversarial loss: 0.565377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.459348; batch adversarial loss: 0.551889\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408001; batch adversarial loss: 0.573568\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444752; batch adversarial loss: 0.477703\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466218; batch adversarial loss: 0.619332\n",
      "epoch 53; iter: 0; batch classifier loss: 0.416271; batch adversarial loss: 0.617177\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447887; batch adversarial loss: 0.558076\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462655; batch adversarial loss: 0.528174\n",
      "epoch 56; iter: 0; batch classifier loss: 0.533281; batch adversarial loss: 0.569512\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405278; batch adversarial loss: 0.588639\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403443; batch adversarial loss: 0.564266\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410455; batch adversarial loss: 0.553524\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418050; batch adversarial loss: 0.560808\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396218; batch adversarial loss: 0.596127\n",
      "epoch 62; iter: 0; batch classifier loss: 0.463005; batch adversarial loss: 0.496553\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429707; batch adversarial loss: 0.534413\n",
      "epoch 64; iter: 0; batch classifier loss: 0.338313; batch adversarial loss: 0.562203\n",
      "epoch 65; iter: 0; batch classifier loss: 0.434330; batch adversarial loss: 0.588150\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398333; batch adversarial loss: 0.539557\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421069; batch adversarial loss: 0.596511\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403625; batch adversarial loss: 0.472872\n",
      "epoch 69; iter: 0; batch classifier loss: 0.372438; batch adversarial loss: 0.517641\n",
      "epoch 70; iter: 0; batch classifier loss: 0.337675; batch adversarial loss: 0.510012\n",
      "epoch 71; iter: 0; batch classifier loss: 0.455717; batch adversarial loss: 0.584447\n",
      "epoch 72; iter: 0; batch classifier loss: 0.449840; batch adversarial loss: 0.618878\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401739; batch adversarial loss: 0.516953\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439589; batch adversarial loss: 0.581725\n",
      "epoch 75; iter: 0; batch classifier loss: 0.332523; batch adversarial loss: 0.658926\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413952; batch adversarial loss: 0.530030\n",
      "epoch 77; iter: 0; batch classifier loss: 0.324066; batch adversarial loss: 0.598533\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439750; batch adversarial loss: 0.507005\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408329; batch adversarial loss: 0.504878\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390337; batch adversarial loss: 0.523961\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374041; batch adversarial loss: 0.510827\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381232; batch adversarial loss: 0.527691\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415542; batch adversarial loss: 0.583194\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437076; batch adversarial loss: 0.515273\n",
      "epoch 85; iter: 0; batch classifier loss: 0.358228; batch adversarial loss: 0.562034\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356391; batch adversarial loss: 0.549216\n",
      "epoch 87; iter: 0; batch classifier loss: 0.432277; batch adversarial loss: 0.593094\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389514; batch adversarial loss: 0.481324\n",
      "epoch 89; iter: 0; batch classifier loss: 0.326330; batch adversarial loss: 0.528385\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355477; batch adversarial loss: 0.586854\n",
      "epoch 91; iter: 0; batch classifier loss: 0.359882; batch adversarial loss: 0.518115\n",
      "epoch 92; iter: 0; batch classifier loss: 0.459502; batch adversarial loss: 0.538190\n",
      "epoch 93; iter: 0; batch classifier loss: 0.326119; batch adversarial loss: 0.561360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449475; batch adversarial loss: 0.527474\n",
      "epoch 95; iter: 0; batch classifier loss: 0.386819; batch adversarial loss: 0.527788\n",
      "epoch 96; iter: 0; batch classifier loss: 0.437781; batch adversarial loss: 0.483591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.358091; batch adversarial loss: 0.584946\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385472; batch adversarial loss: 0.592209\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412320; batch adversarial loss: 0.527872\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384215; batch adversarial loss: 0.525651\n",
      "epoch 101; iter: 0; batch classifier loss: 0.331541; batch adversarial loss: 0.524063\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340485; batch adversarial loss: 0.542500\n",
      "epoch 103; iter: 0; batch classifier loss: 0.424222; batch adversarial loss: 0.527854\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344919; batch adversarial loss: 0.600850\n",
      "epoch 105; iter: 0; batch classifier loss: 0.311684; batch adversarial loss: 0.525614\n",
      "epoch 106; iter: 0; batch classifier loss: 0.392621; batch adversarial loss: 0.600111\n",
      "epoch 107; iter: 0; batch classifier loss: 0.341472; batch adversarial loss: 0.579176\n",
      "epoch 108; iter: 0; batch classifier loss: 0.437719; batch adversarial loss: 0.472762\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359279; batch adversarial loss: 0.672114\n",
      "epoch 110; iter: 0; batch classifier loss: 0.328822; batch adversarial loss: 0.550380\n",
      "epoch 111; iter: 0; batch classifier loss: 0.410939; batch adversarial loss: 0.547186\n",
      "epoch 112; iter: 0; batch classifier loss: 0.429518; batch adversarial loss: 0.608423\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354819; batch adversarial loss: 0.586530\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392513; batch adversarial loss: 0.560691\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348931; batch adversarial loss: 0.588467\n",
      "epoch 116; iter: 0; batch classifier loss: 0.378110; batch adversarial loss: 0.605204\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411210; batch adversarial loss: 0.535112\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405241; batch adversarial loss: 0.510443\n",
      "epoch 119; iter: 0; batch classifier loss: 0.480700; batch adversarial loss: 0.594331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.435160; batch adversarial loss: 0.579289\n",
      "epoch 121; iter: 0; batch classifier loss: 0.410800; batch adversarial loss: 0.607859\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388472; batch adversarial loss: 0.465422\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376765; batch adversarial loss: 0.620630\n",
      "epoch 124; iter: 0; batch classifier loss: 0.314135; batch adversarial loss: 0.571095\n",
      "epoch 125; iter: 0; batch classifier loss: 0.436463; batch adversarial loss: 0.604445\n",
      "epoch 126; iter: 0; batch classifier loss: 0.325731; batch adversarial loss: 0.520389\n",
      "epoch 127; iter: 0; batch classifier loss: 0.392744; batch adversarial loss: 0.544618\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362359; batch adversarial loss: 0.473951\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367391; batch adversarial loss: 0.540296\n",
      "epoch 130; iter: 0; batch classifier loss: 0.438953; batch adversarial loss: 0.559935\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372746; batch adversarial loss: 0.510674\n",
      "epoch 132; iter: 0; batch classifier loss: 0.361543; batch adversarial loss: 0.556029\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377366; batch adversarial loss: 0.598703\n",
      "epoch 134; iter: 0; batch classifier loss: 0.359958; batch adversarial loss: 0.553967\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365445; batch adversarial loss: 0.575171\n",
      "epoch 136; iter: 0; batch classifier loss: 0.432908; batch adversarial loss: 0.532513\n",
      "epoch 137; iter: 0; batch classifier loss: 0.378942; batch adversarial loss: 0.622811\n",
      "epoch 138; iter: 0; batch classifier loss: 0.534151; batch adversarial loss: 0.553101\n",
      "epoch 139; iter: 0; batch classifier loss: 0.380046; batch adversarial loss: 0.516309\n",
      "epoch 140; iter: 0; batch classifier loss: 0.410457; batch adversarial loss: 0.534710\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366899; batch adversarial loss: 0.471616\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363399; batch adversarial loss: 0.535080\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412333; batch adversarial loss: 0.580754\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338659; batch adversarial loss: 0.606222\n",
      "epoch 145; iter: 0; batch classifier loss: 0.453690; batch adversarial loss: 0.603778\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363089; batch adversarial loss: 0.507174\n",
      "epoch 147; iter: 0; batch classifier loss: 0.392801; batch adversarial loss: 0.545995\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312905; batch adversarial loss: 0.510445\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374410; batch adversarial loss: 0.548378\n",
      "epoch 150; iter: 0; batch classifier loss: 0.438014; batch adversarial loss: 0.491197\n",
      "epoch 151; iter: 0; batch classifier loss: 0.346442; batch adversarial loss: 0.544387\n",
      "epoch 152; iter: 0; batch classifier loss: 0.300709; batch adversarial loss: 0.559706\n",
      "epoch 153; iter: 0; batch classifier loss: 0.416337; batch adversarial loss: 0.507542\n",
      "epoch 154; iter: 0; batch classifier loss: 0.406559; batch adversarial loss: 0.514922\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347634; batch adversarial loss: 0.565706\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325395; batch adversarial loss: 0.456359\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368486; batch adversarial loss: 0.536779\n",
      "epoch 158; iter: 0; batch classifier loss: 0.458508; batch adversarial loss: 0.499190\n",
      "epoch 159; iter: 0; batch classifier loss: 0.412238; batch adversarial loss: 0.507821\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323224; batch adversarial loss: 0.550211\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397920; batch adversarial loss: 0.536004\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412648; batch adversarial loss: 0.560744\n",
      "epoch 163; iter: 0; batch classifier loss: 0.316186; batch adversarial loss: 0.561861\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350103; batch adversarial loss: 0.531967\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342011; batch adversarial loss: 0.609382\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328219; batch adversarial loss: 0.545644\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345044; batch adversarial loss: 0.597886\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375313; batch adversarial loss: 0.536474\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394404; batch adversarial loss: 0.572299\n",
      "epoch 170; iter: 0; batch classifier loss: 0.263932; batch adversarial loss: 0.592886\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390529; batch adversarial loss: 0.546141\n",
      "epoch 172; iter: 0; batch classifier loss: 0.277403; batch adversarial loss: 0.566611\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349685; batch adversarial loss: 0.505072\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372065; batch adversarial loss: 0.590329\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352645; batch adversarial loss: 0.614191\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368810; batch adversarial loss: 0.565232\n",
      "epoch 177; iter: 0; batch classifier loss: 0.382323; batch adversarial loss: 0.513336\n",
      "epoch 178; iter: 0; batch classifier loss: 0.341583; batch adversarial loss: 0.464345\n",
      "epoch 179; iter: 0; batch classifier loss: 0.465768; batch adversarial loss: 0.533485\n",
      "epoch 180; iter: 0; batch classifier loss: 0.345329; batch adversarial loss: 0.572910\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383741; batch adversarial loss: 0.605545\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391324; batch adversarial loss: 0.499078\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356715; batch adversarial loss: 0.593499\n",
      "epoch 184; iter: 0; batch classifier loss: 0.301029; batch adversarial loss: 0.548646\n",
      "epoch 185; iter: 0; batch classifier loss: 0.363238; batch adversarial loss: 0.520795\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377653; batch adversarial loss: 0.544615\n",
      "epoch 187; iter: 0; batch classifier loss: 0.318449; batch adversarial loss: 0.510705\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353682; batch adversarial loss: 0.639830\n",
      "epoch 189; iter: 0; batch classifier loss: 0.289052; batch adversarial loss: 0.614692\n",
      "epoch 190; iter: 0; batch classifier loss: 0.307887; batch adversarial loss: 0.623553\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377822; batch adversarial loss: 0.569600\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327479; batch adversarial loss: 0.518638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.305007; batch adversarial loss: 0.569027\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338539; batch adversarial loss: 0.508407\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309529; batch adversarial loss: 0.556212\n",
      "epoch 196; iter: 0; batch classifier loss: 0.258446; batch adversarial loss: 0.528259\n",
      "epoch 197; iter: 0; batch classifier loss: 0.294006; batch adversarial loss: 0.524572\n",
      "epoch 198; iter: 0; batch classifier loss: 0.480118; batch adversarial loss: 0.581013\n",
      "epoch 199; iter: 0; batch classifier loss: 0.356288; batch adversarial loss: 0.565776\n",
      "epoch 0; iter: 0; batch classifier loss: 0.653632; batch adversarial loss: 0.635385\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628844; batch adversarial loss: 0.662919\n",
      "epoch 2; iter: 0; batch classifier loss: 0.643519; batch adversarial loss: 0.662645\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538725; batch adversarial loss: 0.675124\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538068; batch adversarial loss: 0.650072\n",
      "epoch 5; iter: 0; batch classifier loss: 0.640747; batch adversarial loss: 0.565892\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533742; batch adversarial loss: 0.664194\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566689; batch adversarial loss: 0.614596\n",
      "epoch 8; iter: 0; batch classifier loss: 0.584505; batch adversarial loss: 0.582591\n",
      "epoch 9; iter: 0; batch classifier loss: 0.597355; batch adversarial loss: 0.663118\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536752; batch adversarial loss: 0.567031\n",
      "epoch 11; iter: 0; batch classifier loss: 0.596579; batch adversarial loss: 0.615279\n",
      "epoch 12; iter: 0; batch classifier loss: 0.472520; batch adversarial loss: 0.564631\n",
      "epoch 13; iter: 0; batch classifier loss: 0.561960; batch adversarial loss: 0.579870\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542997; batch adversarial loss: 0.538775\n",
      "epoch 15; iter: 0; batch classifier loss: 0.458115; batch adversarial loss: 0.569841\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491307; batch adversarial loss: 0.581389\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462549; batch adversarial loss: 0.585623\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491788; batch adversarial loss: 0.551328\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465453; batch adversarial loss: 0.624991\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448175; batch adversarial loss: 0.524855\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523445; batch adversarial loss: 0.677162\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521815; batch adversarial loss: 0.520382\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490097; batch adversarial loss: 0.526108\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477018; batch adversarial loss: 0.516609\n",
      "epoch 25; iter: 0; batch classifier loss: 0.540923; batch adversarial loss: 0.578677\n",
      "epoch 26; iter: 0; batch classifier loss: 0.436672; batch adversarial loss: 0.553194\n",
      "epoch 27; iter: 0; batch classifier loss: 0.521024; batch adversarial loss: 0.563120\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487467; batch adversarial loss: 0.440867\n",
      "epoch 29; iter: 0; batch classifier loss: 0.478141; batch adversarial loss: 0.513483\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496110; batch adversarial loss: 0.571164\n",
      "epoch 31; iter: 0; batch classifier loss: 0.525858; batch adversarial loss: 0.563894\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488532; batch adversarial loss: 0.614508\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461705; batch adversarial loss: 0.510979\n",
      "epoch 34; iter: 0; batch classifier loss: 0.521364; batch adversarial loss: 0.562235\n",
      "epoch 35; iter: 0; batch classifier loss: 0.512393; batch adversarial loss: 0.508644\n",
      "epoch 36; iter: 0; batch classifier loss: 0.547311; batch adversarial loss: 0.642616\n",
      "epoch 37; iter: 0; batch classifier loss: 0.377708; batch adversarial loss: 0.536414\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389958; batch adversarial loss: 0.545680\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429624; batch adversarial loss: 0.589504\n",
      "epoch 40; iter: 0; batch classifier loss: 0.483402; batch adversarial loss: 0.526773\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486355; batch adversarial loss: 0.579720\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474214; batch adversarial loss: 0.589520\n",
      "epoch 43; iter: 0; batch classifier loss: 0.466907; batch adversarial loss: 0.534990\n",
      "epoch 44; iter: 0; batch classifier loss: 0.376086; batch adversarial loss: 0.600277\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451817; batch adversarial loss: 0.562565\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480458; batch adversarial loss: 0.562174\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449274; batch adversarial loss: 0.580793\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435585; batch adversarial loss: 0.470657\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427200; batch adversarial loss: 0.571897\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472039; batch adversarial loss: 0.537023\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435569; batch adversarial loss: 0.590251\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416770; batch adversarial loss: 0.516131\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439957; batch adversarial loss: 0.616463\n",
      "epoch 54; iter: 0; batch classifier loss: 0.498060; batch adversarial loss: 0.469294\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436574; batch adversarial loss: 0.591635\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420577; batch adversarial loss: 0.526158\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391957; batch adversarial loss: 0.599928\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431653; batch adversarial loss: 0.481586\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409178; batch adversarial loss: 0.491336\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379716; batch adversarial loss: 0.589456\n",
      "epoch 61; iter: 0; batch classifier loss: 0.472576; batch adversarial loss: 0.627141\n",
      "epoch 62; iter: 0; batch classifier loss: 0.480262; batch adversarial loss: 0.563039\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459761; batch adversarial loss: 0.508137\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407140; batch adversarial loss: 0.542973\n",
      "epoch 65; iter: 0; batch classifier loss: 0.460474; batch adversarial loss: 0.535312\n",
      "epoch 66; iter: 0; batch classifier loss: 0.301299; batch adversarial loss: 0.553994\n",
      "epoch 67; iter: 0; batch classifier loss: 0.459345; batch adversarial loss: 0.534868\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391324; batch adversarial loss: 0.590850\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430209; batch adversarial loss: 0.625253\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424884; batch adversarial loss: 0.573214\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398848; batch adversarial loss: 0.525464\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430563; batch adversarial loss: 0.553738\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424369; batch adversarial loss: 0.590095\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457206; batch adversarial loss: 0.626690\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440768; batch adversarial loss: 0.553450\n",
      "epoch 76; iter: 0; batch classifier loss: 0.417380; batch adversarial loss: 0.526256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416173; batch adversarial loss: 0.553940\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406450; batch adversarial loss: 0.607757\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395821; batch adversarial loss: 0.526828\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435197; batch adversarial loss: 0.508726\n",
      "epoch 81; iter: 0; batch classifier loss: 0.337610; batch adversarial loss: 0.544175\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368478; batch adversarial loss: 0.490665\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416696; batch adversarial loss: 0.481516\n",
      "epoch 84; iter: 0; batch classifier loss: 0.452802; batch adversarial loss: 0.526618\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367101; batch adversarial loss: 0.571546\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433895; batch adversarial loss: 0.571534\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405432; batch adversarial loss: 0.544492\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402297; batch adversarial loss: 0.499411\n",
      "epoch 89; iter: 0; batch classifier loss: 0.328255; batch adversarial loss: 0.489556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.372296; batch adversarial loss: 0.544657\n",
      "epoch 91; iter: 0; batch classifier loss: 0.514530; batch adversarial loss: 0.553962\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393680; batch adversarial loss: 0.452783\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380272; batch adversarial loss: 0.461301\n",
      "epoch 94; iter: 0; batch classifier loss: 0.447003; batch adversarial loss: 0.534880\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424471; batch adversarial loss: 0.536694\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414604; batch adversarial loss: 0.598335\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346329; batch adversarial loss: 0.533944\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370853; batch adversarial loss: 0.596242\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350956; batch adversarial loss: 0.469335\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365353; batch adversarial loss: 0.543996\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394644; batch adversarial loss: 0.560480\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362717; batch adversarial loss: 0.570623\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396400; batch adversarial loss: 0.544517\n",
      "epoch 104; iter: 0; batch classifier loss: 0.381624; batch adversarial loss: 0.526414\n",
      "epoch 105; iter: 0; batch classifier loss: 0.520602; batch adversarial loss: 0.545349\n",
      "epoch 106; iter: 0; batch classifier loss: 0.453766; batch adversarial loss: 0.500303\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387277; batch adversarial loss: 0.544980\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406920; batch adversarial loss: 0.553646\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402841; batch adversarial loss: 0.482070\n",
      "epoch 110; iter: 0; batch classifier loss: 0.347467; batch adversarial loss: 0.544608\n",
      "epoch 111; iter: 0; batch classifier loss: 0.438146; batch adversarial loss: 0.508880\n",
      "epoch 112; iter: 0; batch classifier loss: 0.454642; batch adversarial loss: 0.508393\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386657; batch adversarial loss: 0.508462\n",
      "epoch 114; iter: 0; batch classifier loss: 0.456635; batch adversarial loss: 0.562641\n",
      "epoch 115; iter: 0; batch classifier loss: 0.463182; batch adversarial loss: 0.526414\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377099; batch adversarial loss: 0.534610\n",
      "epoch 117; iter: 0; batch classifier loss: 0.481666; batch adversarial loss: 0.572141\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373796; batch adversarial loss: 0.552824\n",
      "epoch 119; iter: 0; batch classifier loss: 0.316433; batch adversarial loss: 0.544853\n",
      "epoch 120; iter: 0; batch classifier loss: 0.392941; batch adversarial loss: 0.490339\n",
      "epoch 121; iter: 0; batch classifier loss: 0.451965; batch adversarial loss: 0.535560\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335669; batch adversarial loss: 0.544577\n",
      "epoch 123; iter: 0; batch classifier loss: 0.284480; batch adversarial loss: 0.535693\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369287; batch adversarial loss: 0.535180\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380833; batch adversarial loss: 0.526710\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380563; batch adversarial loss: 0.653090\n",
      "epoch 127; iter: 0; batch classifier loss: 0.438917; batch adversarial loss: 0.608778\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355422; batch adversarial loss: 0.553671\n",
      "epoch 129; iter: 0; batch classifier loss: 0.418467; batch adversarial loss: 0.535200\n",
      "epoch 130; iter: 0; batch classifier loss: 0.407314; batch adversarial loss: 0.507608\n",
      "epoch 131; iter: 0; batch classifier loss: 0.435562; batch adversarial loss: 0.589817\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359992; batch adversarial loss: 0.608593\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377462; batch adversarial loss: 0.607767\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343320; batch adversarial loss: 0.562780\n",
      "epoch 135; iter: 0; batch classifier loss: 0.326536; batch adversarial loss: 0.580851\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328768; batch adversarial loss: 0.499136\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357782; batch adversarial loss: 0.508323\n",
      "epoch 138; iter: 0; batch classifier loss: 0.458135; batch adversarial loss: 0.581068\n",
      "epoch 139; iter: 0; batch classifier loss: 0.339871; batch adversarial loss: 0.490464\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348301; batch adversarial loss: 0.608048\n",
      "epoch 141; iter: 0; batch classifier loss: 0.426891; batch adversarial loss: 0.489998\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395104; batch adversarial loss: 0.580868\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369429; batch adversarial loss: 0.571638\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349593; batch adversarial loss: 0.607441\n",
      "epoch 145; iter: 0; batch classifier loss: 0.413509; batch adversarial loss: 0.563107\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346308; batch adversarial loss: 0.598889\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354880; batch adversarial loss: 0.562625\n",
      "epoch 148; iter: 0; batch classifier loss: 0.445119; batch adversarial loss: 0.553740\n",
      "epoch 149; iter: 0; batch classifier loss: 0.414992; batch adversarial loss: 0.544137\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353835; batch adversarial loss: 0.535306\n",
      "epoch 151; iter: 0; batch classifier loss: 0.433853; batch adversarial loss: 0.589304\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374099; batch adversarial loss: 0.552567\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328320; batch adversarial loss: 0.619384\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337238; batch adversarial loss: 0.535857\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406812; batch adversarial loss: 0.508659\n",
      "epoch 156; iter: 0; batch classifier loss: 0.410017; batch adversarial loss: 0.500002\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375238; batch adversarial loss: 0.526670\n",
      "epoch 158; iter: 0; batch classifier loss: 0.391374; batch adversarial loss: 0.544706\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394991; batch adversarial loss: 0.544541\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332839; batch adversarial loss: 0.616140\n",
      "epoch 161; iter: 0; batch classifier loss: 0.352731; batch adversarial loss: 0.517670\n",
      "epoch 162; iter: 0; batch classifier loss: 0.422544; batch adversarial loss: 0.517795\n",
      "epoch 163; iter: 0; batch classifier loss: 0.299427; batch adversarial loss: 0.517404\n",
      "epoch 164; iter: 0; batch classifier loss: 0.417031; batch adversarial loss: 0.535182\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348937; batch adversarial loss: 0.507954\n",
      "epoch 166; iter: 0; batch classifier loss: 0.345284; batch adversarial loss: 0.498708\n",
      "epoch 167; iter: 0; batch classifier loss: 0.428607; batch adversarial loss: 0.608337\n",
      "epoch 168; iter: 0; batch classifier loss: 0.279496; batch adversarial loss: 0.526387\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355465; batch adversarial loss: 0.526415\n",
      "epoch 170; iter: 0; batch classifier loss: 0.402004; batch adversarial loss: 0.581049\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370205; batch adversarial loss: 0.563825\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317131; batch adversarial loss: 0.526113\n",
      "epoch 173; iter: 0; batch classifier loss: 0.461215; batch adversarial loss: 0.554114\n",
      "epoch 174; iter: 0; batch classifier loss: 0.332603; batch adversarial loss: 0.461158\n",
      "epoch 175; iter: 0; batch classifier loss: 0.439363; batch adversarial loss: 0.562919\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360803; batch adversarial loss: 0.508636\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374298; batch adversarial loss: 0.536138\n",
      "epoch 178; iter: 0; batch classifier loss: 0.289958; batch adversarial loss: 0.535728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337802; batch adversarial loss: 0.544683\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352115; batch adversarial loss: 0.508588\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373306; batch adversarial loss: 0.580862\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337033; batch adversarial loss: 0.499569\n",
      "epoch 183; iter: 0; batch classifier loss: 0.267009; batch adversarial loss: 0.544567\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336027; batch adversarial loss: 0.526157\n",
      "epoch 185; iter: 0; batch classifier loss: 0.405685; batch adversarial loss: 0.571192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.404734; batch adversarial loss: 0.517928\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342385; batch adversarial loss: 0.553763\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374089; batch adversarial loss: 0.545005\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404799; batch adversarial loss: 0.571981\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346126; batch adversarial loss: 0.562628\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344478; batch adversarial loss: 0.617409\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313466; batch adversarial loss: 0.563289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364737; batch adversarial loss: 0.535308\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343386; batch adversarial loss: 0.563470\n",
      "epoch 195; iter: 0; batch classifier loss: 0.368483; batch adversarial loss: 0.526595\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327660; batch adversarial loss: 0.480740\n",
      "epoch 197; iter: 0; batch classifier loss: 0.403473; batch adversarial loss: 0.590088\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334925; batch adversarial loss: 0.553689\n",
      "epoch 199; iter: 0; batch classifier loss: 0.303362; batch adversarial loss: 0.571800\n",
      "epoch 0; iter: 0; batch classifier loss: 0.795888; batch adversarial loss: 0.565147\n",
      "epoch 1; iter: 0; batch classifier loss: 0.570843; batch adversarial loss: 0.644282\n",
      "epoch 2; iter: 0; batch classifier loss: 0.566607; batch adversarial loss: 0.650441\n",
      "epoch 3; iter: 0; batch classifier loss: 0.645136; batch adversarial loss: 0.673261\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580910; batch adversarial loss: 0.661584\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559494; batch adversarial loss: 0.532343\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562415; batch adversarial loss: 0.613527\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533078; batch adversarial loss: 0.595483\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546270; batch adversarial loss: 0.639371\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506238; batch adversarial loss: 0.625680\n",
      "epoch 10; iter: 0; batch classifier loss: 0.597471; batch adversarial loss: 0.588857\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593389; batch adversarial loss: 0.616232\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578681; batch adversarial loss: 0.581989\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539066; batch adversarial loss: 0.559341\n",
      "epoch 14; iter: 0; batch classifier loss: 0.453936; batch adversarial loss: 0.549228\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506798; batch adversarial loss: 0.529460\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514862; batch adversarial loss: 0.574667\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514192; batch adversarial loss: 0.604678\n",
      "epoch 18; iter: 0; batch classifier loss: 0.420730; batch adversarial loss: 0.554866\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485693; batch adversarial loss: 0.521048\n",
      "epoch 20; iter: 0; batch classifier loss: 0.415437; batch adversarial loss: 0.547340\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485018; batch adversarial loss: 0.532524\n",
      "epoch 22; iter: 0; batch classifier loss: 0.571320; batch adversarial loss: 0.559347\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531659; batch adversarial loss: 0.573320\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527268; batch adversarial loss: 0.567754\n",
      "epoch 25; iter: 0; batch classifier loss: 0.464273; batch adversarial loss: 0.545517\n",
      "epoch 26; iter: 0; batch classifier loss: 0.429016; batch adversarial loss: 0.562487\n",
      "epoch 27; iter: 0; batch classifier loss: 0.522292; batch adversarial loss: 0.461169\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498021; batch adversarial loss: 0.588115\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496529; batch adversarial loss: 0.552435\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422213; batch adversarial loss: 0.544922\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486299; batch adversarial loss: 0.573476\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433849; batch adversarial loss: 0.567950\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443823; batch adversarial loss: 0.508168\n",
      "epoch 34; iter: 0; batch classifier loss: 0.486084; batch adversarial loss: 0.506499\n",
      "epoch 35; iter: 0; batch classifier loss: 0.384282; batch adversarial loss: 0.561775\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468772; batch adversarial loss: 0.570179\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487679; batch adversarial loss: 0.488877\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474751; batch adversarial loss: 0.493075\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458646; batch adversarial loss: 0.522498\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497516; batch adversarial loss: 0.538205\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489049; batch adversarial loss: 0.601498\n",
      "epoch 42; iter: 0; batch classifier loss: 0.539689; batch adversarial loss: 0.533468\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537641; batch adversarial loss: 0.509915\n",
      "epoch 44; iter: 0; batch classifier loss: 0.449850; batch adversarial loss: 0.516324\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438262; batch adversarial loss: 0.571488\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430775; batch adversarial loss: 0.589030\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476177; batch adversarial loss: 0.535112\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448962; batch adversarial loss: 0.514322\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405976; batch adversarial loss: 0.533285\n",
      "epoch 50; iter: 0; batch classifier loss: 0.377659; batch adversarial loss: 0.500833\n",
      "epoch 51; iter: 0; batch classifier loss: 0.371603; batch adversarial loss: 0.570212\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476055; batch adversarial loss: 0.418888\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383243; batch adversarial loss: 0.590286\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438036; batch adversarial loss: 0.472838\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476448; batch adversarial loss: 0.526955\n",
      "epoch 56; iter: 0; batch classifier loss: 0.478727; batch adversarial loss: 0.544363\n",
      "epoch 57; iter: 0; batch classifier loss: 0.436030; batch adversarial loss: 0.606521\n",
      "epoch 58; iter: 0; batch classifier loss: 0.372954; batch adversarial loss: 0.526049\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423390; batch adversarial loss: 0.544046\n",
      "epoch 60; iter: 0; batch classifier loss: 0.498780; batch adversarial loss: 0.606378\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410000; batch adversarial loss: 0.525504\n",
      "epoch 62; iter: 0; batch classifier loss: 0.337429; batch adversarial loss: 0.579862\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411599; batch adversarial loss: 0.590962\n",
      "epoch 64; iter: 0; batch classifier loss: 0.501940; batch adversarial loss: 0.472185\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441432; batch adversarial loss: 0.663169\n",
      "epoch 66; iter: 0; batch classifier loss: 0.424371; batch adversarial loss: 0.562298\n",
      "epoch 67; iter: 0; batch classifier loss: 0.449711; batch adversarial loss: 0.470393\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391121; batch adversarial loss: 0.546133\n",
      "epoch 69; iter: 0; batch classifier loss: 0.472189; batch adversarial loss: 0.490558\n",
      "epoch 70; iter: 0; batch classifier loss: 0.452689; batch adversarial loss: 0.508643\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471043; batch adversarial loss: 0.543777\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418374; batch adversarial loss: 0.572275\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383613; batch adversarial loss: 0.506980\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387680; batch adversarial loss: 0.572830\n",
      "epoch 75; iter: 0; batch classifier loss: 0.485783; batch adversarial loss: 0.553990\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370127; batch adversarial loss: 0.553651\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387533; batch adversarial loss: 0.490669\n",
      "epoch 78; iter: 0; batch classifier loss: 0.356876; batch adversarial loss: 0.507019\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404777; batch adversarial loss: 0.562141\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356241; batch adversarial loss: 0.597328\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403333; batch adversarial loss: 0.536573\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396586; batch adversarial loss: 0.590846\n",
      "epoch 83; iter: 0; batch classifier loss: 0.456488; batch adversarial loss: 0.507967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.528167; batch adversarial loss: 0.552949\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346932; batch adversarial loss: 0.553076\n",
      "epoch 86; iter: 0; batch classifier loss: 0.393796; batch adversarial loss: 0.543831\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433416; batch adversarial loss: 0.581205\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363917; batch adversarial loss: 0.515536\n",
      "epoch 89; iter: 0; batch classifier loss: 0.448134; batch adversarial loss: 0.543016\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348291; batch adversarial loss: 0.507726\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397085; batch adversarial loss: 0.565434\n",
      "epoch 92; iter: 0; batch classifier loss: 0.325238; batch adversarial loss: 0.580884\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393227; batch adversarial loss: 0.506797\n",
      "epoch 94; iter: 0; batch classifier loss: 0.379479; batch adversarial loss: 0.562220\n",
      "epoch 95; iter: 0; batch classifier loss: 0.321804; batch adversarial loss: 0.499150\n",
      "epoch 96; iter: 0; batch classifier loss: 0.480441; batch adversarial loss: 0.563686\n",
      "epoch 97; iter: 0; batch classifier loss: 0.480955; batch adversarial loss: 0.561895\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404770; batch adversarial loss: 0.543291\n",
      "epoch 99; iter: 0; batch classifier loss: 0.346715; batch adversarial loss: 0.617521\n",
      "epoch 100; iter: 0; batch classifier loss: 0.485102; batch adversarial loss: 0.608263\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347308; batch adversarial loss: 0.543134\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330686; batch adversarial loss: 0.617074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356095; batch adversarial loss: 0.525721\n",
      "epoch 104; iter: 0; batch classifier loss: 0.478757; batch adversarial loss: 0.488250\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343632; batch adversarial loss: 0.526388\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362412; batch adversarial loss: 0.489234\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402595; batch adversarial loss: 0.682385\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435357; batch adversarial loss: 0.543469\n",
      "epoch 109; iter: 0; batch classifier loss: 0.329737; batch adversarial loss: 0.543274\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362868; batch adversarial loss: 0.598710\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401937; batch adversarial loss: 0.515433\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412441; batch adversarial loss: 0.507838\n",
      "epoch 113; iter: 0; batch classifier loss: 0.431175; batch adversarial loss: 0.526375\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384085; batch adversarial loss: 0.535222\n",
      "epoch 115; iter: 0; batch classifier loss: 0.445659; batch adversarial loss: 0.617046\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323877; batch adversarial loss: 0.509077\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351301; batch adversarial loss: 0.545094\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375148; batch adversarial loss: 0.498415\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367335; batch adversarial loss: 0.606893\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378217; batch adversarial loss: 0.538833\n",
      "epoch 121; iter: 0; batch classifier loss: 0.331256; batch adversarial loss: 0.516128\n",
      "epoch 122; iter: 0; batch classifier loss: 0.344297; batch adversarial loss: 0.444895\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389905; batch adversarial loss: 0.554655\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369040; batch adversarial loss: 0.526071\n",
      "epoch 125; iter: 0; batch classifier loss: 0.504796; batch adversarial loss: 0.525538\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360735; batch adversarial loss: 0.608007\n",
      "epoch 127; iter: 0; batch classifier loss: 0.326214; batch adversarial loss: 0.499877\n",
      "epoch 128; iter: 0; batch classifier loss: 0.420218; batch adversarial loss: 0.545619\n",
      "epoch 129; iter: 0; batch classifier loss: 0.459705; batch adversarial loss: 0.591118\n",
      "epoch 130; iter: 0; batch classifier loss: 0.310612; batch adversarial loss: 0.589836\n",
      "epoch 131; iter: 0; batch classifier loss: 0.298893; batch adversarial loss: 0.544219\n",
      "epoch 132; iter: 0; batch classifier loss: 0.295405; batch adversarial loss: 0.545385\n",
      "epoch 133; iter: 0; batch classifier loss: 0.303011; batch adversarial loss: 0.526568\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358319; batch adversarial loss: 0.480103\n",
      "epoch 135; iter: 0; batch classifier loss: 0.418754; batch adversarial loss: 0.563214\n",
      "epoch 136; iter: 0; batch classifier loss: 0.388427; batch adversarial loss: 0.590341\n",
      "epoch 137; iter: 0; batch classifier loss: 0.449654; batch adversarial loss: 0.505683\n",
      "epoch 138; iter: 0; batch classifier loss: 0.303268; batch adversarial loss: 0.600528\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356798; batch adversarial loss: 0.526396\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327301; batch adversarial loss: 0.508302\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332290; batch adversarial loss: 0.525765\n",
      "epoch 142; iter: 0; batch classifier loss: 0.308295; batch adversarial loss: 0.516951\n",
      "epoch 143; iter: 0; batch classifier loss: 0.393956; batch adversarial loss: 0.527211\n",
      "epoch 144; iter: 0; batch classifier loss: 0.427068; batch adversarial loss: 0.534588\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405369; batch adversarial loss: 0.515952\n",
      "epoch 146; iter: 0; batch classifier loss: 0.429169; batch adversarial loss: 0.524448\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384323; batch adversarial loss: 0.490971\n",
      "epoch 148; iter: 0; batch classifier loss: 0.400282; batch adversarial loss: 0.571868\n",
      "epoch 149; iter: 0; batch classifier loss: 0.389116; batch adversarial loss: 0.525395\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382143; batch adversarial loss: 0.508063\n",
      "epoch 151; iter: 0; batch classifier loss: 0.446698; batch adversarial loss: 0.543956\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346001; batch adversarial loss: 0.542274\n",
      "epoch 153; iter: 0; batch classifier loss: 0.319468; batch adversarial loss: 0.488620\n",
      "epoch 154; iter: 0; batch classifier loss: 0.449367; batch adversarial loss: 0.546478\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354814; batch adversarial loss: 0.526217\n",
      "epoch 156; iter: 0; batch classifier loss: 0.360249; batch adversarial loss: 0.525118\n",
      "epoch 157; iter: 0; batch classifier loss: 0.358804; batch adversarial loss: 0.497974\n",
      "epoch 158; iter: 0; batch classifier loss: 0.493225; batch adversarial loss: 0.533595\n",
      "epoch 159; iter: 0; batch classifier loss: 0.365655; batch adversarial loss: 0.524952\n",
      "epoch 160; iter: 0; batch classifier loss: 0.326324; batch adversarial loss: 0.497377\n",
      "epoch 161; iter: 0; batch classifier loss: 0.390075; batch adversarial loss: 0.506943\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383309; batch adversarial loss: 0.561309\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397036; batch adversarial loss: 0.536921\n",
      "epoch 164; iter: 0; batch classifier loss: 0.456023; batch adversarial loss: 0.544247\n",
      "epoch 165; iter: 0; batch classifier loss: 0.428472; batch adversarial loss: 0.580409\n",
      "epoch 166; iter: 0; batch classifier loss: 0.326513; batch adversarial loss: 0.506048\n",
      "epoch 167; iter: 0; batch classifier loss: 0.423346; batch adversarial loss: 0.635098\n",
      "epoch 168; iter: 0; batch classifier loss: 0.231680; batch adversarial loss: 0.600078\n",
      "epoch 169; iter: 0; batch classifier loss: 0.396027; batch adversarial loss: 0.515928\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337681; batch adversarial loss: 0.508742\n",
      "epoch 171; iter: 0; batch classifier loss: 0.345464; batch adversarial loss: 0.496648\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388650; batch adversarial loss: 0.489169\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387517; batch adversarial loss: 0.572132\n",
      "epoch 174; iter: 0; batch classifier loss: 0.297638; batch adversarial loss: 0.626271\n",
      "epoch 175; iter: 0; batch classifier loss: 0.393089; batch adversarial loss: 0.507990\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408040; batch adversarial loss: 0.565002\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358989; batch adversarial loss: 0.544052\n",
      "epoch 178; iter: 0; batch classifier loss: 0.294552; batch adversarial loss: 0.462154\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318953; batch adversarial loss: 0.579542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.447317; batch adversarial loss: 0.526583\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323509; batch adversarial loss: 0.562806\n",
      "epoch 182; iter: 0; batch classifier loss: 0.288033; batch adversarial loss: 0.490686\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367968; batch adversarial loss: 0.543288\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319073; batch adversarial loss: 0.543372\n",
      "epoch 185; iter: 0; batch classifier loss: 0.456221; batch adversarial loss: 0.508336\n",
      "epoch 186; iter: 0; batch classifier loss: 0.325518; batch adversarial loss: 0.490874\n",
      "epoch 187; iter: 0; batch classifier loss: 0.400934; batch adversarial loss: 0.637448\n",
      "epoch 188; iter: 0; batch classifier loss: 0.425351; batch adversarial loss: 0.507060\n",
      "epoch 189; iter: 0; batch classifier loss: 0.366267; batch adversarial loss: 0.609093\n",
      "epoch 190; iter: 0; batch classifier loss: 0.363969; batch adversarial loss: 0.591294\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377376; batch adversarial loss: 0.480379\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357070; batch adversarial loss: 0.582402\n",
      "epoch 193; iter: 0; batch classifier loss: 0.407173; batch adversarial loss: 0.571659\n",
      "epoch 194; iter: 0; batch classifier loss: 0.361335; batch adversarial loss: 0.618511\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317927; batch adversarial loss: 0.562866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.302469; batch adversarial loss: 0.552694\n",
      "epoch 197; iter: 0; batch classifier loss: 0.306294; batch adversarial loss: 0.618443\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403107; batch adversarial loss: 0.534769\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318901; batch adversarial loss: 0.573533\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720129; batch adversarial loss: 0.610401\n",
      "epoch 1; iter: 0; batch classifier loss: 0.553700; batch adversarial loss: 0.641132\n",
      "epoch 2; iter: 0; batch classifier loss: 0.530992; batch adversarial loss: 0.636110\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602229; batch adversarial loss: 0.644593\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543509; batch adversarial loss: 0.635864\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555483; batch adversarial loss: 0.625203\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513200; batch adversarial loss: 0.621844\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567748; batch adversarial loss: 0.602930\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577139; batch adversarial loss: 0.589148\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528770; batch adversarial loss: 0.597198\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501246; batch adversarial loss: 0.573668\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540403; batch adversarial loss: 0.561734\n",
      "epoch 12; iter: 0; batch classifier loss: 0.477825; batch adversarial loss: 0.526352\n",
      "epoch 13; iter: 0; batch classifier loss: 0.609253; batch adversarial loss: 0.556703\n",
      "epoch 14; iter: 0; batch classifier loss: 0.575030; batch adversarial loss: 0.524462\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501797; batch adversarial loss: 0.560765\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537374; batch adversarial loss: 0.596102\n",
      "epoch 17; iter: 0; batch classifier loss: 0.596677; batch adversarial loss: 0.563946\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444369; batch adversarial loss: 0.565403\n",
      "epoch 19; iter: 0; batch classifier loss: 0.479805; batch adversarial loss: 0.626018\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485369; batch adversarial loss: 0.523195\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484890; batch adversarial loss: 0.509200\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463167; batch adversarial loss: 0.549086\n",
      "epoch 23; iter: 0; batch classifier loss: 0.435002; batch adversarial loss: 0.534337\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460594; batch adversarial loss: 0.565388\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417500; batch adversarial loss: 0.598497\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485397; batch adversarial loss: 0.566531\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467079; batch adversarial loss: 0.603201\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472485; batch adversarial loss: 0.521055\n",
      "epoch 29; iter: 0; batch classifier loss: 0.404788; batch adversarial loss: 0.579477\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462726; batch adversarial loss: 0.574436\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500797; batch adversarial loss: 0.586708\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510825; batch adversarial loss: 0.492546\n",
      "epoch 33; iter: 0; batch classifier loss: 0.505861; batch adversarial loss: 0.617122\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443224; batch adversarial loss: 0.551758\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433627; batch adversarial loss: 0.591745\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470936; batch adversarial loss: 0.637317\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479034; batch adversarial loss: 0.562902\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512077; batch adversarial loss: 0.543607\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497369; batch adversarial loss: 0.516700\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461057; batch adversarial loss: 0.572420\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415271; batch adversarial loss: 0.499688\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448259; batch adversarial loss: 0.516116\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422543; batch adversarial loss: 0.516299\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492445; batch adversarial loss: 0.564620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454432; batch adversarial loss: 0.545526\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480654; batch adversarial loss: 0.617324\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468373; batch adversarial loss: 0.571546\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509800; batch adversarial loss: 0.588628\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464184; batch adversarial loss: 0.569095\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434179; batch adversarial loss: 0.497091\n",
      "epoch 51; iter: 0; batch classifier loss: 0.474336; batch adversarial loss: 0.515436\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408704; batch adversarial loss: 0.526345\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396427; batch adversarial loss: 0.553381\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397941; batch adversarial loss: 0.592376\n",
      "epoch 55; iter: 0; batch classifier loss: 0.515383; batch adversarial loss: 0.564521\n",
      "epoch 56; iter: 0; batch classifier loss: 0.459390; batch adversarial loss: 0.564069\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421744; batch adversarial loss: 0.592551\n",
      "epoch 58; iter: 0; batch classifier loss: 0.349693; batch adversarial loss: 0.496710\n",
      "epoch 59; iter: 0; batch classifier loss: 0.380558; batch adversarial loss: 0.467076\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452508; batch adversarial loss: 0.542298\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430031; batch adversarial loss: 0.506238\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434305; batch adversarial loss: 0.601143\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391034; batch adversarial loss: 0.479041\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418705; batch adversarial loss: 0.544481\n",
      "epoch 65; iter: 0; batch classifier loss: 0.505554; batch adversarial loss: 0.545697\n",
      "epoch 66; iter: 0; batch classifier loss: 0.517571; batch adversarial loss: 0.487725\n",
      "epoch 67; iter: 0; batch classifier loss: 0.481440; batch adversarial loss: 0.460131\n",
      "epoch 68; iter: 0; batch classifier loss: 0.441175; batch adversarial loss: 0.525807\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389043; batch adversarial loss: 0.544616\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464602; batch adversarial loss: 0.639078\n",
      "epoch 71; iter: 0; batch classifier loss: 0.509810; batch adversarial loss: 0.516309\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393247; batch adversarial loss: 0.469911\n",
      "epoch 73; iter: 0; batch classifier loss: 0.406971; batch adversarial loss: 0.545276\n",
      "epoch 74; iter: 0; batch classifier loss: 0.476445; batch adversarial loss: 0.600208\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429574; batch adversarial loss: 0.543714\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405347; batch adversarial loss: 0.563708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.402873; batch adversarial loss: 0.535489\n",
      "epoch 78; iter: 0; batch classifier loss: 0.460805; batch adversarial loss: 0.506922\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433584; batch adversarial loss: 0.524594\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414912; batch adversarial loss: 0.488436\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371056; batch adversarial loss: 0.497434\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359923; batch adversarial loss: 0.581635\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404728; batch adversarial loss: 0.525076\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415802; batch adversarial loss: 0.516919\n",
      "epoch 85; iter: 0; batch classifier loss: 0.449007; batch adversarial loss: 0.561950\n",
      "epoch 86; iter: 0; batch classifier loss: 0.442839; batch adversarial loss: 0.488271\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374164; batch adversarial loss: 0.459526\n",
      "epoch 88; iter: 0; batch classifier loss: 0.452959; batch adversarial loss: 0.497430\n",
      "epoch 89; iter: 0; batch classifier loss: 0.320614; batch adversarial loss: 0.553316\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350002; batch adversarial loss: 0.563419\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402333; batch adversarial loss: 0.554599\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374635; batch adversarial loss: 0.562582\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368110; batch adversarial loss: 0.535277\n",
      "epoch 94; iter: 0; batch classifier loss: 0.437898; batch adversarial loss: 0.506622\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417211; batch adversarial loss: 0.543940\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401481; batch adversarial loss: 0.536466\n",
      "epoch 97; iter: 0; batch classifier loss: 0.456019; batch adversarial loss: 0.639777\n",
      "epoch 98; iter: 0; batch classifier loss: 0.446866; batch adversarial loss: 0.611347\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368300; batch adversarial loss: 0.516363\n",
      "epoch 100; iter: 0; batch classifier loss: 0.329200; batch adversarial loss: 0.535867\n",
      "epoch 101; iter: 0; batch classifier loss: 0.369450; batch adversarial loss: 0.506946\n",
      "epoch 102; iter: 0; batch classifier loss: 0.287638; batch adversarial loss: 0.488271\n",
      "epoch 103; iter: 0; batch classifier loss: 0.501019; batch adversarial loss: 0.572309\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364387; batch adversarial loss: 0.506943\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361105; batch adversarial loss: 0.554221\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343473; batch adversarial loss: 0.601731\n",
      "epoch 107; iter: 0; batch classifier loss: 0.430216; batch adversarial loss: 0.516344\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379974; batch adversarial loss: 0.629453\n",
      "epoch 109; iter: 0; batch classifier loss: 0.428198; batch adversarial loss: 0.563537\n",
      "epoch 110; iter: 0; batch classifier loss: 0.338490; batch adversarial loss: 0.496510\n",
      "epoch 111; iter: 0; batch classifier loss: 0.315291; batch adversarial loss: 0.467429\n",
      "epoch 112; iter: 0; batch classifier loss: 0.423537; batch adversarial loss: 0.563242\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355010; batch adversarial loss: 0.525885\n",
      "epoch 114; iter: 0; batch classifier loss: 0.462627; batch adversarial loss: 0.496273\n",
      "epoch 115; iter: 0; batch classifier loss: 0.406799; batch adversarial loss: 0.507999\n",
      "epoch 116; iter: 0; batch classifier loss: 0.367470; batch adversarial loss: 0.479271\n",
      "epoch 117; iter: 0; batch classifier loss: 0.413656; batch adversarial loss: 0.497876\n",
      "epoch 118; iter: 0; batch classifier loss: 0.422674; batch adversarial loss: 0.507008\n",
      "epoch 119; iter: 0; batch classifier loss: 0.313389; batch adversarial loss: 0.600270\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366649; batch adversarial loss: 0.516866\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364312; batch adversarial loss: 0.497218\n",
      "epoch 122; iter: 0; batch classifier loss: 0.466134; batch adversarial loss: 0.526630\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395614; batch adversarial loss: 0.544796\n",
      "epoch 124; iter: 0; batch classifier loss: 0.450085; batch adversarial loss: 0.589958\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361362; batch adversarial loss: 0.535980\n",
      "epoch 126; iter: 0; batch classifier loss: 0.335054; batch adversarial loss: 0.572998\n",
      "epoch 127; iter: 0; batch classifier loss: 0.442376; batch adversarial loss: 0.611119\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432861; batch adversarial loss: 0.555057\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360147; batch adversarial loss: 0.582147\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362011; batch adversarial loss: 0.582798\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340021; batch adversarial loss: 0.460293\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339447; batch adversarial loss: 0.507391\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383170; batch adversarial loss: 0.535601\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340703; batch adversarial loss: 0.648649\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346989; batch adversarial loss: 0.508176\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371466; batch adversarial loss: 0.554413\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374969; batch adversarial loss: 0.593142\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366985; batch adversarial loss: 0.544712\n",
      "epoch 139; iter: 0; batch classifier loss: 0.351609; batch adversarial loss: 0.506352\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364597; batch adversarial loss: 0.477843\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398867; batch adversarial loss: 0.535424\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389230; batch adversarial loss: 0.591318\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408615; batch adversarial loss: 0.543767\n",
      "epoch 144; iter: 0; batch classifier loss: 0.451199; batch adversarial loss: 0.590544\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403351; batch adversarial loss: 0.534249\n",
      "epoch 146; iter: 0; batch classifier loss: 0.440690; batch adversarial loss: 0.478049\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336966; batch adversarial loss: 0.544073\n",
      "epoch 148; iter: 0; batch classifier loss: 0.393093; batch adversarial loss: 0.459213\n",
      "epoch 149; iter: 0; batch classifier loss: 0.461342; batch adversarial loss: 0.563163\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371259; batch adversarial loss: 0.553646\n",
      "epoch 151; iter: 0; batch classifier loss: 0.389868; batch adversarial loss: 0.572346\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376013; batch adversarial loss: 0.515255\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320760; batch adversarial loss: 0.506856\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349735; batch adversarial loss: 0.535836\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314469; batch adversarial loss: 0.591514\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380609; batch adversarial loss: 0.629149\n",
      "epoch 157; iter: 0; batch classifier loss: 0.379963; batch adversarial loss: 0.639469\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381675; batch adversarial loss: 0.506033\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367608; batch adversarial loss: 0.572875\n",
      "epoch 160; iter: 0; batch classifier loss: 0.482597; batch adversarial loss: 0.564053\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357705; batch adversarial loss: 0.563460\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352471; batch adversarial loss: 0.515898\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350900; batch adversarial loss: 0.525339\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414361; batch adversarial loss: 0.619916\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405796; batch adversarial loss: 0.553403\n",
      "epoch 166; iter: 0; batch classifier loss: 0.391210; batch adversarial loss: 0.469993\n",
      "epoch 167; iter: 0; batch classifier loss: 0.448486; batch adversarial loss: 0.488163\n",
      "epoch 168; iter: 0; batch classifier loss: 0.329942; batch adversarial loss: 0.554469\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350653; batch adversarial loss: 0.506742\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342173; batch adversarial loss: 0.553847\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401795; batch adversarial loss: 0.554415\n",
      "epoch 172; iter: 0; batch classifier loss: 0.430982; batch adversarial loss: 0.525962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.347214; batch adversarial loss: 0.553082\n",
      "epoch 174; iter: 0; batch classifier loss: 0.418782; batch adversarial loss: 0.535140\n",
      "epoch 175; iter: 0; batch classifier loss: 0.385975; batch adversarial loss: 0.554490\n",
      "epoch 176; iter: 0; batch classifier loss: 0.279772; batch adversarial loss: 0.554348\n",
      "epoch 177; iter: 0; batch classifier loss: 0.333975; batch adversarial loss: 0.525842\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416270; batch adversarial loss: 0.676428\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377524; batch adversarial loss: 0.629341\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366415; batch adversarial loss: 0.515862\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361850; batch adversarial loss: 0.619607\n",
      "epoch 182; iter: 0; batch classifier loss: 0.417102; batch adversarial loss: 0.572637\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372156; batch adversarial loss: 0.526599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.398492; batch adversarial loss: 0.582388\n",
      "epoch 185; iter: 0; batch classifier loss: 0.433840; batch adversarial loss: 0.563670\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379248; batch adversarial loss: 0.601464\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389161; batch adversarial loss: 0.535991\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373511; batch adversarial loss: 0.572721\n",
      "epoch 189; iter: 0; batch classifier loss: 0.458546; batch adversarial loss: 0.574062\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357699; batch adversarial loss: 0.611526\n",
      "epoch 191; iter: 0; batch classifier loss: 0.285238; batch adversarial loss: 0.563394\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387720; batch adversarial loss: 0.601249\n",
      "epoch 193; iter: 0; batch classifier loss: 0.414212; batch adversarial loss: 0.497356\n",
      "epoch 194; iter: 0; batch classifier loss: 0.411737; batch adversarial loss: 0.601993\n",
      "epoch 195; iter: 0; batch classifier loss: 0.389965; batch adversarial loss: 0.516930\n",
      "epoch 196; iter: 0; batch classifier loss: 0.398189; batch adversarial loss: 0.630422\n",
      "epoch 197; iter: 0; batch classifier loss: 0.275659; batch adversarial loss: 0.506089\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358876; batch adversarial loss: 0.544583\n",
      "epoch 199; iter: 0; batch classifier loss: 0.408186; batch adversarial loss: 0.555042\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731237; batch adversarial loss: 0.690661\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596526; batch adversarial loss: 0.669315\n",
      "epoch 2; iter: 0; batch classifier loss: 0.508437; batch adversarial loss: 0.640714\n",
      "epoch 3; iter: 0; batch classifier loss: 0.532997; batch adversarial loss: 0.602263\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541716; batch adversarial loss: 0.604744\n",
      "epoch 5; iter: 0; batch classifier loss: 0.603676; batch adversarial loss: 0.589311\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553651; batch adversarial loss: 0.627496\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532442; batch adversarial loss: 0.568485\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588769; batch adversarial loss: 0.588602\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499188; batch adversarial loss: 0.564078\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480819; batch adversarial loss: 0.575685\n",
      "epoch 11; iter: 0; batch classifier loss: 0.483256; batch adversarial loss: 0.534526\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511636; batch adversarial loss: 0.585551\n",
      "epoch 13; iter: 0; batch classifier loss: 0.523789; batch adversarial loss: 0.617097\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535923; batch adversarial loss: 0.584229\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548824; batch adversarial loss: 0.592438\n",
      "epoch 16; iter: 0; batch classifier loss: 0.594156; batch adversarial loss: 0.613740\n",
      "epoch 17; iter: 0; batch classifier loss: 0.411690; batch adversarial loss: 0.557037\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489376; batch adversarial loss: 0.596616\n",
      "epoch 19; iter: 0; batch classifier loss: 0.494054; batch adversarial loss: 0.595498\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451696; batch adversarial loss: 0.553461\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492272; batch adversarial loss: 0.640426\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466603; batch adversarial loss: 0.578329\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511042; batch adversarial loss: 0.535192\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489378; batch adversarial loss: 0.533160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492683; batch adversarial loss: 0.569436\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490116; batch adversarial loss: 0.557636\n",
      "epoch 27; iter: 0; batch classifier loss: 0.536300; batch adversarial loss: 0.559932\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479826; batch adversarial loss: 0.533203\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413241; batch adversarial loss: 0.548559\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449455; batch adversarial loss: 0.505470\n",
      "epoch 31; iter: 0; batch classifier loss: 0.482839; batch adversarial loss: 0.562796\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448886; batch adversarial loss: 0.571727\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466241; batch adversarial loss: 0.528202\n",
      "epoch 34; iter: 0; batch classifier loss: 0.367637; batch adversarial loss: 0.537112\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448967; batch adversarial loss: 0.553212\n",
      "epoch 36; iter: 0; batch classifier loss: 0.385662; batch adversarial loss: 0.534022\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458908; batch adversarial loss: 0.582044\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474376; batch adversarial loss: 0.591262\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424464; batch adversarial loss: 0.551944\n",
      "epoch 40; iter: 0; batch classifier loss: 0.568440; batch adversarial loss: 0.582791\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404465; batch adversarial loss: 0.568007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483954; batch adversarial loss: 0.545019\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422275; batch adversarial loss: 0.542759\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422504; batch adversarial loss: 0.479757\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441050; batch adversarial loss: 0.562212\n",
      "epoch 46; iter: 0; batch classifier loss: 0.518391; batch adversarial loss: 0.581854\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375966; batch adversarial loss: 0.533978\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481206; batch adversarial loss: 0.543764\n",
      "epoch 49; iter: 0; batch classifier loss: 0.488126; batch adversarial loss: 0.513231\n",
      "epoch 50; iter: 0; batch classifier loss: 0.501547; batch adversarial loss: 0.609241\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441955; batch adversarial loss: 0.509911\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462773; batch adversarial loss: 0.552329\n",
      "epoch 53; iter: 0; batch classifier loss: 0.289715; batch adversarial loss: 0.506358\n",
      "epoch 54; iter: 0; batch classifier loss: 0.365910; batch adversarial loss: 0.591141\n",
      "epoch 55; iter: 0; batch classifier loss: 0.453577; batch adversarial loss: 0.486099\n",
      "epoch 56; iter: 0; batch classifier loss: 0.464184; batch adversarial loss: 0.501601\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416825; batch adversarial loss: 0.515204\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414223; batch adversarial loss: 0.590038\n",
      "epoch 59; iter: 0; batch classifier loss: 0.469199; batch adversarial loss: 0.525679\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382389; batch adversarial loss: 0.571001\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416432; batch adversarial loss: 0.492194\n",
      "epoch 62; iter: 0; batch classifier loss: 0.367335; batch adversarial loss: 0.564756\n",
      "epoch 63; iter: 0; batch classifier loss: 0.439824; batch adversarial loss: 0.570652\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361707; batch adversarial loss: 0.513408\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403111; batch adversarial loss: 0.505732\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408397; batch adversarial loss: 0.505984\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386659; batch adversarial loss: 0.524585\n",
      "epoch 68; iter: 0; batch classifier loss: 0.420185; batch adversarial loss: 0.606008\n",
      "epoch 69; iter: 0; batch classifier loss: 0.385121; batch adversarial loss: 0.532706\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443571; batch adversarial loss: 0.572845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.466531; batch adversarial loss: 0.540119\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414954; batch adversarial loss: 0.599181\n",
      "epoch 73; iter: 0; batch classifier loss: 0.470317; batch adversarial loss: 0.598310\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406127; batch adversarial loss: 0.545318\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430534; batch adversarial loss: 0.643495\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420199; batch adversarial loss: 0.561853\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408205; batch adversarial loss: 0.589587\n",
      "epoch 78; iter: 0; batch classifier loss: 0.338485; batch adversarial loss: 0.631789\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389411; batch adversarial loss: 0.584516\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407954; batch adversarial loss: 0.547024\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385310; batch adversarial loss: 0.452657\n",
      "epoch 82; iter: 0; batch classifier loss: 0.326467; batch adversarial loss: 0.541169\n",
      "epoch 83; iter: 0; batch classifier loss: 0.287959; batch adversarial loss: 0.476814\n",
      "epoch 84; iter: 0; batch classifier loss: 0.495509; batch adversarial loss: 0.617184\n",
      "epoch 85; iter: 0; batch classifier loss: 0.430133; batch adversarial loss: 0.588326\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417918; batch adversarial loss: 0.426041\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396713; batch adversarial loss: 0.527922\n",
      "epoch 88; iter: 0; batch classifier loss: 0.327955; batch adversarial loss: 0.556614\n",
      "epoch 89; iter: 0; batch classifier loss: 0.455989; batch adversarial loss: 0.563888\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363957; batch adversarial loss: 0.674200\n",
      "epoch 91; iter: 0; batch classifier loss: 0.357578; batch adversarial loss: 0.480999\n",
      "epoch 92; iter: 0; batch classifier loss: 0.451443; batch adversarial loss: 0.509920\n",
      "epoch 93; iter: 0; batch classifier loss: 0.332882; batch adversarial loss: 0.527030\n",
      "epoch 94; iter: 0; batch classifier loss: 0.457788; batch adversarial loss: 0.561178\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394811; batch adversarial loss: 0.554225\n",
      "epoch 96; iter: 0; batch classifier loss: 0.453271; batch adversarial loss: 0.517409\n",
      "epoch 97; iter: 0; batch classifier loss: 0.439928; batch adversarial loss: 0.507833\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380681; batch adversarial loss: 0.537007\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416274; batch adversarial loss: 0.479085\n",
      "epoch 100; iter: 0; batch classifier loss: 0.425532; batch adversarial loss: 0.518999\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384858; batch adversarial loss: 0.583393\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377795; batch adversarial loss: 0.580533\n",
      "epoch 103; iter: 0; batch classifier loss: 0.434393; batch adversarial loss: 0.506888\n",
      "epoch 104; iter: 0; batch classifier loss: 0.448272; batch adversarial loss: 0.504846\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396736; batch adversarial loss: 0.596364\n",
      "epoch 106; iter: 0; batch classifier loss: 0.357116; batch adversarial loss: 0.532670\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391787; batch adversarial loss: 0.525399\n",
      "epoch 108; iter: 0; batch classifier loss: 0.361504; batch adversarial loss: 0.579504\n",
      "epoch 109; iter: 0; batch classifier loss: 0.308741; batch adversarial loss: 0.564633\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372538; batch adversarial loss: 0.593101\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389283; batch adversarial loss: 0.564521\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394814; batch adversarial loss: 0.507403\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378352; batch adversarial loss: 0.507174\n",
      "epoch 114; iter: 0; batch classifier loss: 0.479370; batch adversarial loss: 0.590888\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366710; batch adversarial loss: 0.460797\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402892; batch adversarial loss: 0.519950\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408320; batch adversarial loss: 0.563108\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404485; batch adversarial loss: 0.562326\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352332; batch adversarial loss: 0.524525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.397773; batch adversarial loss: 0.526593\n",
      "epoch 121; iter: 0; batch classifier loss: 0.293578; batch adversarial loss: 0.544930\n",
      "epoch 122; iter: 0; batch classifier loss: 0.327880; batch adversarial loss: 0.544325\n",
      "epoch 123; iter: 0; batch classifier loss: 0.397315; batch adversarial loss: 0.555088\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376059; batch adversarial loss: 0.507969\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351498; batch adversarial loss: 0.554769\n",
      "epoch 126; iter: 0; batch classifier loss: 0.312337; batch adversarial loss: 0.507209\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365423; batch adversarial loss: 0.608048\n",
      "epoch 128; iter: 0; batch classifier loss: 0.327662; batch adversarial loss: 0.600384\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358070; batch adversarial loss: 0.561743\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382254; batch adversarial loss: 0.564041\n",
      "epoch 131; iter: 0; batch classifier loss: 0.411434; batch adversarial loss: 0.562214\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400779; batch adversarial loss: 0.507586\n",
      "epoch 133; iter: 0; batch classifier loss: 0.368916; batch adversarial loss: 0.617353\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354473; batch adversarial loss: 0.602582\n",
      "epoch 135; iter: 0; batch classifier loss: 0.322696; batch adversarial loss: 0.590054\n",
      "epoch 136; iter: 0; batch classifier loss: 0.413424; batch adversarial loss: 0.617193\n",
      "epoch 137; iter: 0; batch classifier loss: 0.421965; batch adversarial loss: 0.573660\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393395; batch adversarial loss: 0.559169\n",
      "epoch 139; iter: 0; batch classifier loss: 0.318496; batch adversarial loss: 0.582675\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397417; batch adversarial loss: 0.548269\n",
      "epoch 141; iter: 0; batch classifier loss: 0.436579; batch adversarial loss: 0.520326\n",
      "epoch 142; iter: 0; batch classifier loss: 0.344467; batch adversarial loss: 0.505029\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369483; batch adversarial loss: 0.516468\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327503; batch adversarial loss: 0.617201\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356721; batch adversarial loss: 0.570485\n",
      "epoch 146; iter: 0; batch classifier loss: 0.397959; batch adversarial loss: 0.545518\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340962; batch adversarial loss: 0.588589\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373699; batch adversarial loss: 0.552234\n",
      "epoch 149; iter: 0; batch classifier loss: 0.381631; batch adversarial loss: 0.565193\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368805; batch adversarial loss: 0.569378\n",
      "epoch 151; iter: 0; batch classifier loss: 0.342880; batch adversarial loss: 0.543477\n",
      "epoch 152; iter: 0; batch classifier loss: 0.408698; batch adversarial loss: 0.609782\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349132; batch adversarial loss: 0.555138\n",
      "epoch 154; iter: 0; batch classifier loss: 0.287436; batch adversarial loss: 0.555446\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344109; batch adversarial loss: 0.544477\n",
      "epoch 156; iter: 0; batch classifier loss: 0.392309; batch adversarial loss: 0.498256\n",
      "epoch 157; iter: 0; batch classifier loss: 0.417384; batch adversarial loss: 0.580775\n",
      "epoch 158; iter: 0; batch classifier loss: 0.430195; batch adversarial loss: 0.490323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387011; batch adversarial loss: 0.682677\n",
      "epoch 160; iter: 0; batch classifier loss: 0.279273; batch adversarial loss: 0.525861\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374531; batch adversarial loss: 0.516372\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343294; batch adversarial loss: 0.515001\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379507; batch adversarial loss: 0.480287\n",
      "epoch 164; iter: 0; batch classifier loss: 0.404469; batch adversarial loss: 0.498941\n",
      "epoch 165; iter: 0; batch classifier loss: 0.278708; batch adversarial loss: 0.470079\n",
      "epoch 166; iter: 0; batch classifier loss: 0.412410; batch adversarial loss: 0.524942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.333111; batch adversarial loss: 0.581807\n",
      "epoch 168; iter: 0; batch classifier loss: 0.313551; batch adversarial loss: 0.553129\n",
      "epoch 169; iter: 0; batch classifier loss: 0.419771; batch adversarial loss: 0.441349\n",
      "epoch 170; iter: 0; batch classifier loss: 0.307844; batch adversarial loss: 0.516305\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323908; batch adversarial loss: 0.492122\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357107; batch adversarial loss: 0.634639\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339283; batch adversarial loss: 0.478872\n",
      "epoch 174; iter: 0; batch classifier loss: 0.307480; batch adversarial loss: 0.525437\n",
      "epoch 175; iter: 0; batch classifier loss: 0.427525; batch adversarial loss: 0.551564\n",
      "epoch 176; iter: 0; batch classifier loss: 0.446106; batch adversarial loss: 0.584069\n",
      "epoch 177; iter: 0; batch classifier loss: 0.423233; batch adversarial loss: 0.518975\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417974; batch adversarial loss: 0.522765\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394381; batch adversarial loss: 0.521514\n",
      "epoch 180; iter: 0; batch classifier loss: 0.365974; batch adversarial loss: 0.503364\n",
      "epoch 181; iter: 0; batch classifier loss: 0.326533; batch adversarial loss: 0.634677\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377718; batch adversarial loss: 0.570120\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370881; batch adversarial loss: 0.644246\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366096; batch adversarial loss: 0.535887\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328789; batch adversarial loss: 0.626162\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375847; batch adversarial loss: 0.534355\n",
      "epoch 187; iter: 0; batch classifier loss: 0.381192; batch adversarial loss: 0.589638\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355835; batch adversarial loss: 0.509016\n",
      "epoch 189; iter: 0; batch classifier loss: 0.409846; batch adversarial loss: 0.517171\n",
      "epoch 190; iter: 0; batch classifier loss: 0.298062; batch adversarial loss: 0.552551\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340124; batch adversarial loss: 0.506034\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348465; batch adversarial loss: 0.519330\n",
      "epoch 193; iter: 0; batch classifier loss: 0.355027; batch adversarial loss: 0.451775\n",
      "epoch 194; iter: 0; batch classifier loss: 0.329410; batch adversarial loss: 0.606404\n",
      "epoch 195; iter: 0; batch classifier loss: 0.331459; batch adversarial loss: 0.545146\n",
      "epoch 196; iter: 0; batch classifier loss: 0.308416; batch adversarial loss: 0.518092\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352683; batch adversarial loss: 0.564020\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343364; batch adversarial loss: 0.501260\n",
      "epoch 199; iter: 0; batch classifier loss: 0.312932; batch adversarial loss: 0.652730\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691564; batch adversarial loss: 0.834795\n",
      "epoch 1; iter: 0; batch classifier loss: 0.783104; batch adversarial loss: 0.881776\n",
      "epoch 2; iter: 0; batch classifier loss: 0.970215; batch adversarial loss: 0.855648\n",
      "epoch 3; iter: 0; batch classifier loss: 0.930184; batch adversarial loss: 0.774380\n",
      "epoch 4; iter: 0; batch classifier loss: 1.092495; batch adversarial loss: 0.716148\n",
      "epoch 5; iter: 0; batch classifier loss: 0.945060; batch adversarial loss: 0.671157\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586748; batch adversarial loss: 0.606474\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592283; batch adversarial loss: 0.630640\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499913; batch adversarial loss: 0.615122\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535641; batch adversarial loss: 0.591127\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569454; batch adversarial loss: 0.583483\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492403; batch adversarial loss: 0.553368\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523587; batch adversarial loss: 0.553868\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528077; batch adversarial loss: 0.549510\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518576; batch adversarial loss: 0.532767\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462761; batch adversarial loss: 0.572104\n",
      "epoch 16; iter: 0; batch classifier loss: 0.578661; batch adversarial loss: 0.536048\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543724; batch adversarial loss: 0.553064\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483318; batch adversarial loss: 0.617243\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504965; batch adversarial loss: 0.567347\n",
      "epoch 20; iter: 0; batch classifier loss: 0.544852; batch adversarial loss: 0.532349\n",
      "epoch 21; iter: 0; batch classifier loss: 0.557879; batch adversarial loss: 0.557348\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496874; batch adversarial loss: 0.541979\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499941; batch adversarial loss: 0.500491\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465226; batch adversarial loss: 0.629049\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462224; batch adversarial loss: 0.538280\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490700; batch adversarial loss: 0.584677\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495312; batch adversarial loss: 0.513790\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529902; batch adversarial loss: 0.596738\n",
      "epoch 29; iter: 0; batch classifier loss: 0.414957; batch adversarial loss: 0.530170\n",
      "epoch 30; iter: 0; batch classifier loss: 0.397484; batch adversarial loss: 0.536999\n",
      "epoch 31; iter: 0; batch classifier loss: 0.563257; batch adversarial loss: 0.574445\n",
      "epoch 32; iter: 0; batch classifier loss: 0.536752; batch adversarial loss: 0.596301\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405076; batch adversarial loss: 0.518432\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435070; batch adversarial loss: 0.568488\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426403; batch adversarial loss: 0.564817\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453110; batch adversarial loss: 0.547810\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408921; batch adversarial loss: 0.591489\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448335; batch adversarial loss: 0.612156\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436903; batch adversarial loss: 0.580679\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468544; batch adversarial loss: 0.575651\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451894; batch adversarial loss: 0.535977\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402757; batch adversarial loss: 0.482354\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393360; batch adversarial loss: 0.598445\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455872; batch adversarial loss: 0.571821\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367978; batch adversarial loss: 0.617881\n",
      "epoch 46; iter: 0; batch classifier loss: 0.427712; batch adversarial loss: 0.499621\n",
      "epoch 47; iter: 0; batch classifier loss: 0.394973; batch adversarial loss: 0.499205\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382627; batch adversarial loss: 0.616018\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458573; batch adversarial loss: 0.544173\n",
      "epoch 50; iter: 0; batch classifier loss: 0.450710; batch adversarial loss: 0.508652\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415559; batch adversarial loss: 0.571612\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434112; batch adversarial loss: 0.489515\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384553; batch adversarial loss: 0.517503\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452969; batch adversarial loss: 0.553186\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429583; batch adversarial loss: 0.571905\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473701; batch adversarial loss: 0.517004\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406485; batch adversarial loss: 0.571147\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423295; batch adversarial loss: 0.552682\n",
      "epoch 59; iter: 0; batch classifier loss: 0.465200; batch adversarial loss: 0.498456\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435366; batch adversarial loss: 0.581920\n",
      "epoch 61; iter: 0; batch classifier loss: 0.388838; batch adversarial loss: 0.628071\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390333; batch adversarial loss: 0.452421\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419476; batch adversarial loss: 0.491513\n",
      "epoch 64; iter: 0; batch classifier loss: 0.450135; batch adversarial loss: 0.488885\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389175; batch adversarial loss: 0.525482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.489115; batch adversarial loss: 0.588727\n",
      "epoch 67; iter: 0; batch classifier loss: 0.376879; batch adversarial loss: 0.600390\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356625; batch adversarial loss: 0.552200\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378404; batch adversarial loss: 0.532597\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402784; batch adversarial loss: 0.579681\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399615; batch adversarial loss: 0.450353\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385132; batch adversarial loss: 0.535749\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418912; batch adversarial loss: 0.589623\n",
      "epoch 74; iter: 0; batch classifier loss: 0.420789; batch adversarial loss: 0.545213\n",
      "epoch 75; iter: 0; batch classifier loss: 0.453546; batch adversarial loss: 0.508456\n",
      "epoch 76; iter: 0; batch classifier loss: 0.431712; batch adversarial loss: 0.563324\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426666; batch adversarial loss: 0.598076\n",
      "epoch 78; iter: 0; batch classifier loss: 0.345948; batch adversarial loss: 0.596608\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386438; batch adversarial loss: 0.525549\n",
      "epoch 80; iter: 0; batch classifier loss: 0.338714; batch adversarial loss: 0.533529\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408621; batch adversarial loss: 0.586813\n",
      "epoch 82; iter: 0; batch classifier loss: 0.466618; batch adversarial loss: 0.557841\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394110; batch adversarial loss: 0.490010\n",
      "epoch 84; iter: 0; batch classifier loss: 0.337185; batch adversarial loss: 0.617667\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369547; batch adversarial loss: 0.561927\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435663; batch adversarial loss: 0.534812\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365483; batch adversarial loss: 0.535689\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411173; batch adversarial loss: 0.524411\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406826; batch adversarial loss: 0.549423\n",
      "epoch 90; iter: 0; batch classifier loss: 0.422807; batch adversarial loss: 0.531661\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383325; batch adversarial loss: 0.599800\n",
      "epoch 92; iter: 0; batch classifier loss: 0.339237; batch adversarial loss: 0.599009\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364043; batch adversarial loss: 0.533789\n",
      "epoch 94; iter: 0; batch classifier loss: 0.339259; batch adversarial loss: 0.517190\n",
      "epoch 95; iter: 0; batch classifier loss: 0.363577; batch adversarial loss: 0.544808\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382077; batch adversarial loss: 0.545862\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336812; batch adversarial loss: 0.609630\n",
      "epoch 98; iter: 0; batch classifier loss: 0.324874; batch adversarial loss: 0.542657\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407726; batch adversarial loss: 0.644891\n",
      "epoch 100; iter: 0; batch classifier loss: 0.436462; batch adversarial loss: 0.526025\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335816; batch adversarial loss: 0.555904\n",
      "epoch 102; iter: 0; batch classifier loss: 0.375071; batch adversarial loss: 0.536001\n",
      "epoch 103; iter: 0; batch classifier loss: 0.320316; batch adversarial loss: 0.579305\n",
      "epoch 104; iter: 0; batch classifier loss: 0.448495; batch adversarial loss: 0.559008\n",
      "epoch 105; iter: 0; batch classifier loss: 0.340193; batch adversarial loss: 0.510010\n",
      "epoch 106; iter: 0; batch classifier loss: 0.302677; batch adversarial loss: 0.602853\n",
      "epoch 107; iter: 0; batch classifier loss: 0.335965; batch adversarial loss: 0.542242\n",
      "epoch 108; iter: 0; batch classifier loss: 0.339894; batch adversarial loss: 0.562688\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365449; batch adversarial loss: 0.550640\n",
      "epoch 110; iter: 0; batch classifier loss: 0.418732; batch adversarial loss: 0.528979\n",
      "epoch 111; iter: 0; batch classifier loss: 0.318474; batch adversarial loss: 0.573284\n",
      "epoch 112; iter: 0; batch classifier loss: 0.273037; batch adversarial loss: 0.543886\n",
      "epoch 113; iter: 0; batch classifier loss: 0.301566; batch adversarial loss: 0.555204\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369703; batch adversarial loss: 0.562448\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393041; batch adversarial loss: 0.570059\n",
      "epoch 116; iter: 0; batch classifier loss: 0.281466; batch adversarial loss: 0.555691\n",
      "epoch 117; iter: 0; batch classifier loss: 0.364821; batch adversarial loss: 0.506578\n",
      "epoch 118; iter: 0; batch classifier loss: 0.328547; batch adversarial loss: 0.637707\n",
      "epoch 119; iter: 0; batch classifier loss: 0.351424; batch adversarial loss: 0.536870\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373496; batch adversarial loss: 0.591059\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346379; batch adversarial loss: 0.580711\n",
      "epoch 122; iter: 0; batch classifier loss: 0.327697; batch adversarial loss: 0.598219\n",
      "epoch 123; iter: 0; batch classifier loss: 0.364110; batch adversarial loss: 0.524246\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387464; batch adversarial loss: 0.449093\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376394; batch adversarial loss: 0.489605\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376128; batch adversarial loss: 0.507705\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358018; batch adversarial loss: 0.551808\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329577; batch adversarial loss: 0.610218\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342003; batch adversarial loss: 0.531938\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389211; batch adversarial loss: 0.617410\n",
      "epoch 131; iter: 0; batch classifier loss: 0.325357; batch adversarial loss: 0.574895\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342169; batch adversarial loss: 0.647050\n",
      "epoch 133; iter: 0; batch classifier loss: 0.268664; batch adversarial loss: 0.534262\n",
      "epoch 134; iter: 0; batch classifier loss: 0.296001; batch adversarial loss: 0.529797\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338819; batch adversarial loss: 0.562600\n",
      "epoch 136; iter: 0; batch classifier loss: 0.379640; batch adversarial loss: 0.482064\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356400; batch adversarial loss: 0.545167\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320512; batch adversarial loss: 0.600656\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352316; batch adversarial loss: 0.579940\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409725; batch adversarial loss: 0.487784\n",
      "epoch 141; iter: 0; batch classifier loss: 0.506381; batch adversarial loss: 0.479776\n",
      "epoch 142; iter: 0; batch classifier loss: 0.332366; batch adversarial loss: 0.588151\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368205; batch adversarial loss: 0.568219\n",
      "epoch 144; iter: 0; batch classifier loss: 0.314800; batch adversarial loss: 0.534992\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340747; batch adversarial loss: 0.489512\n",
      "epoch 146; iter: 0; batch classifier loss: 0.318185; batch adversarial loss: 0.582883\n",
      "epoch 147; iter: 0; batch classifier loss: 0.375315; batch adversarial loss: 0.596498\n",
      "epoch 148; iter: 0; batch classifier loss: 0.278978; batch adversarial loss: 0.554852\n",
      "epoch 149; iter: 0; batch classifier loss: 0.325405; batch adversarial loss: 0.598272\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390413; batch adversarial loss: 0.508382\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350551; batch adversarial loss: 0.494198\n",
      "epoch 152; iter: 0; batch classifier loss: 0.298561; batch adversarial loss: 0.546527\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366740; batch adversarial loss: 0.582297\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317156; batch adversarial loss: 0.495714\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394368; batch adversarial loss: 0.482663\n",
      "epoch 156; iter: 0; batch classifier loss: 0.273982; batch adversarial loss: 0.547252\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384088; batch adversarial loss: 0.592361\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370020; batch adversarial loss: 0.580622\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375277; batch adversarial loss: 0.578791\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373608; batch adversarial loss: 0.518672\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392586; batch adversarial loss: 0.532821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.394349; batch adversarial loss: 0.614777\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311177; batch adversarial loss: 0.591822\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346028; batch adversarial loss: 0.525457\n",
      "epoch 165; iter: 0; batch classifier loss: 0.320434; batch adversarial loss: 0.513040\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347311; batch adversarial loss: 0.564935\n",
      "epoch 167; iter: 0; batch classifier loss: 0.299204; batch adversarial loss: 0.562948\n",
      "epoch 168; iter: 0; batch classifier loss: 0.242029; batch adversarial loss: 0.518716\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343511; batch adversarial loss: 0.544734\n",
      "epoch 170; iter: 0; batch classifier loss: 0.381084; batch adversarial loss: 0.572177\n",
      "epoch 171; iter: 0; batch classifier loss: 0.313897; batch adversarial loss: 0.545156\n",
      "epoch 172; iter: 0; batch classifier loss: 0.253089; batch adversarial loss: 0.571354\n",
      "epoch 173; iter: 0; batch classifier loss: 0.323392; batch adversarial loss: 0.585303\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396705; batch adversarial loss: 0.564230\n",
      "epoch 175; iter: 0; batch classifier loss: 0.297948; batch adversarial loss: 0.527933\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319356; batch adversarial loss: 0.518466\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345934; batch adversarial loss: 0.563361\n",
      "epoch 178; iter: 0; batch classifier loss: 0.293422; batch adversarial loss: 0.516711\n",
      "epoch 179; iter: 0; batch classifier loss: 0.286944; batch adversarial loss: 0.530222\n",
      "epoch 180; iter: 0; batch classifier loss: 0.287250; batch adversarial loss: 0.550026\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311698; batch adversarial loss: 0.539159\n",
      "epoch 182; iter: 0; batch classifier loss: 0.239392; batch adversarial loss: 0.553157\n",
      "epoch 183; iter: 0; batch classifier loss: 0.425093; batch adversarial loss: 0.538152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.307332; batch adversarial loss: 0.523409\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331853; batch adversarial loss: 0.572724\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358191; batch adversarial loss: 0.523798\n",
      "epoch 187; iter: 0; batch classifier loss: 0.398483; batch adversarial loss: 0.534877\n",
      "epoch 188; iter: 0; batch classifier loss: 0.398724; batch adversarial loss: 0.565169\n",
      "epoch 189; iter: 0; batch classifier loss: 0.286285; batch adversarial loss: 0.598596\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379849; batch adversarial loss: 0.556533\n",
      "epoch 191; iter: 0; batch classifier loss: 0.307783; batch adversarial loss: 0.593237\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353045; batch adversarial loss: 0.635160\n",
      "epoch 193; iter: 0; batch classifier loss: 0.396957; batch adversarial loss: 0.571806\n",
      "epoch 194; iter: 0; batch classifier loss: 0.296180; batch adversarial loss: 0.504937\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311077; batch adversarial loss: 0.426426\n",
      "epoch 196; iter: 0; batch classifier loss: 0.406283; batch adversarial loss: 0.433106\n",
      "epoch 197; iter: 0; batch classifier loss: 0.383324; batch adversarial loss: 0.586350\n",
      "epoch 198; iter: 0; batch classifier loss: 0.225059; batch adversarial loss: 0.527009\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316946; batch adversarial loss: 0.573585\n",
      "epoch 0; iter: 0; batch classifier loss: 0.742351; batch adversarial loss: 0.720893\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613870; batch adversarial loss: 0.681471\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581174; batch adversarial loss: 0.669297\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570987; batch adversarial loss: 0.634756\n",
      "epoch 4; iter: 0; batch classifier loss: 0.481475; batch adversarial loss: 0.644423\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509543; batch adversarial loss: 0.611619\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577477; batch adversarial loss: 0.614850\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523354; batch adversarial loss: 0.548174\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573083; batch adversarial loss: 0.557231\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549928; batch adversarial loss: 0.591787\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508336; batch adversarial loss: 0.577962\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507501; batch adversarial loss: 0.561699\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565507; batch adversarial loss: 0.580152\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490850; batch adversarial loss: 0.563741\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506367; batch adversarial loss: 0.527241\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519237; batch adversarial loss: 0.582125\n",
      "epoch 16; iter: 0; batch classifier loss: 0.626469; batch adversarial loss: 0.576156\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480367; batch adversarial loss: 0.538830\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487233; batch adversarial loss: 0.574640\n",
      "epoch 19; iter: 0; batch classifier loss: 0.548742; batch adversarial loss: 0.636026\n",
      "epoch 20; iter: 0; batch classifier loss: 0.542335; batch adversarial loss: 0.535327\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528469; batch adversarial loss: 0.580983\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492023; batch adversarial loss: 0.528343\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455211; batch adversarial loss: 0.495052\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471843; batch adversarial loss: 0.544640\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446504; batch adversarial loss: 0.480090\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513452; batch adversarial loss: 0.562197\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495385; batch adversarial loss: 0.562322\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419681; batch adversarial loss: 0.545164\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454560; batch adversarial loss: 0.521358\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431589; batch adversarial loss: 0.543377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448577; batch adversarial loss: 0.591238\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484226; batch adversarial loss: 0.518087\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446403; batch adversarial loss: 0.552210\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476797; batch adversarial loss: 0.534267\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475695; batch adversarial loss: 0.606066\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451589; batch adversarial loss: 0.526326\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473901; batch adversarial loss: 0.493290\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465303; batch adversarial loss: 0.553237\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441203; batch adversarial loss: 0.505538\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460858; batch adversarial loss: 0.553338\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483306; batch adversarial loss: 0.607576\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422750; batch adversarial loss: 0.498945\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446038; batch adversarial loss: 0.581912\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463610; batch adversarial loss: 0.553931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485842; batch adversarial loss: 0.519171\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444051; batch adversarial loss: 0.520845\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444604; batch adversarial loss: 0.568891\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445403; batch adversarial loss: 0.545784\n",
      "epoch 49; iter: 0; batch classifier loss: 0.484173; batch adversarial loss: 0.471682\n",
      "epoch 50; iter: 0; batch classifier loss: 0.365433; batch adversarial loss: 0.579574\n",
      "epoch 51; iter: 0; batch classifier loss: 0.344795; batch adversarial loss: 0.569774\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470158; batch adversarial loss: 0.607259\n",
      "epoch 53; iter: 0; batch classifier loss: 0.541033; batch adversarial loss: 0.514072\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445564; batch adversarial loss: 0.407372\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429374; batch adversarial loss: 0.535363\n",
      "epoch 56; iter: 0; batch classifier loss: 0.461093; batch adversarial loss: 0.566798\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420395; batch adversarial loss: 0.536601\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409066; batch adversarial loss: 0.547193\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391092; batch adversarial loss: 0.542912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.419032; batch adversarial loss: 0.561718\n",
      "epoch 61; iter: 0; batch classifier loss: 0.437599; batch adversarial loss: 0.522427\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442040; batch adversarial loss: 0.561748\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473743; batch adversarial loss: 0.623443\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449966; batch adversarial loss: 0.590595\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379174; batch adversarial loss: 0.586391\n",
      "epoch 66; iter: 0; batch classifier loss: 0.470914; batch adversarial loss: 0.516806\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395061; batch adversarial loss: 0.562496\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438544; batch adversarial loss: 0.601206\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396692; batch adversarial loss: 0.559748\n",
      "epoch 70; iter: 0; batch classifier loss: 0.350855; batch adversarial loss: 0.616609\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451177; batch adversarial loss: 0.533636\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403137; batch adversarial loss: 0.500574\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427262; batch adversarial loss: 0.616313\n",
      "epoch 74; iter: 0; batch classifier loss: 0.338682; batch adversarial loss: 0.609089\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417139; batch adversarial loss: 0.479286\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369778; batch adversarial loss: 0.629987\n",
      "epoch 77; iter: 0; batch classifier loss: 0.397550; batch adversarial loss: 0.560782\n",
      "epoch 78; iter: 0; batch classifier loss: 0.346921; batch adversarial loss: 0.547268\n",
      "epoch 79; iter: 0; batch classifier loss: 0.451444; batch adversarial loss: 0.561640\n",
      "epoch 80; iter: 0; batch classifier loss: 0.446933; batch adversarial loss: 0.573180\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393939; batch adversarial loss: 0.471751\n",
      "epoch 82; iter: 0; batch classifier loss: 0.507886; batch adversarial loss: 0.579105\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376684; batch adversarial loss: 0.526701\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355017; batch adversarial loss: 0.609486\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378673; batch adversarial loss: 0.543282\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409678; batch adversarial loss: 0.537113\n",
      "epoch 87; iter: 0; batch classifier loss: 0.442861; batch adversarial loss: 0.529454\n",
      "epoch 88; iter: 0; batch classifier loss: 0.465029; batch adversarial loss: 0.527218\n",
      "epoch 89; iter: 0; batch classifier loss: 0.333888; batch adversarial loss: 0.529549\n",
      "epoch 90; iter: 0; batch classifier loss: 0.319590; batch adversarial loss: 0.617882\n",
      "epoch 91; iter: 0; batch classifier loss: 0.446752; batch adversarial loss: 0.590513\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425953; batch adversarial loss: 0.578766\n",
      "epoch 93; iter: 0; batch classifier loss: 0.498942; batch adversarial loss: 0.594315\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405461; batch adversarial loss: 0.525418\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399792; batch adversarial loss: 0.524420\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377647; batch adversarial loss: 0.587129\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418563; batch adversarial loss: 0.543536\n",
      "epoch 98; iter: 0; batch classifier loss: 0.341675; batch adversarial loss: 0.496918\n",
      "epoch 99; iter: 0; batch classifier loss: 0.391837; batch adversarial loss: 0.530146\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401882; batch adversarial loss: 0.517586\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359527; batch adversarial loss: 0.618041\n",
      "epoch 102; iter: 0; batch classifier loss: 0.413251; batch adversarial loss: 0.500474\n",
      "epoch 103; iter: 0; batch classifier loss: 0.319349; batch adversarial loss: 0.580552\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415902; batch adversarial loss: 0.564611\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407406; batch adversarial loss: 0.544120\n",
      "epoch 106; iter: 0; batch classifier loss: 0.339775; batch adversarial loss: 0.625325\n",
      "epoch 107; iter: 0; batch classifier loss: 0.430227; batch adversarial loss: 0.570781\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369262; batch adversarial loss: 0.524255\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371244; batch adversarial loss: 0.563672\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339997; batch adversarial loss: 0.551654\n",
      "epoch 111; iter: 0; batch classifier loss: 0.447294; batch adversarial loss: 0.560327\n",
      "epoch 112; iter: 0; batch classifier loss: 0.413508; batch adversarial loss: 0.535939\n",
      "epoch 113; iter: 0; batch classifier loss: 0.457557; batch adversarial loss: 0.583901\n",
      "epoch 114; iter: 0; batch classifier loss: 0.416536; batch adversarial loss: 0.546599\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379413; batch adversarial loss: 0.519686\n",
      "epoch 116; iter: 0; batch classifier loss: 0.441505; batch adversarial loss: 0.578669\n",
      "epoch 117; iter: 0; batch classifier loss: 0.364290; batch adversarial loss: 0.633847\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417247; batch adversarial loss: 0.555210\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384823; batch adversarial loss: 0.482343\n",
      "epoch 120; iter: 0; batch classifier loss: 0.319133; batch adversarial loss: 0.515196\n",
      "epoch 121; iter: 0; batch classifier loss: 0.342160; batch adversarial loss: 0.498947\n",
      "epoch 122; iter: 0; batch classifier loss: 0.432529; batch adversarial loss: 0.569521\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372585; batch adversarial loss: 0.490199\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373736; batch adversarial loss: 0.589527\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375937; batch adversarial loss: 0.607799\n",
      "epoch 126; iter: 0; batch classifier loss: 0.311708; batch adversarial loss: 0.569919\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367581; batch adversarial loss: 0.580364\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352504; batch adversarial loss: 0.506040\n",
      "epoch 129; iter: 0; batch classifier loss: 0.317205; batch adversarial loss: 0.582881\n",
      "epoch 130; iter: 0; batch classifier loss: 0.401437; batch adversarial loss: 0.534254\n",
      "epoch 131; iter: 0; batch classifier loss: 0.298899; batch adversarial loss: 0.561998\n",
      "epoch 132; iter: 0; batch classifier loss: 0.471310; batch adversarial loss: 0.469713\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349244; batch adversarial loss: 0.545230\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351445; batch adversarial loss: 0.562675\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376245; batch adversarial loss: 0.536011\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399885; batch adversarial loss: 0.544340\n",
      "epoch 137; iter: 0; batch classifier loss: 0.450396; batch adversarial loss: 0.536162\n",
      "epoch 138; iter: 0; batch classifier loss: 0.313534; batch adversarial loss: 0.581852\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378621; batch adversarial loss: 0.574861\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377225; batch adversarial loss: 0.552010\n",
      "epoch 141; iter: 0; batch classifier loss: 0.431109; batch adversarial loss: 0.615552\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384725; batch adversarial loss: 0.489824\n",
      "epoch 143; iter: 0; batch classifier loss: 0.404295; batch adversarial loss: 0.516596\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341655; batch adversarial loss: 0.553050\n",
      "epoch 145; iter: 0; batch classifier loss: 0.345436; batch adversarial loss: 0.471191\n",
      "epoch 146; iter: 0; batch classifier loss: 0.370182; batch adversarial loss: 0.535225\n",
      "epoch 147; iter: 0; batch classifier loss: 0.386754; batch adversarial loss: 0.552133\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417658; batch adversarial loss: 0.496656\n",
      "epoch 149; iter: 0; batch classifier loss: 0.425455; batch adversarial loss: 0.489328\n",
      "epoch 150; iter: 0; batch classifier loss: 0.449354; batch adversarial loss: 0.534643\n",
      "epoch 151; iter: 0; batch classifier loss: 0.385597; batch adversarial loss: 0.572009\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364050; batch adversarial loss: 0.536776\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351977; batch adversarial loss: 0.499209\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329975; batch adversarial loss: 0.554156\n",
      "epoch 155; iter: 0; batch classifier loss: 0.493967; batch adversarial loss: 0.617408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.364913; batch adversarial loss: 0.535024\n",
      "epoch 157; iter: 0; batch classifier loss: 0.407642; batch adversarial loss: 0.562732\n",
      "epoch 158; iter: 0; batch classifier loss: 0.440124; batch adversarial loss: 0.500269\n",
      "epoch 159; iter: 0; batch classifier loss: 0.397231; batch adversarial loss: 0.545533\n",
      "epoch 160; iter: 0; batch classifier loss: 0.441843; batch adversarial loss: 0.554893\n",
      "epoch 161; iter: 0; batch classifier loss: 0.425969; batch adversarial loss: 0.568749\n",
      "epoch 162; iter: 0; batch classifier loss: 0.409970; batch adversarial loss: 0.471480\n",
      "epoch 163; iter: 0; batch classifier loss: 0.393855; batch adversarial loss: 0.607276\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350813; batch adversarial loss: 0.525106\n",
      "epoch 165; iter: 0; batch classifier loss: 0.266145; batch adversarial loss: 0.545602\n",
      "epoch 166; iter: 0; batch classifier loss: 0.475046; batch adversarial loss: 0.553983\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358228; batch adversarial loss: 0.646152\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387358; batch adversarial loss: 0.508237\n",
      "epoch 169; iter: 0; batch classifier loss: 0.415516; batch adversarial loss: 0.581684\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368010; batch adversarial loss: 0.489533\n",
      "epoch 171; iter: 0; batch classifier loss: 0.387490; batch adversarial loss: 0.616608\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402447; batch adversarial loss: 0.498316\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372266; batch adversarial loss: 0.526247\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350013; batch adversarial loss: 0.517052\n",
      "epoch 175; iter: 0; batch classifier loss: 0.429391; batch adversarial loss: 0.570787\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316053; batch adversarial loss: 0.552202\n",
      "epoch 177; iter: 0; batch classifier loss: 0.426203; batch adversarial loss: 0.569524\n",
      "epoch 178; iter: 0; batch classifier loss: 0.348482; batch adversarial loss: 0.543251\n",
      "epoch 179; iter: 0; batch classifier loss: 0.433013; batch adversarial loss: 0.472056\n",
      "epoch 180; iter: 0; batch classifier loss: 0.393668; batch adversarial loss: 0.581738\n",
      "epoch 181; iter: 0; batch classifier loss: 0.406959; batch adversarial loss: 0.525023\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359706; batch adversarial loss: 0.643813\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342569; batch adversarial loss: 0.553463\n",
      "epoch 184; iter: 0; batch classifier loss: 0.399029; batch adversarial loss: 0.580310\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387739; batch adversarial loss: 0.554139\n",
      "epoch 186; iter: 0; batch classifier loss: 0.352530; batch adversarial loss: 0.507665\n",
      "epoch 187; iter: 0; batch classifier loss: 0.433311; batch adversarial loss: 0.572791\n",
      "epoch 188; iter: 0; batch classifier loss: 0.394202; batch adversarial loss: 0.498933\n",
      "epoch 189; iter: 0; batch classifier loss: 0.434533; batch adversarial loss: 0.625663\n",
      "epoch 190; iter: 0; batch classifier loss: 0.420911; batch adversarial loss: 0.571782\n",
      "epoch 191; iter: 0; batch classifier loss: 0.462844; batch adversarial loss: 0.536045\n",
      "epoch 192; iter: 0; batch classifier loss: 0.443393; batch adversarial loss: 0.617525\n",
      "epoch 193; iter: 0; batch classifier loss: 0.418259; batch adversarial loss: 0.533845\n",
      "epoch 194; iter: 0; batch classifier loss: 0.459475; batch adversarial loss: 0.517187\n",
      "epoch 195; iter: 0; batch classifier loss: 0.285671; batch adversarial loss: 0.544684\n",
      "epoch 196; iter: 0; batch classifier loss: 0.385314; batch adversarial loss: 0.480234\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345186; batch adversarial loss: 0.574035\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384395; batch adversarial loss: 0.573802\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355925; batch adversarial loss: 0.500200\n",
      "epoch 0; iter: 0; batch classifier loss: 0.902386; batch adversarial loss: 0.808978\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610401; batch adversarial loss: 0.738927\n",
      "epoch 2; iter: 0; batch classifier loss: 0.660435; batch adversarial loss: 0.698596\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579532; batch adversarial loss: 0.658142\n",
      "epoch 4; iter: 0; batch classifier loss: 0.627716; batch adversarial loss: 0.636368\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544434; batch adversarial loss: 0.602110\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553781; batch adversarial loss: 0.592782\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520036; batch adversarial loss: 0.556391\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508280; batch adversarial loss: 0.569451\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522372; batch adversarial loss: 0.600229\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539582; batch adversarial loss: 0.577339\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514123; batch adversarial loss: 0.528168\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570013; batch adversarial loss: 0.561241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540476; batch adversarial loss: 0.537012\n",
      "epoch 14; iter: 0; batch classifier loss: 0.456735; batch adversarial loss: 0.535150\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539495; batch adversarial loss: 0.580277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452903; batch adversarial loss: 0.563204\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516045; batch adversarial loss: 0.548006\n",
      "epoch 18; iter: 0; batch classifier loss: 0.475374; batch adversarial loss: 0.588460\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500824; batch adversarial loss: 0.544978\n",
      "epoch 20; iter: 0; batch classifier loss: 0.567318; batch adversarial loss: 0.547849\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521873; batch adversarial loss: 0.566681\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549131; batch adversarial loss: 0.590357\n",
      "epoch 23; iter: 0; batch classifier loss: 0.579857; batch adversarial loss: 0.544805\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457005; batch adversarial loss: 0.610940\n",
      "epoch 25; iter: 0; batch classifier loss: 0.399809; batch adversarial loss: 0.548999\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445580; batch adversarial loss: 0.614718\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493114; batch adversarial loss: 0.626003\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468863; batch adversarial loss: 0.583136\n",
      "epoch 29; iter: 0; batch classifier loss: 0.558329; batch adversarial loss: 0.509539\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453043; batch adversarial loss: 0.516710\n",
      "epoch 31; iter: 0; batch classifier loss: 0.529057; batch adversarial loss: 0.585092\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445534; batch adversarial loss: 0.554653\n",
      "epoch 33; iter: 0; batch classifier loss: 0.431866; batch adversarial loss: 0.637126\n",
      "epoch 34; iter: 0; batch classifier loss: 0.531576; batch adversarial loss: 0.553956\n",
      "epoch 35; iter: 0; batch classifier loss: 0.520682; batch adversarial loss: 0.509308\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477841; batch adversarial loss: 0.537173\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412035; batch adversarial loss: 0.519118\n",
      "epoch 38; iter: 0; batch classifier loss: 0.456291; batch adversarial loss: 0.579023\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431819; batch adversarial loss: 0.555645\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472952; batch adversarial loss: 0.537723\n",
      "epoch 41; iter: 0; batch classifier loss: 0.562670; batch adversarial loss: 0.599087\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403155; batch adversarial loss: 0.515076\n",
      "epoch 43; iter: 0; batch classifier loss: 0.382066; batch adversarial loss: 0.559255\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427928; batch adversarial loss: 0.562217\n",
      "epoch 45; iter: 0; batch classifier loss: 0.531745; batch adversarial loss: 0.532044\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479094; batch adversarial loss: 0.587056\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444476; batch adversarial loss: 0.555227\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400145; batch adversarial loss: 0.504643\n",
      "epoch 49; iter: 0; batch classifier loss: 0.527015; batch adversarial loss: 0.646157\n",
      "epoch 50; iter: 0; batch classifier loss: 0.491703; batch adversarial loss: 0.533743\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414790; batch adversarial loss: 0.552022\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398914; batch adversarial loss: 0.555878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.397599; batch adversarial loss: 0.549179\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440911; batch adversarial loss: 0.545236\n",
      "epoch 55; iter: 0; batch classifier loss: 0.452055; batch adversarial loss: 0.601204\n",
      "epoch 56; iter: 0; batch classifier loss: 0.475537; batch adversarial loss: 0.573840\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369101; batch adversarial loss: 0.591008\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448229; batch adversarial loss: 0.483300\n",
      "epoch 59; iter: 0; batch classifier loss: 0.348210; batch adversarial loss: 0.597472\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398977; batch adversarial loss: 0.501763\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424932; batch adversarial loss: 0.615867\n",
      "epoch 62; iter: 0; batch classifier loss: 0.487962; batch adversarial loss: 0.571667\n",
      "epoch 63; iter: 0; batch classifier loss: 0.528007; batch adversarial loss: 0.544937\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449284; batch adversarial loss: 0.589335\n",
      "epoch 65; iter: 0; batch classifier loss: 0.468636; batch adversarial loss: 0.499806\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454342; batch adversarial loss: 0.490857\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384805; batch adversarial loss: 0.553626\n",
      "epoch 68; iter: 0; batch classifier loss: 0.435180; batch adversarial loss: 0.553781\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457189; batch adversarial loss: 0.562229\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425056; batch adversarial loss: 0.625929\n",
      "epoch 71; iter: 0; batch classifier loss: 0.305553; batch adversarial loss: 0.572065\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376591; batch adversarial loss: 0.569668\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395267; batch adversarial loss: 0.537490\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391436; batch adversarial loss: 0.521354\n",
      "epoch 75; iter: 0; batch classifier loss: 0.459149; batch adversarial loss: 0.522017\n",
      "epoch 76; iter: 0; batch classifier loss: 0.450687; batch adversarial loss: 0.540717\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425801; batch adversarial loss: 0.520820\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406041; batch adversarial loss: 0.475775\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379835; batch adversarial loss: 0.598053\n",
      "epoch 80; iter: 0; batch classifier loss: 0.382919; batch adversarial loss: 0.574409\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404089; batch adversarial loss: 0.566413\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404045; batch adversarial loss: 0.500541\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367010; batch adversarial loss: 0.518461\n",
      "epoch 84; iter: 0; batch classifier loss: 0.438836; batch adversarial loss: 0.581077\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365501; batch adversarial loss: 0.546817\n",
      "epoch 86; iter: 0; batch classifier loss: 0.436172; batch adversarial loss: 0.669067\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345310; batch adversarial loss: 0.518302\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441065; batch adversarial loss: 0.491059\n",
      "epoch 89; iter: 0; batch classifier loss: 0.449688; batch adversarial loss: 0.537272\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425996; batch adversarial loss: 0.579433\n",
      "epoch 91; iter: 0; batch classifier loss: 0.419399; batch adversarial loss: 0.581268\n",
      "epoch 92; iter: 0; batch classifier loss: 0.416253; batch adversarial loss: 0.563139\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400629; batch adversarial loss: 0.481154\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385161; batch adversarial loss: 0.535759\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413933; batch adversarial loss: 0.435372\n",
      "epoch 96; iter: 0; batch classifier loss: 0.434141; batch adversarial loss: 0.581941\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386840; batch adversarial loss: 0.544759\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385223; batch adversarial loss: 0.625471\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460063; batch adversarial loss: 0.562389\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390949; batch adversarial loss: 0.517348\n",
      "epoch 101; iter: 0; batch classifier loss: 0.466265; batch adversarial loss: 0.498335\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393131; batch adversarial loss: 0.489654\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381245; batch adversarial loss: 0.518400\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374915; batch adversarial loss: 0.526134\n",
      "epoch 105; iter: 0; batch classifier loss: 0.481420; batch adversarial loss: 0.617782\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378828; batch adversarial loss: 0.499628\n",
      "epoch 107; iter: 0; batch classifier loss: 0.360650; batch adversarial loss: 0.563479\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413735; batch adversarial loss: 0.553078\n",
      "epoch 109; iter: 0; batch classifier loss: 0.442820; batch adversarial loss: 0.528369\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402619; batch adversarial loss: 0.535471\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361467; batch adversarial loss: 0.607730\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394502; batch adversarial loss: 0.499410\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392728; batch adversarial loss: 0.498560\n",
      "epoch 114; iter: 0; batch classifier loss: 0.313001; batch adversarial loss: 0.544615\n",
      "epoch 115; iter: 0; batch classifier loss: 0.403449; batch adversarial loss: 0.544284\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402038; batch adversarial loss: 0.517908\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348425; batch adversarial loss: 0.535566\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381705; batch adversarial loss: 0.544395\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395278; batch adversarial loss: 0.553808\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406426; batch adversarial loss: 0.599382\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341742; batch adversarial loss: 0.590631\n",
      "epoch 122; iter: 0; batch classifier loss: 0.340311; batch adversarial loss: 0.490169\n",
      "epoch 123; iter: 0; batch classifier loss: 0.405439; batch adversarial loss: 0.580781\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346204; batch adversarial loss: 0.535819\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361429; batch adversarial loss: 0.544337\n",
      "epoch 126; iter: 0; batch classifier loss: 0.308917; batch adversarial loss: 0.517400\n",
      "epoch 127; iter: 0; batch classifier loss: 0.400886; batch adversarial loss: 0.572174\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381288; batch adversarial loss: 0.563536\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350768; batch adversarial loss: 0.535161\n",
      "epoch 130; iter: 0; batch classifier loss: 0.426589; batch adversarial loss: 0.526003\n",
      "epoch 131; iter: 0; batch classifier loss: 0.341738; batch adversarial loss: 0.562870\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415398; batch adversarial loss: 0.544849\n",
      "epoch 133; iter: 0; batch classifier loss: 0.317261; batch adversarial loss: 0.543581\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390822; batch adversarial loss: 0.554064\n",
      "epoch 135; iter: 0; batch classifier loss: 0.386933; batch adversarial loss: 0.580517\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369481; batch adversarial loss: 0.508490\n",
      "epoch 137; iter: 0; batch classifier loss: 0.293275; batch adversarial loss: 0.608105\n",
      "epoch 138; iter: 0; batch classifier loss: 0.333194; batch adversarial loss: 0.562256\n",
      "epoch 139; iter: 0; batch classifier loss: 0.396958; batch adversarial loss: 0.570692\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375992; batch adversarial loss: 0.535323\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434836; batch adversarial loss: 0.581410\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318232; batch adversarial loss: 0.590318\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361630; batch adversarial loss: 0.563178\n",
      "epoch 144; iter: 0; batch classifier loss: 0.422911; batch adversarial loss: 0.499383\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349552; batch adversarial loss: 0.544433\n",
      "epoch 146; iter: 0; batch classifier loss: 0.354407; batch adversarial loss: 0.608479\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361026; batch adversarial loss: 0.544490\n",
      "epoch 148; iter: 0; batch classifier loss: 0.309451; batch adversarial loss: 0.581544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.428486; batch adversarial loss: 0.508243\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381847; batch adversarial loss: 0.608270\n",
      "epoch 151; iter: 0; batch classifier loss: 0.383312; batch adversarial loss: 0.617743\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342480; batch adversarial loss: 0.498845\n",
      "epoch 153; iter: 0; batch classifier loss: 0.312044; batch adversarial loss: 0.554097\n",
      "epoch 154; iter: 0; batch classifier loss: 0.364747; batch adversarial loss: 0.524942\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413832; batch adversarial loss: 0.470578\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355984; batch adversarial loss: 0.564648\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399290; batch adversarial loss: 0.589891\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321612; batch adversarial loss: 0.535106\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322192; batch adversarial loss: 0.451771\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314570; batch adversarial loss: 0.561901\n",
      "epoch 161; iter: 0; batch classifier loss: 0.302300; batch adversarial loss: 0.490630\n",
      "epoch 162; iter: 0; batch classifier loss: 0.425382; batch adversarial loss: 0.618961\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369974; batch adversarial loss: 0.624393\n",
      "epoch 164; iter: 0; batch classifier loss: 0.444600; batch adversarial loss: 0.534536\n",
      "epoch 165; iter: 0; batch classifier loss: 0.351339; batch adversarial loss: 0.599428\n",
      "epoch 166; iter: 0; batch classifier loss: 0.362278; batch adversarial loss: 0.580108\n",
      "epoch 167; iter: 0; batch classifier loss: 0.309691; batch adversarial loss: 0.562508\n",
      "epoch 168; iter: 0; batch classifier loss: 0.399955; batch adversarial loss: 0.517235\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342360; batch adversarial loss: 0.544819\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355391; batch adversarial loss: 0.554039\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349245; batch adversarial loss: 0.607913\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353164; batch adversarial loss: 0.617412\n",
      "epoch 173; iter: 0; batch classifier loss: 0.397876; batch adversarial loss: 0.470698\n",
      "epoch 174; iter: 0; batch classifier loss: 0.460860; batch adversarial loss: 0.461166\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395384; batch adversarial loss: 0.499511\n",
      "epoch 176; iter: 0; batch classifier loss: 0.331582; batch adversarial loss: 0.617156\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362920; batch adversarial loss: 0.489348\n",
      "epoch 178; iter: 0; batch classifier loss: 0.275636; batch adversarial loss: 0.571031\n",
      "epoch 179; iter: 0; batch classifier loss: 0.365732; batch adversarial loss: 0.563291\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366509; batch adversarial loss: 0.509592\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342559; batch adversarial loss: 0.517728\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333395; batch adversarial loss: 0.477973\n",
      "epoch 183; iter: 0; batch classifier loss: 0.415765; batch adversarial loss: 0.562447\n",
      "epoch 184; iter: 0; batch classifier loss: 0.367580; batch adversarial loss: 0.528757\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391399; batch adversarial loss: 0.553689\n",
      "epoch 186; iter: 0; batch classifier loss: 0.302963; batch adversarial loss: 0.578639\n",
      "epoch 187; iter: 0; batch classifier loss: 0.337103; batch adversarial loss: 0.585174\n",
      "epoch 188; iter: 0; batch classifier loss: 0.288387; batch adversarial loss: 0.608479\n",
      "epoch 189; iter: 0; batch classifier loss: 0.392519; batch adversarial loss: 0.629097\n",
      "epoch 190; iter: 0; batch classifier loss: 0.337692; batch adversarial loss: 0.614732\n",
      "epoch 191; iter: 0; batch classifier loss: 0.399830; batch adversarial loss: 0.563114\n",
      "epoch 192; iter: 0; batch classifier loss: 0.316518; batch adversarial loss: 0.562969\n",
      "epoch 193; iter: 0; batch classifier loss: 0.380803; batch adversarial loss: 0.508108\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360563; batch adversarial loss: 0.554180\n",
      "epoch 195; iter: 0; batch classifier loss: 0.295335; batch adversarial loss: 0.591172\n",
      "epoch 196; iter: 0; batch classifier loss: 0.427555; batch adversarial loss: 0.545817\n",
      "epoch 197; iter: 0; batch classifier loss: 0.461297; batch adversarial loss: 0.546477\n",
      "epoch 198; iter: 0; batch classifier loss: 0.327165; batch adversarial loss: 0.615803\n",
      "epoch 199; iter: 0; batch classifier loss: 0.409221; batch adversarial loss: 0.599453\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692746; batch adversarial loss: 0.793967\n",
      "epoch 1; iter: 0; batch classifier loss: 0.766604; batch adversarial loss: 0.851877\n",
      "epoch 2; iter: 0; batch classifier loss: 0.833532; batch adversarial loss: 0.790511\n",
      "epoch 3; iter: 0; batch classifier loss: 0.816426; batch adversarial loss: 0.697980\n",
      "epoch 4; iter: 0; batch classifier loss: 0.670042; batch adversarial loss: 0.672772\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534051; batch adversarial loss: 0.623694\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597690; batch adversarial loss: 0.617836\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578834; batch adversarial loss: 0.625279\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569403; batch adversarial loss: 0.588581\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525269; batch adversarial loss: 0.585104\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541415; batch adversarial loss: 0.602646\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574377; batch adversarial loss: 0.629021\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509425; batch adversarial loss: 0.687559\n",
      "epoch 13; iter: 0; batch classifier loss: 0.591114; batch adversarial loss: 0.584411\n",
      "epoch 14; iter: 0; batch classifier loss: 0.571715; batch adversarial loss: 0.580456\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498673; batch adversarial loss: 0.647228\n",
      "epoch 16; iter: 0; batch classifier loss: 0.432974; batch adversarial loss: 0.584278\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496348; batch adversarial loss: 0.559158\n",
      "epoch 18; iter: 0; batch classifier loss: 0.495489; batch adversarial loss: 0.531039\n",
      "epoch 19; iter: 0; batch classifier loss: 0.529661; batch adversarial loss: 0.565361\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483200; batch adversarial loss: 0.500263\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470612; batch adversarial loss: 0.584985\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446443; batch adversarial loss: 0.562338\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480657; batch adversarial loss: 0.540304\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475647; batch adversarial loss: 0.536274\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485176; batch adversarial loss: 0.536647\n",
      "epoch 26; iter: 0; batch classifier loss: 0.449623; batch adversarial loss: 0.538189\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473177; batch adversarial loss: 0.528922\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499636; batch adversarial loss: 0.532122\n",
      "epoch 29; iter: 0; batch classifier loss: 0.410984; batch adversarial loss: 0.615327\n",
      "epoch 30; iter: 0; batch classifier loss: 0.541336; batch adversarial loss: 0.508300\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506268; batch adversarial loss: 0.527074\n",
      "epoch 32; iter: 0; batch classifier loss: 0.501124; batch adversarial loss: 0.574129\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503821; batch adversarial loss: 0.586142\n",
      "epoch 34; iter: 0; batch classifier loss: 0.578378; batch adversarial loss: 0.575189\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433528; batch adversarial loss: 0.576557\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353763; batch adversarial loss: 0.587915\n",
      "epoch 37; iter: 0; batch classifier loss: 0.335479; batch adversarial loss: 0.588015\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398159; batch adversarial loss: 0.595210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443821; batch adversarial loss: 0.611188\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447150; batch adversarial loss: 0.553647\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447844; batch adversarial loss: 0.597109\n",
      "epoch 42; iter: 0; batch classifier loss: 0.565555; batch adversarial loss: 0.528384\n",
      "epoch 43; iter: 0; batch classifier loss: 0.501259; batch adversarial loss: 0.465308\n",
      "epoch 44; iter: 0; batch classifier loss: 0.357935; batch adversarial loss: 0.528618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.475951; batch adversarial loss: 0.590581\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447565; batch adversarial loss: 0.568633\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410365; batch adversarial loss: 0.526389\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452727; batch adversarial loss: 0.602688\n",
      "epoch 49; iter: 0; batch classifier loss: 0.364094; batch adversarial loss: 0.524638\n",
      "epoch 50; iter: 0; batch classifier loss: 0.381869; batch adversarial loss: 0.569585\n",
      "epoch 51; iter: 0; batch classifier loss: 0.365180; batch adversarial loss: 0.557961\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417943; batch adversarial loss: 0.630505\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411573; batch adversarial loss: 0.569147\n",
      "epoch 54; iter: 0; batch classifier loss: 0.490252; batch adversarial loss: 0.537338\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397088; batch adversarial loss: 0.568344\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454047; batch adversarial loss: 0.509785\n",
      "epoch 57; iter: 0; batch classifier loss: 0.430774; batch adversarial loss: 0.527038\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407994; batch adversarial loss: 0.500542\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422675; batch adversarial loss: 0.596665\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416535; batch adversarial loss: 0.536073\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429076; batch adversarial loss: 0.675379\n",
      "epoch 62; iter: 0; batch classifier loss: 0.354600; batch adversarial loss: 0.569932\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387147; batch adversarial loss: 0.553919\n",
      "epoch 64; iter: 0; batch classifier loss: 0.368981; batch adversarial loss: 0.534826\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419832; batch adversarial loss: 0.534971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.333021; batch adversarial loss: 0.578997\n",
      "epoch 67; iter: 0; batch classifier loss: 0.439866; batch adversarial loss: 0.563131\n",
      "epoch 68; iter: 0; batch classifier loss: 0.333098; batch adversarial loss: 0.613631\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401707; batch adversarial loss: 0.588737\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368589; batch adversarial loss: 0.587677\n",
      "epoch 71; iter: 0; batch classifier loss: 0.367541; batch adversarial loss: 0.553774\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385920; batch adversarial loss: 0.641023\n",
      "epoch 73; iter: 0; batch classifier loss: 0.362594; batch adversarial loss: 0.623762\n",
      "epoch 74; iter: 0; batch classifier loss: 0.435739; batch adversarial loss: 0.616216\n",
      "epoch 75; iter: 0; batch classifier loss: 0.372560; batch adversarial loss: 0.509293\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376069; batch adversarial loss: 0.634006\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393629; batch adversarial loss: 0.570930\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392360; batch adversarial loss: 0.536281\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452717; batch adversarial loss: 0.526075\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371108; batch adversarial loss: 0.553200\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385258; batch adversarial loss: 0.545338\n",
      "epoch 82; iter: 0; batch classifier loss: 0.318754; batch adversarial loss: 0.510169\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374247; batch adversarial loss: 0.624471\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402405; batch adversarial loss: 0.571338\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404562; batch adversarial loss: 0.517814\n",
      "epoch 86; iter: 0; batch classifier loss: 0.314730; batch adversarial loss: 0.527100\n",
      "epoch 87; iter: 0; batch classifier loss: 0.361015; batch adversarial loss: 0.535899\n",
      "epoch 88; iter: 0; batch classifier loss: 0.466232; batch adversarial loss: 0.535673\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355552; batch adversarial loss: 0.509565\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350723; batch adversarial loss: 0.545513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403630; batch adversarial loss: 0.562574\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354923; batch adversarial loss: 0.579741\n",
      "epoch 93; iter: 0; batch classifier loss: 0.436911; batch adversarial loss: 0.624491\n",
      "epoch 94; iter: 0; batch classifier loss: 0.323088; batch adversarial loss: 0.562169\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391135; batch adversarial loss: 0.553929\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389133; batch adversarial loss: 0.536081\n",
      "epoch 97; iter: 0; batch classifier loss: 0.345541; batch adversarial loss: 0.553530\n",
      "epoch 98; iter: 0; batch classifier loss: 0.346458; batch adversarial loss: 0.509398\n",
      "epoch 99; iter: 0; batch classifier loss: 0.296578; batch adversarial loss: 0.527159\n",
      "epoch 100; iter: 0; batch classifier loss: 0.356807; batch adversarial loss: 0.518030\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393739; batch adversarial loss: 0.570811\n",
      "epoch 102; iter: 0; batch classifier loss: 0.360906; batch adversarial loss: 0.536412\n",
      "epoch 103; iter: 0; batch classifier loss: 0.353532; batch adversarial loss: 0.526782\n",
      "epoch 104; iter: 0; batch classifier loss: 0.332240; batch adversarial loss: 0.500893\n",
      "epoch 105; iter: 0; batch classifier loss: 0.335018; batch adversarial loss: 0.597661\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326952; batch adversarial loss: 0.642051\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358360; batch adversarial loss: 0.518175\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387346; batch adversarial loss: 0.562271\n",
      "epoch 109; iter: 0; batch classifier loss: 0.441643; batch adversarial loss: 0.562671\n",
      "epoch 110; iter: 0; batch classifier loss: 0.409667; batch adversarial loss: 0.544721\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367613; batch adversarial loss: 0.633304\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366445; batch adversarial loss: 0.535786\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355386; batch adversarial loss: 0.553199\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388130; batch adversarial loss: 0.553972\n",
      "epoch 115; iter: 0; batch classifier loss: 0.319860; batch adversarial loss: 0.589496\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343327; batch adversarial loss: 0.570922\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346393; batch adversarial loss: 0.553880\n",
      "epoch 118; iter: 0; batch classifier loss: 0.312086; batch adversarial loss: 0.625163\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377121; batch adversarial loss: 0.570962\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386832; batch adversarial loss: 0.483192\n",
      "epoch 121; iter: 0; batch classifier loss: 0.457685; batch adversarial loss: 0.562778\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367263; batch adversarial loss: 0.466275\n",
      "epoch 123; iter: 0; batch classifier loss: 0.383542; batch adversarial loss: 0.518293\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340481; batch adversarial loss: 0.517012\n",
      "epoch 125; iter: 0; batch classifier loss: 0.304385; batch adversarial loss: 0.625163\n",
      "epoch 126; iter: 0; batch classifier loss: 0.297147; batch adversarial loss: 0.606436\n",
      "epoch 127; iter: 0; batch classifier loss: 0.361677; batch adversarial loss: 0.553562\n",
      "epoch 128; iter: 0; batch classifier loss: 0.386754; batch adversarial loss: 0.517936\n",
      "epoch 129; iter: 0; batch classifier loss: 0.299012; batch adversarial loss: 0.500328\n",
      "epoch 130; iter: 0; batch classifier loss: 0.314077; batch adversarial loss: 0.553001\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350669; batch adversarial loss: 0.544306\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373974; batch adversarial loss: 0.508008\n",
      "epoch 133; iter: 0; batch classifier loss: 0.321122; batch adversarial loss: 0.508848\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349474; batch adversarial loss: 0.447775\n",
      "epoch 135; iter: 0; batch classifier loss: 0.300532; batch adversarial loss: 0.554264\n",
      "epoch 136; iter: 0; batch classifier loss: 0.362182; batch adversarial loss: 0.491151\n",
      "epoch 137; iter: 0; batch classifier loss: 0.289320; batch adversarial loss: 0.528219\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404071; batch adversarial loss: 0.560205\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334986; batch adversarial loss: 0.589459\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342271; batch adversarial loss: 0.491308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.419480; batch adversarial loss: 0.535114\n",
      "epoch 142; iter: 0; batch classifier loss: 0.292205; batch adversarial loss: 0.498271\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329720; batch adversarial loss: 0.578857\n",
      "epoch 144; iter: 0; batch classifier loss: 0.429495; batch adversarial loss: 0.552555\n",
      "epoch 145; iter: 0; batch classifier loss: 0.425268; batch adversarial loss: 0.602331\n",
      "epoch 146; iter: 0; batch classifier loss: 0.294276; batch adversarial loss: 0.472607\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350041; batch adversarial loss: 0.580579\n",
      "epoch 148; iter: 0; batch classifier loss: 0.286234; batch adversarial loss: 0.564866\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363091; batch adversarial loss: 0.493662\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381057; batch adversarial loss: 0.475482\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368019; batch adversarial loss: 0.518862\n",
      "epoch 152; iter: 0; batch classifier loss: 0.315430; batch adversarial loss: 0.605990\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386522; batch adversarial loss: 0.659400\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412669; batch adversarial loss: 0.509139\n",
      "epoch 155; iter: 0; batch classifier loss: 0.427411; batch adversarial loss: 0.509705\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314028; batch adversarial loss: 0.528823\n",
      "epoch 157; iter: 0; batch classifier loss: 0.452231; batch adversarial loss: 0.597820\n",
      "epoch 158; iter: 0; batch classifier loss: 0.435461; batch adversarial loss: 0.694054\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346380; batch adversarial loss: 0.607031\n",
      "epoch 160; iter: 0; batch classifier loss: 0.391196; batch adversarial loss: 0.632628\n",
      "epoch 161; iter: 0; batch classifier loss: 0.290723; batch adversarial loss: 0.588253\n",
      "epoch 162; iter: 0; batch classifier loss: 0.318666; batch adversarial loss: 0.518359\n",
      "epoch 163; iter: 0; batch classifier loss: 0.320637; batch adversarial loss: 0.518220\n",
      "epoch 164; iter: 0; batch classifier loss: 0.293138; batch adversarial loss: 0.482998\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333762; batch adversarial loss: 0.571545\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358051; batch adversarial loss: 0.606610\n",
      "epoch 167; iter: 0; batch classifier loss: 0.313328; batch adversarial loss: 0.500654\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343685; batch adversarial loss: 0.597744\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360422; batch adversarial loss: 0.607197\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378543; batch adversarial loss: 0.526598\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409596; batch adversarial loss: 0.606496\n",
      "epoch 172; iter: 0; batch classifier loss: 0.304358; batch adversarial loss: 0.430698\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316391; batch adversarial loss: 0.624733\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381003; batch adversarial loss: 0.518000\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351907; batch adversarial loss: 0.554831\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368819; batch adversarial loss: 0.544527\n",
      "epoch 177; iter: 0; batch classifier loss: 0.408651; batch adversarial loss: 0.597451\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368705; batch adversarial loss: 0.500507\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345535; batch adversarial loss: 0.509012\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359936; batch adversarial loss: 0.429989\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347125; batch adversarial loss: 0.545166\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375094; batch adversarial loss: 0.554206\n",
      "epoch 183; iter: 0; batch classifier loss: 0.297495; batch adversarial loss: 0.544477\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313326; batch adversarial loss: 0.481986\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397753; batch adversarial loss: 0.455774\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340894; batch adversarial loss: 0.561936\n",
      "epoch 187; iter: 0; batch classifier loss: 0.378584; batch adversarial loss: 0.579945\n",
      "epoch 188; iter: 0; batch classifier loss: 0.339496; batch adversarial loss: 0.545252\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379639; batch adversarial loss: 0.518637\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395671; batch adversarial loss: 0.571634\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360331; batch adversarial loss: 0.562104\n",
      "epoch 192; iter: 0; batch classifier loss: 0.316387; batch adversarial loss: 0.518567\n",
      "epoch 193; iter: 0; batch classifier loss: 0.299548; batch adversarial loss: 0.553783\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335250; batch adversarial loss: 0.491499\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339079; batch adversarial loss: 0.527272\n",
      "epoch 196; iter: 0; batch classifier loss: 0.397562; batch adversarial loss: 0.615668\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315214; batch adversarial loss: 0.580377\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389115; batch adversarial loss: 0.492401\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340401; batch adversarial loss: 0.562215\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671560; batch adversarial loss: 0.616246\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603496; batch adversarial loss: 0.627522\n",
      "epoch 2; iter: 0; batch classifier loss: 0.608641; batch adversarial loss: 0.657895\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641278; batch adversarial loss: 0.627092\n",
      "epoch 4; iter: 0; batch classifier loss: 0.560990; batch adversarial loss: 0.652919\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533234; batch adversarial loss: 0.566978\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599818; batch adversarial loss: 0.591959\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553453; batch adversarial loss: 0.630029\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560157; batch adversarial loss: 0.537834\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563147; batch adversarial loss: 0.593967\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569147; batch adversarial loss: 0.583077\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506520; batch adversarial loss: 0.554909\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517135; batch adversarial loss: 0.530705\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527225; batch adversarial loss: 0.532305\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532763; batch adversarial loss: 0.545169\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506453; batch adversarial loss: 0.579583\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507761; batch adversarial loss: 0.477873\n",
      "epoch 17; iter: 0; batch classifier loss: 0.589137; batch adversarial loss: 0.577510\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489406; batch adversarial loss: 0.492527\n",
      "epoch 19; iter: 0; batch classifier loss: 0.464598; batch adversarial loss: 0.540504\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499589; batch adversarial loss: 0.496581\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499031; batch adversarial loss: 0.555046\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467983; batch adversarial loss: 0.558554\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538248; batch adversarial loss: 0.600586\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506967; batch adversarial loss: 0.588442\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498697; batch adversarial loss: 0.574900\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506999; batch adversarial loss: 0.564149\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451551; batch adversarial loss: 0.542429\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516957; batch adversarial loss: 0.626933\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509749; batch adversarial loss: 0.477675\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485885; batch adversarial loss: 0.555598\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449604; batch adversarial loss: 0.572055\n",
      "epoch 32; iter: 0; batch classifier loss: 0.550830; batch adversarial loss: 0.566656\n",
      "epoch 33; iter: 0; batch classifier loss: 0.531406; batch adversarial loss: 0.546179\n",
      "epoch 34; iter: 0; batch classifier loss: 0.520056; batch adversarial loss: 0.551499\n",
      "epoch 35; iter: 0; batch classifier loss: 0.462072; batch adversarial loss: 0.535495\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449472; batch adversarial loss: 0.499564\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465788; batch adversarial loss: 0.554542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.497089; batch adversarial loss: 0.554733\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479513; batch adversarial loss: 0.499520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484474; batch adversarial loss: 0.468672\n",
      "epoch 41; iter: 0; batch classifier loss: 0.342885; batch adversarial loss: 0.553806\n",
      "epoch 42; iter: 0; batch classifier loss: 0.330524; batch adversarial loss: 0.535854\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463248; batch adversarial loss: 0.477530\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493565; batch adversarial loss: 0.478177\n",
      "epoch 45; iter: 0; batch classifier loss: 0.499975; batch adversarial loss: 0.496356\n",
      "epoch 46; iter: 0; batch classifier loss: 0.450334; batch adversarial loss: 0.515204\n",
      "epoch 47; iter: 0; batch classifier loss: 0.445526; batch adversarial loss: 0.627716\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440619; batch adversarial loss: 0.497908\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384805; batch adversarial loss: 0.564058\n",
      "epoch 50; iter: 0; batch classifier loss: 0.482317; batch adversarial loss: 0.525230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411528; batch adversarial loss: 0.631868\n",
      "epoch 52; iter: 0; batch classifier loss: 0.527144; batch adversarial loss: 0.477639\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449931; batch adversarial loss: 0.555670\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435813; batch adversarial loss: 0.506807\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404074; batch adversarial loss: 0.497616\n",
      "epoch 56; iter: 0; batch classifier loss: 0.459024; batch adversarial loss: 0.573614\n",
      "epoch 57; iter: 0; batch classifier loss: 0.510090; batch adversarial loss: 0.544782\n",
      "epoch 58; iter: 0; batch classifier loss: 0.502312; batch adversarial loss: 0.573167\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429815; batch adversarial loss: 0.410309\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447596; batch adversarial loss: 0.564603\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421224; batch adversarial loss: 0.506787\n",
      "epoch 62; iter: 0; batch classifier loss: 0.468651; batch adversarial loss: 0.545056\n",
      "epoch 63; iter: 0; batch classifier loss: 0.407447; batch adversarial loss: 0.535364\n",
      "epoch 64; iter: 0; batch classifier loss: 0.467490; batch adversarial loss: 0.573206\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423535; batch adversarial loss: 0.582319\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443362; batch adversarial loss: 0.591324\n",
      "epoch 67; iter: 0; batch classifier loss: 0.397494; batch adversarial loss: 0.487195\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434020; batch adversarial loss: 0.507435\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376070; batch adversarial loss: 0.525025\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423314; batch adversarial loss: 0.563772\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414384; batch adversarial loss: 0.554470\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455576; batch adversarial loss: 0.544683\n",
      "epoch 73; iter: 0; batch classifier loss: 0.345116; batch adversarial loss: 0.450166\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405561; batch adversarial loss: 0.497129\n",
      "epoch 75; iter: 0; batch classifier loss: 0.499901; batch adversarial loss: 0.477953\n",
      "epoch 76; iter: 0; batch classifier loss: 0.452419; batch adversarial loss: 0.525246\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399501; batch adversarial loss: 0.468585\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390719; batch adversarial loss: 0.592188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422952; batch adversarial loss: 0.535313\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363121; batch adversarial loss: 0.486854\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427753; batch adversarial loss: 0.486129\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383488; batch adversarial loss: 0.525183\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377058; batch adversarial loss: 0.574014\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384283; batch adversarial loss: 0.582358\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410767; batch adversarial loss: 0.535117\n",
      "epoch 86; iter: 0; batch classifier loss: 0.306047; batch adversarial loss: 0.516765\n",
      "epoch 87; iter: 0; batch classifier loss: 0.452145; batch adversarial loss: 0.610422\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425375; batch adversarial loss: 0.497460\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405237; batch adversarial loss: 0.591540\n",
      "epoch 90; iter: 0; batch classifier loss: 0.454359; batch adversarial loss: 0.591767\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362499; batch adversarial loss: 0.516254\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366688; batch adversarial loss: 0.468552\n",
      "epoch 93; iter: 0; batch classifier loss: 0.521493; batch adversarial loss: 0.534757\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375763; batch adversarial loss: 0.497120\n",
      "epoch 95; iter: 0; batch classifier loss: 0.411200; batch adversarial loss: 0.564290\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381719; batch adversarial loss: 0.497207\n",
      "epoch 97; iter: 0; batch classifier loss: 0.387932; batch adversarial loss: 0.563567\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386996; batch adversarial loss: 0.525839\n",
      "epoch 99; iter: 0; batch classifier loss: 0.507731; batch adversarial loss: 0.525931\n",
      "epoch 100; iter: 0; batch classifier loss: 0.334163; batch adversarial loss: 0.582241\n",
      "epoch 101; iter: 0; batch classifier loss: 0.375169; batch adversarial loss: 0.621565\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426331; batch adversarial loss: 0.496344\n",
      "epoch 103; iter: 0; batch classifier loss: 0.446185; batch adversarial loss: 0.612436\n",
      "epoch 104; iter: 0; batch classifier loss: 0.345545; batch adversarial loss: 0.515623\n",
      "epoch 105; iter: 0; batch classifier loss: 0.513770; batch adversarial loss: 0.468441\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381671; batch adversarial loss: 0.611463\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403232; batch adversarial loss: 0.564576\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407770; batch adversarial loss: 0.592260\n",
      "epoch 109; iter: 0; batch classifier loss: 0.441478; batch adversarial loss: 0.582031\n",
      "epoch 110; iter: 0; batch classifier loss: 0.338665; batch adversarial loss: 0.563397\n",
      "epoch 111; iter: 0; batch classifier loss: 0.392655; batch adversarial loss: 0.563350\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412528; batch adversarial loss: 0.592172\n",
      "epoch 113; iter: 0; batch classifier loss: 0.436967; batch adversarial loss: 0.515943\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373758; batch adversarial loss: 0.515889\n",
      "epoch 115; iter: 0; batch classifier loss: 0.425174; batch adversarial loss: 0.554325\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365322; batch adversarial loss: 0.431047\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350042; batch adversarial loss: 0.553892\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370160; batch adversarial loss: 0.582499\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410893; batch adversarial loss: 0.506720\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377837; batch adversarial loss: 0.458948\n",
      "epoch 121; iter: 0; batch classifier loss: 0.402129; batch adversarial loss: 0.506560\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387712; batch adversarial loss: 0.620791\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357669; batch adversarial loss: 0.534570\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372664; batch adversarial loss: 0.497222\n",
      "epoch 125; iter: 0; batch classifier loss: 0.385061; batch adversarial loss: 0.478752\n",
      "epoch 126; iter: 0; batch classifier loss: 0.429269; batch adversarial loss: 0.554178\n",
      "epoch 127; iter: 0; batch classifier loss: 0.359841; batch adversarial loss: 0.535696\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376166; batch adversarial loss: 0.506748\n",
      "epoch 129; iter: 0; batch classifier loss: 0.408931; batch adversarial loss: 0.544881\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405473; batch adversarial loss: 0.477684\n",
      "epoch 131; iter: 0; batch classifier loss: 0.378804; batch adversarial loss: 0.592457\n",
      "epoch 132; iter: 0; batch classifier loss: 0.430872; batch adversarial loss: 0.506198\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340711; batch adversarial loss: 0.506447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.371387; batch adversarial loss: 0.553723\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397311; batch adversarial loss: 0.487638\n",
      "epoch 136; iter: 0; batch classifier loss: 0.413456; batch adversarial loss: 0.496744\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348749; batch adversarial loss: 0.457535\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335430; batch adversarial loss: 0.593665\n",
      "epoch 139; iter: 0; batch classifier loss: 0.478401; batch adversarial loss: 0.507252\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366940; batch adversarial loss: 0.534927\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351619; batch adversarial loss: 0.563570\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362313; batch adversarial loss: 0.516584\n",
      "epoch 143; iter: 0; batch classifier loss: 0.416789; batch adversarial loss: 0.620817\n",
      "epoch 144; iter: 0; batch classifier loss: 0.490896; batch adversarial loss: 0.544770\n",
      "epoch 145; iter: 0; batch classifier loss: 0.429617; batch adversarial loss: 0.506426\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399591; batch adversarial loss: 0.525527\n",
      "epoch 147; iter: 0; batch classifier loss: 0.424180; batch adversarial loss: 0.583536\n",
      "epoch 148; iter: 0; batch classifier loss: 0.388931; batch adversarial loss: 0.495548\n",
      "epoch 149; iter: 0; batch classifier loss: 0.413790; batch adversarial loss: 0.487054\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363728; batch adversarial loss: 0.524666\n",
      "epoch 151; iter: 0; batch classifier loss: 0.416074; batch adversarial loss: 0.593476\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354434; batch adversarial loss: 0.552186\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361678; batch adversarial loss: 0.552763\n",
      "epoch 154; iter: 0; batch classifier loss: 0.439125; batch adversarial loss: 0.469530\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413867; batch adversarial loss: 0.564308\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354664; batch adversarial loss: 0.506602\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403635; batch adversarial loss: 0.523626\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343620; batch adversarial loss: 0.512123\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346993; batch adversarial loss: 0.545051\n",
      "epoch 160; iter: 0; batch classifier loss: 0.361848; batch adversarial loss: 0.556647\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361307; batch adversarial loss: 0.556558\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379466; batch adversarial loss: 0.447819\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338475; batch adversarial loss: 0.572898\n",
      "epoch 164; iter: 0; batch classifier loss: 0.475362; batch adversarial loss: 0.478392\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358006; batch adversarial loss: 0.506349\n",
      "epoch 166; iter: 0; batch classifier loss: 0.475781; batch adversarial loss: 0.516292\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363289; batch adversarial loss: 0.497045\n",
      "epoch 168; iter: 0; batch classifier loss: 0.402724; batch adversarial loss: 0.544409\n",
      "epoch 169; iter: 0; batch classifier loss: 0.493079; batch adversarial loss: 0.563453\n",
      "epoch 170; iter: 0; batch classifier loss: 0.340594; batch adversarial loss: 0.649216\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348608; batch adversarial loss: 0.592779\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317134; batch adversarial loss: 0.572370\n",
      "epoch 173; iter: 0; batch classifier loss: 0.311032; batch adversarial loss: 0.524502\n",
      "epoch 174; iter: 0; batch classifier loss: 0.313796; batch adversarial loss: 0.650695\n",
      "epoch 175; iter: 0; batch classifier loss: 0.389676; batch adversarial loss: 0.524579\n",
      "epoch 176; iter: 0; batch classifier loss: 0.306613; batch adversarial loss: 0.583146\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374334; batch adversarial loss: 0.524806\n",
      "epoch 178; iter: 0; batch classifier loss: 0.395696; batch adversarial loss: 0.524095\n",
      "epoch 179; iter: 0; batch classifier loss: 0.427350; batch adversarial loss: 0.487359\n",
      "epoch 180; iter: 0; batch classifier loss: 0.348485; batch adversarial loss: 0.554742\n",
      "epoch 181; iter: 0; batch classifier loss: 0.298310; batch adversarial loss: 0.555309\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371612; batch adversarial loss: 0.544828\n",
      "epoch 183; iter: 0; batch classifier loss: 0.310256; batch adversarial loss: 0.543491\n",
      "epoch 184; iter: 0; batch classifier loss: 0.449687; batch adversarial loss: 0.494405\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351082; batch adversarial loss: 0.611246\n",
      "epoch 186; iter: 0; batch classifier loss: 0.302420; batch adversarial loss: 0.562927\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332122; batch adversarial loss: 0.595222\n",
      "epoch 188; iter: 0; batch classifier loss: 0.445256; batch adversarial loss: 0.576006\n",
      "epoch 189; iter: 0; batch classifier loss: 0.427576; batch adversarial loss: 0.528439\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332796; batch adversarial loss: 0.472476\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357672; batch adversarial loss: 0.583454\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362232; batch adversarial loss: 0.504709\n",
      "epoch 193; iter: 0; batch classifier loss: 0.491100; batch adversarial loss: 0.439813\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308515; batch adversarial loss: 0.508320\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323630; batch adversarial loss: 0.487577\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356036; batch adversarial loss: 0.516333\n",
      "epoch 197; iter: 0; batch classifier loss: 0.325359; batch adversarial loss: 0.468968\n",
      "epoch 198; iter: 0; batch classifier loss: 0.300997; batch adversarial loss: 0.572548\n",
      "epoch 199; iter: 0; batch classifier loss: 0.418083; batch adversarial loss: 0.537572\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709183; batch adversarial loss: 0.748439\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591745; batch adversarial loss: 0.693694\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571075; batch adversarial loss: 0.656934\n",
      "epoch 3; iter: 0; batch classifier loss: 0.501900; batch adversarial loss: 0.656407\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555129; batch adversarial loss: 0.618218\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537599; batch adversarial loss: 0.613554\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549155; batch adversarial loss: 0.593397\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558289; batch adversarial loss: 0.579830\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495244; batch adversarial loss: 0.615918\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507536; batch adversarial loss: 0.624336\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489638; batch adversarial loss: 0.567592\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515582; batch adversarial loss: 0.580542\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564150; batch adversarial loss: 0.562241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525894; batch adversarial loss: 0.576687\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474014; batch adversarial loss: 0.554804\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487722; batch adversarial loss: 0.537699\n",
      "epoch 16; iter: 0; batch classifier loss: 0.603962; batch adversarial loss: 0.544154\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506335; batch adversarial loss: 0.504037\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460423; batch adversarial loss: 0.536943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508997; batch adversarial loss: 0.509777\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518981; batch adversarial loss: 0.561471\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491092; batch adversarial loss: 0.518482\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478628; batch adversarial loss: 0.489029\n",
      "epoch 23; iter: 0; batch classifier loss: 0.537918; batch adversarial loss: 0.566600\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435143; batch adversarial loss: 0.553227\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446210; batch adversarial loss: 0.618319\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455778; batch adversarial loss: 0.548141\n",
      "epoch 27; iter: 0; batch classifier loss: 0.539540; batch adversarial loss: 0.552437\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516906; batch adversarial loss: 0.560829\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477373; batch adversarial loss: 0.561886\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481336; batch adversarial loss: 0.574915\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501192; batch adversarial loss: 0.492829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.457460; batch adversarial loss: 0.647582\n",
      "epoch 33; iter: 0; batch classifier loss: 0.520697; batch adversarial loss: 0.476620\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426864; batch adversarial loss: 0.522931\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406902; batch adversarial loss: 0.515666\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440474; batch adversarial loss: 0.566051\n",
      "epoch 37; iter: 0; batch classifier loss: 0.501982; batch adversarial loss: 0.550895\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417528; batch adversarial loss: 0.570157\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442763; batch adversarial loss: 0.503041\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430885; batch adversarial loss: 0.461030\n",
      "epoch 41; iter: 0; batch classifier loss: 0.517032; batch adversarial loss: 0.603228\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411686; batch adversarial loss: 0.476430\n",
      "epoch 43; iter: 0; batch classifier loss: 0.488380; batch adversarial loss: 0.523281\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395620; batch adversarial loss: 0.590021\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412132; batch adversarial loss: 0.508205\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439998; batch adversarial loss: 0.605310\n",
      "epoch 47; iter: 0; batch classifier loss: 0.381714; batch adversarial loss: 0.449737\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442079; batch adversarial loss: 0.518608\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464288; batch adversarial loss: 0.544963\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394997; batch adversarial loss: 0.518388\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429009; batch adversarial loss: 0.537678\n",
      "epoch 52; iter: 0; batch classifier loss: 0.486210; batch adversarial loss: 0.542549\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421485; batch adversarial loss: 0.500183\n",
      "epoch 54; iter: 0; batch classifier loss: 0.498242; batch adversarial loss: 0.652521\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405956; batch adversarial loss: 0.544690\n",
      "epoch 56; iter: 0; batch classifier loss: 0.350191; batch adversarial loss: 0.475766\n",
      "epoch 57; iter: 0; batch classifier loss: 0.368565; batch adversarial loss: 0.517957\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386497; batch adversarial loss: 0.606998\n",
      "epoch 59; iter: 0; batch classifier loss: 0.436633; batch adversarial loss: 0.535131\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405290; batch adversarial loss: 0.544291\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426428; batch adversarial loss: 0.515951\n",
      "epoch 62; iter: 0; batch classifier loss: 0.480275; batch adversarial loss: 0.527498\n",
      "epoch 63; iter: 0; batch classifier loss: 0.318639; batch adversarial loss: 0.542891\n",
      "epoch 64; iter: 0; batch classifier loss: 0.368206; batch adversarial loss: 0.588566\n",
      "epoch 65; iter: 0; batch classifier loss: 0.495041; batch adversarial loss: 0.555505\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427517; batch adversarial loss: 0.507515\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435316; batch adversarial loss: 0.542674\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413209; batch adversarial loss: 0.596435\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433118; batch adversarial loss: 0.525270\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385348; batch adversarial loss: 0.459631\n",
      "epoch 71; iter: 0; batch classifier loss: 0.374510; batch adversarial loss: 0.581122\n",
      "epoch 72; iter: 0; batch classifier loss: 0.368327; batch adversarial loss: 0.509462\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407491; batch adversarial loss: 0.563243\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436367; batch adversarial loss: 0.470025\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357596; batch adversarial loss: 0.593322\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405287; batch adversarial loss: 0.599899\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442846; batch adversarial loss: 0.484154\n",
      "epoch 78; iter: 0; batch classifier loss: 0.451551; batch adversarial loss: 0.596807\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369780; batch adversarial loss: 0.562090\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411946; batch adversarial loss: 0.623968\n",
      "epoch 81; iter: 0; batch classifier loss: 0.363758; batch adversarial loss: 0.536812\n",
      "epoch 82; iter: 0; batch classifier loss: 0.461195; batch adversarial loss: 0.508261\n",
      "epoch 83; iter: 0; batch classifier loss: 0.483436; batch adversarial loss: 0.526929\n",
      "epoch 84; iter: 0; batch classifier loss: 0.539616; batch adversarial loss: 0.625136\n",
      "epoch 85; iter: 0; batch classifier loss: 0.338886; batch adversarial loss: 0.544898\n",
      "epoch 86; iter: 0; batch classifier loss: 0.462245; batch adversarial loss: 0.527508\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406700; batch adversarial loss: 0.599976\n",
      "epoch 88; iter: 0; batch classifier loss: 0.334354; batch adversarial loss: 0.572851\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374193; batch adversarial loss: 0.551742\n",
      "epoch 90; iter: 0; batch classifier loss: 0.382314; batch adversarial loss: 0.569961\n",
      "epoch 91; iter: 0; batch classifier loss: 0.431853; batch adversarial loss: 0.564143\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392232; batch adversarial loss: 0.544107\n",
      "epoch 93; iter: 0; batch classifier loss: 0.458317; batch adversarial loss: 0.525368\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406945; batch adversarial loss: 0.526487\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446566; batch adversarial loss: 0.562297\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438561; batch adversarial loss: 0.515948\n",
      "epoch 97; iter: 0; batch classifier loss: 0.332524; batch adversarial loss: 0.607720\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389297; batch adversarial loss: 0.591237\n",
      "epoch 99; iter: 0; batch classifier loss: 0.488001; batch adversarial loss: 0.609183\n",
      "epoch 100; iter: 0; batch classifier loss: 0.339877; batch adversarial loss: 0.508306\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417906; batch adversarial loss: 0.536851\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412500; batch adversarial loss: 0.535509\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414151; batch adversarial loss: 0.541976\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387531; batch adversarial loss: 0.596446\n",
      "epoch 105; iter: 0; batch classifier loss: 0.475357; batch adversarial loss: 0.560644\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413482; batch adversarial loss: 0.516860\n",
      "epoch 107; iter: 0; batch classifier loss: 0.317768; batch adversarial loss: 0.589832\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367363; batch adversarial loss: 0.614863\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402476; batch adversarial loss: 0.569429\n",
      "epoch 110; iter: 0; batch classifier loss: 0.413782; batch adversarial loss: 0.506205\n",
      "epoch 111; iter: 0; batch classifier loss: 0.397083; batch adversarial loss: 0.570516\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356713; batch adversarial loss: 0.592560\n",
      "epoch 113; iter: 0; batch classifier loss: 0.321641; batch adversarial loss: 0.599891\n",
      "epoch 114; iter: 0; batch classifier loss: 0.283909; batch adversarial loss: 0.553821\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354648; batch adversarial loss: 0.498209\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394200; batch adversarial loss: 0.589249\n",
      "epoch 117; iter: 0; batch classifier loss: 0.310072; batch adversarial loss: 0.554690\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387451; batch adversarial loss: 0.467408\n",
      "epoch 119; iter: 0; batch classifier loss: 0.389327; batch adversarial loss: 0.607583\n",
      "epoch 120; iter: 0; batch classifier loss: 0.310693; batch adversarial loss: 0.554005\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383181; batch adversarial loss: 0.634089\n",
      "epoch 122; iter: 0; batch classifier loss: 0.310947; batch adversarial loss: 0.591166\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368554; batch adversarial loss: 0.544344\n",
      "epoch 124; iter: 0; batch classifier loss: 0.313864; batch adversarial loss: 0.517715\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334302; batch adversarial loss: 0.535185\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396690; batch adversarial loss: 0.571417\n",
      "epoch 127; iter: 0; batch classifier loss: 0.321958; batch adversarial loss: 0.490219\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402482; batch adversarial loss: 0.553677\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.580186\n",
      "epoch 130; iter: 0; batch classifier loss: 0.562873; batch adversarial loss: 0.571265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.470556; batch adversarial loss: 0.562008\n",
      "epoch 132; iter: 0; batch classifier loss: 0.398756; batch adversarial loss: 0.562930\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347731; batch adversarial loss: 0.470158\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369437; batch adversarial loss: 0.589711\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361271; batch adversarial loss: 0.635236\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393757; batch adversarial loss: 0.463582\n",
      "epoch 137; iter: 0; batch classifier loss: 0.395558; batch adversarial loss: 0.533249\n",
      "epoch 138; iter: 0; batch classifier loss: 0.407606; batch adversarial loss: 0.543299\n",
      "epoch 139; iter: 0; batch classifier loss: 0.375641; batch adversarial loss: 0.498958\n",
      "epoch 140; iter: 0; batch classifier loss: 0.465608; batch adversarial loss: 0.596119\n",
      "epoch 141; iter: 0; batch classifier loss: 0.384153; batch adversarial loss: 0.510206\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359032; batch adversarial loss: 0.572331\n",
      "epoch 143; iter: 0; batch classifier loss: 0.439488; batch adversarial loss: 0.570925\n",
      "epoch 144; iter: 0; batch classifier loss: 0.453268; batch adversarial loss: 0.460773\n",
      "epoch 145; iter: 0; batch classifier loss: 0.284886; batch adversarial loss: 0.590275\n",
      "epoch 146; iter: 0; batch classifier loss: 0.415147; batch adversarial loss: 0.614931\n",
      "epoch 147; iter: 0; batch classifier loss: 0.437373; batch adversarial loss: 0.590206\n",
      "epoch 148; iter: 0; batch classifier loss: 0.429010; batch adversarial loss: 0.426586\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349338; batch adversarial loss: 0.481338\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.546177\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372780; batch adversarial loss: 0.506188\n",
      "epoch 152; iter: 0; batch classifier loss: 0.337403; batch adversarial loss: 0.563812\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327679; batch adversarial loss: 0.490005\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321298; batch adversarial loss: 0.556322\n",
      "epoch 155; iter: 0; batch classifier loss: 0.289683; batch adversarial loss: 0.617990\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378171; batch adversarial loss: 0.545113\n",
      "epoch 157; iter: 0; batch classifier loss: 0.389620; batch adversarial loss: 0.534425\n",
      "epoch 158; iter: 0; batch classifier loss: 0.348405; batch adversarial loss: 0.535739\n",
      "epoch 159; iter: 0; batch classifier loss: 0.330720; batch adversarial loss: 0.482533\n",
      "epoch 160; iter: 0; batch classifier loss: 0.312372; batch adversarial loss: 0.456638\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325140; batch adversarial loss: 0.583271\n",
      "epoch 162; iter: 0; batch classifier loss: 0.299054; batch adversarial loss: 0.555920\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374376; batch adversarial loss: 0.618251\n",
      "epoch 164; iter: 0; batch classifier loss: 0.374476; batch adversarial loss: 0.596397\n",
      "epoch 165; iter: 0; batch classifier loss: 0.424594; batch adversarial loss: 0.592166\n",
      "epoch 166; iter: 0; batch classifier loss: 0.293591; batch adversarial loss: 0.589983\n",
      "epoch 167; iter: 0; batch classifier loss: 0.320398; batch adversarial loss: 0.519448\n",
      "epoch 168; iter: 0; batch classifier loss: 0.396515; batch adversarial loss: 0.577564\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322791; batch adversarial loss: 0.538093\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333212; batch adversarial loss: 0.515544\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334975; batch adversarial loss: 0.616118\n",
      "epoch 172; iter: 0; batch classifier loss: 0.361111; batch adversarial loss: 0.500988\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357816; batch adversarial loss: 0.563603\n",
      "epoch 174; iter: 0; batch classifier loss: 0.419382; batch adversarial loss: 0.505337\n",
      "epoch 175; iter: 0; batch classifier loss: 0.536564; batch adversarial loss: 0.608877\n",
      "epoch 176; iter: 0; batch classifier loss: 0.423382; batch adversarial loss: 0.552793\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314848; batch adversarial loss: 0.553410\n",
      "epoch 178; iter: 0; batch classifier loss: 0.245346; batch adversarial loss: 0.555193\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355293; batch adversarial loss: 0.571868\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359273; batch adversarial loss: 0.555409\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338983; batch adversarial loss: 0.607621\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391684; batch adversarial loss: 0.535455\n",
      "epoch 183; iter: 0; batch classifier loss: 0.320930; batch adversarial loss: 0.662417\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362447; batch adversarial loss: 0.617898\n",
      "epoch 185; iter: 0; batch classifier loss: 0.257298; batch adversarial loss: 0.509559\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361130; batch adversarial loss: 0.644869\n",
      "epoch 187; iter: 0; batch classifier loss: 0.459455; batch adversarial loss: 0.488985\n",
      "epoch 188; iter: 0; batch classifier loss: 0.393546; batch adversarial loss: 0.535554\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355614; batch adversarial loss: 0.473242\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332818; batch adversarial loss: 0.545591\n",
      "epoch 191; iter: 0; batch classifier loss: 0.333895; batch adversarial loss: 0.487749\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348479; batch adversarial loss: 0.525786\n",
      "epoch 193; iter: 0; batch classifier loss: 0.293442; batch adversarial loss: 0.572120\n",
      "epoch 194; iter: 0; batch classifier loss: 0.387659; batch adversarial loss: 0.597173\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290282; batch adversarial loss: 0.507103\n",
      "epoch 196; iter: 0; batch classifier loss: 0.385498; batch adversarial loss: 0.524933\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354806; batch adversarial loss: 0.508553\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301344; batch adversarial loss: 0.501451\n",
      "epoch 199; iter: 0; batch classifier loss: 0.328082; batch adversarial loss: 0.600074\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718493; batch adversarial loss: 0.761360\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582079; batch adversarial loss: 0.659545\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593941; batch adversarial loss: 0.627634\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624995; batch adversarial loss: 0.660066\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517030; batch adversarial loss: 0.640394\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607164; batch adversarial loss: 0.601625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595712; batch adversarial loss: 0.566743\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532706; batch adversarial loss: 0.555433\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491671; batch adversarial loss: 0.624397\n",
      "epoch 9; iter: 0; batch classifier loss: 0.591563; batch adversarial loss: 0.622073\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491287; batch adversarial loss: 0.599198\n",
      "epoch 11; iter: 0; batch classifier loss: 0.650720; batch adversarial loss: 0.522003\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539047; batch adversarial loss: 0.591138\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502875; batch adversarial loss: 0.609051\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500392; batch adversarial loss: 0.610100\n",
      "epoch 15; iter: 0; batch classifier loss: 0.442300; batch adversarial loss: 0.660379\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520751; batch adversarial loss: 0.523951\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453433; batch adversarial loss: 0.551037\n",
      "epoch 18; iter: 0; batch classifier loss: 0.537695; batch adversarial loss: 0.591059\n",
      "epoch 19; iter: 0; batch classifier loss: 0.445098; batch adversarial loss: 0.575082\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521726; batch adversarial loss: 0.615273\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498013; batch adversarial loss: 0.517552\n",
      "epoch 22; iter: 0; batch classifier loss: 0.461603; batch adversarial loss: 0.584246\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464280; batch adversarial loss: 0.519982\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495880; batch adversarial loss: 0.689809\n",
      "epoch 25; iter: 0; batch classifier loss: 0.459503; batch adversarial loss: 0.643008\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451406; batch adversarial loss: 0.537057\n",
      "epoch 27; iter: 0; batch classifier loss: 0.421655; batch adversarial loss: 0.528808\n",
      "epoch 28; iter: 0; batch classifier loss: 0.550202; batch adversarial loss: 0.564312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.479485; batch adversarial loss: 0.590388\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446562; batch adversarial loss: 0.546152\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499981; batch adversarial loss: 0.617973\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429817; batch adversarial loss: 0.498589\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459812; batch adversarial loss: 0.508687\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419888; batch adversarial loss: 0.519055\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433097; batch adversarial loss: 0.547560\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405519; batch adversarial loss: 0.533978\n",
      "epoch 37; iter: 0; batch classifier loss: 0.507762; batch adversarial loss: 0.523759\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434952; batch adversarial loss: 0.538724\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434930; batch adversarial loss: 0.586685\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480332; batch adversarial loss: 0.557202\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484247; batch adversarial loss: 0.491608\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407902; batch adversarial loss: 0.641897\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451443; batch adversarial loss: 0.585745\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457571; batch adversarial loss: 0.583969\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407361; batch adversarial loss: 0.552849\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444383; batch adversarial loss: 0.584783\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420468; batch adversarial loss: 0.590641\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478404; batch adversarial loss: 0.527795\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466142; batch adversarial loss: 0.651019\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410710; batch adversarial loss: 0.579149\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383896; batch adversarial loss: 0.520969\n",
      "epoch 52; iter: 0; batch classifier loss: 0.568300; batch adversarial loss: 0.545595\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401839; batch adversarial loss: 0.470086\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455499; batch adversarial loss: 0.519539\n",
      "epoch 55; iter: 0; batch classifier loss: 0.363383; batch adversarial loss: 0.606543\n",
      "epoch 56; iter: 0; batch classifier loss: 0.477281; batch adversarial loss: 0.510578\n",
      "epoch 57; iter: 0; batch classifier loss: 0.419443; batch adversarial loss: 0.492211\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440760; batch adversarial loss: 0.597723\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428606; batch adversarial loss: 0.562725\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406329; batch adversarial loss: 0.508984\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436846; batch adversarial loss: 0.517741\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434623; batch adversarial loss: 0.474079\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399835; batch adversarial loss: 0.535662\n",
      "epoch 64; iter: 0; batch classifier loss: 0.367915; batch adversarial loss: 0.482886\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382603; batch adversarial loss: 0.579790\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405256; batch adversarial loss: 0.536060\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434185; batch adversarial loss: 0.536603\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442368; batch adversarial loss: 0.535435\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378044; batch adversarial loss: 0.524741\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391700; batch adversarial loss: 0.551204\n",
      "epoch 71; iter: 0; batch classifier loss: 0.501405; batch adversarial loss: 0.444265\n",
      "epoch 72; iter: 0; batch classifier loss: 0.515495; batch adversarial loss: 0.508702\n",
      "epoch 73; iter: 0; batch classifier loss: 0.452285; batch adversarial loss: 0.517510\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410898; batch adversarial loss: 0.550945\n",
      "epoch 75; iter: 0; batch classifier loss: 0.470540; batch adversarial loss: 0.543708\n",
      "epoch 76; iter: 0; batch classifier loss: 0.436370; batch adversarial loss: 0.572494\n",
      "epoch 77; iter: 0; batch classifier loss: 0.380435; batch adversarial loss: 0.558992\n",
      "epoch 78; iter: 0; batch classifier loss: 0.343248; batch adversarial loss: 0.483999\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411397; batch adversarial loss: 0.455485\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398288; batch adversarial loss: 0.552263\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375278; batch adversarial loss: 0.536864\n",
      "epoch 82; iter: 0; batch classifier loss: 0.318978; batch adversarial loss: 0.571018\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394933; batch adversarial loss: 0.562771\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408966; batch adversarial loss: 0.570904\n",
      "epoch 85; iter: 0; batch classifier loss: 0.324638; batch adversarial loss: 0.614914\n",
      "epoch 86; iter: 0; batch classifier loss: 0.340210; batch adversarial loss: 0.615630\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429472; batch adversarial loss: 0.632463\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376048; batch adversarial loss: 0.553645\n",
      "epoch 89; iter: 0; batch classifier loss: 0.360348; batch adversarial loss: 0.623813\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388326; batch adversarial loss: 0.544819\n",
      "epoch 91; iter: 0; batch classifier loss: 0.437126; batch adversarial loss: 0.553575\n",
      "epoch 92; iter: 0; batch classifier loss: 0.420940; batch adversarial loss: 0.535294\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437279; batch adversarial loss: 0.553521\n",
      "epoch 94; iter: 0; batch classifier loss: 0.470431; batch adversarial loss: 0.571627\n",
      "epoch 95; iter: 0; batch classifier loss: 0.513996; batch adversarial loss: 0.545610\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384817; batch adversarial loss: 0.589143\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358043; batch adversarial loss: 0.534715\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339037; batch adversarial loss: 0.500338\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373634; batch adversarial loss: 0.517855\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399396; batch adversarial loss: 0.553681\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385422; batch adversarial loss: 0.598653\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370593; batch adversarial loss: 0.588164\n",
      "epoch 103; iter: 0; batch classifier loss: 0.400702; batch adversarial loss: 0.554720\n",
      "epoch 104; iter: 0; batch classifier loss: 0.408266; batch adversarial loss: 0.607180\n",
      "epoch 105; iter: 0; batch classifier loss: 0.484192; batch adversarial loss: 0.570981\n",
      "epoch 106; iter: 0; batch classifier loss: 0.375656; batch adversarial loss: 0.518245\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346654; batch adversarial loss: 0.554226\n",
      "epoch 108; iter: 0; batch classifier loss: 0.449774; batch adversarial loss: 0.596643\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375519; batch adversarial loss: 0.481928\n",
      "epoch 110; iter: 0; batch classifier loss: 0.406873; batch adversarial loss: 0.561971\n",
      "epoch 111; iter: 0; batch classifier loss: 0.360966; batch adversarial loss: 0.463122\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415300; batch adversarial loss: 0.562462\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407885; batch adversarial loss: 0.571157\n",
      "epoch 114; iter: 0; batch classifier loss: 0.437975; batch adversarial loss: 0.623672\n",
      "epoch 115; iter: 0; batch classifier loss: 0.369669; batch adversarial loss: 0.526987\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346493; batch adversarial loss: 0.606191\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383952; batch adversarial loss: 0.571149\n",
      "epoch 118; iter: 0; batch classifier loss: 0.451637; batch adversarial loss: 0.544654\n",
      "epoch 119; iter: 0; batch classifier loss: 0.468974; batch adversarial loss: 0.579732\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352698; batch adversarial loss: 0.562807\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394823; batch adversarial loss: 0.589594\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345863; batch adversarial loss: 0.499804\n",
      "epoch 123; iter: 0; batch classifier loss: 0.397235; batch adversarial loss: 0.499627\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370394; batch adversarial loss: 0.544468\n",
      "epoch 125; iter: 0; batch classifier loss: 0.335943; batch adversarial loss: 0.463396\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353119; batch adversarial loss: 0.553915\n",
      "epoch 127; iter: 0; batch classifier loss: 0.363472; batch adversarial loss: 0.507537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.386978; batch adversarial loss: 0.573114\n",
      "epoch 129; iter: 0; batch classifier loss: 0.428557; batch adversarial loss: 0.553696\n",
      "epoch 130; iter: 0; batch classifier loss: 0.491587; batch adversarial loss: 0.571832\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394151; batch adversarial loss: 0.508933\n",
      "epoch 132; iter: 0; batch classifier loss: 0.379712; batch adversarial loss: 0.491128\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398356; batch adversarial loss: 0.564519\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365737; batch adversarial loss: 0.606986\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389200; batch adversarial loss: 0.526595\n",
      "epoch 136; iter: 0; batch classifier loss: 0.427310; batch adversarial loss: 0.500350\n",
      "epoch 137; iter: 0; batch classifier loss: 0.438409; batch adversarial loss: 0.518340\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357699; batch adversarial loss: 0.544746\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389114; batch adversarial loss: 0.491452\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358296; batch adversarial loss: 0.598833\n",
      "epoch 141; iter: 0; batch classifier loss: 0.361660; batch adversarial loss: 0.553755\n",
      "epoch 142; iter: 0; batch classifier loss: 0.373012; batch adversarial loss: 0.589396\n",
      "epoch 143; iter: 0; batch classifier loss: 0.327699; batch adversarial loss: 0.536011\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358454; batch adversarial loss: 0.580679\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362396; batch adversarial loss: 0.606820\n",
      "epoch 146; iter: 0; batch classifier loss: 0.320030; batch adversarial loss: 0.543918\n",
      "epoch 147; iter: 0; batch classifier loss: 0.289122; batch adversarial loss: 0.589336\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405457; batch adversarial loss: 0.580943\n",
      "epoch 149; iter: 0; batch classifier loss: 0.422194; batch adversarial loss: 0.644254\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389979; batch adversarial loss: 0.617015\n",
      "epoch 151; iter: 0; batch classifier loss: 0.318496; batch adversarial loss: 0.591641\n",
      "epoch 152; iter: 0; batch classifier loss: 0.389777; batch adversarial loss: 0.542464\n",
      "epoch 153; iter: 0; batch classifier loss: 0.428766; batch adversarial loss: 0.622633\n",
      "epoch 154; iter: 0; batch classifier loss: 0.401877; batch adversarial loss: 0.504991\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364135; batch adversarial loss: 0.568449\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395448; batch adversarial loss: 0.494368\n",
      "epoch 157; iter: 0; batch classifier loss: 0.342478; batch adversarial loss: 0.549769\n",
      "epoch 158; iter: 0; batch classifier loss: 0.410614; batch adversarial loss: 0.588715\n",
      "epoch 159; iter: 0; batch classifier loss: 0.320128; batch adversarial loss: 0.660800\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386085; batch adversarial loss: 0.552123\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362625; batch adversarial loss: 0.544783\n",
      "epoch 162; iter: 0; batch classifier loss: 0.409472; batch adversarial loss: 0.559547\n",
      "epoch 163; iter: 0; batch classifier loss: 0.405170; batch adversarial loss: 0.552588\n",
      "epoch 164; iter: 0; batch classifier loss: 0.404816; batch adversarial loss: 0.571334\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375617; batch adversarial loss: 0.580460\n",
      "epoch 166; iter: 0; batch classifier loss: 0.320049; batch adversarial loss: 0.542128\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341190; batch adversarial loss: 0.536372\n",
      "epoch 168; iter: 0; batch classifier loss: 0.385792; batch adversarial loss: 0.580486\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321343; batch adversarial loss: 0.572917\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336010; batch adversarial loss: 0.581033\n",
      "epoch 171; iter: 0; batch classifier loss: 0.436373; batch adversarial loss: 0.580517\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374112; batch adversarial loss: 0.624206\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369628; batch adversarial loss: 0.553765\n",
      "epoch 174; iter: 0; batch classifier loss: 0.404214; batch adversarial loss: 0.561789\n",
      "epoch 175; iter: 0; batch classifier loss: 0.420628; batch adversarial loss: 0.598300\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408369; batch adversarial loss: 0.526367\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314414; batch adversarial loss: 0.554263\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343936; batch adversarial loss: 0.499533\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399032; batch adversarial loss: 0.573143\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335535; batch adversarial loss: 0.545141\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328205; batch adversarial loss: 0.518134\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314445; batch adversarial loss: 0.570989\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384176; batch adversarial loss: 0.483238\n",
      "epoch 184; iter: 0; batch classifier loss: 0.390637; batch adversarial loss: 0.545574\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369577; batch adversarial loss: 0.492426\n",
      "epoch 186; iter: 0; batch classifier loss: 0.364813; batch adversarial loss: 0.606183\n",
      "epoch 187; iter: 0; batch classifier loss: 0.354574; batch adversarial loss: 0.447287\n",
      "epoch 188; iter: 0; batch classifier loss: 0.333844; batch adversarial loss: 0.624352\n",
      "epoch 189; iter: 0; batch classifier loss: 0.310720; batch adversarial loss: 0.615702\n",
      "epoch 190; iter: 0; batch classifier loss: 0.292606; batch adversarial loss: 0.508684\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313754; batch adversarial loss: 0.661428\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337402; batch adversarial loss: 0.526563\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353276; batch adversarial loss: 0.562414\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322697; batch adversarial loss: 0.544731\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302286; batch adversarial loss: 0.526812\n",
      "epoch 196; iter: 0; batch classifier loss: 0.353715; batch adversarial loss: 0.481073\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377040; batch adversarial loss: 0.517552\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335311; batch adversarial loss: 0.525864\n",
      "epoch 199; iter: 0; batch classifier loss: 0.347778; batch adversarial loss: 0.507092\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701673; batch adversarial loss: 0.639144\n",
      "epoch 1; iter: 0; batch classifier loss: 0.648210; batch adversarial loss: 0.652304\n",
      "epoch 2; iter: 0; batch classifier loss: 0.637651; batch adversarial loss: 0.692107\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651500; batch adversarial loss: 0.636329\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559231; batch adversarial loss: 0.658937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569569; batch adversarial loss: 0.628743\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587401; batch adversarial loss: 0.592244\n",
      "epoch 7; iter: 0; batch classifier loss: 0.633888; batch adversarial loss: 0.577012\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503495; batch adversarial loss: 0.623713\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524425; batch adversarial loss: 0.569079\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541080; batch adversarial loss: 0.585709\n",
      "epoch 11; iter: 0; batch classifier loss: 0.469748; batch adversarial loss: 0.536902\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572296; batch adversarial loss: 0.579396\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558825; batch adversarial loss: 0.571365\n",
      "epoch 14; iter: 0; batch classifier loss: 0.550040; batch adversarial loss: 0.561240\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485619; batch adversarial loss: 0.524882\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525742; batch adversarial loss: 0.527363\n",
      "epoch 17; iter: 0; batch classifier loss: 0.542457; batch adversarial loss: 0.556729\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496298; batch adversarial loss: 0.488136\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545203; batch adversarial loss: 0.556111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504401; batch adversarial loss: 0.495093\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498270; batch adversarial loss: 0.519024\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481263; batch adversarial loss: 0.534080\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499675; batch adversarial loss: 0.544331\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446272; batch adversarial loss: 0.574137\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482184; batch adversarial loss: 0.490903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.497715; batch adversarial loss: 0.444803\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469257; batch adversarial loss: 0.540972\n",
      "epoch 28; iter: 0; batch classifier loss: 0.417283; batch adversarial loss: 0.609032\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463591; batch adversarial loss: 0.514611\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515518; batch adversarial loss: 0.479130\n",
      "epoch 31; iter: 0; batch classifier loss: 0.423273; batch adversarial loss: 0.573663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504262; batch adversarial loss: 0.544343\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494339; batch adversarial loss: 0.506820\n",
      "epoch 34; iter: 0; batch classifier loss: 0.522754; batch adversarial loss: 0.572097\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434660; batch adversarial loss: 0.562272\n",
      "epoch 36; iter: 0; batch classifier loss: 0.431565; batch adversarial loss: 0.485723\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457525; batch adversarial loss: 0.544649\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453500; batch adversarial loss: 0.524462\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493393; batch adversarial loss: 0.504350\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464607; batch adversarial loss: 0.581761\n",
      "epoch 41; iter: 0; batch classifier loss: 0.480031; batch adversarial loss: 0.525354\n",
      "epoch 42; iter: 0; batch classifier loss: 0.491789; batch adversarial loss: 0.526341\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406783; batch adversarial loss: 0.580646\n",
      "epoch 44; iter: 0; batch classifier loss: 0.524681; batch adversarial loss: 0.546395\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463858; batch adversarial loss: 0.515186\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414585; batch adversarial loss: 0.517154\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461855; batch adversarial loss: 0.534552\n",
      "epoch 48; iter: 0; batch classifier loss: 0.504896; batch adversarial loss: 0.479880\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412158; batch adversarial loss: 0.479484\n",
      "epoch 50; iter: 0; batch classifier loss: 0.483505; batch adversarial loss: 0.543309\n",
      "epoch 51; iter: 0; batch classifier loss: 0.521519; batch adversarial loss: 0.659971\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443828; batch adversarial loss: 0.497415\n",
      "epoch 53; iter: 0; batch classifier loss: 0.434157; batch adversarial loss: 0.507688\n",
      "epoch 54; iter: 0; batch classifier loss: 0.409207; batch adversarial loss: 0.490137\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462998; batch adversarial loss: 0.621106\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434491; batch adversarial loss: 0.612438\n",
      "epoch 57; iter: 0; batch classifier loss: 0.498210; batch adversarial loss: 0.564156\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443899; batch adversarial loss: 0.545275\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449385; batch adversarial loss: 0.564243\n",
      "epoch 60; iter: 0; batch classifier loss: 0.371520; batch adversarial loss: 0.535162\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454460; batch adversarial loss: 0.617241\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383222; batch adversarial loss: 0.571378\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385355; batch adversarial loss: 0.460413\n",
      "epoch 64; iter: 0; batch classifier loss: 0.514598; batch adversarial loss: 0.422851\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384809; batch adversarial loss: 0.553867\n",
      "epoch 66; iter: 0; batch classifier loss: 0.451709; batch adversarial loss: 0.601575\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401042; batch adversarial loss: 0.487092\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397439; batch adversarial loss: 0.590781\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429591; batch adversarial loss: 0.514649\n",
      "epoch 70; iter: 0; batch classifier loss: 0.483977; batch adversarial loss: 0.526105\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358707; batch adversarial loss: 0.535242\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415463; batch adversarial loss: 0.513964\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428493; batch adversarial loss: 0.505968\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363800; batch adversarial loss: 0.574729\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393217; batch adversarial loss: 0.554209\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390482; batch adversarial loss: 0.534785\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383611; batch adversarial loss: 0.534952\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441139; batch adversarial loss: 0.545596\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436347; batch adversarial loss: 0.526496\n",
      "epoch 80; iter: 0; batch classifier loss: 0.382028; batch adversarial loss: 0.517655\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418485; batch adversarial loss: 0.505681\n",
      "epoch 82; iter: 0; batch classifier loss: 0.449874; batch adversarial loss: 0.534743\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421833; batch adversarial loss: 0.555321\n",
      "epoch 84; iter: 0; batch classifier loss: 0.465324; batch adversarial loss: 0.532974\n",
      "epoch 85; iter: 0; batch classifier loss: 0.357939; batch adversarial loss: 0.530045\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395103; batch adversarial loss: 0.577033\n",
      "epoch 87; iter: 0; batch classifier loss: 0.443499; batch adversarial loss: 0.592866\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360535; batch adversarial loss: 0.571503\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388995; batch adversarial loss: 0.577890\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407480; batch adversarial loss: 0.521890\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402481; batch adversarial loss: 0.521706\n",
      "epoch 92; iter: 0; batch classifier loss: 0.435708; batch adversarial loss: 0.657429\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378276; batch adversarial loss: 0.493181\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404288; batch adversarial loss: 0.540603\n",
      "epoch 95; iter: 0; batch classifier loss: 0.457552; batch adversarial loss: 0.631446\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428711; batch adversarial loss: 0.648890\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416677; batch adversarial loss: 0.592600\n",
      "epoch 98; iter: 0; batch classifier loss: 0.466479; batch adversarial loss: 0.582512\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424430; batch adversarial loss: 0.563217\n",
      "epoch 100; iter: 0; batch classifier loss: 0.453119; batch adversarial loss: 0.479041\n",
      "epoch 101; iter: 0; batch classifier loss: 0.480739; batch adversarial loss: 0.581640\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345413; batch adversarial loss: 0.516605\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372349; batch adversarial loss: 0.442107\n",
      "epoch 104; iter: 0; batch classifier loss: 0.462820; batch adversarial loss: 0.525256\n",
      "epoch 105; iter: 0; batch classifier loss: 0.314272; batch adversarial loss: 0.525740\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353357; batch adversarial loss: 0.450471\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380447; batch adversarial loss: 0.553848\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396456; batch adversarial loss: 0.554075\n",
      "epoch 109; iter: 0; batch classifier loss: 0.463804; batch adversarial loss: 0.479051\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381998; batch adversarial loss: 0.573746\n",
      "epoch 111; iter: 0; batch classifier loss: 0.501090; batch adversarial loss: 0.609625\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379269; batch adversarial loss: 0.477927\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386139; batch adversarial loss: 0.669967\n",
      "epoch 114; iter: 0; batch classifier loss: 0.447521; batch adversarial loss: 0.497650\n",
      "epoch 115; iter: 0; batch classifier loss: 0.430434; batch adversarial loss: 0.477619\n",
      "epoch 116; iter: 0; batch classifier loss: 0.330953; batch adversarial loss: 0.437606\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399869; batch adversarial loss: 0.506858\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417789; batch adversarial loss: 0.573751\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382822; batch adversarial loss: 0.534422\n",
      "epoch 120; iter: 0; batch classifier loss: 0.421955; batch adversarial loss: 0.544277\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349098; batch adversarial loss: 0.526811\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397591; batch adversarial loss: 0.563311\n",
      "epoch 123; iter: 0; batch classifier loss: 0.432750; batch adversarial loss: 0.666773\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380606; batch adversarial loss: 0.460050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.468327; batch adversarial loss: 0.478350\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413713; batch adversarial loss: 0.592048\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380871; batch adversarial loss: 0.620719\n",
      "epoch 128; iter: 0; batch classifier loss: 0.339868; batch adversarial loss: 0.516334\n",
      "epoch 129; iter: 0; batch classifier loss: 0.421899; batch adversarial loss: 0.601657\n",
      "epoch 130; iter: 0; batch classifier loss: 0.323538; batch adversarial loss: 0.525937\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348453; batch adversarial loss: 0.535794\n",
      "epoch 132; iter: 0; batch classifier loss: 0.441510; batch adversarial loss: 0.487341\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412123; batch adversarial loss: 0.525264\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339282; batch adversarial loss: 0.582670\n",
      "epoch 135; iter: 0; batch classifier loss: 0.444321; batch adversarial loss: 0.649720\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354764; batch adversarial loss: 0.478803\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359516; batch adversarial loss: 0.516123\n",
      "epoch 138; iter: 0; batch classifier loss: 0.391633; batch adversarial loss: 0.525320\n",
      "epoch 139; iter: 0; batch classifier loss: 0.489690; batch adversarial loss: 0.468491\n",
      "epoch 140; iter: 0; batch classifier loss: 0.428119; batch adversarial loss: 0.487903\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339572; batch adversarial loss: 0.534536\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341265; batch adversarial loss: 0.582768\n",
      "epoch 143; iter: 0; batch classifier loss: 0.247768; batch adversarial loss: 0.524725\n",
      "epoch 144; iter: 0; batch classifier loss: 0.375537; batch adversarial loss: 0.523908\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390026; batch adversarial loss: 0.420079\n",
      "epoch 146; iter: 0; batch classifier loss: 0.431153; batch adversarial loss: 0.506904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383773; batch adversarial loss: 0.506155\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331686; batch adversarial loss: 0.564113\n",
      "epoch 149; iter: 0; batch classifier loss: 0.408488; batch adversarial loss: 0.545160\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381416; batch adversarial loss: 0.469139\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364391; batch adversarial loss: 0.513861\n",
      "epoch 152; iter: 0; batch classifier loss: 0.456737; batch adversarial loss: 0.536676\n",
      "epoch 153; iter: 0; batch classifier loss: 0.425281; batch adversarial loss: 0.545503\n",
      "epoch 154; iter: 0; batch classifier loss: 0.347875; batch adversarial loss: 0.560093\n",
      "epoch 155; iter: 0; batch classifier loss: 0.429409; batch adversarial loss: 0.450759\n",
      "epoch 156; iter: 0; batch classifier loss: 0.392031; batch adversarial loss: 0.516373\n",
      "epoch 157; iter: 0; batch classifier loss: 0.414219; batch adversarial loss: 0.516488\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381794; batch adversarial loss: 0.506590\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349842; batch adversarial loss: 0.590653\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406156; batch adversarial loss: 0.498267\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344849; batch adversarial loss: 0.526000\n",
      "epoch 162; iter: 0; batch classifier loss: 0.492215; batch adversarial loss: 0.525774\n",
      "epoch 163; iter: 0; batch classifier loss: 0.360459; batch adversarial loss: 0.526108\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372606; batch adversarial loss: 0.479434\n",
      "epoch 165; iter: 0; batch classifier loss: 0.396476; batch adversarial loss: 0.506702\n",
      "epoch 166; iter: 0; batch classifier loss: 0.408979; batch adversarial loss: 0.516117\n",
      "epoch 167; iter: 0; batch classifier loss: 0.381218; batch adversarial loss: 0.536229\n",
      "epoch 168; iter: 0; batch classifier loss: 0.522307; batch adversarial loss: 0.573076\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357940; batch adversarial loss: 0.468456\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346520; batch adversarial loss: 0.600036\n",
      "epoch 171; iter: 0; batch classifier loss: 0.462063; batch adversarial loss: 0.516167\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394574; batch adversarial loss: 0.497521\n",
      "epoch 173; iter: 0; batch classifier loss: 0.423175; batch adversarial loss: 0.516812\n",
      "epoch 174; iter: 0; batch classifier loss: 0.333324; batch adversarial loss: 0.535082\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372976; batch adversarial loss: 0.525315\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347630; batch adversarial loss: 0.524690\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383952; batch adversarial loss: 0.534770\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337744; batch adversarial loss: 0.582918\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379759; batch adversarial loss: 0.544171\n",
      "epoch 180; iter: 0; batch classifier loss: 0.394579; batch adversarial loss: 0.535248\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420615; batch adversarial loss: 0.572316\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387437; batch adversarial loss: 0.516105\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384440; batch adversarial loss: 0.610130\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375798; batch adversarial loss: 0.591605\n",
      "epoch 185; iter: 0; batch classifier loss: 0.469171; batch adversarial loss: 0.563756\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392938; batch adversarial loss: 0.620048\n",
      "epoch 187; iter: 0; batch classifier loss: 0.331624; batch adversarial loss: 0.600948\n",
      "epoch 188; iter: 0; batch classifier loss: 0.401372; batch adversarial loss: 0.591977\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333405; batch adversarial loss: 0.525750\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351348; batch adversarial loss: 0.535246\n",
      "epoch 191; iter: 0; batch classifier loss: 0.394879; batch adversarial loss: 0.506193\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318812; batch adversarial loss: 0.487100\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348269; batch adversarial loss: 0.591978\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324010; batch adversarial loss: 0.563089\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363436; batch adversarial loss: 0.516480\n",
      "epoch 196; iter: 0; batch classifier loss: 0.470137; batch adversarial loss: 0.449352\n",
      "epoch 197; iter: 0; batch classifier loss: 0.419711; batch adversarial loss: 0.498063\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336924; batch adversarial loss: 0.534559\n",
      "epoch 199; iter: 0; batch classifier loss: 0.405286; batch adversarial loss: 0.507289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706653; batch adversarial loss: 0.837897\n",
      "epoch 1; iter: 0; batch classifier loss: 0.827515; batch adversarial loss: 0.934169\n",
      "epoch 2; iter: 0; batch classifier loss: 0.974074; batch adversarial loss: 0.885165\n",
      "epoch 3; iter: 0; batch classifier loss: 1.028242; batch adversarial loss: 0.812913\n",
      "epoch 4; iter: 0; batch classifier loss: 1.038581; batch adversarial loss: 0.744068\n",
      "epoch 5; iter: 0; batch classifier loss: 0.903098; batch adversarial loss: 0.677884\n",
      "epoch 6; iter: 0; batch classifier loss: 0.776597; batch adversarial loss: 0.621035\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575822; batch adversarial loss: 0.627447\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576542; batch adversarial loss: 0.592004\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529816; batch adversarial loss: 0.615278\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515563; batch adversarial loss: 0.557985\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527200; batch adversarial loss: 0.585946\n",
      "epoch 12; iter: 0; batch classifier loss: 0.568401; batch adversarial loss: 0.542368\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559441; batch adversarial loss: 0.553545\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559198; batch adversarial loss: 0.581314\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488466; batch adversarial loss: 0.546983\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513119; batch adversarial loss: 0.555975\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496976; batch adversarial loss: 0.528725\n",
      "epoch 18; iter: 0; batch classifier loss: 0.538244; batch adversarial loss: 0.545159\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441483; batch adversarial loss: 0.542523\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493324; batch adversarial loss: 0.494962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.527305; batch adversarial loss: 0.532177\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447665; batch adversarial loss: 0.523141\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504308; batch adversarial loss: 0.490615\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484732; batch adversarial loss: 0.548294\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465419; batch adversarial loss: 0.546596\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428429; batch adversarial loss: 0.535105\n",
      "epoch 27; iter: 0; batch classifier loss: 0.561322; batch adversarial loss: 0.479325\n",
      "epoch 28; iter: 0; batch classifier loss: 0.524554; batch adversarial loss: 0.489540\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488446; batch adversarial loss: 0.475462\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482189; batch adversarial loss: 0.611151\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400388; batch adversarial loss: 0.510933\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436517; batch adversarial loss: 0.468584\n",
      "epoch 33; iter: 0; batch classifier loss: 0.513606; batch adversarial loss: 0.541526\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411156; batch adversarial loss: 0.545062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464333; batch adversarial loss: 0.537602\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473370; batch adversarial loss: 0.510682\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412036; batch adversarial loss: 0.565160\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523062; batch adversarial loss: 0.424171\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452002; batch adversarial loss: 0.527102\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448724; batch adversarial loss: 0.555802\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446182; batch adversarial loss: 0.499092\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480428; batch adversarial loss: 0.518435\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419436; batch adversarial loss: 0.539336\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402632; batch adversarial loss: 0.511313\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460199; batch adversarial loss: 0.565152\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422910; batch adversarial loss: 0.500283\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449914; batch adversarial loss: 0.544891\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445151; batch adversarial loss: 0.505213\n",
      "epoch 49; iter: 0; batch classifier loss: 0.387930; batch adversarial loss: 0.545114\n",
      "epoch 50; iter: 0; batch classifier loss: 0.481211; batch adversarial loss: 0.469140\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463315; batch adversarial loss: 0.621619\n",
      "epoch 52; iter: 0; batch classifier loss: 0.388576; batch adversarial loss: 0.546092\n",
      "epoch 53; iter: 0; batch classifier loss: 0.416636; batch adversarial loss: 0.592170\n",
      "epoch 54; iter: 0; batch classifier loss: 0.374156; batch adversarial loss: 0.580587\n",
      "epoch 55; iter: 0; batch classifier loss: 0.347104; batch adversarial loss: 0.563889\n",
      "epoch 56; iter: 0; batch classifier loss: 0.349619; batch adversarial loss: 0.566936\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382004; batch adversarial loss: 0.573096\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396694; batch adversarial loss: 0.497902\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411038; batch adversarial loss: 0.486863\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414067; batch adversarial loss: 0.564545\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386538; batch adversarial loss: 0.535807\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397187; batch adversarial loss: 0.544804\n",
      "epoch 63; iter: 0; batch classifier loss: 0.340061; batch adversarial loss: 0.487112\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407741; batch adversarial loss: 0.486992\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362139; batch adversarial loss: 0.573565\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403583; batch adversarial loss: 0.583735\n",
      "epoch 67; iter: 0; batch classifier loss: 0.456005; batch adversarial loss: 0.535143\n",
      "epoch 68; iter: 0; batch classifier loss: 0.354772; batch adversarial loss: 0.564381\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425263; batch adversarial loss: 0.525291\n",
      "epoch 70; iter: 0; batch classifier loss: 0.339923; batch adversarial loss: 0.466759\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402304; batch adversarial loss: 0.544727\n",
      "epoch 72; iter: 0; batch classifier loss: 0.357028; batch adversarial loss: 0.524901\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423533; batch adversarial loss: 0.545140\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432742; batch adversarial loss: 0.505823\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403960; batch adversarial loss: 0.495388\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415063; batch adversarial loss: 0.613239\n",
      "epoch 77; iter: 0; batch classifier loss: 0.314561; batch adversarial loss: 0.543825\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354739; batch adversarial loss: 0.625526\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430576; batch adversarial loss: 0.513269\n",
      "epoch 80; iter: 0; batch classifier loss: 0.322819; batch adversarial loss: 0.465969\n",
      "epoch 81; iter: 0; batch classifier loss: 0.412678; batch adversarial loss: 0.524957\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368511; batch adversarial loss: 0.535334\n",
      "epoch 83; iter: 0; batch classifier loss: 0.322865; batch adversarial loss: 0.525215\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440275; batch adversarial loss: 0.553463\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364581; batch adversarial loss: 0.632794\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380422; batch adversarial loss: 0.553344\n",
      "epoch 87; iter: 0; batch classifier loss: 0.327854; batch adversarial loss: 0.563093\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379575; batch adversarial loss: 0.524710\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387344; batch adversarial loss: 0.484366\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375481; batch adversarial loss: 0.455556\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410812; batch adversarial loss: 0.495545\n",
      "epoch 92; iter: 0; batch classifier loss: 0.296404; batch adversarial loss: 0.533999\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349992; batch adversarial loss: 0.486387\n",
      "epoch 94; iter: 0; batch classifier loss: 0.379439; batch adversarial loss: 0.426033\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345083; batch adversarial loss: 0.601483\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400638; batch adversarial loss: 0.576786\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344646; batch adversarial loss: 0.408881\n",
      "epoch 98; iter: 0; batch classifier loss: 0.350204; batch adversarial loss: 0.489202\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360371; batch adversarial loss: 0.487793\n",
      "epoch 100; iter: 0; batch classifier loss: 0.354728; batch adversarial loss: 0.562878\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358304; batch adversarial loss: 0.535499\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367411; batch adversarial loss: 0.515429\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376688; batch adversarial loss: 0.417307\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348479; batch adversarial loss: 0.515967\n",
      "epoch 105; iter: 0; batch classifier loss: 0.350157; batch adversarial loss: 0.544173\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404473; batch adversarial loss: 0.535285\n",
      "epoch 107; iter: 0; batch classifier loss: 0.332310; batch adversarial loss: 0.525942\n",
      "epoch 108; iter: 0; batch classifier loss: 0.319546; batch adversarial loss: 0.524222\n",
      "epoch 109; iter: 0; batch classifier loss: 0.343964; batch adversarial loss: 0.583680\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368186; batch adversarial loss: 0.583855\n",
      "epoch 111; iter: 0; batch classifier loss: 0.284178; batch adversarial loss: 0.438165\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371480; batch adversarial loss: 0.514198\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369017; batch adversarial loss: 0.514941\n",
      "epoch 114; iter: 0; batch classifier loss: 0.303506; batch adversarial loss: 0.487576\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393247; batch adversarial loss: 0.533003\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361097; batch adversarial loss: 0.475084\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358190; batch adversarial loss: 0.514561\n",
      "epoch 118; iter: 0; batch classifier loss: 0.291448; batch adversarial loss: 0.496442\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415304; batch adversarial loss: 0.524696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.360608; batch adversarial loss: 0.514191\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393393; batch adversarial loss: 0.536332\n",
      "epoch 122; iter: 0; batch classifier loss: 0.328820; batch adversarial loss: 0.466101\n",
      "epoch 123; iter: 0; batch classifier loss: 0.398178; batch adversarial loss: 0.515677\n",
      "epoch 124; iter: 0; batch classifier loss: 0.413283; batch adversarial loss: 0.456695\n",
      "epoch 125; iter: 0; batch classifier loss: 0.400777; batch adversarial loss: 0.541935\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360291; batch adversarial loss: 0.473693\n",
      "epoch 127; iter: 0; batch classifier loss: 0.339525; batch adversarial loss: 0.569883\n",
      "epoch 128; iter: 0; batch classifier loss: 0.230936; batch adversarial loss: 0.573086\n",
      "epoch 129; iter: 0; batch classifier loss: 0.392182; batch adversarial loss: 0.553604\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386004; batch adversarial loss: 0.565846\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321568; batch adversarial loss: 0.427687\n",
      "epoch 132; iter: 0; batch classifier loss: 0.387744; batch adversarial loss: 0.516315\n",
      "epoch 133; iter: 0; batch classifier loss: 0.280223; batch adversarial loss: 0.474642\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340460; batch adversarial loss: 0.535377\n",
      "epoch 135; iter: 0; batch classifier loss: 0.324480; batch adversarial loss: 0.526209\n",
      "epoch 136; iter: 0; batch classifier loss: 0.454599; batch adversarial loss: 0.574685\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357292; batch adversarial loss: 0.544674\n",
      "epoch 138; iter: 0; batch classifier loss: 0.296837; batch adversarial loss: 0.505615\n",
      "epoch 139; iter: 0; batch classifier loss: 0.288972; batch adversarial loss: 0.525009\n",
      "epoch 140; iter: 0; batch classifier loss: 0.368772; batch adversarial loss: 0.420606\n",
      "epoch 141; iter: 0; batch classifier loss: 0.360502; batch adversarial loss: 0.621175\n",
      "epoch 142; iter: 0; batch classifier loss: 0.275592; batch adversarial loss: 0.543563\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356654; batch adversarial loss: 0.563861\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327110; batch adversarial loss: 0.546082\n",
      "epoch 145; iter: 0; batch classifier loss: 0.275068; batch adversarial loss: 0.506444\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345639; batch adversarial loss: 0.583631\n",
      "epoch 147; iter: 0; batch classifier loss: 0.280870; batch adversarial loss: 0.535798\n",
      "epoch 148; iter: 0; batch classifier loss: 0.348526; batch adversarial loss: 0.506060\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336006; batch adversarial loss: 0.543282\n",
      "epoch 150; iter: 0; batch classifier loss: 0.298152; batch adversarial loss: 0.496504\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336812; batch adversarial loss: 0.504925\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360186; batch adversarial loss: 0.565125\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391873; batch adversarial loss: 0.503758\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372417; batch adversarial loss: 0.506503\n",
      "epoch 155; iter: 0; batch classifier loss: 0.315729; batch adversarial loss: 0.620474\n",
      "epoch 156; iter: 0; batch classifier loss: 0.287657; batch adversarial loss: 0.534828\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335101; batch adversarial loss: 0.551839\n",
      "epoch 158; iter: 0; batch classifier loss: 0.465966; batch adversarial loss: 0.523269\n",
      "epoch 159; iter: 0; batch classifier loss: 0.307315; batch adversarial loss: 0.504490\n",
      "epoch 160; iter: 0; batch classifier loss: 0.315434; batch adversarial loss: 0.487129\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330002; batch adversarial loss: 0.494304\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364439; batch adversarial loss: 0.513641\n",
      "epoch 163; iter: 0; batch classifier loss: 0.387476; batch adversarial loss: 0.495040\n",
      "epoch 164; iter: 0; batch classifier loss: 0.325952; batch adversarial loss: 0.526084\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321255; batch adversarial loss: 0.467368\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377161; batch adversarial loss: 0.575706\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360964; batch adversarial loss: 0.563366\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351105; batch adversarial loss: 0.566750\n",
      "epoch 169; iter: 0; batch classifier loss: 0.378552; batch adversarial loss: 0.505921\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373263; batch adversarial loss: 0.535389\n",
      "epoch 171; iter: 0; batch classifier loss: 0.331591; batch adversarial loss: 0.515691\n",
      "epoch 172; iter: 0; batch classifier loss: 0.268444; batch adversarial loss: 0.541581\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322275; batch adversarial loss: 0.512971\n",
      "epoch 174; iter: 0; batch classifier loss: 0.271467; batch adversarial loss: 0.552159\n",
      "epoch 175; iter: 0; batch classifier loss: 0.312989; batch adversarial loss: 0.523949\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372560; batch adversarial loss: 0.644939\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383077; batch adversarial loss: 0.525218\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317303; batch adversarial loss: 0.495872\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298746; batch adversarial loss: 0.583162\n",
      "epoch 180; iter: 0; batch classifier loss: 0.427736; batch adversarial loss: 0.572691\n",
      "epoch 181; iter: 0; batch classifier loss: 0.297200; batch adversarial loss: 0.582484\n",
      "epoch 182; iter: 0; batch classifier loss: 0.293033; batch adversarial loss: 0.563445\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345176; batch adversarial loss: 0.526395\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309361; batch adversarial loss: 0.438200\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393833; batch adversarial loss: 0.516940\n",
      "epoch 186; iter: 0; batch classifier loss: 0.430361; batch adversarial loss: 0.437167\n",
      "epoch 187; iter: 0; batch classifier loss: 0.412828; batch adversarial loss: 0.514199\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324595; batch adversarial loss: 0.553954\n",
      "epoch 189; iter: 0; batch classifier loss: 0.282279; batch adversarial loss: 0.546115\n",
      "epoch 190; iter: 0; batch classifier loss: 0.289220; batch adversarial loss: 0.564100\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351132; batch adversarial loss: 0.535579\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345844; batch adversarial loss: 0.583874\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395039; batch adversarial loss: 0.606287\n",
      "epoch 194; iter: 0; batch classifier loss: 0.331970; batch adversarial loss: 0.593047\n",
      "epoch 195; iter: 0; batch classifier loss: 0.300293; batch adversarial loss: 0.594324\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328842; batch adversarial loss: 0.486906\n",
      "epoch 197; iter: 0; batch classifier loss: 0.319606; batch adversarial loss: 0.524835\n",
      "epoch 198; iter: 0; batch classifier loss: 0.316060; batch adversarial loss: 0.495367\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335322; batch adversarial loss: 0.456100\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657815; batch adversarial loss: 0.802296\n",
      "epoch 1; iter: 0; batch classifier loss: 0.758508; batch adversarial loss: 1.117586\n",
      "epoch 2; iter: 0; batch classifier loss: 0.905895; batch adversarial loss: 1.046404\n",
      "epoch 3; iter: 0; batch classifier loss: 0.931365; batch adversarial loss: 0.940570\n",
      "epoch 4; iter: 0; batch classifier loss: 0.865497; batch adversarial loss: 0.875693\n",
      "epoch 5; iter: 0; batch classifier loss: 0.737802; batch adversarial loss: 0.788463\n",
      "epoch 6; iter: 0; batch classifier loss: 0.761426; batch adversarial loss: 0.738968\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565649; batch adversarial loss: 0.685055\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483736; batch adversarial loss: 0.638666\n",
      "epoch 9; iter: 0; batch classifier loss: 0.631064; batch adversarial loss: 0.625397\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480572; batch adversarial loss: 0.573115\n",
      "epoch 11; iter: 0; batch classifier loss: 0.616739; batch adversarial loss: 0.606020\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569574; batch adversarial loss: 0.605992\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530753; batch adversarial loss: 0.567987\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530461; batch adversarial loss: 0.591851\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485084; batch adversarial loss: 0.579520\n",
      "epoch 16; iter: 0; batch classifier loss: 0.451919; batch adversarial loss: 0.588561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.592281; batch adversarial loss: 0.530998\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483286; batch adversarial loss: 0.518039\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451912; batch adversarial loss: 0.549971\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437543; batch adversarial loss: 0.520691\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514975; batch adversarial loss: 0.581832\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464824; batch adversarial loss: 0.571904\n",
      "epoch 23; iter: 0; batch classifier loss: 0.435900; batch adversarial loss: 0.507697\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456220; batch adversarial loss: 0.501426\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518875; batch adversarial loss: 0.612243\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498094; batch adversarial loss: 0.564345\n",
      "epoch 27; iter: 0; batch classifier loss: 0.486412; batch adversarial loss: 0.558215\n",
      "epoch 28; iter: 0; batch classifier loss: 0.500728; batch adversarial loss: 0.475281\n",
      "epoch 29; iter: 0; batch classifier loss: 0.525942; batch adversarial loss: 0.522944\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449522; batch adversarial loss: 0.572849\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497080; batch adversarial loss: 0.515823\n",
      "epoch 32; iter: 0; batch classifier loss: 0.533691; batch adversarial loss: 0.531245\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471796; batch adversarial loss: 0.485159\n",
      "epoch 34; iter: 0; batch classifier loss: 0.513871; batch adversarial loss: 0.485133\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484381; batch adversarial loss: 0.516021\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484490; batch adversarial loss: 0.539755\n",
      "epoch 37; iter: 0; batch classifier loss: 0.535529; batch adversarial loss: 0.587841\n",
      "epoch 38; iter: 0; batch classifier loss: 0.510674; batch adversarial loss: 0.586918\n",
      "epoch 39; iter: 0; batch classifier loss: 0.472427; batch adversarial loss: 0.502376\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471842; batch adversarial loss: 0.546692\n",
      "epoch 41; iter: 0; batch classifier loss: 0.556534; batch adversarial loss: 0.571371\n",
      "epoch 42; iter: 0; batch classifier loss: 0.528368; batch adversarial loss: 0.609174\n",
      "epoch 43; iter: 0; batch classifier loss: 0.360082; batch adversarial loss: 0.568449\n",
      "epoch 44; iter: 0; batch classifier loss: 0.479088; batch adversarial loss: 0.510086\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401353; batch adversarial loss: 0.574499\n",
      "epoch 46; iter: 0; batch classifier loss: 0.570395; batch adversarial loss: 0.553993\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393642; batch adversarial loss: 0.481366\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450950; batch adversarial loss: 0.525252\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522280; batch adversarial loss: 0.481376\n",
      "epoch 50; iter: 0; batch classifier loss: 0.489140; batch adversarial loss: 0.498411\n",
      "epoch 51; iter: 0; batch classifier loss: 0.476165; batch adversarial loss: 0.516850\n",
      "epoch 52; iter: 0; batch classifier loss: 0.367657; batch adversarial loss: 0.572780\n",
      "epoch 53; iter: 0; batch classifier loss: 0.407999; batch adversarial loss: 0.547101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455666; batch adversarial loss: 0.543051\n",
      "epoch 55; iter: 0; batch classifier loss: 0.451044; batch adversarial loss: 0.617723\n",
      "epoch 56; iter: 0; batch classifier loss: 0.476711; batch adversarial loss: 0.599253\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427559; batch adversarial loss: 0.489843\n",
      "epoch 58; iter: 0; batch classifier loss: 0.433705; batch adversarial loss: 0.498516\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392278; batch adversarial loss: 0.536050\n",
      "epoch 60; iter: 0; batch classifier loss: 0.408291; batch adversarial loss: 0.544418\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383687; batch adversarial loss: 0.589168\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397172; batch adversarial loss: 0.552665\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423446; batch adversarial loss: 0.552043\n",
      "epoch 64; iter: 0; batch classifier loss: 0.529059; batch adversarial loss: 0.507816\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409008; batch adversarial loss: 0.574583\n",
      "epoch 66; iter: 0; batch classifier loss: 0.334941; batch adversarial loss: 0.555303\n",
      "epoch 67; iter: 0; batch classifier loss: 0.468922; batch adversarial loss: 0.572203\n",
      "epoch 68; iter: 0; batch classifier loss: 0.470687; batch adversarial loss: 0.571417\n",
      "epoch 69; iter: 0; batch classifier loss: 0.460787; batch adversarial loss: 0.517673\n",
      "epoch 70; iter: 0; batch classifier loss: 0.390746; batch adversarial loss: 0.627474\n",
      "epoch 71; iter: 0; batch classifier loss: 0.368010; batch adversarial loss: 0.572684\n",
      "epoch 72; iter: 0; batch classifier loss: 0.354900; batch adversarial loss: 0.553158\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439746; batch adversarial loss: 0.526033\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416414; batch adversarial loss: 0.636609\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379820; batch adversarial loss: 0.507887\n",
      "epoch 76; iter: 0; batch classifier loss: 0.486166; batch adversarial loss: 0.525988\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404690; batch adversarial loss: 0.609111\n",
      "epoch 78; iter: 0; batch classifier loss: 0.340527; batch adversarial loss: 0.589794\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440928; batch adversarial loss: 0.469732\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423386; batch adversarial loss: 0.534367\n",
      "epoch 81; iter: 0; batch classifier loss: 0.325739; batch adversarial loss: 0.533487\n",
      "epoch 82; iter: 0; batch classifier loss: 0.351674; batch adversarial loss: 0.553361\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448613; batch adversarial loss: 0.553227\n",
      "epoch 84; iter: 0; batch classifier loss: 0.387664; batch adversarial loss: 0.580941\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410797; batch adversarial loss: 0.498565\n",
      "epoch 86; iter: 0; batch classifier loss: 0.351821; batch adversarial loss: 0.498515\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420741; batch adversarial loss: 0.572448\n",
      "epoch 88; iter: 0; batch classifier loss: 0.321408; batch adversarial loss: 0.460926\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427117; batch adversarial loss: 0.544247\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411169; batch adversarial loss: 0.553586\n",
      "epoch 91; iter: 0; batch classifier loss: 0.311115; batch adversarial loss: 0.619103\n",
      "epoch 92; iter: 0; batch classifier loss: 0.333069; batch adversarial loss: 0.526303\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383129; batch adversarial loss: 0.599782\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406176; batch adversarial loss: 0.599748\n",
      "epoch 95; iter: 0; batch classifier loss: 0.438673; batch adversarial loss: 0.637685\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375032; batch adversarial loss: 0.544453\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375481; batch adversarial loss: 0.480033\n",
      "epoch 98; iter: 0; batch classifier loss: 0.321983; batch adversarial loss: 0.489645\n",
      "epoch 99; iter: 0; batch classifier loss: 0.448929; batch adversarial loss: 0.562840\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399860; batch adversarial loss: 0.599887\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401399; batch adversarial loss: 0.581661\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410832; batch adversarial loss: 0.516542\n",
      "epoch 103; iter: 0; batch classifier loss: 0.334961; batch adversarial loss: 0.553171\n",
      "epoch 104; iter: 0; batch classifier loss: 0.425865; batch adversarial loss: 0.534982\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424542; batch adversarial loss: 0.608604\n",
      "epoch 106; iter: 0; batch classifier loss: 0.320803; batch adversarial loss: 0.599916\n",
      "epoch 107; iter: 0; batch classifier loss: 0.351816; batch adversarial loss: 0.571891\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366683; batch adversarial loss: 0.497736\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412998; batch adversarial loss: 0.461342\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396819; batch adversarial loss: 0.535074\n",
      "epoch 111; iter: 0; batch classifier loss: 0.298159; batch adversarial loss: 0.562760\n",
      "epoch 112; iter: 0; batch classifier loss: 0.468019; batch adversarial loss: 0.543787\n",
      "epoch 113; iter: 0; batch classifier loss: 0.327691; batch adversarial loss: 0.462569\n",
      "epoch 114; iter: 0; batch classifier loss: 0.303665; batch adversarial loss: 0.499183\n",
      "epoch 115; iter: 0; batch classifier loss: 0.413399; batch adversarial loss: 0.664185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.362942; batch adversarial loss: 0.591076\n",
      "epoch 117; iter: 0; batch classifier loss: 0.319677; batch adversarial loss: 0.489453\n",
      "epoch 118; iter: 0; batch classifier loss: 0.430619; batch adversarial loss: 0.608475\n",
      "epoch 119; iter: 0; batch classifier loss: 0.452530; batch adversarial loss: 0.638013\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380442; batch adversarial loss: 0.553875\n",
      "epoch 121; iter: 0; batch classifier loss: 0.372998; batch adversarial loss: 0.543199\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358758; batch adversarial loss: 0.527819\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388719; batch adversarial loss: 0.553626\n",
      "epoch 124; iter: 0; batch classifier loss: 0.277776; batch adversarial loss: 0.462114\n",
      "epoch 125; iter: 0; batch classifier loss: 0.464953; batch adversarial loss: 0.628040\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406801; batch adversarial loss: 0.489122\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378123; batch adversarial loss: 0.545040\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422498; batch adversarial loss: 0.525383\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403565; batch adversarial loss: 0.608763\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346629; batch adversarial loss: 0.553894\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343257; batch adversarial loss: 0.498570\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421444; batch adversarial loss: 0.572513\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377671; batch adversarial loss: 0.534612\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397935; batch adversarial loss: 0.571902\n",
      "epoch 135; iter: 0; batch classifier loss: 0.430393; batch adversarial loss: 0.544531\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373814; batch adversarial loss: 0.534351\n",
      "epoch 137; iter: 0; batch classifier loss: 0.258239; batch adversarial loss: 0.481159\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353352; batch adversarial loss: 0.434301\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428307; batch adversarial loss: 0.470617\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309625; batch adversarial loss: 0.480028\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363572; batch adversarial loss: 0.517800\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353042; batch adversarial loss: 0.497259\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330996; batch adversarial loss: 0.489380\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374777; batch adversarial loss: 0.544321\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365338; batch adversarial loss: 0.553836\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382320; batch adversarial loss: 0.563989\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381263; batch adversarial loss: 0.562219\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365567; batch adversarial loss: 0.525296\n",
      "epoch 149; iter: 0; batch classifier loss: 0.371618; batch adversarial loss: 0.516930\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384055; batch adversarial loss: 0.535656\n",
      "epoch 151; iter: 0; batch classifier loss: 0.291072; batch adversarial loss: 0.553969\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351241; batch adversarial loss: 0.526801\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370133; batch adversarial loss: 0.488931\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356217; batch adversarial loss: 0.619160\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370245; batch adversarial loss: 0.562981\n",
      "epoch 156; iter: 0; batch classifier loss: 0.311470; batch adversarial loss: 0.516310\n",
      "epoch 157; iter: 0; batch classifier loss: 0.342784; batch adversarial loss: 0.488961\n",
      "epoch 158; iter: 0; batch classifier loss: 0.428557; batch adversarial loss: 0.562551\n",
      "epoch 159; iter: 0; batch classifier loss: 0.314670; batch adversarial loss: 0.544597\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341204; batch adversarial loss: 0.590949\n",
      "epoch 161; iter: 0; batch classifier loss: 0.429859; batch adversarial loss: 0.553792\n",
      "epoch 162; iter: 0; batch classifier loss: 0.407564; batch adversarial loss: 0.535525\n",
      "epoch 163; iter: 0; batch classifier loss: 0.381565; batch adversarial loss: 0.479659\n",
      "epoch 164; iter: 0; batch classifier loss: 0.470136; batch adversarial loss: 0.562309\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329378; batch adversarial loss: 0.516804\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358073; batch adversarial loss: 0.599856\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335756; batch adversarial loss: 0.581510\n",
      "epoch 168; iter: 0; batch classifier loss: 0.311517; batch adversarial loss: 0.571150\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343626; batch adversarial loss: 0.515684\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322630; batch adversarial loss: 0.544269\n",
      "epoch 171; iter: 0; batch classifier loss: 0.435857; batch adversarial loss: 0.636618\n",
      "epoch 172; iter: 0; batch classifier loss: 0.301822; batch adversarial loss: 0.535525\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329342; batch adversarial loss: 0.581709\n",
      "epoch 174; iter: 0; batch classifier loss: 0.317708; batch adversarial loss: 0.536092\n",
      "epoch 175; iter: 0; batch classifier loss: 0.398104; batch adversarial loss: 0.544848\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410089; batch adversarial loss: 0.516180\n",
      "epoch 177; iter: 0; batch classifier loss: 0.412829; batch adversarial loss: 0.581221\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330621; batch adversarial loss: 0.581245\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364304; batch adversarial loss: 0.489750\n",
      "epoch 180; iter: 0; batch classifier loss: 0.405186; batch adversarial loss: 0.653868\n",
      "epoch 181; iter: 0; batch classifier loss: 0.327242; batch adversarial loss: 0.588880\n",
      "epoch 182; iter: 0; batch classifier loss: 0.280001; batch adversarial loss: 0.517071\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373190; batch adversarial loss: 0.535038\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381005; batch adversarial loss: 0.618172\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370824; batch adversarial loss: 0.572331\n",
      "epoch 186; iter: 0; batch classifier loss: 0.394132; batch adversarial loss: 0.572915\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365059; batch adversarial loss: 0.535752\n",
      "epoch 188; iter: 0; batch classifier loss: 0.307391; batch adversarial loss: 0.600428\n",
      "epoch 189; iter: 0; batch classifier loss: 0.313901; batch adversarial loss: 0.516695\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357341; batch adversarial loss: 0.526410\n",
      "epoch 191; iter: 0; batch classifier loss: 0.327703; batch adversarial loss: 0.498160\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315850; batch adversarial loss: 0.525956\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378779; batch adversarial loss: 0.581380\n",
      "epoch 194; iter: 0; batch classifier loss: 0.306060; batch adversarial loss: 0.618711\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332069; batch adversarial loss: 0.554018\n",
      "epoch 196; iter: 0; batch classifier loss: 0.460325; batch adversarial loss: 0.497941\n",
      "epoch 197; iter: 0; batch classifier loss: 0.302546; batch adversarial loss: 0.544922\n",
      "epoch 198; iter: 0; batch classifier loss: 0.407436; batch adversarial loss: 0.553326\n",
      "epoch 199; iter: 0; batch classifier loss: 0.279886; batch adversarial loss: 0.534961\n",
      "epoch 0; iter: 0; batch classifier loss: 0.659467; batch adversarial loss: 0.653024\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622330; batch adversarial loss: 0.649835\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573266; batch adversarial loss: 0.588302\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598913; batch adversarial loss: 0.613800\n",
      "epoch 4; iter: 0; batch classifier loss: 0.514751; batch adversarial loss: 0.626040\n",
      "epoch 5; iter: 0; batch classifier loss: 0.505007; batch adversarial loss: 0.643563\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578673; batch adversarial loss: 0.643112\n",
      "epoch 7; iter: 0; batch classifier loss: 0.473517; batch adversarial loss: 0.678926\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518291; batch adversarial loss: 0.542053\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487222; batch adversarial loss: 0.611085\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544554; batch adversarial loss: 0.627398\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490035; batch adversarial loss: 0.598046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.551130; batch adversarial loss: 0.575605\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580885; batch adversarial loss: 0.519757\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553623; batch adversarial loss: 0.536651\n",
      "epoch 15; iter: 0; batch classifier loss: 0.518917; batch adversarial loss: 0.545133\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454242; batch adversarial loss: 0.532772\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510074; batch adversarial loss: 0.598936\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513863; batch adversarial loss: 0.561680\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441316; batch adversarial loss: 0.592756\n",
      "epoch 20; iter: 0; batch classifier loss: 0.415311; batch adversarial loss: 0.646458\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513050; batch adversarial loss: 0.514982\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470759; batch adversarial loss: 0.534823\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438433; batch adversarial loss: 0.569333\n",
      "epoch 24; iter: 0; batch classifier loss: 0.450088; batch adversarial loss: 0.544788\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453203; batch adversarial loss: 0.562563\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463164; batch adversarial loss: 0.555529\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474687; batch adversarial loss: 0.538804\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465028; batch adversarial loss: 0.611667\n",
      "epoch 29; iter: 0; batch classifier loss: 0.566242; batch adversarial loss: 0.545337\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482883; batch adversarial loss: 0.541766\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449606; batch adversarial loss: 0.517018\n",
      "epoch 32; iter: 0; batch classifier loss: 0.480770; batch adversarial loss: 0.552542\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452602; batch adversarial loss: 0.539203\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456797; batch adversarial loss: 0.623490\n",
      "epoch 35; iter: 0; batch classifier loss: 0.522089; batch adversarial loss: 0.536733\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353177; batch adversarial loss: 0.529969\n",
      "epoch 37; iter: 0; batch classifier loss: 0.484137; batch adversarial loss: 0.535556\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469288; batch adversarial loss: 0.534839\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464557; batch adversarial loss: 0.548122\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446525; batch adversarial loss: 0.536256\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462896; batch adversarial loss: 0.474621\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470319; batch adversarial loss: 0.528860\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433939; batch adversarial loss: 0.581011\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435420; batch adversarial loss: 0.471618\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438493; batch adversarial loss: 0.597953\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382211; batch adversarial loss: 0.544187\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439028; batch adversarial loss: 0.572690\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418720; batch adversarial loss: 0.464119\n",
      "epoch 49; iter: 0; batch classifier loss: 0.490203; batch adversarial loss: 0.538423\n",
      "epoch 50; iter: 0; batch classifier loss: 0.476070; batch adversarial loss: 0.589148\n",
      "epoch 51; iter: 0; batch classifier loss: 0.401368; batch adversarial loss: 0.534443\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438401; batch adversarial loss: 0.519033\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423736; batch adversarial loss: 0.517489\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402249; batch adversarial loss: 0.516829\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417054; batch adversarial loss: 0.581419\n",
      "epoch 56; iter: 0; batch classifier loss: 0.450276; batch adversarial loss: 0.571675\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437117; batch adversarial loss: 0.541130\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429847; batch adversarial loss: 0.562656\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369611; batch adversarial loss: 0.483070\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391925; batch adversarial loss: 0.525961\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391750; batch adversarial loss: 0.463865\n",
      "epoch 62; iter: 0; batch classifier loss: 0.359741; batch adversarial loss: 0.492605\n",
      "epoch 63; iter: 0; batch classifier loss: 0.389562; batch adversarial loss: 0.519292\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394136; batch adversarial loss: 0.546945\n",
      "epoch 65; iter: 0; batch classifier loss: 0.336167; batch adversarial loss: 0.518628\n",
      "epoch 66; iter: 0; batch classifier loss: 0.497816; batch adversarial loss: 0.625642\n",
      "epoch 67; iter: 0; batch classifier loss: 0.357203; batch adversarial loss: 0.536451\n",
      "epoch 68; iter: 0; batch classifier loss: 0.366659; batch adversarial loss: 0.563253\n",
      "epoch 69; iter: 0; batch classifier loss: 0.500983; batch adversarial loss: 0.596958\n",
      "epoch 70; iter: 0; batch classifier loss: 0.364398; batch adversarial loss: 0.562173\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422744; batch adversarial loss: 0.487885\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390334; batch adversarial loss: 0.634675\n",
      "epoch 73; iter: 0; batch classifier loss: 0.444220; batch adversarial loss: 0.516299\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452659; batch adversarial loss: 0.589770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.577944; batch adversarial loss: 0.507230\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412993; batch adversarial loss: 0.569780\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409561; batch adversarial loss: 0.573380\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389775; batch adversarial loss: 0.470521\n",
      "epoch 79; iter: 0; batch classifier loss: 0.335658; batch adversarial loss: 0.536563\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411584; batch adversarial loss: 0.508945\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421637; batch adversarial loss: 0.499014\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406199; batch adversarial loss: 0.528061\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386225; batch adversarial loss: 0.572420\n",
      "epoch 84; iter: 0; batch classifier loss: 0.432702; batch adversarial loss: 0.555603\n",
      "epoch 85; iter: 0; batch classifier loss: 0.375650; batch adversarial loss: 0.628411\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371307; batch adversarial loss: 0.607384\n",
      "epoch 87; iter: 0; batch classifier loss: 0.447949; batch adversarial loss: 0.641372\n",
      "epoch 88; iter: 0; batch classifier loss: 0.336251; batch adversarial loss: 0.500934\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355365; batch adversarial loss: 0.535167\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419350; batch adversarial loss: 0.423887\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391127; batch adversarial loss: 0.536022\n",
      "epoch 92; iter: 0; batch classifier loss: 0.496086; batch adversarial loss: 0.588249\n",
      "epoch 93; iter: 0; batch classifier loss: 0.407032; batch adversarial loss: 0.501186\n",
      "epoch 94; iter: 0; batch classifier loss: 0.364206; batch adversarial loss: 0.543739\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440684; batch adversarial loss: 0.597479\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422530; batch adversarial loss: 0.625895\n",
      "epoch 97; iter: 0; batch classifier loss: 0.473910; batch adversarial loss: 0.597763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359196; batch adversarial loss: 0.552084\n",
      "epoch 99; iter: 0; batch classifier loss: 0.346205; batch adversarial loss: 0.561915\n",
      "epoch 100; iter: 0; batch classifier loss: 0.354854; batch adversarial loss: 0.435609\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393253; batch adversarial loss: 0.545813\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400922; batch adversarial loss: 0.472405\n",
      "epoch 103; iter: 0; batch classifier loss: 0.466811; batch adversarial loss: 0.545833\n",
      "epoch 104; iter: 0; batch classifier loss: 0.437868; batch adversarial loss: 0.546375\n",
      "epoch 105; iter: 0; batch classifier loss: 0.367631; batch adversarial loss: 0.514982\n",
      "epoch 106; iter: 0; batch classifier loss: 0.329127; batch adversarial loss: 0.545104\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379450; batch adversarial loss: 0.581591\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353968; batch adversarial loss: 0.534484\n",
      "epoch 109; iter: 0; batch classifier loss: 0.394704; batch adversarial loss: 0.493644\n",
      "epoch 110; iter: 0; batch classifier loss: 0.483571; batch adversarial loss: 0.590142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.396241; batch adversarial loss: 0.545700\n",
      "epoch 112; iter: 0; batch classifier loss: 0.369467; batch adversarial loss: 0.543073\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363144; batch adversarial loss: 0.517973\n",
      "epoch 114; iter: 0; batch classifier loss: 0.334667; batch adversarial loss: 0.536224\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396930; batch adversarial loss: 0.616120\n",
      "epoch 116; iter: 0; batch classifier loss: 0.354528; batch adversarial loss: 0.518546\n",
      "epoch 117; iter: 0; batch classifier loss: 0.316879; batch adversarial loss: 0.527571\n",
      "epoch 118; iter: 0; batch classifier loss: 0.411675; batch adversarial loss: 0.606672\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371596; batch adversarial loss: 0.562587\n",
      "epoch 120; iter: 0; batch classifier loss: 0.431278; batch adversarial loss: 0.534042\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335973; batch adversarial loss: 0.526935\n",
      "epoch 122; iter: 0; batch classifier loss: 0.360407; batch adversarial loss: 0.472384\n",
      "epoch 123; iter: 0; batch classifier loss: 0.492006; batch adversarial loss: 0.579336\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397062; batch adversarial loss: 0.533751\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342556; batch adversarial loss: 0.607027\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365758; batch adversarial loss: 0.524739\n",
      "epoch 127; iter: 0; batch classifier loss: 0.308006; batch adversarial loss: 0.516244\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389647; batch adversarial loss: 0.526584\n",
      "epoch 129; iter: 0; batch classifier loss: 0.334714; batch adversarial loss: 0.499929\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388828; batch adversarial loss: 0.589542\n",
      "epoch 131; iter: 0; batch classifier loss: 0.478962; batch adversarial loss: 0.516557\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413515; batch adversarial loss: 0.515798\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357422; batch adversarial loss: 0.607717\n",
      "epoch 134; iter: 0; batch classifier loss: 0.431357; batch adversarial loss: 0.561360\n",
      "epoch 135; iter: 0; batch classifier loss: 0.425520; batch adversarial loss: 0.581168\n",
      "epoch 136; iter: 0; batch classifier loss: 0.418893; batch adversarial loss: 0.556136\n",
      "epoch 137; iter: 0; batch classifier loss: 0.427726; batch adversarial loss: 0.598687\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375015; batch adversarial loss: 0.488730\n",
      "epoch 139; iter: 0; batch classifier loss: 0.296863; batch adversarial loss: 0.625422\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360356; batch adversarial loss: 0.654286\n",
      "epoch 141; iter: 0; batch classifier loss: 0.305088; batch adversarial loss: 0.518293\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335107; batch adversarial loss: 0.519040\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401464; batch adversarial loss: 0.580538\n",
      "epoch 144; iter: 0; batch classifier loss: 0.424756; batch adversarial loss: 0.589895\n",
      "epoch 145; iter: 0; batch classifier loss: 0.279891; batch adversarial loss: 0.598183\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404507; batch adversarial loss: 0.581475\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372981; batch adversarial loss: 0.571070\n",
      "epoch 148; iter: 0; batch classifier loss: 0.321081; batch adversarial loss: 0.579962\n",
      "epoch 149; iter: 0; batch classifier loss: 0.395918; batch adversarial loss: 0.535951\n",
      "epoch 150; iter: 0; batch classifier loss: 0.323896; batch adversarial loss: 0.606726\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378075; batch adversarial loss: 0.517797\n",
      "epoch 152; iter: 0; batch classifier loss: 0.291789; batch adversarial loss: 0.472174\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385478; batch adversarial loss: 0.507557\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340264; batch adversarial loss: 0.643453\n",
      "epoch 155; iter: 0; batch classifier loss: 0.471850; batch adversarial loss: 0.579944\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403542; batch adversarial loss: 0.549801\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331264; batch adversarial loss: 0.622274\n",
      "epoch 158; iter: 0; batch classifier loss: 0.385250; batch adversarial loss: 0.601835\n",
      "epoch 159; iter: 0; batch classifier loss: 0.412604; batch adversarial loss: 0.591568\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404958; batch adversarial loss: 0.523685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.348060; batch adversarial loss: 0.528792\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353651; batch adversarial loss: 0.652982\n",
      "epoch 163; iter: 0; batch classifier loss: 0.395897; batch adversarial loss: 0.554020\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410582; batch adversarial loss: 0.500273\n",
      "epoch 165; iter: 0; batch classifier loss: 0.433711; batch adversarial loss: 0.633714\n",
      "epoch 166; iter: 0; batch classifier loss: 0.419049; batch adversarial loss: 0.597052\n",
      "epoch 167; iter: 0; batch classifier loss: 0.398566; batch adversarial loss: 0.527623\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343556; batch adversarial loss: 0.579638\n",
      "epoch 169; iter: 0; batch classifier loss: 0.409045; batch adversarial loss: 0.544771\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393355; batch adversarial loss: 0.456067\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349990; batch adversarial loss: 0.500419\n",
      "epoch 172; iter: 0; batch classifier loss: 0.489391; batch adversarial loss: 0.554326\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385598; batch adversarial loss: 0.579935\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392319; batch adversarial loss: 0.571192\n",
      "epoch 175; iter: 0; batch classifier loss: 0.385194; batch adversarial loss: 0.563119\n",
      "epoch 176; iter: 0; batch classifier loss: 0.510147; batch adversarial loss: 0.544658\n",
      "epoch 177; iter: 0; batch classifier loss: 0.404070; batch adversarial loss: 0.517687\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372240; batch adversarial loss: 0.598281\n",
      "epoch 179; iter: 0; batch classifier loss: 0.305109; batch adversarial loss: 0.516327\n",
      "epoch 180; iter: 0; batch classifier loss: 0.272016; batch adversarial loss: 0.562123\n",
      "epoch 181; iter: 0; batch classifier loss: 0.317717; batch adversarial loss: 0.563757\n",
      "epoch 182; iter: 0; batch classifier loss: 0.335262; batch adversarial loss: 0.526656\n",
      "epoch 183; iter: 0; batch classifier loss: 0.357039; batch adversarial loss: 0.563712\n",
      "epoch 184; iter: 0; batch classifier loss: 0.316858; batch adversarial loss: 0.545551\n",
      "epoch 185; iter: 0; batch classifier loss: 0.317739; batch adversarial loss: 0.625934\n",
      "epoch 186; iter: 0; batch classifier loss: 0.393837; batch adversarial loss: 0.535792\n",
      "epoch 187; iter: 0; batch classifier loss: 0.431988; batch adversarial loss: 0.525877\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346309; batch adversarial loss: 0.597245\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365737; batch adversarial loss: 0.661605\n",
      "epoch 190; iter: 0; batch classifier loss: 0.458103; batch adversarial loss: 0.517061\n",
      "epoch 191; iter: 0; batch classifier loss: 0.332801; batch adversarial loss: 0.571302\n",
      "epoch 192; iter: 0; batch classifier loss: 0.258497; batch adversarial loss: 0.500013\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368718; batch adversarial loss: 0.536151\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357447; batch adversarial loss: 0.570516\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343668; batch adversarial loss: 0.596341\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357691; batch adversarial loss: 0.526475\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350072; batch adversarial loss: 0.580361\n",
      "epoch 198; iter: 0; batch classifier loss: 0.326693; batch adversarial loss: 0.525596\n",
      "epoch 199; iter: 0; batch classifier loss: 0.436895; batch adversarial loss: 0.543444\n",
      "epoch 0; iter: 0; batch classifier loss: 0.800022; batch adversarial loss: 0.713895\n",
      "epoch 1; iter: 0; batch classifier loss: 0.562534; batch adversarial loss: 0.670711\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571095; batch adversarial loss: 0.658138\n",
      "epoch 3; iter: 0; batch classifier loss: 0.638855; batch adversarial loss: 0.651605\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568024; batch adversarial loss: 0.626948\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585340; batch adversarial loss: 0.630375\n",
      "epoch 6; iter: 0; batch classifier loss: 0.604710; batch adversarial loss: 0.632069\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465723; batch adversarial loss: 0.593379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.583745; batch adversarial loss: 0.601205\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516820; batch adversarial loss: 0.586643\n",
      "epoch 10; iter: 0; batch classifier loss: 0.448187; batch adversarial loss: 0.554397\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508109; batch adversarial loss: 0.526724\n",
      "epoch 12; iter: 0; batch classifier loss: 0.546077; batch adversarial loss: 0.568279\n",
      "epoch 13; iter: 0; batch classifier loss: 0.531567; batch adversarial loss: 0.570923\n",
      "epoch 14; iter: 0; batch classifier loss: 0.575470; batch adversarial loss: 0.547418\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558794; batch adversarial loss: 0.540717\n",
      "epoch 16; iter: 0; batch classifier loss: 0.588824; batch adversarial loss: 0.551638\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481278; batch adversarial loss: 0.536535\n",
      "epoch 18; iter: 0; batch classifier loss: 0.494531; batch adversarial loss: 0.615093\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554111; batch adversarial loss: 0.534498\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463133; batch adversarial loss: 0.532449\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467989; batch adversarial loss: 0.562342\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477244; batch adversarial loss: 0.525296\n",
      "epoch 23; iter: 0; batch classifier loss: 0.526032; batch adversarial loss: 0.579796\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498931; batch adversarial loss: 0.589974\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528168; batch adversarial loss: 0.582707\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513242; batch adversarial loss: 0.565380\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475863; batch adversarial loss: 0.547691\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499913; batch adversarial loss: 0.507782\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437335; batch adversarial loss: 0.526575\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432056; batch adversarial loss: 0.499320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449264; batch adversarial loss: 0.560244\n",
      "epoch 32; iter: 0; batch classifier loss: 0.394812; batch adversarial loss: 0.599029\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450693; batch adversarial loss: 0.520052\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482617; batch adversarial loss: 0.532506\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451186; batch adversarial loss: 0.661811\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495942; batch adversarial loss: 0.553022\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406487; batch adversarial loss: 0.560105\n",
      "epoch 38; iter: 0; batch classifier loss: 0.402753; batch adversarial loss: 0.547922\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449301; batch adversarial loss: 0.538542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448774; batch adversarial loss: 0.554167\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428790; batch adversarial loss: 0.538413\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406866; batch adversarial loss: 0.583797\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419371; batch adversarial loss: 0.597925\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484002; batch adversarial loss: 0.554626\n",
      "epoch 45; iter: 0; batch classifier loss: 0.515081; batch adversarial loss: 0.546367\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438307; batch adversarial loss: 0.571306\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405839; batch adversarial loss: 0.562139\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407893; batch adversarial loss: 0.552787\n",
      "epoch 49; iter: 0; batch classifier loss: 0.386742; batch adversarial loss: 0.560242\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395317; batch adversarial loss: 0.579672\n",
      "epoch 51; iter: 0; batch classifier loss: 0.478150; batch adversarial loss: 0.536274\n",
      "epoch 52; iter: 0; batch classifier loss: 0.369891; batch adversarial loss: 0.526502\n",
      "epoch 53; iter: 0; batch classifier loss: 0.370912; batch adversarial loss: 0.545455\n",
      "epoch 54; iter: 0; batch classifier loss: 0.368719; batch adversarial loss: 0.510367\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421964; batch adversarial loss: 0.562643\n",
      "epoch 56; iter: 0; batch classifier loss: 0.478636; batch adversarial loss: 0.571829\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408214; batch adversarial loss: 0.464500\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427722; batch adversarial loss: 0.506380\n",
      "epoch 59; iter: 0; batch classifier loss: 0.397721; batch adversarial loss: 0.585345\n",
      "epoch 60; iter: 0; batch classifier loss: 0.459493; batch adversarial loss: 0.642740\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460645; batch adversarial loss: 0.549785\n",
      "epoch 62; iter: 0; batch classifier loss: 0.483583; batch adversarial loss: 0.600335\n",
      "epoch 63; iter: 0; batch classifier loss: 0.362822; batch adversarial loss: 0.493306\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424941; batch adversarial loss: 0.541572\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416183; batch adversarial loss: 0.561955\n",
      "epoch 66; iter: 0; batch classifier loss: 0.370021; batch adversarial loss: 0.580436\n",
      "epoch 67; iter: 0; batch classifier loss: 0.502814; batch adversarial loss: 0.623072\n",
      "epoch 68; iter: 0; batch classifier loss: 0.463058; batch adversarial loss: 0.580173\n",
      "epoch 69; iter: 0; batch classifier loss: 0.480133; batch adversarial loss: 0.483766\n",
      "epoch 70; iter: 0; batch classifier loss: 0.456813; batch adversarial loss: 0.553236\n",
      "epoch 71; iter: 0; batch classifier loss: 0.464810; batch adversarial loss: 0.563080\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455432; batch adversarial loss: 0.570964\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373761; batch adversarial loss: 0.561108\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423917; batch adversarial loss: 0.536421\n",
      "epoch 75; iter: 0; batch classifier loss: 0.513763; batch adversarial loss: 0.562322\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399012; batch adversarial loss: 0.553213\n",
      "epoch 77; iter: 0; batch classifier loss: 0.367012; batch adversarial loss: 0.544095\n",
      "epoch 78; iter: 0; batch classifier loss: 0.492005; batch adversarial loss: 0.544517\n",
      "epoch 79; iter: 0; batch classifier loss: 0.454548; batch adversarial loss: 0.500809\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470107; batch adversarial loss: 0.482388\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376369; batch adversarial loss: 0.528858\n",
      "epoch 82; iter: 0; batch classifier loss: 0.456272; batch adversarial loss: 0.472516\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387543; batch adversarial loss: 0.552812\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440374; batch adversarial loss: 0.508263\n",
      "epoch 85; iter: 0; batch classifier loss: 0.472740; batch adversarial loss: 0.579624\n",
      "epoch 86; iter: 0; batch classifier loss: 0.491410; batch adversarial loss: 0.493957\n",
      "epoch 87; iter: 0; batch classifier loss: 0.312552; batch adversarial loss: 0.581478\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399516; batch adversarial loss: 0.542875\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357571; batch adversarial loss: 0.588988\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427650; batch adversarial loss: 0.508996\n",
      "epoch 91; iter: 0; batch classifier loss: 0.342039; batch adversarial loss: 0.614965\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434450; batch adversarial loss: 0.659372\n",
      "epoch 93; iter: 0; batch classifier loss: 0.333030; batch adversarial loss: 0.554241\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374986; batch adversarial loss: 0.535936\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440301; batch adversarial loss: 0.545255\n",
      "epoch 96; iter: 0; batch classifier loss: 0.436288; batch adversarial loss: 0.597361\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440658; batch adversarial loss: 0.526901\n",
      "epoch 98; iter: 0; batch classifier loss: 0.297879; batch adversarial loss: 0.553676\n",
      "epoch 99; iter: 0; batch classifier loss: 0.426091; batch adversarial loss: 0.508720\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383031; batch adversarial loss: 0.624142\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426905; batch adversarial loss: 0.571173\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412885; batch adversarial loss: 0.563931\n",
      "epoch 103; iter: 0; batch classifier loss: 0.334174; batch adversarial loss: 0.534995\n",
      "epoch 104; iter: 0; batch classifier loss: 0.403150; batch adversarial loss: 0.577586\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342795; batch adversarial loss: 0.650227\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398698; batch adversarial loss: 0.543881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.340713; batch adversarial loss: 0.524315\n",
      "epoch 108; iter: 0; batch classifier loss: 0.478922; batch adversarial loss: 0.426731\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403000; batch adversarial loss: 0.544633\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385609; batch adversarial loss: 0.589656\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436309; batch adversarial loss: 0.600197\n",
      "epoch 112; iter: 0; batch classifier loss: 0.399550; batch adversarial loss: 0.616569\n",
      "epoch 113; iter: 0; batch classifier loss: 0.436150; batch adversarial loss: 0.492900\n",
      "epoch 114; iter: 0; batch classifier loss: 0.500858; batch adversarial loss: 0.562261\n",
      "epoch 115; iter: 0; batch classifier loss: 0.432600; batch adversarial loss: 0.538244\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379277; batch adversarial loss: 0.589393\n",
      "epoch 117; iter: 0; batch classifier loss: 0.418858; batch adversarial loss: 0.570395\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391058; batch adversarial loss: 0.544487\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379799; batch adversarial loss: 0.597175\n",
      "epoch 120; iter: 0; batch classifier loss: 0.453411; batch adversarial loss: 0.526089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.342390; batch adversarial loss: 0.571418\n",
      "epoch 122; iter: 0; batch classifier loss: 0.441726; batch adversarial loss: 0.535483\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366222; batch adversarial loss: 0.483856\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399886; batch adversarial loss: 0.578340\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379728; batch adversarial loss: 0.482287\n",
      "epoch 126; iter: 0; batch classifier loss: 0.419468; batch adversarial loss: 0.598034\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370247; batch adversarial loss: 0.591924\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349388; batch adversarial loss: 0.606404\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401670; batch adversarial loss: 0.589263\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402159; batch adversarial loss: 0.545636\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382684; batch adversarial loss: 0.554392\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359064; batch adversarial loss: 0.526674\n",
      "epoch 133; iter: 0; batch classifier loss: 0.459038; batch adversarial loss: 0.554548\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379136; batch adversarial loss: 0.561873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.446119; batch adversarial loss: 0.597610\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397248; batch adversarial loss: 0.536613\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349481; batch adversarial loss: 0.588814\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380469; batch adversarial loss: 0.553891\n",
      "epoch 139; iter: 0; batch classifier loss: 0.444106; batch adversarial loss: 0.615620\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374376; batch adversarial loss: 0.579980\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359545; batch adversarial loss: 0.571732\n",
      "epoch 142; iter: 0; batch classifier loss: 0.373909; batch adversarial loss: 0.527540\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383544; batch adversarial loss: 0.581154\n",
      "epoch 144; iter: 0; batch classifier loss: 0.325238; batch adversarial loss: 0.570023\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363162; batch adversarial loss: 0.488637\n",
      "epoch 146; iter: 0; batch classifier loss: 0.407596; batch adversarial loss: 0.587389\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355924; batch adversarial loss: 0.543688\n",
      "epoch 148; iter: 0; batch classifier loss: 0.340829; batch adversarial loss: 0.551989\n",
      "epoch 149; iter: 0; batch classifier loss: 0.404701; batch adversarial loss: 0.436608\n",
      "epoch 150; iter: 0; batch classifier loss: 0.441135; batch adversarial loss: 0.548462\n",
      "epoch 151; iter: 0; batch classifier loss: 0.389066; batch adversarial loss: 0.527406\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352209; batch adversarial loss: 0.553007\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369802; batch adversarial loss: 0.566161\n",
      "epoch 154; iter: 0; batch classifier loss: 0.408740; batch adversarial loss: 0.552712\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376530; batch adversarial loss: 0.509187\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334825; batch adversarial loss: 0.485073\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365366; batch adversarial loss: 0.527663\n",
      "epoch 158; iter: 0; batch classifier loss: 0.349644; batch adversarial loss: 0.546861\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391113; batch adversarial loss: 0.573211\n",
      "epoch 160; iter: 0; batch classifier loss: 0.327549; batch adversarial loss: 0.554345\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357740; batch adversarial loss: 0.579350\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355303; batch adversarial loss: 0.596199\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391058; batch adversarial loss: 0.553341\n",
      "epoch 164; iter: 0; batch classifier loss: 0.464342; batch adversarial loss: 0.605766\n",
      "epoch 165; iter: 0; batch classifier loss: 0.322830; batch adversarial loss: 0.448563\n",
      "epoch 166; iter: 0; batch classifier loss: 0.417805; batch adversarial loss: 0.552959\n",
      "epoch 167; iter: 0; batch classifier loss: 0.295063; batch adversarial loss: 0.535904\n",
      "epoch 168; iter: 0; batch classifier loss: 0.459016; batch adversarial loss: 0.563526\n",
      "epoch 169; iter: 0; batch classifier loss: 0.430609; batch adversarial loss: 0.553735\n",
      "epoch 170; iter: 0; batch classifier loss: 0.309085; batch adversarial loss: 0.571671\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381239; batch adversarial loss: 0.561865\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336315; batch adversarial loss: 0.473639\n",
      "epoch 173; iter: 0; batch classifier loss: 0.313070; batch adversarial loss: 0.552483\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396285; batch adversarial loss: 0.509258\n",
      "epoch 175; iter: 0; batch classifier loss: 0.288014; batch adversarial loss: 0.562661\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393147; batch adversarial loss: 0.547466\n",
      "epoch 177; iter: 0; batch classifier loss: 0.299156; batch adversarial loss: 0.500960\n",
      "epoch 178; iter: 0; batch classifier loss: 0.424475; batch adversarial loss: 0.616132\n",
      "epoch 179; iter: 0; batch classifier loss: 0.405151; batch adversarial loss: 0.588555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.442523; batch adversarial loss: 0.537111\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384383; batch adversarial loss: 0.676065\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337021; batch adversarial loss: 0.569715\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376206; batch adversarial loss: 0.578156\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317120; batch adversarial loss: 0.580886\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333660; batch adversarial loss: 0.543543\n",
      "epoch 186; iter: 0; batch classifier loss: 0.298840; batch adversarial loss: 0.612583\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371465; batch adversarial loss: 0.462149\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336867; batch adversarial loss: 0.528395\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292110; batch adversarial loss: 0.571440\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344525; batch adversarial loss: 0.536143\n",
      "epoch 191; iter: 0; batch classifier loss: 0.326926; batch adversarial loss: 0.525816\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396052; batch adversarial loss: 0.572970\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403261; batch adversarial loss: 0.595187\n",
      "epoch 194; iter: 0; batch classifier loss: 0.295086; batch adversarial loss: 0.555121\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317104; batch adversarial loss: 0.607540\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355574; batch adversarial loss: 0.636079\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360074; batch adversarial loss: 0.597860\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358648; batch adversarial loss: 0.509939\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380182; batch adversarial loss: 0.562332\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698129; batch adversarial loss: 0.539375\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574827; batch adversarial loss: 0.642733\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574374; batch adversarial loss: 0.684601\n",
      "epoch 3; iter: 0; batch classifier loss: 0.600361; batch adversarial loss: 0.696953\n",
      "epoch 4; iter: 0; batch classifier loss: 0.660262; batch adversarial loss: 0.730295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.544078; batch adversarial loss: 0.610186\n",
      "epoch 6; iter: 0; batch classifier loss: 0.671562; batch adversarial loss: 0.778587\n",
      "epoch 7; iter: 0; batch classifier loss: 0.684038; batch adversarial loss: 0.628928\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558204; batch adversarial loss: 0.599224\n",
      "epoch 9; iter: 0; batch classifier loss: 0.594361; batch adversarial loss: 0.660223\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540654; batch adversarial loss: 0.586882\n",
      "epoch 11; iter: 0; batch classifier loss: 0.628695; batch adversarial loss: 0.598754\n",
      "epoch 12; iter: 0; batch classifier loss: 0.597111; batch adversarial loss: 0.541869\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557763; batch adversarial loss: 0.514709\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497404; batch adversarial loss: 0.561634\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521067; batch adversarial loss: 0.466920\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453482; batch adversarial loss: 0.555640\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473598; batch adversarial loss: 0.531888\n",
      "epoch 18; iter: 0; batch classifier loss: 0.434169; batch adversarial loss: 0.687243\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437623; batch adversarial loss: 0.470959\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466992; batch adversarial loss: 0.505769\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481209; batch adversarial loss: 0.553440\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475714; batch adversarial loss: 0.613801\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504678; batch adversarial loss: 0.493325\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478163; batch adversarial loss: 0.489990\n",
      "epoch 25; iter: 0; batch classifier loss: 0.538045; batch adversarial loss: 0.543195\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492140; batch adversarial loss: 0.504369\n",
      "epoch 27; iter: 0; batch classifier loss: 0.408917; batch adversarial loss: 0.527258\n",
      "epoch 28; iter: 0; batch classifier loss: 0.518311; batch adversarial loss: 0.554097\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463820; batch adversarial loss: 0.553267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471249; batch adversarial loss: 0.501338\n",
      "epoch 31; iter: 0; batch classifier loss: 0.527844; batch adversarial loss: 0.572096\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460629; batch adversarial loss: 0.536474\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497577; batch adversarial loss: 0.497697\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310498; batch adversarial loss: 0.527487\n",
      "epoch 35; iter: 0; batch classifier loss: 0.387955; batch adversarial loss: 0.508056\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448155; batch adversarial loss: 0.457930\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500489; batch adversarial loss: 0.538930\n",
      "epoch 38; iter: 0; batch classifier loss: 0.536682; batch adversarial loss: 0.534083\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405958; batch adversarial loss: 0.526222\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451544; batch adversarial loss: 0.544242\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462071; batch adversarial loss: 0.589812\n",
      "epoch 42; iter: 0; batch classifier loss: 0.404482; batch adversarial loss: 0.525050\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467349; batch adversarial loss: 0.591740\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382903; batch adversarial loss: 0.628468\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397059; batch adversarial loss: 0.600836\n",
      "epoch 46; iter: 0; batch classifier loss: 0.386060; batch adversarial loss: 0.534492\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412471; batch adversarial loss: 0.564943\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420323; batch adversarial loss: 0.563987\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391209; batch adversarial loss: 0.563784\n",
      "epoch 50; iter: 0; batch classifier loss: 0.502468; batch adversarial loss: 0.497436\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399440; batch adversarial loss: 0.678800\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409033; batch adversarial loss: 0.516262\n",
      "epoch 53; iter: 0; batch classifier loss: 0.345121; batch adversarial loss: 0.592918\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428689; batch adversarial loss: 0.534720\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409900; batch adversarial loss: 0.506698\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415213; batch adversarial loss: 0.583007\n",
      "epoch 57; iter: 0; batch classifier loss: 0.371732; batch adversarial loss: 0.621387\n",
      "epoch 58; iter: 0; batch classifier loss: 0.405108; batch adversarial loss: 0.526852\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357359; batch adversarial loss: 0.526114\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402673; batch adversarial loss: 0.476632\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426888; batch adversarial loss: 0.571946\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417978; batch adversarial loss: 0.524157\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463409; batch adversarial loss: 0.532978\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377352; batch adversarial loss: 0.532867\n",
      "epoch 65; iter: 0; batch classifier loss: 0.392622; batch adversarial loss: 0.565209\n",
      "epoch 66; iter: 0; batch classifier loss: 0.515470; batch adversarial loss: 0.604639\n",
      "epoch 67; iter: 0; batch classifier loss: 0.358235; batch adversarial loss: 0.554864\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417184; batch adversarial loss: 0.572863\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404903; batch adversarial loss: 0.559534\n",
      "epoch 70; iter: 0; batch classifier loss: 0.371937; batch adversarial loss: 0.562893\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480858; batch adversarial loss: 0.546201\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432285; batch adversarial loss: 0.564604\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412219; batch adversarial loss: 0.551033\n",
      "epoch 74; iter: 0; batch classifier loss: 0.349062; batch adversarial loss: 0.517702\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423214; batch adversarial loss: 0.566272\n",
      "epoch 76; iter: 0; batch classifier loss: 0.496694; batch adversarial loss: 0.508065\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378428; batch adversarial loss: 0.619169\n",
      "epoch 78; iter: 0; batch classifier loss: 0.464003; batch adversarial loss: 0.469862\n",
      "epoch 79; iter: 0; batch classifier loss: 0.355380; batch adversarial loss: 0.592216\n",
      "epoch 80; iter: 0; batch classifier loss: 0.413235; batch adversarial loss: 0.516226\n",
      "epoch 81; iter: 0; batch classifier loss: 0.469087; batch adversarial loss: 0.487593\n",
      "epoch 82; iter: 0; batch classifier loss: 0.331157; batch adversarial loss: 0.506382\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392433; batch adversarial loss: 0.469019\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389030; batch adversarial loss: 0.592182\n",
      "epoch 85; iter: 0; batch classifier loss: 0.345877; batch adversarial loss: 0.431080\n",
      "epoch 86; iter: 0; batch classifier loss: 0.392002; batch adversarial loss: 0.544461\n",
      "epoch 87; iter: 0; batch classifier loss: 0.510669; batch adversarial loss: 0.449385\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420919; batch adversarial loss: 0.543721\n",
      "epoch 89; iter: 0; batch classifier loss: 0.329444; batch adversarial loss: 0.534910\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430125; batch adversarial loss: 0.468436\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376717; batch adversarial loss: 0.573831\n",
      "epoch 92; iter: 0; batch classifier loss: 0.362880; batch adversarial loss: 0.543634\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431417; batch adversarial loss: 0.593187\n",
      "epoch 94; iter: 0; batch classifier loss: 0.369492; batch adversarial loss: 0.544602\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398418; batch adversarial loss: 0.487020\n",
      "epoch 96; iter: 0; batch classifier loss: 0.413342; batch adversarial loss: 0.563259\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411113; batch adversarial loss: 0.572869\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398415; batch adversarial loss: 0.506384\n",
      "epoch 99; iter: 0; batch classifier loss: 0.335513; batch adversarial loss: 0.563681\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372394; batch adversarial loss: 0.563664\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406298; batch adversarial loss: 0.506491\n",
      "epoch 102; iter: 0; batch classifier loss: 0.336807; batch adversarial loss: 0.629536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103; iter: 0; batch classifier loss: 0.368447; batch adversarial loss: 0.506379\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349398; batch adversarial loss: 0.544849\n",
      "epoch 105; iter: 0; batch classifier loss: 0.505679; batch adversarial loss: 0.534720\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378735; batch adversarial loss: 0.486583\n",
      "epoch 107; iter: 0; batch classifier loss: 0.453414; batch adversarial loss: 0.514817\n",
      "epoch 108; iter: 0; batch classifier loss: 0.409961; batch adversarial loss: 0.504631\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361795; batch adversarial loss: 0.563239\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395648; batch adversarial loss: 0.521925\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415573; batch adversarial loss: 0.591534\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371798; batch adversarial loss: 0.492204\n",
      "epoch 113; iter: 0; batch classifier loss: 0.403055; batch adversarial loss: 0.539943\n",
      "epoch 114; iter: 0; batch classifier loss: 0.429828; batch adversarial loss: 0.564404\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409983; batch adversarial loss: 0.482923\n",
      "epoch 116; iter: 0; batch classifier loss: 0.491430; batch adversarial loss: 0.490663\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357209; batch adversarial loss: 0.571097\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382532; batch adversarial loss: 0.471019\n",
      "epoch 119; iter: 0; batch classifier loss: 0.432332; batch adversarial loss: 0.557967\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387770; batch adversarial loss: 0.537310\n",
      "epoch 121; iter: 0; batch classifier loss: 0.437025; batch adversarial loss: 0.471325\n",
      "epoch 122; iter: 0; batch classifier loss: 0.461581; batch adversarial loss: 0.582808\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390156; batch adversarial loss: 0.537651\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407969; batch adversarial loss: 0.578743\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387693; batch adversarial loss: 0.498523\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381772; batch adversarial loss: 0.506360\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376050; batch adversarial loss: 0.552157\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365123; batch adversarial loss: 0.611638\n",
      "epoch 129; iter: 0; batch classifier loss: 0.313731; batch adversarial loss: 0.573561\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357034; batch adversarial loss: 0.641019\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405173; batch adversarial loss: 0.572984\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373196; batch adversarial loss: 0.533558\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392321; batch adversarial loss: 0.534607\n",
      "epoch 134; iter: 0; batch classifier loss: 0.360968; batch adversarial loss: 0.595150\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335507; batch adversarial loss: 0.553564\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403060; batch adversarial loss: 0.613063\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400276; batch adversarial loss: 0.556119\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377229; batch adversarial loss: 0.476976\n",
      "epoch 139; iter: 0; batch classifier loss: 0.426646; batch adversarial loss: 0.497140\n",
      "epoch 140; iter: 0; batch classifier loss: 0.292706; batch adversarial loss: 0.603092\n",
      "epoch 141; iter: 0; batch classifier loss: 0.458872; batch adversarial loss: 0.496643\n",
      "epoch 142; iter: 0; batch classifier loss: 0.406449; batch adversarial loss: 0.564524\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359702; batch adversarial loss: 0.584155\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340690; batch adversarial loss: 0.546317\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397408; batch adversarial loss: 0.563625\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313855; batch adversarial loss: 0.517443\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350458; batch adversarial loss: 0.591323\n",
      "epoch 148; iter: 0; batch classifier loss: 0.387205; batch adversarial loss: 0.504004\n",
      "epoch 149; iter: 0; batch classifier loss: 0.429481; batch adversarial loss: 0.496929\n",
      "epoch 150; iter: 0; batch classifier loss: 0.424284; batch adversarial loss: 0.620591\n",
      "epoch 151; iter: 0; batch classifier loss: 0.311270; batch adversarial loss: 0.458412\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351831; batch adversarial loss: 0.573524\n",
      "epoch 153; iter: 0; batch classifier loss: 0.331254; batch adversarial loss: 0.527223\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351545; batch adversarial loss: 0.448748\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314603; batch adversarial loss: 0.535010\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325505; batch adversarial loss: 0.468086\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.525830\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329600; batch adversarial loss: 0.457704\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348517; batch adversarial loss: 0.612079\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358828; batch adversarial loss: 0.524702\n",
      "epoch 161; iter: 0; batch classifier loss: 0.321454; batch adversarial loss: 0.515399\n",
      "epoch 162; iter: 0; batch classifier loss: 0.398429; batch adversarial loss: 0.544668\n",
      "epoch 163; iter: 0; batch classifier loss: 0.332201; batch adversarial loss: 0.516715\n",
      "epoch 164; iter: 0; batch classifier loss: 0.425056; batch adversarial loss: 0.458100\n",
      "epoch 165; iter: 0; batch classifier loss: 0.337037; batch adversarial loss: 0.478736\n",
      "epoch 166; iter: 0; batch classifier loss: 0.413405; batch adversarial loss: 0.603750\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343038; batch adversarial loss: 0.543756\n",
      "epoch 168; iter: 0; batch classifier loss: 0.407045; batch adversarial loss: 0.459938\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372902; batch adversarial loss: 0.458797\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378617; batch adversarial loss: 0.477616\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372980; batch adversarial loss: 0.469060\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372851; batch adversarial loss: 0.525373\n",
      "epoch 173; iter: 0; batch classifier loss: 0.296230; batch adversarial loss: 0.515165\n",
      "epoch 174; iter: 0; batch classifier loss: 0.389004; batch adversarial loss: 0.536625\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329266; batch adversarial loss: 0.496859\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349823; batch adversarial loss: 0.649379\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346844; batch adversarial loss: 0.526339\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363585; batch adversarial loss: 0.467960\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377665; batch adversarial loss: 0.486418\n",
      "epoch 180; iter: 0; batch classifier loss: 0.409266; batch adversarial loss: 0.486088\n",
      "epoch 181; iter: 0; batch classifier loss: 0.413313; batch adversarial loss: 0.533658\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378143; batch adversarial loss: 0.466464\n",
      "epoch 183; iter: 0; batch classifier loss: 0.422857; batch adversarial loss: 0.588259\n",
      "epoch 184; iter: 0; batch classifier loss: 0.280819; batch adversarial loss: 0.476756\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349889; batch adversarial loss: 0.584237\n",
      "epoch 186; iter: 0; batch classifier loss: 0.418070; batch adversarial loss: 0.516222\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358362; batch adversarial loss: 0.525578\n",
      "epoch 188; iter: 0; batch classifier loss: 0.418870; batch adversarial loss: 0.573582\n",
      "epoch 189; iter: 0; batch classifier loss: 0.262819; batch adversarial loss: 0.581634\n",
      "epoch 190; iter: 0; batch classifier loss: 0.427805; batch adversarial loss: 0.515063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.328653; batch adversarial loss: 0.478547\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333022; batch adversarial loss: 0.611325\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337460; batch adversarial loss: 0.508337\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344516; batch adversarial loss: 0.535845\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309927; batch adversarial loss: 0.537026\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376931; batch adversarial loss: 0.572754\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360310; batch adversarial loss: 0.572777\n",
      "epoch 198; iter: 0; batch classifier loss: 0.339547; batch adversarial loss: 0.535705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.345886; batch adversarial loss: 0.564099\n",
      "epoch 0; iter: 0; batch classifier loss: 0.750326; batch adversarial loss: 0.787482\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556196; batch adversarial loss: 0.723965\n",
      "epoch 2; iter: 0; batch classifier loss: 0.597353; batch adversarial loss: 0.723652\n",
      "epoch 3; iter: 0; batch classifier loss: 0.640361; batch adversarial loss: 0.667561\n",
      "epoch 4; iter: 0; batch classifier loss: 0.561229; batch adversarial loss: 0.696385\n",
      "epoch 5; iter: 0; batch classifier loss: 0.647083; batch adversarial loss: 0.661867\n",
      "epoch 6; iter: 0; batch classifier loss: 0.566022; batch adversarial loss: 0.628587\n",
      "epoch 7; iter: 0; batch classifier loss: 0.602548; batch adversarial loss: 0.581071\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532157; batch adversarial loss: 0.562809\n",
      "epoch 9; iter: 0; batch classifier loss: 0.583181; batch adversarial loss: 0.564116\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520402; batch adversarial loss: 0.595542\n",
      "epoch 11; iter: 0; batch classifier loss: 0.469062; batch adversarial loss: 0.583448\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503642; batch adversarial loss: 0.587247\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488419; batch adversarial loss: 0.604688\n",
      "epoch 14; iter: 0; batch classifier loss: 0.580722; batch adversarial loss: 0.538545\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484138; batch adversarial loss: 0.565811\n",
      "epoch 16; iter: 0; batch classifier loss: 0.517501; batch adversarial loss: 0.610689\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466168; batch adversarial loss: 0.531197\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478766; batch adversarial loss: 0.575170\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441039; batch adversarial loss: 0.566329\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509168; batch adversarial loss: 0.559136\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514370; batch adversarial loss: 0.534832\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480853; batch adversarial loss: 0.553624\n",
      "epoch 23; iter: 0; batch classifier loss: 0.524185; batch adversarial loss: 0.482688\n",
      "epoch 24; iter: 0; batch classifier loss: 0.428296; batch adversarial loss: 0.533174\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471538; batch adversarial loss: 0.551921\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473659; batch adversarial loss: 0.559055\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537639; batch adversarial loss: 0.500907\n",
      "epoch 28; iter: 0; batch classifier loss: 0.436545; batch adversarial loss: 0.584453\n",
      "epoch 29; iter: 0; batch classifier loss: 0.364325; batch adversarial loss: 0.576467\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490830; batch adversarial loss: 0.501481\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417330; batch adversarial loss: 0.634043\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438556; batch adversarial loss: 0.563353\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459200; batch adversarial loss: 0.496930\n",
      "epoch 34; iter: 0; batch classifier loss: 0.495070; batch adversarial loss: 0.521005\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474107; batch adversarial loss: 0.554274\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450503; batch adversarial loss: 0.580072\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491795; batch adversarial loss: 0.521915\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439383; batch adversarial loss: 0.605803\n",
      "epoch 39; iter: 0; batch classifier loss: 0.390161; batch adversarial loss: 0.503170\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399233; batch adversarial loss: 0.527557\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429404; batch adversarial loss: 0.622108\n",
      "epoch 42; iter: 0; batch classifier loss: 0.485091; batch adversarial loss: 0.554014\n",
      "epoch 43; iter: 0; batch classifier loss: 0.377014; batch adversarial loss: 0.570711\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390471; batch adversarial loss: 0.527460\n",
      "epoch 45; iter: 0; batch classifier loss: 0.493706; batch adversarial loss: 0.562097\n",
      "epoch 46; iter: 0; batch classifier loss: 0.494602; batch adversarial loss: 0.615406\n",
      "epoch 47; iter: 0; batch classifier loss: 0.382792; batch adversarial loss: 0.607457\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414112; batch adversarial loss: 0.588896\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406577; batch adversarial loss: 0.580792\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403170; batch adversarial loss: 0.642921\n",
      "epoch 51; iter: 0; batch classifier loss: 0.369817; batch adversarial loss: 0.571650\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464798; batch adversarial loss: 0.508504\n",
      "epoch 53; iter: 0; batch classifier loss: 0.385751; batch adversarial loss: 0.553809\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410082; batch adversarial loss: 0.472215\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394792; batch adversarial loss: 0.535807\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419030; batch adversarial loss: 0.535676\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391869; batch adversarial loss: 0.634970\n",
      "epoch 58; iter: 0; batch classifier loss: 0.348016; batch adversarial loss: 0.553585\n",
      "epoch 59; iter: 0; batch classifier loss: 0.443174; batch adversarial loss: 0.499406\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383122; batch adversarial loss: 0.553590\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429801; batch adversarial loss: 0.571776\n",
      "epoch 62; iter: 0; batch classifier loss: 0.363981; batch adversarial loss: 0.535590\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449032; batch adversarial loss: 0.535415\n",
      "epoch 64; iter: 0; batch classifier loss: 0.379679; batch adversarial loss: 0.526482\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388400; batch adversarial loss: 0.553774\n",
      "epoch 66; iter: 0; batch classifier loss: 0.360302; batch adversarial loss: 0.473000\n",
      "epoch 67; iter: 0; batch classifier loss: 0.339896; batch adversarial loss: 0.552328\n",
      "epoch 68; iter: 0; batch classifier loss: 0.341323; batch adversarial loss: 0.589136\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406198; batch adversarial loss: 0.542670\n",
      "epoch 70; iter: 0; batch classifier loss: 0.394971; batch adversarial loss: 0.493086\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407414; batch adversarial loss: 0.562548\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414960; batch adversarial loss: 0.544319\n",
      "epoch 73; iter: 0; batch classifier loss: 0.529846; batch adversarial loss: 0.535309\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380342; batch adversarial loss: 0.517589\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449279; batch adversarial loss: 0.554446\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384957; batch adversarial loss: 0.515749\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387373; batch adversarial loss: 0.564110\n",
      "epoch 78; iter: 0; batch classifier loss: 0.295615; batch adversarial loss: 0.564457\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420801; batch adversarial loss: 0.552729\n",
      "epoch 80; iter: 0; batch classifier loss: 0.372527; batch adversarial loss: 0.542762\n",
      "epoch 81; iter: 0; batch classifier loss: 0.355223; batch adversarial loss: 0.615680\n",
      "epoch 82; iter: 0; batch classifier loss: 0.334408; batch adversarial loss: 0.624609\n",
      "epoch 83; iter: 0; batch classifier loss: 0.336394; batch adversarial loss: 0.546908\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415779; batch adversarial loss: 0.590436\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405499; batch adversarial loss: 0.644123\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365364; batch adversarial loss: 0.571781\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369659; batch adversarial loss: 0.454382\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348023; batch adversarial loss: 0.553626\n",
      "epoch 89; iter: 0; batch classifier loss: 0.441445; batch adversarial loss: 0.509008\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348411; batch adversarial loss: 0.588487\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349131; batch adversarial loss: 0.543581\n",
      "epoch 92; iter: 0; batch classifier loss: 0.452294; batch adversarial loss: 0.499072\n",
      "epoch 93; iter: 0; batch classifier loss: 0.359896; batch adversarial loss: 0.535106\n",
      "epoch 94; iter: 0; batch classifier loss: 0.487660; batch adversarial loss: 0.519127\n",
      "epoch 95; iter: 0; batch classifier loss: 0.372891; batch adversarial loss: 0.464690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.455146; batch adversarial loss: 0.523279\n",
      "epoch 97; iter: 0; batch classifier loss: 0.343539; batch adversarial loss: 0.535977\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406884; batch adversarial loss: 0.545255\n",
      "epoch 99; iter: 0; batch classifier loss: 0.334688; batch adversarial loss: 0.527506\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384908; batch adversarial loss: 0.617892\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401216; batch adversarial loss: 0.545565\n",
      "epoch 102; iter: 0; batch classifier loss: 0.284485; batch adversarial loss: 0.444405\n",
      "epoch 103; iter: 0; batch classifier loss: 0.363783; batch adversarial loss: 0.580309\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364638; batch adversarial loss: 0.508028\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385819; batch adversarial loss: 0.508098\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378084; batch adversarial loss: 0.508066\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403318; batch adversarial loss: 0.590122\n",
      "epoch 108; iter: 0; batch classifier loss: 0.512617; batch adversarial loss: 0.589722\n",
      "epoch 109; iter: 0; batch classifier loss: 0.309673; batch adversarial loss: 0.552568\n",
      "epoch 110; iter: 0; batch classifier loss: 0.420612; batch adversarial loss: 0.544005\n",
      "epoch 111; iter: 0; batch classifier loss: 0.340348; batch adversarial loss: 0.643224\n",
      "epoch 112; iter: 0; batch classifier loss: 0.332087; batch adversarial loss: 0.509495\n",
      "epoch 113; iter: 0; batch classifier loss: 0.426584; batch adversarial loss: 0.580821\n",
      "epoch 114; iter: 0; batch classifier loss: 0.433568; batch adversarial loss: 0.667517\n",
      "epoch 115; iter: 0; batch classifier loss: 0.338771; batch adversarial loss: 0.587176\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420531; batch adversarial loss: 0.516083\n",
      "epoch 117; iter: 0; batch classifier loss: 0.328440; batch adversarial loss: 0.562241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.371355; batch adversarial loss: 0.508058\n",
      "epoch 119; iter: 0; batch classifier loss: 0.391292; batch adversarial loss: 0.533397\n",
      "epoch 120; iter: 0; batch classifier loss: 0.333223; batch adversarial loss: 0.529860\n",
      "epoch 121; iter: 0; batch classifier loss: 0.311186; batch adversarial loss: 0.572675\n",
      "epoch 122; iter: 0; batch classifier loss: 0.401597; batch adversarial loss: 0.579446\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387522; batch adversarial loss: 0.532535\n",
      "epoch 124; iter: 0; batch classifier loss: 0.429257; batch adversarial loss: 0.481415\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361513; batch adversarial loss: 0.499549\n",
      "epoch 126; iter: 0; batch classifier loss: 0.471156; batch adversarial loss: 0.550570\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360401; batch adversarial loss: 0.526298\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313759; batch adversarial loss: 0.546787\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358359; batch adversarial loss: 0.511572\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322752; batch adversarial loss: 0.592011\n",
      "epoch 131; iter: 0; batch classifier loss: 0.418911; batch adversarial loss: 0.508801\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394709; batch adversarial loss: 0.531788\n",
      "epoch 133; iter: 0; batch classifier loss: 0.337316; batch adversarial loss: 0.492621\n",
      "epoch 134; iter: 0; batch classifier loss: 0.334779; batch adversarial loss: 0.524722\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325452; batch adversarial loss: 0.563722\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324142; batch adversarial loss: 0.526216\n",
      "epoch 137; iter: 0; batch classifier loss: 0.406007; batch adversarial loss: 0.526585\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382320; batch adversarial loss: 0.663771\n",
      "epoch 139; iter: 0; batch classifier loss: 0.407100; batch adversarial loss: 0.544423\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327141; batch adversarial loss: 0.544851\n",
      "epoch 141; iter: 0; batch classifier loss: 0.486718; batch adversarial loss: 0.508193\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391353; batch adversarial loss: 0.561230\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383159; batch adversarial loss: 0.563130\n",
      "epoch 144; iter: 0; batch classifier loss: 0.393562; batch adversarial loss: 0.489619\n",
      "epoch 145; iter: 0; batch classifier loss: 0.287413; batch adversarial loss: 0.480145\n",
      "epoch 146; iter: 0; batch classifier loss: 0.277470; batch adversarial loss: 0.553763\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344473; batch adversarial loss: 0.554048\n",
      "epoch 148; iter: 0; batch classifier loss: 0.318037; batch adversarial loss: 0.626889\n",
      "epoch 149; iter: 0; batch classifier loss: 0.394749; batch adversarial loss: 0.544570\n",
      "epoch 150; iter: 0; batch classifier loss: 0.424689; batch adversarial loss: 0.535878\n",
      "epoch 151; iter: 0; batch classifier loss: 0.293324; batch adversarial loss: 0.598951\n",
      "epoch 152; iter: 0; batch classifier loss: 0.288488; batch adversarial loss: 0.526928\n",
      "epoch 153; iter: 0; batch classifier loss: 0.459318; batch adversarial loss: 0.562276\n",
      "epoch 154; iter: 0; batch classifier loss: 0.283498; batch adversarial loss: 0.499227\n",
      "epoch 155; iter: 0; batch classifier loss: 0.295965; batch adversarial loss: 0.589732\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362931; batch adversarial loss: 0.634659\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364072; batch adversarial loss: 0.553577\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321315; batch adversarial loss: 0.536204\n",
      "epoch 159; iter: 0; batch classifier loss: 0.319505; batch adversarial loss: 0.499659\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333870; batch adversarial loss: 0.572250\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383619; batch adversarial loss: 0.581081\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352613; batch adversarial loss: 0.536197\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343592; batch adversarial loss: 0.526672\n",
      "epoch 164; iter: 0; batch classifier loss: 0.321718; batch adversarial loss: 0.507626\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373086; batch adversarial loss: 0.517739\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388693; batch adversarial loss: 0.499564\n",
      "epoch 167; iter: 0; batch classifier loss: 0.397907; batch adversarial loss: 0.517949\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367672; batch adversarial loss: 0.562714\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370923; batch adversarial loss: 0.526956\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383607; batch adversarial loss: 0.607304\n",
      "epoch 171; iter: 0; batch classifier loss: 0.449463; batch adversarial loss: 0.535795\n",
      "epoch 172; iter: 0; batch classifier loss: 0.306660; batch adversarial loss: 0.599342\n",
      "epoch 173; iter: 0; batch classifier loss: 0.412688; batch adversarial loss: 0.508326\n",
      "epoch 174; iter: 0; batch classifier loss: 0.290426; batch adversarial loss: 0.544108\n",
      "epoch 175; iter: 0; batch classifier loss: 0.405706; batch adversarial loss: 0.590297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.263688; batch adversarial loss: 0.652334\n",
      "epoch 177; iter: 0; batch classifier loss: 0.368522; batch adversarial loss: 0.580593\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343773; batch adversarial loss: 0.535714\n",
      "epoch 179; iter: 0; batch classifier loss: 0.296926; batch adversarial loss: 0.662219\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368361; batch adversarial loss: 0.544963\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374145; batch adversarial loss: 0.553417\n",
      "epoch 182; iter: 0; batch classifier loss: 0.319214; batch adversarial loss: 0.554270\n",
      "epoch 183; iter: 0; batch classifier loss: 0.359820; batch adversarial loss: 0.462964\n",
      "epoch 184; iter: 0; batch classifier loss: 0.283194; batch adversarial loss: 0.526398\n",
      "epoch 185; iter: 0; batch classifier loss: 0.287488; batch adversarial loss: 0.580973\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383544; batch adversarial loss: 0.571373\n",
      "epoch 187; iter: 0; batch classifier loss: 0.275299; batch adversarial loss: 0.490649\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314619; batch adversarial loss: 0.553713\n",
      "epoch 189; iter: 0; batch classifier loss: 0.397513; batch adversarial loss: 0.498836\n",
      "epoch 190; iter: 0; batch classifier loss: 0.383905; batch adversarial loss: 0.535747\n",
      "epoch 191; iter: 0; batch classifier loss: 0.424548; batch adversarial loss: 0.598132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.320603; batch adversarial loss: 0.536050\n",
      "epoch 193; iter: 0; batch classifier loss: 0.404388; batch adversarial loss: 0.526765\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330684; batch adversarial loss: 0.571532\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321105; batch adversarial loss: 0.544737\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357041; batch adversarial loss: 0.562546\n",
      "epoch 197; iter: 0; batch classifier loss: 0.298351; batch adversarial loss: 0.508673\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404439; batch adversarial loss: 0.608145\n",
      "epoch 199; iter: 0; batch classifier loss: 0.391330; batch adversarial loss: 0.517642\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703255; batch adversarial loss: 0.854220\n",
      "epoch 1; iter: 0; batch classifier loss: 0.664837; batch adversarial loss: 0.971628\n",
      "epoch 2; iter: 0; batch classifier loss: 0.684367; batch adversarial loss: 0.848317\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570204; batch adversarial loss: 0.763692\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568561; batch adversarial loss: 0.732802\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549217; batch adversarial loss: 0.696916\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588922; batch adversarial loss: 0.681751\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534427; batch adversarial loss: 0.673670\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554777; batch adversarial loss: 0.638738\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546217; batch adversarial loss: 0.616231\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561980; batch adversarial loss: 0.642185\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582498; batch adversarial loss: 0.606634\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560214; batch adversarial loss: 0.591507\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552550; batch adversarial loss: 0.632540\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525708; batch adversarial loss: 0.583059\n",
      "epoch 15; iter: 0; batch classifier loss: 0.559082; batch adversarial loss: 0.522744\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527786; batch adversarial loss: 0.568346\n",
      "epoch 17; iter: 0; batch classifier loss: 0.538970; batch adversarial loss: 0.584733\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458390; batch adversarial loss: 0.621514\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482238; batch adversarial loss: 0.615270\n",
      "epoch 20; iter: 0; batch classifier loss: 0.446418; batch adversarial loss: 0.612948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498356; batch adversarial loss: 0.614343\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443957; batch adversarial loss: 0.509774\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531939; batch adversarial loss: 0.591868\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470581; batch adversarial loss: 0.602994\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498974; batch adversarial loss: 0.531726\n",
      "epoch 26; iter: 0; batch classifier loss: 0.533536; batch adversarial loss: 0.477418\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506557; batch adversarial loss: 0.524271\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462121; batch adversarial loss: 0.583969\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463433; batch adversarial loss: 0.522808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.512680; batch adversarial loss: 0.515363\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432244; batch adversarial loss: 0.604324\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516508; batch adversarial loss: 0.631388\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485703; batch adversarial loss: 0.530854\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494381; batch adversarial loss: 0.567086\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454938; batch adversarial loss: 0.525792\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460201; batch adversarial loss: 0.577593\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442855; batch adversarial loss: 0.625810\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447019; batch adversarial loss: 0.548412\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431144; batch adversarial loss: 0.479001\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480304; batch adversarial loss: 0.545135\n",
      "epoch 41; iter: 0; batch classifier loss: 0.515911; batch adversarial loss: 0.565697\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469689; batch adversarial loss: 0.587351\n",
      "epoch 43; iter: 0; batch classifier loss: 0.519955; batch adversarial loss: 0.476068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419466; batch adversarial loss: 0.610306\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456340; batch adversarial loss: 0.569023\n",
      "epoch 46; iter: 0; batch classifier loss: 0.478108; batch adversarial loss: 0.602984\n",
      "epoch 47; iter: 0; batch classifier loss: 0.505314; batch adversarial loss: 0.581750\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431228; batch adversarial loss: 0.555060\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432518; batch adversarial loss: 0.556746\n",
      "epoch 50; iter: 0; batch classifier loss: 0.507843; batch adversarial loss: 0.569873\n",
      "epoch 51; iter: 0; batch classifier loss: 0.497361; batch adversarial loss: 0.555723\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420378; batch adversarial loss: 0.525232\n",
      "epoch 53; iter: 0; batch classifier loss: 0.499551; batch adversarial loss: 0.536402\n",
      "epoch 54; iter: 0; batch classifier loss: 0.386081; batch adversarial loss: 0.608147\n",
      "epoch 55; iter: 0; batch classifier loss: 0.497271; batch adversarial loss: 0.542178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.471076; batch adversarial loss: 0.489773\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408726; batch adversarial loss: 0.544886\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460015; batch adversarial loss: 0.516432\n",
      "epoch 59; iter: 0; batch classifier loss: 0.373100; batch adversarial loss: 0.555279\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442625; batch adversarial loss: 0.517333\n",
      "epoch 61; iter: 0; batch classifier loss: 0.484616; batch adversarial loss: 0.525365\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443624; batch adversarial loss: 0.545016\n",
      "epoch 63; iter: 0; batch classifier loss: 0.455870; batch adversarial loss: 0.535453\n",
      "epoch 64; iter: 0; batch classifier loss: 0.367188; batch adversarial loss: 0.562653\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389126; batch adversarial loss: 0.517139\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409922; batch adversarial loss: 0.636920\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423368; batch adversarial loss: 0.460532\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430780; batch adversarial loss: 0.524942\n",
      "epoch 69; iter: 0; batch classifier loss: 0.472777; batch adversarial loss: 0.590792\n",
      "epoch 70; iter: 0; batch classifier loss: 0.372620; batch adversarial loss: 0.525520\n",
      "epoch 71; iter: 0; batch classifier loss: 0.455159; batch adversarial loss: 0.452324\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413045; batch adversarial loss: 0.497137\n",
      "epoch 73; iter: 0; batch classifier loss: 0.482656; batch adversarial loss: 0.488659\n",
      "epoch 74; iter: 0; batch classifier loss: 0.425869; batch adversarial loss: 0.600541\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426299; batch adversarial loss: 0.543375\n",
      "epoch 76; iter: 0; batch classifier loss: 0.466456; batch adversarial loss: 0.582857\n",
      "epoch 77; iter: 0; batch classifier loss: 0.508315; batch adversarial loss: 0.618520\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368073; batch adversarial loss: 0.588240\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366585; batch adversarial loss: 0.555921\n",
      "epoch 80; iter: 0; batch classifier loss: 0.440247; batch adversarial loss: 0.590508\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432472; batch adversarial loss: 0.572266\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446633; batch adversarial loss: 0.516197\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409421; batch adversarial loss: 0.526222\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375188; batch adversarial loss: 0.601563\n",
      "epoch 85; iter: 0; batch classifier loss: 0.334016; batch adversarial loss: 0.593558\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344910; batch adversarial loss: 0.523797\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372090; batch adversarial loss: 0.534549\n",
      "epoch 88; iter: 0; batch classifier loss: 0.409351; batch adversarial loss: 0.608795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.335596; batch adversarial loss: 0.529135\n",
      "epoch 90; iter: 0; batch classifier loss: 0.482589; batch adversarial loss: 0.544096\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406261; batch adversarial loss: 0.489260\n",
      "epoch 92; iter: 0; batch classifier loss: 0.350443; batch adversarial loss: 0.489703\n",
      "epoch 93; iter: 0; batch classifier loss: 0.501603; batch adversarial loss: 0.525591\n",
      "epoch 94; iter: 0; batch classifier loss: 0.355095; batch adversarial loss: 0.590469\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361066; batch adversarial loss: 0.617702\n",
      "epoch 96; iter: 0; batch classifier loss: 0.317617; batch adversarial loss: 0.518156\n",
      "epoch 97; iter: 0; batch classifier loss: 0.507643; batch adversarial loss: 0.536025\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370377; batch adversarial loss: 0.610188\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441888; batch adversarial loss: 0.553133\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406518; batch adversarial loss: 0.469415\n",
      "epoch 101; iter: 0; batch classifier loss: 0.505761; batch adversarial loss: 0.535155\n",
      "epoch 102; iter: 0; batch classifier loss: 0.317371; batch adversarial loss: 0.515924\n",
      "epoch 103; iter: 0; batch classifier loss: 0.508943; batch adversarial loss: 0.601145\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402694; batch adversarial loss: 0.554476\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383491; batch adversarial loss: 0.536456\n",
      "epoch 106; iter: 0; batch classifier loss: 0.456801; batch adversarial loss: 0.648871\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378848; batch adversarial loss: 0.561024\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355051; batch adversarial loss: 0.504709\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407286; batch adversarial loss: 0.552986\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388720; batch adversarial loss: 0.544673\n",
      "epoch 111; iter: 0; batch classifier loss: 0.377329; batch adversarial loss: 0.574770\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394188; batch adversarial loss: 0.572223\n",
      "epoch 113; iter: 0; batch classifier loss: 0.450092; batch adversarial loss: 0.547075\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394788; batch adversarial loss: 0.507307\n",
      "epoch 115; iter: 0; batch classifier loss: 0.347721; batch adversarial loss: 0.536227\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372411; batch adversarial loss: 0.479556\n",
      "epoch 117; iter: 0; batch classifier loss: 0.334004; batch adversarial loss: 0.526316\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383389; batch adversarial loss: 0.534914\n",
      "epoch 119; iter: 0; batch classifier loss: 0.304262; batch adversarial loss: 0.563486\n",
      "epoch 120; iter: 0; batch classifier loss: 0.450764; batch adversarial loss: 0.573602\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366516; batch adversarial loss: 0.572216\n",
      "epoch 122; iter: 0; batch classifier loss: 0.310786; batch adversarial loss: 0.507934\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414021; batch adversarial loss: 0.574388\n",
      "epoch 124; iter: 0; batch classifier loss: 0.459062; batch adversarial loss: 0.527528\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379301; batch adversarial loss: 0.461588\n",
      "epoch 126; iter: 0; batch classifier loss: 0.364382; batch adversarial loss: 0.528356\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383682; batch adversarial loss: 0.525196\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403980; batch adversarial loss: 0.591608\n",
      "epoch 129; iter: 0; batch classifier loss: 0.421324; batch adversarial loss: 0.517466\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382564; batch adversarial loss: 0.591229\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372556; batch adversarial loss: 0.563103\n",
      "epoch 132; iter: 0; batch classifier loss: 0.485428; batch adversarial loss: 0.535792\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375054; batch adversarial loss: 0.489561\n",
      "epoch 134; iter: 0; batch classifier loss: 0.412976; batch adversarial loss: 0.553477\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395694; batch adversarial loss: 0.517460\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378660; batch adversarial loss: 0.544596\n",
      "epoch 137; iter: 0; batch classifier loss: 0.321157; batch adversarial loss: 0.553427\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373871; batch adversarial loss: 0.572289\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388349; batch adversarial loss: 0.516692\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354383; batch adversarial loss: 0.553800\n",
      "epoch 141; iter: 0; batch classifier loss: 0.376069; batch adversarial loss: 0.534295\n",
      "epoch 142; iter: 0; batch classifier loss: 0.420623; batch adversarial loss: 0.535454\n",
      "epoch 143; iter: 0; batch classifier loss: 0.431663; batch adversarial loss: 0.553156\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366823; batch adversarial loss: 0.562049\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331030; batch adversarial loss: 0.628142\n",
      "epoch 146; iter: 0; batch classifier loss: 0.454710; batch adversarial loss: 0.561226\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397694; batch adversarial loss: 0.535204\n",
      "epoch 148; iter: 0; batch classifier loss: 0.380953; batch adversarial loss: 0.514927\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317618; batch adversarial loss: 0.620087\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399163; batch adversarial loss: 0.450728\n",
      "epoch 151; iter: 0; batch classifier loss: 0.415343; batch adversarial loss: 0.507168\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338627; batch adversarial loss: 0.590675\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367776; batch adversarial loss: 0.517260\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402563; batch adversarial loss: 0.584087\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401946; batch adversarial loss: 0.459653\n",
      "epoch 156; iter: 0; batch classifier loss: 0.433206; batch adversarial loss: 0.562837\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352814; batch adversarial loss: 0.534926\n",
      "epoch 158; iter: 0; batch classifier loss: 0.348066; batch adversarial loss: 0.554093\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354358; batch adversarial loss: 0.665652\n",
      "epoch 160; iter: 0; batch classifier loss: 0.414485; batch adversarial loss: 0.525368\n",
      "epoch 161; iter: 0; batch classifier loss: 0.427198; batch adversarial loss: 0.516758\n",
      "epoch 162; iter: 0; batch classifier loss: 0.297608; batch adversarial loss: 0.414863\n",
      "epoch 163; iter: 0; batch classifier loss: 0.411116; batch adversarial loss: 0.460099\n",
      "epoch 164; iter: 0; batch classifier loss: 0.377551; batch adversarial loss: 0.423340\n",
      "epoch 165; iter: 0; batch classifier loss: 0.289521; batch adversarial loss: 0.602149\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376353; batch adversarial loss: 0.526413\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332528; batch adversarial loss: 0.573176\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348541; batch adversarial loss: 0.543584\n",
      "epoch 169; iter: 0; batch classifier loss: 0.347306; batch adversarial loss: 0.590960\n",
      "epoch 170; iter: 0; batch classifier loss: 0.404105; batch adversarial loss: 0.515572\n",
      "epoch 171; iter: 0; batch classifier loss: 0.319844; batch adversarial loss: 0.580111\n",
      "epoch 172; iter: 0; batch classifier loss: 0.406572; batch adversarial loss: 0.582123\n",
      "epoch 173; iter: 0; batch classifier loss: 0.313731; batch adversarial loss: 0.529466\n",
      "epoch 174; iter: 0; batch classifier loss: 0.346574; batch adversarial loss: 0.516572\n",
      "epoch 175; iter: 0; batch classifier loss: 0.402991; batch adversarial loss: 0.489772\n",
      "epoch 176; iter: 0; batch classifier loss: 0.391443; batch adversarial loss: 0.552557\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360420; batch adversarial loss: 0.507624\n",
      "epoch 178; iter: 0; batch classifier loss: 0.393039; batch adversarial loss: 0.515712\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377751; batch adversarial loss: 0.599608\n",
      "epoch 180; iter: 0; batch classifier loss: 0.397472; batch adversarial loss: 0.534741\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323002; batch adversarial loss: 0.552737\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375223; batch adversarial loss: 0.506618\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373664; batch adversarial loss: 0.553801\n",
      "epoch 184; iter: 0; batch classifier loss: 0.398335; batch adversarial loss: 0.581490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.368814; batch adversarial loss: 0.536037\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407375; batch adversarial loss: 0.562429\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322829; batch adversarial loss: 0.543983\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335441; batch adversarial loss: 0.517463\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395007; batch adversarial loss: 0.488921\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312080; batch adversarial loss: 0.582845\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373707; batch adversarial loss: 0.580962\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335245; batch adversarial loss: 0.591917\n",
      "epoch 193; iter: 0; batch classifier loss: 0.369563; batch adversarial loss: 0.571311\n",
      "epoch 194; iter: 0; batch classifier loss: 0.310265; batch adversarial loss: 0.518279\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334431; batch adversarial loss: 0.498820\n",
      "epoch 196; iter: 0; batch classifier loss: 0.423090; batch adversarial loss: 0.506351\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339525; batch adversarial loss: 0.553523\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353747; batch adversarial loss: 0.441450\n",
      "epoch 199; iter: 0; batch classifier loss: 0.407736; batch adversarial loss: 0.480973\n",
      "epoch 0; iter: 0; batch classifier loss: 0.771727; batch adversarial loss: 0.837553\n",
      "epoch 1; iter: 0; batch classifier loss: 0.818412; batch adversarial loss: 0.842046\n",
      "epoch 2; iter: 0; batch classifier loss: 0.774456; batch adversarial loss: 0.775002\n",
      "epoch 3; iter: 0; batch classifier loss: 0.762863; batch adversarial loss: 0.700119\n",
      "epoch 4; iter: 0; batch classifier loss: 0.750620; batch adversarial loss: 0.680327\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528156; batch adversarial loss: 0.606672\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545799; batch adversarial loss: 0.630113\n",
      "epoch 7; iter: 0; batch classifier loss: 0.589180; batch adversarial loss: 0.578246\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519058; batch adversarial loss: 0.596182\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546129; batch adversarial loss: 0.572296\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539935; batch adversarial loss: 0.586950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491043; batch adversarial loss: 0.582718\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533644; batch adversarial loss: 0.569248\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521010; batch adversarial loss: 0.571488\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448631; batch adversarial loss: 0.639383\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507873; batch adversarial loss: 0.543658\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473164; batch adversarial loss: 0.514533\n",
      "epoch 17; iter: 0; batch classifier loss: 0.574338; batch adversarial loss: 0.546826\n",
      "epoch 18; iter: 0; batch classifier loss: 0.566446; batch adversarial loss: 0.575429\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503052; batch adversarial loss: 0.555526\n",
      "epoch 20; iter: 0; batch classifier loss: 0.565418; batch adversarial loss: 0.505814\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467327; batch adversarial loss: 0.593161\n",
      "epoch 22; iter: 0; batch classifier loss: 0.390429; batch adversarial loss: 0.544058\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518755; batch adversarial loss: 0.606578\n",
      "epoch 24; iter: 0; batch classifier loss: 0.500122; batch adversarial loss: 0.472863\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494533; batch adversarial loss: 0.581769\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482058; batch adversarial loss: 0.553887\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480220; batch adversarial loss: 0.575118\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488737; batch adversarial loss: 0.569156\n",
      "epoch 29; iter: 0; batch classifier loss: 0.516815; batch adversarial loss: 0.506033\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428919; batch adversarial loss: 0.594831\n",
      "epoch 31; iter: 0; batch classifier loss: 0.512411; batch adversarial loss: 0.582470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.564566; batch adversarial loss: 0.596304\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437484; batch adversarial loss: 0.548226\n",
      "epoch 34; iter: 0; batch classifier loss: 0.536866; batch adversarial loss: 0.528450\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496966; batch adversarial loss: 0.585111\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482425; batch adversarial loss: 0.509493\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388913; batch adversarial loss: 0.488084\n",
      "epoch 38; iter: 0; batch classifier loss: 0.528598; batch adversarial loss: 0.538670\n",
      "epoch 39; iter: 0; batch classifier loss: 0.520132; batch adversarial loss: 0.523480\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399049; batch adversarial loss: 0.545097\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422392; batch adversarial loss: 0.523372\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453383; batch adversarial loss: 0.538344\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399613; batch adversarial loss: 0.557363\n",
      "epoch 44; iter: 0; batch classifier loss: 0.338764; batch adversarial loss: 0.511622\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404429; batch adversarial loss: 0.536533\n",
      "epoch 46; iter: 0; batch classifier loss: 0.404144; batch adversarial loss: 0.496665\n",
      "epoch 47; iter: 0; batch classifier loss: 0.498696; batch adversarial loss: 0.597443\n",
      "epoch 48; iter: 0; batch classifier loss: 0.489116; batch adversarial loss: 0.563649\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406589; batch adversarial loss: 0.491165\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458080; batch adversarial loss: 0.544917\n",
      "epoch 51; iter: 0; batch classifier loss: 0.401902; batch adversarial loss: 0.505775\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413066; batch adversarial loss: 0.508440\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436295; batch adversarial loss: 0.563148\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412758; batch adversarial loss: 0.469723\n",
      "epoch 55; iter: 0; batch classifier loss: 0.473902; batch adversarial loss: 0.546021\n",
      "epoch 56; iter: 0; batch classifier loss: 0.310820; batch adversarial loss: 0.552817\n",
      "epoch 57; iter: 0; batch classifier loss: 0.465548; batch adversarial loss: 0.563910\n",
      "epoch 58; iter: 0; batch classifier loss: 0.347497; batch adversarial loss: 0.590786\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428703; batch adversarial loss: 0.553689\n",
      "epoch 60; iter: 0; batch classifier loss: 0.461991; batch adversarial loss: 0.572127\n",
      "epoch 61; iter: 0; batch classifier loss: 0.387535; batch adversarial loss: 0.516716\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439623; batch adversarial loss: 0.590667\n",
      "epoch 63; iter: 0; batch classifier loss: 0.354177; batch adversarial loss: 0.496784\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432536; batch adversarial loss: 0.572643\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427739; batch adversarial loss: 0.535239\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414365; batch adversarial loss: 0.553510\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379516; batch adversarial loss: 0.572589\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445320; batch adversarial loss: 0.523988\n",
      "epoch 69; iter: 0; batch classifier loss: 0.365463; batch adversarial loss: 0.606813\n",
      "epoch 70; iter: 0; batch classifier loss: 0.491896; batch adversarial loss: 0.505501\n",
      "epoch 71; iter: 0; batch classifier loss: 0.328199; batch adversarial loss: 0.581207\n",
      "epoch 72; iter: 0; batch classifier loss: 0.373491; batch adversarial loss: 0.544393\n",
      "epoch 73; iter: 0; batch classifier loss: 0.464600; batch adversarial loss: 0.470389\n",
      "epoch 74; iter: 0; batch classifier loss: 0.337535; batch adversarial loss: 0.543582\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384150; batch adversarial loss: 0.526284\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392352; batch adversarial loss: 0.478889\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437143; batch adversarial loss: 0.544615\n",
      "epoch 78; iter: 0; batch classifier loss: 0.443041; batch adversarial loss: 0.610299\n",
      "epoch 79; iter: 0; batch classifier loss: 0.340796; batch adversarial loss: 0.564274\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408581; batch adversarial loss: 0.545621\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383012; batch adversarial loss: 0.563269\n",
      "epoch 82; iter: 0; batch classifier loss: 0.439554; batch adversarial loss: 0.562079\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401100; batch adversarial loss: 0.581393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.387616; batch adversarial loss: 0.508687\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441414; batch adversarial loss: 0.508253\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411218; batch adversarial loss: 0.565370\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384481; batch adversarial loss: 0.499599\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363972; batch adversarial loss: 0.545383\n",
      "epoch 89; iter: 0; batch classifier loss: 0.359335; batch adversarial loss: 0.563208\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450834; batch adversarial loss: 0.517615\n",
      "epoch 91; iter: 0; batch classifier loss: 0.435235; batch adversarial loss: 0.552956\n",
      "epoch 92; iter: 0; batch classifier loss: 0.350729; batch adversarial loss: 0.554810\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439056; batch adversarial loss: 0.525430\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414916; batch adversarial loss: 0.451726\n",
      "epoch 95; iter: 0; batch classifier loss: 0.447372; batch adversarial loss: 0.552943\n",
      "epoch 96; iter: 0; batch classifier loss: 0.363937; batch adversarial loss: 0.572126\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397918; batch adversarial loss: 0.442469\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393418; batch adversarial loss: 0.517450\n",
      "epoch 99; iter: 0; batch classifier loss: 0.292695; batch adversarial loss: 0.516214\n",
      "epoch 100; iter: 0; batch classifier loss: 0.426003; batch adversarial loss: 0.657036\n",
      "epoch 101; iter: 0; batch classifier loss: 0.428224; batch adversarial loss: 0.516017\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412229; batch adversarial loss: 0.524373\n",
      "epoch 103; iter: 0; batch classifier loss: 0.308236; batch adversarial loss: 0.507891\n",
      "epoch 104; iter: 0; batch classifier loss: 0.332247; batch adversarial loss: 0.618157\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365168; batch adversarial loss: 0.534206\n",
      "epoch 106; iter: 0; batch classifier loss: 0.436553; batch adversarial loss: 0.469266\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388884; batch adversarial loss: 0.563356\n",
      "epoch 108; iter: 0; batch classifier loss: 0.434731; batch adversarial loss: 0.561922\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421762; batch adversarial loss: 0.563070\n",
      "epoch 110; iter: 0; batch classifier loss: 0.492850; batch adversarial loss: 0.581975\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393689; batch adversarial loss: 0.524882\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363793; batch adversarial loss: 0.553877\n",
      "epoch 113; iter: 0; batch classifier loss: 0.322179; batch adversarial loss: 0.469385\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349770; batch adversarial loss: 0.573219\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382274; batch adversarial loss: 0.533724\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319807; batch adversarial loss: 0.544670\n",
      "epoch 117; iter: 0; batch classifier loss: 0.341415; batch adversarial loss: 0.647327\n",
      "epoch 118; iter: 0; batch classifier loss: 0.425432; batch adversarial loss: 0.562487\n",
      "epoch 119; iter: 0; batch classifier loss: 0.317052; batch adversarial loss: 0.554092\n",
      "epoch 120; iter: 0; batch classifier loss: 0.384492; batch adversarial loss: 0.590815\n",
      "epoch 121; iter: 0; batch classifier loss: 0.357866; batch adversarial loss: 0.563140\n",
      "epoch 122; iter: 0; batch classifier loss: 0.340690; batch adversarial loss: 0.600345\n",
      "epoch 123; iter: 0; batch classifier loss: 0.407944; batch adversarial loss: 0.488103\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339328; batch adversarial loss: 0.617936\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384742; batch adversarial loss: 0.507000\n",
      "epoch 126; iter: 0; batch classifier loss: 0.315744; batch adversarial loss: 0.564936\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381975; batch adversarial loss: 0.625345\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325890; batch adversarial loss: 0.470977\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368872; batch adversarial loss: 0.498072\n",
      "epoch 130; iter: 0; batch classifier loss: 0.323519; batch adversarial loss: 0.478393\n",
      "epoch 131; iter: 0; batch classifier loss: 0.369258; batch adversarial loss: 0.535220\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431816; batch adversarial loss: 0.516068\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395927; batch adversarial loss: 0.571773\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400983; batch adversarial loss: 0.535449\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364618; batch adversarial loss: 0.534604\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354944; batch adversarial loss: 0.581912\n",
      "epoch 137; iter: 0; batch classifier loss: 0.288861; batch adversarial loss: 0.554431\n",
      "epoch 138; iter: 0; batch classifier loss: 0.328329; batch adversarial loss: 0.563826\n",
      "epoch 139; iter: 0; batch classifier loss: 0.331859; batch adversarial loss: 0.553872\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358735; batch adversarial loss: 0.518838\n",
      "epoch 141; iter: 0; batch classifier loss: 0.318759; batch adversarial loss: 0.627777\n",
      "epoch 142; iter: 0; batch classifier loss: 0.388316; batch adversarial loss: 0.553850\n",
      "epoch 143; iter: 0; batch classifier loss: 0.372881; batch adversarial loss: 0.496113\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361971; batch adversarial loss: 0.581669\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363871; batch adversarial loss: 0.599221\n",
      "epoch 146; iter: 0; batch classifier loss: 0.348381; batch adversarial loss: 0.551896\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326860; batch adversarial loss: 0.516634\n",
      "epoch 148; iter: 0; batch classifier loss: 0.388056; batch adversarial loss: 0.497710\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354573; batch adversarial loss: 0.553611\n",
      "epoch 150; iter: 0; batch classifier loss: 0.331949; batch adversarial loss: 0.534602\n",
      "epoch 151; iter: 0; batch classifier loss: 0.319679; batch adversarial loss: 0.553777\n",
      "epoch 152; iter: 0; batch classifier loss: 0.315717; batch adversarial loss: 0.571738\n",
      "epoch 153; iter: 0; batch classifier loss: 0.404770; batch adversarial loss: 0.536122\n",
      "epoch 154; iter: 0; batch classifier loss: 0.423836; batch adversarial loss: 0.656770\n",
      "epoch 155; iter: 0; batch classifier loss: 0.444480; batch adversarial loss: 0.572813\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358022; batch adversarial loss: 0.524668\n",
      "epoch 157; iter: 0; batch classifier loss: 0.342537; batch adversarial loss: 0.580153\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366947; batch adversarial loss: 0.610586\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380802; batch adversarial loss: 0.517648\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379683; batch adversarial loss: 0.636411\n",
      "epoch 161; iter: 0; batch classifier loss: 0.249770; batch adversarial loss: 0.544492\n",
      "epoch 162; iter: 0; batch classifier loss: 0.345339; batch adversarial loss: 0.553862\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364879; batch adversarial loss: 0.468667\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335723; batch adversarial loss: 0.562605\n",
      "epoch 165; iter: 0; batch classifier loss: 0.280768; batch adversarial loss: 0.516876\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369056; batch adversarial loss: 0.507517\n",
      "epoch 167; iter: 0; batch classifier loss: 0.279158; batch adversarial loss: 0.630766\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343832; batch adversarial loss: 0.571689\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376875; batch adversarial loss: 0.580689\n",
      "epoch 170; iter: 0; batch classifier loss: 0.423784; batch adversarial loss: 0.554078\n",
      "epoch 171; iter: 0; batch classifier loss: 0.322554; batch adversarial loss: 0.554960\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360149; batch adversarial loss: 0.535085\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372366; batch adversarial loss: 0.563592\n",
      "epoch 174; iter: 0; batch classifier loss: 0.309666; batch adversarial loss: 0.561976\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340674; batch adversarial loss: 0.554567\n",
      "epoch 176; iter: 0; batch classifier loss: 0.433670; batch adversarial loss: 0.591076\n",
      "epoch 177; iter: 0; batch classifier loss: 0.292312; batch adversarial loss: 0.535836\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331956; batch adversarial loss: 0.553981\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362723; batch adversarial loss: 0.609379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.332626; batch adversarial loss: 0.722470\n",
      "epoch 181; iter: 0; batch classifier loss: 0.389369; batch adversarial loss: 0.572435\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391410; batch adversarial loss: 0.480068\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313876; batch adversarial loss: 0.497456\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328144; batch adversarial loss: 0.545139\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336267; batch adversarial loss: 0.552630\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331117; batch adversarial loss: 0.534797\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341311; batch adversarial loss: 0.516400\n",
      "epoch 188; iter: 0; batch classifier loss: 0.294709; batch adversarial loss: 0.553900\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347900; batch adversarial loss: 0.580936\n",
      "epoch 190; iter: 0; batch classifier loss: 0.350383; batch adversarial loss: 0.497758\n",
      "epoch 191; iter: 0; batch classifier loss: 0.334334; batch adversarial loss: 0.534841\n",
      "epoch 192; iter: 0; batch classifier loss: 0.312781; batch adversarial loss: 0.497230\n",
      "epoch 193; iter: 0; batch classifier loss: 0.314325; batch adversarial loss: 0.582143\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344636; batch adversarial loss: 0.488003\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359205; batch adversarial loss: 0.636351\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301865; batch adversarial loss: 0.508588\n",
      "epoch 197; iter: 0; batch classifier loss: 0.433788; batch adversarial loss: 0.441274\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328978; batch adversarial loss: 0.461387\n",
      "epoch 199; iter: 0; batch classifier loss: 0.438524; batch adversarial loss: 0.478645\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682690; batch adversarial loss: 0.638941\n",
      "epoch 1; iter: 0; batch classifier loss: 0.626287; batch adversarial loss: 0.662163\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600393; batch adversarial loss: 0.623184\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576180; batch adversarial loss: 0.606543\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591077; batch adversarial loss: 0.580279\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587804; batch adversarial loss: 0.619143\n",
      "epoch 6; iter: 0; batch classifier loss: 0.698524; batch adversarial loss: 0.555681\n",
      "epoch 7; iter: 0; batch classifier loss: 0.641471; batch adversarial loss: 0.619226\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539251; batch adversarial loss: 0.588770\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551564; batch adversarial loss: 0.561007\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494466; batch adversarial loss: 0.575282\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551739; batch adversarial loss: 0.626520\n",
      "epoch 12; iter: 0; batch classifier loss: 0.589940; batch adversarial loss: 0.521411\n",
      "epoch 13; iter: 0; batch classifier loss: 0.568736; batch adversarial loss: 0.559238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.494962; batch adversarial loss: 0.659831\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537282; batch adversarial loss: 0.584137\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561164; batch adversarial loss: 0.644339\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503018; batch adversarial loss: 0.567332\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534542; batch adversarial loss: 0.547064\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476683; batch adversarial loss: 0.595665\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510183; batch adversarial loss: 0.603020\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517778; batch adversarial loss: 0.510975\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466654; batch adversarial loss: 0.548298\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507270; batch adversarial loss: 0.543424\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528281; batch adversarial loss: 0.519533\n",
      "epoch 25; iter: 0; batch classifier loss: 0.642582; batch adversarial loss: 0.524723\n",
      "epoch 26; iter: 0; batch classifier loss: 0.531473; batch adversarial loss: 0.547305\n",
      "epoch 27; iter: 0; batch classifier loss: 0.497015; batch adversarial loss: 0.511735\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493888; batch adversarial loss: 0.578020\n",
      "epoch 29; iter: 0; batch classifier loss: 0.418279; batch adversarial loss: 0.552704\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476214; batch adversarial loss: 0.511382\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444035; batch adversarial loss: 0.515717\n",
      "epoch 32; iter: 0; batch classifier loss: 0.337827; batch adversarial loss: 0.587332\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482146; batch adversarial loss: 0.655787\n",
      "epoch 34; iter: 0; batch classifier loss: 0.428136; batch adversarial loss: 0.641309\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468113; batch adversarial loss: 0.561786\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490282; batch adversarial loss: 0.537476\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442265; batch adversarial loss: 0.637374\n",
      "epoch 38; iter: 0; batch classifier loss: 0.500772; batch adversarial loss: 0.581726\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498558; batch adversarial loss: 0.435509\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466446; batch adversarial loss: 0.527109\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420246; batch adversarial loss: 0.535298\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448684; batch adversarial loss: 0.508822\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426341; batch adversarial loss: 0.546866\n",
      "epoch 44; iter: 0; batch classifier loss: 0.522670; batch adversarial loss: 0.555180\n",
      "epoch 45; iter: 0; batch classifier loss: 0.518537; batch adversarial loss: 0.566010\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500363; batch adversarial loss: 0.609525\n",
      "epoch 47; iter: 0; batch classifier loss: 0.513853; batch adversarial loss: 0.483683\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419567; batch adversarial loss: 0.615535\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446937; batch adversarial loss: 0.527744\n",
      "epoch 50; iter: 0; batch classifier loss: 0.466036; batch adversarial loss: 0.560403\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455791; batch adversarial loss: 0.590077\n",
      "epoch 52; iter: 0; batch classifier loss: 0.505965; batch adversarial loss: 0.564697\n",
      "epoch 53; iter: 0; batch classifier loss: 0.451702; batch adversarial loss: 0.525325\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411983; batch adversarial loss: 0.554241\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378563; batch adversarial loss: 0.516545\n",
      "epoch 56; iter: 0; batch classifier loss: 0.469727; batch adversarial loss: 0.534512\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411420; batch adversarial loss: 0.517662\n",
      "epoch 58; iter: 0; batch classifier loss: 0.475205; batch adversarial loss: 0.631935\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406376; batch adversarial loss: 0.485459\n",
      "epoch 60; iter: 0; batch classifier loss: 0.429775; batch adversarial loss: 0.509258\n",
      "epoch 61; iter: 0; batch classifier loss: 0.461405; batch adversarial loss: 0.491088\n",
      "epoch 62; iter: 0; batch classifier loss: 0.494837; batch adversarial loss: 0.528377\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449058; batch adversarial loss: 0.587703\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382427; batch adversarial loss: 0.508383\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376459; batch adversarial loss: 0.507915\n",
      "epoch 66; iter: 0; batch classifier loss: 0.364598; batch adversarial loss: 0.534584\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425935; batch adversarial loss: 0.525744\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404834; batch adversarial loss: 0.536885\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388690; batch adversarial loss: 0.560928\n",
      "epoch 70; iter: 0; batch classifier loss: 0.453497; batch adversarial loss: 0.553099\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396016; batch adversarial loss: 0.489820\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393650; batch adversarial loss: 0.561303\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429039; batch adversarial loss: 0.526806\n",
      "epoch 74; iter: 0; batch classifier loss: 0.456701; batch adversarial loss: 0.528652\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393880; batch adversarial loss: 0.577525\n",
      "epoch 76; iter: 0; batch classifier loss: 0.470606; batch adversarial loss: 0.574503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.350841; batch adversarial loss: 0.535902\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405675; batch adversarial loss: 0.581247\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368274; batch adversarial loss: 0.607380\n",
      "epoch 80; iter: 0; batch classifier loss: 0.439150; batch adversarial loss: 0.616957\n",
      "epoch 81; iter: 0; batch classifier loss: 0.492431; batch adversarial loss: 0.553913\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396691; batch adversarial loss: 0.554163\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417769; batch adversarial loss: 0.436084\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380164; batch adversarial loss: 0.572683\n",
      "epoch 85; iter: 0; batch classifier loss: 0.375645; batch adversarial loss: 0.500469\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383132; batch adversarial loss: 0.571991\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385362; batch adversarial loss: 0.508218\n",
      "epoch 88; iter: 0; batch classifier loss: 0.370429; batch adversarial loss: 0.526296\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339444; batch adversarial loss: 0.543317\n",
      "epoch 90; iter: 0; batch classifier loss: 0.414191; batch adversarial loss: 0.598872\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372028; batch adversarial loss: 0.525069\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386389; batch adversarial loss: 0.534983\n",
      "epoch 93; iter: 0; batch classifier loss: 0.426086; batch adversarial loss: 0.570123\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406793; batch adversarial loss: 0.501598\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410109; batch adversarial loss: 0.515961\n",
      "epoch 96; iter: 0; batch classifier loss: 0.404582; batch adversarial loss: 0.582547\n",
      "epoch 97; iter: 0; batch classifier loss: 0.319892; batch adversarial loss: 0.507096\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393681; batch adversarial loss: 0.562734\n",
      "epoch 99; iter: 0; batch classifier loss: 0.435283; batch adversarial loss: 0.555264\n",
      "epoch 100; iter: 0; batch classifier loss: 0.378403; batch adversarial loss: 0.618674\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387713; batch adversarial loss: 0.644095\n",
      "epoch 102; iter: 0; batch classifier loss: 0.328052; batch adversarial loss: 0.553374\n",
      "epoch 103; iter: 0; batch classifier loss: 0.326140; batch adversarial loss: 0.579987\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389626; batch adversarial loss: 0.544145\n",
      "epoch 105; iter: 0; batch classifier loss: 0.448779; batch adversarial loss: 0.533242\n",
      "epoch 106; iter: 0; batch classifier loss: 0.396046; batch adversarial loss: 0.581107\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391440; batch adversarial loss: 0.529700\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406600; batch adversarial loss: 0.551646\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385104; batch adversarial loss: 0.562670\n",
      "epoch 110; iter: 0; batch classifier loss: 0.358422; batch adversarial loss: 0.544675\n",
      "epoch 111; iter: 0; batch classifier loss: 0.397210; batch adversarial loss: 0.595090\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412297; batch adversarial loss: 0.525076\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418419; batch adversarial loss: 0.553865\n",
      "epoch 114; iter: 0; batch classifier loss: 0.316135; batch adversarial loss: 0.550088\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381671; batch adversarial loss: 0.552060\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339878; batch adversarial loss: 0.575132\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360542; batch adversarial loss: 0.572622\n",
      "epoch 118; iter: 0; batch classifier loss: 0.435808; batch adversarial loss: 0.544272\n",
      "epoch 119; iter: 0; batch classifier loss: 0.400418; batch adversarial loss: 0.545025\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418823; batch adversarial loss: 0.527013\n",
      "epoch 121; iter: 0; batch classifier loss: 0.438084; batch adversarial loss: 0.634356\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367950; batch adversarial loss: 0.544976\n",
      "epoch 123; iter: 0; batch classifier loss: 0.412092; batch adversarial loss: 0.518843\n",
      "epoch 124; iter: 0; batch classifier loss: 0.423034; batch adversarial loss: 0.526619\n",
      "epoch 125; iter: 0; batch classifier loss: 0.331116; batch adversarial loss: 0.472398\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357619; batch adversarial loss: 0.437315\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367470; batch adversarial loss: 0.580712\n",
      "epoch 128; iter: 0; batch classifier loss: 0.452624; batch adversarial loss: 0.616428\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327829; batch adversarial loss: 0.653805\n",
      "epoch 130; iter: 0; batch classifier loss: 0.369336; batch adversarial loss: 0.544713\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389475; batch adversarial loss: 0.461757\n",
      "epoch 132; iter: 0; batch classifier loss: 0.293099; batch adversarial loss: 0.526917\n",
      "epoch 133; iter: 0; batch classifier loss: 0.417563; batch adversarial loss: 0.609603\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350786; batch adversarial loss: 0.525918\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402286; batch adversarial loss: 0.516168\n",
      "epoch 136; iter: 0; batch classifier loss: 0.430855; batch adversarial loss: 0.544676\n",
      "epoch 137; iter: 0; batch classifier loss: 0.336399; batch adversarial loss: 0.498889\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380032; batch adversarial loss: 0.570954\n",
      "epoch 139; iter: 0; batch classifier loss: 0.296545; batch adversarial loss: 0.526358\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371861; batch adversarial loss: 0.481125\n",
      "epoch 141; iter: 0; batch classifier loss: 0.372588; batch adversarial loss: 0.473050\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410857; batch adversarial loss: 0.508894\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405848; batch adversarial loss: 0.499266\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341775; batch adversarial loss: 0.571379\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334029; batch adversarial loss: 0.535515\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384103; batch adversarial loss: 0.499344\n",
      "epoch 147; iter: 0; batch classifier loss: 0.389296; batch adversarial loss: 0.562483\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346961; batch adversarial loss: 0.527171\n",
      "epoch 149; iter: 0; batch classifier loss: 0.401544; batch adversarial loss: 0.535956\n",
      "epoch 150; iter: 0; batch classifier loss: 0.286320; batch adversarial loss: 0.589216\n",
      "epoch 151; iter: 0; batch classifier loss: 0.441715; batch adversarial loss: 0.562821\n",
      "epoch 152; iter: 0; batch classifier loss: 0.415506; batch adversarial loss: 0.589386\n",
      "epoch 153; iter: 0; batch classifier loss: 0.377831; batch adversarial loss: 0.525827\n",
      "epoch 154; iter: 0; batch classifier loss: 0.461040; batch adversarial loss: 0.478717\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327385; batch adversarial loss: 0.570311\n",
      "epoch 156; iter: 0; batch classifier loss: 0.445595; batch adversarial loss: 0.609005\n",
      "epoch 157; iter: 0; batch classifier loss: 0.298018; batch adversarial loss: 0.561527\n",
      "epoch 158; iter: 0; batch classifier loss: 0.306402; batch adversarial loss: 0.526322\n",
      "epoch 159; iter: 0; batch classifier loss: 0.379744; batch adversarial loss: 0.524877\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390534; batch adversarial loss: 0.571686\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318433; batch adversarial loss: 0.544241\n",
      "epoch 162; iter: 0; batch classifier loss: 0.431641; batch adversarial loss: 0.517507\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346622; batch adversarial loss: 0.535066\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337720; batch adversarial loss: 0.582026\n",
      "epoch 165; iter: 0; batch classifier loss: 0.454828; batch adversarial loss: 0.555607\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346749; batch adversarial loss: 0.571408\n",
      "epoch 167; iter: 0; batch classifier loss: 0.391894; batch adversarial loss: 0.654567\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395358; batch adversarial loss: 0.609611\n",
      "epoch 169; iter: 0; batch classifier loss: 0.249766; batch adversarial loss: 0.571666\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374726; batch adversarial loss: 0.546428\n",
      "epoch 171; iter: 0; batch classifier loss: 0.432697; batch adversarial loss: 0.506434\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378066; batch adversarial loss: 0.570786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.373779; batch adversarial loss: 0.563080\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338787; batch adversarial loss: 0.471550\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359938; batch adversarial loss: 0.517988\n",
      "epoch 176; iter: 0; batch classifier loss: 0.281974; batch adversarial loss: 0.536348\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315921; batch adversarial loss: 0.561935\n",
      "epoch 178; iter: 0; batch classifier loss: 0.403039; batch adversarial loss: 0.455731\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399134; batch adversarial loss: 0.544970\n",
      "epoch 180; iter: 0; batch classifier loss: 0.407062; batch adversarial loss: 0.543892\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370486; batch adversarial loss: 0.509428\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341784; batch adversarial loss: 0.553537\n",
      "epoch 183; iter: 0; batch classifier loss: 0.300581; batch adversarial loss: 0.599580\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372003; batch adversarial loss: 0.517665\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402442; batch adversarial loss: 0.624451\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357278; batch adversarial loss: 0.607127\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325871; batch adversarial loss: 0.563246\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348765; batch adversarial loss: 0.518790\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340671; batch adversarial loss: 0.580650\n",
      "epoch 190; iter: 0; batch classifier loss: 0.411090; batch adversarial loss: 0.481587\n",
      "epoch 191; iter: 0; batch classifier loss: 0.314373; batch adversarial loss: 0.570524\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404376; batch adversarial loss: 0.562107\n",
      "epoch 193; iter: 0; batch classifier loss: 0.410831; batch adversarial loss: 0.534375\n",
      "epoch 194; iter: 0; batch classifier loss: 0.337543; batch adversarial loss: 0.445188\n",
      "epoch 195; iter: 0; batch classifier loss: 0.410996; batch adversarial loss: 0.581800\n",
      "epoch 196; iter: 0; batch classifier loss: 0.384251; batch adversarial loss: 0.500960\n",
      "epoch 197; iter: 0; batch classifier loss: 0.288228; batch adversarial loss: 0.480587\n",
      "epoch 198; iter: 0; batch classifier loss: 0.425001; batch adversarial loss: 0.570821\n",
      "epoch 199; iter: 0; batch classifier loss: 0.448162; batch adversarial loss: 0.527604\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704456; batch adversarial loss: 1.015205\n",
      "epoch 1; iter: 0; batch classifier loss: 0.892509; batch adversarial loss: 1.367217\n",
      "epoch 2; iter: 0; batch classifier loss: 0.946532; batch adversarial loss: 1.276860\n",
      "epoch 3; iter: 0; batch classifier loss: 1.042036; batch adversarial loss: 1.193661\n",
      "epoch 4; iter: 0; batch classifier loss: 1.009223; batch adversarial loss: 1.071008\n",
      "epoch 5; iter: 0; batch classifier loss: 0.980330; batch adversarial loss: 1.008699\n",
      "epoch 6; iter: 0; batch classifier loss: 1.013873; batch adversarial loss: 0.929136\n",
      "epoch 7; iter: 0; batch classifier loss: 1.055163; batch adversarial loss: 0.842585\n",
      "epoch 8; iter: 0; batch classifier loss: 0.875340; batch adversarial loss: 0.775639\n",
      "epoch 9; iter: 0; batch classifier loss: 0.801175; batch adversarial loss: 0.743577\n",
      "epoch 10; iter: 0; batch classifier loss: 0.648708; batch adversarial loss: 0.680728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593548; batch adversarial loss: 0.635993\n",
      "epoch 12; iter: 0; batch classifier loss: 0.546140; batch adversarial loss: 0.648122\n",
      "epoch 13; iter: 0; batch classifier loss: 0.617242; batch adversarial loss: 0.581656\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463829; batch adversarial loss: 0.632193\n",
      "epoch 15; iter: 0; batch classifier loss: 0.453304; batch adversarial loss: 0.609416\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477564; batch adversarial loss: 0.593515\n",
      "epoch 17; iter: 0; batch classifier loss: 0.587819; batch adversarial loss: 0.596708\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504123; batch adversarial loss: 0.617976\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498286; batch adversarial loss: 0.566074\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515959; batch adversarial loss: 0.568926\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511106; batch adversarial loss: 0.631392\n",
      "epoch 22; iter: 0; batch classifier loss: 0.575682; batch adversarial loss: 0.571162\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511983; batch adversarial loss: 0.544289\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516998; batch adversarial loss: 0.554311\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515592; batch adversarial loss: 0.520086\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510040; batch adversarial loss: 0.619102\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507866; batch adversarial loss: 0.546697\n",
      "epoch 28; iter: 0; batch classifier loss: 0.466551; batch adversarial loss: 0.545979\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506115; batch adversarial loss: 0.644285\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453203; batch adversarial loss: 0.517495\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501932; batch adversarial loss: 0.537838\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487231; batch adversarial loss: 0.504459\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430098; batch adversarial loss: 0.537008\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483903; batch adversarial loss: 0.578111\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499694; batch adversarial loss: 0.518288\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444468; batch adversarial loss: 0.515870\n",
      "epoch 37; iter: 0; batch classifier loss: 0.520885; batch adversarial loss: 0.593351\n",
      "epoch 38; iter: 0; batch classifier loss: 0.524043; batch adversarial loss: 0.576989\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459197; batch adversarial loss: 0.574535\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464402; batch adversarial loss: 0.551341\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474065; batch adversarial loss: 0.540882\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424532; batch adversarial loss: 0.580728\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484707; batch adversarial loss: 0.598555\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478960; batch adversarial loss: 0.526940\n",
      "epoch 45; iter: 0; batch classifier loss: 0.497606; batch adversarial loss: 0.552525\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438929; batch adversarial loss: 0.591495\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410629; batch adversarial loss: 0.571547\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443875; batch adversarial loss: 0.600246\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404591; batch adversarial loss: 0.570810\n",
      "epoch 50; iter: 0; batch classifier loss: 0.359119; batch adversarial loss: 0.585067\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424487; batch adversarial loss: 0.521949\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407682; batch adversarial loss: 0.563438\n",
      "epoch 53; iter: 0; batch classifier loss: 0.476013; batch adversarial loss: 0.491497\n",
      "epoch 54; iter: 0; batch classifier loss: 0.436699; batch adversarial loss: 0.553368\n",
      "epoch 55; iter: 0; batch classifier loss: 0.538029; batch adversarial loss: 0.501714\n",
      "epoch 56; iter: 0; batch classifier loss: 0.509909; batch adversarial loss: 0.500981\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408497; batch adversarial loss: 0.572542\n",
      "epoch 58; iter: 0; batch classifier loss: 0.483675; batch adversarial loss: 0.510358\n",
      "epoch 59; iter: 0; batch classifier loss: 0.475728; batch adversarial loss: 0.493166\n",
      "epoch 60; iter: 0; batch classifier loss: 0.368420; batch adversarial loss: 0.447785\n",
      "epoch 61; iter: 0; batch classifier loss: 0.374375; batch adversarial loss: 0.543758\n",
      "epoch 62; iter: 0; batch classifier loss: 0.468191; batch adversarial loss: 0.500355\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385126; batch adversarial loss: 0.518598\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428891; batch adversarial loss: 0.608008\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427051; batch adversarial loss: 0.526757\n",
      "epoch 66; iter: 0; batch classifier loss: 0.402523; batch adversarial loss: 0.501008\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426939; batch adversarial loss: 0.509244\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423016; batch adversarial loss: 0.572474\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449783; batch adversarial loss: 0.499196\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404075; batch adversarial loss: 0.570560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.364449; batch adversarial loss: 0.535709\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380413; batch adversarial loss: 0.608755\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410854; batch adversarial loss: 0.454373\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393496; batch adversarial loss: 0.508314\n",
      "epoch 75; iter: 0; batch classifier loss: 0.363975; batch adversarial loss: 0.560775\n",
      "epoch 76; iter: 0; batch classifier loss: 0.443896; batch adversarial loss: 0.552389\n",
      "epoch 77; iter: 0; batch classifier loss: 0.448040; batch adversarial loss: 0.544628\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421453; batch adversarial loss: 0.527780\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398536; batch adversarial loss: 0.579809\n",
      "epoch 80; iter: 0; batch classifier loss: 0.499764; batch adversarial loss: 0.552547\n",
      "epoch 81; iter: 0; batch classifier loss: 0.363733; batch adversarial loss: 0.581307\n",
      "epoch 82; iter: 0; batch classifier loss: 0.426307; batch adversarial loss: 0.542814\n",
      "epoch 83; iter: 0; batch classifier loss: 0.309783; batch adversarial loss: 0.545422\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418639; batch adversarial loss: 0.598583\n",
      "epoch 85; iter: 0; batch classifier loss: 0.457220; batch adversarial loss: 0.553535\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350399; batch adversarial loss: 0.616494\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401518; batch adversarial loss: 0.571090\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411136; batch adversarial loss: 0.509008\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433648; batch adversarial loss: 0.545587\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387709; batch adversarial loss: 0.535542\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366476; batch adversarial loss: 0.507848\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379432; batch adversarial loss: 0.562616\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394256; batch adversarial loss: 0.572171\n",
      "epoch 94; iter: 0; batch classifier loss: 0.418344; batch adversarial loss: 0.536129\n",
      "epoch 95; iter: 0; batch classifier loss: 0.454966; batch adversarial loss: 0.562042\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416411; batch adversarial loss: 0.525616\n",
      "epoch 97; iter: 0; batch classifier loss: 0.446631; batch adversarial loss: 0.480007\n",
      "epoch 98; iter: 0; batch classifier loss: 0.337312; batch adversarial loss: 0.473989\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397093; batch adversarial loss: 0.545835\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357085; batch adversarial loss: 0.570812\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434133; batch adversarial loss: 0.571254\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379498; batch adversarial loss: 0.484550\n",
      "epoch 103; iter: 0; batch classifier loss: 0.353067; batch adversarial loss: 0.615561\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365996; batch adversarial loss: 0.535826\n",
      "epoch 105; iter: 0; batch classifier loss: 0.374194; batch adversarial loss: 0.544037\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395864; batch adversarial loss: 0.509121\n",
      "epoch 107; iter: 0; batch classifier loss: 0.343504; batch adversarial loss: 0.589465\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405130; batch adversarial loss: 0.570436\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410159; batch adversarial loss: 0.472396\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356447; batch adversarial loss: 0.501439\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374030; batch adversarial loss: 0.571476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357975; batch adversarial loss: 0.465378\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390129; batch adversarial loss: 0.570785\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388243; batch adversarial loss: 0.544224\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398407; batch adversarial loss: 0.534806\n",
      "epoch 116; iter: 0; batch classifier loss: 0.295730; batch adversarial loss: 0.535093\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383930; batch adversarial loss: 0.543751\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427532; batch adversarial loss: 0.491348\n",
      "epoch 119; iter: 0; batch classifier loss: 0.335812; batch adversarial loss: 0.509231\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407928; batch adversarial loss: 0.563343\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346543; batch adversarial loss: 0.482216\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373110; batch adversarial loss: 0.553732\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349940; batch adversarial loss: 0.517057\n",
      "epoch 124; iter: 0; batch classifier loss: 0.287335; batch adversarial loss: 0.606609\n",
      "epoch 125; iter: 0; batch classifier loss: 0.357723; batch adversarial loss: 0.572772\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334963; batch adversarial loss: 0.587380\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333018; batch adversarial loss: 0.543994\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383955; batch adversarial loss: 0.545415\n",
      "epoch 129; iter: 0; batch classifier loss: 0.423560; batch adversarial loss: 0.562697\n",
      "epoch 130; iter: 0; batch classifier loss: 0.319337; batch adversarial loss: 0.526737\n",
      "epoch 131; iter: 0; batch classifier loss: 0.302752; batch adversarial loss: 0.534667\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376796; batch adversarial loss: 0.491613\n",
      "epoch 133; iter: 0; batch classifier loss: 0.276544; batch adversarial loss: 0.668784\n",
      "epoch 134; iter: 0; batch classifier loss: 0.389355; batch adversarial loss: 0.553168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.455325; batch adversarial loss: 0.508062\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406955; batch adversarial loss: 0.544631\n",
      "epoch 137; iter: 0; batch classifier loss: 0.293836; batch adversarial loss: 0.473926\n",
      "epoch 138; iter: 0; batch classifier loss: 0.347286; batch adversarial loss: 0.498800\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381665; batch adversarial loss: 0.553515\n",
      "epoch 140; iter: 0; batch classifier loss: 0.345752; batch adversarial loss: 0.551716\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381680; batch adversarial loss: 0.553087\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326168; batch adversarial loss: 0.508602\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385472; batch adversarial loss: 0.524379\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327843; batch adversarial loss: 0.634060\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338816; batch adversarial loss: 0.518169\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325923; batch adversarial loss: 0.535322\n",
      "epoch 147; iter: 0; batch classifier loss: 0.357446; batch adversarial loss: 0.527643\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374597; batch adversarial loss: 0.535657\n",
      "epoch 149; iter: 0; batch classifier loss: 0.356727; batch adversarial loss: 0.535306\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344275; batch adversarial loss: 0.580162\n",
      "epoch 151; iter: 0; batch classifier loss: 0.318258; batch adversarial loss: 0.472076\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366074; batch adversarial loss: 0.563362\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355028; batch adversarial loss: 0.572248\n",
      "epoch 154; iter: 0; batch classifier loss: 0.418770; batch adversarial loss: 0.555207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379591; batch adversarial loss: 0.528123\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349124; batch adversarial loss: 0.598819\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372669; batch adversarial loss: 0.561082\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341633; batch adversarial loss: 0.597723\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375959; batch adversarial loss: 0.564058\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357185; batch adversarial loss: 0.651560\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388736; batch adversarial loss: 0.553017\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347608; batch adversarial loss: 0.542776\n",
      "epoch 163; iter: 0; batch classifier loss: 0.352128; batch adversarial loss: 0.527377\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385307; batch adversarial loss: 0.571906\n",
      "epoch 165; iter: 0; batch classifier loss: 0.429155; batch adversarial loss: 0.464961\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346259; batch adversarial loss: 0.580787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.304413; batch adversarial loss: 0.570510\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332690; batch adversarial loss: 0.517993\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376731; batch adversarial loss: 0.509920\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297220; batch adversarial loss: 0.527338\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355746; batch adversarial loss: 0.536412\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375649; batch adversarial loss: 0.515862\n",
      "epoch 173; iter: 0; batch classifier loss: 0.314602; batch adversarial loss: 0.535489\n",
      "epoch 174; iter: 0; batch classifier loss: 0.271634; batch adversarial loss: 0.551540\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329529; batch adversarial loss: 0.536145\n",
      "epoch 176; iter: 0; batch classifier loss: 0.321795; batch adversarial loss: 0.553607\n",
      "epoch 177; iter: 0; batch classifier loss: 0.366207; batch adversarial loss: 0.561552\n",
      "epoch 178; iter: 0; batch classifier loss: 0.300004; batch adversarial loss: 0.608061\n",
      "epoch 179; iter: 0; batch classifier loss: 0.353902; batch adversarial loss: 0.544225\n",
      "epoch 180; iter: 0; batch classifier loss: 0.370785; batch adversarial loss: 0.542487\n",
      "epoch 181; iter: 0; batch classifier loss: 0.340461; batch adversarial loss: 0.490761\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372394; batch adversarial loss: 0.553328\n",
      "epoch 183; iter: 0; batch classifier loss: 0.319352; batch adversarial loss: 0.588873\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397687; batch adversarial loss: 0.508693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.380904; batch adversarial loss: 0.552875\n",
      "epoch 186; iter: 0; batch classifier loss: 0.277664; batch adversarial loss: 0.517892\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365641; batch adversarial loss: 0.537331\n",
      "epoch 188; iter: 0; batch classifier loss: 0.342681; batch adversarial loss: 0.573279\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333428; batch adversarial loss: 0.552855\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376783; batch adversarial loss: 0.510000\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336333; batch adversarial loss: 0.545262\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333780; batch adversarial loss: 0.614213\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345264; batch adversarial loss: 0.578337\n",
      "epoch 194; iter: 0; batch classifier loss: 0.286712; batch adversarial loss: 0.527036\n",
      "epoch 195; iter: 0; batch classifier loss: 0.304838; batch adversarial loss: 0.560966\n",
      "epoch 196; iter: 0; batch classifier loss: 0.293225; batch adversarial loss: 0.553141\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381921; batch adversarial loss: 0.455245\n",
      "epoch 198; iter: 0; batch classifier loss: 0.400322; batch adversarial loss: 0.490968\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359417; batch adversarial loss: 0.561862\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689471; batch adversarial loss: 0.682917\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610751; batch adversarial loss: 0.652171\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575509; batch adversarial loss: 0.639507\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624807; batch adversarial loss: 0.622465\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587118; batch adversarial loss: 0.631043\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564075; batch adversarial loss: 0.604269\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560656; batch adversarial loss: 0.650000\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556021; batch adversarial loss: 0.533930\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555787; batch adversarial loss: 0.588712\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532898; batch adversarial loss: 0.601593\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505777; batch adversarial loss: 0.554417\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530925; batch adversarial loss: 0.548485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485139; batch adversarial loss: 0.610122\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553578; batch adversarial loss: 0.557796\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556660; batch adversarial loss: 0.554097\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534592; batch adversarial loss: 0.595285\n",
      "epoch 16; iter: 0; batch classifier loss: 0.560345; batch adversarial loss: 0.553486\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534768; batch adversarial loss: 0.570139\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514527; batch adversarial loss: 0.524814\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502924; batch adversarial loss: 0.615951\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448401; batch adversarial loss: 0.510659\n",
      "epoch 21; iter: 0; batch classifier loss: 0.518820; batch adversarial loss: 0.580081\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479321; batch adversarial loss: 0.608611\n",
      "epoch 23; iter: 0; batch classifier loss: 0.565783; batch adversarial loss: 0.507432\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452197; batch adversarial loss: 0.508514\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502808; batch adversarial loss: 0.579728\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450278; batch adversarial loss: 0.561911\n",
      "epoch 27; iter: 0; batch classifier loss: 0.508689; batch adversarial loss: 0.526667\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452592; batch adversarial loss: 0.529504\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476950; batch adversarial loss: 0.452710\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475653; batch adversarial loss: 0.605767\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454706; batch adversarial loss: 0.565398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.533989; batch adversarial loss: 0.462485\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455726; batch adversarial loss: 0.559307\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488431; batch adversarial loss: 0.545102\n",
      "epoch 35; iter: 0; batch classifier loss: 0.516151; batch adversarial loss: 0.542544\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435612; batch adversarial loss: 0.519949\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480998; batch adversarial loss: 0.526910\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439933; batch adversarial loss: 0.534945\n",
      "epoch 39; iter: 0; batch classifier loss: 0.472337; batch adversarial loss: 0.528082\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524409; batch adversarial loss: 0.516994\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470412; batch adversarial loss: 0.527580\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480323; batch adversarial loss: 0.536592\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483148; batch adversarial loss: 0.544451\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397682; batch adversarial loss: 0.545427\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480057; batch adversarial loss: 0.562497\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464393; batch adversarial loss: 0.526309\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386811; batch adversarial loss: 0.634440\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427257; batch adversarial loss: 0.618801\n",
      "epoch 49; iter: 0; batch classifier loss: 0.489550; batch adversarial loss: 0.599092\n",
      "epoch 50; iter: 0; batch classifier loss: 0.436829; batch adversarial loss: 0.553082\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427751; batch adversarial loss: 0.590973\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390792; batch adversarial loss: 0.591361\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389483; batch adversarial loss: 0.554269\n",
      "epoch 54; iter: 0; batch classifier loss: 0.539654; batch adversarial loss: 0.602597\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423254; batch adversarial loss: 0.460835\n",
      "epoch 56; iter: 0; batch classifier loss: 0.479972; batch adversarial loss: 0.471958\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454458; batch adversarial loss: 0.544528\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384766; batch adversarial loss: 0.481023\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439067; batch adversarial loss: 0.544789\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392124; batch adversarial loss: 0.572290\n",
      "epoch 61; iter: 0; batch classifier loss: 0.321693; batch adversarial loss: 0.617771\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459694; batch adversarial loss: 0.479470\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395949; batch adversarial loss: 0.535298\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431534; batch adversarial loss: 0.507751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.439069; batch adversarial loss: 0.600002\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439654; batch adversarial loss: 0.572033\n",
      "epoch 67; iter: 0; batch classifier loss: 0.454936; batch adversarial loss: 0.507739\n",
      "epoch 68; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.572489\n",
      "epoch 69; iter: 0; batch classifier loss: 0.498926; batch adversarial loss: 0.553976\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396525; batch adversarial loss: 0.617200\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414515; batch adversarial loss: 0.526500\n",
      "epoch 72; iter: 0; batch classifier loss: 0.511327; batch adversarial loss: 0.508743\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380655; batch adversarial loss: 0.554333\n",
      "epoch 74; iter: 0; batch classifier loss: 0.484829; batch adversarial loss: 0.580890\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404567; batch adversarial loss: 0.553555\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416713; batch adversarial loss: 0.488306\n",
      "epoch 77; iter: 0; batch classifier loss: 0.478336; batch adversarial loss: 0.526287\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372595; batch adversarial loss: 0.590342\n",
      "epoch 79; iter: 0; batch classifier loss: 0.466212; batch adversarial loss: 0.497823\n",
      "epoch 80; iter: 0; batch classifier loss: 0.479421; batch adversarial loss: 0.553262\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406664; batch adversarial loss: 0.535533\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398659; batch adversarial loss: 0.473573\n",
      "epoch 83; iter: 0; batch classifier loss: 0.390990; batch adversarial loss: 0.545303\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418085; batch adversarial loss: 0.481948\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424228; batch adversarial loss: 0.591104\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383100; batch adversarial loss: 0.497672\n",
      "epoch 87; iter: 0; batch classifier loss: 0.446445; batch adversarial loss: 0.579580\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391022; batch adversarial loss: 0.516246\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394826; batch adversarial loss: 0.545453\n",
      "epoch 90; iter: 0; batch classifier loss: 0.468641; batch adversarial loss: 0.629573\n",
      "epoch 91; iter: 0; batch classifier loss: 0.333030; batch adversarial loss: 0.546212\n",
      "epoch 92; iter: 0; batch classifier loss: 0.415138; batch adversarial loss: 0.639055\n",
      "epoch 93; iter: 0; batch classifier loss: 0.443019; batch adversarial loss: 0.581493\n",
      "epoch 94; iter: 0; batch classifier loss: 0.352589; batch adversarial loss: 0.563465\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402272; batch adversarial loss: 0.507392\n",
      "epoch 96; iter: 0; batch classifier loss: 0.406459; batch adversarial loss: 0.553819\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425856; batch adversarial loss: 0.635683\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391944; batch adversarial loss: 0.562635\n",
      "epoch 99; iter: 0; batch classifier loss: 0.539279; batch adversarial loss: 0.591281\n",
      "epoch 100; iter: 0; batch classifier loss: 0.419833; batch adversarial loss: 0.461850\n",
      "epoch 101; iter: 0; batch classifier loss: 0.460132; batch adversarial loss: 0.572388\n",
      "epoch 102; iter: 0; batch classifier loss: 0.333315; batch adversarial loss: 0.563561\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438978; batch adversarial loss: 0.540997\n",
      "epoch 104; iter: 0; batch classifier loss: 0.438434; batch adversarial loss: 0.563604\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342920; batch adversarial loss: 0.535903\n",
      "epoch 106; iter: 0; batch classifier loss: 0.425537; batch adversarial loss: 0.551749\n",
      "epoch 107; iter: 0; batch classifier loss: 0.434231; batch adversarial loss: 0.479063\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364823; batch adversarial loss: 0.652490\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410894; batch adversarial loss: 0.597206\n",
      "epoch 110; iter: 0; batch classifier loss: 0.430453; batch adversarial loss: 0.488287\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361025; batch adversarial loss: 0.535327\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398000; batch adversarial loss: 0.514834\n",
      "epoch 113; iter: 0; batch classifier loss: 0.336367; batch adversarial loss: 0.557850\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368623; batch adversarial loss: 0.583805\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332693; batch adversarial loss: 0.564679\n",
      "epoch 116; iter: 0; batch classifier loss: 0.458661; batch adversarial loss: 0.617824\n",
      "epoch 117; iter: 0; batch classifier loss: 0.426082; batch adversarial loss: 0.635384\n",
      "epoch 118; iter: 0; batch classifier loss: 0.429102; batch adversarial loss: 0.528317\n",
      "epoch 119; iter: 0; batch classifier loss: 0.400293; batch adversarial loss: 0.525890\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363605; batch adversarial loss: 0.564792\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358475; batch adversarial loss: 0.597773\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369877; batch adversarial loss: 0.571126\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353032; batch adversarial loss: 0.534752\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363524; batch adversarial loss: 0.555812\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372242; batch adversarial loss: 0.534715\n",
      "epoch 126; iter: 0; batch classifier loss: 0.370161; batch adversarial loss: 0.517063\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384118; batch adversarial loss: 0.535535\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387889; batch adversarial loss: 0.496517\n",
      "epoch 129; iter: 0; batch classifier loss: 0.307194; batch adversarial loss: 0.564588\n",
      "epoch 130; iter: 0; batch classifier loss: 0.368467; batch adversarial loss: 0.608946\n",
      "epoch 131; iter: 0; batch classifier loss: 0.358790; batch adversarial loss: 0.582074\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384488; batch adversarial loss: 0.617132\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385528; batch adversarial loss: 0.608238\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373770; batch adversarial loss: 0.543842\n",
      "epoch 135; iter: 0; batch classifier loss: 0.328122; batch adversarial loss: 0.500551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.299701; batch adversarial loss: 0.562563\n",
      "epoch 137; iter: 0; batch classifier loss: 0.515418; batch adversarial loss: 0.459588\n",
      "epoch 138; iter: 0; batch classifier loss: 0.323996; batch adversarial loss: 0.488275\n",
      "epoch 139; iter: 0; batch classifier loss: 0.432672; batch adversarial loss: 0.508400\n",
      "epoch 140; iter: 0; batch classifier loss: 0.300644; batch adversarial loss: 0.515810\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409781; batch adversarial loss: 0.563421\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360333; batch adversarial loss: 0.590778\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395034; batch adversarial loss: 0.579856\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367819; batch adversarial loss: 0.508413\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347453; batch adversarial loss: 0.636838\n",
      "epoch 146; iter: 0; batch classifier loss: 0.431271; batch adversarial loss: 0.543454\n",
      "epoch 147; iter: 0; batch classifier loss: 0.312109; batch adversarial loss: 0.471481\n",
      "epoch 148; iter: 0; batch classifier loss: 0.463316; batch adversarial loss: 0.571309\n",
      "epoch 149; iter: 0; batch classifier loss: 0.411359; batch adversarial loss: 0.516310\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320712; batch adversarial loss: 0.563824\n",
      "epoch 151; iter: 0; batch classifier loss: 0.428077; batch adversarial loss: 0.535297\n",
      "epoch 152; iter: 0; batch classifier loss: 0.407307; batch adversarial loss: 0.524613\n",
      "epoch 153; iter: 0; batch classifier loss: 0.378887; batch adversarial loss: 0.562981\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397157; batch adversarial loss: 0.537517\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343211; batch adversarial loss: 0.552105\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366289; batch adversarial loss: 0.588671\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364454; batch adversarial loss: 0.571854\n",
      "epoch 158; iter: 0; batch classifier loss: 0.486296; batch adversarial loss: 0.534055\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394683; batch adversarial loss: 0.536637\n",
      "epoch 160; iter: 0; batch classifier loss: 0.417281; batch adversarial loss: 0.517233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.399216; batch adversarial loss: 0.574617\n",
      "epoch 162; iter: 0; batch classifier loss: 0.384845; batch adversarial loss: 0.498280\n",
      "epoch 163; iter: 0; batch classifier loss: 0.477151; batch adversarial loss: 0.516511\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336377; batch adversarial loss: 0.525269\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359585; batch adversarial loss: 0.500257\n",
      "epoch 166; iter: 0; batch classifier loss: 0.416275; batch adversarial loss: 0.517725\n",
      "epoch 167; iter: 0; batch classifier loss: 0.415180; batch adversarial loss: 0.563615\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320351; batch adversarial loss: 0.526394\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353353; batch adversarial loss: 0.488371\n",
      "epoch 170; iter: 0; batch classifier loss: 0.381038; batch adversarial loss: 0.488740\n",
      "epoch 171; iter: 0; batch classifier loss: 0.398026; batch adversarial loss: 0.478250\n",
      "epoch 172; iter: 0; batch classifier loss: 0.424330; batch adversarial loss: 0.580593\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338057; batch adversarial loss: 0.646942\n",
      "epoch 174; iter: 0; batch classifier loss: 0.415239; batch adversarial loss: 0.555012\n",
      "epoch 175; iter: 0; batch classifier loss: 0.403308; batch adversarial loss: 0.626703\n",
      "epoch 176; iter: 0; batch classifier loss: 0.375850; batch adversarial loss: 0.590267\n",
      "epoch 177; iter: 0; batch classifier loss: 0.364207; batch adversarial loss: 0.583406\n",
      "epoch 178; iter: 0; batch classifier loss: 0.404055; batch adversarial loss: 0.600961\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374239; batch adversarial loss: 0.543613\n",
      "epoch 180; iter: 0; batch classifier loss: 0.320107; batch adversarial loss: 0.602227\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320676; batch adversarial loss: 0.488282\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382899; batch adversarial loss: 0.574202\n",
      "epoch 183; iter: 0; batch classifier loss: 0.302035; batch adversarial loss: 0.618987\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397085; batch adversarial loss: 0.554641\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377078; batch adversarial loss: 0.582748\n",
      "epoch 186; iter: 0; batch classifier loss: 0.425160; batch adversarial loss: 0.489653\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376034; batch adversarial loss: 0.571142\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374052; batch adversarial loss: 0.543254\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362135; batch adversarial loss: 0.610068\n",
      "epoch 190; iter: 0; batch classifier loss: 0.307203; batch adversarial loss: 0.536215\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336590; batch adversarial loss: 0.545641\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343652; batch adversarial loss: 0.553354\n",
      "epoch 193; iter: 0; batch classifier loss: 0.374250; batch adversarial loss: 0.480520\n",
      "epoch 194; iter: 0; batch classifier loss: 0.329921; batch adversarial loss: 0.487276\n",
      "epoch 195; iter: 0; batch classifier loss: 0.408207; batch adversarial loss: 0.571683\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362966; batch adversarial loss: 0.490043\n",
      "epoch 197; iter: 0; batch classifier loss: 0.338126; batch adversarial loss: 0.478440\n",
      "epoch 198; iter: 0; batch classifier loss: 0.432972; batch adversarial loss: 0.507684\n",
      "epoch 199; iter: 0; batch classifier loss: 0.400554; batch adversarial loss: 0.525748\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695258; batch adversarial loss: 0.654479\n",
      "epoch 1; iter: 0; batch classifier loss: 0.558141; batch adversarial loss: 0.653836\n",
      "epoch 2; iter: 0; batch classifier loss: 0.636295; batch adversarial loss: 0.652675\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573496; batch adversarial loss: 0.646335\n",
      "epoch 4; iter: 0; batch classifier loss: 0.602776; batch adversarial loss: 0.657314\n",
      "epoch 5; iter: 0; batch classifier loss: 0.584512; batch adversarial loss: 0.623333\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589806; batch adversarial loss: 0.640559\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573593; batch adversarial loss: 0.616558\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521117; batch adversarial loss: 0.572285\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558381; batch adversarial loss: 0.598568\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574600; batch adversarial loss: 0.555413\n",
      "epoch 11; iter: 0; batch classifier loss: 0.581870; batch adversarial loss: 0.625700\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577481; batch adversarial loss: 0.631953\n",
      "epoch 13; iter: 0; batch classifier loss: 0.574770; batch adversarial loss: 0.594744\n",
      "epoch 14; iter: 0; batch classifier loss: 0.589369; batch adversarial loss: 0.618765\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507106; batch adversarial loss: 0.586858\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547636; batch adversarial loss: 0.604279\n",
      "epoch 17; iter: 0; batch classifier loss: 0.624858; batch adversarial loss: 0.583776\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499487; batch adversarial loss: 0.472091\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491277; batch adversarial loss: 0.553038\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462463; batch adversarial loss: 0.578311\n",
      "epoch 21; iter: 0; batch classifier loss: 0.590624; batch adversarial loss: 0.595253\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489590; batch adversarial loss: 0.550805\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505986; batch adversarial loss: 0.536466\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484596; batch adversarial loss: 0.582602\n",
      "epoch 25; iter: 0; batch classifier loss: 0.558103; batch adversarial loss: 0.539086\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478802; batch adversarial loss: 0.529322\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453251; batch adversarial loss: 0.575309\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484749; batch adversarial loss: 0.586746\n",
      "epoch 29; iter: 0; batch classifier loss: 0.442600; batch adversarial loss: 0.482493\n",
      "epoch 30; iter: 0; batch classifier loss: 0.530529; batch adversarial loss: 0.562272\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506462; batch adversarial loss: 0.569496\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497624; batch adversarial loss: 0.551880\n",
      "epoch 33; iter: 0; batch classifier loss: 0.391254; batch adversarial loss: 0.541392\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412335; batch adversarial loss: 0.562943\n",
      "epoch 35; iter: 0; batch classifier loss: 0.544993; batch adversarial loss: 0.504536\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457027; batch adversarial loss: 0.516744\n",
      "epoch 37; iter: 0; batch classifier loss: 0.488421; batch adversarial loss: 0.518113\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484416; batch adversarial loss: 0.527892\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483014; batch adversarial loss: 0.615086\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434842; batch adversarial loss: 0.509295\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474650; batch adversarial loss: 0.582297\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444121; batch adversarial loss: 0.604625\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451135; batch adversarial loss: 0.512491\n",
      "epoch 44; iter: 0; batch classifier loss: 0.537481; batch adversarial loss: 0.508560\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435397; batch adversarial loss: 0.517014\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460917; batch adversarial loss: 0.543109\n",
      "epoch 47; iter: 0; batch classifier loss: 0.532841; batch adversarial loss: 0.528511\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449633; batch adversarial loss: 0.508019\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405594; batch adversarial loss: 0.545864\n",
      "epoch 50; iter: 0; batch classifier loss: 0.500342; batch adversarial loss: 0.524294\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414664; batch adversarial loss: 0.561686\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440798; batch adversarial loss: 0.597369\n",
      "epoch 53; iter: 0; batch classifier loss: 0.368573; batch adversarial loss: 0.618072\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402960; batch adversarial loss: 0.504101\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459916; batch adversarial loss: 0.479779\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442325; batch adversarial loss: 0.533385\n",
      "epoch 57; iter: 0; batch classifier loss: 0.452299; batch adversarial loss: 0.471091\n",
      "epoch 58; iter: 0; batch classifier loss: 0.348904; batch adversarial loss: 0.540267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.461356; batch adversarial loss: 0.523505\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434919; batch adversarial loss: 0.481917\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467301; batch adversarial loss: 0.532861\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397545; batch adversarial loss: 0.600727\n",
      "epoch 63; iter: 0; batch classifier loss: 0.458078; batch adversarial loss: 0.562162\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436507; batch adversarial loss: 0.528217\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397516; batch adversarial loss: 0.515486\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452449; batch adversarial loss: 0.602460\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401312; batch adversarial loss: 0.510383\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377367; batch adversarial loss: 0.601950\n",
      "epoch 69; iter: 0; batch classifier loss: 0.498319; batch adversarial loss: 0.591031\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426308; batch adversarial loss: 0.546577\n",
      "epoch 71; iter: 0; batch classifier loss: 0.348994; batch adversarial loss: 0.571790\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391044; batch adversarial loss: 0.499432\n",
      "epoch 73; iter: 0; batch classifier loss: 0.492203; batch adversarial loss: 0.487938\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391112; batch adversarial loss: 0.599846\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447219; batch adversarial loss: 0.535254\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402407; batch adversarial loss: 0.563158\n",
      "epoch 77; iter: 0; batch classifier loss: 0.359142; batch adversarial loss: 0.571396\n",
      "epoch 78; iter: 0; batch classifier loss: 0.374850; batch adversarial loss: 0.604799\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411862; batch adversarial loss: 0.469765\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407156; batch adversarial loss: 0.562110\n",
      "epoch 81; iter: 0; batch classifier loss: 0.338204; batch adversarial loss: 0.577270\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411918; batch adversarial loss: 0.582631\n",
      "epoch 83; iter: 0; batch classifier loss: 0.430577; batch adversarial loss: 0.572799\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416499; batch adversarial loss: 0.564441\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381779; batch adversarial loss: 0.528333\n",
      "epoch 86; iter: 0; batch classifier loss: 0.386923; batch adversarial loss: 0.612578\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363842; batch adversarial loss: 0.515920\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413557; batch adversarial loss: 0.600890\n",
      "epoch 89; iter: 0; batch classifier loss: 0.348257; batch adversarial loss: 0.495762\n",
      "epoch 90; iter: 0; batch classifier loss: 0.307685; batch adversarial loss: 0.595930\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384351; batch adversarial loss: 0.584498\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383874; batch adversarial loss: 0.487577\n",
      "epoch 93; iter: 0; batch classifier loss: 0.450247; batch adversarial loss: 0.439197\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370433; batch adversarial loss: 0.545606\n",
      "epoch 95; iter: 0; batch classifier loss: 0.482224; batch adversarial loss: 0.490075\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401089; batch adversarial loss: 0.525778\n",
      "epoch 97; iter: 0; batch classifier loss: 0.322191; batch adversarial loss: 0.505911\n",
      "epoch 98; iter: 0; batch classifier loss: 0.450459; batch adversarial loss: 0.555892\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390045; batch adversarial loss: 0.544023\n",
      "epoch 100; iter: 0; batch classifier loss: 0.378065; batch adversarial loss: 0.490395\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403231; batch adversarial loss: 0.476264\n",
      "epoch 102; iter: 0; batch classifier loss: 0.348342; batch adversarial loss: 0.544819\n",
      "epoch 103; iter: 0; batch classifier loss: 0.343363; batch adversarial loss: 0.585171\n",
      "epoch 104; iter: 0; batch classifier loss: 0.435423; batch adversarial loss: 0.526012\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404810; batch adversarial loss: 0.571982\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353453; batch adversarial loss: 0.586190\n",
      "epoch 107; iter: 0; batch classifier loss: 0.385780; batch adversarial loss: 0.563041\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392467; batch adversarial loss: 0.488468\n",
      "epoch 109; iter: 0; batch classifier loss: 0.459595; batch adversarial loss: 0.543639\n",
      "epoch 110; iter: 0; batch classifier loss: 0.341054; batch adversarial loss: 0.592583\n",
      "epoch 111; iter: 0; batch classifier loss: 0.477996; batch adversarial loss: 0.630189\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389169; batch adversarial loss: 0.535959\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415150; batch adversarial loss: 0.498930\n",
      "epoch 114; iter: 0; batch classifier loss: 0.300424; batch adversarial loss: 0.564301\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382391; batch adversarial loss: 0.496931\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390082; batch adversarial loss: 0.539055\n",
      "epoch 117; iter: 0; batch classifier loss: 0.403278; batch adversarial loss: 0.544837\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403064; batch adversarial loss: 0.546241\n",
      "epoch 119; iter: 0; batch classifier loss: 0.405881; batch adversarial loss: 0.512376\n",
      "epoch 120; iter: 0; batch classifier loss: 0.333693; batch adversarial loss: 0.553238\n",
      "epoch 121; iter: 0; batch classifier loss: 0.429798; batch adversarial loss: 0.512609\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383600; batch adversarial loss: 0.483909\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357848; batch adversarial loss: 0.519315\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353199; batch adversarial loss: 0.555140\n",
      "epoch 125; iter: 0; batch classifier loss: 0.421314; batch adversarial loss: 0.534663\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347780; batch adversarial loss: 0.541306\n",
      "epoch 127; iter: 0; batch classifier loss: 0.400261; batch adversarial loss: 0.486560\n",
      "epoch 128; iter: 0; batch classifier loss: 0.363793; batch adversarial loss: 0.519412\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362831; batch adversarial loss: 0.524938\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364138; batch adversarial loss: 0.509901\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360999; batch adversarial loss: 0.513655\n",
      "epoch 132; iter: 0; batch classifier loss: 0.550573; batch adversarial loss: 0.618266\n",
      "epoch 133; iter: 0; batch classifier loss: 0.286179; batch adversarial loss: 0.531274\n",
      "epoch 134; iter: 0; batch classifier loss: 0.460922; batch adversarial loss: 0.602643\n",
      "epoch 135; iter: 0; batch classifier loss: 0.458298; batch adversarial loss: 0.565033\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368810; batch adversarial loss: 0.450789\n",
      "epoch 137; iter: 0; batch classifier loss: 0.316467; batch adversarial loss: 0.619193\n",
      "epoch 138; iter: 0; batch classifier loss: 0.459034; batch adversarial loss: 0.569663\n",
      "epoch 139; iter: 0; batch classifier loss: 0.351930; batch adversarial loss: 0.519649\n",
      "epoch 140; iter: 0; batch classifier loss: 0.394300; batch adversarial loss: 0.468853\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403704; batch adversarial loss: 0.529907\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359900; batch adversarial loss: 0.572173\n",
      "epoch 143; iter: 0; batch classifier loss: 0.410720; batch adversarial loss: 0.545224\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398605; batch adversarial loss: 0.546940\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356749; batch adversarial loss: 0.483881\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369265; batch adversarial loss: 0.464733\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349394; batch adversarial loss: 0.538859\n",
      "epoch 148; iter: 0; batch classifier loss: 0.438482; batch adversarial loss: 0.526086\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415076; batch adversarial loss: 0.527350\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364582; batch adversarial loss: 0.540571\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361793; batch adversarial loss: 0.529297\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346624; batch adversarial loss: 0.561281\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363953; batch adversarial loss: 0.552036\n",
      "epoch 154; iter: 0; batch classifier loss: 0.430907; batch adversarial loss: 0.527420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.337317; batch adversarial loss: 0.565959\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368036; batch adversarial loss: 0.532437\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403780; batch adversarial loss: 0.550690\n",
      "epoch 158; iter: 0; batch classifier loss: 0.458038; batch adversarial loss: 0.583342\n",
      "epoch 159; iter: 0; batch classifier loss: 0.330059; batch adversarial loss: 0.561469\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376166; batch adversarial loss: 0.560815\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383432; batch adversarial loss: 0.582107\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328418; batch adversarial loss: 0.523794\n",
      "epoch 163; iter: 0; batch classifier loss: 0.370984; batch adversarial loss: 0.514572\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389600; batch adversarial loss: 0.589727\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359762; batch adversarial loss: 0.609525\n",
      "epoch 166; iter: 0; batch classifier loss: 0.400569; batch adversarial loss: 0.552541\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363670; batch adversarial loss: 0.663518\n",
      "epoch 168; iter: 0; batch classifier loss: 0.360806; batch adversarial loss: 0.517553\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341339; batch adversarial loss: 0.527927\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363796; batch adversarial loss: 0.529419\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381607; batch adversarial loss: 0.543083\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330136; batch adversarial loss: 0.553957\n",
      "epoch 173; iter: 0; batch classifier loss: 0.415027; batch adversarial loss: 0.609075\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362316; batch adversarial loss: 0.449278\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326533; batch adversarial loss: 0.532793\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387105; batch adversarial loss: 0.453573\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433620; batch adversarial loss: 0.514697\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387893; batch adversarial loss: 0.534315\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399899; batch adversarial loss: 0.657568\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362473; batch adversarial loss: 0.594111\n",
      "epoch 181; iter: 0; batch classifier loss: 0.329856; batch adversarial loss: 0.637251\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370834; batch adversarial loss: 0.573981\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354445; batch adversarial loss: 0.625917\n",
      "epoch 184; iter: 0; batch classifier loss: 0.426632; batch adversarial loss: 0.573179\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387187; batch adversarial loss: 0.499938\n",
      "epoch 186; iter: 0; batch classifier loss: 0.299263; batch adversarial loss: 0.581798\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375870; batch adversarial loss: 0.526457\n",
      "epoch 188; iter: 0; batch classifier loss: 0.407720; batch adversarial loss: 0.515259\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383874; batch adversarial loss: 0.506954\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327020; batch adversarial loss: 0.515853\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389223; batch adversarial loss: 0.505546\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358975; batch adversarial loss: 0.494716\n",
      "epoch 193; iter: 0; batch classifier loss: 0.490774; batch adversarial loss: 0.655774\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344371; batch adversarial loss: 0.544963\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290811; batch adversarial loss: 0.560699\n",
      "epoch 196; iter: 0; batch classifier loss: 0.420245; batch adversarial loss: 0.468442\n",
      "epoch 197; iter: 0; batch classifier loss: 0.359264; batch adversarial loss: 0.506010\n",
      "epoch 198; iter: 0; batch classifier loss: 0.435185; batch adversarial loss: 0.523553\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396058; batch adversarial loss: 0.589074\n",
      "epoch 0; iter: 0; batch classifier loss: 0.844173; batch adversarial loss: 0.949168\n",
      "epoch 1; iter: 0; batch classifier loss: 0.855764; batch adversarial loss: 0.936333\n",
      "epoch 2; iter: 0; batch classifier loss: 0.875200; batch adversarial loss: 0.871988\n",
      "epoch 3; iter: 0; batch classifier loss: 0.913451; batch adversarial loss: 0.804403\n",
      "epoch 4; iter: 0; batch classifier loss: 0.785415; batch adversarial loss: 0.718914\n",
      "epoch 5; iter: 0; batch classifier loss: 0.748791; batch adversarial loss: 0.689239\n",
      "epoch 6; iter: 0; batch classifier loss: 0.640825; batch adversarial loss: 0.660256\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550552; batch adversarial loss: 0.625090\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514468; batch adversarial loss: 0.589765\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557482; batch adversarial loss: 0.591280\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470554; batch adversarial loss: 0.609866\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575125; batch adversarial loss: 0.597812\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571911; batch adversarial loss: 0.552040\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532536; batch adversarial loss: 0.535858\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478697; batch adversarial loss: 0.590138\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475620; batch adversarial loss: 0.604038\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470241; batch adversarial loss: 0.605426\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550488; batch adversarial loss: 0.512923\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507005; batch adversarial loss: 0.566269\n",
      "epoch 19; iter: 0; batch classifier loss: 0.540796; batch adversarial loss: 0.554679\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491770; batch adversarial loss: 0.544086\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485192; batch adversarial loss: 0.563517\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480179; batch adversarial loss: 0.544888\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487518; batch adversarial loss: 0.645089\n",
      "epoch 24; iter: 0; batch classifier loss: 0.426828; batch adversarial loss: 0.563451\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496490; batch adversarial loss: 0.523430\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484206; batch adversarial loss: 0.597008\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483092; batch adversarial loss: 0.614518\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470994; batch adversarial loss: 0.598537\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397014; batch adversarial loss: 0.539926\n",
      "epoch 30; iter: 0; batch classifier loss: 0.451406; batch adversarial loss: 0.571341\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495969; batch adversarial loss: 0.571995\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494167; batch adversarial loss: 0.605357\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440703; batch adversarial loss: 0.552219\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473653; batch adversarial loss: 0.514904\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402520; batch adversarial loss: 0.616377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445525; batch adversarial loss: 0.539570\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460439; batch adversarial loss: 0.577149\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430581; batch adversarial loss: 0.609992\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392671; batch adversarial loss: 0.685521\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437014; batch adversarial loss: 0.514373\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469922; batch adversarial loss: 0.545040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472480; batch adversarial loss: 0.491614\n",
      "epoch 43; iter: 0; batch classifier loss: 0.466868; batch adversarial loss: 0.468484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450660; batch adversarial loss: 0.542558\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472917; batch adversarial loss: 0.596899\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444512; batch adversarial loss: 0.656848\n",
      "epoch 47; iter: 0; batch classifier loss: 0.485679; batch adversarial loss: 0.548133\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453742; batch adversarial loss: 0.656963\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382878; batch adversarial loss: 0.567760\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386361; batch adversarial loss: 0.501709\n",
      "epoch 51; iter: 0; batch classifier loss: 0.410143; batch adversarial loss: 0.536024\n",
      "epoch 52; iter: 0; batch classifier loss: 0.513490; batch adversarial loss: 0.537281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.389131; batch adversarial loss: 0.564813\n",
      "epoch 54; iter: 0; batch classifier loss: 0.376181; batch adversarial loss: 0.636826\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387926; batch adversarial loss: 0.562508\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417476; batch adversarial loss: 0.582949\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392507; batch adversarial loss: 0.540468\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446236; batch adversarial loss: 0.589216\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447959; batch adversarial loss: 0.589504\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396359; batch adversarial loss: 0.446358\n",
      "epoch 61; iter: 0; batch classifier loss: 0.334884; batch adversarial loss: 0.543843\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379309; batch adversarial loss: 0.596241\n",
      "epoch 63; iter: 0; batch classifier loss: 0.356696; batch adversarial loss: 0.605694\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419494; batch adversarial loss: 0.577053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424047; batch adversarial loss: 0.551727\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419939; batch adversarial loss: 0.599954\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406506; batch adversarial loss: 0.570619\n",
      "epoch 68; iter: 0; batch classifier loss: 0.448251; batch adversarial loss: 0.614113\n",
      "epoch 69; iter: 0; batch classifier loss: 0.372799; batch adversarial loss: 0.536909\n",
      "epoch 70; iter: 0; batch classifier loss: 0.293218; batch adversarial loss: 0.471872\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396690; batch adversarial loss: 0.542644\n",
      "epoch 72; iter: 0; batch classifier loss: 0.359647; batch adversarial loss: 0.554384\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410932; batch adversarial loss: 0.555763\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378354; batch adversarial loss: 0.469770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.472916; batch adversarial loss: 0.584108\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368316; batch adversarial loss: 0.619145\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385335; batch adversarial loss: 0.584537\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382437; batch adversarial loss: 0.579602\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394545; batch adversarial loss: 0.540356\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429741; batch adversarial loss: 0.514507\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365117; batch adversarial loss: 0.524808\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406197; batch adversarial loss: 0.522573\n",
      "epoch 83; iter: 0; batch classifier loss: 0.373298; batch adversarial loss: 0.650432\n",
      "epoch 84; iter: 0; batch classifier loss: 0.425204; batch adversarial loss: 0.638445\n",
      "epoch 85; iter: 0; batch classifier loss: 0.504345; batch adversarial loss: 0.555851\n",
      "epoch 86; iter: 0; batch classifier loss: 0.489515; batch adversarial loss: 0.461518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402174; batch adversarial loss: 0.493340\n",
      "epoch 88; iter: 0; batch classifier loss: 0.281373; batch adversarial loss: 0.577938\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405023; batch adversarial loss: 0.547295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378943; batch adversarial loss: 0.501768\n",
      "epoch 91; iter: 0; batch classifier loss: 0.431580; batch adversarial loss: 0.571403\n",
      "epoch 92; iter: 0; batch classifier loss: 0.440502; batch adversarial loss: 0.492174\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379321; batch adversarial loss: 0.596916\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377139; batch adversarial loss: 0.500932\n",
      "epoch 95; iter: 0; batch classifier loss: 0.451007; batch adversarial loss: 0.518584\n",
      "epoch 96; iter: 0; batch classifier loss: 0.447927; batch adversarial loss: 0.474718\n",
      "epoch 97; iter: 0; batch classifier loss: 0.330278; batch adversarial loss: 0.527160\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384535; batch adversarial loss: 0.536992\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381214; batch adversarial loss: 0.579065\n",
      "epoch 100; iter: 0; batch classifier loss: 0.377315; batch adversarial loss: 0.606451\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420199; batch adversarial loss: 0.517774\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355047; batch adversarial loss: 0.464597\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401269; batch adversarial loss: 0.508563\n",
      "epoch 104; iter: 0; batch classifier loss: 0.437343; batch adversarial loss: 0.464819\n",
      "epoch 105; iter: 0; batch classifier loss: 0.353717; batch adversarial loss: 0.551494\n",
      "epoch 106; iter: 0; batch classifier loss: 0.405969; batch adversarial loss: 0.454330\n",
      "epoch 107; iter: 0; batch classifier loss: 0.274019; batch adversarial loss: 0.498245\n",
      "epoch 108; iter: 0; batch classifier loss: 0.322728; batch adversarial loss: 0.535233\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365404; batch adversarial loss: 0.573314\n",
      "epoch 110; iter: 0; batch classifier loss: 0.326179; batch adversarial loss: 0.491812\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368369; batch adversarial loss: 0.501510\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388622; batch adversarial loss: 0.517800\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400260; batch adversarial loss: 0.501077\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359536; batch adversarial loss: 0.571051\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328321; batch adversarial loss: 0.553755\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366298; batch adversarial loss: 0.579042\n",
      "epoch 117; iter: 0; batch classifier loss: 0.479670; batch adversarial loss: 0.544868\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354874; batch adversarial loss: 0.534574\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370505; batch adversarial loss: 0.634695\n",
      "epoch 120; iter: 0; batch classifier loss: 0.385107; batch adversarial loss: 0.625532\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375118; batch adversarial loss: 0.510391\n",
      "epoch 122; iter: 0; batch classifier loss: 0.281963; batch adversarial loss: 0.535515\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342522; batch adversarial loss: 0.554521\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369609; batch adversarial loss: 0.563015\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350149; batch adversarial loss: 0.562181\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316939; batch adversarial loss: 0.562589\n",
      "epoch 127; iter: 0; batch classifier loss: 0.328258; batch adversarial loss: 0.570219\n",
      "epoch 128; iter: 0; batch classifier loss: 0.345374; batch adversarial loss: 0.641850\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336939; batch adversarial loss: 0.543929\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353560; batch adversarial loss: 0.633442\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335910; batch adversarial loss: 0.579808\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357556; batch adversarial loss: 0.489642\n",
      "epoch 133; iter: 0; batch classifier loss: 0.430771; batch adversarial loss: 0.470974\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377869; batch adversarial loss: 0.502491\n",
      "epoch 135; iter: 0; batch classifier loss: 0.409863; batch adversarial loss: 0.580975\n",
      "epoch 136; iter: 0; batch classifier loss: 0.351607; batch adversarial loss: 0.482313\n",
      "epoch 137; iter: 0; batch classifier loss: 0.313054; batch adversarial loss: 0.510697\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364220; batch adversarial loss: 0.528073\n",
      "epoch 139; iter: 0; batch classifier loss: 0.429025; batch adversarial loss: 0.589455\n",
      "epoch 140; iter: 0; batch classifier loss: 0.382289; batch adversarial loss: 0.591026\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375031; batch adversarial loss: 0.570842\n",
      "epoch 142; iter: 0; batch classifier loss: 0.283330; batch adversarial loss: 0.596716\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380723; batch adversarial loss: 0.535402\n",
      "epoch 144; iter: 0; batch classifier loss: 0.322709; batch adversarial loss: 0.615321\n",
      "epoch 145; iter: 0; batch classifier loss: 0.314667; batch adversarial loss: 0.579130\n",
      "epoch 146; iter: 0; batch classifier loss: 0.362107; batch adversarial loss: 0.554328\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322156; batch adversarial loss: 0.525931\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341862; batch adversarial loss: 0.544722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.387881; batch adversarial loss: 0.491861\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390792; batch adversarial loss: 0.563065\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368534; batch adversarial loss: 0.554457\n",
      "epoch 152; iter: 0; batch classifier loss: 0.423527; batch adversarial loss: 0.527017\n",
      "epoch 153; iter: 0; batch classifier loss: 0.425342; batch adversarial loss: 0.561994\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365451; batch adversarial loss: 0.519000\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342341; batch adversarial loss: 0.526552\n",
      "epoch 156; iter: 0; batch classifier loss: 0.345548; batch adversarial loss: 0.571160\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346605; batch adversarial loss: 0.615767\n",
      "epoch 158; iter: 0; batch classifier loss: 0.293099; batch adversarial loss: 0.509973\n",
      "epoch 159; iter: 0; batch classifier loss: 0.406517; batch adversarial loss: 0.535695\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406182; batch adversarial loss: 0.553570\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380730; batch adversarial loss: 0.483199\n",
      "epoch 162; iter: 0; batch classifier loss: 0.407627; batch adversarial loss: 0.481923\n",
      "epoch 163; iter: 0; batch classifier loss: 0.299345; batch adversarial loss: 0.598358\n",
      "epoch 164; iter: 0; batch classifier loss: 0.297384; batch adversarial loss: 0.589560\n",
      "epoch 165; iter: 0; batch classifier loss: 0.417724; batch adversarial loss: 0.544645\n",
      "epoch 166; iter: 0; batch classifier loss: 0.352381; batch adversarial loss: 0.634291\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367273; batch adversarial loss: 0.527794\n",
      "epoch 168; iter: 0; batch classifier loss: 0.430482; batch adversarial loss: 0.509613\n",
      "epoch 169; iter: 0; batch classifier loss: 0.301553; batch adversarial loss: 0.588725\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393081; batch adversarial loss: 0.624248\n",
      "epoch 171; iter: 0; batch classifier loss: 0.365477; batch adversarial loss: 0.544939\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391490; batch adversarial loss: 0.526862\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341079; batch adversarial loss: 0.633074\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400787; batch adversarial loss: 0.650803\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351116; batch adversarial loss: 0.580383\n",
      "epoch 176; iter: 0; batch classifier loss: 0.243402; batch adversarial loss: 0.571647\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360204; batch adversarial loss: 0.549955\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387279; batch adversarial loss: 0.695344\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334399; batch adversarial loss: 0.533223\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315418; batch adversarial loss: 0.570659\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379922; batch adversarial loss: 0.541564\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376710; batch adversarial loss: 0.596130\n",
      "epoch 183; iter: 0; batch classifier loss: 0.331175; batch adversarial loss: 0.482216\n",
      "epoch 184; iter: 0; batch classifier loss: 0.288644; batch adversarial loss: 0.598122\n",
      "epoch 185; iter: 0; batch classifier loss: 0.395019; batch adversarial loss: 0.500068\n",
      "epoch 186; iter: 0; batch classifier loss: 0.299685; batch adversarial loss: 0.547917\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334729; batch adversarial loss: 0.597325\n",
      "epoch 188; iter: 0; batch classifier loss: 0.451473; batch adversarial loss: 0.598271\n",
      "epoch 189; iter: 0; batch classifier loss: 0.359596; batch adversarial loss: 0.500920\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329983; batch adversarial loss: 0.570137\n",
      "epoch 191; iter: 0; batch classifier loss: 0.451756; batch adversarial loss: 0.474512\n",
      "epoch 192; iter: 0; batch classifier loss: 0.412415; batch adversarial loss: 0.563102\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318167; batch adversarial loss: 0.553629\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368255; batch adversarial loss: 0.571882\n",
      "epoch 195; iter: 0; batch classifier loss: 0.402365; batch adversarial loss: 0.544232\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331727; batch adversarial loss: 0.589486\n",
      "epoch 197; iter: 0; batch classifier loss: 0.425042; batch adversarial loss: 0.589670\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301302; batch adversarial loss: 0.492326\n",
      "epoch 199; iter: 0; batch classifier loss: 0.294275; batch adversarial loss: 0.614970\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694669; batch adversarial loss: 0.652475\n",
      "epoch 1; iter: 0; batch classifier loss: 0.529544; batch adversarial loss: 0.611089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575202; batch adversarial loss: 0.681965\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610925; batch adversarial loss: 0.695557\n",
      "epoch 4; iter: 0; batch classifier loss: 0.563928; batch adversarial loss: 0.672541\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543668; batch adversarial loss: 0.600772\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512779; batch adversarial loss: 0.645004\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578173; batch adversarial loss: 0.636037\n",
      "epoch 8; iter: 0; batch classifier loss: 0.605705; batch adversarial loss: 0.566097\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549066; batch adversarial loss: 0.666381\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567995; batch adversarial loss: 0.589464\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505030; batch adversarial loss: 0.534999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537213; batch adversarial loss: 0.593814\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599794; batch adversarial loss: 0.591673\n",
      "epoch 14; iter: 0; batch classifier loss: 0.537435; batch adversarial loss: 0.655807\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523760; batch adversarial loss: 0.523822\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534865; batch adversarial loss: 0.505124\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528699; batch adversarial loss: 0.559393\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496150; batch adversarial loss: 0.571139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465302; batch adversarial loss: 0.611929\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479275; batch adversarial loss: 0.527141\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501582; batch adversarial loss: 0.496942\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486983; batch adversarial loss: 0.507377\n",
      "epoch 23; iter: 0; batch classifier loss: 0.563945; batch adversarial loss: 0.607509\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491339; batch adversarial loss: 0.546099\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500875; batch adversarial loss: 0.483119\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467684; batch adversarial loss: 0.537919\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447299; batch adversarial loss: 0.544293\n",
      "epoch 28; iter: 0; batch classifier loss: 0.547815; batch adversarial loss: 0.522898\n",
      "epoch 29; iter: 0; batch classifier loss: 0.539677; batch adversarial loss: 0.564524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510337; batch adversarial loss: 0.468152\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470586; batch adversarial loss: 0.580193\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483321; batch adversarial loss: 0.509308\n",
      "epoch 33; iter: 0; batch classifier loss: 0.550291; batch adversarial loss: 0.527516\n",
      "epoch 34; iter: 0; batch classifier loss: 0.386697; batch adversarial loss: 0.508946\n",
      "epoch 35; iter: 0; batch classifier loss: 0.389814; batch adversarial loss: 0.615749\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426221; batch adversarial loss: 0.490000\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402414; batch adversarial loss: 0.560482\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446057; batch adversarial loss: 0.524830\n",
      "epoch 39; iter: 0; batch classifier loss: 0.514220; batch adversarial loss: 0.548108\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422248; batch adversarial loss: 0.516745\n",
      "epoch 41; iter: 0; batch classifier loss: 0.538958; batch adversarial loss: 0.544912\n",
      "epoch 42; iter: 0; batch classifier loss: 0.488249; batch adversarial loss: 0.490497\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430952; batch adversarial loss: 0.500329\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407808; batch adversarial loss: 0.490363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.532541; batch adversarial loss: 0.572211\n",
      "epoch 46; iter: 0; batch classifier loss: 0.376791; batch adversarial loss: 0.552032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.480108; batch adversarial loss: 0.555200\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469017; batch adversarial loss: 0.583637\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389306; batch adversarial loss: 0.627320\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431895; batch adversarial loss: 0.500111\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455862; batch adversarial loss: 0.535046\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431810; batch adversarial loss: 0.545635\n",
      "epoch 53; iter: 0; batch classifier loss: 0.477731; batch adversarial loss: 0.536774\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448335; batch adversarial loss: 0.518909\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390464; batch adversarial loss: 0.553142\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377111; batch adversarial loss: 0.477501\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427127; batch adversarial loss: 0.535067\n",
      "epoch 58; iter: 0; batch classifier loss: 0.499159; batch adversarial loss: 0.472403\n",
      "epoch 59; iter: 0; batch classifier loss: 0.492381; batch adversarial loss: 0.405349\n",
      "epoch 60; iter: 0; batch classifier loss: 0.424057; batch adversarial loss: 0.525777\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402391; batch adversarial loss: 0.608324\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406629; batch adversarial loss: 0.497726\n",
      "epoch 63; iter: 0; batch classifier loss: 0.375699; batch adversarial loss: 0.525530\n",
      "epoch 64; iter: 0; batch classifier loss: 0.561327; batch adversarial loss: 0.553848\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381495; batch adversarial loss: 0.555272\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380160; batch adversarial loss: 0.478224\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399004; batch adversarial loss: 0.497450\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399995; batch adversarial loss: 0.526607\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433713; batch adversarial loss: 0.552613\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409505; batch adversarial loss: 0.554750\n",
      "epoch 71; iter: 0; batch classifier loss: 0.440362; batch adversarial loss: 0.505565\n",
      "epoch 72; iter: 0; batch classifier loss: 0.447934; batch adversarial loss: 0.546093\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378880; batch adversarial loss: 0.496586\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405227; batch adversarial loss: 0.647157\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421127; batch adversarial loss: 0.517031\n",
      "epoch 76; iter: 0; batch classifier loss: 0.341038; batch adversarial loss: 0.516385\n",
      "epoch 77; iter: 0; batch classifier loss: 0.522695; batch adversarial loss: 0.665367\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373299; batch adversarial loss: 0.478718\n",
      "epoch 79; iter: 0; batch classifier loss: 0.450952; batch adversarial loss: 0.674155\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470196; batch adversarial loss: 0.600742\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445848; batch adversarial loss: 0.581369\n",
      "epoch 82; iter: 0; batch classifier loss: 0.519681; batch adversarial loss: 0.610611\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405156; batch adversarial loss: 0.572115\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419622; batch adversarial loss: 0.589419\n",
      "epoch 85; iter: 0; batch classifier loss: 0.386237; batch adversarial loss: 0.488571\n",
      "epoch 86; iter: 0; batch classifier loss: 0.429575; batch adversarial loss: 0.561650\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404483; batch adversarial loss: 0.534497\n",
      "epoch 88; iter: 0; batch classifier loss: 0.404138; batch adversarial loss: 0.564239\n",
      "epoch 89; iter: 0; batch classifier loss: 0.359309; batch adversarial loss: 0.581584\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394478; batch adversarial loss: 0.534791\n",
      "epoch 91; iter: 0; batch classifier loss: 0.450877; batch adversarial loss: 0.515645\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382683; batch adversarial loss: 0.646171\n",
      "epoch 93; iter: 0; batch classifier loss: 0.307053; batch adversarial loss: 0.546275\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424223; batch adversarial loss: 0.591353\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440710; batch adversarial loss: 0.543318\n",
      "epoch 96; iter: 0; batch classifier loss: 0.352753; batch adversarial loss: 0.507752\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388954; batch adversarial loss: 0.552612\n",
      "epoch 98; iter: 0; batch classifier loss: 0.427539; batch adversarial loss: 0.532647\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412144; batch adversarial loss: 0.477837\n",
      "epoch 100; iter: 0; batch classifier loss: 0.335020; batch adversarial loss: 0.517064\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379583; batch adversarial loss: 0.618145\n",
      "epoch 102; iter: 0; batch classifier loss: 0.364568; batch adversarial loss: 0.497003\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372047; batch adversarial loss: 0.581743\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390506; batch adversarial loss: 0.581810\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416744; batch adversarial loss: 0.543730\n",
      "epoch 106; iter: 0; batch classifier loss: 0.474118; batch adversarial loss: 0.591050\n",
      "epoch 107; iter: 0; batch classifier loss: 0.469528; batch adversarial loss: 0.525913\n",
      "epoch 108; iter: 0; batch classifier loss: 0.326510; batch adversarial loss: 0.590153\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413914; batch adversarial loss: 0.451247\n",
      "epoch 110; iter: 0; batch classifier loss: 0.439094; batch adversarial loss: 0.535239\n",
      "epoch 111; iter: 0; batch classifier loss: 0.343322; batch adversarial loss: 0.516373\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370230; batch adversarial loss: 0.544299\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357960; batch adversarial loss: 0.580867\n",
      "epoch 114; iter: 0; batch classifier loss: 0.451534; batch adversarial loss: 0.562649\n",
      "epoch 115; iter: 0; batch classifier loss: 0.315974; batch adversarial loss: 0.572946\n",
      "epoch 116; iter: 0; batch classifier loss: 0.433287; batch adversarial loss: 0.545675\n",
      "epoch 117; iter: 0; batch classifier loss: 0.316460; batch adversarial loss: 0.525087\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402491; batch adversarial loss: 0.562004\n",
      "epoch 119; iter: 0; batch classifier loss: 0.438737; batch adversarial loss: 0.469571\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407047; batch adversarial loss: 0.525447\n",
      "epoch 121; iter: 0; batch classifier loss: 0.446509; batch adversarial loss: 0.590299\n",
      "epoch 122; iter: 0; batch classifier loss: 0.320244; batch adversarial loss: 0.477084\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367606; batch adversarial loss: 0.554280\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397182; batch adversarial loss: 0.496718\n",
      "epoch 125; iter: 0; batch classifier loss: 0.297901; batch adversarial loss: 0.573933\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387621; batch adversarial loss: 0.489214\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367795; batch adversarial loss: 0.617003\n",
      "epoch 128; iter: 0; batch classifier loss: 0.451636; batch adversarial loss: 0.535607\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389209; batch adversarial loss: 0.471850\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402078; batch adversarial loss: 0.425208\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363760; batch adversarial loss: 0.490605\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352271; batch adversarial loss: 0.534786\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395196; batch adversarial loss: 0.571973\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400074; batch adversarial loss: 0.638346\n",
      "epoch 135; iter: 0; batch classifier loss: 0.309057; batch adversarial loss: 0.599654\n",
      "epoch 136; iter: 0; batch classifier loss: 0.398945; batch adversarial loss: 0.543796\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401072; batch adversarial loss: 0.527101\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356234; batch adversarial loss: 0.552062\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389408; batch adversarial loss: 0.589324\n",
      "epoch 140; iter: 0; batch classifier loss: 0.407784; batch adversarial loss: 0.525864\n",
      "epoch 141; iter: 0; batch classifier loss: 0.489939; batch adversarial loss: 0.506377\n",
      "epoch 142; iter: 0; batch classifier loss: 0.437687; batch adversarial loss: 0.507053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.356128; batch adversarial loss: 0.479660\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437410; batch adversarial loss: 0.553594\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382851; batch adversarial loss: 0.526095\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381718; batch adversarial loss: 0.516554\n",
      "epoch 147; iter: 0; batch classifier loss: 0.424115; batch adversarial loss: 0.533734\n",
      "epoch 148; iter: 0; batch classifier loss: 0.372458; batch adversarial loss: 0.505798\n",
      "epoch 149; iter: 0; batch classifier loss: 0.364877; batch adversarial loss: 0.573133\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372341; batch adversarial loss: 0.536260\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408628; batch adversarial loss: 0.570760\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340360; batch adversarial loss: 0.544928\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361200; batch adversarial loss: 0.527789\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363070; batch adversarial loss: 0.534441\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394355; batch adversarial loss: 0.673514\n",
      "epoch 156; iter: 0; batch classifier loss: 0.428359; batch adversarial loss: 0.534268\n",
      "epoch 157; iter: 0; batch classifier loss: 0.388899; batch adversarial loss: 0.527012\n",
      "epoch 158; iter: 0; batch classifier loss: 0.400058; batch adversarial loss: 0.498578\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393197; batch adversarial loss: 0.497704\n",
      "epoch 160; iter: 0; batch classifier loss: 0.334138; batch adversarial loss: 0.526750\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387302; batch adversarial loss: 0.562763\n",
      "epoch 162; iter: 0; batch classifier loss: 0.315512; batch adversarial loss: 0.516681\n",
      "epoch 163; iter: 0; batch classifier loss: 0.322004; batch adversarial loss: 0.646590\n",
      "epoch 164; iter: 0; batch classifier loss: 0.399045; batch adversarial loss: 0.525513\n",
      "epoch 165; iter: 0; batch classifier loss: 0.331898; batch adversarial loss: 0.525479\n",
      "epoch 166; iter: 0; batch classifier loss: 0.304455; batch adversarial loss: 0.582713\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366231; batch adversarial loss: 0.478569\n",
      "epoch 168; iter: 0; batch classifier loss: 0.448202; batch adversarial loss: 0.526410\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367062; batch adversarial loss: 0.562492\n",
      "epoch 170; iter: 0; batch classifier loss: 0.314020; batch adversarial loss: 0.589805\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317831; batch adversarial loss: 0.423288\n",
      "epoch 172; iter: 0; batch classifier loss: 0.408618; batch adversarial loss: 0.525413\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343137; batch adversarial loss: 0.477626\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348617; batch adversarial loss: 0.488772\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340080; batch adversarial loss: 0.554750\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372814; batch adversarial loss: 0.543676\n",
      "epoch 177; iter: 0; batch classifier loss: 0.281324; batch adversarial loss: 0.553106\n",
      "epoch 178; iter: 0; batch classifier loss: 0.327996; batch adversarial loss: 0.477845\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379810; batch adversarial loss: 0.573218\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323378; batch adversarial loss: 0.536316\n",
      "epoch 181; iter: 0; batch classifier loss: 0.254283; batch adversarial loss: 0.508014\n",
      "epoch 182; iter: 0; batch classifier loss: 0.468862; batch adversarial loss: 0.545276\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378809; batch adversarial loss: 0.563870\n",
      "epoch 184; iter: 0; batch classifier loss: 0.411935; batch adversarial loss: 0.574080\n",
      "epoch 185; iter: 0; batch classifier loss: 0.407011; batch adversarial loss: 0.527532\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389927; batch adversarial loss: 0.490131\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389831; batch adversarial loss: 0.563241\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336470; batch adversarial loss: 0.516495\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377968; batch adversarial loss: 0.562153\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338010; batch adversarial loss: 0.553615\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339266; batch adversarial loss: 0.460182\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371838; batch adversarial loss: 0.582343\n",
      "epoch 193; iter: 0; batch classifier loss: 0.380358; batch adversarial loss: 0.553972\n",
      "epoch 194; iter: 0; batch classifier loss: 0.389923; batch adversarial loss: 0.599280\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338771; batch adversarial loss: 0.440945\n",
      "epoch 196; iter: 0; batch classifier loss: 0.411850; batch adversarial loss: 0.564872\n",
      "epoch 197; iter: 0; batch classifier loss: 0.445280; batch adversarial loss: 0.516600\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347285; batch adversarial loss: 0.535982\n",
      "epoch 199; iter: 0; batch classifier loss: 0.429137; batch adversarial loss: 0.534469\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673269; batch adversarial loss: 0.644128\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584971; batch adversarial loss: 0.637810\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591425; batch adversarial loss: 0.649038\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567524; batch adversarial loss: 0.659343\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547410; batch adversarial loss: 0.602416\n",
      "epoch 5; iter: 0; batch classifier loss: 0.624706; batch adversarial loss: 0.577293\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522678; batch adversarial loss: 0.644637\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588901; batch adversarial loss: 0.600340\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580203; batch adversarial loss: 0.592156\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534476; batch adversarial loss: 0.571803\n",
      "epoch 10; iter: 0; batch classifier loss: 0.486722; batch adversarial loss: 0.599529\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544164; batch adversarial loss: 0.562389\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586851; batch adversarial loss: 0.598148\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518662; batch adversarial loss: 0.586409\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470485; batch adversarial loss: 0.576291\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481926; batch adversarial loss: 0.558001\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486296; batch adversarial loss: 0.612486\n",
      "epoch 17; iter: 0; batch classifier loss: 0.594931; batch adversarial loss: 0.545072\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476757; batch adversarial loss: 0.506686\n",
      "epoch 19; iter: 0; batch classifier loss: 0.566072; batch adversarial loss: 0.550125\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528650; batch adversarial loss: 0.524250\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521994; batch adversarial loss: 0.537291\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473065; batch adversarial loss: 0.523347\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515096; batch adversarial loss: 0.501981\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448554; batch adversarial loss: 0.464454\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500597; batch adversarial loss: 0.540581\n",
      "epoch 26; iter: 0; batch classifier loss: 0.576482; batch adversarial loss: 0.499551\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506354; batch adversarial loss: 0.537880\n",
      "epoch 28; iter: 0; batch classifier loss: 0.550464; batch adversarial loss: 0.503945\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458659; batch adversarial loss: 0.597964\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454379; batch adversarial loss: 0.560683\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476953; batch adversarial loss: 0.561749\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484809; batch adversarial loss: 0.685994\n",
      "epoch 33; iter: 0; batch classifier loss: 0.508159; batch adversarial loss: 0.474593\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470057; batch adversarial loss: 0.562029\n",
      "epoch 35; iter: 0; batch classifier loss: 0.505243; batch adversarial loss: 0.561863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421240; batch adversarial loss: 0.535336\n",
      "epoch 37; iter: 0; batch classifier loss: 0.453285; batch adversarial loss: 0.589197\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458678; batch adversarial loss: 0.545810\n",
      "epoch 39; iter: 0; batch classifier loss: 0.484012; batch adversarial loss: 0.597026\n",
      "epoch 40; iter: 0; batch classifier loss: 0.482117; batch adversarial loss: 0.553102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.394945; batch adversarial loss: 0.588936\n",
      "epoch 42; iter: 0; batch classifier loss: 0.366059; batch adversarial loss: 0.492114\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415693; batch adversarial loss: 0.516567\n",
      "epoch 44; iter: 0; batch classifier loss: 0.475149; batch adversarial loss: 0.553208\n",
      "epoch 45; iter: 0; batch classifier loss: 0.517062; batch adversarial loss: 0.545166\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444737; batch adversarial loss: 0.571207\n",
      "epoch 47; iter: 0; batch classifier loss: 0.529411; batch adversarial loss: 0.555723\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422910; batch adversarial loss: 0.565709\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416370; batch adversarial loss: 0.470283\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498435; batch adversarial loss: 0.515232\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432496; batch adversarial loss: 0.526776\n",
      "epoch 52; iter: 0; batch classifier loss: 0.531315; batch adversarial loss: 0.514591\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436045; batch adversarial loss: 0.525423\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424776; batch adversarial loss: 0.581350\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436948; batch adversarial loss: 0.540520\n",
      "epoch 56; iter: 0; batch classifier loss: 0.520804; batch adversarial loss: 0.531247\n",
      "epoch 57; iter: 0; batch classifier loss: 0.378853; batch adversarial loss: 0.525720\n",
      "epoch 58; iter: 0; batch classifier loss: 0.555043; batch adversarial loss: 0.585178\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476891; batch adversarial loss: 0.493712\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386288; batch adversarial loss: 0.602220\n",
      "epoch 61; iter: 0; batch classifier loss: 0.499091; batch adversarial loss: 0.557076\n",
      "epoch 62; iter: 0; batch classifier loss: 0.494557; batch adversarial loss: 0.542681\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419176; batch adversarial loss: 0.551708\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422765; batch adversarial loss: 0.549407\n",
      "epoch 65; iter: 0; batch classifier loss: 0.350525; batch adversarial loss: 0.528010\n",
      "epoch 66; iter: 0; batch classifier loss: 0.505344; batch adversarial loss: 0.612122\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421993; batch adversarial loss: 0.588998\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411282; batch adversarial loss: 0.546965\n",
      "epoch 69; iter: 0; batch classifier loss: 0.347080; batch adversarial loss: 0.477664\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438325; batch adversarial loss: 0.579349\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395150; batch adversarial loss: 0.522896\n",
      "epoch 72; iter: 0; batch classifier loss: 0.461372; batch adversarial loss: 0.547232\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355128; batch adversarial loss: 0.520858\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367225; batch adversarial loss: 0.485449\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362643; batch adversarial loss: 0.545732\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392130; batch adversarial loss: 0.517976\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374911; batch adversarial loss: 0.570537\n",
      "epoch 78; iter: 0; batch classifier loss: 0.414516; batch adversarial loss: 0.551302\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391830; batch adversarial loss: 0.534847\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358096; batch adversarial loss: 0.599129\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417327; batch adversarial loss: 0.479797\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381902; batch adversarial loss: 0.581105\n",
      "epoch 83; iter: 0; batch classifier loss: 0.474198; batch adversarial loss: 0.489300\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375073; batch adversarial loss: 0.543979\n",
      "epoch 85; iter: 0; batch classifier loss: 0.327929; batch adversarial loss: 0.543053\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430296; batch adversarial loss: 0.505624\n",
      "epoch 87; iter: 0; batch classifier loss: 0.409070; batch adversarial loss: 0.561946\n",
      "epoch 88; iter: 0; batch classifier loss: 0.459315; batch adversarial loss: 0.551784\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399719; batch adversarial loss: 0.497960\n",
      "epoch 90; iter: 0; batch classifier loss: 0.406139; batch adversarial loss: 0.561698\n",
      "epoch 91; iter: 0; batch classifier loss: 0.355727; batch adversarial loss: 0.527537\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411668; batch adversarial loss: 0.481900\n",
      "epoch 93; iter: 0; batch classifier loss: 0.322915; batch adversarial loss: 0.581390\n",
      "epoch 94; iter: 0; batch classifier loss: 0.320581; batch adversarial loss: 0.553932\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426801; batch adversarial loss: 0.515569\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394897; batch adversarial loss: 0.544265\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338626; batch adversarial loss: 0.636929\n",
      "epoch 98; iter: 0; batch classifier loss: 0.484366; batch adversarial loss: 0.541598\n",
      "epoch 99; iter: 0; batch classifier loss: 0.443203; batch adversarial loss: 0.470670\n",
      "epoch 100; iter: 0; batch classifier loss: 0.353556; batch adversarial loss: 0.542966\n",
      "epoch 101; iter: 0; batch classifier loss: 0.475107; batch adversarial loss: 0.593930\n",
      "epoch 102; iter: 0; batch classifier loss: 0.344318; batch adversarial loss: 0.560099\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413563; batch adversarial loss: 0.569284\n",
      "epoch 104; iter: 0; batch classifier loss: 0.411553; batch adversarial loss: 0.514042\n",
      "epoch 105; iter: 0; batch classifier loss: 0.437936; batch adversarial loss: 0.472372\n",
      "epoch 106; iter: 0; batch classifier loss: 0.446219; batch adversarial loss: 0.543781\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431933; batch adversarial loss: 0.606599\n",
      "epoch 108; iter: 0; batch classifier loss: 0.335966; batch adversarial loss: 0.518881\n",
      "epoch 109; iter: 0; batch classifier loss: 0.450000; batch adversarial loss: 0.460890\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339415; batch adversarial loss: 0.503485\n",
      "epoch 111; iter: 0; batch classifier loss: 0.496224; batch adversarial loss: 0.591679\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415100; batch adversarial loss: 0.539515\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380949; batch adversarial loss: 0.490238\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329163; batch adversarial loss: 0.596929\n",
      "epoch 115; iter: 0; batch classifier loss: 0.446753; batch adversarial loss: 0.545514\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412440; batch adversarial loss: 0.599000\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392473; batch adversarial loss: 0.592598\n",
      "epoch 118; iter: 0; batch classifier loss: 0.296022; batch adversarial loss: 0.496477\n",
      "epoch 119; iter: 0; batch classifier loss: 0.463658; batch adversarial loss: 0.518750\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382547; batch adversarial loss: 0.528654\n",
      "epoch 121; iter: 0; batch classifier loss: 0.302601; batch adversarial loss: 0.563880\n",
      "epoch 122; iter: 0; batch classifier loss: 0.396318; batch adversarial loss: 0.509950\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378211; batch adversarial loss: 0.536253\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372272; batch adversarial loss: 0.607672\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382179; batch adversarial loss: 0.625584\n",
      "epoch 126; iter: 0; batch classifier loss: 0.324851; batch adversarial loss: 0.543973\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371933; batch adversarial loss: 0.499082\n",
      "epoch 128; iter: 0; batch classifier loss: 0.434167; batch adversarial loss: 0.561823\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378854; batch adversarial loss: 0.470835\n",
      "epoch 130; iter: 0; batch classifier loss: 0.459887; batch adversarial loss: 0.553461\n",
      "epoch 131; iter: 0; batch classifier loss: 0.418455; batch adversarial loss: 0.571995\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327490; batch adversarial loss: 0.617122\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349019; batch adversarial loss: 0.505949\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365083; batch adversarial loss: 0.561455\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399862; batch adversarial loss: 0.488332\n",
      "epoch 136; iter: 0; batch classifier loss: 0.330947; batch adversarial loss: 0.532650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.356567; batch adversarial loss: 0.461232\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364252; batch adversarial loss: 0.521973\n",
      "epoch 139; iter: 0; batch classifier loss: 0.440823; batch adversarial loss: 0.487028\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365421; batch adversarial loss: 0.502606\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343944; batch adversarial loss: 0.520903\n",
      "epoch 142; iter: 0; batch classifier loss: 0.416276; batch adversarial loss: 0.519888\n",
      "epoch 143; iter: 0; batch classifier loss: 0.375781; batch adversarial loss: 0.516941\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327604; batch adversarial loss: 0.515670\n",
      "epoch 145; iter: 0; batch classifier loss: 0.320092; batch adversarial loss: 0.514114\n",
      "epoch 146; iter: 0; batch classifier loss: 0.370812; batch adversarial loss: 0.468329\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354005; batch adversarial loss: 0.499524\n",
      "epoch 148; iter: 0; batch classifier loss: 0.276831; batch adversarial loss: 0.558693\n",
      "epoch 149; iter: 0; batch classifier loss: 0.289943; batch adversarial loss: 0.449058\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384258; batch adversarial loss: 0.592414\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363094; batch adversarial loss: 0.548512\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375191; batch adversarial loss: 0.552187\n",
      "epoch 153; iter: 0; batch classifier loss: 0.395512; batch adversarial loss: 0.534799\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382889; batch adversarial loss: 0.546260\n",
      "epoch 155; iter: 0; batch classifier loss: 0.396671; batch adversarial loss: 0.602046\n",
      "epoch 156; iter: 0; batch classifier loss: 0.397954; batch adversarial loss: 0.583033\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341590; batch adversarial loss: 0.549620\n",
      "epoch 158; iter: 0; batch classifier loss: 0.270488; batch adversarial loss: 0.519735\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360763; batch adversarial loss: 0.527533\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404564; batch adversarial loss: 0.491074\n",
      "epoch 161; iter: 0; batch classifier loss: 0.394186; batch adversarial loss: 0.579700\n",
      "epoch 162; iter: 0; batch classifier loss: 0.467490; batch adversarial loss: 0.596681\n",
      "epoch 163; iter: 0; batch classifier loss: 0.415066; batch adversarial loss: 0.606514\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375385; batch adversarial loss: 0.508171\n",
      "epoch 165; iter: 0; batch classifier loss: 0.439677; batch adversarial loss: 0.515947\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395124; batch adversarial loss: 0.571146\n",
      "epoch 167; iter: 0; batch classifier loss: 0.330751; batch adversarial loss: 0.515729\n",
      "epoch 168; iter: 0; batch classifier loss: 0.328279; batch adversarial loss: 0.541723\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375988; batch adversarial loss: 0.561555\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367895; batch adversarial loss: 0.526768\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349441; batch adversarial loss: 0.541449\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341868; batch adversarial loss: 0.559617\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359644; batch adversarial loss: 0.563980\n",
      "epoch 174; iter: 0; batch classifier loss: 0.317262; batch adversarial loss: 0.525919\n",
      "epoch 175; iter: 0; batch classifier loss: 0.402186; batch adversarial loss: 0.530931\n",
      "epoch 176; iter: 0; batch classifier loss: 0.434771; batch adversarial loss: 0.573113\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339030; batch adversarial loss: 0.644411\n",
      "epoch 178; iter: 0; batch classifier loss: 0.356667; batch adversarial loss: 0.584394\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392690; batch adversarial loss: 0.536257\n",
      "epoch 180; iter: 0; batch classifier loss: 0.313888; batch adversarial loss: 0.586292\n",
      "epoch 181; iter: 0; batch classifier loss: 0.315514; batch adversarial loss: 0.497992\n",
      "epoch 182; iter: 0; batch classifier loss: 0.401810; batch adversarial loss: 0.564171\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358503; batch adversarial loss: 0.506203\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287700; batch adversarial loss: 0.553282\n",
      "epoch 185; iter: 0; batch classifier loss: 0.307724; batch adversarial loss: 0.601959\n",
      "epoch 186; iter: 0; batch classifier loss: 0.418059; batch adversarial loss: 0.505486\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355992; batch adversarial loss: 0.536059\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318906; batch adversarial loss: 0.582614\n",
      "epoch 189; iter: 0; batch classifier loss: 0.466513; batch adversarial loss: 0.528410\n",
      "epoch 190; iter: 0; batch classifier loss: 0.438195; batch adversarial loss: 0.569908\n",
      "epoch 191; iter: 0; batch classifier loss: 0.406112; batch adversarial loss: 0.593165\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352590; batch adversarial loss: 0.497836\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378784; batch adversarial loss: 0.536113\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338572; batch adversarial loss: 0.561353\n",
      "epoch 195; iter: 0; batch classifier loss: 0.377676; batch adversarial loss: 0.606335\n",
      "epoch 196; iter: 0; batch classifier loss: 0.299846; batch adversarial loss: 0.514325\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361747; batch adversarial loss: 0.640714\n",
      "epoch 198; iter: 0; batch classifier loss: 0.395860; batch adversarial loss: 0.579336\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388365; batch adversarial loss: 0.536634\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748818; batch adversarial loss: 1.023805\n",
      "epoch 1; iter: 0; batch classifier loss: 0.840933; batch adversarial loss: 1.116722\n",
      "epoch 2; iter: 0; batch classifier loss: 1.068149; batch adversarial loss: 1.115672\n",
      "epoch 3; iter: 0; batch classifier loss: 1.020257; batch adversarial loss: 1.010823\n",
      "epoch 4; iter: 0; batch classifier loss: 1.166106; batch adversarial loss: 0.970419\n",
      "epoch 5; iter: 0; batch classifier loss: 1.148487; batch adversarial loss: 0.886572\n",
      "epoch 6; iter: 0; batch classifier loss: 1.051394; batch adversarial loss: 0.813190\n",
      "epoch 7; iter: 0; batch classifier loss: 0.859900; batch adversarial loss: 0.748243\n",
      "epoch 8; iter: 0; batch classifier loss: 0.811505; batch adversarial loss: 0.650910\n",
      "epoch 9; iter: 0; batch classifier loss: 0.706239; batch adversarial loss: 0.615571\n",
      "epoch 10; iter: 0; batch classifier loss: 0.626098; batch adversarial loss: 0.622688\n",
      "epoch 11; iter: 0; batch classifier loss: 0.583893; batch adversarial loss: 0.661624\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544320; batch adversarial loss: 0.571620\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479663; batch adversarial loss: 0.561250\n",
      "epoch 14; iter: 0; batch classifier loss: 0.490188; batch adversarial loss: 0.582819\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523095; batch adversarial loss: 0.597375\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512627; batch adversarial loss: 0.585908\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477919; batch adversarial loss: 0.670626\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493927; batch adversarial loss: 0.640876\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524580; batch adversarial loss: 0.569293\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543367; batch adversarial loss: 0.552538\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542317; batch adversarial loss: 0.550133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482300; batch adversarial loss: 0.496876\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485644; batch adversarial loss: 0.558461\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464016; batch adversarial loss: 0.549125\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449842; batch adversarial loss: 0.525694\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477475; batch adversarial loss: 0.543880\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458463; batch adversarial loss: 0.528319\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457484; batch adversarial loss: 0.557834\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450196; batch adversarial loss: 0.607720\n",
      "epoch 30; iter: 0; batch classifier loss: 0.364971; batch adversarial loss: 0.606112\n",
      "epoch 31; iter: 0; batch classifier loss: 0.393937; batch adversarial loss: 0.527338\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482361; batch adversarial loss: 0.531307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.434356; batch adversarial loss: 0.573797\n",
      "epoch 34; iter: 0; batch classifier loss: 0.428707; batch adversarial loss: 0.532905\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433170; batch adversarial loss: 0.534625\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456149; batch adversarial loss: 0.567339\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406405; batch adversarial loss: 0.595866\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441367; batch adversarial loss: 0.576320\n",
      "epoch 39; iter: 0; batch classifier loss: 0.514573; batch adversarial loss: 0.593701\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399323; batch adversarial loss: 0.566575\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431796; batch adversarial loss: 0.586192\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472757; batch adversarial loss: 0.484513\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477427; batch adversarial loss: 0.492523\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412392; batch adversarial loss: 0.555151\n",
      "epoch 45; iter: 0; batch classifier loss: 0.396635; batch adversarial loss: 0.625005\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401761; batch adversarial loss: 0.528485\n",
      "epoch 47; iter: 0; batch classifier loss: 0.470863; batch adversarial loss: 0.566877\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428639; batch adversarial loss: 0.564851\n",
      "epoch 49; iter: 0; batch classifier loss: 0.492714; batch adversarial loss: 0.541007\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423673; batch adversarial loss: 0.571912\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436572; batch adversarial loss: 0.535081\n",
      "epoch 52; iter: 0; batch classifier loss: 0.353384; batch adversarial loss: 0.539893\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438308; batch adversarial loss: 0.539547\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418924; batch adversarial loss: 0.526968\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448246; batch adversarial loss: 0.581377\n",
      "epoch 56; iter: 0; batch classifier loss: 0.422248; batch adversarial loss: 0.509152\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446815; batch adversarial loss: 0.463529\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448356; batch adversarial loss: 0.590114\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388927; batch adversarial loss: 0.625263\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382440; batch adversarial loss: 0.544842\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436648; batch adversarial loss: 0.580815\n",
      "epoch 62; iter: 0; batch classifier loss: 0.350783; batch adversarial loss: 0.589800\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417069; batch adversarial loss: 0.553494\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414360; batch adversarial loss: 0.589463\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382634; batch adversarial loss: 0.579873\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435714; batch adversarial loss: 0.597983\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399208; batch adversarial loss: 0.626291\n",
      "epoch 68; iter: 0; batch classifier loss: 0.507834; batch adversarial loss: 0.554105\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384344; batch adversarial loss: 0.535623\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358084; batch adversarial loss: 0.536229\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436705; batch adversarial loss: 0.590310\n",
      "epoch 72; iter: 0; batch classifier loss: 0.323575; batch adversarial loss: 0.599661\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366330; batch adversarial loss: 0.507069\n",
      "epoch 74; iter: 0; batch classifier loss: 0.353705; batch adversarial loss: 0.642905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.374942; batch adversarial loss: 0.589499\n",
      "epoch 76; iter: 0; batch classifier loss: 0.417117; batch adversarial loss: 0.533975\n",
      "epoch 77; iter: 0; batch classifier loss: 0.312586; batch adversarial loss: 0.587168\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404355; batch adversarial loss: 0.534499\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353793; batch adversarial loss: 0.489013\n",
      "epoch 80; iter: 0; batch classifier loss: 0.354155; batch adversarial loss: 0.478507\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398866; batch adversarial loss: 0.470251\n",
      "epoch 82; iter: 0; batch classifier loss: 0.417331; batch adversarial loss: 0.551307\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370786; batch adversarial loss: 0.553955\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370058; batch adversarial loss: 0.552459\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413048; batch adversarial loss: 0.526730\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426388; batch adversarial loss: 0.527313\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395896; batch adversarial loss: 0.628351\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396358; batch adversarial loss: 0.528059\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413430; batch adversarial loss: 0.580664\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386680; batch adversarial loss: 0.472297\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358027; batch adversarial loss: 0.553323\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385277; batch adversarial loss: 0.560066\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367090; batch adversarial loss: 0.536396\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404168; batch adversarial loss: 0.545410\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442571; batch adversarial loss: 0.541959\n",
      "epoch 96; iter: 0; batch classifier loss: 0.334422; batch adversarial loss: 0.569516\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360319; batch adversarial loss: 0.608538\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411789; batch adversarial loss: 0.523479\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378482; batch adversarial loss: 0.577994\n",
      "epoch 100; iter: 0; batch classifier loss: 0.359944; batch adversarial loss: 0.568354\n",
      "epoch 101; iter: 0; batch classifier loss: 0.334476; batch adversarial loss: 0.518163\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340404; batch adversarial loss: 0.541074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.324416; batch adversarial loss: 0.507049\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375932; batch adversarial loss: 0.525936\n",
      "epoch 105; iter: 0; batch classifier loss: 0.303276; batch adversarial loss: 0.525818\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391814; batch adversarial loss: 0.496328\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431001; batch adversarial loss: 0.570263\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355547; batch adversarial loss: 0.509707\n",
      "epoch 109; iter: 0; batch classifier loss: 0.461654; batch adversarial loss: 0.525479\n",
      "epoch 110; iter: 0; batch classifier loss: 0.483774; batch adversarial loss: 0.516500\n",
      "epoch 111; iter: 0; batch classifier loss: 0.307848; batch adversarial loss: 0.522917\n",
      "epoch 112; iter: 0; batch classifier loss: 0.350158; batch adversarial loss: 0.527281\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351044; batch adversarial loss: 0.516562\n",
      "epoch 114; iter: 0; batch classifier loss: 0.409965; batch adversarial loss: 0.579271\n",
      "epoch 115; iter: 0; batch classifier loss: 0.317039; batch adversarial loss: 0.557244\n",
      "epoch 116; iter: 0; batch classifier loss: 0.275880; batch adversarial loss: 0.570533\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390963; batch adversarial loss: 0.490700\n",
      "epoch 118; iter: 0; batch classifier loss: 0.322601; batch adversarial loss: 0.580735\n",
      "epoch 119; iter: 0; batch classifier loss: 0.358751; batch adversarial loss: 0.498433\n",
      "epoch 120; iter: 0; batch classifier loss: 0.332387; batch adversarial loss: 0.551025\n",
      "epoch 121; iter: 0; batch classifier loss: 0.317891; batch adversarial loss: 0.508249\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389961; batch adversarial loss: 0.499555\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331666; batch adversarial loss: 0.545726\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347403; batch adversarial loss: 0.544095\n",
      "epoch 125; iter: 0; batch classifier loss: 0.405569; batch adversarial loss: 0.531811\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350040; batch adversarial loss: 0.546067\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333947; batch adversarial loss: 0.520029\n",
      "epoch 128; iter: 0; batch classifier loss: 0.331851; batch adversarial loss: 0.563968\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340045; batch adversarial loss: 0.510529\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391448; batch adversarial loss: 0.544371\n",
      "epoch 131; iter: 0; batch classifier loss: 0.446397; batch adversarial loss: 0.593099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.311023; batch adversarial loss: 0.578485\n",
      "epoch 133; iter: 0; batch classifier loss: 0.420521; batch adversarial loss: 0.497250\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355737; batch adversarial loss: 0.571020\n",
      "epoch 135; iter: 0; batch classifier loss: 0.344941; batch adversarial loss: 0.557030\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371285; batch adversarial loss: 0.463430\n",
      "epoch 137; iter: 0; batch classifier loss: 0.433524; batch adversarial loss: 0.521760\n",
      "epoch 138; iter: 0; batch classifier loss: 0.278351; batch adversarial loss: 0.535476\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346825; batch adversarial loss: 0.543687\n",
      "epoch 140; iter: 0; batch classifier loss: 0.314058; batch adversarial loss: 0.497570\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368936; batch adversarial loss: 0.580347\n",
      "epoch 142; iter: 0; batch classifier loss: 0.284297; batch adversarial loss: 0.501106\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371757; batch adversarial loss: 0.473277\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358542; batch adversarial loss: 0.517141\n",
      "epoch 145; iter: 0; batch classifier loss: 0.325034; batch adversarial loss: 0.637155\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381761; batch adversarial loss: 0.675256\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329997; batch adversarial loss: 0.473164\n",
      "epoch 148; iter: 0; batch classifier loss: 0.348102; batch adversarial loss: 0.552938\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362409; batch adversarial loss: 0.526897\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409386; batch adversarial loss: 0.577224\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352344; batch adversarial loss: 0.581253\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395333; batch adversarial loss: 0.546097\n",
      "epoch 153; iter: 0; batch classifier loss: 0.297738; batch adversarial loss: 0.591929\n",
      "epoch 154; iter: 0; batch classifier loss: 0.322043; batch adversarial loss: 0.493303\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343380; batch adversarial loss: 0.514325\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346038; batch adversarial loss: 0.607963\n",
      "epoch 157; iter: 0; batch classifier loss: 0.292195; batch adversarial loss: 0.507067\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347889; batch adversarial loss: 0.628110\n",
      "epoch 159; iter: 0; batch classifier loss: 0.281664; batch adversarial loss: 0.554376\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333357; batch adversarial loss: 0.528320\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337572; batch adversarial loss: 0.556828\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387825; batch adversarial loss: 0.507204\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336858; batch adversarial loss: 0.509209\n",
      "epoch 164; iter: 0; batch classifier loss: 0.292230; batch adversarial loss: 0.581476\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339768; batch adversarial loss: 0.737842\n",
      "epoch 166; iter: 0; batch classifier loss: 0.397282; batch adversarial loss: 0.461677\n",
      "epoch 167; iter: 0; batch classifier loss: 0.308127; batch adversarial loss: 0.642869\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320594; batch adversarial loss: 0.577742\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337927; batch adversarial loss: 0.497634\n",
      "epoch 170; iter: 0; batch classifier loss: 0.312431; batch adversarial loss: 0.461920\n",
      "epoch 171; iter: 0; batch classifier loss: 0.306566; batch adversarial loss: 0.609484\n",
      "epoch 172; iter: 0; batch classifier loss: 0.302828; batch adversarial loss: 0.653330\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369884; batch adversarial loss: 0.545788\n",
      "epoch 174; iter: 0; batch classifier loss: 0.323626; batch adversarial loss: 0.590129\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357787; batch adversarial loss: 0.558319\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376875; batch adversarial loss: 0.516333\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358004; batch adversarial loss: 0.551865\n",
      "epoch 178; iter: 0; batch classifier loss: 0.298818; batch adversarial loss: 0.498796\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343860; batch adversarial loss: 0.599139\n",
      "epoch 180; iter: 0; batch classifier loss: 0.258226; batch adversarial loss: 0.490431\n",
      "epoch 181; iter: 0; batch classifier loss: 0.348634; batch adversarial loss: 0.497604\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376649; batch adversarial loss: 0.572280\n",
      "epoch 183; iter: 0; batch classifier loss: 0.299574; batch adversarial loss: 0.546293\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362686; batch adversarial loss: 0.562152\n",
      "epoch 185; iter: 0; batch classifier loss: 0.299565; batch adversarial loss: 0.542888\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407139; batch adversarial loss: 0.553804\n",
      "epoch 187; iter: 0; batch classifier loss: 0.297550; batch adversarial loss: 0.518639\n",
      "epoch 188; iter: 0; batch classifier loss: 0.344072; batch adversarial loss: 0.537089\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357076; batch adversarial loss: 0.582274\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359599; batch adversarial loss: 0.497950\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360825; batch adversarial loss: 0.644764\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338785; batch adversarial loss: 0.541965\n",
      "epoch 193; iter: 0; batch classifier loss: 0.305121; batch adversarial loss: 0.599930\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322896; batch adversarial loss: 0.609818\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354639; batch adversarial loss: 0.524535\n",
      "epoch 196; iter: 0; batch classifier loss: 0.298420; batch adversarial loss: 0.554744\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365995; batch adversarial loss: 0.469404\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360858; batch adversarial loss: 0.551694\n",
      "epoch 199; iter: 0; batch classifier loss: 0.300558; batch adversarial loss: 0.581384\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729563; batch adversarial loss: 0.565051\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643455; batch adversarial loss: 0.655374\n",
      "epoch 2; iter: 0; batch classifier loss: 0.598655; batch adversarial loss: 0.646333\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557141; batch adversarial loss: 0.652303\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589299; batch adversarial loss: 0.627512\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598348; batch adversarial loss: 0.623239\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607523; batch adversarial loss: 0.643229\n",
      "epoch 7; iter: 0; batch classifier loss: 0.639884; batch adversarial loss: 0.574635\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521335; batch adversarial loss: 0.605806\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532064; batch adversarial loss: 0.603340\n",
      "epoch 10; iter: 0; batch classifier loss: 0.473416; batch adversarial loss: 0.605006\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607983; batch adversarial loss: 0.599811\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480887; batch adversarial loss: 0.600472\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546854; batch adversarial loss: 0.609853\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532987; batch adversarial loss: 0.626288\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491606; batch adversarial loss: 0.577021\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514628; batch adversarial loss: 0.487221\n",
      "epoch 17; iter: 0; batch classifier loss: 0.416932; batch adversarial loss: 0.510977\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539960; batch adversarial loss: 0.507689\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483656; batch adversarial loss: 0.597696\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454923; batch adversarial loss: 0.490417\n",
      "epoch 21; iter: 0; batch classifier loss: 0.423780; batch adversarial loss: 0.614454\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466947; batch adversarial loss: 0.561948\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476947; batch adversarial loss: 0.572329\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457708; batch adversarial loss: 0.564012\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456625; batch adversarial loss: 0.494560\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505667; batch adversarial loss: 0.578409\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437737; batch adversarial loss: 0.496564\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439774; batch adversarial loss: 0.561068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.426873; batch adversarial loss: 0.567703\n",
      "epoch 30; iter: 0; batch classifier loss: 0.426162; batch adversarial loss: 0.600555\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466807; batch adversarial loss: 0.566501\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498048; batch adversarial loss: 0.565023\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434975; batch adversarial loss: 0.532261\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419174; batch adversarial loss: 0.574351\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440089; batch adversarial loss: 0.582953\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405590; batch adversarial loss: 0.516989\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466130; batch adversarial loss: 0.582007\n",
      "epoch 38; iter: 0; batch classifier loss: 0.532279; batch adversarial loss: 0.547896\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458956; batch adversarial loss: 0.484957\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454914; batch adversarial loss: 0.533591\n",
      "epoch 41; iter: 0; batch classifier loss: 0.509142; batch adversarial loss: 0.539908\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445176; batch adversarial loss: 0.598455\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415188; batch adversarial loss: 0.523680\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406933; batch adversarial loss: 0.626786\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376781; batch adversarial loss: 0.570121\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401651; batch adversarial loss: 0.571231\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411188; batch adversarial loss: 0.564900\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421616; batch adversarial loss: 0.512043\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415767; batch adversarial loss: 0.587444\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455704; batch adversarial loss: 0.599240\n",
      "epoch 51; iter: 0; batch classifier loss: 0.478475; batch adversarial loss: 0.509088\n",
      "epoch 52; iter: 0; batch classifier loss: 0.338675; batch adversarial loss: 0.623866\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405055; batch adversarial loss: 0.498210\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469356; batch adversarial loss: 0.579751\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410461; batch adversarial loss: 0.583980\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440892; batch adversarial loss: 0.508786\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421716; batch adversarial loss: 0.508149\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404156; batch adversarial loss: 0.513987\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445903; batch adversarial loss: 0.573062\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435914; batch adversarial loss: 0.586374\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373683; batch adversarial loss: 0.517089\n",
      "epoch 62; iter: 0; batch classifier loss: 0.411972; batch adversarial loss: 0.553106\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420001; batch adversarial loss: 0.519312\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436619; batch adversarial loss: 0.537326\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410179; batch adversarial loss: 0.527885\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416604; batch adversarial loss: 0.427200\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431565; batch adversarial loss: 0.578125\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411141; batch adversarial loss: 0.522114\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432930; batch adversarial loss: 0.580730\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415601; batch adversarial loss: 0.605199\n",
      "epoch 71; iter: 0; batch classifier loss: 0.382166; batch adversarial loss: 0.607838\n",
      "epoch 72; iter: 0; batch classifier loss: 0.359892; batch adversarial loss: 0.557930\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395977; batch adversarial loss: 0.526851\n",
      "epoch 74; iter: 0; batch classifier loss: 0.429154; batch adversarial loss: 0.588735\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362469; batch adversarial loss: 0.588338\n",
      "epoch 76; iter: 0; batch classifier loss: 0.500413; batch adversarial loss: 0.492918\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351807; batch adversarial loss: 0.507901\n",
      "epoch 78; iter: 0; batch classifier loss: 0.458676; batch adversarial loss: 0.552425\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367815; batch adversarial loss: 0.552056\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422340; batch adversarial loss: 0.565577\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387386; batch adversarial loss: 0.515184\n",
      "epoch 82; iter: 0; batch classifier loss: 0.441742; batch adversarial loss: 0.511829\n",
      "epoch 83; iter: 0; batch classifier loss: 0.450577; batch adversarial loss: 0.567963\n",
      "epoch 84; iter: 0; batch classifier loss: 0.434433; batch adversarial loss: 0.589244\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396398; batch adversarial loss: 0.625467\n",
      "epoch 86; iter: 0; batch classifier loss: 0.361934; batch adversarial loss: 0.585238\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396523; batch adversarial loss: 0.634506\n",
      "epoch 88; iter: 0; batch classifier loss: 0.430177; batch adversarial loss: 0.580892\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373593; batch adversarial loss: 0.509383\n",
      "epoch 90; iter: 0; batch classifier loss: 0.385996; batch adversarial loss: 0.590830\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384067; batch adversarial loss: 0.496379\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365226; batch adversarial loss: 0.599789\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384155; batch adversarial loss: 0.528245\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303374; batch adversarial loss: 0.582922\n",
      "epoch 95; iter: 0; batch classifier loss: 0.298595; batch adversarial loss: 0.649812\n",
      "epoch 96; iter: 0; batch classifier loss: 0.497821; batch adversarial loss: 0.574847\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363919; batch adversarial loss: 0.588341\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401562; batch adversarial loss: 0.546210\n",
      "epoch 99; iter: 0; batch classifier loss: 0.487915; batch adversarial loss: 0.573495\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370031; batch adversarial loss: 0.597493\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395636; batch adversarial loss: 0.516584\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416749; batch adversarial loss: 0.594223\n",
      "epoch 103; iter: 0; batch classifier loss: 0.453157; batch adversarial loss: 0.547047\n",
      "epoch 104; iter: 0; batch classifier loss: 0.337633; batch adversarial loss: 0.574278\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382168; batch adversarial loss: 0.517574\n",
      "epoch 106; iter: 0; batch classifier loss: 0.284004; batch adversarial loss: 0.542434\n",
      "epoch 107; iter: 0; batch classifier loss: 0.446914; batch adversarial loss: 0.556617\n",
      "epoch 108; iter: 0; batch classifier loss: 0.416670; batch adversarial loss: 0.589947\n",
      "epoch 109; iter: 0; batch classifier loss: 0.343416; batch adversarial loss: 0.570573\n",
      "epoch 110; iter: 0; batch classifier loss: 0.422304; batch adversarial loss: 0.550340\n",
      "epoch 111; iter: 0; batch classifier loss: 0.360280; batch adversarial loss: 0.527184\n",
      "epoch 112; iter: 0; batch classifier loss: 0.455173; batch adversarial loss: 0.612814\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354055; batch adversarial loss: 0.553118\n",
      "epoch 114; iter: 0; batch classifier loss: 0.437123; batch adversarial loss: 0.507744\n",
      "epoch 115; iter: 0; batch classifier loss: 0.406816; batch adversarial loss: 0.560996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348268; batch adversarial loss: 0.579666\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370949; batch adversarial loss: 0.527878\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405427; batch adversarial loss: 0.561088\n",
      "epoch 119; iter: 0; batch classifier loss: 0.393592; batch adversarial loss: 0.644646\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386159; batch adversarial loss: 0.505002\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345020; batch adversarial loss: 0.562986\n",
      "epoch 122; iter: 0; batch classifier loss: 0.336417; batch adversarial loss: 0.558992\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396327; batch adversarial loss: 0.586584\n",
      "epoch 124; iter: 0; batch classifier loss: 0.441824; batch adversarial loss: 0.532503\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355636; batch adversarial loss: 0.623056\n",
      "epoch 126; iter: 0; batch classifier loss: 0.319508; batch adversarial loss: 0.510745\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333701; batch adversarial loss: 0.515962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.355320; batch adversarial loss: 0.531332\n",
      "epoch 129; iter: 0; batch classifier loss: 0.418055; batch adversarial loss: 0.482178\n",
      "epoch 130; iter: 0; batch classifier loss: 0.416550; batch adversarial loss: 0.508385\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367290; batch adversarial loss: 0.505549\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354048; batch adversarial loss: 0.516946\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349432; batch adversarial loss: 0.516747\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366469; batch adversarial loss: 0.565527\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385627; batch adversarial loss: 0.524027\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389805; batch adversarial loss: 0.573918\n",
      "epoch 137; iter: 0; batch classifier loss: 0.365087; batch adversarial loss: 0.536487\n",
      "epoch 138; iter: 0; batch classifier loss: 0.372847; batch adversarial loss: 0.533260\n",
      "epoch 139; iter: 0; batch classifier loss: 0.314263; batch adversarial loss: 0.552994\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364927; batch adversarial loss: 0.688355\n",
      "epoch 141; iter: 0; batch classifier loss: 0.464149; batch adversarial loss: 0.529028\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318335; batch adversarial loss: 0.501151\n",
      "epoch 143; iter: 0; batch classifier loss: 0.295330; batch adversarial loss: 0.582005\n",
      "epoch 144; iter: 0; batch classifier loss: 0.330016; batch adversarial loss: 0.533527\n",
      "epoch 145; iter: 0; batch classifier loss: 0.396791; batch adversarial loss: 0.570904\n",
      "epoch 146; iter: 0; batch classifier loss: 0.394109; batch adversarial loss: 0.541056\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354748; batch adversarial loss: 0.534646\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331393; batch adversarial loss: 0.581806\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339106; batch adversarial loss: 0.570269\n",
      "epoch 150; iter: 0; batch classifier loss: 0.322817; batch adversarial loss: 0.594304\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351309; batch adversarial loss: 0.514018\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394599; batch adversarial loss: 0.527330\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367464; batch adversarial loss: 0.562780\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356194; batch adversarial loss: 0.517848\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383857; batch adversarial loss: 0.516158\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328942; batch adversarial loss: 0.533916\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362708; batch adversarial loss: 0.481639\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383115; batch adversarial loss: 0.597193\n",
      "epoch 159; iter: 0; batch classifier loss: 0.298398; batch adversarial loss: 0.498258\n",
      "epoch 160; iter: 0; batch classifier loss: 0.367967; batch adversarial loss: 0.553990\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311642; batch adversarial loss: 0.594932\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394655; batch adversarial loss: 0.497154\n",
      "epoch 163; iter: 0; batch classifier loss: 0.322590; batch adversarial loss: 0.573160\n",
      "epoch 164; iter: 0; batch classifier loss: 0.338292; batch adversarial loss: 0.545875\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366278; batch adversarial loss: 0.552163\n",
      "epoch 166; iter: 0; batch classifier loss: 0.295794; batch adversarial loss: 0.660645\n",
      "epoch 167; iter: 0; batch classifier loss: 0.432126; batch adversarial loss: 0.595929\n",
      "epoch 168; iter: 0; batch classifier loss: 0.400101; batch adversarial loss: 0.514677\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385692; batch adversarial loss: 0.598290\n",
      "epoch 170; iter: 0; batch classifier loss: 0.334485; batch adversarial loss: 0.588123\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363646; batch adversarial loss: 0.564661\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318000; batch adversarial loss: 0.563409\n",
      "epoch 173; iter: 0; batch classifier loss: 0.352793; batch adversarial loss: 0.511470\n",
      "epoch 174; iter: 0; batch classifier loss: 0.319982; batch adversarial loss: 0.580797\n",
      "epoch 175; iter: 0; batch classifier loss: 0.411259; batch adversarial loss: 0.536482\n",
      "epoch 176; iter: 0; batch classifier loss: 0.430892; batch adversarial loss: 0.520285\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433638; batch adversarial loss: 0.585617\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358089; batch adversarial loss: 0.522624\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303980; batch adversarial loss: 0.599133\n",
      "epoch 180; iter: 0; batch classifier loss: 0.309129; batch adversarial loss: 0.498863\n",
      "epoch 181; iter: 0; batch classifier loss: 0.430226; batch adversarial loss: 0.508705\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346191; batch adversarial loss: 0.536842\n",
      "epoch 183; iter: 0; batch classifier loss: 0.383510; batch adversarial loss: 0.575535\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319710; batch adversarial loss: 0.505042\n",
      "epoch 185; iter: 0; batch classifier loss: 0.273547; batch adversarial loss: 0.579705\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367486; batch adversarial loss: 0.533817\n",
      "epoch 187; iter: 0; batch classifier loss: 0.305421; batch adversarial loss: 0.616037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.295449; batch adversarial loss: 0.542429\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369523; batch adversarial loss: 0.586481\n",
      "epoch 190; iter: 0; batch classifier loss: 0.313535; batch adversarial loss: 0.533454\n",
      "epoch 191; iter: 0; batch classifier loss: 0.369548; batch adversarial loss: 0.551284\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333641; batch adversarial loss: 0.524459\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356078; batch adversarial loss: 0.484395\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396450; batch adversarial loss: 0.572922\n",
      "epoch 195; iter: 0; batch classifier loss: 0.371100; batch adversarial loss: 0.604234\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372394; batch adversarial loss: 0.588834\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388273; batch adversarial loss: 0.518139\n",
      "epoch 198; iter: 0; batch classifier loss: 0.274359; batch adversarial loss: 0.609361\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348937; batch adversarial loss: 0.587815\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686771; batch adversarial loss: 0.735008\n",
      "epoch 1; iter: 0; batch classifier loss: 0.667462; batch adversarial loss: 0.714712\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624472; batch adversarial loss: 0.668132\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570621; batch adversarial loss: 0.633106\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521761; batch adversarial loss: 0.626390\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537075; batch adversarial loss: 0.640421\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591078; batch adversarial loss: 0.605039\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596394; batch adversarial loss: 0.579904\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577063; batch adversarial loss: 0.588090\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534543; batch adversarial loss: 0.600169\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558009; batch adversarial loss: 0.547903\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554372; batch adversarial loss: 0.565496\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527879; batch adversarial loss: 0.585075\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565586; batch adversarial loss: 0.526557\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535280; batch adversarial loss: 0.514734\n",
      "epoch 15; iter: 0; batch classifier loss: 0.568554; batch adversarial loss: 0.557714\n",
      "epoch 16; iter: 0; batch classifier loss: 0.587416; batch adversarial loss: 0.532987\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539439; batch adversarial loss: 0.607172\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502974; batch adversarial loss: 0.571102\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501410; batch adversarial loss: 0.496435\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505883; batch adversarial loss: 0.572153\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526431; batch adversarial loss: 0.455595\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452236; batch adversarial loss: 0.725898\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467273; batch adversarial loss: 0.557756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.448218; batch adversarial loss: 0.547489\n",
      "epoch 25; iter: 0; batch classifier loss: 0.448241; batch adversarial loss: 0.537045\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435387; batch adversarial loss: 0.546404\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474487; batch adversarial loss: 0.527157\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441746; batch adversarial loss: 0.565567\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534310; batch adversarial loss: 0.520621\n",
      "epoch 30; iter: 0; batch classifier loss: 0.534073; batch adversarial loss: 0.587669\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433003; batch adversarial loss: 0.552942\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469435; batch adversarial loss: 0.558000\n",
      "epoch 33; iter: 0; batch classifier loss: 0.479146; batch adversarial loss: 0.466165\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466484; batch adversarial loss: 0.513442\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481142; batch adversarial loss: 0.531772\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460632; batch adversarial loss: 0.488338\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476155; batch adversarial loss: 0.508107\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452068; batch adversarial loss: 0.558296\n",
      "epoch 39; iter: 0; batch classifier loss: 0.488795; batch adversarial loss: 0.561513\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458327; batch adversarial loss: 0.572367\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478639; batch adversarial loss: 0.534510\n",
      "epoch 42; iter: 0; batch classifier loss: 0.376001; batch adversarial loss: 0.546885\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465070; batch adversarial loss: 0.567998\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445928; batch adversarial loss: 0.574029\n",
      "epoch 45; iter: 0; batch classifier loss: 0.475795; batch adversarial loss: 0.547640\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423244; batch adversarial loss: 0.544913\n",
      "epoch 47; iter: 0; batch classifier loss: 0.445585; batch adversarial loss: 0.460439\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383192; batch adversarial loss: 0.561670\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423411; batch adversarial loss: 0.515068\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439278; batch adversarial loss: 0.554041\n",
      "epoch 51; iter: 0; batch classifier loss: 0.352253; batch adversarial loss: 0.585621\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443424; batch adversarial loss: 0.583076\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472284; batch adversarial loss: 0.502342\n",
      "epoch 54; iter: 0; batch classifier loss: 0.361598; batch adversarial loss: 0.555871\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386381; batch adversarial loss: 0.587385\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421097; batch adversarial loss: 0.481676\n",
      "epoch 57; iter: 0; batch classifier loss: 0.500414; batch adversarial loss: 0.517391\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437829; batch adversarial loss: 0.448973\n",
      "epoch 59; iter: 0; batch classifier loss: 0.377580; batch adversarial loss: 0.483571\n",
      "epoch 60; iter: 0; batch classifier loss: 0.360402; batch adversarial loss: 0.538991\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441467; batch adversarial loss: 0.487287\n",
      "epoch 62; iter: 0; batch classifier loss: 0.466517; batch adversarial loss: 0.565454\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414459; batch adversarial loss: 0.527412\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409319; batch adversarial loss: 0.536054\n",
      "epoch 65; iter: 0; batch classifier loss: 0.337748; batch adversarial loss: 0.563809\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445254; batch adversarial loss: 0.435385\n",
      "epoch 67; iter: 0; batch classifier loss: 0.532067; batch adversarial loss: 0.508528\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422637; batch adversarial loss: 0.516189\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416598; batch adversarial loss: 0.664991\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431591; batch adversarial loss: 0.582080\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405917; batch adversarial loss: 0.534914\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380219; batch adversarial loss: 0.525714\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411400; batch adversarial loss: 0.506620\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367456; batch adversarial loss: 0.591034\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369466; batch adversarial loss: 0.486885\n",
      "epoch 76; iter: 0; batch classifier loss: 0.471280; batch adversarial loss: 0.592482\n",
      "epoch 77; iter: 0; batch classifier loss: 0.342603; batch adversarial loss: 0.554023\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398249; batch adversarial loss: 0.525863\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419525; batch adversarial loss: 0.536193\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451849; batch adversarial loss: 0.553236\n",
      "epoch 81; iter: 0; batch classifier loss: 0.498103; batch adversarial loss: 0.611490\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390562; batch adversarial loss: 0.572330\n",
      "epoch 83; iter: 0; batch classifier loss: 0.443700; batch adversarial loss: 0.534510\n",
      "epoch 84; iter: 0; batch classifier loss: 0.422830; batch adversarial loss: 0.573688\n",
      "epoch 85; iter: 0; batch classifier loss: 0.430594; batch adversarial loss: 0.545445\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358385; batch adversarial loss: 0.611598\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368305; batch adversarial loss: 0.516710\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388107; batch adversarial loss: 0.581677\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406230; batch adversarial loss: 0.572731\n",
      "epoch 90; iter: 0; batch classifier loss: 0.406247; batch adversarial loss: 0.533496\n",
      "epoch 91; iter: 0; batch classifier loss: 0.445564; batch adversarial loss: 0.563483\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371334; batch adversarial loss: 0.488782\n",
      "epoch 93; iter: 0; batch classifier loss: 0.423529; batch adversarial loss: 0.582125\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408989; batch adversarial loss: 0.562882\n",
      "epoch 95; iter: 0; batch classifier loss: 0.482487; batch adversarial loss: 0.553237\n",
      "epoch 96; iter: 0; batch classifier loss: 0.450737; batch adversarial loss: 0.514306\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410624; batch adversarial loss: 0.517592\n",
      "epoch 98; iter: 0; batch classifier loss: 0.453786; batch adversarial loss: 0.535044\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339335; batch adversarial loss: 0.487139\n",
      "epoch 100; iter: 0; batch classifier loss: 0.441152; batch adversarial loss: 0.525283\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347960; batch adversarial loss: 0.514258\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363970; batch adversarial loss: 0.496943\n",
      "epoch 103; iter: 0; batch classifier loss: 0.334263; batch adversarial loss: 0.512318\n",
      "epoch 104; iter: 0; batch classifier loss: 0.380769; batch adversarial loss: 0.560781\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364800; batch adversarial loss: 0.469024\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385470; batch adversarial loss: 0.504382\n",
      "epoch 107; iter: 0; batch classifier loss: 0.440073; batch adversarial loss: 0.458043\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379197; batch adversarial loss: 0.581566\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402724; batch adversarial loss: 0.518378\n",
      "epoch 110; iter: 0; batch classifier loss: 0.473930; batch adversarial loss: 0.499014\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381413; batch adversarial loss: 0.508122\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396792; batch adversarial loss: 0.562737\n",
      "epoch 113; iter: 0; batch classifier loss: 0.460035; batch adversarial loss: 0.616921\n",
      "epoch 114; iter: 0; batch classifier loss: 0.398518; batch adversarial loss: 0.572035\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364685; batch adversarial loss: 0.571765\n",
      "epoch 116; iter: 0; batch classifier loss: 0.418895; batch adversarial loss: 0.544329\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369785; batch adversarial loss: 0.497803\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347686; batch adversarial loss: 0.563924\n",
      "epoch 119; iter: 0; batch classifier loss: 0.459330; batch adversarial loss: 0.525006\n",
      "epoch 120; iter: 0; batch classifier loss: 0.471371; batch adversarial loss: 0.534612\n",
      "epoch 121; iter: 0; batch classifier loss: 0.377957; batch adversarial loss: 0.572763\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388055; batch adversarial loss: 0.515828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.385242; batch adversarial loss: 0.552170\n",
      "epoch 124; iter: 0; batch classifier loss: 0.495314; batch adversarial loss: 0.534116\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349527; batch adversarial loss: 0.508191\n",
      "epoch 126; iter: 0; batch classifier loss: 0.420539; batch adversarial loss: 0.525965\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374786; batch adversarial loss: 0.563358\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387724; batch adversarial loss: 0.497766\n",
      "epoch 129; iter: 0; batch classifier loss: 0.431398; batch adversarial loss: 0.488240\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391457; batch adversarial loss: 0.562636\n",
      "epoch 131; iter: 0; batch classifier loss: 0.352215; batch adversarial loss: 0.590304\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400080; batch adversarial loss: 0.534586\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371260; batch adversarial loss: 0.666529\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375695; batch adversarial loss: 0.553997\n",
      "epoch 135; iter: 0; batch classifier loss: 0.392739; batch adversarial loss: 0.554519\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354410; batch adversarial loss: 0.583511\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341212; batch adversarial loss: 0.618475\n",
      "epoch 138; iter: 0; batch classifier loss: 0.451776; batch adversarial loss: 0.562092\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359958; batch adversarial loss: 0.487909\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343268; batch adversarial loss: 0.629837\n",
      "epoch 141; iter: 0; batch classifier loss: 0.431095; batch adversarial loss: 0.450427\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360066; batch adversarial loss: 0.469610\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376414; batch adversarial loss: 0.545331\n",
      "epoch 144; iter: 0; batch classifier loss: 0.476842; batch adversarial loss: 0.581954\n",
      "epoch 145; iter: 0; batch classifier loss: 0.445066; batch adversarial loss: 0.571107\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404869; batch adversarial loss: 0.545495\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359863; batch adversarial loss: 0.504924\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341688; batch adversarial loss: 0.506532\n",
      "epoch 149; iter: 0; batch classifier loss: 0.425284; batch adversarial loss: 0.497565\n",
      "epoch 150; iter: 0; batch classifier loss: 0.449454; batch adversarial loss: 0.515473\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386151; batch adversarial loss: 0.611399\n",
      "epoch 152; iter: 0; batch classifier loss: 0.398883; batch adversarial loss: 0.525562\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366417; batch adversarial loss: 0.630592\n",
      "epoch 154; iter: 0; batch classifier loss: 0.427637; batch adversarial loss: 0.515582\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392804; batch adversarial loss: 0.488179\n",
      "epoch 156; iter: 0; batch classifier loss: 0.421102; batch adversarial loss: 0.525787\n",
      "epoch 157; iter: 0; batch classifier loss: 0.442628; batch adversarial loss: 0.572478\n",
      "epoch 158; iter: 0; batch classifier loss: 0.288393; batch adversarial loss: 0.544789\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325663; batch adversarial loss: 0.545805\n",
      "epoch 160; iter: 0; batch classifier loss: 0.407827; batch adversarial loss: 0.536559\n",
      "epoch 161; iter: 0; batch classifier loss: 0.434941; batch adversarial loss: 0.572187\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361822; batch adversarial loss: 0.468278\n",
      "epoch 163; iter: 0; batch classifier loss: 0.286149; batch adversarial loss: 0.508080\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375091; batch adversarial loss: 0.534281\n",
      "epoch 165; iter: 0; batch classifier loss: 0.400721; batch adversarial loss: 0.563339\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333244; batch adversarial loss: 0.470071\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387193; batch adversarial loss: 0.516623\n",
      "epoch 168; iter: 0; batch classifier loss: 0.403087; batch adversarial loss: 0.592202\n",
      "epoch 169; iter: 0; batch classifier loss: 0.335349; batch adversarial loss: 0.600364\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386011; batch adversarial loss: 0.515795\n",
      "epoch 171; iter: 0; batch classifier loss: 0.457325; batch adversarial loss: 0.647771\n",
      "epoch 172; iter: 0; batch classifier loss: 0.329065; batch adversarial loss: 0.600655\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355540; batch adversarial loss: 0.582104\n",
      "epoch 174; iter: 0; batch classifier loss: 0.431343; batch adversarial loss: 0.506875\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376094; batch adversarial loss: 0.600376\n",
      "epoch 176; iter: 0; batch classifier loss: 0.398333; batch adversarial loss: 0.581689\n",
      "epoch 177; iter: 0; batch classifier loss: 0.411866; batch adversarial loss: 0.478621\n",
      "epoch 178; iter: 0; batch classifier loss: 0.356312; batch adversarial loss: 0.516267\n",
      "epoch 179; iter: 0; batch classifier loss: 0.363697; batch adversarial loss: 0.516381\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366806; batch adversarial loss: 0.631495\n",
      "epoch 181; iter: 0; batch classifier loss: 0.404685; batch adversarial loss: 0.611371\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334207; batch adversarial loss: 0.638779\n",
      "epoch 183; iter: 0; batch classifier loss: 0.328296; batch adversarial loss: 0.553353\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335320; batch adversarial loss: 0.553378\n",
      "epoch 185; iter: 0; batch classifier loss: 0.305460; batch adversarial loss: 0.516327\n",
      "epoch 186; iter: 0; batch classifier loss: 0.394510; batch adversarial loss: 0.523916\n",
      "epoch 187; iter: 0; batch classifier loss: 0.406082; batch adversarial loss: 0.507112\n",
      "epoch 188; iter: 0; batch classifier loss: 0.326061; batch adversarial loss: 0.535390\n",
      "epoch 189; iter: 0; batch classifier loss: 0.388679; batch adversarial loss: 0.523006\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390144; batch adversarial loss: 0.496086\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364287; batch adversarial loss: 0.498452\n",
      "epoch 192; iter: 0; batch classifier loss: 0.386725; batch adversarial loss: 0.590739\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335457; batch adversarial loss: 0.600330\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350218; batch adversarial loss: 0.543116\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383980; batch adversarial loss: 0.513189\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328619; batch adversarial loss: 0.458763\n",
      "epoch 197; iter: 0; batch classifier loss: 0.412335; batch adversarial loss: 0.591317\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371233; batch adversarial loss: 0.527478\n",
      "epoch 199; iter: 0; batch classifier loss: 0.418499; batch adversarial loss: 0.621387\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689345; batch adversarial loss: 0.635024\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590947; batch adversarial loss: 0.672935\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575578; batch adversarial loss: 0.664538\n",
      "epoch 3; iter: 0; batch classifier loss: 0.505330; batch adversarial loss: 0.663309\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547935; batch adversarial loss: 0.625101\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556741; batch adversarial loss: 0.596418\n",
      "epoch 6; iter: 0; batch classifier loss: 0.693861; batch adversarial loss: 0.613187\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611174; batch adversarial loss: 0.584870\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545682; batch adversarial loss: 0.574893\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571464; batch adversarial loss: 0.611502\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562652; batch adversarial loss: 0.571891\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535794; batch adversarial loss: 0.583879\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557431; batch adversarial loss: 0.556715\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551535; batch adversarial loss: 0.525833\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523802; batch adversarial loss: 0.532270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485364; batch adversarial loss: 0.526846\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491087; batch adversarial loss: 0.593236\n",
      "epoch 17; iter: 0; batch classifier loss: 0.476739; batch adversarial loss: 0.608776\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528905; batch adversarial loss: 0.548264\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484340; batch adversarial loss: 0.589957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.554235; batch adversarial loss: 0.572948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.442417; batch adversarial loss: 0.598293\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531955; batch adversarial loss: 0.582676\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474036; batch adversarial loss: 0.641555\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528307; batch adversarial loss: 0.503639\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533959; batch adversarial loss: 0.556607\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490923; batch adversarial loss: 0.519506\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493995; batch adversarial loss: 0.518814\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469928; batch adversarial loss: 0.489527\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504287; batch adversarial loss: 0.547305\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499811; batch adversarial loss: 0.505936\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409625; batch adversarial loss: 0.538364\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454954; batch adversarial loss: 0.614639\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497000; batch adversarial loss: 0.512719\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417668; batch adversarial loss: 0.613299\n",
      "epoch 35; iter: 0; batch classifier loss: 0.428338; batch adversarial loss: 0.614229\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465378; batch adversarial loss: 0.623493\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486441; batch adversarial loss: 0.614451\n",
      "epoch 38; iter: 0; batch classifier loss: 0.433253; batch adversarial loss: 0.519673\n",
      "epoch 39; iter: 0; batch classifier loss: 0.390287; batch adversarial loss: 0.540499\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413472; batch adversarial loss: 0.483695\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429849; batch adversarial loss: 0.524194\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461870; batch adversarial loss: 0.568413\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427841; batch adversarial loss: 0.631717\n",
      "epoch 44; iter: 0; batch classifier loss: 0.391769; batch adversarial loss: 0.625621\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424872; batch adversarial loss: 0.638526\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388959; batch adversarial loss: 0.544310\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504192; batch adversarial loss: 0.579567\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397292; batch adversarial loss: 0.569185\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466741; batch adversarial loss: 0.572824\n",
      "epoch 50; iter: 0; batch classifier loss: 0.536052; batch adversarial loss: 0.527907\n",
      "epoch 51; iter: 0; batch classifier loss: 0.507669; batch adversarial loss: 0.562501\n",
      "epoch 52; iter: 0; batch classifier loss: 0.314251; batch adversarial loss: 0.579026\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449666; batch adversarial loss: 0.537521\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437943; batch adversarial loss: 0.578867\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433955; batch adversarial loss: 0.515087\n",
      "epoch 56; iter: 0; batch classifier loss: 0.362870; batch adversarial loss: 0.463320\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423165; batch adversarial loss: 0.572727\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427008; batch adversarial loss: 0.491107\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374363; batch adversarial loss: 0.580199\n",
      "epoch 60; iter: 0; batch classifier loss: 0.344709; batch adversarial loss: 0.571980\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425745; batch adversarial loss: 0.536205\n",
      "epoch 62; iter: 0; batch classifier loss: 0.449738; batch adversarial loss: 0.544843\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417537; batch adversarial loss: 0.597026\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395713; batch adversarial loss: 0.527543\n",
      "epoch 65; iter: 0; batch classifier loss: 0.353429; batch adversarial loss: 0.535007\n",
      "epoch 66; iter: 0; batch classifier loss: 0.485708; batch adversarial loss: 0.492340\n",
      "epoch 67; iter: 0; batch classifier loss: 0.473447; batch adversarial loss: 0.562564\n",
      "epoch 68; iter: 0; batch classifier loss: 0.374026; batch adversarial loss: 0.544609\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428242; batch adversarial loss: 0.536500\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384921; batch adversarial loss: 0.553905\n",
      "epoch 71; iter: 0; batch classifier loss: 0.476192; batch adversarial loss: 0.545671\n",
      "epoch 72; iter: 0; batch classifier loss: 0.362965; batch adversarial loss: 0.491431\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388638; batch adversarial loss: 0.526860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433436; batch adversarial loss: 0.518794\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401015; batch adversarial loss: 0.561068\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440439; batch adversarial loss: 0.555407\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406985; batch adversarial loss: 0.589456\n",
      "epoch 78; iter: 0; batch classifier loss: 0.461140; batch adversarial loss: 0.527337\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413413; batch adversarial loss: 0.527632\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402577; batch adversarial loss: 0.537286\n",
      "epoch 81; iter: 0; batch classifier loss: 0.332597; batch adversarial loss: 0.552843\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409969; batch adversarial loss: 0.544188\n",
      "epoch 83; iter: 0; batch classifier loss: 0.478547; batch adversarial loss: 0.545385\n",
      "epoch 84; iter: 0; batch classifier loss: 0.319788; batch adversarial loss: 0.525748\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456641; batch adversarial loss: 0.527670\n",
      "epoch 86; iter: 0; batch classifier loss: 0.447119; batch adversarial loss: 0.661488\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394689; batch adversarial loss: 0.516118\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356000; batch adversarial loss: 0.551992\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399631; batch adversarial loss: 0.553346\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378787; batch adversarial loss: 0.492223\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403035; batch adversarial loss: 0.544760\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428470; batch adversarial loss: 0.571909\n",
      "epoch 93; iter: 0; batch classifier loss: 0.346003; batch adversarial loss: 0.544863\n",
      "epoch 94; iter: 0; batch classifier loss: 0.470688; batch adversarial loss: 0.544221\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375261; batch adversarial loss: 0.517143\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408183; batch adversarial loss: 0.590087\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393478; batch adversarial loss: 0.640785\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386895; batch adversarial loss: 0.589993\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376336; batch adversarial loss: 0.561961\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412961; batch adversarial loss: 0.500838\n",
      "epoch 101; iter: 0; batch classifier loss: 0.348010; batch adversarial loss: 0.589361\n",
      "epoch 102; iter: 0; batch classifier loss: 0.423530; batch adversarial loss: 0.571245\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366936; batch adversarial loss: 0.490666\n",
      "epoch 104; iter: 0; batch classifier loss: 0.329332; batch adversarial loss: 0.563043\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389111; batch adversarial loss: 0.562556\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394778; batch adversarial loss: 0.562657\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371843; batch adversarial loss: 0.536024\n",
      "epoch 108; iter: 0; batch classifier loss: 0.382084; batch adversarial loss: 0.543935\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367618; batch adversarial loss: 0.535745\n",
      "epoch 110; iter: 0; batch classifier loss: 0.400538; batch adversarial loss: 0.572138\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412562; batch adversarial loss: 0.535022\n",
      "epoch 112; iter: 0; batch classifier loss: 0.439890; batch adversarial loss: 0.599145\n",
      "epoch 113; iter: 0; batch classifier loss: 0.403522; batch adversarial loss: 0.544950\n",
      "epoch 114; iter: 0; batch classifier loss: 0.342474; batch adversarial loss: 0.519250\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372329; batch adversarial loss: 0.535948\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369516; batch adversarial loss: 0.624011\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384532; batch adversarial loss: 0.491685\n",
      "epoch 118; iter: 0; batch classifier loss: 0.448215; batch adversarial loss: 0.552526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.386977; batch adversarial loss: 0.562064\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377894; batch adversarial loss: 0.640910\n",
      "epoch 121; iter: 0; batch classifier loss: 0.352559; batch adversarial loss: 0.499747\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361678; batch adversarial loss: 0.569407\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381440; batch adversarial loss: 0.534589\n",
      "epoch 124; iter: 0; batch classifier loss: 0.315185; batch adversarial loss: 0.536425\n",
      "epoch 125; iter: 0; batch classifier loss: 0.400362; batch adversarial loss: 0.508718\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365507; batch adversarial loss: 0.625239\n",
      "epoch 127; iter: 0; batch classifier loss: 0.364289; batch adversarial loss: 0.562973\n",
      "epoch 128; iter: 0; batch classifier loss: 0.339630; batch adversarial loss: 0.579597\n",
      "epoch 129; iter: 0; batch classifier loss: 0.295939; batch adversarial loss: 0.492632\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346589; batch adversarial loss: 0.501848\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386739; batch adversarial loss: 0.588243\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331095; batch adversarial loss: 0.571031\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396669; batch adversarial loss: 0.501203\n",
      "epoch 134; iter: 0; batch classifier loss: 0.430464; batch adversarial loss: 0.509713\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385868; batch adversarial loss: 0.552753\n",
      "epoch 136; iter: 0; batch classifier loss: 0.335561; batch adversarial loss: 0.544412\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340442; batch adversarial loss: 0.525564\n",
      "epoch 138; iter: 0; batch classifier loss: 0.325292; batch adversarial loss: 0.551401\n",
      "epoch 139; iter: 0; batch classifier loss: 0.365877; batch adversarial loss: 0.482678\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356047; batch adversarial loss: 0.464430\n",
      "epoch 141; iter: 0; batch classifier loss: 0.374947; batch adversarial loss: 0.526845\n",
      "epoch 142; iter: 0; batch classifier loss: 0.428137; batch adversarial loss: 0.552877\n",
      "epoch 143; iter: 0; batch classifier loss: 0.307863; batch adversarial loss: 0.564069\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396135; batch adversarial loss: 0.545726\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372114; batch adversarial loss: 0.589558\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360457; batch adversarial loss: 0.553897\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377506; batch adversarial loss: 0.507653\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367802; batch adversarial loss: 0.453830\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374357; batch adversarial loss: 0.581206\n",
      "epoch 150; iter: 0; batch classifier loss: 0.299220; batch adversarial loss: 0.553547\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310496; batch adversarial loss: 0.508359\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354242; batch adversarial loss: 0.591628\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353077; batch adversarial loss: 0.631252\n",
      "epoch 154; iter: 0; batch classifier loss: 0.418104; batch adversarial loss: 0.517768\n",
      "epoch 155; iter: 0; batch classifier loss: 0.407668; batch adversarial loss: 0.492855\n",
      "epoch 156; iter: 0; batch classifier loss: 0.427153; batch adversarial loss: 0.560591\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371678; batch adversarial loss: 0.613998\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319950; batch adversarial loss: 0.553431\n",
      "epoch 159; iter: 0; batch classifier loss: 0.357883; batch adversarial loss: 0.527231\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374445; batch adversarial loss: 0.553152\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399956; batch adversarial loss: 0.623458\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373250; batch adversarial loss: 0.640329\n",
      "epoch 163; iter: 0; batch classifier loss: 0.267524; batch adversarial loss: 0.554699\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348916; batch adversarial loss: 0.519170\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377996; batch adversarial loss: 0.554129\n",
      "epoch 166; iter: 0; batch classifier loss: 0.424406; batch adversarial loss: 0.518510\n",
      "epoch 167; iter: 0; batch classifier loss: 0.298553; batch adversarial loss: 0.491229\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333822; batch adversarial loss: 0.562470\n",
      "epoch 169; iter: 0; batch classifier loss: 0.257865; batch adversarial loss: 0.527098\n",
      "epoch 170; iter: 0; batch classifier loss: 0.332020; batch adversarial loss: 0.562183\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375586; batch adversarial loss: 0.579449\n",
      "epoch 172; iter: 0; batch classifier loss: 0.399286; batch adversarial loss: 0.518192\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361430; batch adversarial loss: 0.589181\n",
      "epoch 174; iter: 0; batch classifier loss: 0.404700; batch adversarial loss: 0.545692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342258; batch adversarial loss: 0.502219\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348921; batch adversarial loss: 0.589125\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346173; batch adversarial loss: 0.528394\n",
      "epoch 178; iter: 0; batch classifier loss: 0.400822; batch adversarial loss: 0.553799\n",
      "epoch 179; iter: 0; batch classifier loss: 0.338940; batch adversarial loss: 0.571010\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360939; batch adversarial loss: 0.562738\n",
      "epoch 181; iter: 0; batch classifier loss: 0.375100; batch adversarial loss: 0.588613\n",
      "epoch 182; iter: 0; batch classifier loss: 0.403671; batch adversarial loss: 0.562347\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367440; batch adversarial loss: 0.518742\n",
      "epoch 184; iter: 0; batch classifier loss: 0.296527; batch adversarial loss: 0.606431\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381713; batch adversarial loss: 0.588170\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347187; batch adversarial loss: 0.624843\n",
      "epoch 187; iter: 0; batch classifier loss: 0.366170; batch adversarial loss: 0.572059\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386954; batch adversarial loss: 0.643744\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395331; batch adversarial loss: 0.589779\n",
      "epoch 190; iter: 0; batch classifier loss: 0.316003; batch adversarial loss: 0.570569\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363336; batch adversarial loss: 0.518452\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363943; batch adversarial loss: 0.544330\n",
      "epoch 193; iter: 0; batch classifier loss: 0.437111; batch adversarial loss: 0.544411\n",
      "epoch 194; iter: 0; batch classifier loss: 0.383075; batch adversarial loss: 0.580209\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362284; batch adversarial loss: 0.579632\n",
      "epoch 196; iter: 0; batch classifier loss: 0.369168; batch adversarial loss: 0.492517\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388055; batch adversarial loss: 0.614775\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341642; batch adversarial loss: 0.571636\n",
      "epoch 199; iter: 0; batch classifier loss: 0.301562; batch adversarial loss: 0.562832\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738129; batch adversarial loss: 0.847556\n",
      "epoch 1; iter: 0; batch classifier loss: 0.807754; batch adversarial loss: 0.839481\n",
      "epoch 2; iter: 0; batch classifier loss: 0.842412; batch adversarial loss: 0.793730\n",
      "epoch 3; iter: 0; batch classifier loss: 0.823873; batch adversarial loss: 0.728980\n",
      "epoch 4; iter: 0; batch classifier loss: 0.698074; batch adversarial loss: 0.643173\n",
      "epoch 5; iter: 0; batch classifier loss: 0.647664; batch adversarial loss: 0.627212\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563580; batch adversarial loss: 0.615480\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607224; batch adversarial loss: 0.607942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574185; batch adversarial loss: 0.578370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.635592; batch adversarial loss: 0.567941\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502535; batch adversarial loss: 0.579313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545704; batch adversarial loss: 0.595791\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555256; batch adversarial loss: 0.549994\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519945; batch adversarial loss: 0.561399\n",
      "epoch 14; iter: 0; batch classifier loss: 0.584095; batch adversarial loss: 0.537102\n",
      "epoch 15; iter: 0; batch classifier loss: 0.466209; batch adversarial loss: 0.561884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475612; batch adversarial loss: 0.553056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.543664; batch adversarial loss: 0.590822\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444411; batch adversarial loss: 0.578195\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473648; batch adversarial loss: 0.518863\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511278; batch adversarial loss: 0.573973\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478002; batch adversarial loss: 0.578822\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573159; batch adversarial loss: 0.631564\n",
      "epoch 23; iter: 0; batch classifier loss: 0.512315; batch adversarial loss: 0.575449\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446719; batch adversarial loss: 0.551914\n",
      "epoch 25; iter: 0; batch classifier loss: 0.454567; batch adversarial loss: 0.567206\n",
      "epoch 26; iter: 0; batch classifier loss: 0.528292; batch adversarial loss: 0.543520\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432116; batch adversarial loss: 0.513728\n",
      "epoch 28; iter: 0; batch classifier loss: 0.530579; batch adversarial loss: 0.626596\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472621; batch adversarial loss: 0.497848\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483437; batch adversarial loss: 0.508848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498948; batch adversarial loss: 0.541348\n",
      "epoch 32; iter: 0; batch classifier loss: 0.440180; batch adversarial loss: 0.555180\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414265; batch adversarial loss: 0.551416\n",
      "epoch 34; iter: 0; batch classifier loss: 0.440495; batch adversarial loss: 0.589569\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456024; batch adversarial loss: 0.535880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.401351; batch adversarial loss: 0.540677\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466148; batch adversarial loss: 0.560219\n",
      "epoch 38; iter: 0; batch classifier loss: 0.521939; batch adversarial loss: 0.596977\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498738; batch adversarial loss: 0.582326\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417635; batch adversarial loss: 0.513499\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411396; batch adversarial loss: 0.562035\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451519; batch adversarial loss: 0.546071\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446991; batch adversarial loss: 0.502495\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437569; batch adversarial loss: 0.549373\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417623; batch adversarial loss: 0.537481\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436261; batch adversarial loss: 0.572098\n",
      "epoch 47; iter: 0; batch classifier loss: 0.319113; batch adversarial loss: 0.500286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.499536; batch adversarial loss: 0.543462\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418339; batch adversarial loss: 0.488811\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457474; batch adversarial loss: 0.553065\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374764; batch adversarial loss: 0.571912\n",
      "epoch 52; iter: 0; batch classifier loss: 0.477310; batch adversarial loss: 0.518222\n",
      "epoch 53; iter: 0; batch classifier loss: 0.358316; batch adversarial loss: 0.517214\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447049; batch adversarial loss: 0.552863\n",
      "epoch 55; iter: 0; batch classifier loss: 0.455373; batch adversarial loss: 0.563698\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421541; batch adversarial loss: 0.498669\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471661; batch adversarial loss: 0.508550\n",
      "epoch 58; iter: 0; batch classifier loss: 0.524324; batch adversarial loss: 0.498742\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391461; batch adversarial loss: 0.507495\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411031; batch adversarial loss: 0.526205\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442107; batch adversarial loss: 0.591473\n",
      "epoch 62; iter: 0; batch classifier loss: 0.356009; batch adversarial loss: 0.572074\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411860; batch adversarial loss: 0.507201\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395189; batch adversarial loss: 0.508099\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406596; batch adversarial loss: 0.535223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384977; batch adversarial loss: 0.451188\n",
      "epoch 67; iter: 0; batch classifier loss: 0.481894; batch adversarial loss: 0.582719\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386338; batch adversarial loss: 0.562865\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378028; batch adversarial loss: 0.462241\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359067; batch adversarial loss: 0.507355\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400917; batch adversarial loss: 0.535204\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391686; batch adversarial loss: 0.544644\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417597; batch adversarial loss: 0.534943\n",
      "epoch 74; iter: 0; batch classifier loss: 0.353840; batch adversarial loss: 0.460868\n",
      "epoch 75; iter: 0; batch classifier loss: 0.279810; batch adversarial loss: 0.525665\n",
      "epoch 76; iter: 0; batch classifier loss: 0.469401; batch adversarial loss: 0.571659\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395930; batch adversarial loss: 0.582054\n",
      "epoch 78; iter: 0; batch classifier loss: 0.423553; batch adversarial loss: 0.599370\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439376; batch adversarial loss: 0.470370\n",
      "epoch 80; iter: 0; batch classifier loss: 0.400235; batch adversarial loss: 0.561889\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417022; batch adversarial loss: 0.543575\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377734; batch adversarial loss: 0.499040\n",
      "epoch 83; iter: 0; batch classifier loss: 0.358852; batch adversarial loss: 0.591227\n",
      "epoch 84; iter: 0; batch classifier loss: 0.456574; batch adversarial loss: 0.564717\n",
      "epoch 85; iter: 0; batch classifier loss: 0.334467; batch adversarial loss: 0.480187\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401766; batch adversarial loss: 0.497356\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356340; batch adversarial loss: 0.518162\n",
      "epoch 88; iter: 0; batch classifier loss: 0.336289; batch adversarial loss: 0.609794\n",
      "epoch 89; iter: 0; batch classifier loss: 0.486812; batch adversarial loss: 0.619100\n",
      "epoch 90; iter: 0; batch classifier loss: 0.372057; batch adversarial loss: 0.562283\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408961; batch adversarial loss: 0.572557\n",
      "epoch 92; iter: 0; batch classifier loss: 0.328530; batch adversarial loss: 0.544677\n",
      "epoch 93; iter: 0; batch classifier loss: 0.502859; batch adversarial loss: 0.544041\n",
      "epoch 94; iter: 0; batch classifier loss: 0.442255; batch adversarial loss: 0.573907\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387736; batch adversarial loss: 0.525303\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364857; batch adversarial loss: 0.610173\n",
      "epoch 97; iter: 0; batch classifier loss: 0.432141; batch adversarial loss: 0.507178\n",
      "epoch 98; iter: 0; batch classifier loss: 0.367919; batch adversarial loss: 0.422618\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403931; batch adversarial loss: 0.639095\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398863; batch adversarial loss: 0.487063\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426264; batch adversarial loss: 0.573024\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376621; batch adversarial loss: 0.517870\n",
      "epoch 103; iter: 0; batch classifier loss: 0.326307; batch adversarial loss: 0.553321\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399378; batch adversarial loss: 0.504475\n",
      "epoch 105; iter: 0; batch classifier loss: 0.334602; batch adversarial loss: 0.524988\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380267; batch adversarial loss: 0.525406\n",
      "epoch 107; iter: 0; batch classifier loss: 0.323656; batch adversarial loss: 0.488029\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383407; batch adversarial loss: 0.460189\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396552; batch adversarial loss: 0.525240\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344259; batch adversarial loss: 0.552590\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376819; batch adversarial loss: 0.600480\n",
      "epoch 112; iter: 0; batch classifier loss: 0.436869; batch adversarial loss: 0.527794\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381086; batch adversarial loss: 0.533818\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329027; batch adversarial loss: 0.527815\n",
      "epoch 115; iter: 0; batch classifier loss: 0.289314; batch adversarial loss: 0.534223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.366104; batch adversarial loss: 0.527176\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339640; batch adversarial loss: 0.545128\n",
      "epoch 118; iter: 0; batch classifier loss: 0.419673; batch adversarial loss: 0.479942\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395258; batch adversarial loss: 0.590298\n",
      "epoch 120; iter: 0; batch classifier loss: 0.397670; batch adversarial loss: 0.552104\n",
      "epoch 121; iter: 0; batch classifier loss: 0.416144; batch adversarial loss: 0.515692\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372767; batch adversarial loss: 0.536816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379366; batch adversarial loss: 0.525643\n",
      "epoch 124; iter: 0; batch classifier loss: 0.318545; batch adversarial loss: 0.543951\n",
      "epoch 125; iter: 0; batch classifier loss: 0.337874; batch adversarial loss: 0.478364\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382585; batch adversarial loss: 0.498711\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352019; batch adversarial loss: 0.554923\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387366; batch adversarial loss: 0.600283\n",
      "epoch 129; iter: 0; batch classifier loss: 0.462152; batch adversarial loss: 0.532619\n",
      "epoch 130; iter: 0; batch classifier loss: 0.400442; batch adversarial loss: 0.545434\n",
      "epoch 131; iter: 0; batch classifier loss: 0.272950; batch adversarial loss: 0.534338\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415712; batch adversarial loss: 0.487302\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378349; batch adversarial loss: 0.598902\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376071; batch adversarial loss: 0.581055\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369476; batch adversarial loss: 0.543980\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386817; batch adversarial loss: 0.517482\n",
      "epoch 137; iter: 0; batch classifier loss: 0.435532; batch adversarial loss: 0.600259\n",
      "epoch 138; iter: 0; batch classifier loss: 0.430496; batch adversarial loss: 0.581964\n",
      "epoch 139; iter: 0; batch classifier loss: 0.320370; batch adversarial loss: 0.580419\n",
      "epoch 140; iter: 0; batch classifier loss: 0.404685; batch adversarial loss: 0.525502\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326228; batch adversarial loss: 0.618372\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383807; batch adversarial loss: 0.599764\n",
      "epoch 143; iter: 0; batch classifier loss: 0.429837; batch adversarial loss: 0.564617\n",
      "epoch 144; iter: 0; batch classifier loss: 0.287004; batch adversarial loss: 0.488836\n",
      "epoch 145; iter: 0; batch classifier loss: 0.328334; batch adversarial loss: 0.591038\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375384; batch adversarial loss: 0.636802\n",
      "epoch 147; iter: 0; batch classifier loss: 0.320264; batch adversarial loss: 0.497641\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364339; batch adversarial loss: 0.535104\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366453; batch adversarial loss: 0.506889\n",
      "epoch 150; iter: 0; batch classifier loss: 0.343584; batch adversarial loss: 0.563448\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341224; batch adversarial loss: 0.470596\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339220; batch adversarial loss: 0.553495\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360060; batch adversarial loss: 0.499859\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360443; batch adversarial loss: 0.541417\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342034; batch adversarial loss: 0.611869\n",
      "epoch 156; iter: 0; batch classifier loss: 0.405329; batch adversarial loss: 0.534130\n",
      "epoch 157; iter: 0; batch classifier loss: 0.410742; batch adversarial loss: 0.497077\n",
      "epoch 158; iter: 0; batch classifier loss: 0.414677; batch adversarial loss: 0.552952\n",
      "epoch 159; iter: 0; batch classifier loss: 0.306724; batch adversarial loss: 0.563722\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384125; batch adversarial loss: 0.554972\n",
      "epoch 161; iter: 0; batch classifier loss: 0.419533; batch adversarial loss: 0.515417\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344007; batch adversarial loss: 0.515915\n",
      "epoch 163; iter: 0; batch classifier loss: 0.333571; batch adversarial loss: 0.478537\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336129; batch adversarial loss: 0.561640\n",
      "epoch 165; iter: 0; batch classifier loss: 0.382478; batch adversarial loss: 0.507575\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380945; batch adversarial loss: 0.601724\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366888; batch adversarial loss: 0.506653\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378729; batch adversarial loss: 0.543910\n",
      "epoch 169; iter: 0; batch classifier loss: 0.449192; batch adversarial loss: 0.433087\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393946; batch adversarial loss: 0.507290\n",
      "epoch 171; iter: 0; batch classifier loss: 0.302965; batch adversarial loss: 0.583080\n",
      "epoch 172; iter: 0; batch classifier loss: 0.277529; batch adversarial loss: 0.563926\n",
      "epoch 173; iter: 0; batch classifier loss: 0.286729; batch adversarial loss: 0.609173\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311048; batch adversarial loss: 0.526352\n",
      "epoch 175; iter: 0; batch classifier loss: 0.353356; batch adversarial loss: 0.479402\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363299; batch adversarial loss: 0.534751\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352946; batch adversarial loss: 0.639025\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357647; batch adversarial loss: 0.618453\n",
      "epoch 179; iter: 0; batch classifier loss: 0.393084; batch adversarial loss: 0.516875\n",
      "epoch 180; iter: 0; batch classifier loss: 0.430541; batch adversarial loss: 0.581429\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332184; batch adversarial loss: 0.478619\n",
      "epoch 182; iter: 0; batch classifier loss: 0.287604; batch adversarial loss: 0.562845\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315669; batch adversarial loss: 0.542599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.303453; batch adversarial loss: 0.564358\n",
      "epoch 185; iter: 0; batch classifier loss: 0.340856; batch adversarial loss: 0.562773\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365705; batch adversarial loss: 0.534364\n",
      "epoch 187; iter: 0; batch classifier loss: 0.266402; batch adversarial loss: 0.563968\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328462; batch adversarial loss: 0.591515\n",
      "epoch 189; iter: 0; batch classifier loss: 0.316489; batch adversarial loss: 0.544234\n",
      "epoch 190; iter: 0; batch classifier loss: 0.447347; batch adversarial loss: 0.507750\n",
      "epoch 191; iter: 0; batch classifier loss: 0.286107; batch adversarial loss: 0.517082\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401568; batch adversarial loss: 0.544040\n",
      "epoch 193; iter: 0; batch classifier loss: 0.290834; batch adversarial loss: 0.591086\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397516; batch adversarial loss: 0.469657\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399492; batch adversarial loss: 0.459535\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332696; batch adversarial loss: 0.601200\n",
      "epoch 197; iter: 0; batch classifier loss: 0.445011; batch adversarial loss: 0.636044\n",
      "epoch 198; iter: 0; batch classifier loss: 0.316747; batch adversarial loss: 0.562771\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319531; batch adversarial loss: 0.562389\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727851; batch adversarial loss: 0.729856\n",
      "epoch 1; iter: 0; batch classifier loss: 0.677036; batch adversarial loss: 0.709789\n",
      "epoch 2; iter: 0; batch classifier loss: 0.628364; batch adversarial loss: 0.659289\n",
      "epoch 3; iter: 0; batch classifier loss: 0.527879; batch adversarial loss: 0.644542\n",
      "epoch 4; iter: 0; batch classifier loss: 0.654068; batch adversarial loss: 0.639298\n",
      "epoch 5; iter: 0; batch classifier loss: 0.520167; batch adversarial loss: 0.619653\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532038; batch adversarial loss: 0.600816\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505026; batch adversarial loss: 0.598383\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573012; batch adversarial loss: 0.661366\n",
      "epoch 9; iter: 0; batch classifier loss: 0.595751; batch adversarial loss: 0.582837\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506592; batch adversarial loss: 0.520684\n",
      "epoch 11; iter: 0; batch classifier loss: 0.595391; batch adversarial loss: 0.565527\n",
      "epoch 12; iter: 0; batch classifier loss: 0.611115; batch adversarial loss: 0.605435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575124; batch adversarial loss: 0.546999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.498603; batch adversarial loss: 0.596386\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491734; batch adversarial loss: 0.575957\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514432; batch adversarial loss: 0.561722\n",
      "epoch 17; iter: 0; batch classifier loss: 0.554371; batch adversarial loss: 0.616320\n",
      "epoch 18; iter: 0; batch classifier loss: 0.430965; batch adversarial loss: 0.556334\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528118; batch adversarial loss: 0.565358\n",
      "epoch 20; iter: 0; batch classifier loss: 0.571822; batch adversarial loss: 0.525851\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487535; batch adversarial loss: 0.523450\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514651; batch adversarial loss: 0.522865\n",
      "epoch 23; iter: 0; batch classifier loss: 0.447365; batch adversarial loss: 0.598184\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477816; batch adversarial loss: 0.501011\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526822; batch adversarial loss: 0.581636\n",
      "epoch 26; iter: 0; batch classifier loss: 0.568710; batch adversarial loss: 0.558194\n",
      "epoch 27; iter: 0; batch classifier loss: 0.524662; batch adversarial loss: 0.546265\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477761; batch adversarial loss: 0.505285\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450759; batch adversarial loss: 0.545854\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404850; batch adversarial loss: 0.600571\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431798; batch adversarial loss: 0.544060\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497819; batch adversarial loss: 0.584540\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421632; batch adversarial loss: 0.545655\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436379; batch adversarial loss: 0.499373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446943; batch adversarial loss: 0.575706\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442833; batch adversarial loss: 0.562063\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446442; batch adversarial loss: 0.602532\n",
      "epoch 38; iter: 0; batch classifier loss: 0.505082; batch adversarial loss: 0.563490\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425316; batch adversarial loss: 0.516880\n",
      "epoch 40; iter: 0; batch classifier loss: 0.530831; batch adversarial loss: 0.571227\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431192; batch adversarial loss: 0.573960\n",
      "epoch 42; iter: 0; batch classifier loss: 0.426838; batch adversarial loss: 0.549793\n",
      "epoch 43; iter: 0; batch classifier loss: 0.404310; batch adversarial loss: 0.471538\n",
      "epoch 44; iter: 0; batch classifier loss: 0.377925; batch adversarial loss: 0.626613\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412913; batch adversarial loss: 0.538594\n",
      "epoch 46; iter: 0; batch classifier loss: 0.453867; batch adversarial loss: 0.564484\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493665; batch adversarial loss: 0.605287\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450582; batch adversarial loss: 0.551001\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447367; batch adversarial loss: 0.507198\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407525; batch adversarial loss: 0.496202\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454372; batch adversarial loss: 0.535761\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475365; batch adversarial loss: 0.526387\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406090; batch adversarial loss: 0.532643\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421256; batch adversarial loss: 0.537027\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378385; batch adversarial loss: 0.542740\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441827; batch adversarial loss: 0.562885\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443505; batch adversarial loss: 0.582007\n",
      "epoch 58; iter: 0; batch classifier loss: 0.343929; batch adversarial loss: 0.581912\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424086; batch adversarial loss: 0.561164\n",
      "epoch 60; iter: 0; batch classifier loss: 0.476432; batch adversarial loss: 0.653494\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442256; batch adversarial loss: 0.627601\n",
      "epoch 62; iter: 0; batch classifier loss: 0.489294; batch adversarial loss: 0.497598\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396539; batch adversarial loss: 0.584560\n",
      "epoch 64; iter: 0; batch classifier loss: 0.468536; batch adversarial loss: 0.555998\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443656; batch adversarial loss: 0.581003\n",
      "epoch 66; iter: 0; batch classifier loss: 0.368622; batch adversarial loss: 0.524768\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372893; batch adversarial loss: 0.588420\n",
      "epoch 68; iter: 0; batch classifier loss: 0.440856; batch adversarial loss: 0.563555\n",
      "epoch 69; iter: 0; batch classifier loss: 0.455335; batch adversarial loss: 0.563554\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402562; batch adversarial loss: 0.581344\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425909; batch adversarial loss: 0.460928\n",
      "epoch 72; iter: 0; batch classifier loss: 0.407738; batch adversarial loss: 0.535024\n",
      "epoch 73; iter: 0; batch classifier loss: 0.436785; batch adversarial loss: 0.545860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390426; batch adversarial loss: 0.478449\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403281; batch adversarial loss: 0.581352\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376297; batch adversarial loss: 0.443509\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375767; batch adversarial loss: 0.518178\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390310; batch adversarial loss: 0.562806\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383889; batch adversarial loss: 0.544313\n",
      "epoch 80; iter: 0; batch classifier loss: 0.521421; batch adversarial loss: 0.462206\n",
      "epoch 81; iter: 0; batch classifier loss: 0.465556; batch adversarial loss: 0.508848\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416058; batch adversarial loss: 0.499742\n",
      "epoch 83; iter: 0; batch classifier loss: 0.393049; batch adversarial loss: 0.527319\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409504; batch adversarial loss: 0.599721\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350027; batch adversarial loss: 0.571020\n",
      "epoch 86; iter: 0; batch classifier loss: 0.423435; batch adversarial loss: 0.610020\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398761; batch adversarial loss: 0.583463\n",
      "epoch 88; iter: 0; batch classifier loss: 0.312909; batch adversarial loss: 0.562858\n",
      "epoch 89; iter: 0; batch classifier loss: 0.441294; batch adversarial loss: 0.571790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.445163; batch adversarial loss: 0.526345\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397461; batch adversarial loss: 0.533188\n",
      "epoch 92; iter: 0; batch classifier loss: 0.443019; batch adversarial loss: 0.535324\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412208; batch adversarial loss: 0.487909\n",
      "epoch 94; iter: 0; batch classifier loss: 0.440224; batch adversarial loss: 0.561332\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442987; batch adversarial loss: 0.536754\n",
      "epoch 96; iter: 0; batch classifier loss: 0.404116; batch adversarial loss: 0.545722\n",
      "epoch 97; iter: 0; batch classifier loss: 0.544275; batch adversarial loss: 0.553315\n",
      "epoch 98; iter: 0; batch classifier loss: 0.399766; batch adversarial loss: 0.518160\n",
      "epoch 99; iter: 0; batch classifier loss: 0.508122; batch adversarial loss: 0.543514\n",
      "epoch 100; iter: 0; batch classifier loss: 0.407890; batch adversarial loss: 0.573971\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401777; batch adversarial loss: 0.524485\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416424; batch adversarial loss: 0.608966\n",
      "epoch 103; iter: 0; batch classifier loss: 0.347179; batch adversarial loss: 0.505822\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416659; batch adversarial loss: 0.480378\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411135; batch adversarial loss: 0.553521\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350477; batch adversarial loss: 0.453206\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354090; batch adversarial loss: 0.451848\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413008; batch adversarial loss: 0.555457\n",
      "epoch 109; iter: 0; batch classifier loss: 0.431524; batch adversarial loss: 0.542517\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429589; batch adversarial loss: 0.525789\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403784; batch adversarial loss: 0.543402\n",
      "epoch 112; iter: 0; batch classifier loss: 0.321712; batch adversarial loss: 0.618054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.404089; batch adversarial loss: 0.553551\n",
      "epoch 114; iter: 0; batch classifier loss: 0.441825; batch adversarial loss: 0.481273\n",
      "epoch 115; iter: 0; batch classifier loss: 0.395457; batch adversarial loss: 0.599383\n",
      "epoch 116; iter: 0; batch classifier loss: 0.454113; batch adversarial loss: 0.618780\n",
      "epoch 117; iter: 0; batch classifier loss: 0.420484; batch adversarial loss: 0.553829\n",
      "epoch 118; iter: 0; batch classifier loss: 0.321671; batch adversarial loss: 0.592085\n",
      "epoch 119; iter: 0; batch classifier loss: 0.449178; batch adversarial loss: 0.544857\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374080; batch adversarial loss: 0.525617\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375053; batch adversarial loss: 0.589907\n",
      "epoch 122; iter: 0; batch classifier loss: 0.305684; batch adversarial loss: 0.608107\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394893; batch adversarial loss: 0.545176\n",
      "epoch 124; iter: 0; batch classifier loss: 0.388666; batch adversarial loss: 0.581051\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402973; batch adversarial loss: 0.499988\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379754; batch adversarial loss: 0.580868\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374653; batch adversarial loss: 0.572629\n",
      "epoch 128; iter: 0; batch classifier loss: 0.319993; batch adversarial loss: 0.433604\n",
      "epoch 129; iter: 0; batch classifier loss: 0.442222; batch adversarial loss: 0.562176\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371793; batch adversarial loss: 0.535188\n",
      "epoch 131; iter: 0; batch classifier loss: 0.486177; batch adversarial loss: 0.552954\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382122; batch adversarial loss: 0.582202\n",
      "epoch 133; iter: 0; batch classifier loss: 0.443384; batch adversarial loss: 0.544734\n",
      "epoch 134; iter: 0; batch classifier loss: 0.451832; batch adversarial loss: 0.552668\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365074; batch adversarial loss: 0.590975\n",
      "epoch 136; iter: 0; batch classifier loss: 0.356203; batch adversarial loss: 0.580530\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366752; batch adversarial loss: 0.610538\n",
      "epoch 138; iter: 0; batch classifier loss: 0.478053; batch adversarial loss: 0.506244\n",
      "epoch 139; iter: 0; batch classifier loss: 0.431872; batch adversarial loss: 0.507417\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357626; batch adversarial loss: 0.480570\n",
      "epoch 141; iter: 0; batch classifier loss: 0.489869; batch adversarial loss: 0.590830\n",
      "epoch 142; iter: 0; batch classifier loss: 0.352513; batch adversarial loss: 0.570894\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406477; batch adversarial loss: 0.600969\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398072; batch adversarial loss: 0.600286\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359831; batch adversarial loss: 0.644854\n",
      "epoch 146; iter: 0; batch classifier loss: 0.356988; batch adversarial loss: 0.442521\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373073; batch adversarial loss: 0.499242\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395466; batch adversarial loss: 0.508114\n",
      "epoch 149; iter: 0; batch classifier loss: 0.360548; batch adversarial loss: 0.564657\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371395; batch adversarial loss: 0.505744\n",
      "epoch 151; iter: 0; batch classifier loss: 0.414792; batch adversarial loss: 0.636919\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350613; batch adversarial loss: 0.599416\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366062; batch adversarial loss: 0.469977\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393641; batch adversarial loss: 0.507786\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359879; batch adversarial loss: 0.499592\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355410; batch adversarial loss: 0.544916\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361570; batch adversarial loss: 0.581329\n",
      "epoch 158; iter: 0; batch classifier loss: 0.436235; batch adversarial loss: 0.552728\n",
      "epoch 159; iter: 0; batch classifier loss: 0.418042; batch adversarial loss: 0.489136\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323456; batch adversarial loss: 0.534377\n",
      "epoch 161; iter: 0; batch classifier loss: 0.360486; batch adversarial loss: 0.619267\n",
      "epoch 162; iter: 0; batch classifier loss: 0.472703; batch adversarial loss: 0.609328\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386610; batch adversarial loss: 0.507599\n",
      "epoch 164; iter: 0; batch classifier loss: 0.317816; batch adversarial loss: 0.534798\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389644; batch adversarial loss: 0.526051\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332909; batch adversarial loss: 0.601409\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332839; batch adversarial loss: 0.638503\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401794; batch adversarial loss: 0.525368\n",
      "epoch 169; iter: 0; batch classifier loss: 0.340219; batch adversarial loss: 0.507345\n",
      "epoch 170; iter: 0; batch classifier loss: 0.411957; batch adversarial loss: 0.508123\n",
      "epoch 171; iter: 0; batch classifier loss: 0.422107; batch adversarial loss: 0.654844\n",
      "epoch 172; iter: 0; batch classifier loss: 0.451222; batch adversarial loss: 0.470494\n",
      "epoch 173; iter: 0; batch classifier loss: 0.434533; batch adversarial loss: 0.526338\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343203; batch adversarial loss: 0.489121\n",
      "epoch 175; iter: 0; batch classifier loss: 0.453343; batch adversarial loss: 0.552316\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308641; batch adversarial loss: 0.517597\n",
      "epoch 177; iter: 0; batch classifier loss: 0.348355; batch adversarial loss: 0.591407\n",
      "epoch 178; iter: 0; batch classifier loss: 0.398072; batch adversarial loss: 0.497205\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368766; batch adversarial loss: 0.524886\n",
      "epoch 180; iter: 0; batch classifier loss: 0.446126; batch adversarial loss: 0.620876\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420275; batch adversarial loss: 0.551736\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336339; batch adversarial loss: 0.509090\n",
      "epoch 183; iter: 0; batch classifier loss: 0.425505; batch adversarial loss: 0.507519\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378314; batch adversarial loss: 0.610226\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389790; batch adversarial loss: 0.571526\n",
      "epoch 186; iter: 0; batch classifier loss: 0.411121; batch adversarial loss: 0.572782\n",
      "epoch 187; iter: 0; batch classifier loss: 0.324774; batch adversarial loss: 0.561774\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311712; batch adversarial loss: 0.526913\n",
      "epoch 189; iter: 0; batch classifier loss: 0.337290; batch adversarial loss: 0.526144\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368605; batch adversarial loss: 0.589869\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378788; batch adversarial loss: 0.590754\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351995; batch adversarial loss: 0.554320\n",
      "epoch 193; iter: 0; batch classifier loss: 0.454593; batch adversarial loss: 0.572446\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357194; batch adversarial loss: 0.515198\n",
      "epoch 195; iter: 0; batch classifier loss: 0.396333; batch adversarial loss: 0.581066\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313547; batch adversarial loss: 0.580109\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356995; batch adversarial loss: 0.571743\n",
      "epoch 198; iter: 0; batch classifier loss: 0.364437; batch adversarial loss: 0.542280\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334477; batch adversarial loss: 0.581313\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772599; batch adversarial loss: 0.703082\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604272; batch adversarial loss: 0.670343\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616282; batch adversarial loss: 0.636652\n",
      "epoch 3; iter: 0; batch classifier loss: 0.606763; batch adversarial loss: 0.638343\n",
      "epoch 4; iter: 0; batch classifier loss: 0.556873; batch adversarial loss: 0.607366\n",
      "epoch 5; iter: 0; batch classifier loss: 0.535561; batch adversarial loss: 0.610149\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535620; batch adversarial loss: 0.595282\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542636; batch adversarial loss: 0.577041\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572181; batch adversarial loss: 0.635590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.507164; batch adversarial loss: 0.560833\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523002; batch adversarial loss: 0.548118\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504253; batch adversarial loss: 0.579097\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503009; batch adversarial loss: 0.588947\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560895; batch adversarial loss: 0.586544\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547304; batch adversarial loss: 0.523693\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474022; batch adversarial loss: 0.604767\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498009; batch adversarial loss: 0.622650\n",
      "epoch 17; iter: 0; batch classifier loss: 0.476396; batch adversarial loss: 0.559538\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522071; batch adversarial loss: 0.652411\n",
      "epoch 19; iter: 0; batch classifier loss: 0.544402; batch adversarial loss: 0.559212\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474860; batch adversarial loss: 0.537638\n",
      "epoch 21; iter: 0; batch classifier loss: 0.566176; batch adversarial loss: 0.572269\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549115; batch adversarial loss: 0.605039\n",
      "epoch 23; iter: 0; batch classifier loss: 0.416382; batch adversarial loss: 0.557898\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446484; batch adversarial loss: 0.559695\n",
      "epoch 25; iter: 0; batch classifier loss: 0.403506; batch adversarial loss: 0.540639\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439009; batch adversarial loss: 0.573474\n",
      "epoch 27; iter: 0; batch classifier loss: 0.411027; batch adversarial loss: 0.499781\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418587; batch adversarial loss: 0.572981\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439274; batch adversarial loss: 0.564604\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450505; batch adversarial loss: 0.496009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.502156; batch adversarial loss: 0.503316\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490631; batch adversarial loss: 0.486686\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400099; batch adversarial loss: 0.569620\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449905; batch adversarial loss: 0.526891\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445338; batch adversarial loss: 0.510088\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492417; batch adversarial loss: 0.579838\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449707; batch adversarial loss: 0.561983\n",
      "epoch 38; iter: 0; batch classifier loss: 0.545932; batch adversarial loss: 0.563518\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436601; batch adversarial loss: 0.607074\n",
      "epoch 40; iter: 0; batch classifier loss: 0.504615; batch adversarial loss: 0.526238\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426341; batch adversarial loss: 0.598221\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434561; batch adversarial loss: 0.590633\n",
      "epoch 43; iter: 0; batch classifier loss: 0.466840; batch adversarial loss: 0.581771\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455298; batch adversarial loss: 0.509024\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473458; batch adversarial loss: 0.535749\n",
      "epoch 46; iter: 0; batch classifier loss: 0.473340; batch adversarial loss: 0.553962\n",
      "epoch 47; iter: 0; batch classifier loss: 0.359748; batch adversarial loss: 0.544935\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381452; batch adversarial loss: 0.524069\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433420; batch adversarial loss: 0.566859\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422288; batch adversarial loss: 0.570565\n",
      "epoch 51; iter: 0; batch classifier loss: 0.365852; batch adversarial loss: 0.588691\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417100; batch adversarial loss: 0.599460\n",
      "epoch 53; iter: 0; batch classifier loss: 0.482861; batch adversarial loss: 0.516430\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416021; batch adversarial loss: 0.509505\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407122; batch adversarial loss: 0.451600\n",
      "epoch 56; iter: 0; batch classifier loss: 0.520842; batch adversarial loss: 0.591917\n",
      "epoch 57; iter: 0; batch classifier loss: 0.373893; batch adversarial loss: 0.535042\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378505; batch adversarial loss: 0.544443\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428709; batch adversarial loss: 0.572396\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389690; batch adversarial loss: 0.589964\n",
      "epoch 61; iter: 0; batch classifier loss: 0.530175; batch adversarial loss: 0.553472\n",
      "epoch 62; iter: 0; batch classifier loss: 0.516442; batch adversarial loss: 0.562446\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433611; batch adversarial loss: 0.499107\n",
      "epoch 64; iter: 0; batch classifier loss: 0.374477; batch adversarial loss: 0.608348\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409439; batch adversarial loss: 0.544219\n",
      "epoch 66; iter: 0; batch classifier loss: 0.506073; batch adversarial loss: 0.534992\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409809; batch adversarial loss: 0.545138\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388389; batch adversarial loss: 0.499283\n",
      "epoch 69; iter: 0; batch classifier loss: 0.327072; batch adversarial loss: 0.589726\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424223; batch adversarial loss: 0.616825\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391861; batch adversarial loss: 0.481417\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422960; batch adversarial loss: 0.490375\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405388; batch adversarial loss: 0.580924\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385762; batch adversarial loss: 0.588982\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375319; batch adversarial loss: 0.472009\n",
      "epoch 76; iter: 0; batch classifier loss: 0.401559; batch adversarial loss: 0.553561\n",
      "epoch 77; iter: 0; batch classifier loss: 0.461341; batch adversarial loss: 0.579906\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352212; batch adversarial loss: 0.490219\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413390; batch adversarial loss: 0.562572\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470292; batch adversarial loss: 0.508384\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408942; batch adversarial loss: 0.590684\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420700; batch adversarial loss: 0.554549\n",
      "epoch 83; iter: 0; batch classifier loss: 0.455200; batch adversarial loss: 0.644625\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390841; batch adversarial loss: 0.572446\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414264; batch adversarial loss: 0.526793\n",
      "epoch 86; iter: 0; batch classifier loss: 0.439168; batch adversarial loss: 0.554137\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412802; batch adversarial loss: 0.590294\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382257; batch adversarial loss: 0.563046\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400071; batch adversarial loss: 0.607682\n",
      "epoch 90; iter: 0; batch classifier loss: 0.449835; batch adversarial loss: 0.553694\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366348; batch adversarial loss: 0.526344\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377603; batch adversarial loss: 0.480707\n",
      "epoch 93; iter: 0; batch classifier loss: 0.435531; batch adversarial loss: 0.571273\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371899; batch adversarial loss: 0.552983\n",
      "epoch 95; iter: 0; batch classifier loss: 0.356784; batch adversarial loss: 0.544830\n",
      "epoch 96; iter: 0; batch classifier loss: 0.488459; batch adversarial loss: 0.507964\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366416; batch adversarial loss: 0.507299\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404466; batch adversarial loss: 0.507593\n",
      "epoch 99; iter: 0; batch classifier loss: 0.421845; batch adversarial loss: 0.526049\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393603; batch adversarial loss: 0.499005\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386321; batch adversarial loss: 0.561800\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399207; batch adversarial loss: 0.526061\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367172; batch adversarial loss: 0.618240\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413332; batch adversarial loss: 0.480127\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432750; batch adversarial loss: 0.526255\n",
      "epoch 106; iter: 0; batch classifier loss: 0.400040; batch adversarial loss: 0.589777\n",
      "epoch 107; iter: 0; batch classifier loss: 0.471268; batch adversarial loss: 0.580164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.369806; batch adversarial loss: 0.599217\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347535; batch adversarial loss: 0.488474\n",
      "epoch 110; iter: 0; batch classifier loss: 0.452309; batch adversarial loss: 0.572884\n",
      "epoch 111; iter: 0; batch classifier loss: 0.435846; batch adversarial loss: 0.553023\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398383; batch adversarial loss: 0.507592\n",
      "epoch 113; iter: 0; batch classifier loss: 0.481070; batch adversarial loss: 0.499118\n",
      "epoch 114; iter: 0; batch classifier loss: 0.406763; batch adversarial loss: 0.618136\n",
      "epoch 115; iter: 0; batch classifier loss: 0.432112; batch adversarial loss: 0.535133\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384126; batch adversarial loss: 0.546273\n",
      "epoch 117; iter: 0; batch classifier loss: 0.315305; batch adversarial loss: 0.463296\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378563; batch adversarial loss: 0.498287\n",
      "epoch 119; iter: 0; batch classifier loss: 0.434513; batch adversarial loss: 0.626699\n",
      "epoch 120; iter: 0; batch classifier loss: 0.317803; batch adversarial loss: 0.544545\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412888; batch adversarial loss: 0.580892\n",
      "epoch 122; iter: 0; batch classifier loss: 0.370777; batch adversarial loss: 0.534335\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348253; batch adversarial loss: 0.508863\n",
      "epoch 124; iter: 0; batch classifier loss: 0.313730; batch adversarial loss: 0.498802\n",
      "epoch 125; iter: 0; batch classifier loss: 0.312813; batch adversarial loss: 0.544300\n",
      "epoch 126; iter: 0; batch classifier loss: 0.546288; batch adversarial loss: 0.536032\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367486; batch adversarial loss: 0.544667\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422983; batch adversarial loss: 0.498804\n",
      "epoch 129; iter: 0; batch classifier loss: 0.454571; batch adversarial loss: 0.571887\n",
      "epoch 130; iter: 0; batch classifier loss: 0.309306; batch adversarial loss: 0.635426\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399669; batch adversarial loss: 0.480428\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360212; batch adversarial loss: 0.507424\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385633; batch adversarial loss: 0.570238\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394569; batch adversarial loss: 0.536415\n",
      "epoch 135; iter: 0; batch classifier loss: 0.419599; batch adversarial loss: 0.526262\n",
      "epoch 136; iter: 0; batch classifier loss: 0.272190; batch adversarial loss: 0.535830\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402487; batch adversarial loss: 0.526026\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384073; batch adversarial loss: 0.516911\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408013; batch adversarial loss: 0.507741\n",
      "epoch 140; iter: 0; batch classifier loss: 0.392300; batch adversarial loss: 0.516999\n",
      "epoch 141; iter: 0; batch classifier loss: 0.393331; batch adversarial loss: 0.517229\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354533; batch adversarial loss: 0.535628\n",
      "epoch 143; iter: 0; batch classifier loss: 0.427988; batch adversarial loss: 0.562704\n",
      "epoch 144; iter: 0; batch classifier loss: 0.410990; batch adversarial loss: 0.526278\n",
      "epoch 145; iter: 0; batch classifier loss: 0.393965; batch adversarial loss: 0.563039\n",
      "epoch 146; iter: 0; batch classifier loss: 0.315493; batch adversarial loss: 0.544824\n",
      "epoch 147; iter: 0; batch classifier loss: 0.481133; batch adversarial loss: 0.498495\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342712; batch adversarial loss: 0.607979\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351604; batch adversarial loss: 0.453193\n",
      "epoch 150; iter: 0; batch classifier loss: 0.386078; batch adversarial loss: 0.535678\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338733; batch adversarial loss: 0.480581\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347423; batch adversarial loss: 0.599180\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379180; batch adversarial loss: 0.526360\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393397; batch adversarial loss: 0.499392\n",
      "epoch 155; iter: 0; batch classifier loss: 0.426565; batch adversarial loss: 0.517446\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366990; batch adversarial loss: 0.645333\n",
      "epoch 157; iter: 0; batch classifier loss: 0.423799; batch adversarial loss: 0.563061\n",
      "epoch 158; iter: 0; batch classifier loss: 0.439226; batch adversarial loss: 0.553274\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366778; batch adversarial loss: 0.581084\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356334; batch adversarial loss: 0.563337\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311219; batch adversarial loss: 0.489317\n",
      "epoch 162; iter: 0; batch classifier loss: 0.511605; batch adversarial loss: 0.490734\n",
      "epoch 163; iter: 0; batch classifier loss: 0.400459; batch adversarial loss: 0.499258\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375531; batch adversarial loss: 0.563011\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356892; batch adversarial loss: 0.490074\n",
      "epoch 166; iter: 0; batch classifier loss: 0.467241; batch adversarial loss: 0.553864\n",
      "epoch 167; iter: 0; batch classifier loss: 0.445222; batch adversarial loss: 0.545286\n",
      "epoch 168; iter: 0; batch classifier loss: 0.421802; batch adversarial loss: 0.490273\n",
      "epoch 169; iter: 0; batch classifier loss: 0.492189; batch adversarial loss: 0.571829\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322022; batch adversarial loss: 0.525945\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348964; batch adversarial loss: 0.589700\n",
      "epoch 172; iter: 0; batch classifier loss: 0.315316; batch adversarial loss: 0.554031\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360735; batch adversarial loss: 0.544632\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351330; batch adversarial loss: 0.626870\n",
      "epoch 175; iter: 0; batch classifier loss: 0.403879; batch adversarial loss: 0.553044\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346219; batch adversarial loss: 0.508282\n",
      "epoch 177; iter: 0; batch classifier loss: 0.373788; batch adversarial loss: 0.471206\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335779; batch adversarial loss: 0.571280\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340287; batch adversarial loss: 0.553422\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390894; batch adversarial loss: 0.489474\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332077; batch adversarial loss: 0.526715\n",
      "epoch 182; iter: 0; batch classifier loss: 0.396476; batch adversarial loss: 0.554053\n",
      "epoch 183; iter: 0; batch classifier loss: 0.394014; batch adversarial loss: 0.581225\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370044; batch adversarial loss: 0.581430\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384973; batch adversarial loss: 0.599182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347228; batch adversarial loss: 0.481069\n",
      "epoch 187; iter: 0; batch classifier loss: 0.273910; batch adversarial loss: 0.572313\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365280; batch adversarial loss: 0.544777\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382240; batch adversarial loss: 0.580789\n",
      "epoch 190; iter: 0; batch classifier loss: 0.282355; batch adversarial loss: 0.453963\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356053; batch adversarial loss: 0.472280\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363914; batch adversarial loss: 0.499350\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338752; batch adversarial loss: 0.462286\n",
      "epoch 194; iter: 0; batch classifier loss: 0.285525; batch adversarial loss: 0.535122\n",
      "epoch 195; iter: 0; batch classifier loss: 0.307729; batch adversarial loss: 0.553537\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364752; batch adversarial loss: 0.543979\n",
      "epoch 197; iter: 0; batch classifier loss: 0.328497; batch adversarial loss: 0.535475\n",
      "epoch 198; iter: 0; batch classifier loss: 0.442753; batch adversarial loss: 0.472099\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385609; batch adversarial loss: 0.526023\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680199; batch adversarial loss: 0.881544\n",
      "epoch 1; iter: 0; batch classifier loss: 0.908412; batch adversarial loss: 1.108194\n",
      "epoch 2; iter: 0; batch classifier loss: 1.090430; batch adversarial loss: 1.049121\n",
      "epoch 3; iter: 0; batch classifier loss: 0.959591; batch adversarial loss: 0.956782\n",
      "epoch 4; iter: 0; batch classifier loss: 1.093592; batch adversarial loss: 0.911554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.941652; batch adversarial loss: 0.807495\n",
      "epoch 6; iter: 0; batch classifier loss: 0.912442; batch adversarial loss: 0.779208\n",
      "epoch 7; iter: 0; batch classifier loss: 0.798940; batch adversarial loss: 0.721467\n",
      "epoch 8; iter: 0; batch classifier loss: 0.736925; batch adversarial loss: 0.664316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.614637; batch adversarial loss: 0.602040\n",
      "epoch 10; iter: 0; batch classifier loss: 0.586598; batch adversarial loss: 0.562011\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548010; batch adversarial loss: 0.615895\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531958; batch adversarial loss: 0.591472\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539571; batch adversarial loss: 0.600721\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540680; batch adversarial loss: 0.570438\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512321; batch adversarial loss: 0.550356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506942; batch adversarial loss: 0.619045\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516233; batch adversarial loss: 0.569308\n",
      "epoch 18; iter: 0; batch classifier loss: 0.570400; batch adversarial loss: 0.535800\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536734; batch adversarial loss: 0.584930\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456131; batch adversarial loss: 0.597063\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468064; batch adversarial loss: 0.588627\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529054; batch adversarial loss: 0.586161\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516094; batch adversarial loss: 0.534088\n",
      "epoch 24; iter: 0; batch classifier loss: 0.578126; batch adversarial loss: 0.544066\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471684; batch adversarial loss: 0.639879\n",
      "epoch 26; iter: 0; batch classifier loss: 0.426822; batch adversarial loss: 0.525957\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437364; batch adversarial loss: 0.564941\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490069; batch adversarial loss: 0.531695\n",
      "epoch 29; iter: 0; batch classifier loss: 0.491202; batch adversarial loss: 0.661115\n",
      "epoch 30; iter: 0; batch classifier loss: 0.492937; batch adversarial loss: 0.583403\n",
      "epoch 31; iter: 0; batch classifier loss: 0.511388; batch adversarial loss: 0.576009\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410603; batch adversarial loss: 0.562566\n",
      "epoch 33; iter: 0; batch classifier loss: 0.493494; batch adversarial loss: 0.569446\n",
      "epoch 34; iter: 0; batch classifier loss: 0.547443; batch adversarial loss: 0.634009\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491464; batch adversarial loss: 0.521441\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410820; batch adversarial loss: 0.535989\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465273; batch adversarial loss: 0.625877\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442494; batch adversarial loss: 0.558927\n",
      "epoch 39; iter: 0; batch classifier loss: 0.551012; batch adversarial loss: 0.447086\n",
      "epoch 40; iter: 0; batch classifier loss: 0.489688; batch adversarial loss: 0.576791\n",
      "epoch 41; iter: 0; batch classifier loss: 0.400497; batch adversarial loss: 0.523937\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445840; batch adversarial loss: 0.595649\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470917; batch adversarial loss: 0.605690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455255; batch adversarial loss: 0.582281\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407069; batch adversarial loss: 0.548528\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422313; batch adversarial loss: 0.592451\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426878; batch adversarial loss: 0.500899\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431659; batch adversarial loss: 0.513656\n",
      "epoch 49; iter: 0; batch classifier loss: 0.461731; batch adversarial loss: 0.524701\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428268; batch adversarial loss: 0.497565\n",
      "epoch 51; iter: 0; batch classifier loss: 0.489923; batch adversarial loss: 0.524831\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385641; batch adversarial loss: 0.568610\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443408; batch adversarial loss: 0.607531\n",
      "epoch 54; iter: 0; batch classifier loss: 0.354706; batch adversarial loss: 0.509980\n",
      "epoch 55; iter: 0; batch classifier loss: 0.495787; batch adversarial loss: 0.511845\n",
      "epoch 56; iter: 0; batch classifier loss: 0.369591; batch adversarial loss: 0.608976\n",
      "epoch 57; iter: 0; batch classifier loss: 0.319561; batch adversarial loss: 0.563130\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409156; batch adversarial loss: 0.589756\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427714; batch adversarial loss: 0.524781\n",
      "epoch 60; iter: 0; batch classifier loss: 0.448375; batch adversarial loss: 0.538528\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416502; batch adversarial loss: 0.601753\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414332; batch adversarial loss: 0.537034\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409179; batch adversarial loss: 0.499195\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419762; batch adversarial loss: 0.598202\n",
      "epoch 65; iter: 0; batch classifier loss: 0.360921; batch adversarial loss: 0.553841\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378154; batch adversarial loss: 0.489646\n",
      "epoch 67; iter: 0; batch classifier loss: 0.330393; batch adversarial loss: 0.524441\n",
      "epoch 68; iter: 0; batch classifier loss: 0.385053; batch adversarial loss: 0.556311\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373688; batch adversarial loss: 0.546272\n",
      "epoch 70; iter: 0; batch classifier loss: 0.338105; batch adversarial loss: 0.542172\n",
      "epoch 71; iter: 0; batch classifier loss: 0.469308; batch adversarial loss: 0.580681\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381338; batch adversarial loss: 0.607445\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395023; batch adversarial loss: 0.587804\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381314; batch adversarial loss: 0.535576\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380228; batch adversarial loss: 0.574429\n",
      "epoch 76; iter: 0; batch classifier loss: 0.436328; batch adversarial loss: 0.562347\n",
      "epoch 77; iter: 0; batch classifier loss: 0.338127; batch adversarial loss: 0.543986\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393738; batch adversarial loss: 0.505817\n",
      "epoch 79; iter: 0; batch classifier loss: 0.364824; batch adversarial loss: 0.570991\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407447; batch adversarial loss: 0.557740\n",
      "epoch 81; iter: 0; batch classifier loss: 0.438334; batch adversarial loss: 0.589541\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376556; batch adversarial loss: 0.527165\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345763; batch adversarial loss: 0.572795\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374301; batch adversarial loss: 0.465720\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385585; batch adversarial loss: 0.561912\n",
      "epoch 86; iter: 0; batch classifier loss: 0.304862; batch adversarial loss: 0.562193\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376028; batch adversarial loss: 0.589600\n",
      "epoch 88; iter: 0; batch classifier loss: 0.361445; batch adversarial loss: 0.492045\n",
      "epoch 89; iter: 0; batch classifier loss: 0.290980; batch adversarial loss: 0.553647\n",
      "epoch 90; iter: 0; batch classifier loss: 0.536673; batch adversarial loss: 0.598901\n",
      "epoch 91; iter: 0; batch classifier loss: 0.328457; batch adversarial loss: 0.544134\n",
      "epoch 92; iter: 0; batch classifier loss: 0.477348; batch adversarial loss: 0.563712\n",
      "epoch 93; iter: 0; batch classifier loss: 0.354353; batch adversarial loss: 0.518138\n",
      "epoch 94; iter: 0; batch classifier loss: 0.359898; batch adversarial loss: 0.533996\n",
      "epoch 95; iter: 0; batch classifier loss: 0.323348; batch adversarial loss: 0.563175\n",
      "epoch 96; iter: 0; batch classifier loss: 0.457615; batch adversarial loss: 0.537058\n",
      "epoch 97; iter: 0; batch classifier loss: 0.272030; batch adversarial loss: 0.588598\n",
      "epoch 98; iter: 0; batch classifier loss: 0.343255; batch adversarial loss: 0.608600\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419785; batch adversarial loss: 0.515941\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408822; batch adversarial loss: 0.599456\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421709; batch adversarial loss: 0.535344\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379887; batch adversarial loss: 0.643636\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402437; batch adversarial loss: 0.518468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.360249; batch adversarial loss: 0.580556\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347064; batch adversarial loss: 0.463614\n",
      "epoch 106; iter: 0; batch classifier loss: 0.414250; batch adversarial loss: 0.553565\n",
      "epoch 107; iter: 0; batch classifier loss: 0.315156; batch adversarial loss: 0.553022\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362172; batch adversarial loss: 0.599042\n",
      "epoch 109; iter: 0; batch classifier loss: 0.329223; batch adversarial loss: 0.634561\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351873; batch adversarial loss: 0.553559\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376135; batch adversarial loss: 0.572217\n",
      "epoch 112; iter: 0; batch classifier loss: 0.345625; batch adversarial loss: 0.553239\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353983; batch adversarial loss: 0.527293\n",
      "epoch 114; iter: 0; batch classifier loss: 0.330520; batch adversarial loss: 0.553811\n",
      "epoch 115; iter: 0; batch classifier loss: 0.428192; batch adversarial loss: 0.527082\n",
      "epoch 116; iter: 0; batch classifier loss: 0.418010; batch adversarial loss: 0.625484\n",
      "epoch 117; iter: 0; batch classifier loss: 0.397860; batch adversarial loss: 0.526938\n",
      "epoch 118; iter: 0; batch classifier loss: 0.456946; batch adversarial loss: 0.580522\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423570; batch adversarial loss: 0.589961\n",
      "epoch 120; iter: 0; batch classifier loss: 0.412530; batch adversarial loss: 0.472694\n",
      "epoch 121; iter: 0; batch classifier loss: 0.331335; batch adversarial loss: 0.563899\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417855; batch adversarial loss: 0.551632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373293; batch adversarial loss: 0.526455\n",
      "epoch 124; iter: 0; batch classifier loss: 0.362135; batch adversarial loss: 0.589146\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342121; batch adversarial loss: 0.553811\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323190; batch adversarial loss: 0.536117\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340778; batch adversarial loss: 0.516556\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403018; batch adversarial loss: 0.570502\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347723; batch adversarial loss: 0.572085\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374388; batch adversarial loss: 0.553169\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363429; batch adversarial loss: 0.580641\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384323; batch adversarial loss: 0.500447\n",
      "epoch 133; iter: 0; batch classifier loss: 0.404227; batch adversarial loss: 0.563418\n",
      "epoch 134; iter: 0; batch classifier loss: 0.430399; batch adversarial loss: 0.660450\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360622; batch adversarial loss: 0.562504\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328544; batch adversarial loss: 0.589754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351178; batch adversarial loss: 0.553282\n",
      "epoch 138; iter: 0; batch classifier loss: 0.423426; batch adversarial loss: 0.607790\n",
      "epoch 139; iter: 0; batch classifier loss: 0.353396; batch adversarial loss: 0.491576\n",
      "epoch 140; iter: 0; batch classifier loss: 0.344083; batch adversarial loss: 0.581415\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348080; batch adversarial loss: 0.591324\n",
      "epoch 142; iter: 0; batch classifier loss: 0.431609; batch adversarial loss: 0.607526\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367919; batch adversarial loss: 0.562578\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389352; batch adversarial loss: 0.562548\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323400; batch adversarial loss: 0.517827\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381468; batch adversarial loss: 0.544046\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363315; batch adversarial loss: 0.580586\n",
      "epoch 148; iter: 0; batch classifier loss: 0.300001; batch adversarial loss: 0.491247\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334418; batch adversarial loss: 0.508783\n",
      "epoch 150; iter: 0; batch classifier loss: 0.343932; batch adversarial loss: 0.570943\n",
      "epoch 151; iter: 0; batch classifier loss: 0.292594; batch adversarial loss: 0.651575\n",
      "epoch 152; iter: 0; batch classifier loss: 0.417446; batch adversarial loss: 0.536215\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355120; batch adversarial loss: 0.563085\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335495; batch adversarial loss: 0.562585\n",
      "epoch 155; iter: 0; batch classifier loss: 0.432106; batch adversarial loss: 0.707459\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340398; batch adversarial loss: 0.507389\n",
      "epoch 157; iter: 0; batch classifier loss: 0.317280; batch adversarial loss: 0.590328\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388807; batch adversarial loss: 0.563208\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349761; batch adversarial loss: 0.482754\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339354; batch adversarial loss: 0.527052\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334828; batch adversarial loss: 0.571502\n",
      "epoch 162; iter: 0; batch classifier loss: 0.399268; batch adversarial loss: 0.517736\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326934; batch adversarial loss: 0.526339\n",
      "epoch 164; iter: 0; batch classifier loss: 0.296335; batch adversarial loss: 0.534830\n",
      "epoch 165; iter: 0; batch classifier loss: 0.323077; batch adversarial loss: 0.509128\n",
      "epoch 166; iter: 0; batch classifier loss: 0.444412; batch adversarial loss: 0.561961\n",
      "epoch 167; iter: 0; batch classifier loss: 0.303605; batch adversarial loss: 0.508450\n",
      "epoch 168; iter: 0; batch classifier loss: 0.283721; batch adversarial loss: 0.525875\n",
      "epoch 169; iter: 0; batch classifier loss: 0.236974; batch adversarial loss: 0.544082\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346869; batch adversarial loss: 0.472901\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323133; batch adversarial loss: 0.481066\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374102; batch adversarial loss: 0.498972\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359608; batch adversarial loss: 0.543684\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360862; batch adversarial loss: 0.581386\n",
      "epoch 175; iter: 0; batch classifier loss: 0.361589; batch adversarial loss: 0.535346\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338024; batch adversarial loss: 0.553410\n",
      "epoch 177; iter: 0; batch classifier loss: 0.468573; batch adversarial loss: 0.507223\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339826; batch adversarial loss: 0.561874\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334320; batch adversarial loss: 0.572677\n",
      "epoch 180; iter: 0; batch classifier loss: 0.342248; batch adversarial loss: 0.554790\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363359; batch adversarial loss: 0.588184\n",
      "epoch 182; iter: 0; batch classifier loss: 0.310395; batch adversarial loss: 0.536471\n",
      "epoch 183; iter: 0; batch classifier loss: 0.296256; batch adversarial loss: 0.535073\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372397; batch adversarial loss: 0.562157\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333614; batch adversarial loss: 0.445726\n",
      "epoch 186; iter: 0; batch classifier loss: 0.258827; batch adversarial loss: 0.581006\n",
      "epoch 187; iter: 0; batch classifier loss: 0.250735; batch adversarial loss: 0.608230\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338462; batch adversarial loss: 0.572587\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347313; batch adversarial loss: 0.597703\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322661; batch adversarial loss: 0.472205\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341700; batch adversarial loss: 0.598692\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373306; batch adversarial loss: 0.562342\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284605; batch adversarial loss: 0.546301\n",
      "epoch 194; iter: 0; batch classifier loss: 0.301459; batch adversarial loss: 0.536121\n",
      "epoch 195; iter: 0; batch classifier loss: 0.424624; batch adversarial loss: 0.544068\n",
      "epoch 196; iter: 0; batch classifier loss: 0.274212; batch adversarial loss: 0.564162\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315018; batch adversarial loss: 0.607025\n",
      "epoch 198; iter: 0; batch classifier loss: 0.413271; batch adversarial loss: 0.634074\n",
      "epoch 199; iter: 0; batch classifier loss: 0.341225; batch adversarial loss: 0.571793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.691468; batch adversarial loss: 0.611005\n",
      "epoch 1; iter: 0; batch classifier loss: 0.529041; batch adversarial loss: 0.672199\n",
      "epoch 2; iter: 0; batch classifier loss: 0.664451; batch adversarial loss: 0.649903\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577230; batch adversarial loss: 0.658492\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573727; batch adversarial loss: 0.588183\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588302; batch adversarial loss: 0.626644\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542035; batch adversarial loss: 0.628974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555443; batch adversarial loss: 0.570998\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522757; batch adversarial loss: 0.665074\n",
      "epoch 9; iter: 0; batch classifier loss: 0.593552; batch adversarial loss: 0.622512\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550913; batch adversarial loss: 0.582898\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533641; batch adversarial loss: 0.594147\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567267; batch adversarial loss: 0.534734\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511902; batch adversarial loss: 0.543467\n",
      "epoch 14; iter: 0; batch classifier loss: 0.493876; batch adversarial loss: 0.585060\n",
      "epoch 15; iter: 0; batch classifier loss: 0.413803; batch adversarial loss: 0.580504\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553073; batch adversarial loss: 0.538730\n",
      "epoch 17; iter: 0; batch classifier loss: 0.448556; batch adversarial loss: 0.561594\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491021; batch adversarial loss: 0.576536\n",
      "epoch 19; iter: 0; batch classifier loss: 0.607698; batch adversarial loss: 0.515853\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470102; batch adversarial loss: 0.601400\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513011; batch adversarial loss: 0.580426\n",
      "epoch 22; iter: 0; batch classifier loss: 0.546555; batch adversarial loss: 0.506303\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468826; batch adversarial loss: 0.576813\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456009; batch adversarial loss: 0.565694\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502311; batch adversarial loss: 0.564878\n",
      "epoch 26; iter: 0; batch classifier loss: 0.533294; batch adversarial loss: 0.571851\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478848; batch adversarial loss: 0.582926\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475483; batch adversarial loss: 0.487249\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444484; batch adversarial loss: 0.560304\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502117; batch adversarial loss: 0.576189\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464322; batch adversarial loss: 0.555648\n",
      "epoch 32; iter: 0; batch classifier loss: 0.523831; batch adversarial loss: 0.530797\n",
      "epoch 33; iter: 0; batch classifier loss: 0.502589; batch adversarial loss: 0.602481\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445375; batch adversarial loss: 0.568133\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498628; batch adversarial loss: 0.508683\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426491; batch adversarial loss: 0.571651\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418228; batch adversarial loss: 0.579348\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454641; batch adversarial loss: 0.527901\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478382; batch adversarial loss: 0.533302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446398; batch adversarial loss: 0.474622\n",
      "epoch 41; iter: 0; batch classifier loss: 0.439333; batch adversarial loss: 0.627630\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505165; batch adversarial loss: 0.446790\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375590; batch adversarial loss: 0.483732\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474650; batch adversarial loss: 0.620893\n",
      "epoch 45; iter: 0; batch classifier loss: 0.512107; batch adversarial loss: 0.520971\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451080; batch adversarial loss: 0.589034\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463304; batch adversarial loss: 0.595884\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459126; batch adversarial loss: 0.490233\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407489; batch adversarial loss: 0.516912\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388194; batch adversarial loss: 0.614814\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427532; batch adversarial loss: 0.616955\n",
      "epoch 52; iter: 0; batch classifier loss: 0.381358; batch adversarial loss: 0.609089\n",
      "epoch 53; iter: 0; batch classifier loss: 0.455638; batch adversarial loss: 0.494207\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429023; batch adversarial loss: 0.519803\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454703; batch adversarial loss: 0.464123\n",
      "epoch 56; iter: 0; batch classifier loss: 0.359721; batch adversarial loss: 0.560079\n",
      "epoch 57; iter: 0; batch classifier loss: 0.478146; batch adversarial loss: 0.463895\n",
      "epoch 58; iter: 0; batch classifier loss: 0.408733; batch adversarial loss: 0.548284\n",
      "epoch 59; iter: 0; batch classifier loss: 0.533208; batch adversarial loss: 0.520856\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356091; batch adversarial loss: 0.643026\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468181; batch adversarial loss: 0.599151\n",
      "epoch 62; iter: 0; batch classifier loss: 0.419834; batch adversarial loss: 0.546224\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415517; batch adversarial loss: 0.622545\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407468; batch adversarial loss: 0.511452\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415267; batch adversarial loss: 0.554244\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439787; batch adversarial loss: 0.528190\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413548; batch adversarial loss: 0.483391\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411755; batch adversarial loss: 0.553769\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437787; batch adversarial loss: 0.544929\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358865; batch adversarial loss: 0.536291\n",
      "epoch 71; iter: 0; batch classifier loss: 0.465263; batch adversarial loss: 0.554407\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400564; batch adversarial loss: 0.625920\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424651; batch adversarial loss: 0.580989\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437642; batch adversarial loss: 0.561426\n",
      "epoch 75; iter: 0; batch classifier loss: 0.431917; batch adversarial loss: 0.563361\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384615; batch adversarial loss: 0.612375\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383053; batch adversarial loss: 0.505234\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386709; batch adversarial loss: 0.592108\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406676; batch adversarial loss: 0.485321\n",
      "epoch 80; iter: 0; batch classifier loss: 0.424188; batch adversarial loss: 0.556137\n",
      "epoch 81; iter: 0; batch classifier loss: 0.444641; batch adversarial loss: 0.536090\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368636; batch adversarial loss: 0.525225\n",
      "epoch 83; iter: 0; batch classifier loss: 0.489228; batch adversarial loss: 0.568040\n",
      "epoch 84; iter: 0; batch classifier loss: 0.340455; batch adversarial loss: 0.630363\n",
      "epoch 85; iter: 0; batch classifier loss: 0.478018; batch adversarial loss: 0.642119\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413433; batch adversarial loss: 0.521481\n",
      "epoch 87; iter: 0; batch classifier loss: 0.431872; batch adversarial loss: 0.436699\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405793; batch adversarial loss: 0.490927\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400089; batch adversarial loss: 0.536987\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383840; batch adversarial loss: 0.564053\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358305; batch adversarial loss: 0.534712\n",
      "epoch 92; iter: 0; batch classifier loss: 0.347904; batch adversarial loss: 0.527224\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389620; batch adversarial loss: 0.651052\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377768; batch adversarial loss: 0.563507\n",
      "epoch 95; iter: 0; batch classifier loss: 0.371329; batch adversarial loss: 0.599876\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417342; batch adversarial loss: 0.493528\n",
      "epoch 97; iter: 0; batch classifier loss: 0.446779; batch adversarial loss: 0.537295\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418662; batch adversarial loss: 0.555721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.454405; batch adversarial loss: 0.527563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382469; batch adversarial loss: 0.544769\n",
      "epoch 101; iter: 0; batch classifier loss: 0.433851; batch adversarial loss: 0.518872\n",
      "epoch 102; iter: 0; batch classifier loss: 0.404103; batch adversarial loss: 0.535264\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438032; batch adversarial loss: 0.589620\n",
      "epoch 104; iter: 0; batch classifier loss: 0.465025; batch adversarial loss: 0.544547\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364410; batch adversarial loss: 0.498141\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402941; batch adversarial loss: 0.435152\n",
      "epoch 107; iter: 0; batch classifier loss: 0.310573; batch adversarial loss: 0.627182\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387360; batch adversarial loss: 0.552391\n",
      "epoch 109; iter: 0; batch classifier loss: 0.362724; batch adversarial loss: 0.553518\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375277; batch adversarial loss: 0.519220\n",
      "epoch 111; iter: 0; batch classifier loss: 0.441921; batch adversarial loss: 0.535178\n",
      "epoch 112; iter: 0; batch classifier loss: 0.465261; batch adversarial loss: 0.544945\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371672; batch adversarial loss: 0.553340\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380521; batch adversarial loss: 0.606617\n",
      "epoch 115; iter: 0; batch classifier loss: 0.304477; batch adversarial loss: 0.571996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.469834; batch adversarial loss: 0.616969\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357604; batch adversarial loss: 0.571291\n",
      "epoch 118; iter: 0; batch classifier loss: 0.413078; batch adversarial loss: 0.481196\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367146; batch adversarial loss: 0.580031\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406717; batch adversarial loss: 0.495469\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373514; batch adversarial loss: 0.560963\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365413; batch adversarial loss: 0.523873\n",
      "epoch 123; iter: 0; batch classifier loss: 0.317376; batch adversarial loss: 0.539514\n",
      "epoch 124; iter: 0; batch classifier loss: 0.431140; batch adversarial loss: 0.514743\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375048; batch adversarial loss: 0.575882\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316653; batch adversarial loss: 0.600665\n",
      "epoch 127; iter: 0; batch classifier loss: 0.332979; batch adversarial loss: 0.577588\n",
      "epoch 128; iter: 0; batch classifier loss: 0.386856; batch adversarial loss: 0.479075\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360093; batch adversarial loss: 0.528584\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425382; batch adversarial loss: 0.570808\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373897; batch adversarial loss: 0.546376\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377439; batch adversarial loss: 0.563067\n",
      "epoch 133; iter: 0; batch classifier loss: 0.453980; batch adversarial loss: 0.587896\n",
      "epoch 134; iter: 0; batch classifier loss: 0.314619; batch adversarial loss: 0.571262\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320308; batch adversarial loss: 0.579729\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385871; batch adversarial loss: 0.545031\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344811; batch adversarial loss: 0.491421\n",
      "epoch 138; iter: 0; batch classifier loss: 0.408126; batch adversarial loss: 0.536185\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332939; batch adversarial loss: 0.518374\n",
      "epoch 140; iter: 0; batch classifier loss: 0.322849; batch adversarial loss: 0.519012\n",
      "epoch 141; iter: 0; batch classifier loss: 0.452519; batch adversarial loss: 0.670105\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397587; batch adversarial loss: 0.598032\n",
      "epoch 143; iter: 0; batch classifier loss: 0.415652; batch adversarial loss: 0.580417\n",
      "epoch 144; iter: 0; batch classifier loss: 0.399074; batch adversarial loss: 0.562202\n",
      "epoch 145; iter: 0; batch classifier loss: 0.406265; batch adversarial loss: 0.562910\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377455; batch adversarial loss: 0.507748\n",
      "epoch 147; iter: 0; batch classifier loss: 0.316044; batch adversarial loss: 0.501338\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375635; batch adversarial loss: 0.554527\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373425; batch adversarial loss: 0.597634\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389939; batch adversarial loss: 0.526226\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372244; batch adversarial loss: 0.562377\n",
      "epoch 152; iter: 0; batch classifier loss: 0.312595; batch adversarial loss: 0.580383\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316938; batch adversarial loss: 0.571308\n",
      "epoch 154; iter: 0; batch classifier loss: 0.491992; batch adversarial loss: 0.526444\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401016; batch adversarial loss: 0.553007\n",
      "epoch 156; iter: 0; batch classifier loss: 0.423647; batch adversarial loss: 0.563102\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350315; batch adversarial loss: 0.580338\n",
      "epoch 158; iter: 0; batch classifier loss: 0.416766; batch adversarial loss: 0.571608\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338417; batch adversarial loss: 0.499879\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356817; batch adversarial loss: 0.499402\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361081; batch adversarial loss: 0.562649\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363693; batch adversarial loss: 0.553117\n",
      "epoch 163; iter: 0; batch classifier loss: 0.276358; batch adversarial loss: 0.480345\n",
      "epoch 164; iter: 0; batch classifier loss: 0.426268; batch adversarial loss: 0.526128\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318931; batch adversarial loss: 0.634387\n",
      "epoch 166; iter: 0; batch classifier loss: 0.315223; batch adversarial loss: 0.571072\n",
      "epoch 167; iter: 0; batch classifier loss: 0.313579; batch adversarial loss: 0.490039\n",
      "epoch 168; iter: 0; batch classifier loss: 0.324383; batch adversarial loss: 0.481513\n",
      "epoch 169; iter: 0; batch classifier loss: 0.467479; batch adversarial loss: 0.534388\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324918; batch adversarial loss: 0.535508\n",
      "epoch 171; iter: 0; batch classifier loss: 0.431607; batch adversarial loss: 0.541730\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344752; batch adversarial loss: 0.524860\n",
      "epoch 173; iter: 0; batch classifier loss: 0.444293; batch adversarial loss: 0.551925\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348934; batch adversarial loss: 0.552706\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342348; batch adversarial loss: 0.554717\n",
      "epoch 176; iter: 0; batch classifier loss: 0.345685; batch adversarial loss: 0.607826\n",
      "epoch 177; iter: 0; batch classifier loss: 0.398222; batch adversarial loss: 0.482525\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357931; batch adversarial loss: 0.570772\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377665; batch adversarial loss: 0.499977\n",
      "epoch 180; iter: 0; batch classifier loss: 0.443547; batch adversarial loss: 0.526513\n",
      "epoch 181; iter: 0; batch classifier loss: 0.408681; batch adversarial loss: 0.571319\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358247; batch adversarial loss: 0.553745\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393670; batch adversarial loss: 0.534961\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335172; batch adversarial loss: 0.606701\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384672; batch adversarial loss: 0.580004\n",
      "epoch 186; iter: 0; batch classifier loss: 0.296323; batch adversarial loss: 0.473285\n",
      "epoch 187; iter: 0; batch classifier loss: 0.409783; batch adversarial loss: 0.508636\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346624; batch adversarial loss: 0.580357\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385056; batch adversarial loss: 0.490928\n",
      "epoch 190; iter: 0; batch classifier loss: 0.378194; batch adversarial loss: 0.553197\n",
      "epoch 191; iter: 0; batch classifier loss: 0.299865; batch adversarial loss: 0.607732\n",
      "epoch 192; iter: 0; batch classifier loss: 0.307532; batch adversarial loss: 0.481138\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316010; batch adversarial loss: 0.517124\n",
      "epoch 194; iter: 0; batch classifier loss: 0.269680; batch adversarial loss: 0.598497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.410370; batch adversarial loss: 0.616455\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341008; batch adversarial loss: 0.582991\n",
      "epoch 197; iter: 0; batch classifier loss: 0.310179; batch adversarial loss: 0.544123\n",
      "epoch 198; iter: 0; batch classifier loss: 0.408792; batch adversarial loss: 0.616376\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397218; batch adversarial loss: 0.578153\n",
      "epoch 0; iter: 0; batch classifier loss: 0.737614; batch adversarial loss: 0.737219\n",
      "epoch 1; iter: 0; batch classifier loss: 0.562869; batch adversarial loss: 0.682506\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574480; batch adversarial loss: 0.677291\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590437; batch adversarial loss: 0.646574\n",
      "epoch 4; iter: 0; batch classifier loss: 0.556441; batch adversarial loss: 0.633257\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553595; batch adversarial loss: 0.600632\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550884; batch adversarial loss: 0.591358\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574175; batch adversarial loss: 0.615346\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562568; batch adversarial loss: 0.605760\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505500; batch adversarial loss: 0.654398\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548215; batch adversarial loss: 0.571714\n",
      "epoch 11; iter: 0; batch classifier loss: 0.610668; batch adversarial loss: 0.571070\n",
      "epoch 12; iter: 0; batch classifier loss: 0.583764; batch adversarial loss: 0.564244\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506963; batch adversarial loss: 0.579542\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497588; batch adversarial loss: 0.509436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484242; batch adversarial loss: 0.508498\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527011; batch adversarial loss: 0.610951\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467550; batch adversarial loss: 0.584525\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474420; batch adversarial loss: 0.565228\n",
      "epoch 19; iter: 0; batch classifier loss: 0.612157; batch adversarial loss: 0.620491\n",
      "epoch 20; iter: 0; batch classifier loss: 0.620785; batch adversarial loss: 0.568096\n",
      "epoch 21; iter: 0; batch classifier loss: 0.518687; batch adversarial loss: 0.538267\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483431; batch adversarial loss: 0.534877\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507852; batch adversarial loss: 0.516267\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464732; batch adversarial loss: 0.502404\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566784; batch adversarial loss: 0.523852\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473905; batch adversarial loss: 0.528493\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493411; batch adversarial loss: 0.513730\n",
      "epoch 28; iter: 0; batch classifier loss: 0.382717; batch adversarial loss: 0.478878\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479189; batch adversarial loss: 0.574394\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478545; batch adversarial loss: 0.466311\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453839; batch adversarial loss: 0.559258\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496748; batch adversarial loss: 0.509683\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453201; batch adversarial loss: 0.555186\n",
      "epoch 34; iter: 0; batch classifier loss: 0.395562; batch adversarial loss: 0.527170\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475766; batch adversarial loss: 0.518517\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439047; batch adversarial loss: 0.508178\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386596; batch adversarial loss: 0.596397\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403466; batch adversarial loss: 0.553872\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429921; batch adversarial loss: 0.554340\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431216; batch adversarial loss: 0.560025\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396984; batch adversarial loss: 0.614487\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390604; batch adversarial loss: 0.591156\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461003; batch adversarial loss: 0.470237\n",
      "epoch 44; iter: 0; batch classifier loss: 0.376772; batch adversarial loss: 0.534998\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450562; batch adversarial loss: 0.544505\n",
      "epoch 46; iter: 0; batch classifier loss: 0.489458; batch adversarial loss: 0.590071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438009; batch adversarial loss: 0.619335\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408805; batch adversarial loss: 0.560689\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391878; batch adversarial loss: 0.646173\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410388; batch adversarial loss: 0.525763\n",
      "epoch 51; iter: 0; batch classifier loss: 0.391319; batch adversarial loss: 0.581372\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457511; batch adversarial loss: 0.514992\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436053; batch adversarial loss: 0.536284\n",
      "epoch 54; iter: 0; batch classifier loss: 0.529289; batch adversarial loss: 0.508667\n",
      "epoch 55; iter: 0; batch classifier loss: 0.438487; batch adversarial loss: 0.517544\n",
      "epoch 56; iter: 0; batch classifier loss: 0.485192; batch adversarial loss: 0.481939\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459927; batch adversarial loss: 0.489375\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404934; batch adversarial loss: 0.508671\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431193; batch adversarial loss: 0.498647\n",
      "epoch 60; iter: 0; batch classifier loss: 0.430412; batch adversarial loss: 0.471006\n",
      "epoch 61; iter: 0; batch classifier loss: 0.333125; batch adversarial loss: 0.534899\n",
      "epoch 62; iter: 0; batch classifier loss: 0.353054; batch adversarial loss: 0.609472\n",
      "epoch 63; iter: 0; batch classifier loss: 0.375084; batch adversarial loss: 0.562943\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361046; batch adversarial loss: 0.589804\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395960; batch adversarial loss: 0.554737\n",
      "epoch 66; iter: 0; batch classifier loss: 0.360095; batch adversarial loss: 0.590493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.501030; batch adversarial loss: 0.517250\n",
      "epoch 68; iter: 0; batch classifier loss: 0.366950; batch adversarial loss: 0.572537\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390281; batch adversarial loss: 0.516059\n",
      "epoch 70; iter: 0; batch classifier loss: 0.364304; batch adversarial loss: 0.590739\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410039; batch adversarial loss: 0.517777\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403472; batch adversarial loss: 0.488637\n",
      "epoch 73; iter: 0; batch classifier loss: 0.363083; batch adversarial loss: 0.546145\n",
      "epoch 74; iter: 0; batch classifier loss: 0.370595; batch adversarial loss: 0.593517\n",
      "epoch 75; iter: 0; batch classifier loss: 0.359225; batch adversarial loss: 0.579640\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392259; batch adversarial loss: 0.574235\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394228; batch adversarial loss: 0.581656\n",
      "epoch 78; iter: 0; batch classifier loss: 0.446142; batch adversarial loss: 0.599481\n",
      "epoch 79; iter: 0; batch classifier loss: 0.320174; batch adversarial loss: 0.581170\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427400; batch adversarial loss: 0.504231\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397305; batch adversarial loss: 0.637346\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400591; batch adversarial loss: 0.534149\n",
      "epoch 83; iter: 0; batch classifier loss: 0.325521; batch adversarial loss: 0.582438\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407759; batch adversarial loss: 0.487504\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391051; batch adversarial loss: 0.538467\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401864; batch adversarial loss: 0.570499\n",
      "epoch 87; iter: 0; batch classifier loss: 0.362913; batch adversarial loss: 0.581955\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387030; batch adversarial loss: 0.519566\n",
      "epoch 89; iter: 0; batch classifier loss: 0.430075; batch adversarial loss: 0.553450\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418734; batch adversarial loss: 0.518003\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349363; batch adversarial loss: 0.580996\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432433; batch adversarial loss: 0.571104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.325896; batch adversarial loss: 0.616380\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391651; batch adversarial loss: 0.562627\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378554; batch adversarial loss: 0.544329\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367690; batch adversarial loss: 0.489403\n",
      "epoch 97; iter: 0; batch classifier loss: 0.324100; batch adversarial loss: 0.498195\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418089; batch adversarial loss: 0.544280\n",
      "epoch 99; iter: 0; batch classifier loss: 0.310018; batch adversarial loss: 0.499981\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365565; batch adversarial loss: 0.534804\n",
      "epoch 101; iter: 0; batch classifier loss: 0.327486; batch adversarial loss: 0.571315\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385675; batch adversarial loss: 0.534479\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440245; batch adversarial loss: 0.488904\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364993; batch adversarial loss: 0.499029\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378276; batch adversarial loss: 0.599940\n",
      "epoch 106; iter: 0; batch classifier loss: 0.286200; batch adversarial loss: 0.580919\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436014; batch adversarial loss: 0.516462\n",
      "epoch 108; iter: 0; batch classifier loss: 0.409302; batch adversarial loss: 0.553325\n",
      "epoch 109; iter: 0; batch classifier loss: 0.449897; batch adversarial loss: 0.536142\n",
      "epoch 110; iter: 0; batch classifier loss: 0.296572; batch adversarial loss: 0.554735\n",
      "epoch 111; iter: 0; batch classifier loss: 0.351357; batch adversarial loss: 0.516775\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372541; batch adversarial loss: 0.534325\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407392; batch adversarial loss: 0.535278\n",
      "epoch 114; iter: 0; batch classifier loss: 0.339806; batch adversarial loss: 0.543293\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371350; batch adversarial loss: 0.479886\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339315; batch adversarial loss: 0.498721\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406403; batch adversarial loss: 0.552754\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389710; batch adversarial loss: 0.535681\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356353; batch adversarial loss: 0.527027\n",
      "epoch 120; iter: 0; batch classifier loss: 0.425776; batch adversarial loss: 0.562955\n",
      "epoch 121; iter: 0; batch classifier loss: 0.331138; batch adversarial loss: 0.535244\n",
      "epoch 122; iter: 0; batch classifier loss: 0.441932; batch adversarial loss: 0.562125\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394152; batch adversarial loss: 0.554950\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365854; batch adversarial loss: 0.582437\n",
      "epoch 125; iter: 0; batch classifier loss: 0.354223; batch adversarial loss: 0.562748\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323078; batch adversarial loss: 0.545089\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350956; batch adversarial loss: 0.525934\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396484; batch adversarial loss: 0.610032\n",
      "epoch 129; iter: 0; batch classifier loss: 0.382773; batch adversarial loss: 0.553247\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376772; batch adversarial loss: 0.563440\n",
      "epoch 131; iter: 0; batch classifier loss: 0.376864; batch adversarial loss: 0.581438\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353033; batch adversarial loss: 0.461351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375472; batch adversarial loss: 0.600330\n",
      "epoch 134; iter: 0; batch classifier loss: 0.405963; batch adversarial loss: 0.480737\n",
      "epoch 135; iter: 0; batch classifier loss: 0.427744; batch adversarial loss: 0.525424\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395360; batch adversarial loss: 0.545067\n",
      "epoch 137; iter: 0; batch classifier loss: 0.300790; batch adversarial loss: 0.555503\n",
      "epoch 138; iter: 0; batch classifier loss: 0.395744; batch adversarial loss: 0.525442\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359263; batch adversarial loss: 0.600116\n",
      "epoch 140; iter: 0; batch classifier loss: 0.313907; batch adversarial loss: 0.627397\n",
      "epoch 141; iter: 0; batch classifier loss: 0.324491; batch adversarial loss: 0.517835\n",
      "epoch 142; iter: 0; batch classifier loss: 0.424920; batch adversarial loss: 0.617835\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368013; batch adversarial loss: 0.544556\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365542; batch adversarial loss: 0.543572\n",
      "epoch 145; iter: 0; batch classifier loss: 0.389549; batch adversarial loss: 0.443823\n",
      "epoch 146; iter: 0; batch classifier loss: 0.308218; batch adversarial loss: 0.573181\n",
      "epoch 147; iter: 0; batch classifier loss: 0.396012; batch adversarial loss: 0.516082\n",
      "epoch 148; iter: 0; batch classifier loss: 0.400808; batch adversarial loss: 0.506480\n",
      "epoch 149; iter: 0; batch classifier loss: 0.291227; batch adversarial loss: 0.628210\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385153; batch adversarial loss: 0.499096\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408787; batch adversarial loss: 0.499225\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338877; batch adversarial loss: 0.534241\n",
      "epoch 153; iter: 0; batch classifier loss: 0.317054; batch adversarial loss: 0.479596\n",
      "epoch 154; iter: 0; batch classifier loss: 0.310545; batch adversarial loss: 0.562210\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314535; batch adversarial loss: 0.590949\n",
      "epoch 156; iter: 0; batch classifier loss: 0.275581; batch adversarial loss: 0.525759\n",
      "epoch 157; iter: 0; batch classifier loss: 0.413795; batch adversarial loss: 0.543766\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378744; batch adversarial loss: 0.607744\n",
      "epoch 159; iter: 0; batch classifier loss: 0.368406; batch adversarial loss: 0.525106\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384148; batch adversarial loss: 0.424829\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350197; batch adversarial loss: 0.534362\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382848; batch adversarial loss: 0.546106\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369337; batch adversarial loss: 0.460378\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398780; batch adversarial loss: 0.525490\n",
      "epoch 165; iter: 0; batch classifier loss: 0.309377; batch adversarial loss: 0.616881\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367210; batch adversarial loss: 0.552416\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301021; batch adversarial loss: 0.591444\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358084; batch adversarial loss: 0.479889\n",
      "epoch 169; iter: 0; batch classifier loss: 0.448493; batch adversarial loss: 0.573054\n",
      "epoch 170; iter: 0; batch classifier loss: 0.456005; batch adversarial loss: 0.553429\n",
      "epoch 171; iter: 0; batch classifier loss: 0.274682; batch adversarial loss: 0.562074\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336676; batch adversarial loss: 0.526453\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316440; batch adversarial loss: 0.488628\n",
      "epoch 174; iter: 0; batch classifier loss: 0.458573; batch adversarial loss: 0.589640\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352767; batch adversarial loss: 0.525356\n",
      "epoch 176; iter: 0; batch classifier loss: 0.476443; batch adversarial loss: 0.517694\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324319; batch adversarial loss: 0.534459\n",
      "epoch 178; iter: 0; batch classifier loss: 0.275064; batch adversarial loss: 0.534994\n",
      "epoch 179; iter: 0; batch classifier loss: 0.310716; batch adversarial loss: 0.469767\n",
      "epoch 180; iter: 0; batch classifier loss: 0.282364; batch adversarial loss: 0.508125\n",
      "epoch 181; iter: 0; batch classifier loss: 0.341260; batch adversarial loss: 0.581360\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375915; batch adversarial loss: 0.515866\n",
      "epoch 183; iter: 0; batch classifier loss: 0.275976; batch adversarial loss: 0.452034\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347325; batch adversarial loss: 0.516230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.284245; batch adversarial loss: 0.636075\n",
      "epoch 186; iter: 0; batch classifier loss: 0.305514; batch adversarial loss: 0.516452\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329026; batch adversarial loss: 0.526629\n",
      "epoch 188; iter: 0; batch classifier loss: 0.408169; batch adversarial loss: 0.554245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.299057; batch adversarial loss: 0.470634\n",
      "epoch 190; iter: 0; batch classifier loss: 0.324091; batch adversarial loss: 0.581213\n",
      "epoch 191; iter: 0; batch classifier loss: 0.432951; batch adversarial loss: 0.572207\n",
      "epoch 192; iter: 0; batch classifier loss: 0.382985; batch adversarial loss: 0.590763\n",
      "epoch 193; iter: 0; batch classifier loss: 0.414984; batch adversarial loss: 0.535074\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324321; batch adversarial loss: 0.536146\n",
      "epoch 195; iter: 0; batch classifier loss: 0.288965; batch adversarial loss: 0.498991\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315806; batch adversarial loss: 0.515978\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353791; batch adversarial loss: 0.563429\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370704; batch adversarial loss: 0.508344\n",
      "epoch 199; iter: 0; batch classifier loss: 0.304267; batch adversarial loss: 0.572620\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729125; batch adversarial loss: 0.682582\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610670; batch adversarial loss: 0.672776\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581469; batch adversarial loss: 0.635571\n",
      "epoch 3; iter: 0; batch classifier loss: 0.514856; batch adversarial loss: 0.634027\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546568; batch adversarial loss: 0.590764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.499155; batch adversarial loss: 0.594111\n",
      "epoch 6; iter: 0; batch classifier loss: 0.489678; batch adversarial loss: 0.610845\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531412; batch adversarial loss: 0.626835\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553988; batch adversarial loss: 0.560566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513897; batch adversarial loss: 0.533289\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520783; batch adversarial loss: 0.602505\n",
      "epoch 11; iter: 0; batch classifier loss: 0.412591; batch adversarial loss: 0.605923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.479580; batch adversarial loss: 0.599985\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512679; batch adversarial loss: 0.591785\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489821; batch adversarial loss: 0.555637\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470668; batch adversarial loss: 0.588676\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537263; batch adversarial loss: 0.605010\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546066; batch adversarial loss: 0.592792\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493275; batch adversarial loss: 0.627585\n",
      "epoch 19; iter: 0; batch classifier loss: 0.539603; batch adversarial loss: 0.579436\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514473; batch adversarial loss: 0.521031\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467843; batch adversarial loss: 0.569661\n",
      "epoch 22; iter: 0; batch classifier loss: 0.428120; batch adversarial loss: 0.587797\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439251; batch adversarial loss: 0.570656\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474285; batch adversarial loss: 0.577009\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523600; batch adversarial loss: 0.542321\n",
      "epoch 26; iter: 0; batch classifier loss: 0.516316; batch adversarial loss: 0.610255\n",
      "epoch 27; iter: 0; batch classifier loss: 0.532195; batch adversarial loss: 0.560890\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477609; batch adversarial loss: 0.491823\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424860; batch adversarial loss: 0.514423\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437715; batch adversarial loss: 0.495343\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435441; batch adversarial loss: 0.589919\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482385; batch adversarial loss: 0.561193\n",
      "epoch 33; iter: 0; batch classifier loss: 0.428543; batch adversarial loss: 0.605443\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430977; batch adversarial loss: 0.538228\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455948; batch adversarial loss: 0.631410\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456216; batch adversarial loss: 0.553236\n",
      "epoch 37; iter: 0; batch classifier loss: 0.538997; batch adversarial loss: 0.572987\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412097; batch adversarial loss: 0.552382\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490942; batch adversarial loss: 0.598787\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524588; batch adversarial loss: 0.550446\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444028; batch adversarial loss: 0.453142\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463490; batch adversarial loss: 0.543440\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483506; batch adversarial loss: 0.480542\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446404; batch adversarial loss: 0.588717\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450496; batch adversarial loss: 0.590057\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432963; batch adversarial loss: 0.533237\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423022; batch adversarial loss: 0.490048\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431067; batch adversarial loss: 0.649371\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434612; batch adversarial loss: 0.559012\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441731; batch adversarial loss: 0.529583\n",
      "epoch 51; iter: 0; batch classifier loss: 0.345862; batch adversarial loss: 0.532636\n",
      "epoch 52; iter: 0; batch classifier loss: 0.396812; batch adversarial loss: 0.546332\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472592; batch adversarial loss: 0.482041\n",
      "epoch 54; iter: 0; batch classifier loss: 0.389932; batch adversarial loss: 0.603755\n",
      "epoch 55; iter: 0; batch classifier loss: 0.383733; batch adversarial loss: 0.563983\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405942; batch adversarial loss: 0.553942\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391095; batch adversarial loss: 0.606635\n",
      "epoch 58; iter: 0; batch classifier loss: 0.449279; batch adversarial loss: 0.591483\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378584; batch adversarial loss: 0.516633\n",
      "epoch 60; iter: 0; batch classifier loss: 0.371164; batch adversarial loss: 0.544426\n",
      "epoch 61; iter: 0; batch classifier loss: 0.371801; batch adversarial loss: 0.502187\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425619; batch adversarial loss: 0.659370\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386754; batch adversarial loss: 0.573029\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438210; batch adversarial loss: 0.579606\n",
      "epoch 65; iter: 0; batch classifier loss: 0.366915; batch adversarial loss: 0.617952\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400661; batch adversarial loss: 0.597055\n",
      "epoch 67; iter: 0; batch classifier loss: 0.345741; batch adversarial loss: 0.563960\n",
      "epoch 68; iter: 0; batch classifier loss: 0.471709; batch adversarial loss: 0.551727\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402583; batch adversarial loss: 0.589485\n",
      "epoch 70; iter: 0; batch classifier loss: 0.318826; batch adversarial loss: 0.598652\n",
      "epoch 71; iter: 0; batch classifier loss: 0.474848; batch adversarial loss: 0.553608\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429566; batch adversarial loss: 0.579349\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368799; batch adversarial loss: 0.525428\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406102; batch adversarial loss: 0.443867\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440751; batch adversarial loss: 0.599053\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394382; batch adversarial loss: 0.515482\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419029; batch adversarial loss: 0.498875\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407548; batch adversarial loss: 0.500199\n",
      "epoch 79; iter: 0; batch classifier loss: 0.463504; batch adversarial loss: 0.599688\n",
      "epoch 80; iter: 0; batch classifier loss: 0.388647; batch adversarial loss: 0.525706\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413307; batch adversarial loss: 0.578699\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371325; batch adversarial loss: 0.553270\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394059; batch adversarial loss: 0.499374\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386548; batch adversarial loss: 0.671605\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360241; batch adversarial loss: 0.580833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.392844; batch adversarial loss: 0.544686\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393449; batch adversarial loss: 0.544525\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386015; batch adversarial loss: 0.527877\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436232; batch adversarial loss: 0.581295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.433801; batch adversarial loss: 0.618493\n",
      "epoch 91; iter: 0; batch classifier loss: 0.512360; batch adversarial loss: 0.562839\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434287; batch adversarial loss: 0.489756\n",
      "epoch 93; iter: 0; batch classifier loss: 0.449675; batch adversarial loss: 0.579178\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375440; batch adversarial loss: 0.571980\n",
      "epoch 95; iter: 0; batch classifier loss: 0.436560; batch adversarial loss: 0.535009\n",
      "epoch 96; iter: 0; batch classifier loss: 0.451215; batch adversarial loss: 0.498905\n",
      "epoch 97; iter: 0; batch classifier loss: 0.432848; batch adversarial loss: 0.525909\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438337; batch adversarial loss: 0.617096\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388763; batch adversarial loss: 0.572719\n",
      "epoch 100; iter: 0; batch classifier loss: 0.342714; batch adversarial loss: 0.482347\n",
      "epoch 101; iter: 0; batch classifier loss: 0.443631; batch adversarial loss: 0.582963\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342527; batch adversarial loss: 0.499274\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385660; batch adversarial loss: 0.552144\n",
      "epoch 104; iter: 0; batch classifier loss: 0.355396; batch adversarial loss: 0.526151\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372423; batch adversarial loss: 0.526834\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413028; batch adversarial loss: 0.617022\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364249; batch adversarial loss: 0.553704\n",
      "epoch 108; iter: 0; batch classifier loss: 0.331382; batch adversarial loss: 0.561449\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415762; batch adversarial loss: 0.481870\n",
      "epoch 110; iter: 0; batch classifier loss: 0.354302; batch adversarial loss: 0.499902\n",
      "epoch 111; iter: 0; batch classifier loss: 0.430373; batch adversarial loss: 0.615036\n",
      "epoch 112; iter: 0; batch classifier loss: 0.342052; batch adversarial loss: 0.634854\n",
      "epoch 113; iter: 0; batch classifier loss: 0.428745; batch adversarial loss: 0.445261\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372312; batch adversarial loss: 0.491130\n",
      "epoch 115; iter: 0; batch classifier loss: 0.377890; batch adversarial loss: 0.516870\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375589; batch adversarial loss: 0.535517\n",
      "epoch 117; iter: 0; batch classifier loss: 0.324178; batch adversarial loss: 0.626705\n",
      "epoch 118; iter: 0; batch classifier loss: 0.336006; batch adversarial loss: 0.553640\n",
      "epoch 119; iter: 0; batch classifier loss: 0.393579; batch adversarial loss: 0.499134\n",
      "epoch 120; iter: 0; batch classifier loss: 0.312740; batch adversarial loss: 0.571028\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404791; batch adversarial loss: 0.444314\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386560; batch adversarial loss: 0.518403\n",
      "epoch 123; iter: 0; batch classifier loss: 0.451406; batch adversarial loss: 0.589744\n",
      "epoch 124; iter: 0; batch classifier loss: 0.454822; batch adversarial loss: 0.610243\n",
      "epoch 125; iter: 0; batch classifier loss: 0.425167; batch adversarial loss: 0.506179\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404604; batch adversarial loss: 0.489547\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389381; batch adversarial loss: 0.472047\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361923; batch adversarial loss: 0.526880\n",
      "epoch 129; iter: 0; batch classifier loss: 0.349556; batch adversarial loss: 0.481858\n",
      "epoch 130; iter: 0; batch classifier loss: 0.420075; batch adversarial loss: 0.554588\n",
      "epoch 131; iter: 0; batch classifier loss: 0.403715; batch adversarial loss: 0.500113\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341975; batch adversarial loss: 0.553704\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326159; batch adversarial loss: 0.528486\n",
      "epoch 134; iter: 0; batch classifier loss: 0.404932; batch adversarial loss: 0.524858\n",
      "epoch 135; iter: 0; batch classifier loss: 0.440443; batch adversarial loss: 0.562101\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378516; batch adversarial loss: 0.507711\n",
      "epoch 137; iter: 0; batch classifier loss: 0.365503; batch adversarial loss: 0.499202\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376287; batch adversarial loss: 0.554233\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362687; batch adversarial loss: 0.519415\n",
      "epoch 140; iter: 0; batch classifier loss: 0.398957; batch adversarial loss: 0.599416\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344659; batch adversarial loss: 0.518006\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405867; batch adversarial loss: 0.635192\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373935; batch adversarial loss: 0.535568\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351044; batch adversarial loss: 0.552917\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355937; batch adversarial loss: 0.570265\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385955; batch adversarial loss: 0.498699\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388610; batch adversarial loss: 0.526380\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327228; batch adversarial loss: 0.581055\n",
      "epoch 149; iter: 0; batch classifier loss: 0.294223; batch adversarial loss: 0.618388\n",
      "epoch 150; iter: 0; batch classifier loss: 0.397687; batch adversarial loss: 0.491545\n",
      "epoch 151; iter: 0; batch classifier loss: 0.319787; batch adversarial loss: 0.571793\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320785; batch adversarial loss: 0.597594\n",
      "epoch 153; iter: 0; batch classifier loss: 0.424967; batch adversarial loss: 0.536482\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404320; batch adversarial loss: 0.543196\n",
      "epoch 155; iter: 0; batch classifier loss: 0.387814; batch adversarial loss: 0.554236\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355497; batch adversarial loss: 0.589619\n",
      "epoch 157; iter: 0; batch classifier loss: 0.338567; batch adversarial loss: 0.527637\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364656; batch adversarial loss: 0.509267\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323741; batch adversarial loss: 0.518189\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400554; batch adversarial loss: 0.427854\n",
      "epoch 161; iter: 0; batch classifier loss: 0.419731; batch adversarial loss: 0.554325\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371490; batch adversarial loss: 0.517195\n",
      "epoch 163; iter: 0; batch classifier loss: 0.301606; batch adversarial loss: 0.616701\n",
      "epoch 164; iter: 0; batch classifier loss: 0.447411; batch adversarial loss: 0.518056\n",
      "epoch 165; iter: 0; batch classifier loss: 0.323937; batch adversarial loss: 0.470801\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377675; batch adversarial loss: 0.562693\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340851; batch adversarial loss: 0.554363\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353778; batch adversarial loss: 0.536094\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351998; batch adversarial loss: 0.526918\n",
      "epoch 170; iter: 0; batch classifier loss: 0.384688; batch adversarial loss: 0.499793\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335806; batch adversarial loss: 0.607501\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355323; batch adversarial loss: 0.472576\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324776; batch adversarial loss: 0.634630\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371856; batch adversarial loss: 0.597930\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323911; batch adversarial loss: 0.545270\n",
      "epoch 176; iter: 0; batch classifier loss: 0.494821; batch adversarial loss: 0.590392\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347560; batch adversarial loss: 0.573062\n",
      "epoch 178; iter: 0; batch classifier loss: 0.472314; batch adversarial loss: 0.536021\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352887; batch adversarial loss: 0.515898\n",
      "epoch 180; iter: 0; batch classifier loss: 0.377275; batch adversarial loss: 0.545256\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362973; batch adversarial loss: 0.517354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.356196; batch adversarial loss: 0.579394\n",
      "epoch 183; iter: 0; batch classifier loss: 0.291282; batch adversarial loss: 0.544092\n",
      "epoch 184; iter: 0; batch classifier loss: 0.393833; batch adversarial loss: 0.500345\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398602; batch adversarial loss: 0.562363\n",
      "epoch 186; iter: 0; batch classifier loss: 0.439790; batch adversarial loss: 0.617756\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363602; batch adversarial loss: 0.552825\n",
      "epoch 188; iter: 0; batch classifier loss: 0.297848; batch adversarial loss: 0.592097\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292323; batch adversarial loss: 0.553927\n",
      "epoch 190; iter: 0; batch classifier loss: 0.419478; batch adversarial loss: 0.471899\n",
      "epoch 191; iter: 0; batch classifier loss: 0.391002; batch adversarial loss: 0.454509\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315482; batch adversarial loss: 0.579796\n",
      "epoch 193; iter: 0; batch classifier loss: 0.448782; batch adversarial loss: 0.491115\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397923; batch adversarial loss: 0.507689\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342636; batch adversarial loss: 0.562282\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370005; batch adversarial loss: 0.499691\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381138; batch adversarial loss: 0.562312\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403835; batch adversarial loss: 0.552219\n",
      "epoch 199; iter: 0; batch classifier loss: 0.324197; batch adversarial loss: 0.526448\n",
      "epoch 0; iter: 0; batch classifier loss: 0.815179; batch adversarial loss: 0.658483\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593483; batch adversarial loss: 0.705626\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624040; batch adversarial loss: 0.675661\n",
      "epoch 3; iter: 0; batch classifier loss: 0.627761; batch adversarial loss: 0.725441\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615377; batch adversarial loss: 0.728824\n",
      "epoch 5; iter: 0; batch classifier loss: 0.581466; batch adversarial loss: 0.657319\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608015; batch adversarial loss: 0.674016\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616662; batch adversarial loss: 0.685506\n",
      "epoch 8; iter: 0; batch classifier loss: 0.606726; batch adversarial loss: 0.666726\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579507; batch adversarial loss: 0.677455\n",
      "epoch 10; iter: 0; batch classifier loss: 0.616060; batch adversarial loss: 0.619817\n",
      "epoch 11; iter: 0; batch classifier loss: 0.662054; batch adversarial loss: 0.638556\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525807; batch adversarial loss: 0.581252\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521866; batch adversarial loss: 0.613385\n",
      "epoch 14; iter: 0; batch classifier loss: 0.597926; batch adversarial loss: 0.580247\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493148; batch adversarial loss: 0.569386\n",
      "epoch 16; iter: 0; batch classifier loss: 0.544619; batch adversarial loss: 0.555888\n",
      "epoch 17; iter: 0; batch classifier loss: 0.445449; batch adversarial loss: 0.596000\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496180; batch adversarial loss: 0.573604\n",
      "epoch 19; iter: 0; batch classifier loss: 0.586198; batch adversarial loss: 0.550593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480655; batch adversarial loss: 0.542413\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536213; batch adversarial loss: 0.565475\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549641; batch adversarial loss: 0.510920\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515547; batch adversarial loss: 0.500990\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505442; batch adversarial loss: 0.508754\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452356; batch adversarial loss: 0.503431\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467777; batch adversarial loss: 0.634217\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453913; batch adversarial loss: 0.535974\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510870; batch adversarial loss: 0.503410\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455956; batch adversarial loss: 0.464495\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491356; batch adversarial loss: 0.596001\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490182; batch adversarial loss: 0.562692\n",
      "epoch 32; iter: 0; batch classifier loss: 0.534446; batch adversarial loss: 0.578895\n",
      "epoch 33; iter: 0; batch classifier loss: 0.417067; batch adversarial loss: 0.525540\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449669; batch adversarial loss: 0.560071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449250; batch adversarial loss: 0.517601\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440436; batch adversarial loss: 0.563080\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503918; batch adversarial loss: 0.606826\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399955; batch adversarial loss: 0.592256\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419331; batch adversarial loss: 0.570870\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417375; batch adversarial loss: 0.514828\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437379; batch adversarial loss: 0.606617\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490278; batch adversarial loss: 0.536762\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444246; batch adversarial loss: 0.509954\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420361; batch adversarial loss: 0.562802\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435629; batch adversarial loss: 0.507284\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420154; batch adversarial loss: 0.507642\n",
      "epoch 47; iter: 0; batch classifier loss: 0.506897; batch adversarial loss: 0.599828\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447322; batch adversarial loss: 0.524817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.505311; batch adversarial loss: 0.500165\n",
      "epoch 50; iter: 0; batch classifier loss: 0.370897; batch adversarial loss: 0.617810\n",
      "epoch 51; iter: 0; batch classifier loss: 0.487862; batch adversarial loss: 0.610660\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404622; batch adversarial loss: 0.499396\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403980; batch adversarial loss: 0.526101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392045; batch adversarial loss: 0.571099\n",
      "epoch 55; iter: 0; batch classifier loss: 0.470640; batch adversarial loss: 0.554994\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416945; batch adversarial loss: 0.590671\n",
      "epoch 57; iter: 0; batch classifier loss: 0.497432; batch adversarial loss: 0.508486\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448690; batch adversarial loss: 0.607062\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400014; batch adversarial loss: 0.562501\n",
      "epoch 60; iter: 0; batch classifier loss: 0.354998; batch adversarial loss: 0.526472\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424484; batch adversarial loss: 0.581384\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451267; batch adversarial loss: 0.535354\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422607; batch adversarial loss: 0.508615\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426469; batch adversarial loss: 0.544923\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425205; batch adversarial loss: 0.553439\n",
      "epoch 66; iter: 0; batch classifier loss: 0.345220; batch adversarial loss: 0.553821\n",
      "epoch 67; iter: 0; batch classifier loss: 0.382969; batch adversarial loss: 0.554005\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415729; batch adversarial loss: 0.580714\n",
      "epoch 69; iter: 0; batch classifier loss: 0.462460; batch adversarial loss: 0.534972\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464701; batch adversarial loss: 0.580701\n",
      "epoch 71; iter: 0; batch classifier loss: 0.421311; batch adversarial loss: 0.516651\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381710; batch adversarial loss: 0.526272\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404808; batch adversarial loss: 0.553966\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441943; batch adversarial loss: 0.599036\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387509; batch adversarial loss: 0.516103\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404550; batch adversarial loss: 0.516731\n",
      "epoch 77; iter: 0; batch classifier loss: 0.270332; batch adversarial loss: 0.516838\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447475; batch adversarial loss: 0.535828\n",
      "epoch 79; iter: 0; batch classifier loss: 0.502535; batch adversarial loss: 0.516885\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360505; batch adversarial loss: 0.590047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.377866; batch adversarial loss: 0.489736\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385197; batch adversarial loss: 0.562555\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374786; batch adversarial loss: 0.443010\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447556; batch adversarial loss: 0.608333\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406074; batch adversarial loss: 0.517230\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419417; batch adversarial loss: 0.563267\n",
      "epoch 87; iter: 0; batch classifier loss: 0.443869; batch adversarial loss: 0.562541\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368313; batch adversarial loss: 0.553845\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436816; batch adversarial loss: 0.653983\n",
      "epoch 90; iter: 0; batch classifier loss: 0.492690; batch adversarial loss: 0.526267\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382519; batch adversarial loss: 0.599883\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404545; batch adversarial loss: 0.516885\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418105; batch adversarial loss: 0.517668\n",
      "epoch 94; iter: 0; batch classifier loss: 0.327106; batch adversarial loss: 0.581059\n",
      "epoch 95; iter: 0; batch classifier loss: 0.472934; batch adversarial loss: 0.598659\n",
      "epoch 96; iter: 0; batch classifier loss: 0.453343; batch adversarial loss: 0.535076\n",
      "epoch 97; iter: 0; batch classifier loss: 0.412416; batch adversarial loss: 0.498473\n",
      "epoch 98; iter: 0; batch classifier loss: 0.374359; batch adversarial loss: 0.535079\n",
      "epoch 99; iter: 0; batch classifier loss: 0.307647; batch adversarial loss: 0.617115\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350565; batch adversarial loss: 0.543522\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392146; batch adversarial loss: 0.548086\n",
      "epoch 102; iter: 0; batch classifier loss: 0.418023; batch adversarial loss: 0.479692\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384320; batch adversarial loss: 0.537047\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362013; batch adversarial loss: 0.561191\n",
      "epoch 105; iter: 0; batch classifier loss: 0.428719; batch adversarial loss: 0.479396\n",
      "epoch 106; iter: 0; batch classifier loss: 0.337995; batch adversarial loss: 0.443497\n",
      "epoch 107; iter: 0; batch classifier loss: 0.475086; batch adversarial loss: 0.545598\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417520; batch adversarial loss: 0.572101\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396425; batch adversarial loss: 0.517914\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372410; batch adversarial loss: 0.625364\n",
      "epoch 111; iter: 0; batch classifier loss: 0.390417; batch adversarial loss: 0.499618\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430709; batch adversarial loss: 0.580695\n",
      "epoch 113; iter: 0; batch classifier loss: 0.398910; batch adversarial loss: 0.572180\n",
      "epoch 114; iter: 0; batch classifier loss: 0.334524; batch adversarial loss: 0.545025\n",
      "epoch 115; iter: 0; batch classifier loss: 0.496592; batch adversarial loss: 0.544953\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370338; batch adversarial loss: 0.580721\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372986; batch adversarial loss: 0.571926\n",
      "epoch 118; iter: 0; batch classifier loss: 0.450276; batch adversarial loss: 0.525475\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408817; batch adversarial loss: 0.553501\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413474; batch adversarial loss: 0.517283\n",
      "epoch 121; iter: 0; batch classifier loss: 0.480091; batch adversarial loss: 0.488542\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363948; batch adversarial loss: 0.471673\n",
      "epoch 123; iter: 0; batch classifier loss: 0.466638; batch adversarial loss: 0.589944\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404771; batch adversarial loss: 0.618231\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410677; batch adversarial loss: 0.609305\n",
      "epoch 126; iter: 0; batch classifier loss: 0.313244; batch adversarial loss: 0.571886\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394612; batch adversarial loss: 0.599643\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397798; batch adversarial loss: 0.545271\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358299; batch adversarial loss: 0.571658\n",
      "epoch 130; iter: 0; batch classifier loss: 0.351524; batch adversarial loss: 0.517250\n",
      "epoch 131; iter: 0; batch classifier loss: 0.462495; batch adversarial loss: 0.571869\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392924; batch adversarial loss: 0.571410\n",
      "epoch 133; iter: 0; batch classifier loss: 0.368030; batch adversarial loss: 0.534269\n",
      "epoch 134; iter: 0; batch classifier loss: 0.319989; batch adversarial loss: 0.608887\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371936; batch adversarial loss: 0.525112\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404297; batch adversarial loss: 0.544626\n",
      "epoch 137; iter: 0; batch classifier loss: 0.414150; batch adversarial loss: 0.544706\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394393; batch adversarial loss: 0.572672\n",
      "epoch 139; iter: 0; batch classifier loss: 0.399894; batch adversarial loss: 0.581244\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348275; batch adversarial loss: 0.581870\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344266; batch adversarial loss: 0.637013\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380278; batch adversarial loss: 0.636501\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385354; batch adversarial loss: 0.553073\n",
      "epoch 144; iter: 0; batch classifier loss: 0.411129; batch adversarial loss: 0.543718\n",
      "epoch 145; iter: 0; batch classifier loss: 0.409727; batch adversarial loss: 0.562640\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382374; batch adversarial loss: 0.499326\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382522; batch adversarial loss: 0.636887\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366912; batch adversarial loss: 0.543187\n",
      "epoch 149; iter: 0; batch classifier loss: 0.296213; batch adversarial loss: 0.617981\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367283; batch adversarial loss: 0.554066\n",
      "epoch 151; iter: 0; batch classifier loss: 0.306173; batch adversarial loss: 0.592363\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372833; batch adversarial loss: 0.570926\n",
      "epoch 153; iter: 0; batch classifier loss: 0.249646; batch adversarial loss: 0.534746\n",
      "epoch 154; iter: 0; batch classifier loss: 0.475404; batch adversarial loss: 0.570511\n",
      "epoch 155; iter: 0; batch classifier loss: 0.301446; batch adversarial loss: 0.554073\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361177; batch adversarial loss: 0.508119\n",
      "epoch 157; iter: 0; batch classifier loss: 0.391062; batch adversarial loss: 0.526670\n",
      "epoch 158; iter: 0; batch classifier loss: 0.436851; batch adversarial loss: 0.535020\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385866; batch adversarial loss: 0.490772\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406575; batch adversarial loss: 0.563459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335164; batch adversarial loss: 0.507626\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331098; batch adversarial loss: 0.598860\n",
      "epoch 163; iter: 0; batch classifier loss: 0.410450; batch adversarial loss: 0.562353\n",
      "epoch 164; iter: 0; batch classifier loss: 0.301012; batch adversarial loss: 0.479837\n",
      "epoch 165; iter: 0; batch classifier loss: 0.370223; batch adversarial loss: 0.544348\n",
      "epoch 166; iter: 0; batch classifier loss: 0.371137; batch adversarial loss: 0.527329\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334552; batch adversarial loss: 0.543726\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354946; batch adversarial loss: 0.636466\n",
      "epoch 169; iter: 0; batch classifier loss: 0.336687; batch adversarial loss: 0.516173\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349255; batch adversarial loss: 0.608134\n",
      "epoch 171; iter: 0; batch classifier loss: 0.299598; batch adversarial loss: 0.553298\n",
      "epoch 172; iter: 0; batch classifier loss: 0.452209; batch adversarial loss: 0.505493\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361442; batch adversarial loss: 0.524151\n",
      "epoch 174; iter: 0; batch classifier loss: 0.471101; batch adversarial loss: 0.556310\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355623; batch adversarial loss: 0.544922\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393588; batch adversarial loss: 0.534082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.414560; batch adversarial loss: 0.488168\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317754; batch adversarial loss: 0.591755\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303769; batch adversarial loss: 0.516542\n",
      "epoch 180; iter: 0; batch classifier loss: 0.399544; batch adversarial loss: 0.506726\n",
      "epoch 181; iter: 0; batch classifier loss: 0.304123; batch adversarial loss: 0.553087\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366023; batch adversarial loss: 0.580604\n",
      "epoch 183; iter: 0; batch classifier loss: 0.429866; batch adversarial loss: 0.535284\n",
      "epoch 184; iter: 0; batch classifier loss: 0.297854; batch adversarial loss: 0.562318\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336446; batch adversarial loss: 0.564091\n",
      "epoch 186; iter: 0; batch classifier loss: 0.412910; batch adversarial loss: 0.482761\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351941; batch adversarial loss: 0.491093\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369852; batch adversarial loss: 0.482206\n",
      "epoch 189; iter: 0; batch classifier loss: 0.320465; batch adversarial loss: 0.553125\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331119; batch adversarial loss: 0.596826\n",
      "epoch 191; iter: 0; batch classifier loss: 0.409397; batch adversarial loss: 0.544510\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338648; batch adversarial loss: 0.508094\n",
      "epoch 193; iter: 0; batch classifier loss: 0.451979; batch adversarial loss: 0.526729\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350695; batch adversarial loss: 0.472232\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342233; batch adversarial loss: 0.490949\n",
      "epoch 196; iter: 0; batch classifier loss: 0.429207; batch adversarial loss: 0.490834\n",
      "epoch 197; iter: 0; batch classifier loss: 0.404851; batch adversarial loss: 0.604286\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375983; batch adversarial loss: 0.515173\n",
      "epoch 199; iter: 0; batch classifier loss: 0.371946; batch adversarial loss: 0.532962\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697944; batch adversarial loss: 0.759817\n",
      "epoch 1; iter: 0; batch classifier loss: 0.558558; batch adversarial loss: 0.718454\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562606; batch adversarial loss: 0.682439\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547239; batch adversarial loss: 0.647627\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590656; batch adversarial loss: 0.648271\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558580; batch adversarial loss: 0.615773\n",
      "epoch 6; iter: 0; batch classifier loss: 0.620184; batch adversarial loss: 0.617941\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564155; batch adversarial loss: 0.596225\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552554; batch adversarial loss: 0.568424\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562054; batch adversarial loss: 0.600867\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550844; batch adversarial loss: 0.559707\n",
      "epoch 11; iter: 0; batch classifier loss: 0.474988; batch adversarial loss: 0.485173\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485072; batch adversarial loss: 0.548131\n",
      "epoch 13; iter: 0; batch classifier loss: 0.459899; batch adversarial loss: 0.591218\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545848; batch adversarial loss: 0.588503\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498915; batch adversarial loss: 0.555857\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531434; batch adversarial loss: 0.602147\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511475; batch adversarial loss: 0.540556\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517938; batch adversarial loss: 0.484093\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499972; batch adversarial loss: 0.607212\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530191; batch adversarial loss: 0.492116\n",
      "epoch 21; iter: 0; batch classifier loss: 0.437793; batch adversarial loss: 0.505366\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483566; batch adversarial loss: 0.552052\n",
      "epoch 23; iter: 0; batch classifier loss: 0.530765; batch adversarial loss: 0.600130\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531762; batch adversarial loss: 0.551390\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470654; batch adversarial loss: 0.538986\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483063; batch adversarial loss: 0.527880\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427160; batch adversarial loss: 0.580822\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457922; batch adversarial loss: 0.556838\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477023; batch adversarial loss: 0.557369\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468423; batch adversarial loss: 0.603363\n",
      "epoch 31; iter: 0; batch classifier loss: 0.561933; batch adversarial loss: 0.522138\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400280; batch adversarial loss: 0.504012\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451940; batch adversarial loss: 0.502888\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432841; batch adversarial loss: 0.639234\n",
      "epoch 35; iter: 0; batch classifier loss: 0.500547; batch adversarial loss: 0.493008\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434336; batch adversarial loss: 0.544836\n",
      "epoch 37; iter: 0; batch classifier loss: 0.437317; batch adversarial loss: 0.491242\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434683; batch adversarial loss: 0.454081\n",
      "epoch 39; iter: 0; batch classifier loss: 0.523529; batch adversarial loss: 0.544814\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454934; batch adversarial loss: 0.599565\n",
      "epoch 41; iter: 0; batch classifier loss: 0.392429; batch adversarial loss: 0.581863\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466639; batch adversarial loss: 0.515845\n",
      "epoch 43; iter: 0; batch classifier loss: 0.404244; batch adversarial loss: 0.581456\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461760; batch adversarial loss: 0.562260\n",
      "epoch 45; iter: 0; batch classifier loss: 0.537860; batch adversarial loss: 0.563083\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437423; batch adversarial loss: 0.636258\n",
      "epoch 47; iter: 0; batch classifier loss: 0.503313; batch adversarial loss: 0.535952\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428295; batch adversarial loss: 0.571151\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391277; batch adversarial loss: 0.572098\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391660; batch adversarial loss: 0.505982\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438356; batch adversarial loss: 0.637947\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429364; batch adversarial loss: 0.469681\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422757; batch adversarial loss: 0.610006\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430115; batch adversarial loss: 0.525958\n",
      "epoch 55; iter: 0; batch classifier loss: 0.366158; batch adversarial loss: 0.564188\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426314; batch adversarial loss: 0.544190\n",
      "epoch 57; iter: 0; batch classifier loss: 0.451720; batch adversarial loss: 0.561731\n",
      "epoch 58; iter: 0; batch classifier loss: 0.405154; batch adversarial loss: 0.599343\n",
      "epoch 59; iter: 0; batch classifier loss: 0.496508; batch adversarial loss: 0.515736\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409758; batch adversarial loss: 0.516191\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395766; batch adversarial loss: 0.545176\n",
      "epoch 62; iter: 0; batch classifier loss: 0.413446; batch adversarial loss: 0.555060\n",
      "epoch 63; iter: 0; batch classifier loss: 0.424492; batch adversarial loss: 0.563310\n",
      "epoch 64; iter: 0; batch classifier loss: 0.485242; batch adversarial loss: 0.507200\n",
      "epoch 65; iter: 0; batch classifier loss: 0.387824; batch adversarial loss: 0.534524\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445360; batch adversarial loss: 0.508146\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408940; batch adversarial loss: 0.562049\n",
      "epoch 68; iter: 0; batch classifier loss: 0.581243; batch adversarial loss: 0.469356\n",
      "epoch 69; iter: 0; batch classifier loss: 0.434966; batch adversarial loss: 0.516165\n",
      "epoch 70; iter: 0; batch classifier loss: 0.470981; batch adversarial loss: 0.537037\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366678; batch adversarial loss: 0.527260\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402742; batch adversarial loss: 0.553887\n",
      "epoch 73; iter: 0; batch classifier loss: 0.522104; batch adversarial loss: 0.469977\n",
      "epoch 74; iter: 0; batch classifier loss: 0.468871; batch adversarial loss: 0.608906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.487316; batch adversarial loss: 0.535136\n",
      "epoch 76; iter: 0; batch classifier loss: 0.322453; batch adversarial loss: 0.516712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379425; batch adversarial loss: 0.516984\n",
      "epoch 78; iter: 0; batch classifier loss: 0.546736; batch adversarial loss: 0.563518\n",
      "epoch 79; iter: 0; batch classifier loss: 0.435502; batch adversarial loss: 0.526859\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356781; batch adversarial loss: 0.460092\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408722; batch adversarial loss: 0.561784\n",
      "epoch 82; iter: 0; batch classifier loss: 0.351084; batch adversarial loss: 0.554962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394915; batch adversarial loss: 0.516600\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390021; batch adversarial loss: 0.535137\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347220; batch adversarial loss: 0.544055\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425644; batch adversarial loss: 0.608427\n",
      "epoch 87; iter: 0; batch classifier loss: 0.419374; batch adversarial loss: 0.535891\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396313; batch adversarial loss: 0.497708\n",
      "epoch 89; iter: 0; batch classifier loss: 0.418951; batch adversarial loss: 0.525441\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398062; batch adversarial loss: 0.526896\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411484; batch adversarial loss: 0.506836\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403264; batch adversarial loss: 0.526903\n",
      "epoch 93; iter: 0; batch classifier loss: 0.476100; batch adversarial loss: 0.497834\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383434; batch adversarial loss: 0.562070\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395390; batch adversarial loss: 0.534427\n",
      "epoch 96; iter: 0; batch classifier loss: 0.415221; batch adversarial loss: 0.515055\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423585; batch adversarial loss: 0.535292\n",
      "epoch 98; iter: 0; batch classifier loss: 0.502382; batch adversarial loss: 0.516681\n",
      "epoch 99; iter: 0; batch classifier loss: 0.362236; batch adversarial loss: 0.458146\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416669; batch adversarial loss: 0.553688\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421744; batch adversarial loss: 0.517631\n",
      "epoch 102; iter: 0; batch classifier loss: 0.483107; batch adversarial loss: 0.518810\n",
      "epoch 103; iter: 0; batch classifier loss: 0.422328; batch adversarial loss: 0.543033\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420749; batch adversarial loss: 0.574108\n",
      "epoch 105; iter: 0; batch classifier loss: 0.390535; batch adversarial loss: 0.535182\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379581; batch adversarial loss: 0.544304\n",
      "epoch 107; iter: 0; batch classifier loss: 0.473865; batch adversarial loss: 0.440794\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383325; batch adversarial loss: 0.582393\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415942; batch adversarial loss: 0.477610\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392736; batch adversarial loss: 0.563940\n",
      "epoch 111; iter: 0; batch classifier loss: 0.282564; batch adversarial loss: 0.554824\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347907; batch adversarial loss: 0.572422\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353395; batch adversarial loss: 0.561276\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362292; batch adversarial loss: 0.552337\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381123; batch adversarial loss: 0.591238\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373524; batch adversarial loss: 0.564722\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386871; batch adversarial loss: 0.506559\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381040; batch adversarial loss: 0.546094\n",
      "epoch 119; iter: 0; batch classifier loss: 0.444718; batch adversarial loss: 0.581606\n",
      "epoch 120; iter: 0; batch classifier loss: 0.419237; batch adversarial loss: 0.583597\n",
      "epoch 121; iter: 0; batch classifier loss: 0.437078; batch adversarial loss: 0.554802\n",
      "epoch 122; iter: 0; batch classifier loss: 0.460646; batch adversarial loss: 0.588986\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381308; batch adversarial loss: 0.440255\n",
      "epoch 124; iter: 0; batch classifier loss: 0.293070; batch adversarial loss: 0.637735\n",
      "epoch 125; iter: 0; batch classifier loss: 0.426171; batch adversarial loss: 0.527267\n",
      "epoch 126; iter: 0; batch classifier loss: 0.415786; batch adversarial loss: 0.591375\n",
      "epoch 127; iter: 0; batch classifier loss: 0.439176; batch adversarial loss: 0.573868\n",
      "epoch 128; iter: 0; batch classifier loss: 0.321706; batch adversarial loss: 0.580740\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394791; batch adversarial loss: 0.618450\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352855; batch adversarial loss: 0.459358\n",
      "epoch 131; iter: 0; batch classifier loss: 0.329177; batch adversarial loss: 0.542248\n",
      "epoch 132; iter: 0; batch classifier loss: 0.290858; batch adversarial loss: 0.491021\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349611; batch adversarial loss: 0.574701\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373004; batch adversarial loss: 0.526478\n",
      "epoch 135; iter: 0; batch classifier loss: 0.302780; batch adversarial loss: 0.489626\n",
      "epoch 136; iter: 0; batch classifier loss: 0.415030; batch adversarial loss: 0.488322\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379895; batch adversarial loss: 0.601232\n",
      "epoch 138; iter: 0; batch classifier loss: 0.418932; batch adversarial loss: 0.556811\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368791; batch adversarial loss: 0.489017\n",
      "epoch 140; iter: 0; batch classifier loss: 0.456266; batch adversarial loss: 0.529404\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329886; batch adversarial loss: 0.543957\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391597; batch adversarial loss: 0.563160\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378688; batch adversarial loss: 0.469113\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352086; batch adversarial loss: 0.609705\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407808; batch adversarial loss: 0.637732\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378465; batch adversarial loss: 0.608011\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339871; batch adversarial loss: 0.545228\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337834; batch adversarial loss: 0.572223\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369720; batch adversarial loss: 0.543985\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363946; batch adversarial loss: 0.537624\n",
      "epoch 151; iter: 0; batch classifier loss: 0.317948; batch adversarial loss: 0.517833\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378306; batch adversarial loss: 0.562938\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366920; batch adversarial loss: 0.506766\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358942; batch adversarial loss: 0.499596\n",
      "epoch 155; iter: 0; batch classifier loss: 0.391712; batch adversarial loss: 0.516961\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377836; batch adversarial loss: 0.566122\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403456; batch adversarial loss: 0.496370\n",
      "epoch 158; iter: 0; batch classifier loss: 0.405045; batch adversarial loss: 0.579892\n",
      "epoch 159; iter: 0; batch classifier loss: 0.253173; batch adversarial loss: 0.470330\n",
      "epoch 160; iter: 0; batch classifier loss: 0.346631; batch adversarial loss: 0.477827\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362624; batch adversarial loss: 0.535334\n",
      "epoch 162; iter: 0; batch classifier loss: 0.399402; batch adversarial loss: 0.535146\n",
      "epoch 163; iter: 0; batch classifier loss: 0.458330; batch adversarial loss: 0.507407\n",
      "epoch 164; iter: 0; batch classifier loss: 0.404670; batch adversarial loss: 0.592406\n",
      "epoch 165; iter: 0; batch classifier loss: 0.336685; batch adversarial loss: 0.488313\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342506; batch adversarial loss: 0.489000\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395633; batch adversarial loss: 0.535879\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347033; batch adversarial loss: 0.527511\n",
      "epoch 169; iter: 0; batch classifier loss: 0.423115; batch adversarial loss: 0.517275\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366658; batch adversarial loss: 0.486860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.336934; batch adversarial loss: 0.561401\n",
      "epoch 172; iter: 0; batch classifier loss: 0.426300; batch adversarial loss: 0.488681\n",
      "epoch 173; iter: 0; batch classifier loss: 0.434623; batch adversarial loss: 0.533988\n",
      "epoch 174; iter: 0; batch classifier loss: 0.422213; batch adversarial loss: 0.565727\n",
      "epoch 175; iter: 0; batch classifier loss: 0.373274; batch adversarial loss: 0.572190\n",
      "epoch 176; iter: 0; batch classifier loss: 0.422213; batch adversarial loss: 0.424399\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315815; batch adversarial loss: 0.524686\n",
      "epoch 178; iter: 0; batch classifier loss: 0.429342; batch adversarial loss: 0.478879\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380399; batch adversarial loss: 0.582682\n",
      "epoch 180; iter: 0; batch classifier loss: 0.305238; batch adversarial loss: 0.498383\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377551; batch adversarial loss: 0.497620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.444493; batch adversarial loss: 0.533872\n",
      "epoch 183; iter: 0; batch classifier loss: 0.426566; batch adversarial loss: 0.534208\n",
      "epoch 184; iter: 0; batch classifier loss: 0.298119; batch adversarial loss: 0.609669\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308614; batch adversarial loss: 0.450784\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338264; batch adversarial loss: 0.514886\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334051; batch adversarial loss: 0.517289\n",
      "epoch 188; iter: 0; batch classifier loss: 0.406475; batch adversarial loss: 0.469626\n",
      "epoch 189; iter: 0; batch classifier loss: 0.317197; batch adversarial loss: 0.563628\n",
      "epoch 190; iter: 0; batch classifier loss: 0.409578; batch adversarial loss: 0.550588\n",
      "epoch 191; iter: 0; batch classifier loss: 0.446825; batch adversarial loss: 0.498115\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401049; batch adversarial loss: 0.609056\n",
      "epoch 193; iter: 0; batch classifier loss: 0.256956; batch adversarial loss: 0.488609\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419826; batch adversarial loss: 0.581388\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351558; batch adversarial loss: 0.527636\n",
      "epoch 196; iter: 0; batch classifier loss: 0.265449; batch adversarial loss: 0.626388\n",
      "epoch 197; iter: 0; batch classifier loss: 0.417833; batch adversarial loss: 0.600473\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350112; batch adversarial loss: 0.515124\n",
      "epoch 199; iter: 0; batch classifier loss: 0.298534; batch adversarial loss: 0.478278\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690091; batch adversarial loss: 0.730528\n",
      "epoch 1; iter: 0; batch classifier loss: 0.750013; batch adversarial loss: 0.759573\n",
      "epoch 2; iter: 0; batch classifier loss: 0.649235; batch adversarial loss: 0.693229\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616939; batch adversarial loss: 0.636149\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581481; batch adversarial loss: 0.629180\n",
      "epoch 5; iter: 0; batch classifier loss: 0.565765; batch adversarial loss: 0.609746\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552554; batch adversarial loss: 0.592541\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535916; batch adversarial loss: 0.576629\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520155; batch adversarial loss: 0.592109\n",
      "epoch 9; iter: 0; batch classifier loss: 0.457726; batch adversarial loss: 0.632603\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548338; batch adversarial loss: 0.539613\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501633; batch adversarial loss: 0.538439\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539299; batch adversarial loss: 0.595225\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525935; batch adversarial loss: 0.558320\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553664; batch adversarial loss: 0.544036\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543853; batch adversarial loss: 0.554082\n",
      "epoch 16; iter: 0; batch classifier loss: 0.524059; batch adversarial loss: 0.502737\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496344; batch adversarial loss: 0.591020\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507322; batch adversarial loss: 0.561837\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501456; batch adversarial loss: 0.494191\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462834; batch adversarial loss: 0.563282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.433898; batch adversarial loss: 0.562654\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486295; batch adversarial loss: 0.480851\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501144; batch adversarial loss: 0.498395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435221; batch adversarial loss: 0.486157\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527177; batch adversarial loss: 0.591202\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480872; batch adversarial loss: 0.514254\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460624; batch adversarial loss: 0.506405\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512482; batch adversarial loss: 0.544393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.518958; batch adversarial loss: 0.609436\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453333; batch adversarial loss: 0.532575\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398820; batch adversarial loss: 0.601868\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422910; batch adversarial loss: 0.429329\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519811; batch adversarial loss: 0.543984\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448024; batch adversarial loss: 0.499085\n",
      "epoch 35; iter: 0; batch classifier loss: 0.509908; batch adversarial loss: 0.519243\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407734; batch adversarial loss: 0.585645\n",
      "epoch 37; iter: 0; batch classifier loss: 0.468858; batch adversarial loss: 0.550684\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406879; batch adversarial loss: 0.543594\n",
      "epoch 39; iter: 0; batch classifier loss: 0.515601; batch adversarial loss: 0.533928\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411770; batch adversarial loss: 0.532671\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426889; batch adversarial loss: 0.508579\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429575; batch adversarial loss: 0.525988\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460787; batch adversarial loss: 0.510087\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458374; batch adversarial loss: 0.580407\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435509; batch adversarial loss: 0.508603\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451389; batch adversarial loss: 0.544510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444191; batch adversarial loss: 0.487744\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449534; batch adversarial loss: 0.488093\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413967; batch adversarial loss: 0.553454\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394942; batch adversarial loss: 0.467603\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470797; batch adversarial loss: 0.458023\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435476; batch adversarial loss: 0.524421\n",
      "epoch 53; iter: 0; batch classifier loss: 0.485569; batch adversarial loss: 0.535395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400985; batch adversarial loss: 0.486715\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485594; batch adversarial loss: 0.476923\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413672; batch adversarial loss: 0.437505\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421198; batch adversarial loss: 0.544789\n",
      "epoch 58; iter: 0; batch classifier loss: 0.510630; batch adversarial loss: 0.553838\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414510; batch adversarial loss: 0.594045\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446648; batch adversarial loss: 0.486398\n",
      "epoch 61; iter: 0; batch classifier loss: 0.487167; batch adversarial loss: 0.554843\n",
      "epoch 62; iter: 0; batch classifier loss: 0.458060; batch adversarial loss: 0.593740\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394851; batch adversarial loss: 0.485991\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437300; batch adversarial loss: 0.613792\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401810; batch adversarial loss: 0.466347\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415871; batch adversarial loss: 0.456340\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366541; batch adversarial loss: 0.505791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.435567; batch adversarial loss: 0.575002\n",
      "epoch 69; iter: 0; batch classifier loss: 0.462915; batch adversarial loss: 0.455826\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413888; batch adversarial loss: 0.496505\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427188; batch adversarial loss: 0.523325\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414251; batch adversarial loss: 0.575669\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391040; batch adversarial loss: 0.554665\n",
      "epoch 74; iter: 0; batch classifier loss: 0.344020; batch adversarial loss: 0.520524\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418979; batch adversarial loss: 0.514439\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397117; batch adversarial loss: 0.559699\n",
      "epoch 77; iter: 0; batch classifier loss: 0.420433; batch adversarial loss: 0.532356\n",
      "epoch 78; iter: 0; batch classifier loss: 0.319240; batch adversarial loss: 0.507440\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367010; batch adversarial loss: 0.583706\n",
      "epoch 80; iter: 0; batch classifier loss: 0.479943; batch adversarial loss: 0.533525\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387347; batch adversarial loss: 0.505853\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446948; batch adversarial loss: 0.564633\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429835; batch adversarial loss: 0.577671\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401195; batch adversarial loss: 0.525095\n",
      "epoch 85; iter: 0; batch classifier loss: 0.461245; batch adversarial loss: 0.592725\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381024; batch adversarial loss: 0.497357\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406634; batch adversarial loss: 0.476519\n",
      "epoch 88; iter: 0; batch classifier loss: 0.347831; batch adversarial loss: 0.544431\n",
      "epoch 89; iter: 0; batch classifier loss: 0.447710; batch adversarial loss: 0.495836\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364322; batch adversarial loss: 0.565133\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393493; batch adversarial loss: 0.475776\n",
      "epoch 92; iter: 0; batch classifier loss: 0.482577; batch adversarial loss: 0.564496\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402734; batch adversarial loss: 0.565015\n",
      "epoch 94; iter: 0; batch classifier loss: 0.493739; batch adversarial loss: 0.515143\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401747; batch adversarial loss: 0.467284\n",
      "epoch 96; iter: 0; batch classifier loss: 0.445689; batch adversarial loss: 0.545137\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437061; batch adversarial loss: 0.475845\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387818; batch adversarial loss: 0.593863\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429257; batch adversarial loss: 0.575360\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387686; batch adversarial loss: 0.534994\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392067; batch adversarial loss: 0.525052\n",
      "epoch 102; iter: 0; batch classifier loss: 0.406289; batch adversarial loss: 0.466576\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413730; batch adversarial loss: 0.535615\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383146; batch adversarial loss: 0.534956\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361521; batch adversarial loss: 0.535131\n",
      "epoch 106; iter: 0; batch classifier loss: 0.485199; batch adversarial loss: 0.495621\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396431; batch adversarial loss: 0.534985\n",
      "epoch 108; iter: 0; batch classifier loss: 0.424678; batch adversarial loss: 0.674631\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355671; batch adversarial loss: 0.505330\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429796; batch adversarial loss: 0.525391\n",
      "epoch 111; iter: 0; batch classifier loss: 0.446296; batch adversarial loss: 0.505434\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376832; batch adversarial loss: 0.486023\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406694; batch adversarial loss: 0.476037\n",
      "epoch 114; iter: 0; batch classifier loss: 0.448247; batch adversarial loss: 0.446450\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348487; batch adversarial loss: 0.565017\n",
      "epoch 116; iter: 0; batch classifier loss: 0.493110; batch adversarial loss: 0.585342\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357741; batch adversarial loss: 0.466514\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387855; batch adversarial loss: 0.535130\n",
      "epoch 119; iter: 0; batch classifier loss: 0.406249; batch adversarial loss: 0.574542\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401059; batch adversarial loss: 0.475814\n",
      "epoch 121; iter: 0; batch classifier loss: 0.423831; batch adversarial loss: 0.584318\n",
      "epoch 122; iter: 0; batch classifier loss: 0.328627; batch adversarial loss: 0.504736\n",
      "epoch 123; iter: 0; batch classifier loss: 0.491760; batch adversarial loss: 0.505493\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353438; batch adversarial loss: 0.534162\n",
      "epoch 125; iter: 0; batch classifier loss: 0.291866; batch adversarial loss: 0.496764\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373697; batch adversarial loss: 0.514927\n",
      "epoch 127; iter: 0; batch classifier loss: 0.416902; batch adversarial loss: 0.476151\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353690; batch adversarial loss: 0.544805\n",
      "epoch 129; iter: 0; batch classifier loss: 0.366610; batch adversarial loss: 0.535694\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342478; batch adversarial loss: 0.554504\n",
      "epoch 131; iter: 0; batch classifier loss: 0.369084; batch adversarial loss: 0.525704\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358639; batch adversarial loss: 0.476015\n",
      "epoch 133; iter: 0; batch classifier loss: 0.461499; batch adversarial loss: 0.514351\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373250; batch adversarial loss: 0.494699\n",
      "epoch 135; iter: 0; batch classifier loss: 0.345652; batch adversarial loss: 0.524811\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421757; batch adversarial loss: 0.474423\n",
      "epoch 137; iter: 0; batch classifier loss: 0.333503; batch adversarial loss: 0.460987\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405658; batch adversarial loss: 0.456279\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357398; batch adversarial loss: 0.451498\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377288; batch adversarial loss: 0.545761\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357840; batch adversarial loss: 0.533996\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386008; batch adversarial loss: 0.574943\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356134; batch adversarial loss: 0.475207\n",
      "epoch 144; iter: 0; batch classifier loss: 0.306773; batch adversarial loss: 0.537533\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353203; batch adversarial loss: 0.534365\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353082; batch adversarial loss: 0.468979\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365822; batch adversarial loss: 0.602191\n",
      "epoch 148; iter: 0; batch classifier loss: 0.302559; batch adversarial loss: 0.593244\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352337; batch adversarial loss: 0.543840\n",
      "epoch 150; iter: 0; batch classifier loss: 0.444598; batch adversarial loss: 0.544787\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371884; batch adversarial loss: 0.506929\n",
      "epoch 152; iter: 0; batch classifier loss: 0.361983; batch adversarial loss: 0.525484\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385934; batch adversarial loss: 0.545424\n",
      "epoch 154; iter: 0; batch classifier loss: 0.419666; batch adversarial loss: 0.484293\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360881; batch adversarial loss: 0.436749\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350787; batch adversarial loss: 0.514616\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353039; batch adversarial loss: 0.503466\n",
      "epoch 158; iter: 0; batch classifier loss: 0.468672; batch adversarial loss: 0.584838\n",
      "epoch 159; iter: 0; batch classifier loss: 0.357883; batch adversarial loss: 0.495924\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379263; batch adversarial loss: 0.525221\n",
      "epoch 161; iter: 0; batch classifier loss: 0.377014; batch adversarial loss: 0.585304\n",
      "epoch 162; iter: 0; batch classifier loss: 0.402069; batch adversarial loss: 0.456767\n",
      "epoch 163; iter: 0; batch classifier loss: 0.290891; batch adversarial loss: 0.467378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.370354; batch adversarial loss: 0.476024\n",
      "epoch 165; iter: 0; batch classifier loss: 0.447289; batch adversarial loss: 0.602860\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340611; batch adversarial loss: 0.546286\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301861; batch adversarial loss: 0.603443\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327148; batch adversarial loss: 0.555326\n",
      "epoch 169; iter: 0; batch classifier loss: 0.373135; batch adversarial loss: 0.466389\n",
      "epoch 170; iter: 0; batch classifier loss: 0.389451; batch adversarial loss: 0.456203\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411210; batch adversarial loss: 0.466552\n",
      "epoch 172; iter: 0; batch classifier loss: 0.440450; batch adversarial loss: 0.496390\n",
      "epoch 173; iter: 0; batch classifier loss: 0.409295; batch adversarial loss: 0.524572\n",
      "epoch 174; iter: 0; batch classifier loss: 0.439170; batch adversarial loss: 0.525223\n",
      "epoch 175; iter: 0; batch classifier loss: 0.315292; batch adversarial loss: 0.505292\n",
      "epoch 176; iter: 0; batch classifier loss: 0.280072; batch adversarial loss: 0.516151\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339843; batch adversarial loss: 0.446384\n",
      "epoch 178; iter: 0; batch classifier loss: 0.386879; batch adversarial loss: 0.524293\n",
      "epoch 179; iter: 0; batch classifier loss: 0.365817; batch adversarial loss: 0.525051\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371593; batch adversarial loss: 0.554904\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343891; batch adversarial loss: 0.465742\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382877; batch adversarial loss: 0.585247\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345331; batch adversarial loss: 0.515456\n",
      "epoch 184; iter: 0; batch classifier loss: 0.270592; batch adversarial loss: 0.594540\n",
      "epoch 185; iter: 0; batch classifier loss: 0.385158; batch adversarial loss: 0.485684\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343674; batch adversarial loss: 0.575216\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373352; batch adversarial loss: 0.456634\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365608; batch adversarial loss: 0.455875\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414842; batch adversarial loss: 0.633027\n",
      "epoch 190; iter: 0; batch classifier loss: 0.429860; batch adversarial loss: 0.456311\n",
      "epoch 191; iter: 0; batch classifier loss: 0.353869; batch adversarial loss: 0.494616\n",
      "epoch 192; iter: 0; batch classifier loss: 0.403479; batch adversarial loss: 0.516175\n",
      "epoch 193; iter: 0; batch classifier loss: 0.339966; batch adversarial loss: 0.654656\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340482; batch adversarial loss: 0.456194\n",
      "epoch 195; iter: 0; batch classifier loss: 0.326629; batch adversarial loss: 0.534999\n",
      "epoch 196; iter: 0; batch classifier loss: 0.440402; batch adversarial loss: 0.536533\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353423; batch adversarial loss: 0.495855\n",
      "epoch 198; iter: 0; batch classifier loss: 0.408391; batch adversarial loss: 0.485601\n",
      "epoch 199; iter: 0; batch classifier loss: 0.461519; batch adversarial loss: 0.506628\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738301; batch adversarial loss: 0.645401\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593424; batch adversarial loss: 0.625458\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466799; batch adversarial loss: 0.633911\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590093; batch adversarial loss: 0.638342\n",
      "epoch 4; iter: 0; batch classifier loss: 0.620955; batch adversarial loss: 0.611308\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556302; batch adversarial loss: 0.589220\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573713; batch adversarial loss: 0.669110\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552690; batch adversarial loss: 0.617433\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569091; batch adversarial loss: 0.622258\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575294; batch adversarial loss: 0.595639\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499750; batch adversarial loss: 0.529900\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573486; batch adversarial loss: 0.580082\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550033; batch adversarial loss: 0.588374\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480032; batch adversarial loss: 0.599117\n",
      "epoch 14; iter: 0; batch classifier loss: 0.574042; batch adversarial loss: 0.626217\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409387; batch adversarial loss: 0.602316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.569077; batch adversarial loss: 0.583010\n",
      "epoch 17; iter: 0; batch classifier loss: 0.565021; batch adversarial loss: 0.589227\n",
      "epoch 18; iter: 0; batch classifier loss: 0.576782; batch adversarial loss: 0.580141\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530890; batch adversarial loss: 0.572358\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521036; batch adversarial loss: 0.699324\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464843; batch adversarial loss: 0.597328\n",
      "epoch 22; iter: 0; batch classifier loss: 0.511131; batch adversarial loss: 0.519875\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490387; batch adversarial loss: 0.559383\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485631; batch adversarial loss: 0.514124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457525; batch adversarial loss: 0.552901\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500721; batch adversarial loss: 0.544681\n",
      "epoch 27; iter: 0; batch classifier loss: 0.523760; batch adversarial loss: 0.479610\n",
      "epoch 28; iter: 0; batch classifier loss: 0.497012; batch adversarial loss: 0.535286\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445687; batch adversarial loss: 0.587184\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471573; batch adversarial loss: 0.560323\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436375; batch adversarial loss: 0.640705\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487763; batch adversarial loss: 0.558807\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420686; batch adversarial loss: 0.626960\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435453; batch adversarial loss: 0.527359\n",
      "epoch 35; iter: 0; batch classifier loss: 0.428050; batch adversarial loss: 0.595120\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407307; batch adversarial loss: 0.525657\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461230; batch adversarial loss: 0.541769\n",
      "epoch 38; iter: 0; batch classifier loss: 0.472154; batch adversarial loss: 0.594547\n",
      "epoch 39; iter: 0; batch classifier loss: 0.503939; batch adversarial loss: 0.545893\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472313; batch adversarial loss: 0.512624\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453688; batch adversarial loss: 0.512280\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422886; batch adversarial loss: 0.540591\n",
      "epoch 43; iter: 0; batch classifier loss: 0.385842; batch adversarial loss: 0.567024\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426440; batch adversarial loss: 0.580576\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437279; batch adversarial loss: 0.563900\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437351; batch adversarial loss: 0.545177\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418278; batch adversarial loss: 0.560940\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461557; batch adversarial loss: 0.570248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443632; batch adversarial loss: 0.544702\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449949; batch adversarial loss: 0.524166\n",
      "epoch 51; iter: 0; batch classifier loss: 0.377185; batch adversarial loss: 0.563288\n",
      "epoch 52; iter: 0; batch classifier loss: 0.493641; batch adversarial loss: 0.587553\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391060; batch adversarial loss: 0.571275\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437322; batch adversarial loss: 0.588429\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478174; batch adversarial loss: 0.569575\n",
      "epoch 56; iter: 0; batch classifier loss: 0.478162; batch adversarial loss: 0.592802\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403971; batch adversarial loss: 0.518597\n",
      "epoch 58; iter: 0; batch classifier loss: 0.491796; batch adversarial loss: 0.522949\n",
      "epoch 59; iter: 0; batch classifier loss: 0.430836; batch adversarial loss: 0.555460\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402966; batch adversarial loss: 0.488184\n",
      "epoch 61; iter: 0; batch classifier loss: 0.450793; batch adversarial loss: 0.535493\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428196; batch adversarial loss: 0.570848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.428042; batch adversarial loss: 0.589155\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460179; batch adversarial loss: 0.517419\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453696; batch adversarial loss: 0.491326\n",
      "epoch 66; iter: 0; batch classifier loss: 0.450001; batch adversarial loss: 0.557462\n",
      "epoch 67; iter: 0; batch classifier loss: 0.358717; batch adversarial loss: 0.607720\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410466; batch adversarial loss: 0.585068\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410098; batch adversarial loss: 0.459459\n",
      "epoch 70; iter: 0; batch classifier loss: 0.471701; batch adversarial loss: 0.576615\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410571; batch adversarial loss: 0.540487\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432093; batch adversarial loss: 0.590453\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394042; batch adversarial loss: 0.573402\n",
      "epoch 74; iter: 0; batch classifier loss: 0.350978; batch adversarial loss: 0.521642\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378737; batch adversarial loss: 0.547784\n",
      "epoch 76; iter: 0; batch classifier loss: 0.437198; batch adversarial loss: 0.564010\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406130; batch adversarial loss: 0.610315\n",
      "epoch 78; iter: 0; batch classifier loss: 0.475249; batch adversarial loss: 0.555604\n",
      "epoch 79; iter: 0; batch classifier loss: 0.449944; batch adversarial loss: 0.487441\n",
      "epoch 80; iter: 0; batch classifier loss: 0.344262; batch adversarial loss: 0.613042\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402320; batch adversarial loss: 0.596023\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389191; batch adversarial loss: 0.525828\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448170; batch adversarial loss: 0.571352\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431812; batch adversarial loss: 0.537987\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397141; batch adversarial loss: 0.553044\n",
      "epoch 86; iter: 0; batch classifier loss: 0.359676; batch adversarial loss: 0.534818\n",
      "epoch 87; iter: 0; batch classifier loss: 0.361666; batch adversarial loss: 0.570216\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387323; batch adversarial loss: 0.522953\n",
      "epoch 89; iter: 0; batch classifier loss: 0.421469; batch adversarial loss: 0.647696\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408102; batch adversarial loss: 0.503477\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374028; batch adversarial loss: 0.579165\n",
      "epoch 92; iter: 0; batch classifier loss: 0.470691; batch adversarial loss: 0.490616\n",
      "epoch 93; iter: 0; batch classifier loss: 0.469881; batch adversarial loss: 0.577678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385349; batch adversarial loss: 0.521207\n",
      "epoch 95; iter: 0; batch classifier loss: 0.411527; batch adversarial loss: 0.644108\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386324; batch adversarial loss: 0.629008\n",
      "epoch 97; iter: 0; batch classifier loss: 0.447326; batch adversarial loss: 0.543734\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412524; batch adversarial loss: 0.560618\n",
      "epoch 99; iter: 0; batch classifier loss: 0.426445; batch adversarial loss: 0.559478\n",
      "epoch 100; iter: 0; batch classifier loss: 0.485097; batch adversarial loss: 0.589451\n",
      "epoch 101; iter: 0; batch classifier loss: 0.330127; batch adversarial loss: 0.599505\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385274; batch adversarial loss: 0.537959\n",
      "epoch 103; iter: 0; batch classifier loss: 0.432707; batch adversarial loss: 0.484819\n",
      "epoch 104; iter: 0; batch classifier loss: 0.279354; batch adversarial loss: 0.484504\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401521; batch adversarial loss: 0.587620\n",
      "epoch 106; iter: 0; batch classifier loss: 0.472425; batch adversarial loss: 0.653728\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382390; batch adversarial loss: 0.611669\n",
      "epoch 108; iter: 0; batch classifier loss: 0.458715; batch adversarial loss: 0.586794\n",
      "epoch 109; iter: 0; batch classifier loss: 0.444119; batch adversarial loss: 0.560512\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429415; batch adversarial loss: 0.536029\n",
      "epoch 111; iter: 0; batch classifier loss: 0.426906; batch adversarial loss: 0.585235\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383583; batch adversarial loss: 0.554843\n",
      "epoch 113; iter: 0; batch classifier loss: 0.348765; batch adversarial loss: 0.580829\n",
      "epoch 114; iter: 0; batch classifier loss: 0.355539; batch adversarial loss: 0.571108\n",
      "epoch 115; iter: 0; batch classifier loss: 0.313397; batch adversarial loss: 0.607673\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353765; batch adversarial loss: 0.579653\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405789; batch adversarial loss: 0.561648\n",
      "epoch 118; iter: 0; batch classifier loss: 0.458673; batch adversarial loss: 0.568441\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368082; batch adversarial loss: 0.501600\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337493; batch adversarial loss: 0.534426\n",
      "epoch 121; iter: 0; batch classifier loss: 0.445274; batch adversarial loss: 0.608203\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382774; batch adversarial loss: 0.546383\n",
      "epoch 123; iter: 0; batch classifier loss: 0.443375; batch adversarial loss: 0.528408\n",
      "epoch 124; iter: 0; batch classifier loss: 0.442667; batch adversarial loss: 0.584743\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397787; batch adversarial loss: 0.532036\n",
      "epoch 126; iter: 0; batch classifier loss: 0.455085; batch adversarial loss: 0.579481\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369664; batch adversarial loss: 0.547193\n",
      "epoch 128; iter: 0; batch classifier loss: 0.451656; batch adversarial loss: 0.604458\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374891; batch adversarial loss: 0.519723\n",
      "epoch 130; iter: 0; batch classifier loss: 0.507602; batch adversarial loss: 0.555638\n",
      "epoch 131; iter: 0; batch classifier loss: 0.447606; batch adversarial loss: 0.527400\n",
      "epoch 132; iter: 0; batch classifier loss: 0.458048; batch adversarial loss: 0.536314\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351279; batch adversarial loss: 0.533143\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390189; batch adversarial loss: 0.584807\n",
      "epoch 135; iter: 0; batch classifier loss: 0.450423; batch adversarial loss: 0.560280\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385686; batch adversarial loss: 0.576310\n",
      "epoch 137; iter: 0; batch classifier loss: 0.437839; batch adversarial loss: 0.646358\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394535; batch adversarial loss: 0.547144\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408304; batch adversarial loss: 0.560271\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329048; batch adversarial loss: 0.555398\n",
      "epoch 141; iter: 0; batch classifier loss: 0.360758; batch adversarial loss: 0.579075\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396941; batch adversarial loss: 0.553312\n",
      "epoch 143; iter: 0; batch classifier loss: 0.318497; batch adversarial loss: 0.563234\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405888; batch adversarial loss: 0.554378\n",
      "epoch 145; iter: 0; batch classifier loss: 0.420526; batch adversarial loss: 0.585266\n",
      "epoch 146; iter: 0; batch classifier loss: 0.469005; batch adversarial loss: 0.536394\n",
      "epoch 147; iter: 0; batch classifier loss: 0.320363; batch adversarial loss: 0.596644\n",
      "epoch 148; iter: 0; batch classifier loss: 0.486375; batch adversarial loss: 0.606026\n",
      "epoch 149; iter: 0; batch classifier loss: 0.395156; batch adversarial loss: 0.597523\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381499; batch adversarial loss: 0.563677\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336970; batch adversarial loss: 0.538309\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326796; batch adversarial loss: 0.613029\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353760; batch adversarial loss: 0.611908\n",
      "epoch 154; iter: 0; batch classifier loss: 0.347441; batch adversarial loss: 0.536160\n",
      "epoch 155; iter: 0; batch classifier loss: 0.303786; batch adversarial loss: 0.587946\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366828; batch adversarial loss: 0.582059\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363647; batch adversarial loss: 0.502497\n",
      "epoch 158; iter: 0; batch classifier loss: 0.423974; batch adversarial loss: 0.493558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.371220; batch adversarial loss: 0.564208\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387913; batch adversarial loss: 0.581310\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339172; batch adversarial loss: 0.571719\n",
      "epoch 162; iter: 0; batch classifier loss: 0.380505; batch adversarial loss: 0.553396\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392082; batch adversarial loss: 0.554926\n",
      "epoch 164; iter: 0; batch classifier loss: 0.430584; batch adversarial loss: 0.511539\n",
      "epoch 165; iter: 0; batch classifier loss: 0.426830; batch adversarial loss: 0.557304\n",
      "epoch 166; iter: 0; batch classifier loss: 0.443567; batch adversarial loss: 0.520733\n",
      "epoch 167; iter: 0; batch classifier loss: 0.398177; batch adversarial loss: 0.629914\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362944; batch adversarial loss: 0.574244\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357728; batch adversarial loss: 0.589328\n",
      "epoch 170; iter: 0; batch classifier loss: 0.384325; batch adversarial loss: 0.553386\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364227; batch adversarial loss: 0.525992\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374753; batch adversarial loss: 0.556849\n",
      "epoch 173; iter: 0; batch classifier loss: 0.400547; batch adversarial loss: 0.567463\n",
      "epoch 174; iter: 0; batch classifier loss: 0.320801; batch adversarial loss: 0.553426\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369998; batch adversarial loss: 0.528924\n",
      "epoch 176; iter: 0; batch classifier loss: 0.355061; batch adversarial loss: 0.553806\n",
      "epoch 177; iter: 0; batch classifier loss: 0.426574; batch adversarial loss: 0.607623\n",
      "epoch 178; iter: 0; batch classifier loss: 0.395966; batch adversarial loss: 0.654378\n",
      "epoch 179; iter: 0; batch classifier loss: 0.276233; batch adversarial loss: 0.530034\n",
      "epoch 180; iter: 0; batch classifier loss: 0.280883; batch adversarial loss: 0.579152\n",
      "epoch 181; iter: 0; batch classifier loss: 0.357611; batch adversarial loss: 0.608187\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408623; batch adversarial loss: 0.553548\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391523; batch adversarial loss: 0.562265\n",
      "epoch 184; iter: 0; batch classifier loss: 0.462125; batch adversarial loss: 0.509827\n",
      "epoch 185; iter: 0; batch classifier loss: 0.380574; batch adversarial loss: 0.619601\n",
      "epoch 186; iter: 0; batch classifier loss: 0.396054; batch adversarial loss: 0.554981\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342530; batch adversarial loss: 0.537503\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369716; batch adversarial loss: 0.580588\n",
      "epoch 189; iter: 0; batch classifier loss: 0.401046; batch adversarial loss: 0.645180\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366554; batch adversarial loss: 0.568933\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346040; batch adversarial loss: 0.477702\n",
      "epoch 192; iter: 0; batch classifier loss: 0.307675; batch adversarial loss: 0.649566\n",
      "epoch 193; iter: 0; batch classifier loss: 0.421761; batch adversarial loss: 0.543025\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368080; batch adversarial loss: 0.550300\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337213; batch adversarial loss: 0.627839\n",
      "epoch 196; iter: 0; batch classifier loss: 0.403642; batch adversarial loss: 0.551869\n",
      "epoch 197; iter: 0; batch classifier loss: 0.410385; batch adversarial loss: 0.584770\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359187; batch adversarial loss: 0.538547\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329072; batch adversarial loss: 0.541901\n",
      "epoch 0; iter: 0; batch classifier loss: 0.752289; batch adversarial loss: 0.645365\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600518; batch adversarial loss: 0.649052\n",
      "epoch 2; iter: 0; batch classifier loss: 0.522763; batch adversarial loss: 0.633360\n",
      "epoch 3; iter: 0; batch classifier loss: 0.613543; batch adversarial loss: 0.606483\n",
      "epoch 4; iter: 0; batch classifier loss: 0.478569; batch adversarial loss: 0.640564\n",
      "epoch 5; iter: 0; batch classifier loss: 0.500097; batch adversarial loss: 0.603752\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574056; batch adversarial loss: 0.587677\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498471; batch adversarial loss: 0.619346\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524652; batch adversarial loss: 0.576297\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542721; batch adversarial loss: 0.558012\n",
      "epoch 10; iter: 0; batch classifier loss: 0.478251; batch adversarial loss: 0.586260\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560686; batch adversarial loss: 0.606376\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578767; batch adversarial loss: 0.582225\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511737; batch adversarial loss: 0.573263\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500176; batch adversarial loss: 0.541615\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490746; batch adversarial loss: 0.560864\n",
      "epoch 16; iter: 0; batch classifier loss: 0.699599; batch adversarial loss: 0.583086\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426325; batch adversarial loss: 0.561676\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526759; batch adversarial loss: 0.565193\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499324; batch adversarial loss: 0.497277\n",
      "epoch 20; iter: 0; batch classifier loss: 0.501478; batch adversarial loss: 0.550776\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469927; batch adversarial loss: 0.567150\n",
      "epoch 22; iter: 0; batch classifier loss: 0.414901; batch adversarial loss: 0.569150\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472572; batch adversarial loss: 0.569869\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511343; batch adversarial loss: 0.515476\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499894; batch adversarial loss: 0.546740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472599; batch adversarial loss: 0.539073\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445217; batch adversarial loss: 0.597539\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464778; batch adversarial loss: 0.581302\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471399; batch adversarial loss: 0.504690\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490768; batch adversarial loss: 0.555946\n",
      "epoch 31; iter: 0; batch classifier loss: 0.487529; batch adversarial loss: 0.512623\n",
      "epoch 32; iter: 0; batch classifier loss: 0.437691; batch adversarial loss: 0.480836\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461198; batch adversarial loss: 0.498732\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426717; batch adversarial loss: 0.580921\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499107; batch adversarial loss: 0.529951\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478403; batch adversarial loss: 0.563785\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440195; batch adversarial loss: 0.578849\n",
      "epoch 38; iter: 0; batch classifier loss: 0.518238; batch adversarial loss: 0.609627\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446624; batch adversarial loss: 0.526609\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424281; batch adversarial loss: 0.567187\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428314; batch adversarial loss: 0.602314\n",
      "epoch 42; iter: 0; batch classifier loss: 0.512205; batch adversarial loss: 0.531396\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439033; batch adversarial loss: 0.626644\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434312; batch adversarial loss: 0.543081\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419859; batch adversarial loss: 0.530345\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444043; batch adversarial loss: 0.563698\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406783; batch adversarial loss: 0.563453\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372480; batch adversarial loss: 0.584521\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455360; batch adversarial loss: 0.555248\n",
      "epoch 50; iter: 0; batch classifier loss: 0.345856; batch adversarial loss: 0.497097\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428276; batch adversarial loss: 0.532447\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446893; batch adversarial loss: 0.618116\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438623; batch adversarial loss: 0.479821\n",
      "epoch 54; iter: 0; batch classifier loss: 0.390845; batch adversarial loss: 0.594639\n",
      "epoch 55; iter: 0; batch classifier loss: 0.358980; batch adversarial loss: 0.555272\n",
      "epoch 56; iter: 0; batch classifier loss: 0.465963; batch adversarial loss: 0.509675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.451971; batch adversarial loss: 0.602405\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399297; batch adversarial loss: 0.491303\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374480; batch adversarial loss: 0.490406\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444905; batch adversarial loss: 0.567517\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438089; batch adversarial loss: 0.472358\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392896; batch adversarial loss: 0.522053\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446419; batch adversarial loss: 0.573852\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411832; batch adversarial loss: 0.530830\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426119; batch adversarial loss: 0.560859\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409706; batch adversarial loss: 0.593322\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384486; batch adversarial loss: 0.517052\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421936; batch adversarial loss: 0.549379\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437010; batch adversarial loss: 0.602502\n",
      "epoch 70; iter: 0; batch classifier loss: 0.453924; batch adversarial loss: 0.506478\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432431; batch adversarial loss: 0.548326\n",
      "epoch 72; iter: 0; batch classifier loss: 0.426847; batch adversarial loss: 0.573662\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390924; batch adversarial loss: 0.544042\n",
      "epoch 74; iter: 0; batch classifier loss: 0.329787; batch adversarial loss: 0.526376\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429411; batch adversarial loss: 0.555536\n",
      "epoch 76; iter: 0; batch classifier loss: 0.358886; batch adversarial loss: 0.531107\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376718; batch adversarial loss: 0.570904\n",
      "epoch 78; iter: 0; batch classifier loss: 0.385669; batch adversarial loss: 0.516814\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384301; batch adversarial loss: 0.523345\n",
      "epoch 80; iter: 0; batch classifier loss: 0.456209; batch adversarial loss: 0.535470\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370652; batch adversarial loss: 0.551858\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377854; batch adversarial loss: 0.516239\n",
      "epoch 83; iter: 0; batch classifier loss: 0.431180; batch adversarial loss: 0.555009\n",
      "epoch 84; iter: 0; batch classifier loss: 0.513937; batch adversarial loss: 0.578978\n",
      "epoch 85; iter: 0; batch classifier loss: 0.426565; batch adversarial loss: 0.521803\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401735; batch adversarial loss: 0.622276\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390129; batch adversarial loss: 0.571087\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414922; batch adversarial loss: 0.525506\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395397; batch adversarial loss: 0.564041\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402904; batch adversarial loss: 0.541828\n",
      "epoch 91; iter: 0; batch classifier loss: 0.401644; batch adversarial loss: 0.478588\n",
      "epoch 92; iter: 0; batch classifier loss: 0.331619; batch adversarial loss: 0.457192\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390376; batch adversarial loss: 0.609666\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387251; batch adversarial loss: 0.523242\n",
      "epoch 95; iter: 0; batch classifier loss: 0.372475; batch adversarial loss: 0.554832\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370753; batch adversarial loss: 0.566230\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395450; batch adversarial loss: 0.585630\n",
      "epoch 98; iter: 0; batch classifier loss: 0.344020; batch adversarial loss: 0.580735\n",
      "epoch 99; iter: 0; batch classifier loss: 0.392881; batch adversarial loss: 0.511683\n",
      "epoch 100; iter: 0; batch classifier loss: 0.476553; batch adversarial loss: 0.535493\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397620; batch adversarial loss: 0.633682\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365936; batch adversarial loss: 0.519567\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372216; batch adversarial loss: 0.594665\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416778; batch adversarial loss: 0.630561\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411331; batch adversarial loss: 0.555495\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434756; batch adversarial loss: 0.557988\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379654; batch adversarial loss: 0.578498\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369451; batch adversarial loss: 0.525332\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347392; batch adversarial loss: 0.526539\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344198; batch adversarial loss: 0.614164\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361970; batch adversarial loss: 0.541781\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403745; batch adversarial loss: 0.572245\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396092; batch adversarial loss: 0.632607\n",
      "epoch 114; iter: 0; batch classifier loss: 0.302066; batch adversarial loss: 0.567435\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390420; batch adversarial loss: 0.574854\n",
      "epoch 116; iter: 0; batch classifier loss: 0.431249; batch adversarial loss: 0.523221\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360391; batch adversarial loss: 0.523237\n",
      "epoch 118; iter: 0; batch classifier loss: 0.435859; batch adversarial loss: 0.517410\n",
      "epoch 119; iter: 0; batch classifier loss: 0.355969; batch adversarial loss: 0.611612\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352607; batch adversarial loss: 0.500931\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365203; batch adversarial loss: 0.618131\n",
      "epoch 122; iter: 0; batch classifier loss: 0.435510; batch adversarial loss: 0.562738\n",
      "epoch 123; iter: 0; batch classifier loss: 0.458990; batch adversarial loss: 0.526516\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379688; batch adversarial loss: 0.490561\n",
      "epoch 125; iter: 0; batch classifier loss: 0.438202; batch adversarial loss: 0.623128\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358972; batch adversarial loss: 0.517431\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382066; batch adversarial loss: 0.584439\n",
      "epoch 128; iter: 0; batch classifier loss: 0.312018; batch adversarial loss: 0.489769\n",
      "epoch 129; iter: 0; batch classifier loss: 0.323187; batch adversarial loss: 0.570585\n",
      "epoch 130; iter: 0; batch classifier loss: 0.399817; batch adversarial loss: 0.570010\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372877; batch adversarial loss: 0.589679\n",
      "epoch 132; iter: 0; batch classifier loss: 0.408856; batch adversarial loss: 0.549998\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396228; batch adversarial loss: 0.554050\n",
      "epoch 134; iter: 0; batch classifier loss: 0.342316; batch adversarial loss: 0.488233\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334543; batch adversarial loss: 0.509198\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397052; batch adversarial loss: 0.571836\n",
      "epoch 137; iter: 0; batch classifier loss: 0.456259; batch adversarial loss: 0.502699\n",
      "epoch 138; iter: 0; batch classifier loss: 0.448702; batch adversarial loss: 0.604732\n",
      "epoch 139; iter: 0; batch classifier loss: 0.430013; batch adversarial loss: 0.491777\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393803; batch adversarial loss: 0.523956\n",
      "epoch 141; iter: 0; batch classifier loss: 0.341795; batch adversarial loss: 0.586736\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326668; batch adversarial loss: 0.539510\n",
      "epoch 143; iter: 0; batch classifier loss: 0.271373; batch adversarial loss: 0.655115\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389417; batch adversarial loss: 0.611027\n",
      "epoch 145; iter: 0; batch classifier loss: 0.413672; batch adversarial loss: 0.624931\n",
      "epoch 146; iter: 0; batch classifier loss: 0.414031; batch adversarial loss: 0.576558\n",
      "epoch 147; iter: 0; batch classifier loss: 0.378471; batch adversarial loss: 0.617506\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391962; batch adversarial loss: 0.528462\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379859; batch adversarial loss: 0.549715\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365689; batch adversarial loss: 0.607242\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386192; batch adversarial loss: 0.514479\n",
      "epoch 152; iter: 0; batch classifier loss: 0.434425; batch adversarial loss: 0.558210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.338625; batch adversarial loss: 0.616872\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384206; batch adversarial loss: 0.526539\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388606; batch adversarial loss: 0.568962\n",
      "epoch 156; iter: 0; batch classifier loss: 0.416687; batch adversarial loss: 0.465859\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374263; batch adversarial loss: 0.496698\n",
      "epoch 158; iter: 0; batch classifier loss: 0.360240; batch adversarial loss: 0.511609\n",
      "epoch 159; iter: 0; batch classifier loss: 0.467183; batch adversarial loss: 0.564647\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374345; batch adversarial loss: 0.522459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.484919; batch adversarial loss: 0.472662\n",
      "epoch 162; iter: 0; batch classifier loss: 0.346375; batch adversarial loss: 0.561738\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330668; batch adversarial loss: 0.548292\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337961; batch adversarial loss: 0.546203\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348311; batch adversarial loss: 0.578315\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389085; batch adversarial loss: 0.568865\n",
      "epoch 167; iter: 0; batch classifier loss: 0.333875; batch adversarial loss: 0.516714\n",
      "epoch 168; iter: 0; batch classifier loss: 0.299967; batch adversarial loss: 0.495169\n",
      "epoch 169; iter: 0; batch classifier loss: 0.414046; batch adversarial loss: 0.539340\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364339; batch adversarial loss: 0.568928\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372510; batch adversarial loss: 0.564642\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349779; batch adversarial loss: 0.591401\n",
      "epoch 173; iter: 0; batch classifier loss: 0.254194; batch adversarial loss: 0.580552\n",
      "epoch 174; iter: 0; batch classifier loss: 0.428453; batch adversarial loss: 0.575140\n",
      "epoch 175; iter: 0; batch classifier loss: 0.498461; batch adversarial loss: 0.563766\n",
      "epoch 176; iter: 0; batch classifier loss: 0.450601; batch adversarial loss: 0.511160\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330232; batch adversarial loss: 0.574388\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335958; batch adversarial loss: 0.598326\n",
      "epoch 179; iter: 0; batch classifier loss: 0.444940; batch adversarial loss: 0.491980\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334810; batch adversarial loss: 0.570484\n",
      "epoch 181; iter: 0; batch classifier loss: 0.300031; batch adversarial loss: 0.578605\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371042; batch adversarial loss: 0.624963\n",
      "epoch 183; iter: 0; batch classifier loss: 0.320307; batch adversarial loss: 0.523459\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325734; batch adversarial loss: 0.523317\n",
      "epoch 185; iter: 0; batch classifier loss: 0.341914; batch adversarial loss: 0.553654\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379866; batch adversarial loss: 0.501975\n",
      "epoch 187; iter: 0; batch classifier loss: 0.312174; batch adversarial loss: 0.480010\n",
      "epoch 188; iter: 0; batch classifier loss: 0.294952; batch adversarial loss: 0.589939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.413791; batch adversarial loss: 0.579395\n",
      "epoch 190; iter: 0; batch classifier loss: 0.300230; batch adversarial loss: 0.600074\n",
      "epoch 191; iter: 0; batch classifier loss: 0.400952; batch adversarial loss: 0.507602\n",
      "epoch 192; iter: 0; batch classifier loss: 0.468651; batch adversarial loss: 0.535218\n",
      "epoch 193; iter: 0; batch classifier loss: 0.410562; batch adversarial loss: 0.587321\n",
      "epoch 194; iter: 0; batch classifier loss: 0.367577; batch adversarial loss: 0.586955\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390803; batch adversarial loss: 0.561882\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315114; batch adversarial loss: 0.544409\n",
      "epoch 197; iter: 0; batch classifier loss: 0.384050; batch adversarial loss: 0.473886\n",
      "epoch 198; iter: 0; batch classifier loss: 0.398520; batch adversarial loss: 0.535847\n",
      "epoch 199; iter: 0; batch classifier loss: 0.419458; batch adversarial loss: 0.544360\n",
      "epoch 0; iter: 0; batch classifier loss: 0.750124; batch adversarial loss: 0.486057\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618020; batch adversarial loss: 0.641581\n",
      "epoch 2; iter: 0; batch classifier loss: 0.521171; batch adversarial loss: 0.639564\n",
      "epoch 3; iter: 0; batch classifier loss: 0.595046; batch adversarial loss: 0.759447\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572010; batch adversarial loss: 0.676589\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587235; batch adversarial loss: 0.687905\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639058; batch adversarial loss: 0.671283\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582907; batch adversarial loss: 0.662440\n",
      "epoch 8; iter: 0; batch classifier loss: 0.710536; batch adversarial loss: 0.594843\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542960; batch adversarial loss: 0.592277\n",
      "epoch 10; iter: 0; batch classifier loss: 0.527575; batch adversarial loss: 0.614707\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524626; batch adversarial loss: 0.560467\n",
      "epoch 12; iter: 0; batch classifier loss: 0.605882; batch adversarial loss: 0.619078\n",
      "epoch 13; iter: 0; batch classifier loss: 0.618018; batch adversarial loss: 0.598435\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558334; batch adversarial loss: 0.582699\n",
      "epoch 15; iter: 0; batch classifier loss: 0.597423; batch adversarial loss: 0.613507\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537652; batch adversarial loss: 0.541458\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536151; batch adversarial loss: 0.557756\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541895; batch adversarial loss: 0.554976\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482259; batch adversarial loss: 0.544111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428153; batch adversarial loss: 0.587315\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513792; batch adversarial loss: 0.568191\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443091; batch adversarial loss: 0.560214\n",
      "epoch 23; iter: 0; batch classifier loss: 0.565206; batch adversarial loss: 0.567990\n",
      "epoch 24; iter: 0; batch classifier loss: 0.469461; batch adversarial loss: 0.580558\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490955; batch adversarial loss: 0.577130\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492326; batch adversarial loss: 0.578389\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459012; batch adversarial loss: 0.562801\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431874; batch adversarial loss: 0.572988\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440637; batch adversarial loss: 0.528019\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450404; batch adversarial loss: 0.525317\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467009; batch adversarial loss: 0.591929\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420939; batch adversarial loss: 0.544182\n",
      "epoch 33; iter: 0; batch classifier loss: 0.500265; batch adversarial loss: 0.555135\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404562; batch adversarial loss: 0.516140\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457244; batch adversarial loss: 0.597175\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432038; batch adversarial loss: 0.542930\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485850; batch adversarial loss: 0.499323\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475452; batch adversarial loss: 0.535437\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442288; batch adversarial loss: 0.580333\n",
      "epoch 40; iter: 0; batch classifier loss: 0.397750; batch adversarial loss: 0.598877\n",
      "epoch 41; iter: 0; batch classifier loss: 0.479170; batch adversarial loss: 0.527458\n",
      "epoch 42; iter: 0; batch classifier loss: 0.507363; batch adversarial loss: 0.472423\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424244; batch adversarial loss: 0.535057\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410007; batch adversarial loss: 0.553266\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432286; batch adversarial loss: 0.535561\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394764; batch adversarial loss: 0.545166\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447610; batch adversarial loss: 0.463675\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423793; batch adversarial loss: 0.544917\n",
      "epoch 49; iter: 0; batch classifier loss: 0.502512; batch adversarial loss: 0.598879\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451200; batch adversarial loss: 0.571869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.568051; batch adversarial loss: 0.616660\n",
      "epoch 52; iter: 0; batch classifier loss: 0.508777; batch adversarial loss: 0.499363\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402958; batch adversarial loss: 0.508236\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426873; batch adversarial loss: 0.544707\n",
      "epoch 55; iter: 0; batch classifier loss: 0.461144; batch adversarial loss: 0.563043\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388746; batch adversarial loss: 0.598790\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413556; batch adversarial loss: 0.564024\n",
      "epoch 58; iter: 0; batch classifier loss: 0.350073; batch adversarial loss: 0.589201\n",
      "epoch 59; iter: 0; batch classifier loss: 0.358612; batch adversarial loss: 0.580617\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405829; batch adversarial loss: 0.496111\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397204; batch adversarial loss: 0.506621\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407793; batch adversarial loss: 0.577102\n",
      "epoch 63; iter: 0; batch classifier loss: 0.360254; batch adversarial loss: 0.497546\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358265; batch adversarial loss: 0.609360\n",
      "epoch 65; iter: 0; batch classifier loss: 0.396371; batch adversarial loss: 0.529206\n",
      "epoch 66; iter: 0; batch classifier loss: 0.362588; batch adversarial loss: 0.562959\n",
      "epoch 67; iter: 0; batch classifier loss: 0.393779; batch adversarial loss: 0.510334\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342610; batch adversarial loss: 0.564121\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440594; batch adversarial loss: 0.553358\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447219; batch adversarial loss: 0.510684\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395597; batch adversarial loss: 0.572568\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404364; batch adversarial loss: 0.490787\n",
      "epoch 73; iter: 0; batch classifier loss: 0.504335; batch adversarial loss: 0.642572\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393573; batch adversarial loss: 0.570317\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375380; batch adversarial loss: 0.517077\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382840; batch adversarial loss: 0.608408\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440292; batch adversarial loss: 0.534797\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352751; batch adversarial loss: 0.517831\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402883; batch adversarial loss: 0.562045\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431143; batch adversarial loss: 0.669707\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360987; batch adversarial loss: 0.480553\n",
      "epoch 82; iter: 0; batch classifier loss: 0.329121; batch adversarial loss: 0.616156\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420633; batch adversarial loss: 0.472938\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419712; batch adversarial loss: 0.489308\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427918; batch adversarial loss: 0.534850\n",
      "epoch 86; iter: 0; batch classifier loss: 0.465370; batch adversarial loss: 0.536059\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428757; batch adversarial loss: 0.527417\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351608; batch adversarial loss: 0.688371\n",
      "epoch 89; iter: 0; batch classifier loss: 0.421275; batch adversarial loss: 0.562999\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404488; batch adversarial loss: 0.517038\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413618; batch adversarial loss: 0.625365\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408065; batch adversarial loss: 0.624806\n",
      "epoch 93; iter: 0; batch classifier loss: 0.440288; batch adversarial loss: 0.563417\n",
      "epoch 94; iter: 0; batch classifier loss: 0.454576; batch adversarial loss: 0.517232\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431292; batch adversarial loss: 0.590405\n",
      "epoch 96; iter: 0; batch classifier loss: 0.331984; batch adversarial loss: 0.572258\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390538; batch adversarial loss: 0.533967\n",
      "epoch 98; iter: 0; batch classifier loss: 0.363421; batch adversarial loss: 0.616977\n",
      "epoch 99; iter: 0; batch classifier loss: 0.435122; batch adversarial loss: 0.517221\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358357; batch adversarial loss: 0.507604\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421769; batch adversarial loss: 0.625596\n",
      "epoch 102; iter: 0; batch classifier loss: 0.431258; batch adversarial loss: 0.460899\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345720; batch adversarial loss: 0.533642\n",
      "epoch 104; iter: 0; batch classifier loss: 0.418227; batch adversarial loss: 0.496465\n",
      "epoch 105; iter: 0; batch classifier loss: 0.341784; batch adversarial loss: 0.588664\n",
      "epoch 106; iter: 0; batch classifier loss: 0.452204; batch adversarial loss: 0.563100\n",
      "epoch 107; iter: 0; batch classifier loss: 0.344543; batch adversarial loss: 0.534242\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386571; batch adversarial loss: 0.562472\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356046; batch adversarial loss: 0.482501\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414495; batch adversarial loss: 0.534323\n",
      "epoch 111; iter: 0; batch classifier loss: 0.425800; batch adversarial loss: 0.507125\n",
      "epoch 112; iter: 0; batch classifier loss: 0.315697; batch adversarial loss: 0.579224\n",
      "epoch 113; iter: 0; batch classifier loss: 0.307866; batch adversarial loss: 0.589505\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386791; batch adversarial loss: 0.580565\n",
      "epoch 115; iter: 0; batch classifier loss: 0.347440; batch adversarial loss: 0.525997\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345550; batch adversarial loss: 0.560811\n",
      "epoch 117; iter: 0; batch classifier loss: 0.301930; batch adversarial loss: 0.581969\n",
      "epoch 118; iter: 0; batch classifier loss: 0.418970; batch adversarial loss: 0.590918\n",
      "epoch 119; iter: 0; batch classifier loss: 0.429547; batch adversarial loss: 0.554067\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381399; batch adversarial loss: 0.517426\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339155; batch adversarial loss: 0.517151\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410362; batch adversarial loss: 0.526493\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365945; batch adversarial loss: 0.535797\n",
      "epoch 124; iter: 0; batch classifier loss: 0.425353; batch adversarial loss: 0.507930\n",
      "epoch 125; iter: 0; batch classifier loss: 0.421651; batch adversarial loss: 0.526308\n",
      "epoch 126; iter: 0; batch classifier loss: 0.429191; batch adversarial loss: 0.481524\n",
      "epoch 127; iter: 0; batch classifier loss: 0.318266; batch adversarial loss: 0.518957\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362971; batch adversarial loss: 0.578942\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375227; batch adversarial loss: 0.533336\n",
      "epoch 130; iter: 0; batch classifier loss: 0.351337; batch adversarial loss: 0.571414\n",
      "epoch 131; iter: 0; batch classifier loss: 0.413556; batch adversarial loss: 0.599033\n",
      "epoch 132; iter: 0; batch classifier loss: 0.409954; batch adversarial loss: 0.562105\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375768; batch adversarial loss: 0.543865\n",
      "epoch 134; iter: 0; batch classifier loss: 0.391458; batch adversarial loss: 0.507629\n",
      "epoch 135; iter: 0; batch classifier loss: 0.444840; batch adversarial loss: 0.618146\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343575; batch adversarial loss: 0.570237\n",
      "epoch 137; iter: 0; batch classifier loss: 0.378471; batch adversarial loss: 0.526195\n",
      "epoch 138; iter: 0; batch classifier loss: 0.272113; batch adversarial loss: 0.599375\n",
      "epoch 139; iter: 0; batch classifier loss: 0.314332; batch adversarial loss: 0.463359\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357109; batch adversarial loss: 0.490312\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368414; batch adversarial loss: 0.509907\n",
      "epoch 142; iter: 0; batch classifier loss: 0.314695; batch adversarial loss: 0.636437\n",
      "epoch 143; iter: 0; batch classifier loss: 0.473158; batch adversarial loss: 0.562983\n",
      "epoch 144; iter: 0; batch classifier loss: 0.308945; batch adversarial loss: 0.562085\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352918; batch adversarial loss: 0.535556\n",
      "epoch 146; iter: 0; batch classifier loss: 0.288776; batch adversarial loss: 0.508805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.350848; batch adversarial loss: 0.578698\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349787; batch adversarial loss: 0.508980\n",
      "epoch 149; iter: 0; batch classifier loss: 0.348837; batch adversarial loss: 0.561437\n",
      "epoch 150; iter: 0; batch classifier loss: 0.432361; batch adversarial loss: 0.526318\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367914; batch adversarial loss: 0.508766\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385970; batch adversarial loss: 0.535526\n",
      "epoch 153; iter: 0; batch classifier loss: 0.412211; batch adversarial loss: 0.563644\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370379; batch adversarial loss: 0.445735\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337834; batch adversarial loss: 0.545199\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332008; batch adversarial loss: 0.589031\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341215; batch adversarial loss: 0.579959\n",
      "epoch 158; iter: 0; batch classifier loss: 0.254491; batch adversarial loss: 0.643219\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388315; batch adversarial loss: 0.534896\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360692; batch adversarial loss: 0.536137\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378738; batch adversarial loss: 0.500418\n",
      "epoch 162; iter: 0; batch classifier loss: 0.403224; batch adversarial loss: 0.536641\n",
      "epoch 163; iter: 0; batch classifier loss: 0.329966; batch adversarial loss: 0.516206\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376973; batch adversarial loss: 0.552502\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398131; batch adversarial loss: 0.526619\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333287; batch adversarial loss: 0.535231\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335967; batch adversarial loss: 0.489515\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373888; batch adversarial loss: 0.526259\n",
      "epoch 169; iter: 0; batch classifier loss: 0.310434; batch adversarial loss: 0.536979\n",
      "epoch 170; iter: 0; batch classifier loss: 0.284551; batch adversarial loss: 0.517261\n",
      "epoch 171; iter: 0; batch classifier loss: 0.368311; batch adversarial loss: 0.554454\n",
      "epoch 172; iter: 0; batch classifier loss: 0.414334; batch adversarial loss: 0.525577\n",
      "epoch 173; iter: 0; batch classifier loss: 0.402150; batch adversarial loss: 0.435494\n",
      "epoch 174; iter: 0; batch classifier loss: 0.299877; batch adversarial loss: 0.589493\n",
      "epoch 175; iter: 0; batch classifier loss: 0.417292; batch adversarial loss: 0.509234\n",
      "epoch 176; iter: 0; batch classifier loss: 0.429065; batch adversarial loss: 0.488072\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337887; batch adversarial loss: 0.560602\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369615; batch adversarial loss: 0.490402\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345532; batch adversarial loss: 0.581269\n",
      "epoch 180; iter: 0; batch classifier loss: 0.393326; batch adversarial loss: 0.581393\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345494; batch adversarial loss: 0.589195\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355429; batch adversarial loss: 0.590859\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384440; batch adversarial loss: 0.506995\n",
      "epoch 184; iter: 0; batch classifier loss: 0.289611; batch adversarial loss: 0.543146\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366239; batch adversarial loss: 0.482360\n",
      "epoch 186; iter: 0; batch classifier loss: 0.380589; batch adversarial loss: 0.470545\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374391; batch adversarial loss: 0.553588\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386546; batch adversarial loss: 0.570900\n",
      "epoch 189; iter: 0; batch classifier loss: 0.337187; batch adversarial loss: 0.499819\n",
      "epoch 190; iter: 0; batch classifier loss: 0.458358; batch adversarial loss: 0.517577\n",
      "epoch 191; iter: 0; batch classifier loss: 0.307302; batch adversarial loss: 0.471226\n",
      "epoch 192; iter: 0; batch classifier loss: 0.372867; batch adversarial loss: 0.516312\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360573; batch adversarial loss: 0.552536\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357766; batch adversarial loss: 0.693466\n",
      "epoch 195; iter: 0; batch classifier loss: 0.433555; batch adversarial loss: 0.581817\n",
      "epoch 196; iter: 0; batch classifier loss: 0.397941; batch adversarial loss: 0.580490\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357556; batch adversarial loss: 0.553778\n",
      "epoch 198; iter: 0; batch classifier loss: 0.376231; batch adversarial loss: 0.552726\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381240; batch adversarial loss: 0.570061\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684671; batch adversarial loss: 0.876173\n",
      "epoch 1; iter: 0; batch classifier loss: 0.796613; batch adversarial loss: 1.094747\n",
      "epoch 2; iter: 0; batch classifier loss: 0.978097; batch adversarial loss: 0.992735\n",
      "epoch 3; iter: 0; batch classifier loss: 0.874379; batch adversarial loss: 0.903080\n",
      "epoch 4; iter: 0; batch classifier loss: 0.887753; batch adversarial loss: 0.829894\n",
      "epoch 5; iter: 0; batch classifier loss: 0.968455; batch adversarial loss: 0.758295\n",
      "epoch 6; iter: 0; batch classifier loss: 0.880929; batch adversarial loss: 0.688969\n",
      "epoch 7; iter: 0; batch classifier loss: 0.629197; batch adversarial loss: 0.635148\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553728; batch adversarial loss: 0.615767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513980; batch adversarial loss: 0.583262\n",
      "epoch 10; iter: 0; batch classifier loss: 0.454394; batch adversarial loss: 0.600254\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526741; batch adversarial loss: 0.594498\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557810; batch adversarial loss: 0.554684\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563901; batch adversarial loss: 0.594610\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538921; batch adversarial loss: 0.555359\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481388; batch adversarial loss: 0.575118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492491; batch adversarial loss: 0.549563\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495400; batch adversarial loss: 0.541123\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499909; batch adversarial loss: 0.555456\n",
      "epoch 19; iter: 0; batch classifier loss: 0.601925; batch adversarial loss: 0.612199\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505712; batch adversarial loss: 0.529362\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484850; batch adversarial loss: 0.551916\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465126; batch adversarial loss: 0.489078\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476792; batch adversarial loss: 0.572930\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463879; batch adversarial loss: 0.547754\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453018; batch adversarial loss: 0.538385\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440472; batch adversarial loss: 0.617892\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464247; batch adversarial loss: 0.520896\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471775; batch adversarial loss: 0.599368\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485822; batch adversarial loss: 0.560196\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458830; batch adversarial loss: 0.567554\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409395; batch adversarial loss: 0.464460\n",
      "epoch 32; iter: 0; batch classifier loss: 0.511126; batch adversarial loss: 0.567727\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464423; batch adversarial loss: 0.514465\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469894; batch adversarial loss: 0.537327\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407011; batch adversarial loss: 0.519217\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472500; batch adversarial loss: 0.521616\n",
      "epoch 37; iter: 0; batch classifier loss: 0.527034; batch adversarial loss: 0.531699\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476090; batch adversarial loss: 0.577687\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457982; batch adversarial loss: 0.579505\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465115; batch adversarial loss: 0.630629\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474090; batch adversarial loss: 0.573335\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469563; batch adversarial loss: 0.504219\n",
      "epoch 43; iter: 0; batch classifier loss: 0.404728; batch adversarial loss: 0.501683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.451400; batch adversarial loss: 0.503964\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448107; batch adversarial loss: 0.520794\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434921; batch adversarial loss: 0.511129\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428067; batch adversarial loss: 0.669348\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482251; batch adversarial loss: 0.624025\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444723; batch adversarial loss: 0.535672\n",
      "epoch 50; iter: 0; batch classifier loss: 0.370466; batch adversarial loss: 0.615974\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417356; batch adversarial loss: 0.526761\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405561; batch adversarial loss: 0.491290\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461206; batch adversarial loss: 0.427290\n",
      "epoch 54; iter: 0; batch classifier loss: 0.478228; batch adversarial loss: 0.508697\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422546; batch adversarial loss: 0.544732\n",
      "epoch 56; iter: 0; batch classifier loss: 0.401692; batch adversarial loss: 0.426471\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402987; batch adversarial loss: 0.544102\n",
      "epoch 58; iter: 0; batch classifier loss: 0.475021; batch adversarial loss: 0.517516\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435332; batch adversarial loss: 0.536608\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445823; batch adversarial loss: 0.535506\n",
      "epoch 61; iter: 0; batch classifier loss: 0.394113; batch adversarial loss: 0.581030\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445232; batch adversarial loss: 0.526556\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376123; batch adversarial loss: 0.517645\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427599; batch adversarial loss: 0.543181\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394584; batch adversarial loss: 0.543694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410949; batch adversarial loss: 0.571975\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444953; batch adversarial loss: 0.609184\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403190; batch adversarial loss: 0.507138\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418322; batch adversarial loss: 0.508177\n",
      "epoch 70; iter: 0; batch classifier loss: 0.372077; batch adversarial loss: 0.461628\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417511; batch adversarial loss: 0.599842\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380260; batch adversarial loss: 0.517542\n",
      "epoch 73; iter: 0; batch classifier loss: 0.364757; batch adversarial loss: 0.462258\n",
      "epoch 74; iter: 0; batch classifier loss: 0.343434; batch adversarial loss: 0.487754\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388008; batch adversarial loss: 0.542050\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416513; batch adversarial loss: 0.654938\n",
      "epoch 77; iter: 0; batch classifier loss: 0.448199; batch adversarial loss: 0.533756\n",
      "epoch 78; iter: 0; batch classifier loss: 0.423894; batch adversarial loss: 0.506680\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370383; batch adversarial loss: 0.525769\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367449; batch adversarial loss: 0.479967\n",
      "epoch 81; iter: 0; batch classifier loss: 0.362649; batch adversarial loss: 0.507814\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384378; batch adversarial loss: 0.589875\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371700; batch adversarial loss: 0.534020\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441782; batch adversarial loss: 0.560844\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370324; batch adversarial loss: 0.507338\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368298; batch adversarial loss: 0.506478\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391952; batch adversarial loss: 0.479610\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356483; batch adversarial loss: 0.535351\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393042; batch adversarial loss: 0.480754\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351737; batch adversarial loss: 0.516917\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380440; batch adversarial loss: 0.559282\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383825; batch adversarial loss: 0.536910\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394637; batch adversarial loss: 0.535612\n",
      "epoch 94; iter: 0; batch classifier loss: 0.342798; batch adversarial loss: 0.561934\n",
      "epoch 95; iter: 0; batch classifier loss: 0.317032; batch adversarial loss: 0.571488\n",
      "epoch 96; iter: 0; batch classifier loss: 0.449647; batch adversarial loss: 0.525023\n",
      "epoch 97; iter: 0; batch classifier loss: 0.343480; batch adversarial loss: 0.536609\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349239; batch adversarial loss: 0.560226\n",
      "epoch 99; iter: 0; batch classifier loss: 0.346048; batch adversarial loss: 0.570372\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383021; batch adversarial loss: 0.560600\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357862; batch adversarial loss: 0.607986\n",
      "epoch 102; iter: 0; batch classifier loss: 0.305607; batch adversarial loss: 0.542923\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438434; batch adversarial loss: 0.572477\n",
      "epoch 104; iter: 0; batch classifier loss: 0.332664; batch adversarial loss: 0.544882\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363294; batch adversarial loss: 0.591539\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383496; batch adversarial loss: 0.462216\n",
      "epoch 107; iter: 0; batch classifier loss: 0.369260; batch adversarial loss: 0.542379\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396903; batch adversarial loss: 0.535821\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371825; batch adversarial loss: 0.609529\n",
      "epoch 110; iter: 0; batch classifier loss: 0.441180; batch adversarial loss: 0.553176\n",
      "epoch 111; iter: 0; batch classifier loss: 0.430872; batch adversarial loss: 0.489572\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411653; batch adversarial loss: 0.545077\n",
      "epoch 113; iter: 0; batch classifier loss: 0.326176; batch adversarial loss: 0.547315\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380837; batch adversarial loss: 0.616805\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354916; batch adversarial loss: 0.498357\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380333; batch adversarial loss: 0.590304\n",
      "epoch 117; iter: 0; batch classifier loss: 0.311094; batch adversarial loss: 0.553095\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356906; batch adversarial loss: 0.553000\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368071; batch adversarial loss: 0.615757\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399858; batch adversarial loss: 0.545186\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341270; batch adversarial loss: 0.582543\n",
      "epoch 122; iter: 0; batch classifier loss: 0.333161; batch adversarial loss: 0.544056\n",
      "epoch 123; iter: 0; batch classifier loss: 0.393417; batch adversarial loss: 0.570610\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395801; batch adversarial loss: 0.579488\n",
      "epoch 125; iter: 0; batch classifier loss: 0.324343; batch adversarial loss: 0.508075\n",
      "epoch 126; iter: 0; batch classifier loss: 0.332907; batch adversarial loss: 0.626768\n",
      "epoch 127; iter: 0; batch classifier loss: 0.327693; batch adversarial loss: 0.545237\n",
      "epoch 128; iter: 0; batch classifier loss: 0.462719; batch adversarial loss: 0.523359\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402244; batch adversarial loss: 0.542688\n",
      "epoch 130; iter: 0; batch classifier loss: 0.438907; batch adversarial loss: 0.596793\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349433; batch adversarial loss: 0.598199\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323632; batch adversarial loss: 0.610912\n",
      "epoch 133; iter: 0; batch classifier loss: 0.405984; batch adversarial loss: 0.463379\n",
      "epoch 134; iter: 0; batch classifier loss: 0.360056; batch adversarial loss: 0.617677\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366323; batch adversarial loss: 0.488955\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381842; batch adversarial loss: 0.609275\n",
      "epoch 137; iter: 0; batch classifier loss: 0.318441; batch adversarial loss: 0.516984\n",
      "epoch 138; iter: 0; batch classifier loss: 0.334527; batch adversarial loss: 0.554761\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343708; batch adversarial loss: 0.564265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.301289; batch adversarial loss: 0.581414\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329937; batch adversarial loss: 0.607304\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379680; batch adversarial loss: 0.627776\n",
      "epoch 143; iter: 0; batch classifier loss: 0.323226; batch adversarial loss: 0.507519\n",
      "epoch 144; iter: 0; batch classifier loss: 0.323196; batch adversarial loss: 0.582143\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374575; batch adversarial loss: 0.480464\n",
      "epoch 146; iter: 0; batch classifier loss: 0.423735; batch adversarial loss: 0.545049\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329455; batch adversarial loss: 0.508358\n",
      "epoch 148; iter: 0; batch classifier loss: 0.316490; batch adversarial loss: 0.572957\n",
      "epoch 149; iter: 0; batch classifier loss: 0.412906; batch adversarial loss: 0.590359\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362605; batch adversarial loss: 0.490332\n",
      "epoch 151; iter: 0; batch classifier loss: 0.297363; batch adversarial loss: 0.525293\n",
      "epoch 152; iter: 0; batch classifier loss: 0.407853; batch adversarial loss: 0.524358\n",
      "epoch 153; iter: 0; batch classifier loss: 0.340837; batch adversarial loss: 0.607632\n",
      "epoch 154; iter: 0; batch classifier loss: 0.339091; batch adversarial loss: 0.508215\n",
      "epoch 155; iter: 0; batch classifier loss: 0.313555; batch adversarial loss: 0.508652\n",
      "epoch 156; iter: 0; batch classifier loss: 0.292777; batch adversarial loss: 0.443989\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337726; batch adversarial loss: 0.572273\n",
      "epoch 158; iter: 0; batch classifier loss: 0.307878; batch adversarial loss: 0.553599\n",
      "epoch 159; iter: 0; batch classifier loss: 0.312074; batch adversarial loss: 0.555118\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364092; batch adversarial loss: 0.615137\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325978; batch adversarial loss: 0.525410\n",
      "epoch 162; iter: 0; batch classifier loss: 0.299910; batch adversarial loss: 0.516597\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341693; batch adversarial loss: 0.498230\n",
      "epoch 164; iter: 0; batch classifier loss: 0.281487; batch adversarial loss: 0.533471\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326458; batch adversarial loss: 0.552027\n",
      "epoch 166; iter: 0; batch classifier loss: 0.437438; batch adversarial loss: 0.508309\n",
      "epoch 167; iter: 0; batch classifier loss: 0.327631; batch adversarial loss: 0.507635\n",
      "epoch 168; iter: 0; batch classifier loss: 0.279398; batch adversarial loss: 0.535287\n",
      "epoch 169; iter: 0; batch classifier loss: 0.279883; batch adversarial loss: 0.599898\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373063; batch adversarial loss: 0.543879\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374555; batch adversarial loss: 0.524576\n",
      "epoch 172; iter: 0; batch classifier loss: 0.310279; batch adversarial loss: 0.553930\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315640; batch adversarial loss: 0.580014\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353217; batch adversarial loss: 0.517710\n",
      "epoch 175; iter: 0; batch classifier loss: 0.318140; batch adversarial loss: 0.526408\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335377; batch adversarial loss: 0.507593\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376845; batch adversarial loss: 0.589546\n",
      "epoch 178; iter: 0; batch classifier loss: 0.305180; batch adversarial loss: 0.552836\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355478; batch adversarial loss: 0.562340\n",
      "epoch 180; iter: 0; batch classifier loss: 0.272322; batch adversarial loss: 0.517584\n",
      "epoch 181; iter: 0; batch classifier loss: 0.359327; batch adversarial loss: 0.543888\n",
      "epoch 182; iter: 0; batch classifier loss: 0.278958; batch adversarial loss: 0.533254\n",
      "epoch 183; iter: 0; batch classifier loss: 0.404991; batch adversarial loss: 0.553507\n",
      "epoch 184; iter: 0; batch classifier loss: 0.312527; batch adversarial loss: 0.554596\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366235; batch adversarial loss: 0.554818\n",
      "epoch 186; iter: 0; batch classifier loss: 0.354220; batch adversarial loss: 0.488800\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333327; batch adversarial loss: 0.489899\n",
      "epoch 188; iter: 0; batch classifier loss: 0.370259; batch adversarial loss: 0.490695\n",
      "epoch 189; iter: 0; batch classifier loss: 0.349092; batch adversarial loss: 0.562838\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384849; batch adversarial loss: 0.672989\n",
      "epoch 191; iter: 0; batch classifier loss: 0.329191; batch adversarial loss: 0.489970\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330494; batch adversarial loss: 0.645488\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318772; batch adversarial loss: 0.572446\n",
      "epoch 194; iter: 0; batch classifier loss: 0.445180; batch adversarial loss: 0.498392\n",
      "epoch 195; iter: 0; batch classifier loss: 0.299987; batch adversarial loss: 0.545054\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378857; batch adversarial loss: 0.598425\n",
      "epoch 197; iter: 0; batch classifier loss: 0.269633; batch adversarial loss: 0.518601\n",
      "epoch 198; iter: 0; batch classifier loss: 0.373401; batch adversarial loss: 0.633821\n",
      "epoch 199; iter: 0; batch classifier loss: 0.343304; batch adversarial loss: 0.553856\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731229; batch adversarial loss: 0.937285\n",
      "epoch 1; iter: 0; batch classifier loss: 0.844506; batch adversarial loss: 1.022920\n",
      "epoch 2; iter: 0; batch classifier loss: 1.034639; batch adversarial loss: 1.026408\n",
      "epoch 3; iter: 0; batch classifier loss: 0.960516; batch adversarial loss: 0.917102\n",
      "epoch 4; iter: 0; batch classifier loss: 0.968402; batch adversarial loss: 0.867317\n",
      "epoch 5; iter: 0; batch classifier loss: 0.856141; batch adversarial loss: 0.798106\n",
      "epoch 6; iter: 0; batch classifier loss: 0.760568; batch adversarial loss: 0.717685\n",
      "epoch 7; iter: 0; batch classifier loss: 0.623371; batch adversarial loss: 0.699130\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601920; batch adversarial loss: 0.644264\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585410; batch adversarial loss: 0.635888\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535690; batch adversarial loss: 0.608765\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536875; batch adversarial loss: 0.622683\n",
      "epoch 12; iter: 0; batch classifier loss: 0.585381; batch adversarial loss: 0.573304\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507265; batch adversarial loss: 0.649109\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514285; batch adversarial loss: 0.513704\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512843; batch adversarial loss: 0.569368\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505658; batch adversarial loss: 0.528504\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560509; batch adversarial loss: 0.573876\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454281; batch adversarial loss: 0.605593\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439746; batch adversarial loss: 0.598981\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500826; batch adversarial loss: 0.546700\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517557; batch adversarial loss: 0.503459\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481203; batch adversarial loss: 0.561942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523343; batch adversarial loss: 0.506200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503081; batch adversarial loss: 0.516107\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437154; batch adversarial loss: 0.605414\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425397; batch adversarial loss: 0.510966\n",
      "epoch 27; iter: 0; batch classifier loss: 0.408874; batch adversarial loss: 0.583374\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438815; batch adversarial loss: 0.562432\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405305; batch adversarial loss: 0.630151\n",
      "epoch 30; iter: 0; batch classifier loss: 0.445258; batch adversarial loss: 0.520335\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491810; batch adversarial loss: 0.575134\n",
      "epoch 32; iter: 0; batch classifier loss: 0.509504; batch adversarial loss: 0.592248\n",
      "epoch 33; iter: 0; batch classifier loss: 0.536662; batch adversarial loss: 0.539539\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480615; batch adversarial loss: 0.535207\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450943; batch adversarial loss: 0.538656\n",
      "epoch 36; iter: 0; batch classifier loss: 0.527829; batch adversarial loss: 0.631301\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477459; batch adversarial loss: 0.542059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.426070; batch adversarial loss: 0.554386\n",
      "epoch 39; iter: 0; batch classifier loss: 0.549523; batch adversarial loss: 0.561600\n",
      "epoch 40; iter: 0; batch classifier loss: 0.508028; batch adversarial loss: 0.608137\n",
      "epoch 41; iter: 0; batch classifier loss: 0.482149; batch adversarial loss: 0.584144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418351; batch adversarial loss: 0.547333\n",
      "epoch 43; iter: 0; batch classifier loss: 0.472786; batch adversarial loss: 0.597988\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478150; batch adversarial loss: 0.520480\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476178; batch adversarial loss: 0.581774\n",
      "epoch 46; iter: 0; batch classifier loss: 0.501452; batch adversarial loss: 0.599421\n",
      "epoch 47; iter: 0; batch classifier loss: 0.397450; batch adversarial loss: 0.569710\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456797; batch adversarial loss: 0.680527\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402263; batch adversarial loss: 0.593924\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374602; batch adversarial loss: 0.607002\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483655; batch adversarial loss: 0.554614\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416573; batch adversarial loss: 0.525705\n",
      "epoch 53; iter: 0; batch classifier loss: 0.460226; batch adversarial loss: 0.447543\n",
      "epoch 54; iter: 0; batch classifier loss: 0.367893; batch adversarial loss: 0.571228\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409302; batch adversarial loss: 0.546035\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417975; batch adversarial loss: 0.530683\n",
      "epoch 57; iter: 0; batch classifier loss: 0.360975; batch adversarial loss: 0.508884\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431940; batch adversarial loss: 0.526124\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391145; batch adversarial loss: 0.455936\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385430; batch adversarial loss: 0.492324\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376759; batch adversarial loss: 0.562442\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387851; batch adversarial loss: 0.624010\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371679; batch adversarial loss: 0.544842\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400674; batch adversarial loss: 0.528177\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436125; batch adversarial loss: 0.598152\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425082; batch adversarial loss: 0.599330\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412659; batch adversarial loss: 0.571770\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388382; batch adversarial loss: 0.589386\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430133; batch adversarial loss: 0.544718\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383116; batch adversarial loss: 0.562671\n",
      "epoch 71; iter: 0; batch classifier loss: 0.343566; batch adversarial loss: 0.580099\n",
      "epoch 72; iter: 0; batch classifier loss: 0.454250; batch adversarial loss: 0.553620\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423703; batch adversarial loss: 0.614752\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433071; batch adversarial loss: 0.483363\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409051; batch adversarial loss: 0.560735\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424861; batch adversarial loss: 0.500336\n",
      "epoch 77; iter: 0; batch classifier loss: 0.453051; batch adversarial loss: 0.561046\n",
      "epoch 78; iter: 0; batch classifier loss: 0.325083; batch adversarial loss: 0.616743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386047; batch adversarial loss: 0.533835\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451456; batch adversarial loss: 0.571106\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414922; batch adversarial loss: 0.522115\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384428; batch adversarial loss: 0.542835\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421965; batch adversarial loss: 0.589899\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400858; batch adversarial loss: 0.660654\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378931; batch adversarial loss: 0.491297\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414603; batch adversarial loss: 0.534909\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420324; batch adversarial loss: 0.527589\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408018; batch adversarial loss: 0.515051\n",
      "epoch 89; iter: 0; batch classifier loss: 0.338656; batch adversarial loss: 0.587592\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381393; batch adversarial loss: 0.527302\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358851; batch adversarial loss: 0.544478\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368068; batch adversarial loss: 0.574848\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385584; batch adversarial loss: 0.502252\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430002; batch adversarial loss: 0.601357\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400146; batch adversarial loss: 0.645221\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401094; batch adversarial loss: 0.528863\n",
      "epoch 97; iter: 0; batch classifier loss: 0.406774; batch adversarial loss: 0.589576\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389050; batch adversarial loss: 0.606077\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342706; batch adversarial loss: 0.500082\n",
      "epoch 100; iter: 0; batch classifier loss: 0.317552; batch adversarial loss: 0.535427\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399400; batch adversarial loss: 0.535609\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370036; batch adversarial loss: 0.553964\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366653; batch adversarial loss: 0.562754\n",
      "epoch 104; iter: 0; batch classifier loss: 0.327643; batch adversarial loss: 0.565448\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369023; batch adversarial loss: 0.553549\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373808; batch adversarial loss: 0.563575\n",
      "epoch 107; iter: 0; batch classifier loss: 0.439820; batch adversarial loss: 0.600877\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411326; batch adversarial loss: 0.615133\n",
      "epoch 109; iter: 0; batch classifier loss: 0.321161; batch adversarial loss: 0.536701\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377878; batch adversarial loss: 0.534856\n",
      "epoch 111; iter: 0; batch classifier loss: 0.281474; batch adversarial loss: 0.579979\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349375; batch adversarial loss: 0.549489\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379848; batch adversarial loss: 0.489721\n",
      "epoch 114; iter: 0; batch classifier loss: 0.419412; batch adversarial loss: 0.597309\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332411; batch adversarial loss: 0.582949\n",
      "epoch 116; iter: 0; batch classifier loss: 0.422658; batch adversarial loss: 0.484682\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369718; batch adversarial loss: 0.484982\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335603; batch adversarial loss: 0.613498\n",
      "epoch 119; iter: 0; batch classifier loss: 0.318421; batch adversarial loss: 0.661829\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370312; batch adversarial loss: 0.598580\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378492; batch adversarial loss: 0.635080\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346110; batch adversarial loss: 0.552997\n",
      "epoch 123; iter: 0; batch classifier loss: 0.306389; batch adversarial loss: 0.483511\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376048; batch adversarial loss: 0.571791\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371215; batch adversarial loss: 0.489837\n",
      "epoch 126; iter: 0; batch classifier loss: 0.326143; batch adversarial loss: 0.565270\n",
      "epoch 127; iter: 0; batch classifier loss: 0.314236; batch adversarial loss: 0.595978\n",
      "epoch 128; iter: 0; batch classifier loss: 0.259571; batch adversarial loss: 0.588231\n",
      "epoch 129; iter: 0; batch classifier loss: 0.322945; batch adversarial loss: 0.519587\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414678; batch adversarial loss: 0.561576\n",
      "epoch 131; iter: 0; batch classifier loss: 0.329764; batch adversarial loss: 0.598859\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355604; batch adversarial loss: 0.561270\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364967; batch adversarial loss: 0.505601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.363028; batch adversarial loss: 0.599084\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399285; batch adversarial loss: 0.544666\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378912; batch adversarial loss: 0.589910\n",
      "epoch 137; iter: 0; batch classifier loss: 0.302616; batch adversarial loss: 0.582349\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363278; batch adversarial loss: 0.571693\n",
      "epoch 139; iter: 0; batch classifier loss: 0.419725; batch adversarial loss: 0.508943\n",
      "epoch 140; iter: 0; batch classifier loss: 0.432008; batch adversarial loss: 0.610079\n",
      "epoch 141; iter: 0; batch classifier loss: 0.431112; batch adversarial loss: 0.552751\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386958; batch adversarial loss: 0.509390\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363303; batch adversarial loss: 0.546673\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401787; batch adversarial loss: 0.616380\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351440; batch adversarial loss: 0.547395\n",
      "epoch 146; iter: 0; batch classifier loss: 0.288705; batch adversarial loss: 0.527379\n",
      "epoch 147; iter: 0; batch classifier loss: 0.412360; batch adversarial loss: 0.535598\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366389; batch adversarial loss: 0.534880\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369617; batch adversarial loss: 0.581046\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421005; batch adversarial loss: 0.581833\n",
      "epoch 151; iter: 0; batch classifier loss: 0.383900; batch adversarial loss: 0.578826\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340787; batch adversarial loss: 0.572084\n",
      "epoch 153; iter: 0; batch classifier loss: 0.261425; batch adversarial loss: 0.483476\n",
      "epoch 154; iter: 0; batch classifier loss: 0.440010; batch adversarial loss: 0.528057\n",
      "epoch 155; iter: 0; batch classifier loss: 0.280507; batch adversarial loss: 0.458916\n",
      "epoch 156; iter: 0; batch classifier loss: 0.306886; batch adversarial loss: 0.544888\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372816; batch adversarial loss: 0.545661\n",
      "epoch 158; iter: 0; batch classifier loss: 0.328789; batch adversarial loss: 0.517435\n",
      "epoch 159; iter: 0; batch classifier loss: 0.288197; batch adversarial loss: 0.643368\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386561; batch adversarial loss: 0.635928\n",
      "epoch 161; iter: 0; batch classifier loss: 0.379171; batch adversarial loss: 0.561814\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400459; batch adversarial loss: 0.576242\n",
      "epoch 163; iter: 0; batch classifier loss: 0.281755; batch adversarial loss: 0.510499\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373051; batch adversarial loss: 0.573661\n",
      "epoch 165; iter: 0; batch classifier loss: 0.309760; batch adversarial loss: 0.563741\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384371; batch adversarial loss: 0.517851\n",
      "epoch 167; iter: 0; batch classifier loss: 0.303528; batch adversarial loss: 0.553231\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317161; batch adversarial loss: 0.481346\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351456; batch adversarial loss: 0.507587\n",
      "epoch 170; iter: 0; batch classifier loss: 0.376088; batch adversarial loss: 0.535309\n",
      "epoch 171; iter: 0; batch classifier loss: 0.406805; batch adversarial loss: 0.525539\n",
      "epoch 172; iter: 0; batch classifier loss: 0.294075; batch adversarial loss: 0.551641\n",
      "epoch 173; iter: 0; batch classifier loss: 0.448024; batch adversarial loss: 0.534663\n",
      "epoch 174; iter: 0; batch classifier loss: 0.349930; batch adversarial loss: 0.542161\n",
      "epoch 175; iter: 0; batch classifier loss: 0.354615; batch adversarial loss: 0.578550\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338313; batch adversarial loss: 0.561387\n",
      "epoch 177; iter: 0; batch classifier loss: 0.370767; batch adversarial loss: 0.492907\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326837; batch adversarial loss: 0.502195\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352664; batch adversarial loss: 0.508386\n",
      "epoch 180; iter: 0; batch classifier loss: 0.326217; batch adversarial loss: 0.563486\n",
      "epoch 181; iter: 0; batch classifier loss: 0.302343; batch adversarial loss: 0.570903\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381243; batch adversarial loss: 0.582247\n",
      "epoch 183; iter: 0; batch classifier loss: 0.416928; batch adversarial loss: 0.581896\n",
      "epoch 184; iter: 0; batch classifier loss: 0.297025; batch adversarial loss: 0.470751\n",
      "epoch 185; iter: 0; batch classifier loss: 0.276525; batch adversarial loss: 0.590138\n",
      "epoch 186; iter: 0; batch classifier loss: 0.354246; batch adversarial loss: 0.517749\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371706; batch adversarial loss: 0.554584\n",
      "epoch 188; iter: 0; batch classifier loss: 0.302945; batch adversarial loss: 0.588979\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348711; batch adversarial loss: 0.624579\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331837; batch adversarial loss: 0.623814\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380801; batch adversarial loss: 0.614021\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361210; batch adversarial loss: 0.660087\n",
      "epoch 193; iter: 0; batch classifier loss: 0.306323; batch adversarial loss: 0.553704\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368238; batch adversarial loss: 0.581517\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353963; batch adversarial loss: 0.581341\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349187; batch adversarial loss: 0.535104\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372737; batch adversarial loss: 0.555803\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387583; batch adversarial loss: 0.528750\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309663; batch adversarial loss: 0.491500\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704798; batch adversarial loss: 0.941433\n",
      "epoch 1; iter: 0; batch classifier loss: 1.005521; batch adversarial loss: 1.330214\n",
      "epoch 2; iter: 0; batch classifier loss: 1.042524; batch adversarial loss: 1.256296\n",
      "epoch 3; iter: 0; batch classifier loss: 1.115342; batch adversarial loss: 1.187892\n",
      "epoch 4; iter: 0; batch classifier loss: 1.260195; batch adversarial loss: 1.091970\n",
      "epoch 5; iter: 0; batch classifier loss: 1.341829; batch adversarial loss: 0.994819\n",
      "epoch 6; iter: 0; batch classifier loss: 1.197773; batch adversarial loss: 0.900700\n",
      "epoch 7; iter: 0; batch classifier loss: 1.302752; batch adversarial loss: 0.846112\n",
      "epoch 8; iter: 0; batch classifier loss: 1.083009; batch adversarial loss: 0.777355\n",
      "epoch 9; iter: 0; batch classifier loss: 1.113953; batch adversarial loss: 0.716165\n",
      "epoch 10; iter: 0; batch classifier loss: 1.140386; batch adversarial loss: 0.685003\n",
      "epoch 11; iter: 0; batch classifier loss: 0.826002; batch adversarial loss: 0.634756\n",
      "epoch 12; iter: 0; batch classifier loss: 0.831993; batch adversarial loss: 0.601401\n",
      "epoch 13; iter: 0; batch classifier loss: 0.603556; batch adversarial loss: 0.571112\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540778; batch adversarial loss: 0.583534\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553629; batch adversarial loss: 0.598366\n",
      "epoch 16; iter: 0; batch classifier loss: 0.626954; batch adversarial loss: 0.557063\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508450; batch adversarial loss: 0.593840\n",
      "epoch 18; iter: 0; batch classifier loss: 0.447643; batch adversarial loss: 0.555678\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491694; batch adversarial loss: 0.583815\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572800; batch adversarial loss: 0.512430\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500191; batch adversarial loss: 0.540160\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515664; batch adversarial loss: 0.529451\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517915; batch adversarial loss: 0.543974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453321; batch adversarial loss: 0.524325\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521352; batch adversarial loss: 0.520633\n",
      "epoch 26; iter: 0; batch classifier loss: 0.509587; batch adversarial loss: 0.515961\n",
      "epoch 27; iter: 0; batch classifier loss: 0.558574; batch adversarial loss: 0.536436\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416506; batch adversarial loss: 0.501801\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507395; batch adversarial loss: 0.566617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.538335; batch adversarial loss: 0.504045\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451529; batch adversarial loss: 0.513070\n",
      "epoch 32; iter: 0; batch classifier loss: 0.549963; batch adversarial loss: 0.540063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477753; batch adversarial loss: 0.514407\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476299; batch adversarial loss: 0.467124\n",
      "epoch 35; iter: 0; batch classifier loss: 0.558379; batch adversarial loss: 0.523170\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455170; batch adversarial loss: 0.551117\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480152; batch adversarial loss: 0.525775\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498218; batch adversarial loss: 0.518343\n",
      "epoch 39; iter: 0; batch classifier loss: 0.373858; batch adversarial loss: 0.515205\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458012; batch adversarial loss: 0.512074\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489028; batch adversarial loss: 0.493831\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467262; batch adversarial loss: 0.473670\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426512; batch adversarial loss: 0.515226\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451563; batch adversarial loss: 0.526214\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425344; batch adversarial loss: 0.560307\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432457; batch adversarial loss: 0.536572\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375838; batch adversarial loss: 0.507580\n",
      "epoch 48; iter: 0; batch classifier loss: 0.506488; batch adversarial loss: 0.576804\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440448; batch adversarial loss: 0.556277\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493239; batch adversarial loss: 0.517147\n",
      "epoch 51; iter: 0; batch classifier loss: 0.396775; batch adversarial loss: 0.602057\n",
      "epoch 52; iter: 0; batch classifier loss: 0.500301; batch adversarial loss: 0.495824\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400754; batch adversarial loss: 0.536725\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406515; batch adversarial loss: 0.516656\n",
      "epoch 55; iter: 0; batch classifier loss: 0.351607; batch adversarial loss: 0.574198\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392873; batch adversarial loss: 0.545117\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468866; batch adversarial loss: 0.554878\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441182; batch adversarial loss: 0.573196\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407366; batch adversarial loss: 0.516247\n",
      "epoch 60; iter: 0; batch classifier loss: 0.498705; batch adversarial loss: 0.478829\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442313; batch adversarial loss: 0.535365\n",
      "epoch 62; iter: 0; batch classifier loss: 0.502605; batch adversarial loss: 0.525732\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473517; batch adversarial loss: 0.563379\n",
      "epoch 64; iter: 0; batch classifier loss: 0.443139; batch adversarial loss: 0.581599\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435087; batch adversarial loss: 0.563505\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430752; batch adversarial loss: 0.609617\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399707; batch adversarial loss: 0.544745\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427096; batch adversarial loss: 0.478755\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448320; batch adversarial loss: 0.469512\n",
      "epoch 70; iter: 0; batch classifier loss: 0.339071; batch adversarial loss: 0.478127\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446416; batch adversarial loss: 0.496583\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415925; batch adversarial loss: 0.505197\n",
      "epoch 73; iter: 0; batch classifier loss: 0.480179; batch adversarial loss: 0.571140\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359017; batch adversarial loss: 0.628912\n",
      "epoch 75; iter: 0; batch classifier loss: 0.346863; batch adversarial loss: 0.573455\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441701; batch adversarial loss: 0.553095\n",
      "epoch 77; iter: 0; batch classifier loss: 0.359660; batch adversarial loss: 0.504412\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355167; batch adversarial loss: 0.572871\n",
      "epoch 79; iter: 0; batch classifier loss: 0.307989; batch adversarial loss: 0.487113\n",
      "epoch 80; iter: 0; batch classifier loss: 0.357921; batch adversarial loss: 0.525224\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394848; batch adversarial loss: 0.619292\n",
      "epoch 82; iter: 0; batch classifier loss: 0.439188; batch adversarial loss: 0.520690\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398676; batch adversarial loss: 0.601654\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426314; batch adversarial loss: 0.570850\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360704; batch adversarial loss: 0.506673\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416696; batch adversarial loss: 0.535997\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390001; batch adversarial loss: 0.524722\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372455; batch adversarial loss: 0.513564\n",
      "epoch 89; iter: 0; batch classifier loss: 0.321125; batch adversarial loss: 0.554995\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401545; batch adversarial loss: 0.523245\n",
      "epoch 91; iter: 0; batch classifier loss: 0.343304; batch adversarial loss: 0.542017\n",
      "epoch 92; iter: 0; batch classifier loss: 0.251474; batch adversarial loss: 0.562870\n",
      "epoch 93; iter: 0; batch classifier loss: 0.423348; batch adversarial loss: 0.637855\n",
      "epoch 94; iter: 0; batch classifier loss: 0.413235; batch adversarial loss: 0.508017\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400868; batch adversarial loss: 0.475164\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392562; batch adversarial loss: 0.505867\n",
      "epoch 97; iter: 0; batch classifier loss: 0.352314; batch adversarial loss: 0.488114\n",
      "epoch 98; iter: 0; batch classifier loss: 0.350741; batch adversarial loss: 0.552944\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366855; batch adversarial loss: 0.464366\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403194; batch adversarial loss: 0.545881\n",
      "epoch 101; iter: 0; batch classifier loss: 0.300583; batch adversarial loss: 0.544026\n",
      "epoch 102; iter: 0; batch classifier loss: 0.436942; batch adversarial loss: 0.563349\n",
      "epoch 103; iter: 0; batch classifier loss: 0.330624; batch adversarial loss: 0.478698\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423332; batch adversarial loss: 0.544280\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372723; batch adversarial loss: 0.631334\n",
      "epoch 106; iter: 0; batch classifier loss: 0.498635; batch adversarial loss: 0.532403\n",
      "epoch 107; iter: 0; batch classifier loss: 0.282486; batch adversarial loss: 0.468975\n",
      "epoch 108; iter: 0; batch classifier loss: 0.349034; batch adversarial loss: 0.570232\n",
      "epoch 109; iter: 0; batch classifier loss: 0.332113; batch adversarial loss: 0.592492\n",
      "epoch 110; iter: 0; batch classifier loss: 0.317019; batch adversarial loss: 0.574156\n",
      "epoch 111; iter: 0; batch classifier loss: 0.320215; batch adversarial loss: 0.498484\n",
      "epoch 112; iter: 0; batch classifier loss: 0.266666; batch adversarial loss: 0.572061\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418445; batch adversarial loss: 0.507849\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422242; batch adversarial loss: 0.490307\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396299; batch adversarial loss: 0.586441\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375645; batch adversarial loss: 0.507287\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372121; batch adversarial loss: 0.564919\n",
      "epoch 118; iter: 0; batch classifier loss: 0.330012; batch adversarial loss: 0.507308\n",
      "epoch 119; iter: 0; batch classifier loss: 0.365956; batch adversarial loss: 0.562074\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366847; batch adversarial loss: 0.498334\n",
      "epoch 121; iter: 0; batch classifier loss: 0.430874; batch adversarial loss: 0.589563\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421737; batch adversarial loss: 0.469133\n",
      "epoch 123; iter: 0; batch classifier loss: 0.310023; batch adversarial loss: 0.570369\n",
      "epoch 124; iter: 0; batch classifier loss: 0.356940; batch adversarial loss: 0.555223\n",
      "epoch 125; iter: 0; batch classifier loss: 0.300122; batch adversarial loss: 0.527477\n",
      "epoch 126; iter: 0; batch classifier loss: 0.355623; batch adversarial loss: 0.505340\n",
      "epoch 127; iter: 0; batch classifier loss: 0.312902; batch adversarial loss: 0.579391\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344409; batch adversarial loss: 0.457945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.316145; batch adversarial loss: 0.498803\n",
      "epoch 130; iter: 0; batch classifier loss: 0.279406; batch adversarial loss: 0.487744\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387519; batch adversarial loss: 0.530697\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318055; batch adversarial loss: 0.497488\n",
      "epoch 133; iter: 0; batch classifier loss: 0.359910; batch adversarial loss: 0.600476\n",
      "epoch 134; iter: 0; batch classifier loss: 0.321304; batch adversarial loss: 0.513923\n",
      "epoch 135; iter: 0; batch classifier loss: 0.435042; batch adversarial loss: 0.621598\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355396; batch adversarial loss: 0.608023\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344627; batch adversarial loss: 0.555603\n",
      "epoch 138; iter: 0; batch classifier loss: 0.347766; batch adversarial loss: 0.531439\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334056; batch adversarial loss: 0.593972\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359348; batch adversarial loss: 0.524567\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353803; batch adversarial loss: 0.477750\n",
      "epoch 142; iter: 0; batch classifier loss: 0.313393; batch adversarial loss: 0.540202\n",
      "epoch 143; iter: 0; batch classifier loss: 0.440055; batch adversarial loss: 0.534302\n",
      "epoch 144; iter: 0; batch classifier loss: 0.297151; batch adversarial loss: 0.530459\n",
      "epoch 145; iter: 0; batch classifier loss: 0.393974; batch adversarial loss: 0.536341\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345189; batch adversarial loss: 0.528943\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332375; batch adversarial loss: 0.514978\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378684; batch adversarial loss: 0.468243\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391802; batch adversarial loss: 0.622524\n",
      "epoch 150; iter: 0; batch classifier loss: 0.291042; batch adversarial loss: 0.564226\n",
      "epoch 151; iter: 0; batch classifier loss: 0.264316; batch adversarial loss: 0.504601\n",
      "epoch 152; iter: 0; batch classifier loss: 0.451775; batch adversarial loss: 0.478590\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376221; batch adversarial loss: 0.483365\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313826; batch adversarial loss: 0.559629\n",
      "epoch 155; iter: 0; batch classifier loss: 0.269623; batch adversarial loss: 0.532964\n",
      "epoch 156; iter: 0; batch classifier loss: 0.324148; batch adversarial loss: 0.535284\n",
      "epoch 157; iter: 0; batch classifier loss: 0.387799; batch adversarial loss: 0.533450\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337838; batch adversarial loss: 0.611007\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348985; batch adversarial loss: 0.535627\n",
      "epoch 160; iter: 0; batch classifier loss: 0.355349; batch adversarial loss: 0.570875\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334658; batch adversarial loss: 0.516787\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383850; batch adversarial loss: 0.613318\n",
      "epoch 163; iter: 0; batch classifier loss: 0.287583; batch adversarial loss: 0.523768\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330801; batch adversarial loss: 0.558969\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330248; batch adversarial loss: 0.490377\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325455; batch adversarial loss: 0.515871\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369829; batch adversarial loss: 0.553019\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362270; batch adversarial loss: 0.574856\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330639; batch adversarial loss: 0.575363\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365350; batch adversarial loss: 0.513423\n",
      "epoch 171; iter: 0; batch classifier loss: 0.286619; batch adversarial loss: 0.514926\n",
      "epoch 172; iter: 0; batch classifier loss: 0.305619; batch adversarial loss: 0.591060\n",
      "epoch 173; iter: 0; batch classifier loss: 0.272290; batch adversarial loss: 0.564132\n",
      "epoch 174; iter: 0; batch classifier loss: 0.391466; batch adversarial loss: 0.527194\n",
      "epoch 175; iter: 0; batch classifier loss: 0.350217; batch adversarial loss: 0.542769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.342386; batch adversarial loss: 0.468706\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337988; batch adversarial loss: 0.468001\n",
      "epoch 178; iter: 0; batch classifier loss: 0.341952; batch adversarial loss: 0.553202\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384144; batch adversarial loss: 0.461424\n",
      "epoch 180; iter: 0; batch classifier loss: 0.373869; batch adversarial loss: 0.545366\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332770; batch adversarial loss: 0.593621\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351088; batch adversarial loss: 0.551387\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348270; batch adversarial loss: 0.600017\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325666; batch adversarial loss: 0.457282\n",
      "epoch 185; iter: 0; batch classifier loss: 0.305511; batch adversarial loss: 0.590001\n",
      "epoch 186; iter: 0; batch classifier loss: 0.381072; batch adversarial loss: 0.448830\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374981; batch adversarial loss: 0.539354\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376634; batch adversarial loss: 0.556655\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358243; batch adversarial loss: 0.585465\n",
      "epoch 190; iter: 0; batch classifier loss: 0.348365; batch adversarial loss: 0.538927\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362323; batch adversarial loss: 0.544013\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308070; batch adversarial loss: 0.559754\n",
      "epoch 193; iter: 0; batch classifier loss: 0.355042; batch adversarial loss: 0.564053\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359872; batch adversarial loss: 0.500074\n",
      "epoch 195; iter: 0; batch classifier loss: 0.409063; batch adversarial loss: 0.569588\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347678; batch adversarial loss: 0.516550\n",
      "epoch 197; iter: 0; batch classifier loss: 0.319691; batch adversarial loss: 0.516731\n",
      "epoch 198; iter: 0; batch classifier loss: 0.374673; batch adversarial loss: 0.551898\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318328; batch adversarial loss: 0.555143\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720531; batch adversarial loss: 0.685102\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627401; batch adversarial loss: 0.653770\n",
      "epoch 2; iter: 0; batch classifier loss: 0.584761; batch adversarial loss: 0.626861\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569244; batch adversarial loss: 0.598450\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603748; batch adversarial loss: 0.577022\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572670; batch adversarial loss: 0.588660\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545555; batch adversarial loss: 0.617759\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524081; batch adversarial loss: 0.574684\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595431; batch adversarial loss: 0.586259\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566871; batch adversarial loss: 0.615918\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578874; batch adversarial loss: 0.597689\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546504; batch adversarial loss: 0.612113\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535755; batch adversarial loss: 0.539479\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548184; batch adversarial loss: 0.548480\n",
      "epoch 14; iter: 0; batch classifier loss: 0.451449; batch adversarial loss: 0.595396\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533107; batch adversarial loss: 0.602761\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550400; batch adversarial loss: 0.580367\n",
      "epoch 17; iter: 0; batch classifier loss: 0.636525; batch adversarial loss: 0.530659\n",
      "epoch 18; iter: 0; batch classifier loss: 0.435279; batch adversarial loss: 0.524999\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470137; batch adversarial loss: 0.554206\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469475; batch adversarial loss: 0.542069\n",
      "epoch 21; iter: 0; batch classifier loss: 0.423252; batch adversarial loss: 0.663296\n",
      "epoch 22; iter: 0; batch classifier loss: 0.542199; batch adversarial loss: 0.538223\n",
      "epoch 23; iter: 0; batch classifier loss: 0.532632; batch adversarial loss: 0.559645\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486601; batch adversarial loss: 0.524927\n",
      "epoch 25; iter: 0; batch classifier loss: 0.441239; batch adversarial loss: 0.538512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.477463; batch adversarial loss: 0.628302\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477512; batch adversarial loss: 0.462751\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434275; batch adversarial loss: 0.616732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.500570; batch adversarial loss: 0.474814\n",
      "epoch 30; iter: 0; batch classifier loss: 0.460222; batch adversarial loss: 0.520437\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421480; batch adversarial loss: 0.576430\n",
      "epoch 32; iter: 0; batch classifier loss: 0.544693; batch adversarial loss: 0.534322\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466710; batch adversarial loss: 0.563946\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467934; batch adversarial loss: 0.547004\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511580; batch adversarial loss: 0.583639\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437854; batch adversarial loss: 0.593738\n",
      "epoch 37; iter: 0; batch classifier loss: 0.527901; batch adversarial loss: 0.541032\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504950; batch adversarial loss: 0.600234\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392792; batch adversarial loss: 0.554993\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430118; batch adversarial loss: 0.498981\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401320; batch adversarial loss: 0.576141\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453091; batch adversarial loss: 0.480723\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460099; batch adversarial loss: 0.579603\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472656; batch adversarial loss: 0.605754\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423070; batch adversarial loss: 0.587102\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430732; batch adversarial loss: 0.598765\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399305; batch adversarial loss: 0.498475\n",
      "epoch 48; iter: 0; batch classifier loss: 0.357563; batch adversarial loss: 0.590213\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432166; batch adversarial loss: 0.481794\n",
      "epoch 50; iter: 0; batch classifier loss: 0.425108; batch adversarial loss: 0.543993\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411573; batch adversarial loss: 0.616544\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392705; batch adversarial loss: 0.617184\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470905; batch adversarial loss: 0.435066\n",
      "epoch 54; iter: 0; batch classifier loss: 0.380254; batch adversarial loss: 0.514941\n",
      "epoch 55; iter: 0; batch classifier loss: 0.427545; batch adversarial loss: 0.536760\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451327; batch adversarial loss: 0.535837\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400255; batch adversarial loss: 0.626627\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418090; batch adversarial loss: 0.544023\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387095; batch adversarial loss: 0.554551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451132; batch adversarial loss: 0.573274\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449519; batch adversarial loss: 0.509701\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459937; batch adversarial loss: 0.543945\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436843; batch adversarial loss: 0.633465\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369357; batch adversarial loss: 0.418933\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367752; batch adversarial loss: 0.571302\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407243; batch adversarial loss: 0.553594\n",
      "epoch 67; iter: 0; batch classifier loss: 0.490993; batch adversarial loss: 0.516389\n",
      "epoch 68; iter: 0; batch classifier loss: 0.346852; batch adversarial loss: 0.571467\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412207; batch adversarial loss: 0.589234\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426929; batch adversarial loss: 0.564059\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437037; batch adversarial loss: 0.535637\n",
      "epoch 72; iter: 0; batch classifier loss: 0.356245; batch adversarial loss: 0.599660\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414856; batch adversarial loss: 0.508830\n",
      "epoch 74; iter: 0; batch classifier loss: 0.357704; batch adversarial loss: 0.562126\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423396; batch adversarial loss: 0.573007\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373645; batch adversarial loss: 0.574039\n",
      "epoch 77; iter: 0; batch classifier loss: 0.342925; batch adversarial loss: 0.554330\n",
      "epoch 78; iter: 0; batch classifier loss: 0.461678; batch adversarial loss: 0.599356\n",
      "epoch 79; iter: 0; batch classifier loss: 0.423478; batch adversarial loss: 0.497687\n",
      "epoch 80; iter: 0; batch classifier loss: 0.344835; batch adversarial loss: 0.653916\n",
      "epoch 81; iter: 0; batch classifier loss: 0.401950; batch adversarial loss: 0.561303\n",
      "epoch 82; iter: 0; batch classifier loss: 0.343954; batch adversarial loss: 0.545254\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429258; batch adversarial loss: 0.489741\n",
      "epoch 84; iter: 0; batch classifier loss: 0.513175; batch adversarial loss: 0.517132\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433382; batch adversarial loss: 0.581395\n",
      "epoch 86; iter: 0; batch classifier loss: 0.386914; batch adversarial loss: 0.561387\n",
      "epoch 87; iter: 0; batch classifier loss: 0.307911; batch adversarial loss: 0.608069\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376852; batch adversarial loss: 0.554030\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391354; batch adversarial loss: 0.589384\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340914; batch adversarial loss: 0.524507\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439885; batch adversarial loss: 0.461609\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351424; batch adversarial loss: 0.534300\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403508; batch adversarial loss: 0.489683\n",
      "epoch 94; iter: 0; batch classifier loss: 0.455562; batch adversarial loss: 0.563222\n",
      "epoch 95; iter: 0; batch classifier loss: 0.371873; batch adversarial loss: 0.542695\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438484; batch adversarial loss: 0.563794\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391767; batch adversarial loss: 0.534620\n",
      "epoch 98; iter: 0; batch classifier loss: 0.338837; batch adversarial loss: 0.579142\n",
      "epoch 99; iter: 0; batch classifier loss: 0.473608; batch adversarial loss: 0.533902\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365094; batch adversarial loss: 0.544524\n",
      "epoch 101; iter: 0; batch classifier loss: 0.350222; batch adversarial loss: 0.513026\n",
      "epoch 102; iter: 0; batch classifier loss: 0.411127; batch adversarial loss: 0.543740\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360795; batch adversarial loss: 0.524707\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413822; batch adversarial loss: 0.603176\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396967; batch adversarial loss: 0.515849\n",
      "epoch 106; iter: 0; batch classifier loss: 0.438666; batch adversarial loss: 0.609523\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412432; batch adversarial loss: 0.615848\n",
      "epoch 108; iter: 0; batch classifier loss: 0.402240; batch adversarial loss: 0.554490\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400341; batch adversarial loss: 0.553747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414116; batch adversarial loss: 0.625323\n",
      "epoch 111; iter: 0; batch classifier loss: 0.302108; batch adversarial loss: 0.508730\n",
      "epoch 112; iter: 0; batch classifier loss: 0.307882; batch adversarial loss: 0.572282\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343085; batch adversarial loss: 0.544793\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346027; batch adversarial loss: 0.589793\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380272; batch adversarial loss: 0.525145\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379750; batch adversarial loss: 0.571711\n",
      "epoch 117; iter: 0; batch classifier loss: 0.331889; batch adversarial loss: 0.535971\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357480; batch adversarial loss: 0.481189\n",
      "epoch 119; iter: 0; batch classifier loss: 0.498418; batch adversarial loss: 0.562305\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.628095\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380556; batch adversarial loss: 0.553865\n",
      "epoch 122; iter: 0; batch classifier loss: 0.354140; batch adversarial loss: 0.589660\n",
      "epoch 123; iter: 0; batch classifier loss: 0.338370; batch adversarial loss: 0.543456\n",
      "epoch 124; iter: 0; batch classifier loss: 0.268286; batch adversarial loss: 0.581181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.360763; batch adversarial loss: 0.535336\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395990; batch adversarial loss: 0.590859\n",
      "epoch 127; iter: 0; batch classifier loss: 0.347070; batch adversarial loss: 0.544208\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328605; batch adversarial loss: 0.525757\n",
      "epoch 129; iter: 0; batch classifier loss: 0.414852; batch adversarial loss: 0.553397\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322252; batch adversarial loss: 0.600520\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407549; batch adversarial loss: 0.544638\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396716; batch adversarial loss: 0.544252\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395381; batch adversarial loss: 0.507821\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379085; batch adversarial loss: 0.526560\n",
      "epoch 135; iter: 0; batch classifier loss: 0.379506; batch adversarial loss: 0.488744\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360674; batch adversarial loss: 0.471563\n",
      "epoch 137; iter: 0; batch classifier loss: 0.338957; batch adversarial loss: 0.516516\n",
      "epoch 138; iter: 0; batch classifier loss: 0.399237; batch adversarial loss: 0.545326\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346310; batch adversarial loss: 0.552096\n",
      "epoch 140; iter: 0; batch classifier loss: 0.432745; batch adversarial loss: 0.489013\n",
      "epoch 141; iter: 0; batch classifier loss: 0.319401; batch adversarial loss: 0.571154\n",
      "epoch 142; iter: 0; batch classifier loss: 0.342074; batch adversarial loss: 0.508252\n",
      "epoch 143; iter: 0; batch classifier loss: 0.339255; batch adversarial loss: 0.563945\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360946; batch adversarial loss: 0.545388\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362505; batch adversarial loss: 0.545318\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374779; batch adversarial loss: 0.580392\n",
      "epoch 147; iter: 0; batch classifier loss: 0.310668; batch adversarial loss: 0.534710\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343408; batch adversarial loss: 0.553696\n",
      "epoch 149; iter: 0; batch classifier loss: 0.305437; batch adversarial loss: 0.545251\n",
      "epoch 150; iter: 0; batch classifier loss: 0.403144; batch adversarial loss: 0.526726\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334605; batch adversarial loss: 0.517427\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330244; batch adversarial loss: 0.535264\n",
      "epoch 153; iter: 0; batch classifier loss: 0.412722; batch adversarial loss: 0.590884\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379217; batch adversarial loss: 0.478912\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357621; batch adversarial loss: 0.552864\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332532; batch adversarial loss: 0.563537\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350601; batch adversarial loss: 0.599101\n",
      "epoch 158; iter: 0; batch classifier loss: 0.305611; batch adversarial loss: 0.590648\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369558; batch adversarial loss: 0.562501\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370995; batch adversarial loss: 0.599161\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356783; batch adversarial loss: 0.471266\n",
      "epoch 162; iter: 0; batch classifier loss: 0.362986; batch adversarial loss: 0.534823\n",
      "epoch 163; iter: 0; batch classifier loss: 0.333483; batch adversarial loss: 0.619441\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358767; batch adversarial loss: 0.534769\n",
      "epoch 165; iter: 0; batch classifier loss: 0.390080; batch adversarial loss: 0.580407\n",
      "epoch 166; iter: 0; batch classifier loss: 0.496863; batch adversarial loss: 0.553408\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394370; batch adversarial loss: 0.526187\n",
      "epoch 168; iter: 0; batch classifier loss: 0.408254; batch adversarial loss: 0.562061\n",
      "epoch 169; iter: 0; batch classifier loss: 0.383349; batch adversarial loss: 0.497528\n",
      "epoch 170; iter: 0; batch classifier loss: 0.407262; batch adversarial loss: 0.527226\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336744; batch adversarial loss: 0.590919\n",
      "epoch 172; iter: 0; batch classifier loss: 0.308304; batch adversarial loss: 0.526087\n",
      "epoch 173; iter: 0; batch classifier loss: 0.310997; batch adversarial loss: 0.489028\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366989; batch adversarial loss: 0.535842\n",
      "epoch 175; iter: 0; batch classifier loss: 0.302494; batch adversarial loss: 0.553221\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336373; batch adversarial loss: 0.526889\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417259; batch adversarial loss: 0.526563\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363091; batch adversarial loss: 0.508666\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323621; batch adversarial loss: 0.562091\n",
      "epoch 180; iter: 0; batch classifier loss: 0.303713; batch adversarial loss: 0.543679\n",
      "epoch 181; iter: 0; batch classifier loss: 0.401613; batch adversarial loss: 0.562067\n",
      "epoch 182; iter: 0; batch classifier loss: 0.319561; batch adversarial loss: 0.562074\n",
      "epoch 183; iter: 0; batch classifier loss: 0.361425; batch adversarial loss: 0.536242\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342659; batch adversarial loss: 0.561440\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376881; batch adversarial loss: 0.534653\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331441; batch adversarial loss: 0.525966\n",
      "epoch 187; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.544896\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384870; batch adversarial loss: 0.553580\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378320; batch adversarial loss: 0.543911\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372910; batch adversarial loss: 0.534417\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313366; batch adversarial loss: 0.489371\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356712; batch adversarial loss: 0.525759\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403386; batch adversarial loss: 0.526854\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382792; batch adversarial loss: 0.526477\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337174; batch adversarial loss: 0.553104\n",
      "epoch 196; iter: 0; batch classifier loss: 0.280321; batch adversarial loss: 0.498491\n",
      "epoch 197; iter: 0; batch classifier loss: 0.359962; batch adversarial loss: 0.553125\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317110; batch adversarial loss: 0.552078\n",
      "epoch 199; iter: 0; batch classifier loss: 0.346836; batch adversarial loss: 0.554029\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684105; batch adversarial loss: 0.604659\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539819; batch adversarial loss: 0.639439\n",
      "epoch 2; iter: 0; batch classifier loss: 0.642424; batch adversarial loss: 0.759919\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538730; batch adversarial loss: 0.667335\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607060; batch adversarial loss: 0.653835\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557649; batch adversarial loss: 0.690928\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590933; batch adversarial loss: 0.727097\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624998; batch adversarial loss: 0.727491\n",
      "epoch 8; iter: 0; batch classifier loss: 0.650738; batch adversarial loss: 0.647572\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578899; batch adversarial loss: 0.602332\n",
      "epoch 10; iter: 0; batch classifier loss: 0.617592; batch adversarial loss: 0.534317\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546033; batch adversarial loss: 0.556095\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551036; batch adversarial loss: 0.608399\n",
      "epoch 13; iter: 0; batch classifier loss: 0.603567; batch adversarial loss: 0.561901\n",
      "epoch 14; iter: 0; batch classifier loss: 0.577515; batch adversarial loss: 0.582490\n",
      "epoch 15; iter: 0; batch classifier loss: 0.615809; batch adversarial loss: 0.601381\n",
      "epoch 16; iter: 0; batch classifier loss: 0.578452; batch adversarial loss: 0.502653\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487182; batch adversarial loss: 0.577025\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559481; batch adversarial loss: 0.573196\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536633; batch adversarial loss: 0.562984\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476877; batch adversarial loss: 0.577512\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512844; batch adversarial loss: 0.506597\n",
      "epoch 22; iter: 0; batch classifier loss: 0.406900; batch adversarial loss: 0.577629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.527887; batch adversarial loss: 0.577801\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517787; batch adversarial loss: 0.536831\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487525; batch adversarial loss: 0.543940\n",
      "epoch 26; iter: 0; batch classifier loss: 0.437453; batch adversarial loss: 0.447658\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507067; batch adversarial loss: 0.523901\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439571; batch adversarial loss: 0.481450\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485421; batch adversarial loss: 0.512210\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434256; batch adversarial loss: 0.596128\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523902; batch adversarial loss: 0.516497\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472271; batch adversarial loss: 0.583073\n",
      "epoch 33; iter: 0; batch classifier loss: 0.419364; batch adversarial loss: 0.607494\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491487; batch adversarial loss: 0.552733\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472621; batch adversarial loss: 0.510887\n",
      "epoch 36; iter: 0; batch classifier loss: 0.467189; batch adversarial loss: 0.532981\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461624; batch adversarial loss: 0.596953\n",
      "epoch 38; iter: 0; batch classifier loss: 0.485686; batch adversarial loss: 0.585998\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451973; batch adversarial loss: 0.519699\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459903; batch adversarial loss: 0.588137\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464739; batch adversarial loss: 0.541281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452326; batch adversarial loss: 0.628629\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438614; batch adversarial loss: 0.611524\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440627; batch adversarial loss: 0.536130\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427954; batch adversarial loss: 0.536168\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469348; batch adversarial loss: 0.580049\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475051; batch adversarial loss: 0.513636\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486101; batch adversarial loss: 0.553117\n",
      "epoch 49; iter: 0; batch classifier loss: 0.511674; batch adversarial loss: 0.618252\n",
      "epoch 50; iter: 0; batch classifier loss: 0.533332; batch adversarial loss: 0.598187\n",
      "epoch 51; iter: 0; batch classifier loss: 0.345601; batch adversarial loss: 0.472602\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461742; batch adversarial loss: 0.629078\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417332; batch adversarial loss: 0.638147\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426048; batch adversarial loss: 0.560896\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460777; batch adversarial loss: 0.468376\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457058; batch adversarial loss: 0.563396\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459403; batch adversarial loss: 0.525366\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434834; batch adversarial loss: 0.452355\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424483; batch adversarial loss: 0.498146\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423332; batch adversarial loss: 0.470844\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391787; batch adversarial loss: 0.594951\n",
      "epoch 62; iter: 0; batch classifier loss: 0.529387; batch adversarial loss: 0.489149\n",
      "epoch 63; iter: 0; batch classifier loss: 0.478016; batch adversarial loss: 0.515048\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382161; batch adversarial loss: 0.544652\n",
      "epoch 65; iter: 0; batch classifier loss: 0.470793; batch adversarial loss: 0.592284\n",
      "epoch 66; iter: 0; batch classifier loss: 0.530353; batch adversarial loss: 0.553869\n",
      "epoch 67; iter: 0; batch classifier loss: 0.476108; batch adversarial loss: 0.572973\n",
      "epoch 68; iter: 0; batch classifier loss: 0.416210; batch adversarial loss: 0.554981\n",
      "epoch 69; iter: 0; batch classifier loss: 0.472141; batch adversarial loss: 0.654072\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443376; batch adversarial loss: 0.477792\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406320; batch adversarial loss: 0.579506\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427322; batch adversarial loss: 0.561991\n",
      "epoch 73; iter: 0; batch classifier loss: 0.496461; batch adversarial loss: 0.435609\n",
      "epoch 74; iter: 0; batch classifier loss: 0.483229; batch adversarial loss: 0.561323\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388389; batch adversarial loss: 0.478259\n",
      "epoch 76; iter: 0; batch classifier loss: 0.425450; batch adversarial loss: 0.589630\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392563; batch adversarial loss: 0.500704\n",
      "epoch 78; iter: 0; batch classifier loss: 0.339301; batch adversarial loss: 0.533622\n",
      "epoch 79; iter: 0; batch classifier loss: 0.505516; batch adversarial loss: 0.589125\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411532; batch adversarial loss: 0.510486\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376850; batch adversarial loss: 0.500350\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371236; batch adversarial loss: 0.478956\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395066; batch adversarial loss: 0.563781\n",
      "epoch 84; iter: 0; batch classifier loss: 0.509824; batch adversarial loss: 0.627540\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412424; batch adversarial loss: 0.516192\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365866; batch adversarial loss: 0.571043\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422951; batch adversarial loss: 0.611192\n",
      "epoch 88; iter: 0; batch classifier loss: 0.546153; batch adversarial loss: 0.516105\n",
      "epoch 89; iter: 0; batch classifier loss: 0.332303; batch adversarial loss: 0.562457\n",
      "epoch 90; iter: 0; batch classifier loss: 0.354507; batch adversarial loss: 0.600240\n",
      "epoch 91; iter: 0; batch classifier loss: 0.471215; batch adversarial loss: 0.557988\n",
      "epoch 92; iter: 0; batch classifier loss: 0.452497; batch adversarial loss: 0.564599\n",
      "epoch 93; iter: 0; batch classifier loss: 0.477157; batch adversarial loss: 0.589277\n",
      "epoch 94; iter: 0; batch classifier loss: 0.461039; batch adversarial loss: 0.516607\n",
      "epoch 95; iter: 0; batch classifier loss: 0.472906; batch adversarial loss: 0.518133\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373453; batch adversarial loss: 0.524566\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366966; batch adversarial loss: 0.561211\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418721; batch adversarial loss: 0.526055\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382688; batch adversarial loss: 0.507887\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417863; batch adversarial loss: 0.535864\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366676; batch adversarial loss: 0.506695\n",
      "epoch 102; iter: 0; batch classifier loss: 0.514006; batch adversarial loss: 0.553356\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409725; batch adversarial loss: 0.584853\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364775; batch adversarial loss: 0.506476\n",
      "epoch 105; iter: 0; batch classifier loss: 0.350559; batch adversarial loss: 0.557892\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335422; batch adversarial loss: 0.459758\n",
      "epoch 107; iter: 0; batch classifier loss: 0.451587; batch adversarial loss: 0.516961\n",
      "epoch 108; iter: 0; batch classifier loss: 0.410931; batch adversarial loss: 0.535476\n",
      "epoch 109; iter: 0; batch classifier loss: 0.456411; batch adversarial loss: 0.500159\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339072; batch adversarial loss: 0.545561\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379326; batch adversarial loss: 0.569888\n",
      "epoch 112; iter: 0; batch classifier loss: 0.455540; batch adversarial loss: 0.535123\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389556; batch adversarial loss: 0.517336\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391498; batch adversarial loss: 0.506767\n",
      "epoch 115; iter: 0; batch classifier loss: 0.545206; batch adversarial loss: 0.508167\n",
      "epoch 116; iter: 0; batch classifier loss: 0.416929; batch adversarial loss: 0.508226\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356292; batch adversarial loss: 0.638151\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343464; batch adversarial loss: 0.553459\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402643; batch adversarial loss: 0.554135\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391775; batch adversarial loss: 0.564047\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394051; batch adversarial loss: 0.579907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.390586; batch adversarial loss: 0.553632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.465696; batch adversarial loss: 0.564007\n",
      "epoch 124; iter: 0; batch classifier loss: 0.489240; batch adversarial loss: 0.488867\n",
      "epoch 125; iter: 0; batch classifier loss: 0.434061; batch adversarial loss: 0.478555\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391910; batch adversarial loss: 0.618846\n",
      "epoch 127; iter: 0; batch classifier loss: 0.409781; batch adversarial loss: 0.514293\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409579; batch adversarial loss: 0.533142\n",
      "epoch 129; iter: 0; batch classifier loss: 0.325191; batch adversarial loss: 0.481252\n",
      "epoch 130; iter: 0; batch classifier loss: 0.481042; batch adversarial loss: 0.563012\n",
      "epoch 131; iter: 0; batch classifier loss: 0.444917; batch adversarial loss: 0.608709\n",
      "epoch 132; iter: 0; batch classifier loss: 0.430929; batch adversarial loss: 0.562394\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336272; batch adversarial loss: 0.555438\n",
      "epoch 134; iter: 0; batch classifier loss: 0.461871; batch adversarial loss: 0.542455\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348779; batch adversarial loss: 0.571321\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361879; batch adversarial loss: 0.562343\n",
      "epoch 137; iter: 0; batch classifier loss: 0.362980; batch adversarial loss: 0.581660\n",
      "epoch 138; iter: 0; batch classifier loss: 0.418178; batch adversarial loss: 0.583252\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360410; batch adversarial loss: 0.591113\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387241; batch adversarial loss: 0.562643\n",
      "epoch 141; iter: 0; batch classifier loss: 0.394194; batch adversarial loss: 0.617297\n",
      "epoch 142; iter: 0; batch classifier loss: 0.487772; batch adversarial loss: 0.553162\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374449; batch adversarial loss: 0.588854\n",
      "epoch 144; iter: 0; batch classifier loss: 0.524769; batch adversarial loss: 0.534128\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339354; batch adversarial loss: 0.488423\n",
      "epoch 146; iter: 0; batch classifier loss: 0.419398; batch adversarial loss: 0.583196\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381567; batch adversarial loss: 0.543056\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376184; batch adversarial loss: 0.517400\n",
      "epoch 149; iter: 0; batch classifier loss: 0.330893; batch adversarial loss: 0.551921\n",
      "epoch 150; iter: 0; batch classifier loss: 0.386342; batch adversarial loss: 0.544169\n",
      "epoch 151; iter: 0; batch classifier loss: 0.444463; batch adversarial loss: 0.564555\n",
      "epoch 152; iter: 0; batch classifier loss: 0.407651; batch adversarial loss: 0.497667\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360345; batch adversarial loss: 0.589012\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360572; batch adversarial loss: 0.506551\n",
      "epoch 155; iter: 0; batch classifier loss: 0.395460; batch adversarial loss: 0.498060\n",
      "epoch 156; iter: 0; batch classifier loss: 0.365583; batch adversarial loss: 0.525993\n",
      "epoch 157; iter: 0; batch classifier loss: 0.420768; batch adversarial loss: 0.500247\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381147; batch adversarial loss: 0.517676\n",
      "epoch 159; iter: 0; batch classifier loss: 0.444420; batch adversarial loss: 0.589873\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380385; batch adversarial loss: 0.496953\n",
      "epoch 161; iter: 0; batch classifier loss: 0.348733; batch adversarial loss: 0.581053\n",
      "epoch 162; iter: 0; batch classifier loss: 0.290485; batch adversarial loss: 0.528249\n",
      "epoch 163; iter: 0; batch classifier loss: 0.443074; batch adversarial loss: 0.663431\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348130; batch adversarial loss: 0.590026\n",
      "epoch 165; iter: 0; batch classifier loss: 0.376092; batch adversarial loss: 0.544823\n",
      "epoch 166; iter: 0; batch classifier loss: 0.352469; batch adversarial loss: 0.533658\n",
      "epoch 167; iter: 0; batch classifier loss: 0.350409; batch adversarial loss: 0.544646\n",
      "epoch 168; iter: 0; batch classifier loss: 0.271856; batch adversarial loss: 0.507372\n",
      "epoch 169; iter: 0; batch classifier loss: 0.393493; batch adversarial loss: 0.599559\n",
      "epoch 170; iter: 0; batch classifier loss: 0.292599; batch adversarial loss: 0.488513\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347835; batch adversarial loss: 0.507756\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365269; batch adversarial loss: 0.580736\n",
      "epoch 173; iter: 0; batch classifier loss: 0.422087; batch adversarial loss: 0.609003\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365739; batch adversarial loss: 0.551649\n",
      "epoch 175; iter: 0; batch classifier loss: 0.411240; batch adversarial loss: 0.590502\n",
      "epoch 176; iter: 0; batch classifier loss: 0.311597; batch adversarial loss: 0.620072\n",
      "epoch 177; iter: 0; batch classifier loss: 0.407211; batch adversarial loss: 0.526473\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369063; batch adversarial loss: 0.554811\n",
      "epoch 179; iter: 0; batch classifier loss: 0.305718; batch adversarial loss: 0.510231\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362914; batch adversarial loss: 0.562265\n",
      "epoch 181; iter: 0; batch classifier loss: 0.351305; batch adversarial loss: 0.526419\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367247; batch adversarial loss: 0.497678\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373849; batch adversarial loss: 0.526298\n",
      "epoch 184; iter: 0; batch classifier loss: 0.448730; batch adversarial loss: 0.480956\n",
      "epoch 185; iter: 0; batch classifier loss: 0.374624; batch adversarial loss: 0.525989\n",
      "epoch 186; iter: 0; batch classifier loss: 0.409620; batch adversarial loss: 0.525939\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371295; batch adversarial loss: 0.551418\n",
      "epoch 188; iter: 0; batch classifier loss: 0.327703; batch adversarial loss: 0.599052\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378590; batch adversarial loss: 0.601333\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345967; batch adversarial loss: 0.508548\n",
      "epoch 191; iter: 0; batch classifier loss: 0.305362; batch adversarial loss: 0.497918\n",
      "epoch 192; iter: 0; batch classifier loss: 0.377602; batch adversarial loss: 0.553712\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300500; batch adversarial loss: 0.554917\n",
      "epoch 194; iter: 0; batch classifier loss: 0.416702; batch adversarial loss: 0.552629\n",
      "epoch 195; iter: 0; batch classifier loss: 0.352622; batch adversarial loss: 0.581514\n",
      "epoch 196; iter: 0; batch classifier loss: 0.422020; batch adversarial loss: 0.589423\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312874; batch adversarial loss: 0.542276\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384011; batch adversarial loss: 0.524888\n",
      "epoch 199; iter: 0; batch classifier loss: 0.495624; batch adversarial loss: 0.580739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748135; batch adversarial loss: 0.832624\n",
      "epoch 1; iter: 0; batch classifier loss: 0.744640; batch adversarial loss: 0.785038\n",
      "epoch 2; iter: 0; batch classifier loss: 0.817069; batch adversarial loss: 0.729966\n",
      "epoch 3; iter: 0; batch classifier loss: 0.716329; batch adversarial loss: 0.665700\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600865; batch adversarial loss: 0.629999\n",
      "epoch 5; iter: 0; batch classifier loss: 0.519382; batch adversarial loss: 0.601537\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612726; batch adversarial loss: 0.619369\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519442; batch adversarial loss: 0.601592\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521585; batch adversarial loss: 0.587592\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524165; batch adversarial loss: 0.640571\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552274; batch adversarial loss: 0.591524\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540542; batch adversarial loss: 0.566698\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555765; batch adversarial loss: 0.558997\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508232; batch adversarial loss: 0.643108\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548527; batch adversarial loss: 0.533843\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432148; batch adversarial loss: 0.562782\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464095; batch adversarial loss: 0.556592\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495974; batch adversarial loss: 0.514834\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444725; batch adversarial loss: 0.535776\n",
      "epoch 19; iter: 0; batch classifier loss: 0.402708; batch adversarial loss: 0.539798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.443187; batch adversarial loss: 0.535263\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509588; batch adversarial loss: 0.505038\n",
      "epoch 22; iter: 0; batch classifier loss: 0.533238; batch adversarial loss: 0.625956\n",
      "epoch 23; iter: 0; batch classifier loss: 0.553614; batch adversarial loss: 0.495886\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519912; batch adversarial loss: 0.544424\n",
      "epoch 25; iter: 0; batch classifier loss: 0.554209; batch adversarial loss: 0.518365\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478043; batch adversarial loss: 0.510245\n",
      "epoch 27; iter: 0; batch classifier loss: 0.410781; batch adversarial loss: 0.580432\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469288; batch adversarial loss: 0.550233\n",
      "epoch 29; iter: 0; batch classifier loss: 0.399763; batch adversarial loss: 0.527981\n",
      "epoch 30; iter: 0; batch classifier loss: 0.531239; batch adversarial loss: 0.510843\n",
      "epoch 31; iter: 0; batch classifier loss: 0.423352; batch adversarial loss: 0.577055\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422416; batch adversarial loss: 0.594221\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432730; batch adversarial loss: 0.542109\n",
      "epoch 34; iter: 0; batch classifier loss: 0.536450; batch adversarial loss: 0.586397\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498373; batch adversarial loss: 0.550497\n",
      "epoch 36; iter: 0; batch classifier loss: 0.483704; batch adversarial loss: 0.604437\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441516; batch adversarial loss: 0.583683\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496594; batch adversarial loss: 0.466429\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436842; batch adversarial loss: 0.605533\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450462; batch adversarial loss: 0.512803\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456206; batch adversarial loss: 0.541926\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429530; batch adversarial loss: 0.556059\n",
      "epoch 43; iter: 0; batch classifier loss: 0.369705; batch adversarial loss: 0.524347\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441561; batch adversarial loss: 0.560053\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465582; batch adversarial loss: 0.443129\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408950; batch adversarial loss: 0.564111\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433068; batch adversarial loss: 0.554789\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445632; batch adversarial loss: 0.523746\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409833; batch adversarial loss: 0.578483\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448841; batch adversarial loss: 0.490678\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490479; batch adversarial loss: 0.533074\n",
      "epoch 52; iter: 0; batch classifier loss: 0.454527; batch adversarial loss: 0.551720\n",
      "epoch 53; iter: 0; batch classifier loss: 0.447126; batch adversarial loss: 0.617244\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426164; batch adversarial loss: 0.606699\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384311; batch adversarial loss: 0.524519\n",
      "epoch 56; iter: 0; batch classifier loss: 0.380401; batch adversarial loss: 0.577771\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441358; batch adversarial loss: 0.553006\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402515; batch adversarial loss: 0.557004\n",
      "epoch 59; iter: 0; batch classifier loss: 0.390735; batch adversarial loss: 0.548695\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425478; batch adversarial loss: 0.566873\n",
      "epoch 61; iter: 0; batch classifier loss: 0.323911; batch adversarial loss: 0.543448\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444122; batch adversarial loss: 0.589599\n",
      "epoch 63; iter: 0; batch classifier loss: 0.440372; batch adversarial loss: 0.523502\n",
      "epoch 64; iter: 0; batch classifier loss: 0.352657; batch adversarial loss: 0.524129\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400450; batch adversarial loss: 0.575072\n",
      "epoch 66; iter: 0; batch classifier loss: 0.399997; batch adversarial loss: 0.561970\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412603; batch adversarial loss: 0.501160\n",
      "epoch 68; iter: 0; batch classifier loss: 0.468809; batch adversarial loss: 0.534849\n",
      "epoch 69; iter: 0; batch classifier loss: 0.370562; batch adversarial loss: 0.597591\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415502; batch adversarial loss: 0.507059\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446998; batch adversarial loss: 0.509813\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394592; batch adversarial loss: 0.553923\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404314; batch adversarial loss: 0.536493\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436914; batch adversarial loss: 0.517219\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421314; batch adversarial loss: 0.563739\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415299; batch adversarial loss: 0.561868\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389397; batch adversarial loss: 0.534582\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394132; batch adversarial loss: 0.576927\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404863; batch adversarial loss: 0.469391\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365846; batch adversarial loss: 0.676020\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358622; batch adversarial loss: 0.625519\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411914; batch adversarial loss: 0.524658\n",
      "epoch 83; iter: 0; batch classifier loss: 0.358861; batch adversarial loss: 0.554280\n",
      "epoch 84; iter: 0; batch classifier loss: 0.335492; batch adversarial loss: 0.536523\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452437; batch adversarial loss: 0.561188\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371516; batch adversarial loss: 0.535837\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410904; batch adversarial loss: 0.546122\n",
      "epoch 88; iter: 0; batch classifier loss: 0.467957; batch adversarial loss: 0.534758\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342299; batch adversarial loss: 0.543466\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350056; batch adversarial loss: 0.490530\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356836; batch adversarial loss: 0.507623\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404809; batch adversarial loss: 0.526406\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386569; batch adversarial loss: 0.498081\n",
      "epoch 94; iter: 0; batch classifier loss: 0.342244; batch adversarial loss: 0.554529\n",
      "epoch 95; iter: 0; batch classifier loss: 0.339392; batch adversarial loss: 0.502677\n",
      "epoch 96; iter: 0; batch classifier loss: 0.337569; batch adversarial loss: 0.631673\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404112; batch adversarial loss: 0.528042\n",
      "epoch 98; iter: 0; batch classifier loss: 0.354324; batch adversarial loss: 0.480626\n",
      "epoch 99; iter: 0; batch classifier loss: 0.477405; batch adversarial loss: 0.620491\n",
      "epoch 100; iter: 0; batch classifier loss: 0.442242; batch adversarial loss: 0.527491\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399055; batch adversarial loss: 0.471727\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347507; batch adversarial loss: 0.506170\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396623; batch adversarial loss: 0.570215\n",
      "epoch 104; iter: 0; batch classifier loss: 0.484665; batch adversarial loss: 0.553027\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363072; batch adversarial loss: 0.527372\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335932; batch adversarial loss: 0.568221\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380024; batch adversarial loss: 0.589092\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348646; batch adversarial loss: 0.524627\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371050; batch adversarial loss: 0.495235\n",
      "epoch 110; iter: 0; batch classifier loss: 0.447532; batch adversarial loss: 0.536901\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372415; batch adversarial loss: 0.515178\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370463; batch adversarial loss: 0.544685\n",
      "epoch 113; iter: 0; batch classifier loss: 0.439046; batch adversarial loss: 0.569260\n",
      "epoch 114; iter: 0; batch classifier loss: 0.407851; batch adversarial loss: 0.640899\n",
      "epoch 115; iter: 0; batch classifier loss: 0.391133; batch adversarial loss: 0.546807\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380703; batch adversarial loss: 0.546984\n",
      "epoch 117; iter: 0; batch classifier loss: 0.432505; batch adversarial loss: 0.534282\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347084; batch adversarial loss: 0.526053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.362849; batch adversarial loss: 0.605050\n",
      "epoch 120; iter: 0; batch classifier loss: 0.409774; batch adversarial loss: 0.592637\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334502; batch adversarial loss: 0.554781\n",
      "epoch 122; iter: 0; batch classifier loss: 0.291669; batch adversarial loss: 0.589665\n",
      "epoch 123; iter: 0; batch classifier loss: 0.363891; batch adversarial loss: 0.489373\n",
      "epoch 124; iter: 0; batch classifier loss: 0.308175; batch adversarial loss: 0.547150\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370159; batch adversarial loss: 0.536344\n",
      "epoch 126; iter: 0; batch classifier loss: 0.389909; batch adversarial loss: 0.572341\n",
      "epoch 127; iter: 0; batch classifier loss: 0.343835; batch adversarial loss: 0.561950\n",
      "epoch 128; iter: 0; batch classifier loss: 0.308423; batch adversarial loss: 0.569833\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324481; batch adversarial loss: 0.518240\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370366; batch adversarial loss: 0.606713\n",
      "epoch 131; iter: 0; batch classifier loss: 0.329858; batch adversarial loss: 0.508438\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353112; batch adversarial loss: 0.618042\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331208; batch adversarial loss: 0.524498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.348432; batch adversarial loss: 0.545881\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373842; batch adversarial loss: 0.601467\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359802; batch adversarial loss: 0.570655\n",
      "epoch 137; iter: 0; batch classifier loss: 0.390547; batch adversarial loss: 0.527847\n",
      "epoch 138; iter: 0; batch classifier loss: 0.302182; batch adversarial loss: 0.518342\n",
      "epoch 139; iter: 0; batch classifier loss: 0.410806; batch adversarial loss: 0.560483\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355401; batch adversarial loss: 0.471055\n",
      "epoch 141; iter: 0; batch classifier loss: 0.304603; batch adversarial loss: 0.598937\n",
      "epoch 142; iter: 0; batch classifier loss: 0.404801; batch adversarial loss: 0.557318\n",
      "epoch 143; iter: 0; batch classifier loss: 0.429317; batch adversarial loss: 0.554102\n",
      "epoch 144; iter: 0; batch classifier loss: 0.294870; batch adversarial loss: 0.408428\n",
      "epoch 145; iter: 0; batch classifier loss: 0.238910; batch adversarial loss: 0.534889\n",
      "epoch 146; iter: 0; batch classifier loss: 0.291056; batch adversarial loss: 0.544219\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383317; batch adversarial loss: 0.599250\n",
      "epoch 148; iter: 0; batch classifier loss: 0.434528; batch adversarial loss: 0.497182\n",
      "epoch 149; iter: 0; batch classifier loss: 0.326099; batch adversarial loss: 0.458256\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390023; batch adversarial loss: 0.549073\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365745; batch adversarial loss: 0.600484\n",
      "epoch 152; iter: 0; batch classifier loss: 0.433480; batch adversarial loss: 0.572624\n",
      "epoch 153; iter: 0; batch classifier loss: 0.382300; batch adversarial loss: 0.545033\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372873; batch adversarial loss: 0.514826\n",
      "epoch 155; iter: 0; batch classifier loss: 0.311296; batch adversarial loss: 0.538460\n",
      "epoch 156; iter: 0; batch classifier loss: 0.389892; batch adversarial loss: 0.499976\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372252; batch adversarial loss: 0.585147\n",
      "epoch 158; iter: 0; batch classifier loss: 0.331084; batch adversarial loss: 0.488755\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354314; batch adversarial loss: 0.570569\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404815; batch adversarial loss: 0.535834\n",
      "epoch 161; iter: 0; batch classifier loss: 0.389889; batch adversarial loss: 0.563844\n",
      "epoch 162; iter: 0; batch classifier loss: 0.346125; batch adversarial loss: 0.636934\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341545; batch adversarial loss: 0.525979\n",
      "epoch 164; iter: 0; batch classifier loss: 0.408082; batch adversarial loss: 0.523483\n",
      "epoch 165; iter: 0; batch classifier loss: 0.337488; batch adversarial loss: 0.581887\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312552; batch adversarial loss: 0.463158\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335193; batch adversarial loss: 0.509157\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369969; batch adversarial loss: 0.482306\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341935; batch adversarial loss: 0.490109\n",
      "epoch 170; iter: 0; batch classifier loss: 0.264800; batch adversarial loss: 0.525444\n",
      "epoch 171; iter: 0; batch classifier loss: 0.309023; batch adversarial loss: 0.543941\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373636; batch adversarial loss: 0.561505\n",
      "epoch 173; iter: 0; batch classifier loss: 0.370181; batch adversarial loss: 0.524529\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375692; batch adversarial loss: 0.479483\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360376; batch adversarial loss: 0.517090\n",
      "epoch 176; iter: 0; batch classifier loss: 0.263763; batch adversarial loss: 0.489514\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377801; batch adversarial loss: 0.443739\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391439; batch adversarial loss: 0.513182\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366298; batch adversarial loss: 0.608957\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369781; batch adversarial loss: 0.532586\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353456; batch adversarial loss: 0.567466\n",
      "epoch 182; iter: 0; batch classifier loss: 0.335114; batch adversarial loss: 0.535481\n",
      "epoch 183; iter: 0; batch classifier loss: 0.279727; batch adversarial loss: 0.537329\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294456; batch adversarial loss: 0.590435\n",
      "epoch 185; iter: 0; batch classifier loss: 0.297598; batch adversarial loss: 0.516123\n",
      "epoch 186; iter: 0; batch classifier loss: 0.410659; batch adversarial loss: 0.499943\n",
      "epoch 187; iter: 0; batch classifier loss: 0.354569; batch adversarial loss: 0.581424\n",
      "epoch 188; iter: 0; batch classifier loss: 0.321241; batch adversarial loss: 0.533967\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355838; batch adversarial loss: 0.555346\n",
      "epoch 190; iter: 0; batch classifier loss: 0.320180; batch adversarial loss: 0.527063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344559; batch adversarial loss: 0.493317\n",
      "epoch 192; iter: 0; batch classifier loss: 0.403090; batch adversarial loss: 0.512855\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344922; batch adversarial loss: 0.561071\n",
      "epoch 194; iter: 0; batch classifier loss: 0.328841; batch adversarial loss: 0.572795\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339204; batch adversarial loss: 0.554896\n",
      "epoch 196; iter: 0; batch classifier loss: 0.278395; batch adversarial loss: 0.589210\n",
      "epoch 197; iter: 0; batch classifier loss: 0.304625; batch adversarial loss: 0.514376\n",
      "epoch 198; iter: 0; batch classifier loss: 0.380310; batch adversarial loss: 0.527077\n",
      "epoch 199; iter: 0; batch classifier loss: 0.295856; batch adversarial loss: 0.452188\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657273; batch adversarial loss: 0.697501\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594122; batch adversarial loss: 0.674099\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625846; batch adversarial loss: 0.641982\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623586; batch adversarial loss: 0.630140\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558021; batch adversarial loss: 0.582730\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561195; batch adversarial loss: 0.567321\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554575; batch adversarial loss: 0.642795\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574806; batch adversarial loss: 0.564485\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495928; batch adversarial loss: 0.595369\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575501; batch adversarial loss: 0.589757\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551861; batch adversarial loss: 0.533774\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516744; batch adversarial loss: 0.562730\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556413; batch adversarial loss: 0.540067\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520559; batch adversarial loss: 0.638004\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442458; batch adversarial loss: 0.593306\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484521; batch adversarial loss: 0.601946\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525616; batch adversarial loss: 0.632319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.539943; batch adversarial loss: 0.559990\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485201; batch adversarial loss: 0.587521\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507887; batch adversarial loss: 0.560390\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496239; batch adversarial loss: 0.542144\n",
      "epoch 21; iter: 0; batch classifier loss: 0.533626; batch adversarial loss: 0.613552\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437592; batch adversarial loss: 0.577134\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493136; batch adversarial loss: 0.556765\n",
      "epoch 24; iter: 0; batch classifier loss: 0.513666; batch adversarial loss: 0.555719\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488626; batch adversarial loss: 0.552691\n",
      "epoch 26; iter: 0; batch classifier loss: 0.504166; batch adversarial loss: 0.591671\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482373; batch adversarial loss: 0.517293\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445042; batch adversarial loss: 0.500362\n",
      "epoch 29; iter: 0; batch classifier loss: 0.539173; batch adversarial loss: 0.530371\n",
      "epoch 30; iter: 0; batch classifier loss: 0.451901; batch adversarial loss: 0.553789\n",
      "epoch 31; iter: 0; batch classifier loss: 0.554067; batch adversarial loss: 0.538139\n",
      "epoch 32; iter: 0; batch classifier loss: 0.524489; batch adversarial loss: 0.528408\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426098; batch adversarial loss: 0.519958\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401188; batch adversarial loss: 0.588449\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475399; batch adversarial loss: 0.572272\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421102; batch adversarial loss: 0.511010\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424880; batch adversarial loss: 0.472669\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474019; batch adversarial loss: 0.554095\n",
      "epoch 39; iter: 0; batch classifier loss: 0.503362; batch adversarial loss: 0.536768\n",
      "epoch 40; iter: 0; batch classifier loss: 0.511208; batch adversarial loss: 0.501367\n",
      "epoch 41; iter: 0; batch classifier loss: 0.455835; batch adversarial loss: 0.542847\n",
      "epoch 42; iter: 0; batch classifier loss: 0.473794; batch adversarial loss: 0.506496\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413819; batch adversarial loss: 0.582441\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454138; batch adversarial loss: 0.546928\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480525; batch adversarial loss: 0.507222\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417080; batch adversarial loss: 0.542589\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493323; batch adversarial loss: 0.581613\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408402; batch adversarial loss: 0.461071\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383357; batch adversarial loss: 0.534843\n",
      "epoch 50; iter: 0; batch classifier loss: 0.491022; batch adversarial loss: 0.560203\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409509; batch adversarial loss: 0.546728\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426297; batch adversarial loss: 0.516673\n",
      "epoch 53; iter: 0; batch classifier loss: 0.373374; batch adversarial loss: 0.536514\n",
      "epoch 54; iter: 0; batch classifier loss: 0.354518; batch adversarial loss: 0.551938\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419151; batch adversarial loss: 0.620514\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456423; batch adversarial loss: 0.608252\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437711; batch adversarial loss: 0.518990\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436487; batch adversarial loss: 0.507560\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410819; batch adversarial loss: 0.535344\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422481; batch adversarial loss: 0.574544\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410941; batch adversarial loss: 0.629582\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457724; batch adversarial loss: 0.489521\n",
      "epoch 63; iter: 0; batch classifier loss: 0.484658; batch adversarial loss: 0.554775\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387660; batch adversarial loss: 0.627886\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437101; batch adversarial loss: 0.557309\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430299; batch adversarial loss: 0.611357\n",
      "epoch 67; iter: 0; batch classifier loss: 0.368689; batch adversarial loss: 0.548364\n",
      "epoch 68; iter: 0; batch classifier loss: 0.416901; batch adversarial loss: 0.502297\n",
      "epoch 69; iter: 0; batch classifier loss: 0.455537; batch adversarial loss: 0.577756\n",
      "epoch 70; iter: 0; batch classifier loss: 0.328413; batch adversarial loss: 0.634878\n",
      "epoch 71; iter: 0; batch classifier loss: 0.299859; batch adversarial loss: 0.534338\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440551; batch adversarial loss: 0.569409\n",
      "epoch 73; iter: 0; batch classifier loss: 0.486460; batch adversarial loss: 0.533141\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383539; batch adversarial loss: 0.616926\n",
      "epoch 75; iter: 0; batch classifier loss: 0.501420; batch adversarial loss: 0.572343\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394923; batch adversarial loss: 0.616201\n",
      "epoch 77; iter: 0; batch classifier loss: 0.377435; batch adversarial loss: 0.537958\n",
      "epoch 78; iter: 0; batch classifier loss: 0.456243; batch adversarial loss: 0.528142\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379741; batch adversarial loss: 0.535366\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371920; batch adversarial loss: 0.507463\n",
      "epoch 81; iter: 0; batch classifier loss: 0.364289; batch adversarial loss: 0.526574\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381047; batch adversarial loss: 0.552388\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360280; batch adversarial loss: 0.564277\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384397; batch adversarial loss: 0.544786\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431341; batch adversarial loss: 0.598728\n",
      "epoch 86; iter: 0; batch classifier loss: 0.502761; batch adversarial loss: 0.544721\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440831; batch adversarial loss: 0.535530\n",
      "epoch 88; iter: 0; batch classifier loss: 0.432718; batch adversarial loss: 0.543606\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376287; batch adversarial loss: 0.534582\n",
      "epoch 90; iter: 0; batch classifier loss: 0.429665; batch adversarial loss: 0.554167\n",
      "epoch 91; iter: 0; batch classifier loss: 0.443767; batch adversarial loss: 0.489502\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412099; batch adversarial loss: 0.555194\n",
      "epoch 93; iter: 0; batch classifier loss: 0.415676; batch adversarial loss: 0.508123\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394784; batch adversarial loss: 0.543647\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446549; batch adversarial loss: 0.507040\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405339; batch adversarial loss: 0.525892\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334937; batch adversarial loss: 0.553149\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395212; batch adversarial loss: 0.481019\n",
      "epoch 99; iter: 0; batch classifier loss: 0.458784; batch adversarial loss: 0.517534\n",
      "epoch 100; iter: 0; batch classifier loss: 0.299260; batch adversarial loss: 0.534447\n",
      "epoch 101; iter: 0; batch classifier loss: 0.373135; batch adversarial loss: 0.590764\n",
      "epoch 102; iter: 0; batch classifier loss: 0.321684; batch adversarial loss: 0.570819\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399555; batch adversarial loss: 0.508001\n",
      "epoch 104; iter: 0; batch classifier loss: 0.324247; batch adversarial loss: 0.572181\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373714; batch adversarial loss: 0.478656\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372417; batch adversarial loss: 0.431793\n",
      "epoch 107; iter: 0; batch classifier loss: 0.444644; batch adversarial loss: 0.571773\n",
      "epoch 108; iter: 0; batch classifier loss: 0.418491; batch adversarial loss: 0.542739\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402405; batch adversarial loss: 0.625973\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405199; batch adversarial loss: 0.536590\n",
      "epoch 111; iter: 0; batch classifier loss: 0.429253; batch adversarial loss: 0.527835\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364997; batch adversarial loss: 0.501159\n",
      "epoch 113; iter: 0; batch classifier loss: 0.402921; batch adversarial loss: 0.462737\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418240; batch adversarial loss: 0.617165\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379502; batch adversarial loss: 0.526264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.329147; batch adversarial loss: 0.633940\n",
      "epoch 117; iter: 0; batch classifier loss: 0.436144; batch adversarial loss: 0.581346\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398569; batch adversarial loss: 0.499465\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410856; batch adversarial loss: 0.536003\n",
      "epoch 120; iter: 0; batch classifier loss: 0.419735; batch adversarial loss: 0.625366\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388176; batch adversarial loss: 0.562400\n",
      "epoch 122; iter: 0; batch classifier loss: 0.428884; batch adversarial loss: 0.573291\n",
      "epoch 123; iter: 0; batch classifier loss: 0.404392; batch adversarial loss: 0.572575\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391387; batch adversarial loss: 0.581739\n",
      "epoch 125; iter: 0; batch classifier loss: 0.453779; batch adversarial loss: 0.562812\n",
      "epoch 126; iter: 0; batch classifier loss: 0.441900; batch adversarial loss: 0.480239\n",
      "epoch 127; iter: 0; batch classifier loss: 0.317801; batch adversarial loss: 0.517969\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355677; batch adversarial loss: 0.571009\n",
      "epoch 129; iter: 0; batch classifier loss: 0.396737; batch adversarial loss: 0.589120\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358028; batch adversarial loss: 0.607048\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365375; batch adversarial loss: 0.525480\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352129; batch adversarial loss: 0.525969\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412830; batch adversarial loss: 0.535138\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393396; batch adversarial loss: 0.526168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366565; batch adversarial loss: 0.517231\n",
      "epoch 136; iter: 0; batch classifier loss: 0.439998; batch adversarial loss: 0.535097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.339149; batch adversarial loss: 0.526797\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320409; batch adversarial loss: 0.572611\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345024; batch adversarial loss: 0.580159\n",
      "epoch 140; iter: 0; batch classifier loss: 0.398546; batch adversarial loss: 0.589598\n",
      "epoch 141; iter: 0; batch classifier loss: 0.347822; batch adversarial loss: 0.517736\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341830; batch adversarial loss: 0.571053\n",
      "epoch 143; iter: 0; batch classifier loss: 0.421804; batch adversarial loss: 0.562457\n",
      "epoch 144; iter: 0; batch classifier loss: 0.318725; batch adversarial loss: 0.608695\n",
      "epoch 145; iter: 0; batch classifier loss: 0.265848; batch adversarial loss: 0.451867\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384442; batch adversarial loss: 0.589844\n",
      "epoch 147; iter: 0; batch classifier loss: 0.314809; batch adversarial loss: 0.526889\n",
      "epoch 148; iter: 0; batch classifier loss: 0.347029; batch adversarial loss: 0.533952\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346731; batch adversarial loss: 0.518523\n",
      "epoch 150; iter: 0; batch classifier loss: 0.395508; batch adversarial loss: 0.552909\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391225; batch adversarial loss: 0.554133\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336659; batch adversarial loss: 0.554028\n",
      "epoch 153; iter: 0; batch classifier loss: 0.447655; batch adversarial loss: 0.535099\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404701; batch adversarial loss: 0.571840\n",
      "epoch 155; iter: 0; batch classifier loss: 0.396561; batch adversarial loss: 0.544690\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351321; batch adversarial loss: 0.516349\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356425; batch adversarial loss: 0.635217\n",
      "epoch 158; iter: 0; batch classifier loss: 0.324791; batch adversarial loss: 0.507569\n",
      "epoch 159; iter: 0; batch classifier loss: 0.474986; batch adversarial loss: 0.461872\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341319; batch adversarial loss: 0.544075\n",
      "epoch 161; iter: 0; batch classifier loss: 0.415129; batch adversarial loss: 0.579812\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361458; batch adversarial loss: 0.517981\n",
      "epoch 163; iter: 0; batch classifier loss: 0.426765; batch adversarial loss: 0.507003\n",
      "epoch 164; iter: 0; batch classifier loss: 0.365504; batch adversarial loss: 0.507696\n",
      "epoch 165; iter: 0; batch classifier loss: 0.403989; batch adversarial loss: 0.525971\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380626; batch adversarial loss: 0.589462\n",
      "epoch 167; iter: 0; batch classifier loss: 0.381824; batch adversarial loss: 0.572206\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372622; batch adversarial loss: 0.563500\n",
      "epoch 169; iter: 0; batch classifier loss: 0.398100; batch adversarial loss: 0.498943\n",
      "epoch 170; iter: 0; batch classifier loss: 0.310404; batch adversarial loss: 0.554321\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411570; batch adversarial loss: 0.499637\n",
      "epoch 172; iter: 0; batch classifier loss: 0.401636; batch adversarial loss: 0.471543\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371191; batch adversarial loss: 0.571110\n",
      "epoch 174; iter: 0; batch classifier loss: 0.274922; batch adversarial loss: 0.562810\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359398; batch adversarial loss: 0.563166\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370312; batch adversarial loss: 0.472050\n",
      "epoch 177; iter: 0; batch classifier loss: 0.424348; batch adversarial loss: 0.572241\n",
      "epoch 178; iter: 0; batch classifier loss: 0.377633; batch adversarial loss: 0.480290\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337928; batch adversarial loss: 0.462474\n",
      "epoch 180; iter: 0; batch classifier loss: 0.460962; batch adversarial loss: 0.552928\n",
      "epoch 181; iter: 0; batch classifier loss: 0.442283; batch adversarial loss: 0.545190\n",
      "epoch 182; iter: 0; batch classifier loss: 0.295486; batch adversarial loss: 0.545062\n",
      "epoch 183; iter: 0; batch classifier loss: 0.430509; batch adversarial loss: 0.534646\n",
      "epoch 184; iter: 0; batch classifier loss: 0.418669; batch adversarial loss: 0.636990\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365477; batch adversarial loss: 0.526706\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407357; batch adversarial loss: 0.618583\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373532; batch adversarial loss: 0.588516\n",
      "epoch 188; iter: 0; batch classifier loss: 0.439046; batch adversarial loss: 0.589827\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382235; batch adversarial loss: 0.480184\n",
      "epoch 190; iter: 0; batch classifier loss: 0.392336; batch adversarial loss: 0.553980\n",
      "epoch 191; iter: 0; batch classifier loss: 0.328080; batch adversarial loss: 0.590139\n",
      "epoch 192; iter: 0; batch classifier loss: 0.385343; batch adversarial loss: 0.617273\n",
      "epoch 193; iter: 0; batch classifier loss: 0.425642; batch adversarial loss: 0.563124\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393058; batch adversarial loss: 0.636410\n",
      "epoch 195; iter: 0; batch classifier loss: 0.345117; batch adversarial loss: 0.571437\n",
      "epoch 196; iter: 0; batch classifier loss: 0.395484; batch adversarial loss: 0.616915\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375675; batch adversarial loss: 0.499964\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340472; batch adversarial loss: 0.544760\n",
      "epoch 199; iter: 0; batch classifier loss: 0.401395; batch adversarial loss: 0.609060\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719825; batch adversarial loss: 0.858453\n",
      "epoch 1; iter: 0; batch classifier loss: 0.703664; batch adversarial loss: 0.874330\n",
      "epoch 2; iter: 0; batch classifier loss: 0.772747; batch adversarial loss: 0.843663\n",
      "epoch 3; iter: 0; batch classifier loss: 0.818093; batch adversarial loss: 0.765896\n",
      "epoch 4; iter: 0; batch classifier loss: 0.649609; batch adversarial loss: 0.685997\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509910; batch adversarial loss: 0.661475\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509318; batch adversarial loss: 0.629997\n",
      "epoch 7; iter: 0; batch classifier loss: 0.422810; batch adversarial loss: 0.602964\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546642; batch adversarial loss: 0.628270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565959; batch adversarial loss: 0.618539\n",
      "epoch 10; iter: 0; batch classifier loss: 0.603837; batch adversarial loss: 0.642111\n",
      "epoch 11; iter: 0; batch classifier loss: 0.476680; batch adversarial loss: 0.601702\n",
      "epoch 12; iter: 0; batch classifier loss: 0.482987; batch adversarial loss: 0.592288\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491496; batch adversarial loss: 0.586390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.462812; batch adversarial loss: 0.561437\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562066; batch adversarial loss: 0.559689\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510975; batch adversarial loss: 0.533468\n",
      "epoch 17; iter: 0; batch classifier loss: 0.589554; batch adversarial loss: 0.602305\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505634; batch adversarial loss: 0.547443\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474901; batch adversarial loss: 0.582844\n",
      "epoch 20; iter: 0; batch classifier loss: 0.405792; batch adversarial loss: 0.596617\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494312; batch adversarial loss: 0.621780\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458786; batch adversarial loss: 0.542234\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474716; batch adversarial loss: 0.541847\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465703; batch adversarial loss: 0.572738\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489362; batch adversarial loss: 0.602421\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508659; batch adversarial loss: 0.555827\n",
      "epoch 27; iter: 0; batch classifier loss: 0.431720; batch adversarial loss: 0.620160\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507050; batch adversarial loss: 0.506403\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480993; batch adversarial loss: 0.564327\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475285; batch adversarial loss: 0.623374\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459247; batch adversarial loss: 0.517851\n",
      "epoch 32; iter: 0; batch classifier loss: 0.492994; batch adversarial loss: 0.523795\n",
      "epoch 33; iter: 0; batch classifier loss: 0.454564; batch adversarial loss: 0.562405\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460540; batch adversarial loss: 0.496555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.524001; batch adversarial loss: 0.511955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482710; batch adversarial loss: 0.610183\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487927; batch adversarial loss: 0.574819\n",
      "epoch 38; iter: 0; batch classifier loss: 0.555485; batch adversarial loss: 0.612664\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417679; batch adversarial loss: 0.604295\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484522; batch adversarial loss: 0.476612\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416714; batch adversarial loss: 0.520872\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482114; batch adversarial loss: 0.538125\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455827; batch adversarial loss: 0.537538\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451018; batch adversarial loss: 0.580630\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467537; batch adversarial loss: 0.605206\n",
      "epoch 46; iter: 0; batch classifier loss: 0.484089; batch adversarial loss: 0.562121\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433594; batch adversarial loss: 0.510608\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440743; batch adversarial loss: 0.553150\n",
      "epoch 49; iter: 0; batch classifier loss: 0.524964; batch adversarial loss: 0.570928\n",
      "epoch 50; iter: 0; batch classifier loss: 0.399871; batch adversarial loss: 0.553234\n",
      "epoch 51; iter: 0; batch classifier loss: 0.367750; batch adversarial loss: 0.570876\n",
      "epoch 52; iter: 0; batch classifier loss: 0.489181; batch adversarial loss: 0.597037\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420204; batch adversarial loss: 0.518904\n",
      "epoch 54; iter: 0; batch classifier loss: 0.398920; batch adversarial loss: 0.526760\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449559; batch adversarial loss: 0.527040\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446107; batch adversarial loss: 0.516692\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468456; batch adversarial loss: 0.499803\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413190; batch adversarial loss: 0.579637\n",
      "epoch 59; iter: 0; batch classifier loss: 0.403142; batch adversarial loss: 0.635041\n",
      "epoch 60; iter: 0; batch classifier loss: 0.476811; batch adversarial loss: 0.545323\n",
      "epoch 61; iter: 0; batch classifier loss: 0.478022; batch adversarial loss: 0.621571\n",
      "epoch 62; iter: 0; batch classifier loss: 0.463479; batch adversarial loss: 0.560908\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446584; batch adversarial loss: 0.517808\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429472; batch adversarial loss: 0.570338\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442956; batch adversarial loss: 0.551984\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435753; batch adversarial loss: 0.556103\n",
      "epoch 67; iter: 0; batch classifier loss: 0.432428; batch adversarial loss: 0.624106\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380850; batch adversarial loss: 0.542880\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426399; batch adversarial loss: 0.588334\n",
      "epoch 70; iter: 0; batch classifier loss: 0.389086; batch adversarial loss: 0.502003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.355082; batch adversarial loss: 0.608096\n",
      "epoch 72; iter: 0; batch classifier loss: 0.346020; batch adversarial loss: 0.554798\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407895; batch adversarial loss: 0.501410\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433056; batch adversarial loss: 0.524809\n",
      "epoch 75; iter: 0; batch classifier loss: 0.428748; batch adversarial loss: 0.601408\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407743; batch adversarial loss: 0.578215\n",
      "epoch 77; iter: 0; batch classifier loss: 0.461777; batch adversarial loss: 0.507957\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395684; batch adversarial loss: 0.506719\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421156; batch adversarial loss: 0.618826\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392045; batch adversarial loss: 0.563215\n",
      "epoch 81; iter: 0; batch classifier loss: 0.434089; batch adversarial loss: 0.587183\n",
      "epoch 82; iter: 0; batch classifier loss: 0.405668; batch adversarial loss: 0.482497\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412260; batch adversarial loss: 0.537380\n",
      "epoch 84; iter: 0; batch classifier loss: 0.459622; batch adversarial loss: 0.560513\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409860; batch adversarial loss: 0.536142\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395239; batch adversarial loss: 0.564230\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428700; batch adversarial loss: 0.603850\n",
      "epoch 88; iter: 0; batch classifier loss: 0.287306; batch adversarial loss: 0.534572\n",
      "epoch 89; iter: 0; batch classifier loss: 0.322124; batch adversarial loss: 0.588944\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375668; batch adversarial loss: 0.552599\n",
      "epoch 91; iter: 0; batch classifier loss: 0.452218; batch adversarial loss: 0.527158\n",
      "epoch 92; iter: 0; batch classifier loss: 0.437899; batch adversarial loss: 0.631596\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356897; batch adversarial loss: 0.500750\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404745; batch adversarial loss: 0.554284\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410837; batch adversarial loss: 0.501549\n",
      "epoch 96; iter: 0; batch classifier loss: 0.346580; batch adversarial loss: 0.599442\n",
      "epoch 97; iter: 0; batch classifier loss: 0.485406; batch adversarial loss: 0.571015\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394274; batch adversarial loss: 0.588811\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422250; batch adversarial loss: 0.500142\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392072; batch adversarial loss: 0.565824\n",
      "epoch 101; iter: 0; batch classifier loss: 0.346025; batch adversarial loss: 0.655004\n",
      "epoch 102; iter: 0; batch classifier loss: 0.390948; batch adversarial loss: 0.608762\n",
      "epoch 103; iter: 0; batch classifier loss: 0.480457; batch adversarial loss: 0.544870\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402494; batch adversarial loss: 0.616149\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352936; batch adversarial loss: 0.547502\n",
      "epoch 106; iter: 0; batch classifier loss: 0.324558; batch adversarial loss: 0.517595\n",
      "epoch 107; iter: 0; batch classifier loss: 0.484920; batch adversarial loss: 0.579062\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422896; batch adversarial loss: 0.502148\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361022; batch adversarial loss: 0.582589\n",
      "epoch 110; iter: 0; batch classifier loss: 0.331684; batch adversarial loss: 0.532606\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407416; batch adversarial loss: 0.563753\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388176; batch adversarial loss: 0.553661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.401288; batch adversarial loss: 0.606638\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357343; batch adversarial loss: 0.536155\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412003; batch adversarial loss: 0.528869\n",
      "epoch 116; iter: 0; batch classifier loss: 0.432772; batch adversarial loss: 0.605673\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374144; batch adversarial loss: 0.658594\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367928; batch adversarial loss: 0.520320\n",
      "epoch 119; iter: 0; batch classifier loss: 0.329171; batch adversarial loss: 0.677461\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400427; batch adversarial loss: 0.527318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.427719; batch adversarial loss: 0.511671\n",
      "epoch 122; iter: 0; batch classifier loss: 0.354174; batch adversarial loss: 0.520336\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366768; batch adversarial loss: 0.536424\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337320; batch adversarial loss: 0.544893\n",
      "epoch 125; iter: 0; batch classifier loss: 0.420587; batch adversarial loss: 0.552566\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374444; batch adversarial loss: 0.553883\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394775; batch adversarial loss: 0.553560\n",
      "epoch 128; iter: 0; batch classifier loss: 0.440025; batch adversarial loss: 0.561658\n",
      "epoch 129; iter: 0; batch classifier loss: 0.381671; batch adversarial loss: 0.518503\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374790; batch adversarial loss: 0.613089\n",
      "epoch 131; iter: 0; batch classifier loss: 0.427107; batch adversarial loss: 0.447929\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376907; batch adversarial loss: 0.516471\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354536; batch adversarial loss: 0.488701\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365243; batch adversarial loss: 0.570322\n",
      "epoch 135; iter: 0; batch classifier loss: 0.312513; batch adversarial loss: 0.554879\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340995; batch adversarial loss: 0.545199\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402004; batch adversarial loss: 0.581409\n",
      "epoch 138; iter: 0; batch classifier loss: 0.445529; batch adversarial loss: 0.570243\n",
      "epoch 139; iter: 0; batch classifier loss: 0.320891; batch adversarial loss: 0.596144\n",
      "epoch 140; iter: 0; batch classifier loss: 0.313278; batch adversarial loss: 0.591568\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334847; batch adversarial loss: 0.572328\n",
      "epoch 142; iter: 0; batch classifier loss: 0.329574; batch adversarial loss: 0.623612\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359091; batch adversarial loss: 0.559089\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371265; batch adversarial loss: 0.594581\n",
      "epoch 145; iter: 0; batch classifier loss: 0.413141; batch adversarial loss: 0.540122\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360877; batch adversarial loss: 0.561718\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372063; batch adversarial loss: 0.598659\n",
      "epoch 148; iter: 0; batch classifier loss: 0.390038; batch adversarial loss: 0.584194\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351842; batch adversarial loss: 0.531947\n",
      "epoch 150; iter: 0; batch classifier loss: 0.274532; batch adversarial loss: 0.618696\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348296; batch adversarial loss: 0.685090\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343148; batch adversarial loss: 0.635336\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383043; batch adversarial loss: 0.545699\n",
      "epoch 154; iter: 0; batch classifier loss: 0.322365; batch adversarial loss: 0.560989\n",
      "epoch 155; iter: 0; batch classifier loss: 0.411551; batch adversarial loss: 0.490314\n",
      "epoch 156; iter: 0; batch classifier loss: 0.435866; batch adversarial loss: 0.604652\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356653; batch adversarial loss: 0.534712\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370916; batch adversarial loss: 0.582726\n",
      "epoch 159; iter: 0; batch classifier loss: 0.454993; batch adversarial loss: 0.659066\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350928; batch adversarial loss: 0.589228\n",
      "epoch 161; iter: 0; batch classifier loss: 0.395962; batch adversarial loss: 0.562937\n",
      "epoch 162; iter: 0; batch classifier loss: 0.339120; batch adversarial loss: 0.545426\n",
      "epoch 163; iter: 0; batch classifier loss: 0.358895; batch adversarial loss: 0.469768\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336342; batch adversarial loss: 0.588943\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353043; batch adversarial loss: 0.597934\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346347; batch adversarial loss: 0.528431\n",
      "epoch 167; iter: 0; batch classifier loss: 0.408720; batch adversarial loss: 0.562879\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306793; batch adversarial loss: 0.484604\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332161; batch adversarial loss: 0.569394\n",
      "epoch 170; iter: 0; batch classifier loss: 0.405091; batch adversarial loss: 0.554015\n",
      "epoch 171; iter: 0; batch classifier loss: 0.313208; batch adversarial loss: 0.587478\n",
      "epoch 172; iter: 0; batch classifier loss: 0.410769; batch adversarial loss: 0.564364\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373811; batch adversarial loss: 0.563624\n",
      "epoch 174; iter: 0; batch classifier loss: 0.323216; batch adversarial loss: 0.587183\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337602; batch adversarial loss: 0.455049\n",
      "epoch 176; iter: 0; batch classifier loss: 0.321791; batch adversarial loss: 0.617481\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384345; batch adversarial loss: 0.599138\n",
      "epoch 178; iter: 0; batch classifier loss: 0.410940; batch adversarial loss: 0.505818\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367125; batch adversarial loss: 0.615120\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340949; batch adversarial loss: 0.500423\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387139; batch adversarial loss: 0.536642\n",
      "epoch 182; iter: 0; batch classifier loss: 0.415412; batch adversarial loss: 0.571127\n",
      "epoch 183; iter: 0; batch classifier loss: 0.310959; batch adversarial loss: 0.510150\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363796; batch adversarial loss: 0.572038\n",
      "epoch 185; iter: 0; batch classifier loss: 0.286868; batch adversarial loss: 0.587730\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358401; batch adversarial loss: 0.607080\n",
      "epoch 187; iter: 0; batch classifier loss: 0.275166; batch adversarial loss: 0.640287\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379590; batch adversarial loss: 0.605226\n",
      "epoch 189; iter: 0; batch classifier loss: 0.326241; batch adversarial loss: 0.500113\n",
      "epoch 190; iter: 0; batch classifier loss: 0.433084; batch adversarial loss: 0.587891\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390916; batch adversarial loss: 0.553812\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384942; batch adversarial loss: 0.511232\n",
      "epoch 193; iter: 0; batch classifier loss: 0.394436; batch adversarial loss: 0.570194\n",
      "epoch 194; iter: 0; batch classifier loss: 0.391241; batch adversarial loss: 0.579300\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310680; batch adversarial loss: 0.526272\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378561; batch adversarial loss: 0.518570\n",
      "epoch 197; iter: 0; batch classifier loss: 0.325247; batch adversarial loss: 0.473460\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341995; batch adversarial loss: 0.535299\n",
      "epoch 199; iter: 0; batch classifier loss: 0.354594; batch adversarial loss: 0.571749\n",
      "epoch 0; iter: 0; batch classifier loss: 0.774736; batch adversarial loss: 0.585730\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585122; batch adversarial loss: 0.642173\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589150; batch adversarial loss: 0.651286\n",
      "epoch 3; iter: 0; batch classifier loss: 0.621691; batch adversarial loss: 0.675455\n",
      "epoch 4; iter: 0; batch classifier loss: 0.668269; batch adversarial loss: 0.632378\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556645; batch adversarial loss: 0.639815\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535489; batch adversarial loss: 0.627392\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553719; batch adversarial loss: 0.621678\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483711; batch adversarial loss: 0.570762\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577947; batch adversarial loss: 0.591259\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500805; batch adversarial loss: 0.544277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.495699; batch adversarial loss: 0.603486\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502185; batch adversarial loss: 0.618992\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517514; batch adversarial loss: 0.517439\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502637; batch adversarial loss: 0.621448\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527584; batch adversarial loss: 0.583828\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540750; batch adversarial loss: 0.591832\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520740; batch adversarial loss: 0.547052\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498612; batch adversarial loss: 0.518441\n",
      "epoch 19; iter: 0; batch classifier loss: 0.467064; batch adversarial loss: 0.568982\n",
      "epoch 20; iter: 0; batch classifier loss: 0.596443; batch adversarial loss: 0.575058\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494386; batch adversarial loss: 0.576911\n",
      "epoch 22; iter: 0; batch classifier loss: 0.488871; batch adversarial loss: 0.587243\n",
      "epoch 23; iter: 0; batch classifier loss: 0.572304; batch adversarial loss: 0.537665\n",
      "epoch 24; iter: 0; batch classifier loss: 0.469634; batch adversarial loss: 0.591298\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485862; batch adversarial loss: 0.655524\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471089; batch adversarial loss: 0.535645\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475788; batch adversarial loss: 0.563133\n",
      "epoch 28; iter: 0; batch classifier loss: 0.443024; batch adversarial loss: 0.616150\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455724; batch adversarial loss: 0.566595\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434406; batch adversarial loss: 0.524712\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449465; batch adversarial loss: 0.547279\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435462; batch adversarial loss: 0.518652\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476459; batch adversarial loss: 0.499706\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441313; batch adversarial loss: 0.575956\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470656; batch adversarial loss: 0.501349\n",
      "epoch 36; iter: 0; batch classifier loss: 0.411635; batch adversarial loss: 0.525928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480371; batch adversarial loss: 0.552641\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444563; batch adversarial loss: 0.599293\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482240; batch adversarial loss: 0.538116\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446015; batch adversarial loss: 0.582021\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419476; batch adversarial loss: 0.545623\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448782; batch adversarial loss: 0.562337\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415700; batch adversarial loss: 0.553179\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375527; batch adversarial loss: 0.489576\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407621; batch adversarial loss: 0.491104\n",
      "epoch 46; iter: 0; batch classifier loss: 0.478312; batch adversarial loss: 0.628042\n",
      "epoch 47; iter: 0; batch classifier loss: 0.492737; batch adversarial loss: 0.546039\n",
      "epoch 48; iter: 0; batch classifier loss: 0.537736; batch adversarial loss: 0.544326\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446854; batch adversarial loss: 0.553873\n",
      "epoch 50; iter: 0; batch classifier loss: 0.445508; batch adversarial loss: 0.524713\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443828; batch adversarial loss: 0.544444\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399341; batch adversarial loss: 0.496562\n",
      "epoch 53; iter: 0; batch classifier loss: 0.528987; batch adversarial loss: 0.516413\n",
      "epoch 54; iter: 0; batch classifier loss: 0.485035; batch adversarial loss: 0.489127\n",
      "epoch 55; iter: 0; batch classifier loss: 0.461107; batch adversarial loss: 0.535228\n",
      "epoch 56; iter: 0; batch classifier loss: 0.470470; batch adversarial loss: 0.627871\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441413; batch adversarial loss: 0.581535\n",
      "epoch 58; iter: 0; batch classifier loss: 0.405521; batch adversarial loss: 0.563445\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406115; batch adversarial loss: 0.488485\n",
      "epoch 60; iter: 0; batch classifier loss: 0.349265; batch adversarial loss: 0.572530\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395493; batch adversarial loss: 0.507233\n",
      "epoch 62; iter: 0; batch classifier loss: 0.456568; batch adversarial loss: 0.507218\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431646; batch adversarial loss: 0.553747\n",
      "epoch 64; iter: 0; batch classifier loss: 0.472720; batch adversarial loss: 0.498204\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443566; batch adversarial loss: 0.516875\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414663; batch adversarial loss: 0.478778\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420002; batch adversarial loss: 0.497430\n",
      "epoch 68; iter: 0; batch classifier loss: 0.453189; batch adversarial loss: 0.534782\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411226; batch adversarial loss: 0.610808\n",
      "epoch 70; iter: 0; batch classifier loss: 0.432639; batch adversarial loss: 0.466522\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407848; batch adversarial loss: 0.574423\n",
      "epoch 72; iter: 0; batch classifier loss: 0.374289; batch adversarial loss: 0.563943\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378779; batch adversarial loss: 0.631459\n",
      "epoch 74; iter: 0; batch classifier loss: 0.354570; batch adversarial loss: 0.534045\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416678; batch adversarial loss: 0.495928\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368608; batch adversarial loss: 0.527617\n",
      "epoch 77; iter: 0; batch classifier loss: 0.307064; batch adversarial loss: 0.569045\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395068; batch adversarial loss: 0.497787\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437749; batch adversarial loss: 0.526521\n",
      "epoch 80; iter: 0; batch classifier loss: 0.368573; batch adversarial loss: 0.506460\n",
      "epoch 81; iter: 0; batch classifier loss: 0.435453; batch adversarial loss: 0.565295\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395073; batch adversarial loss: 0.488393\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388308; batch adversarial loss: 0.592512\n",
      "epoch 84; iter: 0; batch classifier loss: 0.311050; batch adversarial loss: 0.535992\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435711; batch adversarial loss: 0.571888\n",
      "epoch 86; iter: 0; batch classifier loss: 0.437660; batch adversarial loss: 0.626988\n",
      "epoch 87; iter: 0; batch classifier loss: 0.298978; batch adversarial loss: 0.479859\n",
      "epoch 88; iter: 0; batch classifier loss: 0.370972; batch adversarial loss: 0.535335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395097; batch adversarial loss: 0.590810\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386358; batch adversarial loss: 0.535164\n",
      "epoch 91; iter: 0; batch classifier loss: 0.369401; batch adversarial loss: 0.553678\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425221; batch adversarial loss: 0.553478\n",
      "epoch 93; iter: 0; batch classifier loss: 0.396152; batch adversarial loss: 0.553749\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375640; batch adversarial loss: 0.600919\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333122; batch adversarial loss: 0.573017\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384851; batch adversarial loss: 0.582601\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356405; batch adversarial loss: 0.450001\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370112; batch adversarial loss: 0.611139\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361727; batch adversarial loss: 0.628557\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403422; batch adversarial loss: 0.488090\n",
      "epoch 101; iter: 0; batch classifier loss: 0.471952; batch adversarial loss: 0.639095\n",
      "epoch 102; iter: 0; batch classifier loss: 0.364129; batch adversarial loss: 0.647945\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373401; batch adversarial loss: 0.563020\n",
      "epoch 104; iter: 0; batch classifier loss: 0.439377; batch adversarial loss: 0.458157\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358290; batch adversarial loss: 0.600264\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367234; batch adversarial loss: 0.582876\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388342; batch adversarial loss: 0.506153\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385114; batch adversarial loss: 0.602938\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358557; batch adversarial loss: 0.571396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.404798; batch adversarial loss: 0.545834\n",
      "epoch 111; iter: 0; batch classifier loss: 0.280879; batch adversarial loss: 0.440944\n",
      "epoch 112; iter: 0; batch classifier loss: 0.352527; batch adversarial loss: 0.563594\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419463; batch adversarial loss: 0.601296\n",
      "epoch 114; iter: 0; batch classifier loss: 0.446640; batch adversarial loss: 0.525206\n",
      "epoch 115; iter: 0; batch classifier loss: 0.410792; batch adversarial loss: 0.535927\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410688; batch adversarial loss: 0.563169\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368350; batch adversarial loss: 0.479698\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395219; batch adversarial loss: 0.526706\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374402; batch adversarial loss: 0.563135\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380226; batch adversarial loss: 0.525560\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370651; batch adversarial loss: 0.498113\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361578; batch adversarial loss: 0.516290\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400693; batch adversarial loss: 0.572519\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376773; batch adversarial loss: 0.535328\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377967; batch adversarial loss: 0.628753\n",
      "epoch 126; iter: 0; batch classifier loss: 0.331412; batch adversarial loss: 0.525776\n",
      "epoch 127; iter: 0; batch classifier loss: 0.392347; batch adversarial loss: 0.459668\n",
      "epoch 128; iter: 0; batch classifier loss: 0.391137; batch adversarial loss: 0.487280\n",
      "epoch 129; iter: 0; batch classifier loss: 0.328904; batch adversarial loss: 0.544204\n",
      "epoch 130; iter: 0; batch classifier loss: 0.333518; batch adversarial loss: 0.459150\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388112; batch adversarial loss: 0.525648\n",
      "epoch 132; iter: 0; batch classifier loss: 0.385747; batch adversarial loss: 0.563199\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347301; batch adversarial loss: 0.515786\n",
      "epoch 134; iter: 0; batch classifier loss: 0.327157; batch adversarial loss: 0.534787\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350979; batch adversarial loss: 0.563051\n",
      "epoch 136; iter: 0; batch classifier loss: 0.303191; batch adversarial loss: 0.572499\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329697; batch adversarial loss: 0.525890\n",
      "epoch 138; iter: 0; batch classifier loss: 0.339708; batch adversarial loss: 0.572344\n",
      "epoch 139; iter: 0; batch classifier loss: 0.297849; batch adversarial loss: 0.628798\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373693; batch adversarial loss: 0.525745\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342951; batch adversarial loss: 0.497592\n",
      "epoch 142; iter: 0; batch classifier loss: 0.469522; batch adversarial loss: 0.582048\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369302; batch adversarial loss: 0.553289\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395940; batch adversarial loss: 0.572363\n",
      "epoch 145; iter: 0; batch classifier loss: 0.428222; batch adversarial loss: 0.554332\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357977; batch adversarial loss: 0.601609\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373381; batch adversarial loss: 0.497979\n",
      "epoch 148; iter: 0; batch classifier loss: 0.362098; batch adversarial loss: 0.525754\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370324; batch adversarial loss: 0.554028\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370064; batch adversarial loss: 0.535245\n",
      "epoch 151; iter: 0; batch classifier loss: 0.466131; batch adversarial loss: 0.544813\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332929; batch adversarial loss: 0.534998\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399796; batch adversarial loss: 0.488236\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346105; batch adversarial loss: 0.506774\n",
      "epoch 155; iter: 0; batch classifier loss: 0.372708; batch adversarial loss: 0.582683\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333316; batch adversarial loss: 0.506961\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361385; batch adversarial loss: 0.525719\n",
      "epoch 158; iter: 0; batch classifier loss: 0.411388; batch adversarial loss: 0.535197\n",
      "epoch 159; iter: 0; batch classifier loss: 0.439592; batch adversarial loss: 0.525744\n",
      "epoch 160; iter: 0; batch classifier loss: 0.305022; batch adversarial loss: 0.497606\n",
      "epoch 161; iter: 0; batch classifier loss: 0.294330; batch adversarial loss: 0.497694\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359926; batch adversarial loss: 0.497618\n",
      "epoch 163; iter: 0; batch classifier loss: 0.381172; batch adversarial loss: 0.544574\n",
      "epoch 164; iter: 0; batch classifier loss: 0.331340; batch adversarial loss: 0.516457\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329389; batch adversarial loss: 0.591471\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374317; batch adversarial loss: 0.591502\n",
      "epoch 167; iter: 0; batch classifier loss: 0.350525; batch adversarial loss: 0.563731\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330149; batch adversarial loss: 0.478435\n",
      "epoch 169; iter: 0; batch classifier loss: 0.446067; batch adversarial loss: 0.516031\n",
      "epoch 170; iter: 0; batch classifier loss: 0.348509; batch adversarial loss: 0.516617\n",
      "epoch 171; iter: 0; batch classifier loss: 0.308827; batch adversarial loss: 0.535603\n",
      "epoch 172; iter: 0; batch classifier loss: 0.399898; batch adversarial loss: 0.458874\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375500; batch adversarial loss: 0.581865\n",
      "epoch 174; iter: 0; batch classifier loss: 0.419749; batch adversarial loss: 0.555613\n",
      "epoch 175; iter: 0; batch classifier loss: 0.317782; batch adversarial loss: 0.544660\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353144; batch adversarial loss: 0.469274\n",
      "epoch 177; iter: 0; batch classifier loss: 0.327462; batch adversarial loss: 0.543961\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390888; batch adversarial loss: 0.544525\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364683; batch adversarial loss: 0.610290\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352233; batch adversarial loss: 0.544193\n",
      "epoch 181; iter: 0; batch classifier loss: 0.321161; batch adversarial loss: 0.535283\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352470; batch adversarial loss: 0.563653\n",
      "epoch 183; iter: 0; batch classifier loss: 0.401135; batch adversarial loss: 0.544359\n",
      "epoch 184; iter: 0; batch classifier loss: 0.280129; batch adversarial loss: 0.544926\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362677; batch adversarial loss: 0.554061\n",
      "epoch 186; iter: 0; batch classifier loss: 0.402378; batch adversarial loss: 0.554002\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367809; batch adversarial loss: 0.506988\n",
      "epoch 188; iter: 0; batch classifier loss: 0.317874; batch adversarial loss: 0.544383\n",
      "epoch 189; iter: 0; batch classifier loss: 0.407867; batch adversarial loss: 0.516556\n",
      "epoch 190; iter: 0; batch classifier loss: 0.356288; batch adversarial loss: 0.582800\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354331; batch adversarial loss: 0.505717\n",
      "epoch 192; iter: 0; batch classifier loss: 0.494507; batch adversarial loss: 0.525774\n",
      "epoch 193; iter: 0; batch classifier loss: 0.355913; batch adversarial loss: 0.525702\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362497; batch adversarial loss: 0.563433\n",
      "epoch 195; iter: 0; batch classifier loss: 0.297792; batch adversarial loss: 0.600526\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374790; batch adversarial loss: 0.581735\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372777; batch adversarial loss: 0.544668\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378841; batch adversarial loss: 0.534804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.288430; batch adversarial loss: 0.600773\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717773; batch adversarial loss: 0.833226\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588713; batch adversarial loss: 0.900447\n",
      "epoch 2; iter: 0; batch classifier loss: 0.650277; batch adversarial loss: 0.801997\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531642; batch adversarial loss: 0.733414\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589957; batch adversarial loss: 0.690842\n",
      "epoch 5; iter: 0; batch classifier loss: 0.481313; batch adversarial loss: 0.693413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.511626; batch adversarial loss: 0.664207\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503811; batch adversarial loss: 0.642365\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557734; batch adversarial loss: 0.624708\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538332; batch adversarial loss: 0.613353\n",
      "epoch 10; iter: 0; batch classifier loss: 0.587668; batch adversarial loss: 0.621445\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526812; batch adversarial loss: 0.583115\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499109; batch adversarial loss: 0.629972\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532854; batch adversarial loss: 0.580866\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518270; batch adversarial loss: 0.559053\n",
      "epoch 15; iter: 0; batch classifier loss: 0.582936; batch adversarial loss: 0.576637\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532368; batch adversarial loss: 0.595539\n",
      "epoch 17; iter: 0; batch classifier loss: 0.454715; batch adversarial loss: 0.570431\n",
      "epoch 18; iter: 0; batch classifier loss: 0.420043; batch adversarial loss: 0.532761\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503276; batch adversarial loss: 0.540748\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493358; batch adversarial loss: 0.595366\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510014; batch adversarial loss: 0.571164\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531840; batch adversarial loss: 0.583482\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491244; batch adversarial loss: 0.556341\n",
      "epoch 24; iter: 0; batch classifier loss: 0.451576; batch adversarial loss: 0.514462\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495442; batch adversarial loss: 0.517877\n",
      "epoch 26; iter: 0; batch classifier loss: 0.441952; batch adversarial loss: 0.614957\n",
      "epoch 27; iter: 0; batch classifier loss: 0.563804; batch adversarial loss: 0.544487\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460510; batch adversarial loss: 0.572826\n",
      "epoch 29; iter: 0; batch classifier loss: 0.539194; batch adversarial loss: 0.620209\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471549; batch adversarial loss: 0.538169\n",
      "epoch 31; iter: 0; batch classifier loss: 0.419191; batch adversarial loss: 0.519451\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466428; batch adversarial loss: 0.544052\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453528; batch adversarial loss: 0.491683\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430260; batch adversarial loss: 0.518398\n",
      "epoch 35; iter: 0; batch classifier loss: 0.428842; batch adversarial loss: 0.603473\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468458; batch adversarial loss: 0.616081\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423069; batch adversarial loss: 0.581274\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430732; batch adversarial loss: 0.582595\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448166; batch adversarial loss: 0.528956\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423958; batch adversarial loss: 0.484632\n",
      "epoch 41; iter: 0; batch classifier loss: 0.524503; batch adversarial loss: 0.501281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429977; batch adversarial loss: 0.649708\n",
      "epoch 43; iter: 0; batch classifier loss: 0.542366; batch adversarial loss: 0.510251\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447776; batch adversarial loss: 0.552716\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456406; batch adversarial loss: 0.535756\n",
      "epoch 46; iter: 0; batch classifier loss: 0.349100; batch adversarial loss: 0.615900\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477747; batch adversarial loss: 0.496858\n",
      "epoch 48; iter: 0; batch classifier loss: 0.475882; batch adversarial loss: 0.471568\n",
      "epoch 49; iter: 0; batch classifier loss: 0.453918; batch adversarial loss: 0.642950\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413611; batch adversarial loss: 0.535052\n",
      "epoch 51; iter: 0; batch classifier loss: 0.492938; batch adversarial loss: 0.617980\n",
      "epoch 52; iter: 0; batch classifier loss: 0.484989; batch adversarial loss: 0.524862\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395907; batch adversarial loss: 0.489360\n",
      "epoch 54; iter: 0; batch classifier loss: 0.486107; batch adversarial loss: 0.500821\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426054; batch adversarial loss: 0.516161\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396552; batch adversarial loss: 0.524274\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468555; batch adversarial loss: 0.536382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401714; batch adversarial loss: 0.570672\n",
      "epoch 59; iter: 0; batch classifier loss: 0.405761; batch adversarial loss: 0.570268\n",
      "epoch 60; iter: 0; batch classifier loss: 0.449112; batch adversarial loss: 0.589424\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460495; batch adversarial loss: 0.555722\n",
      "epoch 62; iter: 0; batch classifier loss: 0.418529; batch adversarial loss: 0.508694\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397026; batch adversarial loss: 0.520782\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436570; batch adversarial loss: 0.625254\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395656; batch adversarial loss: 0.587792\n",
      "epoch 66; iter: 0; batch classifier loss: 0.326444; batch adversarial loss: 0.546689\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414273; batch adversarial loss: 0.587005\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373011; batch adversarial loss: 0.625475\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373374; batch adversarial loss: 0.559179\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438908; batch adversarial loss: 0.588561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418582; batch adversarial loss: 0.461164\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430791; batch adversarial loss: 0.495127\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403470; batch adversarial loss: 0.553769\n",
      "epoch 74; iter: 0; batch classifier loss: 0.438094; batch adversarial loss: 0.553728\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402189; batch adversarial loss: 0.562691\n",
      "epoch 76; iter: 0; batch classifier loss: 0.354019; batch adversarial loss: 0.564191\n",
      "epoch 77; iter: 0; batch classifier loss: 0.451105; batch adversarial loss: 0.518042\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378654; batch adversarial loss: 0.484243\n",
      "epoch 79; iter: 0; batch classifier loss: 0.331444; batch adversarial loss: 0.517967\n",
      "epoch 80; iter: 0; batch classifier loss: 0.349901; batch adversarial loss: 0.530380\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397973; batch adversarial loss: 0.456278\n",
      "epoch 82; iter: 0; batch classifier loss: 0.438597; batch adversarial loss: 0.615491\n",
      "epoch 83; iter: 0; batch classifier loss: 0.442540; batch adversarial loss: 0.510640\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392826; batch adversarial loss: 0.469447\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428752; batch adversarial loss: 0.555424\n",
      "epoch 86; iter: 0; batch classifier loss: 0.449106; batch adversarial loss: 0.518494\n",
      "epoch 87; iter: 0; batch classifier loss: 0.431395; batch adversarial loss: 0.562684\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363107; batch adversarial loss: 0.531811\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391971; batch adversarial loss: 0.563802\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348063; batch adversarial loss: 0.525666\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412206; batch adversarial loss: 0.491108\n",
      "epoch 92; iter: 0; batch classifier loss: 0.454528; batch adversarial loss: 0.521899\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374125; batch adversarial loss: 0.549444\n",
      "epoch 94; iter: 0; batch classifier loss: 0.428516; batch adversarial loss: 0.590900\n",
      "epoch 95; iter: 0; batch classifier loss: 0.373450; batch adversarial loss: 0.555272\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401200; batch adversarial loss: 0.559322\n",
      "epoch 97; iter: 0; batch classifier loss: 0.464227; batch adversarial loss: 0.571003\n",
      "epoch 98; iter: 0; batch classifier loss: 0.329151; batch adversarial loss: 0.616974\n",
      "epoch 99; iter: 0; batch classifier loss: 0.454003; batch adversarial loss: 0.539896\n",
      "epoch 100; iter: 0; batch classifier loss: 0.464622; batch adversarial loss: 0.529783\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399574; batch adversarial loss: 0.569110\n",
      "epoch 102; iter: 0; batch classifier loss: 0.358248; batch adversarial loss: 0.524047\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372090; batch adversarial loss: 0.576290\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351137; batch adversarial loss: 0.547337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.312616; batch adversarial loss: 0.582751\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395645; batch adversarial loss: 0.449207\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421714; batch adversarial loss: 0.465239\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413968; batch adversarial loss: 0.541654\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383133; batch adversarial loss: 0.526432\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370621; batch adversarial loss: 0.527965\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372809; batch adversarial loss: 0.571850\n",
      "epoch 112; iter: 0; batch classifier loss: 0.352617; batch adversarial loss: 0.496305\n",
      "epoch 113; iter: 0; batch classifier loss: 0.311598; batch adversarial loss: 0.499375\n",
      "epoch 114; iter: 0; batch classifier loss: 0.312937; batch adversarial loss: 0.529808\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358506; batch adversarial loss: 0.517213\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391810; batch adversarial loss: 0.645100\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368255; batch adversarial loss: 0.504357\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358393; batch adversarial loss: 0.557008\n",
      "epoch 119; iter: 0; batch classifier loss: 0.304919; batch adversarial loss: 0.582645\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366044; batch adversarial loss: 0.553784\n",
      "epoch 121; iter: 0; batch classifier loss: 0.300435; batch adversarial loss: 0.537417\n",
      "epoch 122; iter: 0; batch classifier loss: 0.341806; batch adversarial loss: 0.591159\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334729; batch adversarial loss: 0.518872\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379455; batch adversarial loss: 0.550199\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371392; batch adversarial loss: 0.541637\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314190; batch adversarial loss: 0.534167\n",
      "epoch 127; iter: 0; batch classifier loss: 0.423036; batch adversarial loss: 0.561884\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370335; batch adversarial loss: 0.500152\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398787; batch adversarial loss: 0.510340\n",
      "epoch 130; iter: 0; batch classifier loss: 0.306176; batch adversarial loss: 0.586783\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365878; batch adversarial loss: 0.581264\n",
      "epoch 132; iter: 0; batch classifier loss: 0.398419; batch adversarial loss: 0.581018\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370451; batch adversarial loss: 0.507124\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402364; batch adversarial loss: 0.577895\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377537; batch adversarial loss: 0.540086\n",
      "epoch 136; iter: 0; batch classifier loss: 0.299774; batch adversarial loss: 0.500856\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371011; batch adversarial loss: 0.508216\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388936; batch adversarial loss: 0.569838\n",
      "epoch 139; iter: 0; batch classifier loss: 0.405527; batch adversarial loss: 0.535293\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396008; batch adversarial loss: 0.501674\n",
      "epoch 141; iter: 0; batch classifier loss: 0.413048; batch adversarial loss: 0.557001\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361094; batch adversarial loss: 0.558092\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377051; batch adversarial loss: 0.545782\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408724; batch adversarial loss: 0.497750\n",
      "epoch 145; iter: 0; batch classifier loss: 0.313254; batch adversarial loss: 0.561926\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317131; batch adversarial loss: 0.527072\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388302; batch adversarial loss: 0.595258\n",
      "epoch 148; iter: 0; batch classifier loss: 0.441631; batch adversarial loss: 0.569194\n",
      "epoch 149; iter: 0; batch classifier loss: 0.306679; batch adversarial loss: 0.518901\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392724; batch adversarial loss: 0.488103\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365868; batch adversarial loss: 0.571660\n",
      "epoch 152; iter: 0; batch classifier loss: 0.305616; batch adversarial loss: 0.548851\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345874; batch adversarial loss: 0.570205\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351643; batch adversarial loss: 0.608530\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394564; batch adversarial loss: 0.610382\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366749; batch adversarial loss: 0.533776\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367399; batch adversarial loss: 0.542477\n",
      "epoch 158; iter: 0; batch classifier loss: 0.317429; batch adversarial loss: 0.543021\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372882; batch adversarial loss: 0.563016\n",
      "epoch 160; iter: 0; batch classifier loss: 0.327969; batch adversarial loss: 0.551332\n",
      "epoch 161; iter: 0; batch classifier loss: 0.431924; batch adversarial loss: 0.582452\n",
      "epoch 162; iter: 0; batch classifier loss: 0.296525; batch adversarial loss: 0.547956\n",
      "epoch 163; iter: 0; batch classifier loss: 0.474963; batch adversarial loss: 0.599632\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324213; batch adversarial loss: 0.518006\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361196; batch adversarial loss: 0.587419\n",
      "epoch 166; iter: 0; batch classifier loss: 0.392381; batch adversarial loss: 0.545978\n",
      "epoch 167; iter: 0; batch classifier loss: 0.286345; batch adversarial loss: 0.617819\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308671; batch adversarial loss: 0.506546\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376425; batch adversarial loss: 0.551112\n",
      "epoch 170; iter: 0; batch classifier loss: 0.348588; batch adversarial loss: 0.486430\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334546; batch adversarial loss: 0.536516\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364190; batch adversarial loss: 0.537677\n",
      "epoch 173; iter: 0; batch classifier loss: 0.307213; batch adversarial loss: 0.526482\n",
      "epoch 174; iter: 0; batch classifier loss: 0.319254; batch adversarial loss: 0.542539\n",
      "epoch 175; iter: 0; batch classifier loss: 0.394286; batch adversarial loss: 0.451959\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320870; batch adversarial loss: 0.599049\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344915; batch adversarial loss: 0.550002\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343200; batch adversarial loss: 0.506207\n",
      "epoch 179; iter: 0; batch classifier loss: 0.371521; batch adversarial loss: 0.480145\n",
      "epoch 180; iter: 0; batch classifier loss: 0.278618; batch adversarial loss: 0.489294\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333703; batch adversarial loss: 0.615273\n",
      "epoch 182; iter: 0; batch classifier loss: 0.360685; batch adversarial loss: 0.516625\n",
      "epoch 183; iter: 0; batch classifier loss: 0.479294; batch adversarial loss: 0.556801\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360113; batch adversarial loss: 0.587163\n",
      "epoch 185; iter: 0; batch classifier loss: 0.400509; batch adversarial loss: 0.562687\n",
      "epoch 186; iter: 0; batch classifier loss: 0.411460; batch adversarial loss: 0.479916\n",
      "epoch 187; iter: 0; batch classifier loss: 0.401762; batch adversarial loss: 0.629501\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379699; batch adversarial loss: 0.572832\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362526; batch adversarial loss: 0.533687\n",
      "epoch 190; iter: 0; batch classifier loss: 0.286060; batch adversarial loss: 0.456378\n",
      "epoch 191; iter: 0; batch classifier loss: 0.343511; batch adversarial loss: 0.559907\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317883; batch adversarial loss: 0.536981\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389917; batch adversarial loss: 0.461623\n",
      "epoch 194; iter: 0; batch classifier loss: 0.411642; batch adversarial loss: 0.449162\n",
      "epoch 195; iter: 0; batch classifier loss: 0.386456; batch adversarial loss: 0.600165\n",
      "epoch 196; iter: 0; batch classifier loss: 0.348190; batch adversarial loss: 0.473187\n",
      "epoch 197; iter: 0; batch classifier loss: 0.476554; batch adversarial loss: 0.583758\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366957; batch adversarial loss: 0.479405\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348117; batch adversarial loss: 0.472770\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714928; batch adversarial loss: 0.535633\n",
      "epoch 1; iter: 0; batch classifier loss: 0.661284; batch adversarial loss: 0.659147\n",
      "epoch 2; iter: 0; batch classifier loss: 0.619972; batch adversarial loss: 0.659745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.610929; batch adversarial loss: 0.682759\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582964; batch adversarial loss: 0.647060\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600697; batch adversarial loss: 0.618661\n",
      "epoch 6; iter: 0; batch classifier loss: 0.660242; batch adversarial loss: 0.618147\n",
      "epoch 7; iter: 0; batch classifier loss: 0.540730; batch adversarial loss: 0.605464\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525650; batch adversarial loss: 0.599094\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523129; batch adversarial loss: 0.638208\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544797; batch adversarial loss: 0.609270\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511368; batch adversarial loss: 0.567764\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555210; batch adversarial loss: 0.534845\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503370; batch adversarial loss: 0.565071\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524447; batch adversarial loss: 0.631065\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544908; batch adversarial loss: 0.590904\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477807; batch adversarial loss: 0.574111\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529853; batch adversarial loss: 0.592705\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492973; batch adversarial loss: 0.527272\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459717; batch adversarial loss: 0.540757\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482934; batch adversarial loss: 0.514711\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486756; batch adversarial loss: 0.552175\n",
      "epoch 22; iter: 0; batch classifier loss: 0.405920; batch adversarial loss: 0.529218\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451567; batch adversarial loss: 0.503683\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434903; batch adversarial loss: 0.630254\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508743; batch adversarial loss: 0.594443\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440617; batch adversarial loss: 0.475932\n",
      "epoch 27; iter: 0; batch classifier loss: 0.391538; batch adversarial loss: 0.571389\n",
      "epoch 28; iter: 0; batch classifier loss: 0.534325; batch adversarial loss: 0.565570\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432142; batch adversarial loss: 0.599592\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479032; batch adversarial loss: 0.524446\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486505; batch adversarial loss: 0.551330\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474048; batch adversarial loss: 0.542046\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409908; batch adversarial loss: 0.614400\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461970; batch adversarial loss: 0.557667\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456770; batch adversarial loss: 0.569228\n",
      "epoch 36; iter: 0; batch classifier loss: 0.417082; batch adversarial loss: 0.625307\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445534; batch adversarial loss: 0.558439\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469083; batch adversarial loss: 0.544136\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415499; batch adversarial loss: 0.482398\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391252; batch adversarial loss: 0.632314\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475996; batch adversarial loss: 0.622793\n",
      "epoch 42; iter: 0; batch classifier loss: 0.518776; batch adversarial loss: 0.571830\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437393; batch adversarial loss: 0.585817\n",
      "epoch 44; iter: 0; batch classifier loss: 0.449308; batch adversarial loss: 0.570179\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477770; batch adversarial loss: 0.490268\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381648; batch adversarial loss: 0.588097\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424810; batch adversarial loss: 0.527099\n",
      "epoch 48; iter: 0; batch classifier loss: 0.390925; batch adversarial loss: 0.593828\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408071; batch adversarial loss: 0.506809\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430654; batch adversarial loss: 0.543961\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470487; batch adversarial loss: 0.572574\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392129; batch adversarial loss: 0.562249\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458272; batch adversarial loss: 0.553944\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423373; batch adversarial loss: 0.440859\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430275; batch adversarial loss: 0.484018\n",
      "epoch 56; iter: 0; batch classifier loss: 0.521593; batch adversarial loss: 0.535396\n",
      "epoch 57; iter: 0; batch classifier loss: 0.482738; batch adversarial loss: 0.597257\n",
      "epoch 58; iter: 0; batch classifier loss: 0.355193; batch adversarial loss: 0.588430\n",
      "epoch 59; iter: 0; batch classifier loss: 0.345947; batch adversarial loss: 0.454510\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425169; batch adversarial loss: 0.598010\n",
      "epoch 61; iter: 0; batch classifier loss: 0.343801; batch adversarial loss: 0.615449\n",
      "epoch 62; iter: 0; batch classifier loss: 0.404901; batch adversarial loss: 0.555107\n",
      "epoch 63; iter: 0; batch classifier loss: 0.364566; batch adversarial loss: 0.571939\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397033; batch adversarial loss: 0.552796\n",
      "epoch 65; iter: 0; batch classifier loss: 0.392295; batch adversarial loss: 0.499816\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439832; batch adversarial loss: 0.515487\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416940; batch adversarial loss: 0.670576\n",
      "epoch 68; iter: 0; batch classifier loss: 0.452384; batch adversarial loss: 0.543907\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406664; batch adversarial loss: 0.499487\n",
      "epoch 70; iter: 0; batch classifier loss: 0.373556; batch adversarial loss: 0.626576\n",
      "epoch 71; iter: 0; batch classifier loss: 0.313141; batch adversarial loss: 0.535412\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392279; batch adversarial loss: 0.517205\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427764; batch adversarial loss: 0.516577\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388033; batch adversarial loss: 0.599969\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412182; batch adversarial loss: 0.554812\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379566; batch adversarial loss: 0.635958\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434854; batch adversarial loss: 0.600607\n",
      "epoch 78; iter: 0; batch classifier loss: 0.440014; batch adversarial loss: 0.544796\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359962; batch adversarial loss: 0.516737\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401814; batch adversarial loss: 0.589738\n",
      "epoch 81; iter: 0; batch classifier loss: 0.462299; batch adversarial loss: 0.598350\n",
      "epoch 82; iter: 0; batch classifier loss: 0.452781; batch adversarial loss: 0.508491\n",
      "epoch 83; iter: 0; batch classifier loss: 0.389512; batch adversarial loss: 0.525975\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382416; batch adversarial loss: 0.516046\n",
      "epoch 85; iter: 0; batch classifier loss: 0.368388; batch adversarial loss: 0.499828\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427255; batch adversarial loss: 0.670958\n",
      "epoch 87; iter: 0; batch classifier loss: 0.481793; batch adversarial loss: 0.526193\n",
      "epoch 88; iter: 0; batch classifier loss: 0.487895; batch adversarial loss: 0.499919\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367999; batch adversarial loss: 0.535459\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381991; batch adversarial loss: 0.554174\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417003; batch adversarial loss: 0.526151\n",
      "epoch 92; iter: 0; batch classifier loss: 0.446007; batch adversarial loss: 0.462885\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374926; batch adversarial loss: 0.580470\n",
      "epoch 94; iter: 0; batch classifier loss: 0.338094; batch adversarial loss: 0.579742\n",
      "epoch 95; iter: 0; batch classifier loss: 0.433949; batch adversarial loss: 0.517729\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430780; batch adversarial loss: 0.562249\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397353; batch adversarial loss: 0.544216\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369793; batch adversarial loss: 0.452604\n",
      "epoch 99; iter: 0; batch classifier loss: 0.349692; batch adversarial loss: 0.578638\n",
      "epoch 100; iter: 0; batch classifier loss: 0.378842; batch adversarial loss: 0.506424\n",
      "epoch 101; iter: 0; batch classifier loss: 0.445159; batch adversarial loss: 0.616867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.427736; batch adversarial loss: 0.591146\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365817; batch adversarial loss: 0.538525\n",
      "epoch 104; iter: 0; batch classifier loss: 0.431217; batch adversarial loss: 0.552768\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373377; batch adversarial loss: 0.518712\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432441; batch adversarial loss: 0.509110\n",
      "epoch 107; iter: 0; batch classifier loss: 0.318666; batch adversarial loss: 0.518273\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366485; batch adversarial loss: 0.597966\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344315; batch adversarial loss: 0.509076\n",
      "epoch 110; iter: 0; batch classifier loss: 0.376518; batch adversarial loss: 0.652746\n",
      "epoch 111; iter: 0; batch classifier loss: 0.377991; batch adversarial loss: 0.563189\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385738; batch adversarial loss: 0.507939\n",
      "epoch 113; iter: 0; batch classifier loss: 0.339456; batch adversarial loss: 0.443372\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366572; batch adversarial loss: 0.635634\n",
      "epoch 115; iter: 0; batch classifier loss: 0.344616; batch adversarial loss: 0.478428\n",
      "epoch 116; iter: 0; batch classifier loss: 0.455802; batch adversarial loss: 0.543568\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370954; batch adversarial loss: 0.557994\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390127; batch adversarial loss: 0.570794\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342506; batch adversarial loss: 0.634760\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330204; batch adversarial loss: 0.553088\n",
      "epoch 121; iter: 0; batch classifier loss: 0.441969; batch adversarial loss: 0.569142\n",
      "epoch 122; iter: 0; batch classifier loss: 0.319480; batch adversarial loss: 0.506873\n",
      "epoch 123; iter: 0; batch classifier loss: 0.361053; batch adversarial loss: 0.544473\n",
      "epoch 124; iter: 0; batch classifier loss: 0.509331; batch adversarial loss: 0.625840\n",
      "epoch 125; iter: 0; batch classifier loss: 0.430511; batch adversarial loss: 0.555576\n",
      "epoch 126; iter: 0; batch classifier loss: 0.416021; batch adversarial loss: 0.599028\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408803; batch adversarial loss: 0.507426\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365639; batch adversarial loss: 0.494688\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378997; batch adversarial loss: 0.500178\n",
      "epoch 130; iter: 0; batch classifier loss: 0.462373; batch adversarial loss: 0.580901\n",
      "epoch 131; iter: 0; batch classifier loss: 0.437061; batch adversarial loss: 0.480612\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360291; batch adversarial loss: 0.472857\n",
      "epoch 133; iter: 0; batch classifier loss: 0.428685; batch adversarial loss: 0.623313\n",
      "epoch 134; iter: 0; batch classifier loss: 0.419078; batch adversarial loss: 0.571192\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361258; batch adversarial loss: 0.526465\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339196; batch adversarial loss: 0.537598\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403118; batch adversarial loss: 0.454477\n",
      "epoch 138; iter: 0; batch classifier loss: 0.336729; batch adversarial loss: 0.553718\n",
      "epoch 139; iter: 0; batch classifier loss: 0.317312; batch adversarial loss: 0.590923\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405572; batch adversarial loss: 0.627485\n",
      "epoch 141; iter: 0; batch classifier loss: 0.424581; batch adversarial loss: 0.595992\n",
      "epoch 142; iter: 0; batch classifier loss: 0.435740; batch adversarial loss: 0.493220\n",
      "epoch 143; iter: 0; batch classifier loss: 0.288606; batch adversarial loss: 0.506834\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396967; batch adversarial loss: 0.536082\n",
      "epoch 145; iter: 0; batch classifier loss: 0.326131; batch adversarial loss: 0.580887\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371719; batch adversarial loss: 0.591585\n",
      "epoch 147; iter: 0; batch classifier loss: 0.414858; batch adversarial loss: 0.508523\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392473; batch adversarial loss: 0.517727\n",
      "epoch 149; iter: 0; batch classifier loss: 0.356557; batch adversarial loss: 0.615479\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421045; batch adversarial loss: 0.561315\n",
      "epoch 151; iter: 0; batch classifier loss: 0.421367; batch adversarial loss: 0.554930\n",
      "epoch 152; iter: 0; batch classifier loss: 0.321034; batch adversarial loss: 0.545069\n",
      "epoch 153; iter: 0; batch classifier loss: 0.437253; batch adversarial loss: 0.545427\n",
      "epoch 154; iter: 0; batch classifier loss: 0.406225; batch adversarial loss: 0.591996\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379368; batch adversarial loss: 0.560630\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366274; batch adversarial loss: 0.542247\n",
      "epoch 157; iter: 0; batch classifier loss: 0.358240; batch adversarial loss: 0.463796\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343832; batch adversarial loss: 0.508846\n",
      "epoch 159; iter: 0; batch classifier loss: 0.310191; batch adversarial loss: 0.607526\n",
      "epoch 160; iter: 0; batch classifier loss: 0.396485; batch adversarial loss: 0.544292\n",
      "epoch 161; iter: 0; batch classifier loss: 0.444691; batch adversarial loss: 0.534658\n",
      "epoch 162; iter: 0; batch classifier loss: 0.389324; batch adversarial loss: 0.508283\n",
      "epoch 163; iter: 0; batch classifier loss: 0.372658; batch adversarial loss: 0.561204\n",
      "epoch 164; iter: 0; batch classifier loss: 0.421811; batch adversarial loss: 0.607671\n",
      "epoch 165; iter: 0; batch classifier loss: 0.313635; batch adversarial loss: 0.509998\n",
      "epoch 166; iter: 0; batch classifier loss: 0.390629; batch adversarial loss: 0.527373\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401919; batch adversarial loss: 0.606070\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359097; batch adversarial loss: 0.617296\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371778; batch adversarial loss: 0.668218\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393644; batch adversarial loss: 0.518310\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355834; batch adversarial loss: 0.580084\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376862; batch adversarial loss: 0.464320\n",
      "epoch 173; iter: 0; batch classifier loss: 0.500034; batch adversarial loss: 0.508253\n",
      "epoch 174; iter: 0; batch classifier loss: 0.478230; batch adversarial loss: 0.481369\n",
      "epoch 175; iter: 0; batch classifier loss: 0.435633; batch adversarial loss: 0.571376\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400160; batch adversarial loss: 0.571701\n",
      "epoch 177; iter: 0; batch classifier loss: 0.471723; batch adversarial loss: 0.454465\n",
      "epoch 178; iter: 0; batch classifier loss: 0.446266; batch adversarial loss: 0.571906\n",
      "epoch 179; iter: 0; batch classifier loss: 0.301684; batch adversarial loss: 0.652262\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374421; batch adversarial loss: 0.526801\n",
      "epoch 181; iter: 0; batch classifier loss: 0.399805; batch adversarial loss: 0.535814\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383869; batch adversarial loss: 0.481499\n",
      "epoch 183; iter: 0; batch classifier loss: 0.409993; batch adversarial loss: 0.517540\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355867; batch adversarial loss: 0.598654\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281075; batch adversarial loss: 0.616461\n",
      "epoch 186; iter: 0; batch classifier loss: 0.388973; batch adversarial loss: 0.535574\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359979; batch adversarial loss: 0.517623\n",
      "epoch 188; iter: 0; batch classifier loss: 0.440883; batch adversarial loss: 0.607880\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356857; batch adversarial loss: 0.526343\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346654; batch adversarial loss: 0.544697\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324521; batch adversarial loss: 0.571707\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342646; batch adversarial loss: 0.553595\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361236; batch adversarial loss: 0.571791\n",
      "epoch 194; iter: 0; batch classifier loss: 0.291866; batch adversarial loss: 0.535494\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359323; batch adversarial loss: 0.544785\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360115; batch adversarial loss: 0.535546\n",
      "epoch 197; iter: 0; batch classifier loss: 0.407186; batch adversarial loss: 0.535494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.357970; batch adversarial loss: 0.625997\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374421; batch adversarial loss: 0.517646\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681710; batch adversarial loss: 0.554012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608979; batch adversarial loss: 0.660235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.566390; batch adversarial loss: 0.617494\n",
      "epoch 3; iter: 0; batch classifier loss: 0.642718; batch adversarial loss: 0.657726\n",
      "epoch 4; iter: 0; batch classifier loss: 0.522469; batch adversarial loss: 0.665702\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559457; batch adversarial loss: 0.652869\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497732; batch adversarial loss: 0.640504\n",
      "epoch 7; iter: 0; batch classifier loss: 0.677934; batch adversarial loss: 0.587259\n",
      "epoch 8; iter: 0; batch classifier loss: 0.652810; batch adversarial loss: 0.614870\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541189; batch adversarial loss: 0.627048\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536506; batch adversarial loss: 0.628300\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586022; batch adversarial loss: 0.589032\n",
      "epoch 12; iter: 0; batch classifier loss: 0.616202; batch adversarial loss: 0.589068\n",
      "epoch 13; iter: 0; batch classifier loss: 0.469390; batch adversarial loss: 0.560165\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552173; batch adversarial loss: 0.565267\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566422; batch adversarial loss: 0.501116\n",
      "epoch 16; iter: 0; batch classifier loss: 0.548104; batch adversarial loss: 0.545407\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503794; batch adversarial loss: 0.579981\n",
      "epoch 18; iter: 0; batch classifier loss: 0.584098; batch adversarial loss: 0.583081\n",
      "epoch 19; iter: 0; batch classifier loss: 0.467534; batch adversarial loss: 0.587699\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429838; batch adversarial loss: 0.549035\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489570; batch adversarial loss: 0.570163\n",
      "epoch 22; iter: 0; batch classifier loss: 0.548775; batch adversarial loss: 0.530944\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511753; batch adversarial loss: 0.530365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.417647; batch adversarial loss: 0.532108\n",
      "epoch 25; iter: 0; batch classifier loss: 0.562146; batch adversarial loss: 0.551864\n",
      "epoch 26; iter: 0; batch classifier loss: 0.533577; batch adversarial loss: 0.565325\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478952; batch adversarial loss: 0.575452\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494520; batch adversarial loss: 0.573129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462438; batch adversarial loss: 0.532911\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434385; batch adversarial loss: 0.553498\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494189; batch adversarial loss: 0.564287\n",
      "epoch 32; iter: 0; batch classifier loss: 0.576318; batch adversarial loss: 0.470329\n",
      "epoch 33; iter: 0; batch classifier loss: 0.496521; batch adversarial loss: 0.548603\n",
      "epoch 34; iter: 0; batch classifier loss: 0.389443; batch adversarial loss: 0.559507\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455371; batch adversarial loss: 0.561344\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458065; batch adversarial loss: 0.583318\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476160; batch adversarial loss: 0.552792\n",
      "epoch 38; iter: 0; batch classifier loss: 0.502099; batch adversarial loss: 0.570311\n",
      "epoch 39; iter: 0; batch classifier loss: 0.383179; batch adversarial loss: 0.554060\n",
      "epoch 40; iter: 0; batch classifier loss: 0.478590; batch adversarial loss: 0.569064\n",
      "epoch 41; iter: 0; batch classifier loss: 0.513630; batch adversarial loss: 0.625650\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393965; batch adversarial loss: 0.545402\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493782; batch adversarial loss: 0.553004\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397986; batch adversarial loss: 0.563259\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463573; batch adversarial loss: 0.509787\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474594; batch adversarial loss: 0.527145\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469078; batch adversarial loss: 0.526736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483377; batch adversarial loss: 0.491596\n",
      "epoch 49; iter: 0; batch classifier loss: 0.494375; batch adversarial loss: 0.535236\n",
      "epoch 50; iter: 0; batch classifier loss: 0.501194; batch adversarial loss: 0.624745\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400799; batch adversarial loss: 0.535424\n",
      "epoch 52; iter: 0; batch classifier loss: 0.478995; batch adversarial loss: 0.572288\n",
      "epoch 53; iter: 0; batch classifier loss: 0.387809; batch adversarial loss: 0.535008\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392991; batch adversarial loss: 0.561738\n",
      "epoch 55; iter: 0; batch classifier loss: 0.320586; batch adversarial loss: 0.560890\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435803; batch adversarial loss: 0.571460\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427607; batch adversarial loss: 0.581607\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435470; batch adversarial loss: 0.470582\n",
      "epoch 59; iter: 0; batch classifier loss: 0.448332; batch adversarial loss: 0.591784\n",
      "epoch 60; iter: 0; batch classifier loss: 0.408011; batch adversarial loss: 0.534120\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409814; batch adversarial loss: 0.600183\n",
      "epoch 62; iter: 0; batch classifier loss: 0.529594; batch adversarial loss: 0.498648\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433833; batch adversarial loss: 0.572895\n",
      "epoch 64; iter: 0; batch classifier loss: 0.374551; batch adversarial loss: 0.599604\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442450; batch adversarial loss: 0.581294\n",
      "epoch 66; iter: 0; batch classifier loss: 0.484815; batch adversarial loss: 0.544964\n",
      "epoch 67; iter: 0; batch classifier loss: 0.350393; batch adversarial loss: 0.453174\n",
      "epoch 68; iter: 0; batch classifier loss: 0.452335; batch adversarial loss: 0.516677\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407061; batch adversarial loss: 0.489628\n",
      "epoch 70; iter: 0; batch classifier loss: 0.516491; batch adversarial loss: 0.579640\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409879; batch adversarial loss: 0.526013\n",
      "epoch 72; iter: 0; batch classifier loss: 0.484325; batch adversarial loss: 0.490326\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409981; batch adversarial loss: 0.517152\n",
      "epoch 74; iter: 0; batch classifier loss: 0.353277; batch adversarial loss: 0.562312\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457798; batch adversarial loss: 0.534802\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459365; batch adversarial loss: 0.499612\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419227; batch adversarial loss: 0.453756\n",
      "epoch 78; iter: 0; batch classifier loss: 0.490012; batch adversarial loss: 0.544474\n",
      "epoch 79; iter: 0; batch classifier loss: 0.522573; batch adversarial loss: 0.635827\n",
      "epoch 80; iter: 0; batch classifier loss: 0.388912; batch adversarial loss: 0.581469\n",
      "epoch 81; iter: 0; batch classifier loss: 0.372056; batch adversarial loss: 0.535303\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403644; batch adversarial loss: 0.452463\n",
      "epoch 83; iter: 0; batch classifier loss: 0.427221; batch adversarial loss: 0.508068\n",
      "epoch 84; iter: 0; batch classifier loss: 0.347546; batch adversarial loss: 0.581608\n",
      "epoch 85; iter: 0; batch classifier loss: 0.468744; batch adversarial loss: 0.645783\n",
      "epoch 86; iter: 0; batch classifier loss: 0.456954; batch adversarial loss: 0.517133\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363047; batch adversarial loss: 0.526027\n",
      "epoch 88; iter: 0; batch classifier loss: 0.518177; batch adversarial loss: 0.544435\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381457; batch adversarial loss: 0.572022\n",
      "epoch 90; iter: 0; batch classifier loss: 0.349327; batch adversarial loss: 0.535173\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348135; batch adversarial loss: 0.626968\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424844; batch adversarial loss: 0.598898\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367772; batch adversarial loss: 0.516310\n",
      "epoch 94; iter: 0; batch classifier loss: 0.445799; batch adversarial loss: 0.499195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.467114; batch adversarial loss: 0.607788\n",
      "epoch 96; iter: 0; batch classifier loss: 0.409791; batch adversarial loss: 0.571867\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436979; batch adversarial loss: 0.598827\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396362; batch adversarial loss: 0.499652\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409356; batch adversarial loss: 0.561745\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382884; batch adversarial loss: 0.580724\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366875; batch adversarial loss: 0.499894\n",
      "epoch 102; iter: 0; batch classifier loss: 0.484119; batch adversarial loss: 0.553551\n",
      "epoch 103; iter: 0; batch classifier loss: 0.368862; batch adversarial loss: 0.543265\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415603; batch adversarial loss: 0.490516\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371342; batch adversarial loss: 0.597762\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378852; batch adversarial loss: 0.490102\n",
      "epoch 107; iter: 0; batch classifier loss: 0.345028; batch adversarial loss: 0.581573\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406603; batch adversarial loss: 0.526045\n",
      "epoch 109; iter: 0; batch classifier loss: 0.481094; batch adversarial loss: 0.498213\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397358; batch adversarial loss: 0.498233\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398183; batch adversarial loss: 0.489184\n",
      "epoch 112; iter: 0; batch classifier loss: 0.319110; batch adversarial loss: 0.544498\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389617; batch adversarial loss: 0.526252\n",
      "epoch 114; iter: 0; batch classifier loss: 0.484731; batch adversarial loss: 0.552678\n",
      "epoch 115; iter: 0; batch classifier loss: 0.486638; batch adversarial loss: 0.543881\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410611; batch adversarial loss: 0.559984\n",
      "epoch 117; iter: 0; batch classifier loss: 0.428579; batch adversarial loss: 0.625416\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417400; batch adversarial loss: 0.554242\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369760; batch adversarial loss: 0.523484\n",
      "epoch 120; iter: 0; batch classifier loss: 0.423633; batch adversarial loss: 0.535728\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387640; batch adversarial loss: 0.591036\n",
      "epoch 122; iter: 0; batch classifier loss: 0.432705; batch adversarial loss: 0.553197\n",
      "epoch 123; iter: 0; batch classifier loss: 0.312319; batch adversarial loss: 0.427716\n",
      "epoch 124; iter: 0; batch classifier loss: 0.414842; batch adversarial loss: 0.517346\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393691; batch adversarial loss: 0.537163\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323846; batch adversarial loss: 0.525943\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388787; batch adversarial loss: 0.535692\n",
      "epoch 128; iter: 0; batch classifier loss: 0.424644; batch adversarial loss: 0.582710\n",
      "epoch 129; iter: 0; batch classifier loss: 0.474080; batch adversarial loss: 0.517611\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348497; batch adversarial loss: 0.517878\n",
      "epoch 131; iter: 0; batch classifier loss: 0.413875; batch adversarial loss: 0.526255\n",
      "epoch 132; iter: 0; batch classifier loss: 0.429030; batch adversarial loss: 0.488972\n",
      "epoch 133; iter: 0; batch classifier loss: 0.360667; batch adversarial loss: 0.572128\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358121; batch adversarial loss: 0.462924\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364836; batch adversarial loss: 0.472428\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346404; batch adversarial loss: 0.462909\n",
      "epoch 137; iter: 0; batch classifier loss: 0.391183; batch adversarial loss: 0.627018\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363493; batch adversarial loss: 0.508522\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372281; batch adversarial loss: 0.569844\n",
      "epoch 140; iter: 0; batch classifier loss: 0.435889; batch adversarial loss: 0.563071\n",
      "epoch 141; iter: 0; batch classifier loss: 0.388323; batch adversarial loss: 0.590087\n",
      "epoch 142; iter: 0; batch classifier loss: 0.366932; batch adversarial loss: 0.562774\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359771; batch adversarial loss: 0.517653\n",
      "epoch 144; iter: 0; batch classifier loss: 0.442633; batch adversarial loss: 0.545160\n",
      "epoch 145; iter: 0; batch classifier loss: 0.357790; batch adversarial loss: 0.552969\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347180; batch adversarial loss: 0.589816\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383073; batch adversarial loss: 0.618320\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371728; batch adversarial loss: 0.517322\n",
      "epoch 149; iter: 0; batch classifier loss: 0.332171; batch adversarial loss: 0.535701\n",
      "epoch 150; iter: 0; batch classifier loss: 0.366828; batch adversarial loss: 0.572459\n",
      "epoch 151; iter: 0; batch classifier loss: 0.406189; batch adversarial loss: 0.535718\n",
      "epoch 152; iter: 0; batch classifier loss: 0.302910; batch adversarial loss: 0.516717\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352000; batch adversarial loss: 0.607967\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348876; batch adversarial loss: 0.508372\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325557; batch adversarial loss: 0.507999\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401705; batch adversarial loss: 0.535402\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341459; batch adversarial loss: 0.571918\n",
      "epoch 158; iter: 0; batch classifier loss: 0.438173; batch adversarial loss: 0.516964\n",
      "epoch 159; iter: 0; batch classifier loss: 0.340372; batch adversarial loss: 0.580993\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335839; batch adversarial loss: 0.553744\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387188; batch adversarial loss: 0.553740\n",
      "epoch 162; iter: 0; batch classifier loss: 0.435189; batch adversarial loss: 0.516853\n",
      "epoch 163; iter: 0; batch classifier loss: 0.357449; batch adversarial loss: 0.581276\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380424; batch adversarial loss: 0.489867\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362405; batch adversarial loss: 0.517272\n",
      "epoch 166; iter: 0; batch classifier loss: 0.437095; batch adversarial loss: 0.590139\n",
      "epoch 167; iter: 0; batch classifier loss: 0.316387; batch adversarial loss: 0.553560\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361527; batch adversarial loss: 0.499144\n",
      "epoch 169; iter: 0; batch classifier loss: 0.437618; batch adversarial loss: 0.580984\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385746; batch adversarial loss: 0.480864\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392669; batch adversarial loss: 0.526241\n",
      "epoch 172; iter: 0; batch classifier loss: 0.348376; batch adversarial loss: 0.480473\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363812; batch adversarial loss: 0.526315\n",
      "epoch 174; iter: 0; batch classifier loss: 0.342965; batch adversarial loss: 0.617676\n",
      "epoch 175; iter: 0; batch classifier loss: 0.404976; batch adversarial loss: 0.544552\n",
      "epoch 176; iter: 0; batch classifier loss: 0.515008; batch adversarial loss: 0.617655\n",
      "epoch 177; iter: 0; batch classifier loss: 0.341785; batch adversarial loss: 0.544423\n",
      "epoch 178; iter: 0; batch classifier loss: 0.418921; batch adversarial loss: 0.516902\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346171; batch adversarial loss: 0.553842\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392703; batch adversarial loss: 0.553308\n",
      "epoch 181; iter: 0; batch classifier loss: 0.390742; batch adversarial loss: 0.571935\n",
      "epoch 182; iter: 0; batch classifier loss: 0.444794; batch adversarial loss: 0.571537\n",
      "epoch 183; iter: 0; batch classifier loss: 0.364555; batch adversarial loss: 0.526015\n",
      "epoch 184; iter: 0; batch classifier loss: 0.414478; batch adversarial loss: 0.635810\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357931; batch adversarial loss: 0.544480\n",
      "epoch 186; iter: 0; batch classifier loss: 0.372559; batch adversarial loss: 0.544306\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341466; batch adversarial loss: 0.526300\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373755; batch adversarial loss: 0.434714\n",
      "epoch 189; iter: 0; batch classifier loss: 0.515442; batch adversarial loss: 0.571590\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346568; batch adversarial loss: 0.544477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.311177; batch adversarial loss: 0.517091\n",
      "epoch 192; iter: 0; batch classifier loss: 0.341622; batch adversarial loss: 0.553845\n",
      "epoch 193; iter: 0; batch classifier loss: 0.453978; batch adversarial loss: 0.571857\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316092; batch adversarial loss: 0.535749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.402267; batch adversarial loss: 0.526509\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343716; batch adversarial loss: 0.580616\n",
      "epoch 197; iter: 0; batch classifier loss: 0.310923; batch adversarial loss: 0.544784\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321011; batch adversarial loss: 0.599318\n",
      "epoch 199; iter: 0; batch classifier loss: 0.445541; batch adversarial loss: 0.535586\n",
      "epoch 0; iter: 0; batch classifier loss: 0.776328; batch adversarial loss: 0.576371\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630438; batch adversarial loss: 0.665878\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578180; batch adversarial loss: 0.673957\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541212; batch adversarial loss: 0.615234\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579394; batch adversarial loss: 0.614854\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496547; batch adversarial loss: 0.574549\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583701; batch adversarial loss: 0.579429\n",
      "epoch 7; iter: 0; batch classifier loss: 0.560116; batch adversarial loss: 0.588961\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550437; batch adversarial loss: 0.619644\n",
      "epoch 9; iter: 0; batch classifier loss: 0.596364; batch adversarial loss: 0.549934\n",
      "epoch 10; iter: 0; batch classifier loss: 0.534240; batch adversarial loss: 0.597799\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567015; batch adversarial loss: 0.584560\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491048; batch adversarial loss: 0.525291\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508784; batch adversarial loss: 0.605587\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500749; batch adversarial loss: 0.588146\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522971; batch adversarial loss: 0.567256\n",
      "epoch 16; iter: 0; batch classifier loss: 0.437589; batch adversarial loss: 0.548363\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511939; batch adversarial loss: 0.613516\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533401; batch adversarial loss: 0.579254\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480007; batch adversarial loss: 0.518267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485933; batch adversarial loss: 0.632102\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543678; batch adversarial loss: 0.495636\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465771; batch adversarial loss: 0.528035\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506702; batch adversarial loss: 0.567999\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494875; batch adversarial loss: 0.583386\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491780; batch adversarial loss: 0.562206\n",
      "epoch 26; iter: 0; batch classifier loss: 0.516421; batch adversarial loss: 0.518155\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487584; batch adversarial loss: 0.551076\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435437; batch adversarial loss: 0.540957\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452050; batch adversarial loss: 0.546901\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454477; batch adversarial loss: 0.541569\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467216; batch adversarial loss: 0.564552\n",
      "epoch 32; iter: 0; batch classifier loss: 0.394343; batch adversarial loss: 0.589085\n",
      "epoch 33; iter: 0; batch classifier loss: 0.449130; batch adversarial loss: 0.509484\n",
      "epoch 34; iter: 0; batch classifier loss: 0.391896; batch adversarial loss: 0.574502\n",
      "epoch 35; iter: 0; batch classifier loss: 0.503584; batch adversarial loss: 0.516384\n",
      "epoch 36; iter: 0; batch classifier loss: 0.416783; batch adversarial loss: 0.596365\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467040; batch adversarial loss: 0.508939\n",
      "epoch 38; iter: 0; batch classifier loss: 0.510228; batch adversarial loss: 0.572848\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418825; batch adversarial loss: 0.696901\n",
      "epoch 40; iter: 0; batch classifier loss: 0.427637; batch adversarial loss: 0.491226\n",
      "epoch 41; iter: 0; batch classifier loss: 0.522085; batch adversarial loss: 0.590413\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469074; batch adversarial loss: 0.553927\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493691; batch adversarial loss: 0.581551\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407957; batch adversarial loss: 0.534959\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443712; batch adversarial loss: 0.579764\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408633; batch adversarial loss: 0.635044\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418582; batch adversarial loss: 0.626637\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443352; batch adversarial loss: 0.598195\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393176; batch adversarial loss: 0.536725\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423207; batch adversarial loss: 0.517757\n",
      "epoch 51; iter: 0; batch classifier loss: 0.369199; batch adversarial loss: 0.526685\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415958; batch adversarial loss: 0.525459\n",
      "epoch 53; iter: 0; batch classifier loss: 0.503948; batch adversarial loss: 0.553541\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452187; batch adversarial loss: 0.535424\n",
      "epoch 55; iter: 0; batch classifier loss: 0.489766; batch adversarial loss: 0.516866\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411716; batch adversarial loss: 0.598988\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416241; batch adversarial loss: 0.545122\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469591; batch adversarial loss: 0.554138\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369038; batch adversarial loss: 0.597771\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427956; batch adversarial loss: 0.553349\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412958; batch adversarial loss: 0.491426\n",
      "epoch 62; iter: 0; batch classifier loss: 0.460131; batch adversarial loss: 0.517805\n",
      "epoch 63; iter: 0; batch classifier loss: 0.389967; batch adversarial loss: 0.508483\n",
      "epoch 64; iter: 0; batch classifier loss: 0.332987; batch adversarial loss: 0.553496\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381719; batch adversarial loss: 0.535836\n",
      "epoch 66; iter: 0; batch classifier loss: 0.503690; batch adversarial loss: 0.617680\n",
      "epoch 67; iter: 0; batch classifier loss: 0.446454; batch adversarial loss: 0.498067\n",
      "epoch 68; iter: 0; batch classifier loss: 0.477721; batch adversarial loss: 0.598093\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433582; batch adversarial loss: 0.503862\n",
      "epoch 70; iter: 0; batch classifier loss: 0.441205; batch adversarial loss: 0.587139\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431362; batch adversarial loss: 0.570061\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429757; batch adversarial loss: 0.459931\n",
      "epoch 73; iter: 0; batch classifier loss: 0.365495; batch adversarial loss: 0.551368\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382219; batch adversarial loss: 0.598852\n",
      "epoch 75; iter: 0; batch classifier loss: 0.471077; batch adversarial loss: 0.494417\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422911; batch adversarial loss: 0.524053\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400840; batch adversarial loss: 0.482102\n",
      "epoch 78; iter: 0; batch classifier loss: 0.419607; batch adversarial loss: 0.566155\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413744; batch adversarial loss: 0.590687\n",
      "epoch 80; iter: 0; batch classifier loss: 0.400759; batch adversarial loss: 0.580455\n",
      "epoch 81; iter: 0; batch classifier loss: 0.372696; batch adversarial loss: 0.573067\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435472; batch adversarial loss: 0.641263\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386176; batch adversarial loss: 0.615199\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371539; batch adversarial loss: 0.527027\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391688; batch adversarial loss: 0.543520\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397591; batch adversarial loss: 0.553334\n",
      "epoch 87; iter: 0; batch classifier loss: 0.464577; batch adversarial loss: 0.579997\n",
      "epoch 88; iter: 0; batch classifier loss: 0.449824; batch adversarial loss: 0.532925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.431832; batch adversarial loss: 0.490958\n",
      "epoch 90; iter: 0; batch classifier loss: 0.439295; batch adversarial loss: 0.610121\n",
      "epoch 91; iter: 0; batch classifier loss: 0.450770; batch adversarial loss: 0.579184\n",
      "epoch 92; iter: 0; batch classifier loss: 0.465269; batch adversarial loss: 0.498214\n",
      "epoch 93; iter: 0; batch classifier loss: 0.451854; batch adversarial loss: 0.625972\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411218; batch adversarial loss: 0.577357\n",
      "epoch 95; iter: 0; batch classifier loss: 0.448135; batch adversarial loss: 0.607449\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398726; batch adversarial loss: 0.536106\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358168; batch adversarial loss: 0.491078\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365565; batch adversarial loss: 0.617573\n",
      "epoch 99; iter: 0; batch classifier loss: 0.320464; batch adversarial loss: 0.537104\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383634; batch adversarial loss: 0.579921\n",
      "epoch 101; iter: 0; batch classifier loss: 0.348974; batch adversarial loss: 0.518196\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416141; batch adversarial loss: 0.482974\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372130; batch adversarial loss: 0.518094\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366215; batch adversarial loss: 0.553597\n",
      "epoch 105; iter: 0; batch classifier loss: 0.427892; batch adversarial loss: 0.517977\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389509; batch adversarial loss: 0.571414\n",
      "epoch 107; iter: 0; batch classifier loss: 0.385411; batch adversarial loss: 0.553528\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390987; batch adversarial loss: 0.607218\n",
      "epoch 109; iter: 0; batch classifier loss: 0.446981; batch adversarial loss: 0.570514\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398408; batch adversarial loss: 0.561674\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372071; batch adversarial loss: 0.526692\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430670; batch adversarial loss: 0.544172\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363119; batch adversarial loss: 0.614958\n",
      "epoch 114; iter: 0; batch classifier loss: 0.453771; batch adversarial loss: 0.543126\n",
      "epoch 115; iter: 0; batch classifier loss: 0.375302; batch adversarial loss: 0.570931\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343735; batch adversarial loss: 0.498921\n",
      "epoch 117; iter: 0; batch classifier loss: 0.417835; batch adversarial loss: 0.480105\n",
      "epoch 118; iter: 0; batch classifier loss: 0.371507; batch adversarial loss: 0.589475\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356618; batch adversarial loss: 0.525676\n",
      "epoch 120; iter: 0; batch classifier loss: 0.445155; batch adversarial loss: 0.617178\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369053; batch adversarial loss: 0.526393\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395755; batch adversarial loss: 0.553949\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352056; batch adversarial loss: 0.562197\n",
      "epoch 124; iter: 0; batch classifier loss: 0.335998; batch adversarial loss: 0.490297\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326304; batch adversarial loss: 0.544746\n",
      "epoch 126; iter: 0; batch classifier loss: 0.324700; batch adversarial loss: 0.571572\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443849; batch adversarial loss: 0.589933\n",
      "epoch 128; iter: 0; batch classifier loss: 0.426226; batch adversarial loss: 0.517263\n",
      "epoch 129; iter: 0; batch classifier loss: 0.408292; batch adversarial loss: 0.535940\n",
      "epoch 130; iter: 0; batch classifier loss: 0.332517; batch adversarial loss: 0.453358\n",
      "epoch 131; iter: 0; batch classifier loss: 0.333627; batch adversarial loss: 0.543206\n",
      "epoch 132; iter: 0; batch classifier loss: 0.417031; batch adversarial loss: 0.506525\n",
      "epoch 133; iter: 0; batch classifier loss: 0.324568; batch adversarial loss: 0.481027\n",
      "epoch 134; iter: 0; batch classifier loss: 0.346619; batch adversarial loss: 0.581814\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343810; batch adversarial loss: 0.544424\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387192; batch adversarial loss: 0.524900\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366815; batch adversarial loss: 0.553733\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387077; batch adversarial loss: 0.525866\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361309; batch adversarial loss: 0.590140\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343114; batch adversarial loss: 0.562257\n",
      "epoch 141; iter: 0; batch classifier loss: 0.388973; batch adversarial loss: 0.633512\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358393; batch adversarial loss: 0.491637\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374616; batch adversarial loss: 0.571696\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392038; batch adversarial loss: 0.473894\n",
      "epoch 145; iter: 0; batch classifier loss: 0.396615; batch adversarial loss: 0.526877\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376471; batch adversarial loss: 0.571306\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336821; batch adversarial loss: 0.589420\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334902; batch adversarial loss: 0.499828\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377370; batch adversarial loss: 0.544406\n",
      "epoch 150; iter: 0; batch classifier loss: 0.316849; batch adversarial loss: 0.553136\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334026; batch adversarial loss: 0.518179\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397040; batch adversarial loss: 0.588906\n",
      "epoch 153; iter: 0; batch classifier loss: 0.337752; batch adversarial loss: 0.579918\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317290; batch adversarial loss: 0.609563\n",
      "epoch 155; iter: 0; batch classifier loss: 0.339054; batch adversarial loss: 0.519093\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336312; batch adversarial loss: 0.552316\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373921; batch adversarial loss: 0.525866\n",
      "epoch 158; iter: 0; batch classifier loss: 0.304517; batch adversarial loss: 0.544766\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377349; batch adversarial loss: 0.580197\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332894; batch adversarial loss: 0.464693\n",
      "epoch 161; iter: 0; batch classifier loss: 0.276001; batch adversarial loss: 0.606868\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412533; batch adversarial loss: 0.571402\n",
      "epoch 163; iter: 0; batch classifier loss: 0.455460; batch adversarial loss: 0.580548\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394014; batch adversarial loss: 0.562556\n",
      "epoch 165; iter: 0; batch classifier loss: 0.429448; batch adversarial loss: 0.445717\n",
      "epoch 166; iter: 0; batch classifier loss: 0.317736; batch adversarial loss: 0.508469\n",
      "epoch 167; iter: 0; batch classifier loss: 0.446978; batch adversarial loss: 0.517469\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373112; batch adversarial loss: 0.553617\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376843; batch adversarial loss: 0.553579\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368941; batch adversarial loss: 0.508666\n",
      "epoch 171; iter: 0; batch classifier loss: 0.367823; batch adversarial loss: 0.544486\n",
      "epoch 172; iter: 0; batch classifier loss: 0.445041; batch adversarial loss: 0.552643\n",
      "epoch 173; iter: 0; batch classifier loss: 0.395426; batch adversarial loss: 0.525639\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338691; batch adversarial loss: 0.553606\n",
      "epoch 175; iter: 0; batch classifier loss: 0.324826; batch adversarial loss: 0.525055\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378208; batch adversarial loss: 0.618127\n",
      "epoch 177; iter: 0; batch classifier loss: 0.349688; batch adversarial loss: 0.480110\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326880; batch adversarial loss: 0.599348\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298820; batch adversarial loss: 0.624831\n",
      "epoch 180; iter: 0; batch classifier loss: 0.357601; batch adversarial loss: 0.526407\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373003; batch adversarial loss: 0.600094\n",
      "epoch 182; iter: 0; batch classifier loss: 0.361865; batch adversarial loss: 0.534031\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341496; batch adversarial loss: 0.453743\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363427; batch adversarial loss: 0.572738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.367710; batch adversarial loss: 0.581604\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347470; batch adversarial loss: 0.534851\n",
      "epoch 187; iter: 0; batch classifier loss: 0.273423; batch adversarial loss: 0.509360\n",
      "epoch 188; iter: 0; batch classifier loss: 0.445225; batch adversarial loss: 0.607269\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395507; batch adversarial loss: 0.536358\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326667; batch adversarial loss: 0.544659\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336174; batch adversarial loss: 0.516311\n",
      "epoch 192; iter: 0; batch classifier loss: 0.360614; batch adversarial loss: 0.535115\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335245; batch adversarial loss: 0.518753\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343479; batch adversarial loss: 0.561793\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365919; batch adversarial loss: 0.599073\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327612; batch adversarial loss: 0.561951\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381646; batch adversarial loss: 0.526253\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356083; batch adversarial loss: 0.623804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.256630; batch adversarial loss: 0.561563\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722937; batch adversarial loss: 0.640351\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616708; batch adversarial loss: 0.650881\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556336; batch adversarial loss: 0.682531\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541790; batch adversarial loss: 0.628819\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614411; batch adversarial loss: 0.679488\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587126; batch adversarial loss: 0.652940\n",
      "epoch 6; iter: 0; batch classifier loss: 0.462844; batch adversarial loss: 0.609152\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545984; batch adversarial loss: 0.593713\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551944; batch adversarial loss: 0.636316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508949; batch adversarial loss: 0.588905\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542978; batch adversarial loss: 0.543326\n",
      "epoch 11; iter: 0; batch classifier loss: 0.488936; batch adversarial loss: 0.571929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498981; batch adversarial loss: 0.589335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557471; batch adversarial loss: 0.575912\n",
      "epoch 14; iter: 0; batch classifier loss: 0.596602; batch adversarial loss: 0.614059\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504981; batch adversarial loss: 0.549527\n",
      "epoch 16; iter: 0; batch classifier loss: 0.642658; batch adversarial loss: 0.565075\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496874; batch adversarial loss: 0.563972\n",
      "epoch 18; iter: 0; batch classifier loss: 0.580709; batch adversarial loss: 0.573934\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468053; batch adversarial loss: 0.582081\n",
      "epoch 20; iter: 0; batch classifier loss: 0.390703; batch adversarial loss: 0.587493\n",
      "epoch 21; iter: 0; batch classifier loss: 0.427155; batch adversarial loss: 0.481828\n",
      "epoch 22; iter: 0; batch classifier loss: 0.442968; batch adversarial loss: 0.582849\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423618; batch adversarial loss: 0.498788\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473195; batch adversarial loss: 0.552636\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452376; batch adversarial loss: 0.541036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444087; batch adversarial loss: 0.591014\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454176; batch adversarial loss: 0.621644\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446935; batch adversarial loss: 0.616939\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496004; batch adversarial loss: 0.606251\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482772; batch adversarial loss: 0.564259\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474697; batch adversarial loss: 0.529373\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450058; batch adversarial loss: 0.503345\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481090; batch adversarial loss: 0.596249\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432722; batch adversarial loss: 0.467897\n",
      "epoch 35; iter: 0; batch classifier loss: 0.534502; batch adversarial loss: 0.579475\n",
      "epoch 36; iter: 0; batch classifier loss: 0.479679; batch adversarial loss: 0.613836\n",
      "epoch 37; iter: 0; batch classifier loss: 0.411731; batch adversarial loss: 0.500904\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460570; batch adversarial loss: 0.542927\n",
      "epoch 39; iter: 0; batch classifier loss: 0.359790; batch adversarial loss: 0.630299\n",
      "epoch 40; iter: 0; batch classifier loss: 0.505547; batch adversarial loss: 0.564323\n",
      "epoch 41; iter: 0; batch classifier loss: 0.506321; batch adversarial loss: 0.421041\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480371; batch adversarial loss: 0.562368\n",
      "epoch 43; iter: 0; batch classifier loss: 0.515734; batch adversarial loss: 0.597443\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409294; batch adversarial loss: 0.572057\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444665; batch adversarial loss: 0.564207\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487366; batch adversarial loss: 0.580694\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399155; batch adversarial loss: 0.643396\n",
      "epoch 48; iter: 0; batch classifier loss: 0.361872; batch adversarial loss: 0.552768\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406109; batch adversarial loss: 0.473136\n",
      "epoch 50; iter: 0; batch classifier loss: 0.387037; batch adversarial loss: 0.499273\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411760; batch adversarial loss: 0.624024\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456196; batch adversarial loss: 0.614788\n",
      "epoch 53; iter: 0; batch classifier loss: 0.360729; batch adversarial loss: 0.625359\n",
      "epoch 54; iter: 0; batch classifier loss: 0.382964; batch adversarial loss: 0.571247\n",
      "epoch 55; iter: 0; batch classifier loss: 0.479629; batch adversarial loss: 0.535306\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444020; batch adversarial loss: 0.579697\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413174; batch adversarial loss: 0.606191\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438755; batch adversarial loss: 0.516780\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462420; batch adversarial loss: 0.587112\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434210; batch adversarial loss: 0.490775\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381781; batch adversarial loss: 0.545728\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457482; batch adversarial loss: 0.508819\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402084; batch adversarial loss: 0.536455\n",
      "epoch 64; iter: 0; batch classifier loss: 0.469948; batch adversarial loss: 0.500048\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383581; batch adversarial loss: 0.580339\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404800; batch adversarial loss: 0.527029\n",
      "epoch 67; iter: 0; batch classifier loss: 0.446746; batch adversarial loss: 0.624474\n",
      "epoch 68; iter: 0; batch classifier loss: 0.482063; batch adversarial loss: 0.552947\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411323; batch adversarial loss: 0.573628\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431379; batch adversarial loss: 0.588556\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427849; batch adversarial loss: 0.507167\n",
      "epoch 72; iter: 0; batch classifier loss: 0.421958; batch adversarial loss: 0.598154\n",
      "epoch 73; iter: 0; batch classifier loss: 0.381703; batch adversarial loss: 0.495564\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386374; batch adversarial loss: 0.500120\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364916; batch adversarial loss: 0.591693\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430433; batch adversarial loss: 0.583284\n",
      "epoch 77; iter: 0; batch classifier loss: 0.327371; batch adversarial loss: 0.624962\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376429; batch adversarial loss: 0.545272\n",
      "epoch 79; iter: 0; batch classifier loss: 0.331288; batch adversarial loss: 0.597701\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451329; batch adversarial loss: 0.580221\n",
      "epoch 81; iter: 0; batch classifier loss: 0.352630; batch adversarial loss: 0.517683\n",
      "epoch 82; iter: 0; batch classifier loss: 0.370912; batch adversarial loss: 0.526242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.372594; batch adversarial loss: 0.553663\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412087; batch adversarial loss: 0.499610\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370584; batch adversarial loss: 0.553529\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373399; batch adversarial loss: 0.473725\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367205; batch adversarial loss: 0.545553\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402403; batch adversarial loss: 0.633438\n",
      "epoch 89; iter: 0; batch classifier loss: 0.430828; batch adversarial loss: 0.562689\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452622; batch adversarial loss: 0.598837\n",
      "epoch 91; iter: 0; batch classifier loss: 0.353393; batch adversarial loss: 0.651907\n",
      "epoch 92; iter: 0; batch classifier loss: 0.436077; batch adversarial loss: 0.591282\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357651; batch adversarial loss: 0.534316\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415947; batch adversarial loss: 0.616057\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396151; batch adversarial loss: 0.535697\n",
      "epoch 96; iter: 0; batch classifier loss: 0.344149; batch adversarial loss: 0.562198\n",
      "epoch 97; iter: 0; batch classifier loss: 0.406313; batch adversarial loss: 0.553713\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409063; batch adversarial loss: 0.509929\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378346; batch adversarial loss: 0.490452\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433528; batch adversarial loss: 0.562284\n",
      "epoch 101; iter: 0; batch classifier loss: 0.286208; batch adversarial loss: 0.588808\n",
      "epoch 102; iter: 0; batch classifier loss: 0.438995; batch adversarial loss: 0.490628\n",
      "epoch 103; iter: 0; batch classifier loss: 0.393838; batch adversarial loss: 0.526426\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389990; batch adversarial loss: 0.571402\n",
      "epoch 105; iter: 0; batch classifier loss: 0.445919; batch adversarial loss: 0.553586\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355717; batch adversarial loss: 0.465741\n",
      "epoch 107; iter: 0; batch classifier loss: 0.384024; batch adversarial loss: 0.579879\n",
      "epoch 108; iter: 0; batch classifier loss: 0.409064; batch adversarial loss: 0.517360\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379448; batch adversarial loss: 0.554772\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411088; batch adversarial loss: 0.553318\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391525; batch adversarial loss: 0.651003\n",
      "epoch 112; iter: 0; batch classifier loss: 0.432478; batch adversarial loss: 0.482218\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421963; batch adversarial loss: 0.543798\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374212; batch adversarial loss: 0.570863\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394466; batch adversarial loss: 0.517757\n",
      "epoch 116; iter: 0; batch classifier loss: 0.310382; batch adversarial loss: 0.588925\n",
      "epoch 117; iter: 0; batch classifier loss: 0.394793; batch adversarial loss: 0.507879\n",
      "epoch 118; iter: 0; batch classifier loss: 0.332927; batch adversarial loss: 0.588441\n",
      "epoch 119; iter: 0; batch classifier loss: 0.444460; batch adversarial loss: 0.518252\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391435; batch adversarial loss: 0.509831\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400696; batch adversarial loss: 0.597920\n",
      "epoch 122; iter: 0; batch classifier loss: 0.333440; batch adversarial loss: 0.580363\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352870; batch adversarial loss: 0.570337\n",
      "epoch 124; iter: 0; batch classifier loss: 0.362830; batch adversarial loss: 0.543971\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394556; batch adversarial loss: 0.562874\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344915; batch adversarial loss: 0.535758\n",
      "epoch 127; iter: 0; batch classifier loss: 0.406624; batch adversarial loss: 0.552959\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381703; batch adversarial loss: 0.562249\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388304; batch adversarial loss: 0.589045\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372829; batch adversarial loss: 0.580487\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387768; batch adversarial loss: 0.527105\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413124; batch adversarial loss: 0.563093\n",
      "epoch 133; iter: 0; batch classifier loss: 0.457150; batch adversarial loss: 0.553669\n",
      "epoch 134; iter: 0; batch classifier loss: 0.380954; batch adversarial loss: 0.553408\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408045; batch adversarial loss: 0.554061\n",
      "epoch 136; iter: 0; batch classifier loss: 0.391722; batch adversarial loss: 0.580971\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347485; batch adversarial loss: 0.598832\n",
      "epoch 138; iter: 0; batch classifier loss: 0.400739; batch adversarial loss: 0.527029\n",
      "epoch 139; iter: 0; batch classifier loss: 0.399432; batch adversarial loss: 0.598433\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391007; batch adversarial loss: 0.571001\n",
      "epoch 141; iter: 0; batch classifier loss: 0.384278; batch adversarial loss: 0.563433\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335243; batch adversarial loss: 0.517712\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342062; batch adversarial loss: 0.535375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359883; batch adversarial loss: 0.544326\n",
      "epoch 145; iter: 0; batch classifier loss: 0.326001; batch adversarial loss: 0.624913\n",
      "epoch 146; iter: 0; batch classifier loss: 0.401111; batch adversarial loss: 0.562280\n",
      "epoch 147; iter: 0; batch classifier loss: 0.436772; batch adversarial loss: 0.543909\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337070; batch adversarial loss: 0.553719\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351444; batch adversarial loss: 0.561986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.315068; batch adversarial loss: 0.544614\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330673; batch adversarial loss: 0.535706\n",
      "epoch 152; iter: 0; batch classifier loss: 0.400976; batch adversarial loss: 0.545694\n",
      "epoch 153; iter: 0; batch classifier loss: 0.452213; batch adversarial loss: 0.580404\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346292; batch adversarial loss: 0.561978\n",
      "epoch 155; iter: 0; batch classifier loss: 0.439200; batch adversarial loss: 0.490563\n",
      "epoch 156; iter: 0; batch classifier loss: 0.428229; batch adversarial loss: 0.562156\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313644; batch adversarial loss: 0.553597\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363196; batch adversarial loss: 0.598457\n",
      "epoch 159; iter: 0; batch classifier loss: 0.392002; batch adversarial loss: 0.562465\n",
      "epoch 160; iter: 0; batch classifier loss: 0.410823; batch adversarial loss: 0.518425\n",
      "epoch 161; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.571290\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382056; batch adversarial loss: 0.580649\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397455; batch adversarial loss: 0.552977\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395020; batch adversarial loss: 0.571647\n",
      "epoch 165; iter: 0; batch classifier loss: 0.417499; batch adversarial loss: 0.491251\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369892; batch adversarial loss: 0.562050\n",
      "epoch 167; iter: 0; batch classifier loss: 0.392112; batch adversarial loss: 0.527393\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344116; batch adversarial loss: 0.509153\n",
      "epoch 169; iter: 0; batch classifier loss: 0.391293; batch adversarial loss: 0.589826\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378817; batch adversarial loss: 0.536244\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333988; batch adversarial loss: 0.499844\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402828; batch adversarial loss: 0.535252\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302263; batch adversarial loss: 0.562416\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376635; batch adversarial loss: 0.598119\n",
      "epoch 175; iter: 0; batch classifier loss: 0.444228; batch adversarial loss: 0.589050\n",
      "epoch 176; iter: 0; batch classifier loss: 0.272071; batch adversarial loss: 0.624995\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377263; batch adversarial loss: 0.588744\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345639; batch adversarial loss: 0.562729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.389868; batch adversarial loss: 0.500008\n",
      "epoch 180; iter: 0; batch classifier loss: 0.321248; batch adversarial loss: 0.553567\n",
      "epoch 181; iter: 0; batch classifier loss: 0.413638; batch adversarial loss: 0.553662\n",
      "epoch 182; iter: 0; batch classifier loss: 0.326298; batch adversarial loss: 0.508908\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371298; batch adversarial loss: 0.526903\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350048; batch adversarial loss: 0.482011\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365139; batch adversarial loss: 0.482790\n",
      "epoch 186; iter: 0; batch classifier loss: 0.362324; batch adversarial loss: 0.535563\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364624; batch adversarial loss: 0.571505\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391180; batch adversarial loss: 0.544448\n",
      "epoch 189; iter: 0; batch classifier loss: 0.320701; batch adversarial loss: 0.588837\n",
      "epoch 190; iter: 0; batch classifier loss: 0.437117; batch adversarial loss: 0.438179\n",
      "epoch 191; iter: 0; batch classifier loss: 0.348875; batch adversarial loss: 0.553171\n",
      "epoch 192; iter: 0; batch classifier loss: 0.420993; batch adversarial loss: 0.509143\n",
      "epoch 193; iter: 0; batch classifier loss: 0.425416; batch adversarial loss: 0.643278\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358217; batch adversarial loss: 0.588953\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336157; batch adversarial loss: 0.562426\n",
      "epoch 196; iter: 0; batch classifier loss: 0.371857; batch adversarial loss: 0.562587\n",
      "epoch 197; iter: 0; batch classifier loss: 0.374084; batch adversarial loss: 0.509004\n",
      "epoch 198; iter: 0; batch classifier loss: 0.295526; batch adversarial loss: 0.535608\n",
      "epoch 199; iter: 0; batch classifier loss: 0.437176; batch adversarial loss: 0.580587\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670445; batch adversarial loss: 0.835397\n",
      "epoch 1; iter: 0; batch classifier loss: 0.806751; batch adversarial loss: 0.953366\n",
      "epoch 2; iter: 0; batch classifier loss: 0.846023; batch adversarial loss: 0.908092\n",
      "epoch 3; iter: 0; batch classifier loss: 0.874558; batch adversarial loss: 0.817686\n",
      "epoch 4; iter: 0; batch classifier loss: 0.805771; batch adversarial loss: 0.777616\n",
      "epoch 5; iter: 0; batch classifier loss: 0.743151; batch adversarial loss: 0.708163\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595897; batch adversarial loss: 0.663291\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537241; batch adversarial loss: 0.618362\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533382; batch adversarial loss: 0.586213\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585791; batch adversarial loss: 0.575687\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574891; batch adversarial loss: 0.664795\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544160; batch adversarial loss: 0.595102\n",
      "epoch 12; iter: 0; batch classifier loss: 0.588564; batch adversarial loss: 0.592243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547442; batch adversarial loss: 0.543831\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520694; batch adversarial loss: 0.573310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544022; batch adversarial loss: 0.594146\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498211; batch adversarial loss: 0.573256\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486108; batch adversarial loss: 0.517309\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493833; batch adversarial loss: 0.599398\n",
      "epoch 19; iter: 0; batch classifier loss: 0.546865; batch adversarial loss: 0.582513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.418051; batch adversarial loss: 0.607147\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494389; batch adversarial loss: 0.502986\n",
      "epoch 22; iter: 0; batch classifier loss: 0.444651; batch adversarial loss: 0.528123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493835; batch adversarial loss: 0.641199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.443539; batch adversarial loss: 0.560072\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466063; batch adversarial loss: 0.558322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448722; batch adversarial loss: 0.537133\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488046; batch adversarial loss: 0.542011\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506904; batch adversarial loss: 0.537078\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477188; batch adversarial loss: 0.553442\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502078; batch adversarial loss: 0.603102\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443190; batch adversarial loss: 0.583845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445296; batch adversarial loss: 0.656825\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473689; batch adversarial loss: 0.456721\n",
      "epoch 34; iter: 0; batch classifier loss: 0.495437; batch adversarial loss: 0.638593\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406988; batch adversarial loss: 0.553802\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502631; batch adversarial loss: 0.502040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.419682; batch adversarial loss: 0.511643\n",
      "epoch 38; iter: 0; batch classifier loss: 0.344997; batch adversarial loss: 0.584107\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440120; batch adversarial loss: 0.481354\n",
      "epoch 40; iter: 0; batch classifier loss: 0.438646; batch adversarial loss: 0.505545\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471514; batch adversarial loss: 0.455355\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463486; batch adversarial loss: 0.571698\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426146; batch adversarial loss: 0.600640\n",
      "epoch 44; iter: 0; batch classifier loss: 0.469164; batch adversarial loss: 0.539139\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437028; batch adversarial loss: 0.476705\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460794; batch adversarial loss: 0.519444\n",
      "epoch 47; iter: 0; batch classifier loss: 0.391721; batch adversarial loss: 0.508660\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454485; batch adversarial loss: 0.526807\n",
      "epoch 49; iter: 0; batch classifier loss: 0.387732; batch adversarial loss: 0.549507\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459498; batch adversarial loss: 0.497712\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400000; batch adversarial loss: 0.583654\n",
      "epoch 52; iter: 0; batch classifier loss: 0.468114; batch adversarial loss: 0.554509\n",
      "epoch 53; iter: 0; batch classifier loss: 0.365825; batch adversarial loss: 0.586318\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420737; batch adversarial loss: 0.563829\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422784; batch adversarial loss: 0.544350\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396200; batch adversarial loss: 0.583411\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369937; batch adversarial loss: 0.619652\n",
      "epoch 58; iter: 0; batch classifier loss: 0.334164; batch adversarial loss: 0.581294\n",
      "epoch 59; iter: 0; batch classifier loss: 0.395455; batch adversarial loss: 0.489303\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434314; batch adversarial loss: 0.469523\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451717; batch adversarial loss: 0.580033\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393345; batch adversarial loss: 0.581365\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438970; batch adversarial loss: 0.566148\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384990; batch adversarial loss: 0.506910\n",
      "epoch 65; iter: 0; batch classifier loss: 0.434590; batch adversarial loss: 0.535454\n",
      "epoch 66; iter: 0; batch classifier loss: 0.375126; batch adversarial loss: 0.535606\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405783; batch adversarial loss: 0.563279\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407836; batch adversarial loss: 0.582083\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357618; batch adversarial loss: 0.544134\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384870; batch adversarial loss: 0.572161\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414866; batch adversarial loss: 0.545472\n",
      "epoch 72; iter: 0; batch classifier loss: 0.278979; batch adversarial loss: 0.535426\n",
      "epoch 73; iter: 0; batch classifier loss: 0.352963; batch adversarial loss: 0.516951\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380942; batch adversarial loss: 0.525684\n",
      "epoch 75; iter: 0; batch classifier loss: 0.514185; batch adversarial loss: 0.648247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.454938; batch adversarial loss: 0.695551\n",
      "epoch 77; iter: 0; batch classifier loss: 0.446926; batch adversarial loss: 0.516359\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372936; batch adversarial loss: 0.506445\n",
      "epoch 79; iter: 0; batch classifier loss: 0.461901; batch adversarial loss: 0.600092\n",
      "epoch 80; iter: 0; batch classifier loss: 0.317583; batch adversarial loss: 0.516074\n",
      "epoch 81; iter: 0; batch classifier loss: 0.486312; batch adversarial loss: 0.591329\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418535; batch adversarial loss: 0.534942\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405887; batch adversarial loss: 0.571552\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376859; batch adversarial loss: 0.626722\n",
      "epoch 85; iter: 0; batch classifier loss: 0.358708; batch adversarial loss: 0.450845\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373676; batch adversarial loss: 0.544282\n",
      "epoch 87; iter: 0; batch classifier loss: 0.317868; batch adversarial loss: 0.608247\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375843; batch adversarial loss: 0.552774\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388932; batch adversarial loss: 0.479486\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367446; batch adversarial loss: 0.479146\n",
      "epoch 91; iter: 0; batch classifier loss: 0.353368; batch adversarial loss: 0.525513\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381638; batch adversarial loss: 0.571220\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441437; batch adversarial loss: 0.628456\n",
      "epoch 94; iter: 0; batch classifier loss: 0.332403; batch adversarial loss: 0.507526\n",
      "epoch 95; iter: 0; batch classifier loss: 0.349156; batch adversarial loss: 0.525346\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392092; batch adversarial loss: 0.581941\n",
      "epoch 97; iter: 0; batch classifier loss: 0.300564; batch adversarial loss: 0.563365\n",
      "epoch 98; iter: 0; batch classifier loss: 0.306479; batch adversarial loss: 0.526197\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354255; batch adversarial loss: 0.508130\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368980; batch adversarial loss: 0.479210\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385926; batch adversarial loss: 0.553962\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412557; batch adversarial loss: 0.561355\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397021; batch adversarial loss: 0.581265\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423083; batch adversarial loss: 0.666478\n",
      "epoch 105; iter: 0; batch classifier loss: 0.349446; batch adversarial loss: 0.543849\n",
      "epoch 106; iter: 0; batch classifier loss: 0.410958; batch adversarial loss: 0.516075\n",
      "epoch 107; iter: 0; batch classifier loss: 0.303593; batch adversarial loss: 0.525903\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327104; batch adversarial loss: 0.469256\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397890; batch adversarial loss: 0.590689\n",
      "epoch 110; iter: 0; batch classifier loss: 0.346429; batch adversarial loss: 0.554972\n",
      "epoch 111; iter: 0; batch classifier loss: 0.263121; batch adversarial loss: 0.684699\n",
      "epoch 112; iter: 0; batch classifier loss: 0.458174; batch adversarial loss: 0.582647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.388763; batch adversarial loss: 0.470148\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375927; batch adversarial loss: 0.553765\n",
      "epoch 115; iter: 0; batch classifier loss: 0.299761; batch adversarial loss: 0.563362\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358782; batch adversarial loss: 0.526990\n",
      "epoch 117; iter: 0; batch classifier loss: 0.312739; batch adversarial loss: 0.525616\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393725; batch adversarial loss: 0.535515\n",
      "epoch 119; iter: 0; batch classifier loss: 0.421852; batch adversarial loss: 0.592045\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364611; batch adversarial loss: 0.581177\n",
      "epoch 121; iter: 0; batch classifier loss: 0.317914; batch adversarial loss: 0.535094\n",
      "epoch 122; iter: 0; batch classifier loss: 0.264813; batch adversarial loss: 0.471311\n",
      "epoch 123; iter: 0; batch classifier loss: 0.473464; batch adversarial loss: 0.582910\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363713; batch adversarial loss: 0.554262\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375064; batch adversarial loss: 0.554220\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377434; batch adversarial loss: 0.489343\n",
      "epoch 127; iter: 0; batch classifier loss: 0.485081; batch adversarial loss: 0.572186\n",
      "epoch 128; iter: 0; batch classifier loss: 0.439933; batch adversarial loss: 0.552999\n",
      "epoch 129; iter: 0; batch classifier loss: 0.487183; batch adversarial loss: 0.609852\n",
      "epoch 130; iter: 0; batch classifier loss: 0.320149; batch adversarial loss: 0.574096\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385708; batch adversarial loss: 0.645863\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354041; batch adversarial loss: 0.525538\n",
      "epoch 133; iter: 0; batch classifier loss: 0.290634; batch adversarial loss: 0.581802\n",
      "epoch 134; iter: 0; batch classifier loss: 0.320769; batch adversarial loss: 0.525598\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343040; batch adversarial loss: 0.590876\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381189; batch adversarial loss: 0.535327\n",
      "epoch 137; iter: 0; batch classifier loss: 0.429577; batch adversarial loss: 0.507456\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369015; batch adversarial loss: 0.497750\n",
      "epoch 139; iter: 0; batch classifier loss: 0.321900; batch adversarial loss: 0.562980\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342695; batch adversarial loss: 0.554826\n",
      "epoch 141; iter: 0; batch classifier loss: 0.419873; batch adversarial loss: 0.526324\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335677; batch adversarial loss: 0.516614\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322791; batch adversarial loss: 0.581351\n",
      "epoch 144; iter: 0; batch classifier loss: 0.315492; batch adversarial loss: 0.553801\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347079; batch adversarial loss: 0.498456\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347436; batch adversarial loss: 0.479585\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337173; batch adversarial loss: 0.535614\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403208; batch adversarial loss: 0.526188\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322175; batch adversarial loss: 0.664617\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367360; batch adversarial loss: 0.647485\n",
      "epoch 151; iter: 0; batch classifier loss: 0.313313; batch adversarial loss: 0.610925\n",
      "epoch 152; iter: 0; batch classifier loss: 0.345145; batch adversarial loss: 0.432326\n",
      "epoch 153; iter: 0; batch classifier loss: 0.274390; batch adversarial loss: 0.591707\n",
      "epoch 154; iter: 0; batch classifier loss: 0.334601; batch adversarial loss: 0.561881\n",
      "epoch 155; iter: 0; batch classifier loss: 0.405389; batch adversarial loss: 0.525412\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370617; batch adversarial loss: 0.498890\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340425; batch adversarial loss: 0.564036\n",
      "epoch 158; iter: 0; batch classifier loss: 0.348093; batch adversarial loss: 0.506901\n",
      "epoch 159; iter: 0; batch classifier loss: 0.340972; batch adversarial loss: 0.563451\n",
      "epoch 160; iter: 0; batch classifier loss: 0.305627; batch adversarial loss: 0.590861\n",
      "epoch 161; iter: 0; batch classifier loss: 0.406917; batch adversarial loss: 0.563635\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326619; batch adversarial loss: 0.563206\n",
      "epoch 163; iter: 0; batch classifier loss: 0.263023; batch adversarial loss: 0.459882\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345035; batch adversarial loss: 0.563585\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385801; batch adversarial loss: 0.573553\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360774; batch adversarial loss: 0.619694\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359887; batch adversarial loss: 0.591963\n",
      "epoch 168; iter: 0; batch classifier loss: 0.457631; batch adversarial loss: 0.572837\n",
      "epoch 169; iter: 0; batch classifier loss: 0.289862; batch adversarial loss: 0.526287\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366467; batch adversarial loss: 0.544227\n",
      "epoch 171; iter: 0; batch classifier loss: 0.312627; batch adversarial loss: 0.450898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.314730; batch adversarial loss: 0.563204\n",
      "epoch 173; iter: 0; batch classifier loss: 0.379334; batch adversarial loss: 0.609319\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385924; batch adversarial loss: 0.554230\n",
      "epoch 175; iter: 0; batch classifier loss: 0.269109; batch adversarial loss: 0.497661\n",
      "epoch 176; iter: 0; batch classifier loss: 0.430269; batch adversarial loss: 0.581746\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306014; batch adversarial loss: 0.517202\n",
      "epoch 178; iter: 0; batch classifier loss: 0.356387; batch adversarial loss: 0.451628\n",
      "epoch 179; iter: 0; batch classifier loss: 0.328288; batch adversarial loss: 0.534794\n",
      "epoch 180; iter: 0; batch classifier loss: 0.278204; batch adversarial loss: 0.562649\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367977; batch adversarial loss: 0.638147\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372269; batch adversarial loss: 0.533453\n",
      "epoch 183; iter: 0; batch classifier loss: 0.365660; batch adversarial loss: 0.580642\n",
      "epoch 184; iter: 0; batch classifier loss: 0.333958; batch adversarial loss: 0.580574\n",
      "epoch 185; iter: 0; batch classifier loss: 0.273191; batch adversarial loss: 0.488210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348800; batch adversarial loss: 0.563229\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357514; batch adversarial loss: 0.506863\n",
      "epoch 188; iter: 0; batch classifier loss: 0.306971; batch adversarial loss: 0.553470\n",
      "epoch 189; iter: 0; batch classifier loss: 0.416271; batch adversarial loss: 0.488710\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358456; batch adversarial loss: 0.497502\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392725; batch adversarial loss: 0.479203\n",
      "epoch 192; iter: 0; batch classifier loss: 0.295536; batch adversarial loss: 0.554289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368156; batch adversarial loss: 0.573443\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335976; batch adversarial loss: 0.535693\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376869; batch adversarial loss: 0.591463\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320609; batch adversarial loss: 0.572418\n",
      "epoch 197; iter: 0; batch classifier loss: 0.291671; batch adversarial loss: 0.573066\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323969; batch adversarial loss: 0.554339\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331832; batch adversarial loss: 0.534560\n",
      "epoch 0; iter: 0; batch classifier loss: 0.779657; batch adversarial loss: 0.833367\n",
      "epoch 1; iter: 0; batch classifier loss: 0.651323; batch adversarial loss: 0.767007\n",
      "epoch 2; iter: 0; batch classifier loss: 0.658651; batch adversarial loss: 0.742833\n",
      "epoch 3; iter: 0; batch classifier loss: 0.655989; batch adversarial loss: 0.688502\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546533; batch adversarial loss: 0.659120\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614924; batch adversarial loss: 0.650375\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508449; batch adversarial loss: 0.638644\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520752; batch adversarial loss: 0.634406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539102; batch adversarial loss: 0.638336\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576467; batch adversarial loss: 0.582728\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533417; batch adversarial loss: 0.580261\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490248; batch adversarial loss: 0.592357\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511351; batch adversarial loss: 0.602616\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560698; batch adversarial loss: 0.562944\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504778; batch adversarial loss: 0.552822\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497280; batch adversarial loss: 0.539710\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534900; batch adversarial loss: 0.584820\n",
      "epoch 17; iter: 0; batch classifier loss: 0.554614; batch adversarial loss: 0.554670\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471669; batch adversarial loss: 0.507286\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500961; batch adversarial loss: 0.599409\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485733; batch adversarial loss: 0.533533\n",
      "epoch 21; iter: 0; batch classifier loss: 0.551080; batch adversarial loss: 0.630839\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494569; batch adversarial loss: 0.496400\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495743; batch adversarial loss: 0.649828\n",
      "epoch 24; iter: 0; batch classifier loss: 0.537152; batch adversarial loss: 0.560045\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523213; batch adversarial loss: 0.578905\n",
      "epoch 26; iter: 0; batch classifier loss: 0.392766; batch adversarial loss: 0.513936\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455855; batch adversarial loss: 0.567138\n",
      "epoch 28; iter: 0; batch classifier loss: 0.552243; batch adversarial loss: 0.570632\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435427; batch adversarial loss: 0.615028\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472209; batch adversarial loss: 0.621612\n",
      "epoch 31; iter: 0; batch classifier loss: 0.542298; batch adversarial loss: 0.547913\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403093; batch adversarial loss: 0.521284\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447909; batch adversarial loss: 0.553257\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488781; batch adversarial loss: 0.539618\n",
      "epoch 35; iter: 0; batch classifier loss: 0.522429; batch adversarial loss: 0.611775\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502764; batch adversarial loss: 0.616408\n",
      "epoch 37; iter: 0; batch classifier loss: 0.468521; batch adversarial loss: 0.487747\n",
      "epoch 38; iter: 0; batch classifier loss: 0.433502; batch adversarial loss: 0.587576\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427871; batch adversarial loss: 0.553800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.380771; batch adversarial loss: 0.631129\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404301; batch adversarial loss: 0.570159\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462901; batch adversarial loss: 0.545842\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463593; batch adversarial loss: 0.465796\n",
      "epoch 44; iter: 0; batch classifier loss: 0.467547; batch adversarial loss: 0.502899\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470460; batch adversarial loss: 0.588632\n",
      "epoch 46; iter: 0; batch classifier loss: 0.481046; batch adversarial loss: 0.519862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475111; batch adversarial loss: 0.537265\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449605; batch adversarial loss: 0.545812\n",
      "epoch 49; iter: 0; batch classifier loss: 0.375803; batch adversarial loss: 0.519613\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410542; batch adversarial loss: 0.614290\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374188; batch adversarial loss: 0.605220\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420387; batch adversarial loss: 0.476126\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402999; batch adversarial loss: 0.597215\n",
      "epoch 54; iter: 0; batch classifier loss: 0.383520; batch adversarial loss: 0.561874\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413199; batch adversarial loss: 0.535581\n",
      "epoch 56; iter: 0; batch classifier loss: 0.460564; batch adversarial loss: 0.596480\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445013; batch adversarial loss: 0.562782\n",
      "epoch 58; iter: 0; batch classifier loss: 0.375651; batch adversarial loss: 0.519806\n",
      "epoch 59; iter: 0; batch classifier loss: 0.375793; batch adversarial loss: 0.510546\n",
      "epoch 60; iter: 0; batch classifier loss: 0.480719; batch adversarial loss: 0.571725\n",
      "epoch 61; iter: 0; batch classifier loss: 0.388792; batch adversarial loss: 0.588653\n",
      "epoch 62; iter: 0; batch classifier loss: 0.507992; batch adversarial loss: 0.571217\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422213; batch adversarial loss: 0.475730\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489839; batch adversarial loss: 0.483065\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426908; batch adversarial loss: 0.562181\n",
      "epoch 66; iter: 0; batch classifier loss: 0.296550; batch adversarial loss: 0.535733\n",
      "epoch 67; iter: 0; batch classifier loss: 0.443464; batch adversarial loss: 0.553313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.368500; batch adversarial loss: 0.562160\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384114; batch adversarial loss: 0.580310\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343962; batch adversarial loss: 0.571086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.473423; batch adversarial loss: 0.554842\n",
      "epoch 72; iter: 0; batch classifier loss: 0.323878; batch adversarial loss: 0.483969\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383016; batch adversarial loss: 0.605830\n",
      "epoch 74; iter: 0; batch classifier loss: 0.331758; batch adversarial loss: 0.535927\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443355; batch adversarial loss: 0.561922\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380978; batch adversarial loss: 0.598537\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442541; batch adversarial loss: 0.508709\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439159; batch adversarial loss: 0.517466\n",
      "epoch 79; iter: 0; batch classifier loss: 0.337104; batch adversarial loss: 0.589041\n",
      "epoch 80; iter: 0; batch classifier loss: 0.461569; batch adversarial loss: 0.544601\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424289; batch adversarial loss: 0.535830\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388691; batch adversarial loss: 0.544903\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376709; batch adversarial loss: 0.508868\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449861; batch adversarial loss: 0.543718\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382940; batch adversarial loss: 0.560323\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406834; batch adversarial loss: 0.578579\n",
      "epoch 87; iter: 0; batch classifier loss: 0.337796; batch adversarial loss: 0.542941\n",
      "epoch 88; iter: 0; batch classifier loss: 0.380478; batch adversarial loss: 0.547427\n",
      "epoch 89; iter: 0; batch classifier loss: 0.330995; batch adversarial loss: 0.535490\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348067; batch adversarial loss: 0.607318\n",
      "epoch 91; iter: 0; batch classifier loss: 0.418205; batch adversarial loss: 0.631688\n",
      "epoch 92; iter: 0; batch classifier loss: 0.358136; batch adversarial loss: 0.518858\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392590; batch adversarial loss: 0.623158\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430590; batch adversarial loss: 0.544323\n",
      "epoch 95; iter: 0; batch classifier loss: 0.447320; batch adversarial loss: 0.526964\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341854; batch adversarial loss: 0.597370\n",
      "epoch 97; iter: 0; batch classifier loss: 0.333458; batch adversarial loss: 0.544957\n",
      "epoch 98; iter: 0; batch classifier loss: 0.450215; batch adversarial loss: 0.572266\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351700; batch adversarial loss: 0.536322\n",
      "epoch 100; iter: 0; batch classifier loss: 0.452151; batch adversarial loss: 0.509270\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390841; batch adversarial loss: 0.570677\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363549; batch adversarial loss: 0.545092\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360286; batch adversarial loss: 0.552854\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364493; batch adversarial loss: 0.606136\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347127; batch adversarial loss: 0.580001\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393025; batch adversarial loss: 0.562785\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381065; batch adversarial loss: 0.484310\n",
      "epoch 108; iter: 0; batch classifier loss: 0.423393; batch adversarial loss: 0.501125\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331846; batch adversarial loss: 0.536636\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388047; batch adversarial loss: 0.606428\n",
      "epoch 111; iter: 0; batch classifier loss: 0.450687; batch adversarial loss: 0.500622\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394802; batch adversarial loss: 0.589110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392830; batch adversarial loss: 0.518088\n",
      "epoch 114; iter: 0; batch classifier loss: 0.315668; batch adversarial loss: 0.536177\n",
      "epoch 115; iter: 0; batch classifier loss: 0.347369; batch adversarial loss: 0.544017\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377549; batch adversarial loss: 0.624613\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386964; batch adversarial loss: 0.499829\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397732; batch adversarial loss: 0.543923\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404692; batch adversarial loss: 0.554067\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371104; batch adversarial loss: 0.516868\n",
      "epoch 121; iter: 0; batch classifier loss: 0.386947; batch adversarial loss: 0.617604\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399100; batch adversarial loss: 0.562786\n",
      "epoch 123; iter: 0; batch classifier loss: 0.386437; batch adversarial loss: 0.544446\n",
      "epoch 124; iter: 0; batch classifier loss: 0.293450; batch adversarial loss: 0.527594\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395663; batch adversarial loss: 0.587404\n",
      "epoch 126; iter: 0; batch classifier loss: 0.434592; batch adversarial loss: 0.516422\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355351; batch adversarial loss: 0.561969\n",
      "epoch 128; iter: 0; batch classifier loss: 0.274826; batch adversarial loss: 0.544360\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337775; batch adversarial loss: 0.571614\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364908; batch adversarial loss: 0.650982\n",
      "epoch 131; iter: 0; batch classifier loss: 0.397717; batch adversarial loss: 0.517958\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347319; batch adversarial loss: 0.554346\n",
      "epoch 133; iter: 0; batch classifier loss: 0.427458; batch adversarial loss: 0.625046\n",
      "epoch 134; iter: 0; batch classifier loss: 0.307295; batch adversarial loss: 0.518606\n",
      "epoch 135; iter: 0; batch classifier loss: 0.483974; batch adversarial loss: 0.544882\n",
      "epoch 136; iter: 0; batch classifier loss: 0.407708; batch adversarial loss: 0.563464\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368356; batch adversarial loss: 0.545212\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370048; batch adversarial loss: 0.544909\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416160; batch adversarial loss: 0.509791\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377221; batch adversarial loss: 0.579413\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325892; batch adversarial loss: 0.527520\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318771; batch adversarial loss: 0.544579\n",
      "epoch 143; iter: 0; batch classifier loss: 0.303941; batch adversarial loss: 0.553281\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359679; batch adversarial loss: 0.632774\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369382; batch adversarial loss: 0.544956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.414337; batch adversarial loss: 0.553916\n",
      "epoch 147; iter: 0; batch classifier loss: 0.259801; batch adversarial loss: 0.623543\n",
      "epoch 148; iter: 0; batch classifier loss: 0.333678; batch adversarial loss: 0.641443\n",
      "epoch 149; iter: 0; batch classifier loss: 0.404896; batch adversarial loss: 0.526721\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369899; batch adversarial loss: 0.571779\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386986; batch adversarial loss: 0.553987\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377952; batch adversarial loss: 0.615143\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389920; batch adversarial loss: 0.545233\n",
      "epoch 154; iter: 0; batch classifier loss: 0.423077; batch adversarial loss: 0.527296\n",
      "epoch 155; iter: 0; batch classifier loss: 0.326738; batch adversarial loss: 0.562544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391626; batch adversarial loss: 0.606036\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372661; batch adversarial loss: 0.553454\n",
      "epoch 158; iter: 0; batch classifier loss: 0.320725; batch adversarial loss: 0.491924\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375022; batch adversarial loss: 0.518490\n",
      "epoch 160; iter: 0; batch classifier loss: 0.316660; batch adversarial loss: 0.571083\n",
      "epoch 161; iter: 0; batch classifier loss: 0.433080; batch adversarial loss: 0.545197\n",
      "epoch 162; iter: 0; batch classifier loss: 0.367800; batch adversarial loss: 0.571291\n",
      "epoch 163; iter: 0; batch classifier loss: 0.377805; batch adversarial loss: 0.632728\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414296; batch adversarial loss: 0.518465\n",
      "epoch 165; iter: 0; batch classifier loss: 0.316952; batch adversarial loss: 0.483011\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328707; batch adversarial loss: 0.580327\n",
      "epoch 167; iter: 0; batch classifier loss: 0.455508; batch adversarial loss: 0.509634\n",
      "epoch 168; iter: 0; batch classifier loss: 0.275875; batch adversarial loss: 0.633567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 169; iter: 0; batch classifier loss: 0.437106; batch adversarial loss: 0.544492\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329955; batch adversarial loss: 0.545254\n",
      "epoch 171; iter: 0; batch classifier loss: 0.399446; batch adversarial loss: 0.605886\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368667; batch adversarial loss: 0.534998\n",
      "epoch 173; iter: 0; batch classifier loss: 0.328288; batch adversarial loss: 0.544772\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400085; batch adversarial loss: 0.535624\n",
      "epoch 175; iter: 0; batch classifier loss: 0.263617; batch adversarial loss: 0.588469\n",
      "epoch 176; iter: 0; batch classifier loss: 0.331100; batch adversarial loss: 0.562666\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305329; batch adversarial loss: 0.580377\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371632; batch adversarial loss: 0.545181\n",
      "epoch 179; iter: 0; batch classifier loss: 0.325049; batch adversarial loss: 0.500864\n",
      "epoch 180; iter: 0; batch classifier loss: 0.459405; batch adversarial loss: 0.553618\n",
      "epoch 181; iter: 0; batch classifier loss: 0.448996; batch adversarial loss: 0.527528\n",
      "epoch 182; iter: 0; batch classifier loss: 0.317524; batch adversarial loss: 0.562274\n",
      "epoch 183; iter: 0; batch classifier loss: 0.475670; batch adversarial loss: 0.509469\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381809; batch adversarial loss: 0.579906\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332413; batch adversarial loss: 0.536215\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399151; batch adversarial loss: 0.509757\n",
      "epoch 187; iter: 0; batch classifier loss: 0.324777; batch adversarial loss: 0.579766\n",
      "epoch 188; iter: 0; batch classifier loss: 0.351811; batch adversarial loss: 0.632437\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333091; batch adversarial loss: 0.552972\n",
      "epoch 190; iter: 0; batch classifier loss: 0.408929; batch adversarial loss: 0.553978\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336288; batch adversarial loss: 0.632872\n",
      "epoch 192; iter: 0; batch classifier loss: 0.296564; batch adversarial loss: 0.579836\n",
      "epoch 193; iter: 0; batch classifier loss: 0.480636; batch adversarial loss: 0.580562\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350550; batch adversarial loss: 0.492093\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353071; batch adversarial loss: 0.518250\n",
      "epoch 196; iter: 0; batch classifier loss: 0.318136; batch adversarial loss: 0.606315\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332376; batch adversarial loss: 0.632865\n",
      "epoch 198; iter: 0; batch classifier loss: 0.417684; batch adversarial loss: 0.553829\n",
      "epoch 199; iter: 0; batch classifier loss: 0.280242; batch adversarial loss: 0.562388\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728519; batch adversarial loss: 0.715578\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537169; batch adversarial loss: 0.672650\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609049; batch adversarial loss: 0.683589\n",
      "epoch 3; iter: 0; batch classifier loss: 0.549202; batch adversarial loss: 0.618047\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589741; batch adversarial loss: 0.667060\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570939; batch adversarial loss: 0.646667\n",
      "epoch 6; iter: 0; batch classifier loss: 0.483141; batch adversarial loss: 0.573035\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624715; batch adversarial loss: 0.570374\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514215; batch adversarial loss: 0.554137\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541458; batch adversarial loss: 0.567182\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568494; batch adversarial loss: 0.595293\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568472; batch adversarial loss: 0.611751\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558360; batch adversarial loss: 0.598154\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539688; batch adversarial loss: 0.574941\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515633; batch adversarial loss: 0.562575\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483552; batch adversarial loss: 0.571126\n",
      "epoch 16; iter: 0; batch classifier loss: 0.427250; batch adversarial loss: 0.542181\n",
      "epoch 17; iter: 0; batch classifier loss: 0.580292; batch adversarial loss: 0.552629\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532005; batch adversarial loss: 0.513559\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438731; batch adversarial loss: 0.511782\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483356; batch adversarial loss: 0.561118\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491520; batch adversarial loss: 0.575284\n",
      "epoch 22; iter: 0; batch classifier loss: 0.428660; batch adversarial loss: 0.497698\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471752; batch adversarial loss: 0.624264\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547659; batch adversarial loss: 0.501196\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452793; batch adversarial loss: 0.567667\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485239; batch adversarial loss: 0.485362\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505743; batch adversarial loss: 0.543533\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455551; batch adversarial loss: 0.529122\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455062; batch adversarial loss: 0.507444\n",
      "epoch 30; iter: 0; batch classifier loss: 0.435204; batch adversarial loss: 0.589089\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500867; batch adversarial loss: 0.575480\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457688; batch adversarial loss: 0.537816\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455009; batch adversarial loss: 0.566728\n",
      "epoch 34; iter: 0; batch classifier loss: 0.490406; batch adversarial loss: 0.535728\n",
      "epoch 35; iter: 0; batch classifier loss: 0.366495; batch adversarial loss: 0.511190\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410552; batch adversarial loss: 0.482629\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499706; batch adversarial loss: 0.538019\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512392; batch adversarial loss: 0.508090\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423203; batch adversarial loss: 0.488176\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456979; batch adversarial loss: 0.572904\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481935; batch adversarial loss: 0.467126\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480007; batch adversarial loss: 0.516762\n",
      "epoch 43; iter: 0; batch classifier loss: 0.538450; batch adversarial loss: 0.602262\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423668; batch adversarial loss: 0.577387\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430436; batch adversarial loss: 0.557500\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491376; batch adversarial loss: 0.564516\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375658; batch adversarial loss: 0.522712\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425680; batch adversarial loss: 0.573215\n",
      "epoch 49; iter: 0; batch classifier loss: 0.425138; batch adversarial loss: 0.507670\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432001; batch adversarial loss: 0.555696\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436612; batch adversarial loss: 0.619482\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412764; batch adversarial loss: 0.524409\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480527; batch adversarial loss: 0.541670\n",
      "epoch 54; iter: 0; batch classifier loss: 0.465641; batch adversarial loss: 0.476913\n",
      "epoch 55; iter: 0; batch classifier loss: 0.531456; batch adversarial loss: 0.581480\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428075; batch adversarial loss: 0.571477\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408558; batch adversarial loss: 0.557997\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413257; batch adversarial loss: 0.527964\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387661; batch adversarial loss: 0.591904\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426186; batch adversarial loss: 0.495825\n",
      "epoch 61; iter: 0; batch classifier loss: 0.387467; batch adversarial loss: 0.553271\n",
      "epoch 62; iter: 0; batch classifier loss: 0.462095; batch adversarial loss: 0.522096\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422468; batch adversarial loss: 0.512262\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390179; batch adversarial loss: 0.506850\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397019; batch adversarial loss: 0.482769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.359139; batch adversarial loss: 0.631956\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429337; batch adversarial loss: 0.434485\n",
      "epoch 68; iter: 0; batch classifier loss: 0.435398; batch adversarial loss: 0.560193\n",
      "epoch 69; iter: 0; batch classifier loss: 0.461949; batch adversarial loss: 0.546870\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385848; batch adversarial loss: 0.555966\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406161; batch adversarial loss: 0.592560\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416766; batch adversarial loss: 0.601637\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448062; batch adversarial loss: 0.544996\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389388; batch adversarial loss: 0.542919\n",
      "epoch 75; iter: 0; batch classifier loss: 0.434562; batch adversarial loss: 0.469947\n",
      "epoch 76; iter: 0; batch classifier loss: 0.499898; batch adversarial loss: 0.527819\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385603; batch adversarial loss: 0.517039\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415959; batch adversarial loss: 0.554519\n",
      "epoch 79; iter: 0; batch classifier loss: 0.494830; batch adversarial loss: 0.563597\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384459; batch adversarial loss: 0.534383\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371668; batch adversarial loss: 0.533489\n",
      "epoch 82; iter: 0; batch classifier loss: 0.417828; batch adversarial loss: 0.476579\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405046; batch adversarial loss: 0.543245\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391043; batch adversarial loss: 0.600603\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428312; batch adversarial loss: 0.437452\n",
      "epoch 86; iter: 0; batch classifier loss: 0.459548; batch adversarial loss: 0.564257\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422105; batch adversarial loss: 0.446669\n",
      "epoch 88; iter: 0; batch classifier loss: 0.482788; batch adversarial loss: 0.555874\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411074; batch adversarial loss: 0.535526\n",
      "epoch 90; iter: 0; batch classifier loss: 0.471129; batch adversarial loss: 0.573675\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383883; batch adversarial loss: 0.544441\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424171; batch adversarial loss: 0.466158\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405108; batch adversarial loss: 0.622986\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449744; batch adversarial loss: 0.437437\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345742; batch adversarial loss: 0.486479\n",
      "epoch 96; iter: 0; batch classifier loss: 0.359650; batch adversarial loss: 0.536127\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334575; batch adversarial loss: 0.506605\n",
      "epoch 98; iter: 0; batch classifier loss: 0.326813; batch adversarial loss: 0.621311\n",
      "epoch 99; iter: 0; batch classifier loss: 0.371151; batch adversarial loss: 0.505486\n",
      "epoch 100; iter: 0; batch classifier loss: 0.462874; batch adversarial loss: 0.506522\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434958; batch adversarial loss: 0.535181\n",
      "epoch 102; iter: 0; batch classifier loss: 0.333248; batch adversarial loss: 0.419948\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371876; batch adversarial loss: 0.535261\n",
      "epoch 104; iter: 0; batch classifier loss: 0.317621; batch adversarial loss: 0.535566\n",
      "epoch 105; iter: 0; batch classifier loss: 0.344941; batch adversarial loss: 0.574302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421608; batch adversarial loss: 0.565646\n",
      "epoch 107; iter: 0; batch classifier loss: 0.410160; batch adversarial loss: 0.525318\n",
      "epoch 108; iter: 0; batch classifier loss: 0.445565; batch adversarial loss: 0.468387\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421431; batch adversarial loss: 0.554165\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426603; batch adversarial loss: 0.505576\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384358; batch adversarial loss: 0.554559\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353211; batch adversarial loss: 0.526012\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383022; batch adversarial loss: 0.553769\n",
      "epoch 114; iter: 0; batch classifier loss: 0.457409; batch adversarial loss: 0.535127\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393496; batch adversarial loss: 0.545770\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390142; batch adversarial loss: 0.535560\n",
      "epoch 117; iter: 0; batch classifier loss: 0.400031; batch adversarial loss: 0.641183\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403975; batch adversarial loss: 0.592166\n",
      "epoch 119; iter: 0; batch classifier loss: 0.463508; batch adversarial loss: 0.473120\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408550; batch adversarial loss: 0.543944\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395305; batch adversarial loss: 0.555196\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359430; batch adversarial loss: 0.429216\n",
      "epoch 123; iter: 0; batch classifier loss: 0.316157; batch adversarial loss: 0.505804\n",
      "epoch 124; iter: 0; batch classifier loss: 0.409820; batch adversarial loss: 0.536915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.447734; batch adversarial loss: 0.574887\n",
      "epoch 126; iter: 0; batch classifier loss: 0.458513; batch adversarial loss: 0.583865\n",
      "epoch 127; iter: 0; batch classifier loss: 0.474765; batch adversarial loss: 0.621852\n",
      "epoch 128; iter: 0; batch classifier loss: 0.438807; batch adversarial loss: 0.544932\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354415; batch adversarial loss: 0.572285\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362790; batch adversarial loss: 0.517082\n",
      "epoch 131; iter: 0; batch classifier loss: 0.319907; batch adversarial loss: 0.564048\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390246; batch adversarial loss: 0.495693\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351999; batch adversarial loss: 0.438590\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382154; batch adversarial loss: 0.438870\n",
      "epoch 135; iter: 0; batch classifier loss: 0.357524; batch adversarial loss: 0.477853\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403891; batch adversarial loss: 0.544192\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375660; batch adversarial loss: 0.583195\n",
      "epoch 138; iter: 0; batch classifier loss: 0.305098; batch adversarial loss: 0.488136\n",
      "epoch 139; iter: 0; batch classifier loss: 0.315602; batch adversarial loss: 0.534650\n",
      "epoch 140; iter: 0; batch classifier loss: 0.395181; batch adversarial loss: 0.525135\n",
      "epoch 141; iter: 0; batch classifier loss: 0.302376; batch adversarial loss: 0.536643\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378087; batch adversarial loss: 0.544957\n",
      "epoch 143; iter: 0; batch classifier loss: 0.407091; batch adversarial loss: 0.517194\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437975; batch adversarial loss: 0.525304\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349169; batch adversarial loss: 0.545422\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400634; batch adversarial loss: 0.622472\n",
      "epoch 147; iter: 0; batch classifier loss: 0.288153; batch adversarial loss: 0.544329\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403813; batch adversarial loss: 0.553460\n",
      "epoch 149; iter: 0; batch classifier loss: 0.364375; batch adversarial loss: 0.554915\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338731; batch adversarial loss: 0.543163\n",
      "epoch 151; iter: 0; batch classifier loss: 0.413293; batch adversarial loss: 0.515787\n",
      "epoch 152; iter: 0; batch classifier loss: 0.420917; batch adversarial loss: 0.610465\n",
      "epoch 153; iter: 0; batch classifier loss: 0.417103; batch adversarial loss: 0.514235\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379473; batch adversarial loss: 0.456498\n",
      "epoch 155; iter: 0; batch classifier loss: 0.407634; batch adversarial loss: 0.623450\n",
      "epoch 156; iter: 0; batch classifier loss: 0.438815; batch adversarial loss: 0.497334\n",
      "epoch 157; iter: 0; batch classifier loss: 0.452431; batch adversarial loss: 0.535435\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339981; batch adversarial loss: 0.506138\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341475; batch adversarial loss: 0.573080\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318595; batch adversarial loss: 0.593408\n",
      "epoch 161; iter: 0; batch classifier loss: 0.360638; batch adversarial loss: 0.524953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.414659; batch adversarial loss: 0.505341\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339502; batch adversarial loss: 0.505621\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398207; batch adversarial loss: 0.534266\n",
      "epoch 165; iter: 0; batch classifier loss: 0.416713; batch adversarial loss: 0.534346\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366841; batch adversarial loss: 0.592882\n",
      "epoch 167; iter: 0; batch classifier loss: 0.455531; batch adversarial loss: 0.534158\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352474; batch adversarial loss: 0.534114\n",
      "epoch 169; iter: 0; batch classifier loss: 0.287332; batch adversarial loss: 0.505920\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397222; batch adversarial loss: 0.527357\n",
      "epoch 171; iter: 0; batch classifier loss: 0.361130; batch adversarial loss: 0.498070\n",
      "epoch 172; iter: 0; batch classifier loss: 0.434888; batch adversarial loss: 0.555261\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357360; batch adversarial loss: 0.572776\n",
      "epoch 174; iter: 0; batch classifier loss: 0.398533; batch adversarial loss: 0.563587\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313056; batch adversarial loss: 0.602446\n",
      "epoch 176; iter: 0; batch classifier loss: 0.359486; batch adversarial loss: 0.536191\n",
      "epoch 177; iter: 0; batch classifier loss: 0.373575; batch adversarial loss: 0.515933\n",
      "epoch 178; iter: 0; batch classifier loss: 0.453460; batch adversarial loss: 0.553844\n",
      "epoch 179; iter: 0; batch classifier loss: 0.425515; batch adversarial loss: 0.591771\n",
      "epoch 180; iter: 0; batch classifier loss: 0.487849; batch adversarial loss: 0.572180\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387138; batch adversarial loss: 0.498174\n",
      "epoch 182; iter: 0; batch classifier loss: 0.452193; batch adversarial loss: 0.525361\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393448; batch adversarial loss: 0.496704\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353099; batch adversarial loss: 0.505693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349186; batch adversarial loss: 0.565977\n",
      "epoch 186; iter: 0; batch classifier loss: 0.430722; batch adversarial loss: 0.514808\n",
      "epoch 187; iter: 0; batch classifier loss: 0.380472; batch adversarial loss: 0.486363\n",
      "epoch 188; iter: 0; batch classifier loss: 0.317948; batch adversarial loss: 0.603297\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384714; batch adversarial loss: 0.419738\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372647; batch adversarial loss: 0.515600\n",
      "epoch 191; iter: 0; batch classifier loss: 0.326407; batch adversarial loss: 0.544320\n",
      "epoch 192; iter: 0; batch classifier loss: 0.456956; batch adversarial loss: 0.563227\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307807; batch adversarial loss: 0.601294\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349527; batch adversarial loss: 0.478289\n",
      "epoch 195; iter: 0; batch classifier loss: 0.405215; batch adversarial loss: 0.545817\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362759; batch adversarial loss: 0.591670\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340676; batch adversarial loss: 0.554134\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372612; batch adversarial loss: 0.553605\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374037; batch adversarial loss: 0.573469\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724701; batch adversarial loss: 0.670540\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604176; batch adversarial loss: 0.650302\n",
      "epoch 2; iter: 0; batch classifier loss: 0.588639; batch adversarial loss: 0.639489\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581667; batch adversarial loss: 0.665504\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574278; batch adversarial loss: 0.647812\n",
      "epoch 5; iter: 0; batch classifier loss: 0.500595; batch adversarial loss: 0.602533\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491110; batch adversarial loss: 0.599860\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555485; batch adversarial loss: 0.633900\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513383; batch adversarial loss: 0.582801\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535841; batch adversarial loss: 0.601840\n",
      "epoch 10; iter: 0; batch classifier loss: 0.595546; batch adversarial loss: 0.578269\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554973; batch adversarial loss: 0.604723\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560975; batch adversarial loss: 0.576091\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517182; batch adversarial loss: 0.493959\n",
      "epoch 14; iter: 0; batch classifier loss: 0.519943; batch adversarial loss: 0.561881\n",
      "epoch 15; iter: 0; batch classifier loss: 0.476407; batch adversarial loss: 0.696548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484801; batch adversarial loss: 0.568966\n",
      "epoch 17; iter: 0; batch classifier loss: 0.483383; batch adversarial loss: 0.560517\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456756; batch adversarial loss: 0.582014\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521483; batch adversarial loss: 0.561452\n",
      "epoch 20; iter: 0; batch classifier loss: 0.481798; batch adversarial loss: 0.583557\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495476; batch adversarial loss: 0.522556\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509317; batch adversarial loss: 0.616590\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454075; batch adversarial loss: 0.570105\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454961; batch adversarial loss: 0.547083\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488360; batch adversarial loss: 0.605445\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460215; batch adversarial loss: 0.507557\n",
      "epoch 27; iter: 0; batch classifier loss: 0.544572; batch adversarial loss: 0.589453\n",
      "epoch 28; iter: 0; batch classifier loss: 0.551949; batch adversarial loss: 0.514022\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497347; batch adversarial loss: 0.558169\n",
      "epoch 30; iter: 0; batch classifier loss: 0.546805; batch adversarial loss: 0.557369\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488005; batch adversarial loss: 0.609877\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490486; batch adversarial loss: 0.503933\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459555; batch adversarial loss: 0.544857\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447017; batch adversarial loss: 0.570344\n",
      "epoch 35; iter: 0; batch classifier loss: 0.371998; batch adversarial loss: 0.531628\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505785; batch adversarial loss: 0.561531\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450906; batch adversarial loss: 0.463182\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452036; batch adversarial loss: 0.588094\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414260; batch adversarial loss: 0.582896\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443265; batch adversarial loss: 0.597559\n",
      "epoch 41; iter: 0; batch classifier loss: 0.457350; batch adversarial loss: 0.599104\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471078; batch adversarial loss: 0.596035\n",
      "epoch 43; iter: 0; batch classifier loss: 0.515752; batch adversarial loss: 0.545362\n",
      "epoch 44; iter: 0; batch classifier loss: 0.385300; batch adversarial loss: 0.518587\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498292; batch adversarial loss: 0.526163\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471606; batch adversarial loss: 0.445187\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429605; batch adversarial loss: 0.571324\n",
      "epoch 48; iter: 0; batch classifier loss: 0.502077; batch adversarial loss: 0.552870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.496649; batch adversarial loss: 0.535565\n",
      "epoch 50; iter: 0; batch classifier loss: 0.504738; batch adversarial loss: 0.455094\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438891; batch adversarial loss: 0.616283\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426742; batch adversarial loss: 0.500235\n",
      "epoch 53; iter: 0; batch classifier loss: 0.490214; batch adversarial loss: 0.509070\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438553; batch adversarial loss: 0.481708\n",
      "epoch 55; iter: 0; batch classifier loss: 0.435924; batch adversarial loss: 0.535699\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466584; batch adversarial loss: 0.582289\n",
      "epoch 57; iter: 0; batch classifier loss: 0.492282; batch adversarial loss: 0.606764\n",
      "epoch 58; iter: 0; batch classifier loss: 0.515148; batch adversarial loss: 0.542703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.409688; batch adversarial loss: 0.582037\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425889; batch adversarial loss: 0.461319\n",
      "epoch 61; iter: 0; batch classifier loss: 0.462130; batch adversarial loss: 0.482285\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446258; batch adversarial loss: 0.500805\n",
      "epoch 63; iter: 0; batch classifier loss: 0.499579; batch adversarial loss: 0.624874\n",
      "epoch 64; iter: 0; batch classifier loss: 0.490770; batch adversarial loss: 0.526902\n",
      "epoch 65; iter: 0; batch classifier loss: 0.361587; batch adversarial loss: 0.526046\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426891; batch adversarial loss: 0.507983\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416880; batch adversarial loss: 0.561852\n",
      "epoch 68; iter: 0; batch classifier loss: 0.368671; batch adversarial loss: 0.571700\n",
      "epoch 69; iter: 0; batch classifier loss: 0.408138; batch adversarial loss: 0.516645\n",
      "epoch 70; iter: 0; batch classifier loss: 0.485515; batch adversarial loss: 0.518465\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393788; batch adversarial loss: 0.580798\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438693; batch adversarial loss: 0.506826\n",
      "epoch 73; iter: 0; batch classifier loss: 0.430860; batch adversarial loss: 0.580095\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426083; batch adversarial loss: 0.553560\n",
      "epoch 75; iter: 0; batch classifier loss: 0.459299; batch adversarial loss: 0.479371\n",
      "epoch 76; iter: 0; batch classifier loss: 0.389132; batch adversarial loss: 0.508188\n",
      "epoch 77; iter: 0; batch classifier loss: 0.491100; batch adversarial loss: 0.572088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439485; batch adversarial loss: 0.550444\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391405; batch adversarial loss: 0.553456\n",
      "epoch 80; iter: 0; batch classifier loss: 0.487205; batch adversarial loss: 0.509384\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384175; batch adversarial loss: 0.471506\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390042; batch adversarial loss: 0.492935\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412236; batch adversarial loss: 0.545556\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400381; batch adversarial loss: 0.580170\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408210; batch adversarial loss: 0.587793\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425269; batch adversarial loss: 0.543077\n",
      "epoch 87; iter: 0; batch classifier loss: 0.403279; batch adversarial loss: 0.499765\n",
      "epoch 88; iter: 0; batch classifier loss: 0.475846; batch adversarial loss: 0.524887\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415615; batch adversarial loss: 0.594101\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350689; batch adversarial loss: 0.532458\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387295; batch adversarial loss: 0.617583\n",
      "epoch 92; iter: 0; batch classifier loss: 0.426785; batch adversarial loss: 0.580068\n",
      "epoch 93; iter: 0; batch classifier loss: 0.476541; batch adversarial loss: 0.564068\n",
      "epoch 94; iter: 0; batch classifier loss: 0.349799; batch adversarial loss: 0.554847\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422111; batch adversarial loss: 0.571204\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417463; batch adversarial loss: 0.572172\n",
      "epoch 97; iter: 0; batch classifier loss: 0.311752; batch adversarial loss: 0.554538\n",
      "epoch 98; iter: 0; batch classifier loss: 0.435900; batch adversarial loss: 0.497315\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378837; batch adversarial loss: 0.499765\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398073; batch adversarial loss: 0.608147\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336191; batch adversarial loss: 0.628939\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409465; batch adversarial loss: 0.582297\n",
      "epoch 103; iter: 0; batch classifier loss: 0.478992; batch adversarial loss: 0.553715\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385807; batch adversarial loss: 0.489688\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378765; batch adversarial loss: 0.526839\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371129; batch adversarial loss: 0.553555\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377269; batch adversarial loss: 0.571460\n",
      "epoch 108; iter: 0; batch classifier loss: 0.304547; batch adversarial loss: 0.581928\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400888; batch adversarial loss: 0.516513\n",
      "epoch 110; iter: 0; batch classifier loss: 0.417822; batch adversarial loss: 0.580228\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409158; batch adversarial loss: 0.499573\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339766; batch adversarial loss: 0.606531\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358848; batch adversarial loss: 0.535640\n",
      "epoch 114; iter: 0; batch classifier loss: 0.309808; batch adversarial loss: 0.607912\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411624; batch adversarial loss: 0.526189\n",
      "epoch 116; iter: 0; batch classifier loss: 0.419525; batch adversarial loss: 0.563160\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381013; batch adversarial loss: 0.615446\n",
      "epoch 118; iter: 0; batch classifier loss: 0.429232; batch adversarial loss: 0.590123\n",
      "epoch 119; iter: 0; batch classifier loss: 0.473551; batch adversarial loss: 0.616076\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401305; batch adversarial loss: 0.597894\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320128; batch adversarial loss: 0.562490\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367990; batch adversarial loss: 0.608417\n",
      "epoch 123; iter: 0; batch classifier loss: 0.405612; batch adversarial loss: 0.544143\n",
      "epoch 124; iter: 0; batch classifier loss: 0.302160; batch adversarial loss: 0.471978\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410184; batch adversarial loss: 0.634190\n",
      "epoch 126; iter: 0; batch classifier loss: 0.307190; batch adversarial loss: 0.570647\n",
      "epoch 127; iter: 0; batch classifier loss: 0.328726; batch adversarial loss: 0.591140\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346551; batch adversarial loss: 0.572308\n",
      "epoch 129; iter: 0; batch classifier loss: 0.353347; batch adversarial loss: 0.507120\n",
      "epoch 130; iter: 0; batch classifier loss: 0.418610; batch adversarial loss: 0.591817\n",
      "epoch 131; iter: 0; batch classifier loss: 0.434210; batch adversarial loss: 0.518224\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353599; batch adversarial loss: 0.681768\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350235; batch adversarial loss: 0.535238\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394751; batch adversarial loss: 0.482029\n",
      "epoch 135; iter: 0; batch classifier loss: 0.379249; batch adversarial loss: 0.555400\n",
      "epoch 136; iter: 0; batch classifier loss: 0.329554; batch adversarial loss: 0.517481\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368237; batch adversarial loss: 0.562588\n",
      "epoch 138; iter: 0; batch classifier loss: 0.409226; batch adversarial loss: 0.536628\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379763; batch adversarial loss: 0.481740\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387612; batch adversarial loss: 0.517755\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339448; batch adversarial loss: 0.544989\n",
      "epoch 142; iter: 0; batch classifier loss: 0.475806; batch adversarial loss: 0.499066\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365571; batch adversarial loss: 0.571670\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362718; batch adversarial loss: 0.581349\n",
      "epoch 145; iter: 0; batch classifier loss: 0.448873; batch adversarial loss: 0.580487\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363922; batch adversarial loss: 0.524460\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372154; batch adversarial loss: 0.606716\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395522; batch adversarial loss: 0.591956\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363399; batch adversarial loss: 0.634372\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352046; batch adversarial loss: 0.518299\n",
      "epoch 151; iter: 0; batch classifier loss: 0.301941; batch adversarial loss: 0.578795\n",
      "epoch 152; iter: 0; batch classifier loss: 0.327653; batch adversarial loss: 0.551773\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336730; batch adversarial loss: 0.590169\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390350; batch adversarial loss: 0.581885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.392488; batch adversarial loss: 0.552129\n",
      "epoch 156; iter: 0; batch classifier loss: 0.327401; batch adversarial loss: 0.491822\n",
      "epoch 157; iter: 0; batch classifier loss: 0.478577; batch adversarial loss: 0.482036\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369940; batch adversarial loss: 0.607506\n",
      "epoch 159; iter: 0; batch classifier loss: 0.355049; batch adversarial loss: 0.526663\n",
      "epoch 160; iter: 0; batch classifier loss: 0.388301; batch adversarial loss: 0.508151\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412753; batch adversarial loss: 0.518372\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365652; batch adversarial loss: 0.481299\n",
      "epoch 163; iter: 0; batch classifier loss: 0.417065; batch adversarial loss: 0.499486\n",
      "epoch 164; iter: 0; batch classifier loss: 0.396673; batch adversarial loss: 0.516978\n",
      "epoch 165; iter: 0; batch classifier loss: 0.368161; batch adversarial loss: 0.552477\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349837; batch adversarial loss: 0.489056\n",
      "epoch 167; iter: 0; batch classifier loss: 0.280888; batch adversarial loss: 0.672518\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375154; batch adversarial loss: 0.498328\n",
      "epoch 169; iter: 0; batch classifier loss: 0.396050; batch adversarial loss: 0.591267\n",
      "epoch 170; iter: 0; batch classifier loss: 0.295927; batch adversarial loss: 0.590360\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392439; batch adversarial loss: 0.581681\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378355; batch adversarial loss: 0.518175\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360514; batch adversarial loss: 0.553607\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399251; batch adversarial loss: 0.605374\n",
      "epoch 175; iter: 0; batch classifier loss: 0.312920; batch adversarial loss: 0.554221\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376621; batch adversarial loss: 0.644701\n",
      "epoch 177; iter: 0; batch classifier loss: 0.322603; batch adversarial loss: 0.544727\n",
      "epoch 178; iter: 0; batch classifier loss: 0.446158; batch adversarial loss: 0.607943\n",
      "epoch 179; iter: 0; batch classifier loss: 0.441307; batch adversarial loss: 0.536903\n",
      "epoch 180; iter: 0; batch classifier loss: 0.486500; batch adversarial loss: 0.591112\n",
      "epoch 181; iter: 0; batch classifier loss: 0.290587; batch adversarial loss: 0.599193\n",
      "epoch 182; iter: 0; batch classifier loss: 0.301187; batch adversarial loss: 0.617077\n",
      "epoch 183; iter: 0; batch classifier loss: 0.316619; batch adversarial loss: 0.609111\n",
      "epoch 184; iter: 0; batch classifier loss: 0.388985; batch adversarial loss: 0.543540\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303984; batch adversarial loss: 0.489999\n",
      "epoch 186; iter: 0; batch classifier loss: 0.295666; batch adversarial loss: 0.553378\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358784; batch adversarial loss: 0.544588\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348215; batch adversarial loss: 0.536553\n",
      "epoch 189; iter: 0; batch classifier loss: 0.418730; batch adversarial loss: 0.579070\n",
      "epoch 190; iter: 0; batch classifier loss: 0.441334; batch adversarial loss: 0.571120\n",
      "epoch 191; iter: 0; batch classifier loss: 0.292394; batch adversarial loss: 0.527045\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342302; batch adversarial loss: 0.597379\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300781; batch adversarial loss: 0.490911\n",
      "epoch 194; iter: 0; batch classifier loss: 0.346849; batch adversarial loss: 0.589455\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363752; batch adversarial loss: 0.536460\n",
      "epoch 196; iter: 0; batch classifier loss: 0.408294; batch adversarial loss: 0.517507\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368265; batch adversarial loss: 0.499658\n",
      "epoch 198; iter: 0; batch classifier loss: 0.305831; batch adversarial loss: 0.544647\n",
      "epoch 199; iter: 0; batch classifier loss: 0.404845; batch adversarial loss: 0.535590\n",
      "epoch 0; iter: 0; batch classifier loss: 0.781667; batch adversarial loss: 0.644894\n",
      "epoch 1; iter: 0; batch classifier loss: 0.617507; batch adversarial loss: 0.654508\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652409; batch adversarial loss: 0.624769\n",
      "epoch 3; iter: 0; batch classifier loss: 0.535593; batch adversarial loss: 0.595126\n",
      "epoch 4; iter: 0; batch classifier loss: 0.457789; batch adversarial loss: 0.617432\n",
      "epoch 5; iter: 0; batch classifier loss: 0.499360; batch adversarial loss: 0.652322\n",
      "epoch 6; iter: 0; batch classifier loss: 0.484076; batch adversarial loss: 0.631642\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548517; batch adversarial loss: 0.630199\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519464; batch adversarial loss: 0.561999\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556137; batch adversarial loss: 0.585293\n",
      "epoch 10; iter: 0; batch classifier loss: 0.495454; batch adversarial loss: 0.615696\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495169; batch adversarial loss: 0.617006\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509415; batch adversarial loss: 0.629149\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525991; batch adversarial loss: 0.565756\n",
      "epoch 14; iter: 0; batch classifier loss: 0.570615; batch adversarial loss: 0.619787\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541055; batch adversarial loss: 0.576197\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525159; batch adversarial loss: 0.593109\n",
      "epoch 17; iter: 0; batch classifier loss: 0.457188; batch adversarial loss: 0.603176\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533264; batch adversarial loss: 0.529884\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500133; batch adversarial loss: 0.552942\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556769; batch adversarial loss: 0.534434\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504840; batch adversarial loss: 0.501282\n",
      "epoch 22; iter: 0; batch classifier loss: 0.510270; batch adversarial loss: 0.585335\n",
      "epoch 23; iter: 0; batch classifier loss: 0.594103; batch adversarial loss: 0.557750\n",
      "epoch 24; iter: 0; batch classifier loss: 0.552890; batch adversarial loss: 0.541487\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485411; batch adversarial loss: 0.533096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.418008; batch adversarial loss: 0.611702\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450731; batch adversarial loss: 0.529625\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475954; batch adversarial loss: 0.471119\n",
      "epoch 29; iter: 0; batch classifier loss: 0.418190; batch adversarial loss: 0.513115\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510718; batch adversarial loss: 0.552067\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447458; batch adversarial loss: 0.579381\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498687; batch adversarial loss: 0.524447\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450391; batch adversarial loss: 0.500453\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511062; batch adversarial loss: 0.543926\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453005; batch adversarial loss: 0.533857\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495160; batch adversarial loss: 0.498040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454319; batch adversarial loss: 0.542087\n",
      "epoch 38; iter: 0; batch classifier loss: 0.410171; batch adversarial loss: 0.557212\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447233; batch adversarial loss: 0.487060\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447072; batch adversarial loss: 0.499688\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470266; batch adversarial loss: 0.618144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400939; batch adversarial loss: 0.563525\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439214; batch adversarial loss: 0.617432\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493120; batch adversarial loss: 0.600090\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395104; batch adversarial loss: 0.497995\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441855; batch adversarial loss: 0.517765\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432095; batch adversarial loss: 0.582884\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451389; batch adversarial loss: 0.497726\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440943; batch adversarial loss: 0.554711\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414417; batch adversarial loss: 0.524629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.405795; batch adversarial loss: 0.536977\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423692; batch adversarial loss: 0.591312\n",
      "epoch 53; iter: 0; batch classifier loss: 0.488408; batch adversarial loss: 0.488438\n",
      "epoch 54; iter: 0; batch classifier loss: 0.388845; batch adversarial loss: 0.552645\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415213; batch adversarial loss: 0.555115\n",
      "epoch 56; iter: 0; batch classifier loss: 0.384006; batch adversarial loss: 0.524698\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393577; batch adversarial loss: 0.564070\n",
      "epoch 58; iter: 0; batch classifier loss: 0.416786; batch adversarial loss: 0.636969\n",
      "epoch 59; iter: 0; batch classifier loss: 0.492927; batch adversarial loss: 0.459007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420594; batch adversarial loss: 0.583283\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414325; batch adversarial loss: 0.598631\n",
      "epoch 62; iter: 0; batch classifier loss: 0.372380; batch adversarial loss: 0.469416\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378989; batch adversarial loss: 0.535289\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426904; batch adversarial loss: 0.505563\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442508; batch adversarial loss: 0.522619\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409531; batch adversarial loss: 0.593993\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340502; batch adversarial loss: 0.626818\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397179; batch adversarial loss: 0.579839\n",
      "epoch 69; iter: 0; batch classifier loss: 0.360062; batch adversarial loss: 0.590533\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428168; batch adversarial loss: 0.508196\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423922; batch adversarial loss: 0.564090\n",
      "epoch 72; iter: 0; batch classifier loss: 0.485378; batch adversarial loss: 0.509711\n",
      "epoch 73; iter: 0; batch classifier loss: 0.338060; batch adversarial loss: 0.570488\n",
      "epoch 74; iter: 0; batch classifier loss: 0.440649; batch adversarial loss: 0.545208\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433700; batch adversarial loss: 0.553642\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405311; batch adversarial loss: 0.580708\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413592; batch adversarial loss: 0.471706\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368222; batch adversarial loss: 0.489339\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420903; batch adversarial loss: 0.590082\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419036; batch adversarial loss: 0.564229\n",
      "epoch 81; iter: 0; batch classifier loss: 0.319960; batch adversarial loss: 0.434643\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398806; batch adversarial loss: 0.608583\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345002; batch adversarial loss: 0.472509\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380156; batch adversarial loss: 0.546578\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399250; batch adversarial loss: 0.534376\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379014; batch adversarial loss: 0.589473\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416021; batch adversarial loss: 0.572947\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354930; batch adversarial loss: 0.522623\n",
      "epoch 89; iter: 0; batch classifier loss: 0.351246; batch adversarial loss: 0.580833\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373828; batch adversarial loss: 0.561811\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365733; batch adversarial loss: 0.627947\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389846; batch adversarial loss: 0.572189\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421769; batch adversarial loss: 0.527004\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380154; batch adversarial loss: 0.534601\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395350; batch adversarial loss: 0.533572\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386699; batch adversarial loss: 0.452127\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418737; batch adversarial loss: 0.571899\n",
      "epoch 98; iter: 0; batch classifier loss: 0.449907; batch adversarial loss: 0.536252\n",
      "epoch 99; iter: 0; batch classifier loss: 0.334256; batch adversarial loss: 0.524633\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390346; batch adversarial loss: 0.534274\n",
      "epoch 101; iter: 0; batch classifier loss: 0.458014; batch adversarial loss: 0.554316\n",
      "epoch 102; iter: 0; batch classifier loss: 0.451457; batch adversarial loss: 0.564705\n",
      "epoch 103; iter: 0; batch classifier loss: 0.460138; batch adversarial loss: 0.545395\n",
      "epoch 104; iter: 0; batch classifier loss: 0.447030; batch adversarial loss: 0.555612\n",
      "epoch 105; iter: 0; batch classifier loss: 0.468896; batch adversarial loss: 0.524520\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384364; batch adversarial loss: 0.554377\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402382; batch adversarial loss: 0.516889\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379711; batch adversarial loss: 0.460342\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391334; batch adversarial loss: 0.553671\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359153; batch adversarial loss: 0.628489\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384705; batch adversarial loss: 0.644422\n",
      "epoch 112; iter: 0; batch classifier loss: 0.318357; batch adversarial loss: 0.608264\n",
      "epoch 113; iter: 0; batch classifier loss: 0.341438; batch adversarial loss: 0.488973\n",
      "epoch 114; iter: 0; batch classifier loss: 0.419754; batch adversarial loss: 0.583666\n",
      "epoch 115; iter: 0; batch classifier loss: 0.378766; batch adversarial loss: 0.629017\n",
      "epoch 116; iter: 0; batch classifier loss: 0.445900; batch adversarial loss: 0.525105\n",
      "epoch 117; iter: 0; batch classifier loss: 0.420539; batch adversarial loss: 0.472379\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373016; batch adversarial loss: 0.543571\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381402; batch adversarial loss: 0.479917\n",
      "epoch 120; iter: 0; batch classifier loss: 0.317410; batch adversarial loss: 0.636975\n",
      "epoch 121; iter: 0; batch classifier loss: 0.516210; batch adversarial loss: 0.563449\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326198; batch adversarial loss: 0.524632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.476127; batch adversarial loss: 0.534516\n",
      "epoch 124; iter: 0; batch classifier loss: 0.324527; batch adversarial loss: 0.543947\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415818; batch adversarial loss: 0.526784\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361458; batch adversarial loss: 0.563000\n",
      "epoch 127; iter: 0; batch classifier loss: 0.414050; batch adversarial loss: 0.488571\n",
      "epoch 128; iter: 0; batch classifier loss: 0.431455; batch adversarial loss: 0.544741\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337233; batch adversarial loss: 0.571110\n",
      "epoch 130; iter: 0; batch classifier loss: 0.471304; batch adversarial loss: 0.599864\n",
      "epoch 131; iter: 0; batch classifier loss: 0.448654; batch adversarial loss: 0.617917\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392791; batch adversarial loss: 0.515983\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377579; batch adversarial loss: 0.554140\n",
      "epoch 134; iter: 0; batch classifier loss: 0.321457; batch adversarial loss: 0.535108\n",
      "epoch 135; iter: 0; batch classifier loss: 0.438086; batch adversarial loss: 0.536300\n",
      "epoch 136; iter: 0; batch classifier loss: 0.465105; batch adversarial loss: 0.508367\n",
      "epoch 137; iter: 0; batch classifier loss: 0.416871; batch adversarial loss: 0.525524\n",
      "epoch 138; iter: 0; batch classifier loss: 0.416382; batch adversarial loss: 0.526764\n",
      "epoch 139; iter: 0; batch classifier loss: 0.297534; batch adversarial loss: 0.534950\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325880; batch adversarial loss: 0.552990\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358478; batch adversarial loss: 0.507660\n",
      "epoch 142; iter: 0; batch classifier loss: 0.306443; batch adversarial loss: 0.554648\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370706; batch adversarial loss: 0.545196\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377871; batch adversarial loss: 0.497121\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376056; batch adversarial loss: 0.488972\n",
      "epoch 146; iter: 0; batch classifier loss: 0.290315; batch adversarial loss: 0.646733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.323264; batch adversarial loss: 0.478101\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397737; batch adversarial loss: 0.572094\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374018; batch adversarial loss: 0.554170\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385733; batch adversarial loss: 0.571589\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372025; batch adversarial loss: 0.516687\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385782; batch adversarial loss: 0.544644\n",
      "epoch 153; iter: 0; batch classifier loss: 0.318737; batch adversarial loss: 0.554368\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357458; batch adversarial loss: 0.588743\n",
      "epoch 155; iter: 0; batch classifier loss: 0.378054; batch adversarial loss: 0.525592\n",
      "epoch 156; iter: 0; batch classifier loss: 0.360822; batch adversarial loss: 0.601824\n",
      "epoch 157; iter: 0; batch classifier loss: 0.443556; batch adversarial loss: 0.571657\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330807; batch adversarial loss: 0.581208\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383778; batch adversarial loss: 0.525036\n",
      "epoch 160; iter: 0; batch classifier loss: 0.405839; batch adversarial loss: 0.544433\n",
      "epoch 161; iter: 0; batch classifier loss: 0.402622; batch adversarial loss: 0.591074\n",
      "epoch 162; iter: 0; batch classifier loss: 0.301828; batch adversarial loss: 0.582161\n",
      "epoch 163; iter: 0; batch classifier loss: 0.446442; batch adversarial loss: 0.461227\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350759; batch adversarial loss: 0.553665\n",
      "epoch 165; iter: 0; batch classifier loss: 0.320982; batch adversarial loss: 0.562272\n",
      "epoch 166; iter: 0; batch classifier loss: 0.375918; batch adversarial loss: 0.517651\n",
      "epoch 167; iter: 0; batch classifier loss: 0.408906; batch adversarial loss: 0.563653\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357432; batch adversarial loss: 0.534740\n",
      "epoch 169; iter: 0; batch classifier loss: 0.417357; batch adversarial loss: 0.637043\n",
      "epoch 170; iter: 0; batch classifier loss: 0.300508; batch adversarial loss: 0.460477\n",
      "epoch 171; iter: 0; batch classifier loss: 0.453619; batch adversarial loss: 0.592825\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354478; batch adversarial loss: 0.525414\n",
      "epoch 173; iter: 0; batch classifier loss: 0.366769; batch adversarial loss: 0.517156\n",
      "epoch 174; iter: 0; batch classifier loss: 0.306876; batch adversarial loss: 0.610106\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326008; batch adversarial loss: 0.564059\n",
      "epoch 176; iter: 0; batch classifier loss: 0.429297; batch adversarial loss: 0.571130\n",
      "epoch 177; iter: 0; batch classifier loss: 0.420603; batch adversarial loss: 0.516250\n",
      "epoch 178; iter: 0; batch classifier loss: 0.439748; batch adversarial loss: 0.488866\n",
      "epoch 179; iter: 0; batch classifier loss: 0.308304; batch adversarial loss: 0.563645\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360505; batch adversarial loss: 0.563550\n",
      "epoch 181; iter: 0; batch classifier loss: 0.378748; batch adversarial loss: 0.610524\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379968; batch adversarial loss: 0.544961\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342406; batch adversarial loss: 0.517614\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383655; batch adversarial loss: 0.534500\n",
      "epoch 185; iter: 0; batch classifier loss: 0.313476; batch adversarial loss: 0.573194\n",
      "epoch 186; iter: 0; batch classifier loss: 0.400896; batch adversarial loss: 0.508436\n",
      "epoch 187; iter: 0; batch classifier loss: 0.394993; batch adversarial loss: 0.489021\n",
      "epoch 188; iter: 0; batch classifier loss: 0.284689; batch adversarial loss: 0.618427\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335710; batch adversarial loss: 0.506874\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336434; batch adversarial loss: 0.479876\n",
      "epoch 191; iter: 0; batch classifier loss: 0.400855; batch adversarial loss: 0.545287\n",
      "epoch 192; iter: 0; batch classifier loss: 0.395997; batch adversarial loss: 0.572221\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344871; batch adversarial loss: 0.534600\n",
      "epoch 194; iter: 0; batch classifier loss: 0.339593; batch adversarial loss: 0.655089\n",
      "epoch 195; iter: 0; batch classifier loss: 0.523012; batch adversarial loss: 0.582316\n",
      "epoch 196; iter: 0; batch classifier loss: 0.428996; batch adversarial loss: 0.580465\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396785; batch adversarial loss: 0.627732\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359440; batch adversarial loss: 0.562342\n",
      "epoch 199; iter: 0; batch classifier loss: 0.382095; batch adversarial loss: 0.645532\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704302; batch adversarial loss: 0.775367\n",
      "epoch 1; iter: 0; batch classifier loss: 0.698330; batch adversarial loss: 0.799292\n",
      "epoch 2; iter: 0; batch classifier loss: 0.915003; batch adversarial loss: 0.834165\n",
      "epoch 3; iter: 0; batch classifier loss: 0.907213; batch adversarial loss: 0.778215\n",
      "epoch 4; iter: 0; batch classifier loss: 0.745100; batch adversarial loss: 0.688519\n",
      "epoch 5; iter: 0; batch classifier loss: 0.636906; batch adversarial loss: 0.653833\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548387; batch adversarial loss: 0.630511\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524836; batch adversarial loss: 0.608594\n",
      "epoch 8; iter: 0; batch classifier loss: 0.600159; batch adversarial loss: 0.652195\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472489; batch adversarial loss: 0.596640\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517843; batch adversarial loss: 0.526048\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504321; batch adversarial loss: 0.601175\n",
      "epoch 12; iter: 0; batch classifier loss: 0.479966; batch adversarial loss: 0.589571\n",
      "epoch 13; iter: 0; batch classifier loss: 0.646145; batch adversarial loss: 0.570049\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518837; batch adversarial loss: 0.560383\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533536; batch adversarial loss: 0.574202\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512937; batch adversarial loss: 0.615413\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453198; batch adversarial loss: 0.547297\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559292; batch adversarial loss: 0.549230\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535071; batch adversarial loss: 0.586655\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492356; batch adversarial loss: 0.570206\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539692; batch adversarial loss: 0.591846\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484371; batch adversarial loss: 0.522000\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493836; batch adversarial loss: 0.475133\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454205; batch adversarial loss: 0.579010\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470687; batch adversarial loss: 0.521892\n",
      "epoch 26; iter: 0; batch classifier loss: 0.421514; batch adversarial loss: 0.616237\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487200; batch adversarial loss: 0.570887\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472391; batch adversarial loss: 0.528406\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506048; batch adversarial loss: 0.627276\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402502; batch adversarial loss: 0.568088\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454171; batch adversarial loss: 0.492035\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478243; batch adversarial loss: 0.570805\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465887; batch adversarial loss: 0.534274\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420396; batch adversarial loss: 0.520415\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484432; batch adversarial loss: 0.570466\n",
      "epoch 36; iter: 0; batch classifier loss: 0.506393; batch adversarial loss: 0.649683\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499500; batch adversarial loss: 0.517175\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422661; batch adversarial loss: 0.530652\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435142; batch adversarial loss: 0.548140\n",
      "epoch 40; iter: 0; batch classifier loss: 0.527104; batch adversarial loss: 0.612463\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433945; batch adversarial loss: 0.535922\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411318; batch adversarial loss: 0.502647\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441270; batch adversarial loss: 0.609199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.508898; batch adversarial loss: 0.548089\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445259; batch adversarial loss: 0.571463\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474060; batch adversarial loss: 0.384076\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455491; batch adversarial loss: 0.481094\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486090; batch adversarial loss: 0.561309\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404412; batch adversarial loss: 0.554475\n",
      "epoch 50; iter: 0; batch classifier loss: 0.405948; batch adversarial loss: 0.513973\n",
      "epoch 51; iter: 0; batch classifier loss: 0.385556; batch adversarial loss: 0.564479\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433798; batch adversarial loss: 0.481939\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399207; batch adversarial loss: 0.607665\n",
      "epoch 54; iter: 0; batch classifier loss: 0.494667; batch adversarial loss: 0.608808\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431009; batch adversarial loss: 0.590990\n",
      "epoch 56; iter: 0; batch classifier loss: 0.340495; batch adversarial loss: 0.589172\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472182; batch adversarial loss: 0.525992\n",
      "epoch 58; iter: 0; batch classifier loss: 0.510029; batch adversarial loss: 0.614637\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411233; batch adversarial loss: 0.543382\n",
      "epoch 60; iter: 0; batch classifier loss: 0.317712; batch adversarial loss: 0.537508\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408213; batch adversarial loss: 0.510197\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439127; batch adversarial loss: 0.445684\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400642; batch adversarial loss: 0.455866\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394405; batch adversarial loss: 0.563036\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414135; batch adversarial loss: 0.580575\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428903; batch adversarial loss: 0.535626\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351820; batch adversarial loss: 0.535094\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439657; batch adversarial loss: 0.608089\n",
      "epoch 69; iter: 0; batch classifier loss: 0.489698; batch adversarial loss: 0.500402\n",
      "epoch 70; iter: 0; batch classifier loss: 0.390545; batch adversarial loss: 0.490674\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365742; batch adversarial loss: 0.436945\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412626; batch adversarial loss: 0.553831\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394064; batch adversarial loss: 0.634462\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408149; batch adversarial loss: 0.526713\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356183; batch adversarial loss: 0.526813\n",
      "epoch 76; iter: 0; batch classifier loss: 0.423360; batch adversarial loss: 0.615885\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409437; batch adversarial loss: 0.499531\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399637; batch adversarial loss: 0.616160\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367866; batch adversarial loss: 0.517550\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401008; batch adversarial loss: 0.517569\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421754; batch adversarial loss: 0.535818\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435158; batch adversarial loss: 0.553662\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394884; batch adversarial loss: 0.544748\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365164; batch adversarial loss: 0.553532\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416884; batch adversarial loss: 0.607143\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360244; batch adversarial loss: 0.544601\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373313; batch adversarial loss: 0.527027\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376519; batch adversarial loss: 0.607249\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394785; batch adversarial loss: 0.535534\n",
      "epoch 90; iter: 0; batch classifier loss: 0.372201; batch adversarial loss: 0.625509\n",
      "epoch 91; iter: 0; batch classifier loss: 0.325766; batch adversarial loss: 0.571589\n",
      "epoch 92; iter: 0; batch classifier loss: 0.443268; batch adversarial loss: 0.589568\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413104; batch adversarial loss: 0.590882\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373400; batch adversarial loss: 0.498753\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425693; batch adversarial loss: 0.561320\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376774; batch adversarial loss: 0.532212\n",
      "epoch 97; iter: 0; batch classifier loss: 0.490592; batch adversarial loss: 0.608293\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362123; batch adversarial loss: 0.597770\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360911; batch adversarial loss: 0.550581\n",
      "epoch 100; iter: 0; batch classifier loss: 0.366988; batch adversarial loss: 0.583197\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381881; batch adversarial loss: 0.564190\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355771; batch adversarial loss: 0.530523\n",
      "epoch 103; iter: 0; batch classifier loss: 0.475425; batch adversarial loss: 0.534821\n",
      "epoch 104; iter: 0; batch classifier loss: 0.414885; batch adversarial loss: 0.571102\n",
      "epoch 105; iter: 0; batch classifier loss: 0.463534; batch adversarial loss: 0.569015\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409335; batch adversarial loss: 0.561045\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431127; batch adversarial loss: 0.544028\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355438; batch adversarial loss: 0.528838\n",
      "epoch 109; iter: 0; batch classifier loss: 0.342981; batch adversarial loss: 0.490539\n",
      "epoch 110; iter: 0; batch classifier loss: 0.294632; batch adversarial loss: 0.534888\n",
      "epoch 111; iter: 0; batch classifier loss: 0.339924; batch adversarial loss: 0.570442\n",
      "epoch 112; iter: 0; batch classifier loss: 0.337785; batch adversarial loss: 0.554519\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406544; batch adversarial loss: 0.535130\n",
      "epoch 114; iter: 0; batch classifier loss: 0.345440; batch adversarial loss: 0.473211\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412152; batch adversarial loss: 0.534972\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345282; batch adversarial loss: 0.561833\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402452; batch adversarial loss: 0.587988\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406373; batch adversarial loss: 0.570702\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384007; batch adversarial loss: 0.486265\n",
      "epoch 120; iter: 0; batch classifier loss: 0.440441; batch adversarial loss: 0.484731\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348675; batch adversarial loss: 0.542887\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350013; batch adversarial loss: 0.624024\n",
      "epoch 123; iter: 0; batch classifier loss: 0.323242; batch adversarial loss: 0.540177\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361943; batch adversarial loss: 0.538189\n",
      "epoch 125; iter: 0; batch classifier loss: 0.424141; batch adversarial loss: 0.571837\n",
      "epoch 126; iter: 0; batch classifier loss: 0.456533; batch adversarial loss: 0.591230\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352110; batch adversarial loss: 0.615135\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357345; batch adversarial loss: 0.458054\n",
      "epoch 129; iter: 0; batch classifier loss: 0.352058; batch adversarial loss: 0.499730\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396157; batch adversarial loss: 0.677264\n",
      "epoch 131; iter: 0; batch classifier loss: 0.413352; batch adversarial loss: 0.572786\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312678; batch adversarial loss: 0.563534\n",
      "epoch 133; iter: 0; batch classifier loss: 0.298795; batch adversarial loss: 0.535498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361288; batch adversarial loss: 0.581442\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385111; batch adversarial loss: 0.563529\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346590; batch adversarial loss: 0.544172\n",
      "epoch 137; iter: 0; batch classifier loss: 0.380989; batch adversarial loss: 0.588851\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366161; batch adversarial loss: 0.472142\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367412; batch adversarial loss: 0.652792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.405354; batch adversarial loss: 0.580602\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403822; batch adversarial loss: 0.589863\n",
      "epoch 142; iter: 0; batch classifier loss: 0.261797; batch adversarial loss: 0.471438\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371859; batch adversarial loss: 0.442921\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372791; batch adversarial loss: 0.596938\n",
      "epoch 145; iter: 0; batch classifier loss: 0.357191; batch adversarial loss: 0.572307\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339562; batch adversarial loss: 0.505747\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351543; batch adversarial loss: 0.551924\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392336; batch adversarial loss: 0.661835\n",
      "epoch 149; iter: 0; batch classifier loss: 0.325883; batch adversarial loss: 0.525162\n",
      "epoch 150; iter: 0; batch classifier loss: 0.395235; batch adversarial loss: 0.523935\n",
      "epoch 151; iter: 0; batch classifier loss: 0.397160; batch adversarial loss: 0.605787\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377346; batch adversarial loss: 0.544008\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316782; batch adversarial loss: 0.544516\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363695; batch adversarial loss: 0.526379\n",
      "epoch 155; iter: 0; batch classifier loss: 0.363775; batch adversarial loss: 0.505592\n",
      "epoch 156; iter: 0; batch classifier loss: 0.286762; batch adversarial loss: 0.534288\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360700; batch adversarial loss: 0.516451\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380505; batch adversarial loss: 0.582868\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345482; batch adversarial loss: 0.588676\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353655; batch adversarial loss: 0.569873\n",
      "epoch 161; iter: 0; batch classifier loss: 0.281372; batch adversarial loss: 0.562719\n",
      "epoch 162; iter: 0; batch classifier loss: 0.375974; batch adversarial loss: 0.615993\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345436; batch adversarial loss: 0.526620\n",
      "epoch 164; iter: 0; batch classifier loss: 0.349656; batch adversarial loss: 0.605027\n",
      "epoch 165; iter: 0; batch classifier loss: 0.283722; batch adversarial loss: 0.511084\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388563; batch adversarial loss: 0.510527\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360580; batch adversarial loss: 0.588438\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327122; batch adversarial loss: 0.518362\n",
      "epoch 169; iter: 0; batch classifier loss: 0.365528; batch adversarial loss: 0.624388\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354248; batch adversarial loss: 0.553351\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385584; batch adversarial loss: 0.588898\n",
      "epoch 172; iter: 0; batch classifier loss: 0.314927; batch adversarial loss: 0.499621\n",
      "epoch 173; iter: 0; batch classifier loss: 0.320579; batch adversarial loss: 0.563300\n",
      "epoch 174; iter: 0; batch classifier loss: 0.329047; batch adversarial loss: 0.642788\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380291; batch adversarial loss: 0.563232\n",
      "epoch 176; iter: 0; batch classifier loss: 0.264634; batch adversarial loss: 0.562555\n",
      "epoch 177; iter: 0; batch classifier loss: 0.357250; batch adversarial loss: 0.545050\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309827; batch adversarial loss: 0.544651\n",
      "epoch 179; iter: 0; batch classifier loss: 0.388414; batch adversarial loss: 0.481923\n",
      "epoch 180; iter: 0; batch classifier loss: 0.319021; batch adversarial loss: 0.508413\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311358; batch adversarial loss: 0.526210\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380082; batch adversarial loss: 0.489112\n",
      "epoch 183; iter: 0; batch classifier loss: 0.365790; batch adversarial loss: 0.580202\n",
      "epoch 184; iter: 0; batch classifier loss: 0.424777; batch adversarial loss: 0.587620\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366934; batch adversarial loss: 0.561252\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342394; batch adversarial loss: 0.534150\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342656; batch adversarial loss: 0.518440\n",
      "epoch 188; iter: 0; batch classifier loss: 0.445977; batch adversarial loss: 0.441857\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340678; batch adversarial loss: 0.490053\n",
      "epoch 190; iter: 0; batch classifier loss: 0.298271; batch adversarial loss: 0.526969\n",
      "epoch 191; iter: 0; batch classifier loss: 0.286129; batch adversarial loss: 0.553460\n",
      "epoch 192; iter: 0; batch classifier loss: 0.341240; batch adversarial loss: 0.530568\n",
      "epoch 193; iter: 0; batch classifier loss: 0.365786; batch adversarial loss: 0.553014\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308010; batch adversarial loss: 0.554302\n",
      "epoch 195; iter: 0; batch classifier loss: 0.295432; batch adversarial loss: 0.605602\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359690; batch adversarial loss: 0.535531\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339144; batch adversarial loss: 0.526607\n",
      "epoch 198; iter: 0; batch classifier loss: 0.322348; batch adversarial loss: 0.716268\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329301; batch adversarial loss: 0.525656\n",
      "epoch 0; iter: 0; batch classifier loss: 0.630473; batch adversarial loss: 0.709879\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590284; batch adversarial loss: 0.654344\n",
      "epoch 2; iter: 0; batch classifier loss: 0.536734; batch adversarial loss: 0.633337\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541523; batch adversarial loss: 0.642064\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519259; batch adversarial loss: 0.597790\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569797; batch adversarial loss: 0.624468\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519201; batch adversarial loss: 0.594797\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583345; batch adversarial loss: 0.590150\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533742; batch adversarial loss: 0.565415\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545840; batch adversarial loss: 0.639546\n",
      "epoch 10; iter: 0; batch classifier loss: 0.636625; batch adversarial loss: 0.548427\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508340; batch adversarial loss: 0.554248\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509777; batch adversarial loss: 0.571914\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477808; batch adversarial loss: 0.594355\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510902; batch adversarial loss: 0.581460\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524267; batch adversarial loss: 0.509412\n",
      "epoch 16; iter: 0; batch classifier loss: 0.468501; batch adversarial loss: 0.556347\n",
      "epoch 17; iter: 0; batch classifier loss: 0.439078; batch adversarial loss: 0.561572\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522119; batch adversarial loss: 0.579456\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492160; batch adversarial loss: 0.598176\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432321; batch adversarial loss: 0.488177\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468165; batch adversarial loss: 0.597070\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463573; batch adversarial loss: 0.461189\n",
      "epoch 23; iter: 0; batch classifier loss: 0.537528; batch adversarial loss: 0.555373\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497067; batch adversarial loss: 0.530377\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492025; batch adversarial loss: 0.502678\n",
      "epoch 26; iter: 0; batch classifier loss: 0.447465; batch adversarial loss: 0.562957\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506624; batch adversarial loss: 0.516093\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486088; batch adversarial loss: 0.538442\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444964; batch adversarial loss: 0.551221\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480073; batch adversarial loss: 0.515292\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463569; batch adversarial loss: 0.542749\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425007; batch adversarial loss: 0.597734\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445987; batch adversarial loss: 0.510159\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461428; batch adversarial loss: 0.464464\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406789; batch adversarial loss: 0.577761\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461347; batch adversarial loss: 0.590517\n",
      "epoch 37; iter: 0; batch classifier loss: 0.515971; batch adversarial loss: 0.554976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.399056; batch adversarial loss: 0.545002\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430956; batch adversarial loss: 0.597094\n",
      "epoch 40; iter: 0; batch classifier loss: 0.401762; batch adversarial loss: 0.501399\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402471; batch adversarial loss: 0.527719\n",
      "epoch 42; iter: 0; batch classifier loss: 0.435042; batch adversarial loss: 0.517730\n",
      "epoch 43; iter: 0; batch classifier loss: 0.536816; batch adversarial loss: 0.571350\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438287; batch adversarial loss: 0.544614\n",
      "epoch 45; iter: 0; batch classifier loss: 0.546281; batch adversarial loss: 0.535021\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434802; batch adversarial loss: 0.562666\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399382; batch adversarial loss: 0.571438\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382636; batch adversarial loss: 0.499236\n",
      "epoch 49; iter: 0; batch classifier loss: 0.454933; batch adversarial loss: 0.544050\n",
      "epoch 50; iter: 0; batch classifier loss: 0.447464; batch adversarial loss: 0.544935\n",
      "epoch 51; iter: 0; batch classifier loss: 0.387958; batch adversarial loss: 0.571194\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417233; batch adversarial loss: 0.526488\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418146; batch adversarial loss: 0.500149\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405903; batch adversarial loss: 0.589846\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437042; batch adversarial loss: 0.607178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.369637; batch adversarial loss: 0.607306\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415514; batch adversarial loss: 0.517820\n",
      "epoch 58; iter: 0; batch classifier loss: 0.406335; batch adversarial loss: 0.553637\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357320; batch adversarial loss: 0.517708\n",
      "epoch 60; iter: 0; batch classifier loss: 0.351960; batch adversarial loss: 0.535653\n",
      "epoch 61; iter: 0; batch classifier loss: 0.358520; batch adversarial loss: 0.544549\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383978; batch adversarial loss: 0.571519\n",
      "epoch 63; iter: 0; batch classifier loss: 0.427614; batch adversarial loss: 0.508299\n",
      "epoch 64; iter: 0; batch classifier loss: 0.417734; batch adversarial loss: 0.598680\n",
      "epoch 65; iter: 0; batch classifier loss: 0.358380; batch adversarial loss: 0.589648\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395670; batch adversarial loss: 0.553704\n",
      "epoch 67; iter: 0; batch classifier loss: 0.415089; batch adversarial loss: 0.571689\n",
      "epoch 68; iter: 0; batch classifier loss: 0.465754; batch adversarial loss: 0.526700\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447400; batch adversarial loss: 0.553606\n",
      "epoch 70; iter: 0; batch classifier loss: 0.370649; batch adversarial loss: 0.562585\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446744; batch adversarial loss: 0.553539\n",
      "epoch 72; iter: 0; batch classifier loss: 0.368713; batch adversarial loss: 0.562564\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414780; batch adversarial loss: 0.545003\n",
      "epoch 74; iter: 0; batch classifier loss: 0.467457; batch adversarial loss: 0.544638\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398106; batch adversarial loss: 0.544718\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386587; batch adversarial loss: 0.526683\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442832; batch adversarial loss: 0.517680\n",
      "epoch 78; iter: 0; batch classifier loss: 0.345228; batch adversarial loss: 0.616721\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415791; batch adversarial loss: 0.507796\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420317; batch adversarial loss: 0.507849\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407342; batch adversarial loss: 0.595812\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457515; batch adversarial loss: 0.534295\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341223; batch adversarial loss: 0.572193\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381424; batch adversarial loss: 0.615408\n",
      "epoch 85; iter: 0; batch classifier loss: 0.442528; batch adversarial loss: 0.535283\n",
      "epoch 86; iter: 0; batch classifier loss: 0.364399; batch adversarial loss: 0.525331\n",
      "epoch 87; iter: 0; batch classifier loss: 0.436894; batch adversarial loss: 0.601705\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389539; batch adversarial loss: 0.507454\n",
      "epoch 89; iter: 0; batch classifier loss: 0.454289; batch adversarial loss: 0.571125\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393911; batch adversarial loss: 0.526089\n",
      "epoch 91; iter: 0; batch classifier loss: 0.454236; batch adversarial loss: 0.546321\n",
      "epoch 92; iter: 0; batch classifier loss: 0.330713; batch adversarial loss: 0.580803\n",
      "epoch 93; iter: 0; batch classifier loss: 0.451595; batch adversarial loss: 0.563966\n",
      "epoch 94; iter: 0; batch classifier loss: 0.367016; batch adversarial loss: 0.562394\n",
      "epoch 95; iter: 0; batch classifier loss: 0.383493; batch adversarial loss: 0.572345\n",
      "epoch 96; iter: 0; batch classifier loss: 0.409935; batch adversarial loss: 0.561212\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416451; batch adversarial loss: 0.573105\n",
      "epoch 98; iter: 0; batch classifier loss: 0.336473; batch adversarial loss: 0.537369\n",
      "epoch 99; iter: 0; batch classifier loss: 0.427650; batch adversarial loss: 0.500332\n",
      "epoch 100; iter: 0; batch classifier loss: 0.378255; batch adversarial loss: 0.563088\n",
      "epoch 101; iter: 0; batch classifier loss: 0.322118; batch adversarial loss: 0.562434\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374867; batch adversarial loss: 0.562756\n",
      "epoch 103; iter: 0; batch classifier loss: 0.447066; batch adversarial loss: 0.572002\n",
      "epoch 104; iter: 0; batch classifier loss: 0.325680; batch adversarial loss: 0.607097\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355450; batch adversarial loss: 0.599018\n",
      "epoch 106; iter: 0; batch classifier loss: 0.300135; batch adversarial loss: 0.553459\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402646; batch adversarial loss: 0.481383\n",
      "epoch 108; iter: 0; batch classifier loss: 0.485112; batch adversarial loss: 0.607853\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361241; batch adversarial loss: 0.526806\n",
      "epoch 110; iter: 0; batch classifier loss: 0.325573; batch adversarial loss: 0.569421\n",
      "epoch 111; iter: 0; batch classifier loss: 0.462533; batch adversarial loss: 0.544883\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381139; batch adversarial loss: 0.537295\n",
      "epoch 113; iter: 0; batch classifier loss: 0.397264; batch adversarial loss: 0.489265\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391384; batch adversarial loss: 0.655568\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358502; batch adversarial loss: 0.557485\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361793; batch adversarial loss: 0.526689\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392841; batch adversarial loss: 0.664532\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402722; batch adversarial loss: 0.480600\n",
      "epoch 119; iter: 0; batch classifier loss: 0.360129; batch adversarial loss: 0.528058\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415463; batch adversarial loss: 0.544021\n",
      "epoch 121; iter: 0; batch classifier loss: 0.251136; batch adversarial loss: 0.648840\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382518; batch adversarial loss: 0.633528\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395681; batch adversarial loss: 0.582501\n",
      "epoch 124; iter: 0; batch classifier loss: 0.434630; batch adversarial loss: 0.596570\n",
      "epoch 125; iter: 0; batch classifier loss: 0.357902; batch adversarial loss: 0.534846\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403832; batch adversarial loss: 0.505334\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371954; batch adversarial loss: 0.553470\n",
      "epoch 128; iter: 0; batch classifier loss: 0.453389; batch adversarial loss: 0.532758\n",
      "epoch 129; iter: 0; batch classifier loss: 0.417395; batch adversarial loss: 0.583411\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408762; batch adversarial loss: 0.570654\n",
      "epoch 131; iter: 0; batch classifier loss: 0.300339; batch adversarial loss: 0.590073\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371741; batch adversarial loss: 0.580770\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376694; batch adversarial loss: 0.608286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.391373; batch adversarial loss: 0.572218\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350672; batch adversarial loss: 0.535582\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404751; batch adversarial loss: 0.549990\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401083; batch adversarial loss: 0.516749\n",
      "epoch 138; iter: 0; batch classifier loss: 0.499192; batch adversarial loss: 0.539061\n",
      "epoch 139; iter: 0; batch classifier loss: 0.419011; batch adversarial loss: 0.527073\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377614; batch adversarial loss: 0.517326\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411422; batch adversarial loss: 0.543437\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363739; batch adversarial loss: 0.562115\n",
      "epoch 143; iter: 0; batch classifier loss: 0.347375; batch adversarial loss: 0.626421\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377705; batch adversarial loss: 0.572372\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355176; batch adversarial loss: 0.544227\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367424; batch adversarial loss: 0.555283\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384514; batch adversarial loss: 0.486617\n",
      "epoch 148; iter: 0; batch classifier loss: 0.456942; batch adversarial loss: 0.508262\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352315; batch adversarial loss: 0.479529\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325081; batch adversarial loss: 0.571473\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326559; batch adversarial loss: 0.571585\n",
      "epoch 152; iter: 0; batch classifier loss: 0.381087; batch adversarial loss: 0.480000\n",
      "epoch 153; iter: 0; batch classifier loss: 0.359536; batch adversarial loss: 0.523543\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372262; batch adversarial loss: 0.489779\n",
      "epoch 155; iter: 0; batch classifier loss: 0.477718; batch adversarial loss: 0.559854\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363962; batch adversarial loss: 0.543080\n",
      "epoch 157; iter: 0; batch classifier loss: 0.307855; batch adversarial loss: 0.561526\n",
      "epoch 158; iter: 0; batch classifier loss: 0.325170; batch adversarial loss: 0.600773\n",
      "epoch 159; iter: 0; batch classifier loss: 0.319843; batch adversarial loss: 0.553473\n",
      "epoch 160; iter: 0; batch classifier loss: 0.391935; batch adversarial loss: 0.535283\n",
      "epoch 161; iter: 0; batch classifier loss: 0.312977; batch adversarial loss: 0.481432\n",
      "epoch 162; iter: 0; batch classifier loss: 0.316083; batch adversarial loss: 0.660228\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340541; batch adversarial loss: 0.573212\n",
      "epoch 164; iter: 0; batch classifier loss: 0.367832; batch adversarial loss: 0.517245\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355642; batch adversarial loss: 0.536249\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333919; batch adversarial loss: 0.608690\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360701; batch adversarial loss: 0.507753\n",
      "epoch 168; iter: 0; batch classifier loss: 0.324785; batch adversarial loss: 0.517003\n",
      "epoch 169; iter: 0; batch classifier loss: 0.440361; batch adversarial loss: 0.507616\n",
      "epoch 170; iter: 0; batch classifier loss: 0.486185; batch adversarial loss: 0.507306\n",
      "epoch 171; iter: 0; batch classifier loss: 0.412460; batch adversarial loss: 0.563243\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351227; batch adversarial loss: 0.524795\n",
      "epoch 173; iter: 0; batch classifier loss: 0.325271; batch adversarial loss: 0.562289\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344708; batch adversarial loss: 0.535581\n",
      "epoch 175; iter: 0; batch classifier loss: 0.417713; batch adversarial loss: 0.617513\n",
      "epoch 176; iter: 0; batch classifier loss: 0.375708; batch adversarial loss: 0.506951\n",
      "epoch 177; iter: 0; batch classifier loss: 0.334565; batch adversarial loss: 0.535182\n",
      "epoch 178; iter: 0; batch classifier loss: 0.301583; batch adversarial loss: 0.526246\n",
      "epoch 179; iter: 0; batch classifier loss: 0.289860; batch adversarial loss: 0.516224\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387151; batch adversarial loss: 0.513669\n",
      "epoch 181; iter: 0; batch classifier loss: 0.388052; batch adversarial loss: 0.556066\n",
      "epoch 182; iter: 0; batch classifier loss: 0.328210; batch adversarial loss: 0.526260\n",
      "epoch 183; iter: 0; batch classifier loss: 0.433003; batch adversarial loss: 0.547711\n",
      "epoch 184; iter: 0; batch classifier loss: 0.399259; batch adversarial loss: 0.597643\n",
      "epoch 185; iter: 0; batch classifier loss: 0.341922; batch adversarial loss: 0.559605\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361091; batch adversarial loss: 0.505189\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325561; batch adversarial loss: 0.558422\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330657; batch adversarial loss: 0.496331\n",
      "epoch 189; iter: 0; batch classifier loss: 0.459359; batch adversarial loss: 0.592562\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312628; batch adversarial loss: 0.580196\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370050; batch adversarial loss: 0.575567\n",
      "epoch 192; iter: 0; batch classifier loss: 0.419440; batch adversarial loss: 0.470866\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300446; batch adversarial loss: 0.472271\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368499; batch adversarial loss: 0.554959\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359532; batch adversarial loss: 0.480993\n",
      "epoch 196; iter: 0; batch classifier loss: 0.271288; batch adversarial loss: 0.500082\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345511; batch adversarial loss: 0.573031\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365854; batch adversarial loss: 0.661683\n",
      "epoch 199; iter: 0; batch classifier loss: 0.356884; batch adversarial loss: 0.528605\n",
      "epoch 0; iter: 0; batch classifier loss: 0.773482; batch adversarial loss: 0.951563\n",
      "epoch 1; iter: 0; batch classifier loss: 0.769854; batch adversarial loss: 1.009956\n",
      "epoch 2; iter: 0; batch classifier loss: 0.960121; batch adversarial loss: 0.935697\n",
      "epoch 3; iter: 0; batch classifier loss: 0.993539; batch adversarial loss: 0.881353\n",
      "epoch 4; iter: 0; batch classifier loss: 1.005415; batch adversarial loss: 0.809413\n",
      "epoch 5; iter: 0; batch classifier loss: 1.009571; batch adversarial loss: 0.749781\n",
      "epoch 6; iter: 0; batch classifier loss: 0.916122; batch adversarial loss: 0.692770\n",
      "epoch 7; iter: 0; batch classifier loss: 0.824468; batch adversarial loss: 0.640170\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633186; batch adversarial loss: 0.633062\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546405; batch adversarial loss: 0.585961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555571; batch adversarial loss: 0.576786\n",
      "epoch 11; iter: 0; batch classifier loss: 0.578870; batch adversarial loss: 0.602995\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515859; batch adversarial loss: 0.623196\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527860; batch adversarial loss: 0.572781\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480847; batch adversarial loss: 0.556732\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537541; batch adversarial loss: 0.562632\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537606; batch adversarial loss: 0.569230\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535062; batch adversarial loss: 0.590773\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547496; batch adversarial loss: 0.569357\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528009; batch adversarial loss: 0.535646\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512101; batch adversarial loss: 0.554693\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542057; batch adversarial loss: 0.489848\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519409; batch adversarial loss: 0.567731\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540963; batch adversarial loss: 0.514703\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478075; batch adversarial loss: 0.534854\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462469; batch adversarial loss: 0.524001\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489649; batch adversarial loss: 0.604213\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520392; batch adversarial loss: 0.535603\n",
      "epoch 28; iter: 0; batch classifier loss: 0.533625; batch adversarial loss: 0.572950\n",
      "epoch 29; iter: 0; batch classifier loss: 0.515021; batch adversarial loss: 0.606587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.488681; batch adversarial loss: 0.515637\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505396; batch adversarial loss: 0.581153\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529032; batch adversarial loss: 0.533863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472853; batch adversarial loss: 0.625585\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471706; batch adversarial loss: 0.452686\n",
      "epoch 35; iter: 0; batch classifier loss: 0.415870; batch adversarial loss: 0.531010\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422702; batch adversarial loss: 0.652217\n",
      "epoch 37; iter: 0; batch classifier loss: 0.453641; batch adversarial loss: 0.612349\n",
      "epoch 38; iter: 0; batch classifier loss: 0.350220; batch adversarial loss: 0.516622\n",
      "epoch 39; iter: 0; batch classifier loss: 0.525563; batch adversarial loss: 0.521466\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450046; batch adversarial loss: 0.510067\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472860; batch adversarial loss: 0.570547\n",
      "epoch 42; iter: 0; batch classifier loss: 0.437216; batch adversarial loss: 0.627741\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471878; batch adversarial loss: 0.557259\n",
      "epoch 44; iter: 0; batch classifier loss: 0.530518; batch adversarial loss: 0.526743\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516877; batch adversarial loss: 0.540592\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460217; batch adversarial loss: 0.480472\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417644; batch adversarial loss: 0.549205\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409846; batch adversarial loss: 0.552193\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424660; batch adversarial loss: 0.518085\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433331; batch adversarial loss: 0.597825\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411767; batch adversarial loss: 0.512817\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448683; batch adversarial loss: 0.608271\n",
      "epoch 53; iter: 0; batch classifier loss: 0.365795; batch adversarial loss: 0.615469\n",
      "epoch 54; iter: 0; batch classifier loss: 0.521221; batch adversarial loss: 0.542902\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429192; batch adversarial loss: 0.568261\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393379; batch adversarial loss: 0.632567\n",
      "epoch 57; iter: 0; batch classifier loss: 0.484714; batch adversarial loss: 0.587265\n",
      "epoch 58; iter: 0; batch classifier loss: 0.377538; batch adversarial loss: 0.529136\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449954; batch adversarial loss: 0.490553\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407018; batch adversarial loss: 0.581425\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417393; batch adversarial loss: 0.624392\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421240; batch adversarial loss: 0.561762\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371736; batch adversarial loss: 0.571479\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377904; batch adversarial loss: 0.562367\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441896; batch adversarial loss: 0.634699\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384645; batch adversarial loss: 0.597325\n",
      "epoch 67; iter: 0; batch classifier loss: 0.355582; batch adversarial loss: 0.508432\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364106; batch adversarial loss: 0.598747\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413442; batch adversarial loss: 0.535687\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374868; batch adversarial loss: 0.487785\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373482; batch adversarial loss: 0.616128\n",
      "epoch 72; iter: 0; batch classifier loss: 0.454450; batch adversarial loss: 0.609660\n",
      "epoch 73; iter: 0; batch classifier loss: 0.350282; batch adversarial loss: 0.543794\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443294; batch adversarial loss: 0.538668\n",
      "epoch 75; iter: 0; batch classifier loss: 0.435476; batch adversarial loss: 0.591188\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392104; batch adversarial loss: 0.555355\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402146; batch adversarial loss: 0.618378\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402218; batch adversarial loss: 0.509774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.310515; batch adversarial loss: 0.544748\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398194; batch adversarial loss: 0.562311\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429869; batch adversarial loss: 0.535893\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366346; batch adversarial loss: 0.517537\n",
      "epoch 83; iter: 0; batch classifier loss: 0.447134; batch adversarial loss: 0.553519\n",
      "epoch 84; iter: 0; batch classifier loss: 0.420656; batch adversarial loss: 0.471858\n",
      "epoch 85; iter: 0; batch classifier loss: 0.287445; batch adversarial loss: 0.480925\n",
      "epoch 86; iter: 0; batch classifier loss: 0.331389; batch adversarial loss: 0.515657\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405550; batch adversarial loss: 0.589913\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354251; batch adversarial loss: 0.580708\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334143; batch adversarial loss: 0.572613\n",
      "epoch 90; iter: 0; batch classifier loss: 0.347517; batch adversarial loss: 0.571993\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395689; batch adversarial loss: 0.499491\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404248; batch adversarial loss: 0.490645\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344042; batch adversarial loss: 0.490333\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365769; batch adversarial loss: 0.544416\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416439; batch adversarial loss: 0.544844\n",
      "epoch 96; iter: 0; batch classifier loss: 0.343196; batch adversarial loss: 0.572099\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383748; batch adversarial loss: 0.481125\n",
      "epoch 98; iter: 0; batch classifier loss: 0.332748; batch adversarial loss: 0.553579\n",
      "epoch 99; iter: 0; batch classifier loss: 0.394113; batch adversarial loss: 0.535610\n",
      "epoch 100; iter: 0; batch classifier loss: 0.331215; batch adversarial loss: 0.580720\n",
      "epoch 101; iter: 0; batch classifier loss: 0.430061; batch adversarial loss: 0.544692\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426329; batch adversarial loss: 0.588689\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379826; batch adversarial loss: 0.580829\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393900; batch adversarial loss: 0.453132\n",
      "epoch 105; iter: 0; batch classifier loss: 0.353412; batch adversarial loss: 0.517234\n",
      "epoch 106; iter: 0; batch classifier loss: 0.291516; batch adversarial loss: 0.544942\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346526; batch adversarial loss: 0.561616\n",
      "epoch 108; iter: 0; batch classifier loss: 0.424944; batch adversarial loss: 0.571442\n",
      "epoch 109; iter: 0; batch classifier loss: 0.453346; batch adversarial loss: 0.590787\n",
      "epoch 110; iter: 0; batch classifier loss: 0.338986; batch adversarial loss: 0.524553\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365818; batch adversarial loss: 0.552786\n",
      "epoch 112; iter: 0; batch classifier loss: 0.478537; batch adversarial loss: 0.562067\n",
      "epoch 113; iter: 0; batch classifier loss: 0.310437; batch adversarial loss: 0.507309\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347795; batch adversarial loss: 0.482120\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336746; batch adversarial loss: 0.543255\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398162; batch adversarial loss: 0.600007\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407099; batch adversarial loss: 0.527016\n",
      "epoch 118; iter: 0; batch classifier loss: 0.318128; batch adversarial loss: 0.525849\n",
      "epoch 119; iter: 0; batch classifier loss: 0.482158; batch adversarial loss: 0.490331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.342641; batch adversarial loss: 0.626781\n",
      "epoch 121; iter: 0; batch classifier loss: 0.477376; batch adversarial loss: 0.562990\n",
      "epoch 122; iter: 0; batch classifier loss: 0.374781; batch adversarial loss: 0.508717\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343802; batch adversarial loss: 0.544390\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405016; batch adversarial loss: 0.606772\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412343; batch adversarial loss: 0.499491\n",
      "epoch 126; iter: 0; batch classifier loss: 0.283799; batch adversarial loss: 0.481452\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334230; batch adversarial loss: 0.553467\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348311; batch adversarial loss: 0.472893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.343435; batch adversarial loss: 0.544160\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360327; batch adversarial loss: 0.526284\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398754; batch adversarial loss: 0.535964\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340313; batch adversarial loss: 0.526725\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372657; batch adversarial loss: 0.479760\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351782; batch adversarial loss: 0.645181\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314937; batch adversarial loss: 0.526757\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401380; batch adversarial loss: 0.516773\n",
      "epoch 137; iter: 0; batch classifier loss: 0.472940; batch adversarial loss: 0.609019\n",
      "epoch 138; iter: 0; batch classifier loss: 0.337156; batch adversarial loss: 0.572332\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349506; batch adversarial loss: 0.617094\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352157; batch adversarial loss: 0.573575\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351648; batch adversarial loss: 0.497615\n",
      "epoch 142; iter: 0; batch classifier loss: 0.471633; batch adversarial loss: 0.536087\n",
      "epoch 143; iter: 0; batch classifier loss: 0.319309; batch adversarial loss: 0.498062\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361110; batch adversarial loss: 0.480545\n",
      "epoch 145; iter: 0; batch classifier loss: 0.479469; batch adversarial loss: 0.553567\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346216; batch adversarial loss: 0.572305\n",
      "epoch 147; iter: 0; batch classifier loss: 0.328284; batch adversarial loss: 0.516812\n",
      "epoch 148; iter: 0; batch classifier loss: 0.435827; batch adversarial loss: 0.535446\n",
      "epoch 149; iter: 0; batch classifier loss: 0.302644; batch adversarial loss: 0.617417\n",
      "epoch 150; iter: 0; batch classifier loss: 0.297639; batch adversarial loss: 0.608575\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345660; batch adversarial loss: 0.607967\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340989; batch adversarial loss: 0.526484\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381155; batch adversarial loss: 0.562574\n",
      "epoch 154; iter: 0; batch classifier loss: 0.331573; batch adversarial loss: 0.553497\n",
      "epoch 155; iter: 0; batch classifier loss: 0.302236; batch adversarial loss: 0.589775\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370635; batch adversarial loss: 0.499215\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328960; batch adversarial loss: 0.561913\n",
      "epoch 158; iter: 0; batch classifier loss: 0.349310; batch adversarial loss: 0.526501\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371541; batch adversarial loss: 0.544436\n",
      "epoch 160; iter: 0; batch classifier loss: 0.285846; batch adversarial loss: 0.544752\n",
      "epoch 161; iter: 0; batch classifier loss: 0.323454; batch adversarial loss: 0.571584\n",
      "epoch 162; iter: 0; batch classifier loss: 0.266429; batch adversarial loss: 0.544178\n",
      "epoch 163; iter: 0; batch classifier loss: 0.307866; batch adversarial loss: 0.508200\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346575; batch adversarial loss: 0.535809\n",
      "epoch 165; iter: 0; batch classifier loss: 0.308637; batch adversarial loss: 0.517620\n",
      "epoch 166; iter: 0; batch classifier loss: 0.307124; batch adversarial loss: 0.581234\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301821; batch adversarial loss: 0.544586\n",
      "epoch 168; iter: 0; batch classifier loss: 0.291192; batch adversarial loss: 0.590233\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382793; batch adversarial loss: 0.544676\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329643; batch adversarial loss: 0.608410\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372300; batch adversarial loss: 0.526999\n",
      "epoch 172; iter: 0; batch classifier loss: 0.285553; batch adversarial loss: 0.517660\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430146; batch adversarial loss: 0.517058\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338633; batch adversarial loss: 0.535916\n",
      "epoch 175; iter: 0; batch classifier loss: 0.404254; batch adversarial loss: 0.562889\n",
      "epoch 176; iter: 0; batch classifier loss: 0.321184; batch adversarial loss: 0.598838\n",
      "epoch 177; iter: 0; batch classifier loss: 0.304479; batch adversarial loss: 0.635587\n",
      "epoch 178; iter: 0; batch classifier loss: 0.298360; batch adversarial loss: 0.572019\n",
      "epoch 179; iter: 0; batch classifier loss: 0.289727; batch adversarial loss: 0.517412\n",
      "epoch 180; iter: 0; batch classifier loss: 0.326752; batch adversarial loss: 0.589949\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338835; batch adversarial loss: 0.526315\n",
      "epoch 182; iter: 0; batch classifier loss: 0.317706; batch adversarial loss: 0.581087\n",
      "epoch 183; iter: 0; batch classifier loss: 0.265656; batch adversarial loss: 0.481393\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294395; batch adversarial loss: 0.553702\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321910; batch adversarial loss: 0.636093\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375875; batch adversarial loss: 0.572158\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339974; batch adversarial loss: 0.562112\n",
      "epoch 188; iter: 0; batch classifier loss: 0.370442; batch adversarial loss: 0.489437\n",
      "epoch 189; iter: 0; batch classifier loss: 0.282567; batch adversarial loss: 0.571169\n",
      "epoch 190; iter: 0; batch classifier loss: 0.403197; batch adversarial loss: 0.517184\n",
      "epoch 191; iter: 0; batch classifier loss: 0.273278; batch adversarial loss: 0.516869\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365610; batch adversarial loss: 0.636033\n",
      "epoch 193; iter: 0; batch classifier loss: 0.254928; batch adversarial loss: 0.516848\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338981; batch adversarial loss: 0.562675\n",
      "epoch 195; iter: 0; batch classifier loss: 0.315769; batch adversarial loss: 0.563169\n",
      "epoch 196; iter: 0; batch classifier loss: 0.246393; batch adversarial loss: 0.535421\n",
      "epoch 197; iter: 0; batch classifier loss: 0.328079; batch adversarial loss: 0.462838\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353831; batch adversarial loss: 0.499276\n",
      "epoch 199; iter: 0; batch classifier loss: 0.276267; batch adversarial loss: 0.581042\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688664; batch adversarial loss: 1.027805\n",
      "epoch 1; iter: 0; batch classifier loss: 0.894093; batch adversarial loss: 1.347993\n",
      "epoch 2; iter: 0; batch classifier loss: 1.159715; batch adversarial loss: 1.368262\n",
      "epoch 3; iter: 0; batch classifier loss: 1.215074; batch adversarial loss: 1.245458\n",
      "epoch 4; iter: 0; batch classifier loss: 1.246585; batch adversarial loss: 1.136234\n",
      "epoch 5; iter: 0; batch classifier loss: 1.136336; batch adversarial loss: 1.015392\n",
      "epoch 6; iter: 0; batch classifier loss: 1.313233; batch adversarial loss: 0.959537\n",
      "epoch 7; iter: 0; batch classifier loss: 1.279493; batch adversarial loss: 0.898046\n",
      "epoch 8; iter: 0; batch classifier loss: 1.353850; batch adversarial loss: 0.858065\n",
      "epoch 9; iter: 0; batch classifier loss: 1.064034; batch adversarial loss: 0.753396\n",
      "epoch 10; iter: 0; batch classifier loss: 0.992331; batch adversarial loss: 0.702285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.885850; batch adversarial loss: 0.703176\n",
      "epoch 12; iter: 0; batch classifier loss: 0.745442; batch adversarial loss: 0.629044\n",
      "epoch 13; iter: 0; batch classifier loss: 0.650883; batch adversarial loss: 0.626883\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558447; batch adversarial loss: 0.593929\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536464; batch adversarial loss: 0.565910\n",
      "epoch 16; iter: 0; batch classifier loss: 0.583279; batch adversarial loss: 0.521607\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491103; batch adversarial loss: 0.573729\n",
      "epoch 18; iter: 0; batch classifier loss: 0.443303; batch adversarial loss: 0.579287\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508763; batch adversarial loss: 0.528603\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521297; batch adversarial loss: 0.575411\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511903; batch adversarial loss: 0.583362\n",
      "epoch 22; iter: 0; batch classifier loss: 0.523242; batch adversarial loss: 0.586506\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507678; batch adversarial loss: 0.578799\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482930; batch adversarial loss: 0.505847\n",
      "epoch 25; iter: 0; batch classifier loss: 0.536384; batch adversarial loss: 0.532368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.543332; batch adversarial loss: 0.570131\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473231; batch adversarial loss: 0.539650\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480017; batch adversarial loss: 0.603304\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438652; batch adversarial loss: 0.477413\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476335; batch adversarial loss: 0.579282\n",
      "epoch 31; iter: 0; batch classifier loss: 0.413839; batch adversarial loss: 0.608689\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442806; batch adversarial loss: 0.573562\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507707; batch adversarial loss: 0.614185\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420301; batch adversarial loss: 0.507841\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419471; batch adversarial loss: 0.572557\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478435; batch adversarial loss: 0.585730\n",
      "epoch 37; iter: 0; batch classifier loss: 0.432582; batch adversarial loss: 0.525343\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473253; batch adversarial loss: 0.512000\n",
      "epoch 39; iter: 0; batch classifier loss: 0.574352; batch adversarial loss: 0.550653\n",
      "epoch 40; iter: 0; batch classifier loss: 0.438361; batch adversarial loss: 0.623842\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425143; batch adversarial loss: 0.594350\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450707; batch adversarial loss: 0.565126\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442860; batch adversarial loss: 0.522272\n",
      "epoch 44; iter: 0; batch classifier loss: 0.372104; batch adversarial loss: 0.524611\n",
      "epoch 45; iter: 0; batch classifier loss: 0.365541; batch adversarial loss: 0.552720\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382275; batch adversarial loss: 0.592114\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464176; batch adversarial loss: 0.614632\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372277; batch adversarial loss: 0.586765\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417276; batch adversarial loss: 0.585039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395744; batch adversarial loss: 0.503593\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432439; batch adversarial loss: 0.583853\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437653; batch adversarial loss: 0.565347\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429432; batch adversarial loss: 0.557083\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394151; batch adversarial loss: 0.537015\n",
      "epoch 55; iter: 0; batch classifier loss: 0.315282; batch adversarial loss: 0.561245\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409463; batch adversarial loss: 0.531397\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392843; batch adversarial loss: 0.587341\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472199; batch adversarial loss: 0.554888\n",
      "epoch 59; iter: 0; batch classifier loss: 0.538273; batch adversarial loss: 0.562413\n",
      "epoch 60; iter: 0; batch classifier loss: 0.438403; batch adversarial loss: 0.495043\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389042; batch adversarial loss: 0.532156\n",
      "epoch 62; iter: 0; batch classifier loss: 0.381929; batch adversarial loss: 0.477034\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374099; batch adversarial loss: 0.504537\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414119; batch adversarial loss: 0.469414\n",
      "epoch 65; iter: 0; batch classifier loss: 0.356678; batch adversarial loss: 0.512077\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396685; batch adversarial loss: 0.558924\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402479; batch adversarial loss: 0.573718\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417119; batch adversarial loss: 0.536914\n",
      "epoch 69; iter: 0; batch classifier loss: 0.446786; batch adversarial loss: 0.608293\n",
      "epoch 70; iter: 0; batch classifier loss: 0.325907; batch adversarial loss: 0.517163\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407852; batch adversarial loss: 0.542819\n",
      "epoch 72; iter: 0; batch classifier loss: 0.353494; batch adversarial loss: 0.503611\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422031; batch adversarial loss: 0.518238\n",
      "epoch 74; iter: 0; batch classifier loss: 0.438608; batch adversarial loss: 0.532076\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375284; batch adversarial loss: 0.602496\n",
      "epoch 76; iter: 0; batch classifier loss: 0.345365; batch adversarial loss: 0.586954\n",
      "epoch 77; iter: 0; batch classifier loss: 0.367468; batch adversarial loss: 0.554544\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376521; batch adversarial loss: 0.530870\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385688; batch adversarial loss: 0.542120\n",
      "epoch 80; iter: 0; batch classifier loss: 0.410994; batch adversarial loss: 0.525366\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384330; batch adversarial loss: 0.540159\n",
      "epoch 82; iter: 0; batch classifier loss: 0.496025; batch adversarial loss: 0.512320\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364985; batch adversarial loss: 0.558452\n",
      "epoch 84; iter: 0; batch classifier loss: 0.314753; batch adversarial loss: 0.516776\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416064; batch adversarial loss: 0.565396\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365225; batch adversarial loss: 0.497478\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360866; batch adversarial loss: 0.590027\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368186; batch adversarial loss: 0.539913\n",
      "epoch 89; iter: 0; batch classifier loss: 0.364251; batch adversarial loss: 0.603062\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376203; batch adversarial loss: 0.513668\n",
      "epoch 91; iter: 0; batch classifier loss: 0.353329; batch adversarial loss: 0.461005\n",
      "epoch 92; iter: 0; batch classifier loss: 0.416541; batch adversarial loss: 0.581308\n",
      "epoch 93; iter: 0; batch classifier loss: 0.362387; batch adversarial loss: 0.605030\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357077; batch adversarial loss: 0.557930\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357322; batch adversarial loss: 0.555423\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388681; batch adversarial loss: 0.519391\n",
      "epoch 97; iter: 0; batch classifier loss: 0.326449; batch adversarial loss: 0.576308\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416177; batch adversarial loss: 0.486921\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375950; batch adversarial loss: 0.556567\n",
      "epoch 100; iter: 0; batch classifier loss: 0.425605; batch adversarial loss: 0.580512\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386306; batch adversarial loss: 0.571514\n",
      "epoch 102; iter: 0; batch classifier loss: 0.290960; batch adversarial loss: 0.492315\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354468; batch adversarial loss: 0.482819\n",
      "epoch 104; iter: 0; batch classifier loss: 0.394185; batch adversarial loss: 0.474134\n",
      "epoch 105; iter: 0; batch classifier loss: 0.341101; batch adversarial loss: 0.544930\n",
      "epoch 106; iter: 0; batch classifier loss: 0.322058; batch adversarial loss: 0.471521\n",
      "epoch 107; iter: 0; batch classifier loss: 0.313668; batch adversarial loss: 0.604245\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386522; batch adversarial loss: 0.517007\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337827; batch adversarial loss: 0.515172\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372344; batch adversarial loss: 0.565719\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406975; batch adversarial loss: 0.495511\n",
      "epoch 112; iter: 0; batch classifier loss: 0.295053; batch adversarial loss: 0.543597\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363868; batch adversarial loss: 0.547426\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372836; batch adversarial loss: 0.565614\n",
      "epoch 115; iter: 0; batch classifier loss: 0.320393; batch adversarial loss: 0.504977\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369806; batch adversarial loss: 0.592418\n",
      "epoch 117; iter: 0; batch classifier loss: 0.286362; batch adversarial loss: 0.583112\n",
      "epoch 118; iter: 0; batch classifier loss: 0.324795; batch adversarial loss: 0.545614\n",
      "epoch 119; iter: 0; batch classifier loss: 0.309817; batch adversarial loss: 0.543207\n",
      "epoch 120; iter: 0; batch classifier loss: 0.316686; batch adversarial loss: 0.640682\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345786; batch adversarial loss: 0.525609\n",
      "epoch 122; iter: 0; batch classifier loss: 0.334521; batch adversarial loss: 0.537259\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362175; batch adversarial loss: 0.488214\n",
      "epoch 124; iter: 0; batch classifier loss: 0.355251; batch adversarial loss: 0.492995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.365297; batch adversarial loss: 0.564913\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369867; batch adversarial loss: 0.519628\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370783; batch adversarial loss: 0.564031\n",
      "epoch 128; iter: 0; batch classifier loss: 0.308600; batch adversarial loss: 0.502822\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388332; batch adversarial loss: 0.520592\n",
      "epoch 130; iter: 0; batch classifier loss: 0.314707; batch adversarial loss: 0.474444\n",
      "epoch 131; iter: 0; batch classifier loss: 0.324113; batch adversarial loss: 0.597941\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350832; batch adversarial loss: 0.509241\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349100; batch adversarial loss: 0.509826\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369795; batch adversarial loss: 0.474434\n",
      "epoch 135; iter: 0; batch classifier loss: 0.282282; batch adversarial loss: 0.482490\n",
      "epoch 136; iter: 0; batch classifier loss: 0.273599; batch adversarial loss: 0.587930\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383122; batch adversarial loss: 0.580465\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355807; batch adversarial loss: 0.544230\n",
      "epoch 139; iter: 0; batch classifier loss: 0.290640; batch adversarial loss: 0.500232\n",
      "epoch 140; iter: 0; batch classifier loss: 0.422294; batch adversarial loss: 0.544514\n",
      "epoch 141; iter: 0; batch classifier loss: 0.397085; batch adversarial loss: 0.561511\n",
      "epoch 142; iter: 0; batch classifier loss: 0.324785; batch adversarial loss: 0.518299\n",
      "epoch 143; iter: 0; batch classifier loss: 0.425466; batch adversarial loss: 0.500256\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302954; batch adversarial loss: 0.562623\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352398; batch adversarial loss: 0.544795\n",
      "epoch 146; iter: 0; batch classifier loss: 0.355417; batch adversarial loss: 0.526896\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303920; batch adversarial loss: 0.634094\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335258; batch adversarial loss: 0.534696\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319749; batch adversarial loss: 0.561414\n",
      "epoch 150; iter: 0; batch classifier loss: 0.448126; batch adversarial loss: 0.561700\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341799; batch adversarial loss: 0.554073\n",
      "epoch 152; iter: 0; batch classifier loss: 0.322078; batch adversarial loss: 0.525549\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348196; batch adversarial loss: 0.598337\n",
      "epoch 154; iter: 0; batch classifier loss: 0.322189; batch adversarial loss: 0.577533\n",
      "epoch 155; iter: 0; batch classifier loss: 0.353246; batch adversarial loss: 0.522830\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378917; batch adversarial loss: 0.533025\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312193; batch adversarial loss: 0.601048\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356081; batch adversarial loss: 0.611336\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342370; batch adversarial loss: 0.543646\n",
      "epoch 160; iter: 0; batch classifier loss: 0.306852; batch adversarial loss: 0.489350\n",
      "epoch 161; iter: 0; batch classifier loss: 0.371859; batch adversarial loss: 0.608969\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373147; batch adversarial loss: 0.474466\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362021; batch adversarial loss: 0.519717\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328529; batch adversarial loss: 0.590405\n",
      "epoch 165; iter: 0; batch classifier loss: 0.245095; batch adversarial loss: 0.579719\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325226; batch adversarial loss: 0.526018\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337950; batch adversarial loss: 0.571151\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308446; batch adversarial loss: 0.578751\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312523; batch adversarial loss: 0.490754\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324730; batch adversarial loss: 0.571006\n",
      "epoch 171; iter: 0; batch classifier loss: 0.379415; batch adversarial loss: 0.499199\n",
      "epoch 172; iter: 0; batch classifier loss: 0.268384; batch adversarial loss: 0.543121\n",
      "epoch 173; iter: 0; batch classifier loss: 0.328275; batch adversarial loss: 0.503325\n",
      "epoch 174; iter: 0; batch classifier loss: 0.283376; batch adversarial loss: 0.533708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323877; batch adversarial loss: 0.599382\n",
      "epoch 176; iter: 0; batch classifier loss: 0.422979; batch adversarial loss: 0.543946\n",
      "epoch 177; iter: 0; batch classifier loss: 0.348445; batch adversarial loss: 0.572230\n",
      "epoch 178; iter: 0; batch classifier loss: 0.254346; batch adversarial loss: 0.572190\n",
      "epoch 179; iter: 0; batch classifier loss: 0.277188; batch adversarial loss: 0.553642\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362922; batch adversarial loss: 0.528738\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334961; batch adversarial loss: 0.536355\n",
      "epoch 182; iter: 0; batch classifier loss: 0.343978; batch adversarial loss: 0.484157\n",
      "epoch 183; iter: 0; batch classifier loss: 0.304223; batch adversarial loss: 0.473666\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294464; batch adversarial loss: 0.606929\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281005; batch adversarial loss: 0.527019\n",
      "epoch 186; iter: 0; batch classifier loss: 0.311683; batch adversarial loss: 0.571330\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375403; batch adversarial loss: 0.517418\n",
      "epoch 188; iter: 0; batch classifier loss: 0.302554; batch adversarial loss: 0.464081\n",
      "epoch 189; iter: 0; batch classifier loss: 0.301833; batch adversarial loss: 0.581135\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333793; batch adversarial loss: 0.562491\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330220; batch adversarial loss: 0.580689\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357304; batch adversarial loss: 0.624819\n",
      "epoch 193; iter: 0; batch classifier loss: 0.311404; batch adversarial loss: 0.545078\n",
      "epoch 194; iter: 0; batch classifier loss: 0.285157; batch adversarial loss: 0.499575\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330234; batch adversarial loss: 0.571608\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315008; batch adversarial loss: 0.553702\n",
      "epoch 197; iter: 0; batch classifier loss: 0.311583; batch adversarial loss: 0.526519\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375098; batch adversarial loss: 0.481718\n",
      "epoch 199; iter: 0; batch classifier loss: 0.272218; batch adversarial loss: 0.481185\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705012; batch adversarial loss: 0.872176\n",
      "epoch 1; iter: 0; batch classifier loss: 0.753328; batch adversarial loss: 1.036334\n",
      "epoch 2; iter: 0; batch classifier loss: 0.918532; batch adversarial loss: 0.973838\n",
      "epoch 3; iter: 0; batch classifier loss: 1.023437; batch adversarial loss: 0.899210\n",
      "epoch 4; iter: 0; batch classifier loss: 1.079472; batch adversarial loss: 0.826003\n",
      "epoch 5; iter: 0; batch classifier loss: 0.985999; batch adversarial loss: 0.750556\n",
      "epoch 6; iter: 0; batch classifier loss: 0.966845; batch adversarial loss: 0.705408\n",
      "epoch 7; iter: 0; batch classifier loss: 0.965933; batch adversarial loss: 0.643948\n",
      "epoch 8; iter: 0; batch classifier loss: 0.839658; batch adversarial loss: 0.624587\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564653; batch adversarial loss: 0.586023\n",
      "epoch 10; iter: 0; batch classifier loss: 0.497730; batch adversarial loss: 0.540805\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573908; batch adversarial loss: 0.591211\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533185; batch adversarial loss: 0.597952\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542116; batch adversarial loss: 0.594815\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539621; batch adversarial loss: 0.567066\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488251; batch adversarial loss: 0.565853\n",
      "epoch 16; iter: 0; batch classifier loss: 0.567935; batch adversarial loss: 0.589607\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523957; batch adversarial loss: 0.615746\n",
      "epoch 18; iter: 0; batch classifier loss: 0.470848; batch adversarial loss: 0.511314\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455893; batch adversarial loss: 0.581571\n",
      "epoch 20; iter: 0; batch classifier loss: 0.481460; batch adversarial loss: 0.554871\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530102; batch adversarial loss: 0.574737\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468493; batch adversarial loss: 0.471411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.505802; batch adversarial loss: 0.518589\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470690; batch adversarial loss: 0.527407\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492064; batch adversarial loss: 0.566111\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457734; batch adversarial loss: 0.586069\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490467; batch adversarial loss: 0.569709\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491087; batch adversarial loss: 0.554202\n",
      "epoch 29; iter: 0; batch classifier loss: 0.553375; batch adversarial loss: 0.529608\n",
      "epoch 30; iter: 0; batch classifier loss: 0.494494; batch adversarial loss: 0.530000\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472951; batch adversarial loss: 0.578085\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464913; batch adversarial loss: 0.576246\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464153; batch adversarial loss: 0.541786\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441961; batch adversarial loss: 0.447586\n",
      "epoch 35; iter: 0; batch classifier loss: 0.534046; batch adversarial loss: 0.548370\n",
      "epoch 36; iter: 0; batch classifier loss: 0.491018; batch adversarial loss: 0.536987\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417284; batch adversarial loss: 0.607346\n",
      "epoch 38; iter: 0; batch classifier loss: 0.394735; batch adversarial loss: 0.560115\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438124; batch adversarial loss: 0.563971\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443249; batch adversarial loss: 0.534370\n",
      "epoch 41; iter: 0; batch classifier loss: 0.409977; batch adversarial loss: 0.530088\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418310; batch adversarial loss: 0.525178\n",
      "epoch 43; iter: 0; batch classifier loss: 0.364311; batch adversarial loss: 0.495691\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402172; batch adversarial loss: 0.555634\n",
      "epoch 45; iter: 0; batch classifier loss: 0.410283; batch adversarial loss: 0.553848\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446818; batch adversarial loss: 0.560780\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410102; batch adversarial loss: 0.510215\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439654; batch adversarial loss: 0.581793\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415254; batch adversarial loss: 0.545231\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406488; batch adversarial loss: 0.618515\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433895; batch adversarial loss: 0.510760\n",
      "epoch 52; iter: 0; batch classifier loss: 0.490062; batch adversarial loss: 0.512207\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443994; batch adversarial loss: 0.500963\n",
      "epoch 54; iter: 0; batch classifier loss: 0.356836; batch adversarial loss: 0.547596\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431044; batch adversarial loss: 0.607709\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420457; batch adversarial loss: 0.508402\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395246; batch adversarial loss: 0.553949\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398560; batch adversarial loss: 0.563557\n",
      "epoch 59; iter: 0; batch classifier loss: 0.330433; batch adversarial loss: 0.480642\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401429; batch adversarial loss: 0.480496\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403981; batch adversarial loss: 0.433686\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422761; batch adversarial loss: 0.498464\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412503; batch adversarial loss: 0.581899\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437313; batch adversarial loss: 0.563226\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402919; batch adversarial loss: 0.535110\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412650; batch adversarial loss: 0.562915\n",
      "epoch 67; iter: 0; batch classifier loss: 0.427590; batch adversarial loss: 0.525568\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438165; batch adversarial loss: 0.573537\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435629; batch adversarial loss: 0.544084\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359967; batch adversarial loss: 0.591030\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431043; batch adversarial loss: 0.487743\n",
      "epoch 72; iter: 0; batch classifier loss: 0.344124; batch adversarial loss: 0.572216\n",
      "epoch 73; iter: 0; batch classifier loss: 0.362150; batch adversarial loss: 0.506405\n",
      "epoch 74; iter: 0; batch classifier loss: 0.448129; batch adversarial loss: 0.573049\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409960; batch adversarial loss: 0.506489\n",
      "epoch 76; iter: 0; batch classifier loss: 0.512803; batch adversarial loss: 0.555733\n",
      "epoch 77; iter: 0; batch classifier loss: 0.361906; batch adversarial loss: 0.526098\n",
      "epoch 78; iter: 0; batch classifier loss: 0.374670; batch adversarial loss: 0.534745\n",
      "epoch 79; iter: 0; batch classifier loss: 0.431162; batch adversarial loss: 0.553921\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417447; batch adversarial loss: 0.544015\n",
      "epoch 81; iter: 0; batch classifier loss: 0.437780; batch adversarial loss: 0.507208\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387420; batch adversarial loss: 0.582236\n",
      "epoch 83; iter: 0; batch classifier loss: 0.389393; batch adversarial loss: 0.516246\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389133; batch adversarial loss: 0.543977\n",
      "epoch 85; iter: 0; batch classifier loss: 0.357874; batch adversarial loss: 0.544629\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420488; batch adversarial loss: 0.543626\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406852; batch adversarial loss: 0.563889\n",
      "epoch 88; iter: 0; batch classifier loss: 0.338366; batch adversarial loss: 0.572884\n",
      "epoch 89; iter: 0; batch classifier loss: 0.346265; batch adversarial loss: 0.498253\n",
      "epoch 90; iter: 0; batch classifier loss: 0.445060; batch adversarial loss: 0.535187\n",
      "epoch 91; iter: 0; batch classifier loss: 0.332404; batch adversarial loss: 0.497636\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374298; batch adversarial loss: 0.601820\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353819; batch adversarial loss: 0.571118\n",
      "epoch 94; iter: 0; batch classifier loss: 0.388591; batch adversarial loss: 0.582651\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322186; batch adversarial loss: 0.563065\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416283; batch adversarial loss: 0.497750\n",
      "epoch 97; iter: 0; batch classifier loss: 0.456536; batch adversarial loss: 0.583993\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410922; batch adversarial loss: 0.515834\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359720; batch adversarial loss: 0.536334\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394655; batch adversarial loss: 0.543308\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394913; batch adversarial loss: 0.516033\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374844; batch adversarial loss: 0.582409\n",
      "epoch 103; iter: 0; batch classifier loss: 0.299740; batch adversarial loss: 0.574145\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362730; batch adversarial loss: 0.497188\n",
      "epoch 105; iter: 0; batch classifier loss: 0.324799; batch adversarial loss: 0.601406\n",
      "epoch 106; iter: 0; batch classifier loss: 0.392604; batch adversarial loss: 0.526443\n",
      "epoch 107; iter: 0; batch classifier loss: 0.336917; batch adversarial loss: 0.497014\n",
      "epoch 108; iter: 0; batch classifier loss: 0.419058; batch adversarial loss: 0.591792\n",
      "epoch 109; iter: 0; batch classifier loss: 0.299396; batch adversarial loss: 0.506625\n",
      "epoch 110; iter: 0; batch classifier loss: 0.423384; batch adversarial loss: 0.487854\n",
      "epoch 111; iter: 0; batch classifier loss: 0.357042; batch adversarial loss: 0.534558\n",
      "epoch 112; iter: 0; batch classifier loss: 0.421279; batch adversarial loss: 0.604020\n",
      "epoch 113; iter: 0; batch classifier loss: 0.376072; batch adversarial loss: 0.477689\n",
      "epoch 114; iter: 0; batch classifier loss: 0.353416; batch adversarial loss: 0.497652\n",
      "epoch 115; iter: 0; batch classifier loss: 0.353883; batch adversarial loss: 0.460184\n",
      "epoch 116; iter: 0; batch classifier loss: 0.424563; batch adversarial loss: 0.573835\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360157; batch adversarial loss: 0.582655\n",
      "epoch 118; iter: 0; batch classifier loss: 0.443076; batch adversarial loss: 0.544154\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334998; batch adversarial loss: 0.487718\n",
      "epoch 120; iter: 0; batch classifier loss: 0.321119; batch adversarial loss: 0.516500\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370084; batch adversarial loss: 0.573311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.365742; batch adversarial loss: 0.423085\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331089; batch adversarial loss: 0.580879\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385019; batch adversarial loss: 0.611209\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344394; batch adversarial loss: 0.650427\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379512; batch adversarial loss: 0.580587\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340826; batch adversarial loss: 0.536245\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395673; batch adversarial loss: 0.580652\n",
      "epoch 129; iter: 0; batch classifier loss: 0.371452; batch adversarial loss: 0.564385\n",
      "epoch 130; iter: 0; batch classifier loss: 0.392183; batch adversarial loss: 0.513504\n",
      "epoch 131; iter: 0; batch classifier loss: 0.329103; batch adversarial loss: 0.553504\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364924; batch adversarial loss: 0.496707\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340805; batch adversarial loss: 0.477382\n",
      "epoch 134; iter: 0; batch classifier loss: 0.335780; batch adversarial loss: 0.422677\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382286; batch adversarial loss: 0.525349\n",
      "epoch 136; iter: 0; batch classifier loss: 0.434453; batch adversarial loss: 0.603939\n",
      "epoch 137; iter: 0; batch classifier loss: 0.307887; batch adversarial loss: 0.581998\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338013; batch adversarial loss: 0.575912\n",
      "epoch 139; iter: 0; batch classifier loss: 0.286394; batch adversarial loss: 0.554378\n",
      "epoch 140; iter: 0; batch classifier loss: 0.330935; batch adversarial loss: 0.611187\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377687; batch adversarial loss: 0.526806\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350353; batch adversarial loss: 0.563187\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350279; batch adversarial loss: 0.498514\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336075; batch adversarial loss: 0.555801\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335294; batch adversarial loss: 0.544482\n",
      "epoch 146; iter: 0; batch classifier loss: 0.251600; batch adversarial loss: 0.534137\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332402; batch adversarial loss: 0.468858\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379072; batch adversarial loss: 0.589984\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402719; batch adversarial loss: 0.532082\n",
      "epoch 150; iter: 0; batch classifier loss: 0.309964; batch adversarial loss: 0.582816\n",
      "epoch 151; iter: 0; batch classifier loss: 0.305646; batch adversarial loss: 0.542698\n",
      "epoch 152; iter: 0; batch classifier loss: 0.361595; batch adversarial loss: 0.636968\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330246; batch adversarial loss: 0.514992\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344980; batch adversarial loss: 0.581588\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357465; batch adversarial loss: 0.639960\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339433; batch adversarial loss: 0.523559\n",
      "epoch 157; iter: 0; batch classifier loss: 0.297619; batch adversarial loss: 0.573972\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368137; batch adversarial loss: 0.514448\n",
      "epoch 159; iter: 0; batch classifier loss: 0.288442; batch adversarial loss: 0.600780\n",
      "epoch 160; iter: 0; batch classifier loss: 0.305749; batch adversarial loss: 0.469758\n",
      "epoch 161; iter: 0; batch classifier loss: 0.416681; batch adversarial loss: 0.553041\n",
      "epoch 162; iter: 0; batch classifier loss: 0.336902; batch adversarial loss: 0.640492\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348171; batch adversarial loss: 0.554054\n",
      "epoch 164; iter: 0; batch classifier loss: 0.288076; batch adversarial loss: 0.592468\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356148; batch adversarial loss: 0.583396\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374731; batch adversarial loss: 0.553583\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329122; batch adversarial loss: 0.526783\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352587; batch adversarial loss: 0.561925\n",
      "epoch 169; iter: 0; batch classifier loss: 0.299533; batch adversarial loss: 0.573910\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345325; batch adversarial loss: 0.507004\n",
      "epoch 171; iter: 0; batch classifier loss: 0.290278; batch adversarial loss: 0.591099\n",
      "epoch 172; iter: 0; batch classifier loss: 0.290844; batch adversarial loss: 0.544791\n",
      "epoch 173; iter: 0; batch classifier loss: 0.451423; batch adversarial loss: 0.537553\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393694; batch adversarial loss: 0.517886\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343351; batch adversarial loss: 0.544720\n",
      "epoch 176; iter: 0; batch classifier loss: 0.322317; batch adversarial loss: 0.600221\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340273; batch adversarial loss: 0.502846\n",
      "epoch 178; iter: 0; batch classifier loss: 0.298412; batch adversarial loss: 0.506878\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394571; batch adversarial loss: 0.582737\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354428; batch adversarial loss: 0.525597\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331974; batch adversarial loss: 0.554918\n",
      "epoch 182; iter: 0; batch classifier loss: 0.294387; batch adversarial loss: 0.583360\n",
      "epoch 183; iter: 0; batch classifier loss: 0.303673; batch adversarial loss: 0.497175\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385003; batch adversarial loss: 0.498015\n",
      "epoch 185; iter: 0; batch classifier loss: 0.410864; batch adversarial loss: 0.518044\n",
      "epoch 186; iter: 0; batch classifier loss: 0.290291; batch adversarial loss: 0.469553\n",
      "epoch 187; iter: 0; batch classifier loss: 0.289888; batch adversarial loss: 0.525789\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356688; batch adversarial loss: 0.515842\n",
      "epoch 189; iter: 0; batch classifier loss: 0.245347; batch adversarial loss: 0.555384\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309276; batch adversarial loss: 0.552144\n",
      "epoch 191; iter: 0; batch classifier loss: 0.304688; batch adversarial loss: 0.488056\n",
      "epoch 192; iter: 0; batch classifier loss: 0.304019; batch adversarial loss: 0.479542\n",
      "epoch 193; iter: 0; batch classifier loss: 0.411744; batch adversarial loss: 0.554841\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393650; batch adversarial loss: 0.537742\n",
      "epoch 195; iter: 0; batch classifier loss: 0.314381; batch adversarial loss: 0.497082\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330141; batch adversarial loss: 0.563339\n",
      "epoch 197; iter: 0; batch classifier loss: 0.413128; batch adversarial loss: 0.506450\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328967; batch adversarial loss: 0.620263\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355773; batch adversarial loss: 0.555065\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714332; batch adversarial loss: 0.677209\n",
      "epoch 1; iter: 0; batch classifier loss: 0.562953; batch adversarial loss: 0.704691\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581741; batch adversarial loss: 0.705041\n",
      "epoch 3; iter: 0; batch classifier loss: 0.516946; batch adversarial loss: 0.608730\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518394; batch adversarial loss: 0.693719\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553161; batch adversarial loss: 0.633712\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565205; batch adversarial loss: 0.653783\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542986; batch adversarial loss: 0.599223\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490932; batch adversarial loss: 0.563678\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585808; batch adversarial loss: 0.572068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518999; batch adversarial loss: 0.638629\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512554; batch adversarial loss: 0.594764\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544097; batch adversarial loss: 0.595007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544769; batch adversarial loss: 0.595058\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466568; batch adversarial loss: 0.552520\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531280; batch adversarial loss: 0.603646\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538385; batch adversarial loss: 0.552397\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501078; batch adversarial loss: 0.508626\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473236; batch adversarial loss: 0.548202\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457937; batch adversarial loss: 0.587800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.475278; batch adversarial loss: 0.558182\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528731; batch adversarial loss: 0.603908\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515930; batch adversarial loss: 0.575561\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420489; batch adversarial loss: 0.570261\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482026; batch adversarial loss: 0.602195\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437567; batch adversarial loss: 0.590431\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440624; batch adversarial loss: 0.615630\n",
      "epoch 27; iter: 0; batch classifier loss: 0.504222; batch adversarial loss: 0.530680\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421751; batch adversarial loss: 0.562368\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463497; batch adversarial loss: 0.557532\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467375; batch adversarial loss: 0.553237\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455491; batch adversarial loss: 0.478142\n",
      "epoch 32; iter: 0; batch classifier loss: 0.561564; batch adversarial loss: 0.572836\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467811; batch adversarial loss: 0.537536\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446714; batch adversarial loss: 0.608274\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423960; batch adversarial loss: 0.527506\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445437; batch adversarial loss: 0.565974\n",
      "epoch 37; iter: 0; batch classifier loss: 0.398935; batch adversarial loss: 0.491016\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431628; batch adversarial loss: 0.541533\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462914; batch adversarial loss: 0.533060\n",
      "epoch 40; iter: 0; batch classifier loss: 0.438284; batch adversarial loss: 0.572246\n",
      "epoch 41; iter: 0; batch classifier loss: 0.502282; batch adversarial loss: 0.635072\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489200; batch adversarial loss: 0.515091\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446199; batch adversarial loss: 0.554912\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405238; batch adversarial loss: 0.534942\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455387; batch adversarial loss: 0.499736\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426397; batch adversarial loss: 0.508198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409015; batch adversarial loss: 0.563102\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457049; batch adversarial loss: 0.578233\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416150; batch adversarial loss: 0.582418\n",
      "epoch 50; iter: 0; batch classifier loss: 0.494969; batch adversarial loss: 0.553910\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413438; batch adversarial loss: 0.642749\n",
      "epoch 52; iter: 0; batch classifier loss: 0.388614; batch adversarial loss: 0.605905\n",
      "epoch 53; iter: 0; batch classifier loss: 0.352105; batch adversarial loss: 0.536656\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408361; batch adversarial loss: 0.490357\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483136; batch adversarial loss: 0.571540\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438349; batch adversarial loss: 0.635169\n",
      "epoch 57; iter: 0; batch classifier loss: 0.375645; batch adversarial loss: 0.625506\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392459; batch adversarial loss: 0.516607\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466580; batch adversarial loss: 0.608428\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397768; batch adversarial loss: 0.508581\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427033; batch adversarial loss: 0.517945\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383231; batch adversarial loss: 0.562503\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385746; batch adversarial loss: 0.562525\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422883; batch adversarial loss: 0.562659\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423836; batch adversarial loss: 0.617515\n",
      "epoch 66; iter: 0; batch classifier loss: 0.351230; batch adversarial loss: 0.535729\n",
      "epoch 67; iter: 0; batch classifier loss: 0.382886; batch adversarial loss: 0.608511\n",
      "epoch 68; iter: 0; batch classifier loss: 0.482318; batch adversarial loss: 0.543978\n",
      "epoch 69; iter: 0; batch classifier loss: 0.456673; batch adversarial loss: 0.545035\n",
      "epoch 70; iter: 0; batch classifier loss: 0.394478; batch adversarial loss: 0.662538\n",
      "epoch 71; iter: 0; batch classifier loss: 0.460648; batch adversarial loss: 0.462857\n",
      "epoch 72; iter: 0; batch classifier loss: 0.373713; batch adversarial loss: 0.517360\n",
      "epoch 73; iter: 0; batch classifier loss: 0.381146; batch adversarial loss: 0.471933\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399010; batch adversarial loss: 0.517557\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396057; batch adversarial loss: 0.553597\n",
      "epoch 76; iter: 0; batch classifier loss: 0.455197; batch adversarial loss: 0.562364\n",
      "epoch 77; iter: 0; batch classifier loss: 0.478914; batch adversarial loss: 0.535363\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362274; batch adversarial loss: 0.498892\n",
      "epoch 79; iter: 0; batch classifier loss: 0.304061; batch adversarial loss: 0.562749\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363910; batch adversarial loss: 0.508064\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390808; batch adversarial loss: 0.535409\n",
      "epoch 82; iter: 0; batch classifier loss: 0.346623; batch adversarial loss: 0.544326\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382154; batch adversarial loss: 0.499070\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390749; batch adversarial loss: 0.544624\n",
      "epoch 85; iter: 0; batch classifier loss: 0.356429; batch adversarial loss: 0.553731\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405644; batch adversarial loss: 0.554266\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366095; batch adversarial loss: 0.425984\n",
      "epoch 88; iter: 0; batch classifier loss: 0.499805; batch adversarial loss: 0.553702\n",
      "epoch 89; iter: 0; batch classifier loss: 0.420473; batch adversarial loss: 0.589931\n",
      "epoch 90; iter: 0; batch classifier loss: 0.406992; batch adversarial loss: 0.553480\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427721; batch adversarial loss: 0.580612\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371080; batch adversarial loss: 0.553587\n",
      "epoch 93; iter: 0; batch classifier loss: 0.490138; batch adversarial loss: 0.517539\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446619; batch adversarial loss: 0.599082\n",
      "epoch 95; iter: 0; batch classifier loss: 0.334191; batch adversarial loss: 0.489861\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372741; batch adversarial loss: 0.535451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368711; batch adversarial loss: 0.644660\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390595; batch adversarial loss: 0.553800\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408940; batch adversarial loss: 0.517242\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398654; batch adversarial loss: 0.644693\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414387; batch adversarial loss: 0.489615\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412409; batch adversarial loss: 0.581030\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385661; batch adversarial loss: 0.480834\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349792; batch adversarial loss: 0.580696\n",
      "epoch 105; iter: 0; batch classifier loss: 0.453968; batch adversarial loss: 0.544515\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381117; batch adversarial loss: 0.480618\n",
      "epoch 107; iter: 0; batch classifier loss: 0.453476; batch adversarial loss: 0.580937\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400900; batch adversarial loss: 0.590376\n",
      "epoch 109; iter: 0; batch classifier loss: 0.390671; batch adversarial loss: 0.525993\n",
      "epoch 110; iter: 0; batch classifier loss: 0.399775; batch adversarial loss: 0.535610\n",
      "epoch 111; iter: 0; batch classifier loss: 0.469737; batch adversarial loss: 0.617907\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326283; batch adversarial loss: 0.571766\n",
      "epoch 113; iter: 0; batch classifier loss: 0.428603; batch adversarial loss: 0.499003\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347708; batch adversarial loss: 0.617180\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370165; batch adversarial loss: 0.571796\n",
      "epoch 116; iter: 0; batch classifier loss: 0.397569; batch adversarial loss: 0.489684\n",
      "epoch 117; iter: 0; batch classifier loss: 0.417344; batch adversarial loss: 0.499051\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384052; batch adversarial loss: 0.517265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.412579; batch adversarial loss: 0.562484\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341772; batch adversarial loss: 0.617337\n",
      "epoch 121; iter: 0; batch classifier loss: 0.413766; batch adversarial loss: 0.572162\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400212; batch adversarial loss: 0.553643\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352780; batch adversarial loss: 0.571608\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403060; batch adversarial loss: 0.562646\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411881; batch adversarial loss: 0.517308\n",
      "epoch 126; iter: 0; batch classifier loss: 0.422487; batch adversarial loss: 0.498791\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362287; batch adversarial loss: 0.525928\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375725; batch adversarial loss: 0.535234\n",
      "epoch 129; iter: 0; batch classifier loss: 0.400419; batch adversarial loss: 0.526265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362280; batch adversarial loss: 0.498666\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399985; batch adversarial loss: 0.671960\n",
      "epoch 132; iter: 0; batch classifier loss: 0.316296; batch adversarial loss: 0.571893\n",
      "epoch 133; iter: 0; batch classifier loss: 0.414372; batch adversarial loss: 0.517086\n",
      "epoch 134; iter: 0; batch classifier loss: 0.252990; batch adversarial loss: 0.526145\n",
      "epoch 135; iter: 0; batch classifier loss: 0.431942; batch adversarial loss: 0.507818\n",
      "epoch 136; iter: 0; batch classifier loss: 0.266060; batch adversarial loss: 0.498763\n",
      "epoch 137; iter: 0; batch classifier loss: 0.404294; batch adversarial loss: 0.516816\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373431; batch adversarial loss: 0.480972\n",
      "epoch 139; iter: 0; batch classifier loss: 0.312566; batch adversarial loss: 0.535493\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354362; batch adversarial loss: 0.508351\n",
      "epoch 141; iter: 0; batch classifier loss: 0.308883; batch adversarial loss: 0.626530\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375884; batch adversarial loss: 0.581417\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358305; batch adversarial loss: 0.535827\n",
      "epoch 144; iter: 0; batch classifier loss: 0.400656; batch adversarial loss: 0.553739\n",
      "epoch 145; iter: 0; batch classifier loss: 0.305757; batch adversarial loss: 0.599328\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327771; batch adversarial loss: 0.572023\n",
      "epoch 147; iter: 0; batch classifier loss: 0.403364; batch adversarial loss: 0.498466\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357972; batch adversarial loss: 0.562909\n",
      "epoch 149; iter: 0; batch classifier loss: 0.422446; batch adversarial loss: 0.554025\n",
      "epoch 150; iter: 0; batch classifier loss: 0.329292; batch adversarial loss: 0.525858\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353202; batch adversarial loss: 0.562634\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366068; batch adversarial loss: 0.544839\n",
      "epoch 153; iter: 0; batch classifier loss: 0.404749; batch adversarial loss: 0.480492\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358898; batch adversarial loss: 0.608429\n",
      "epoch 155; iter: 0; batch classifier loss: 0.407629; batch adversarial loss: 0.554216\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337960; batch adversarial loss: 0.516922\n",
      "epoch 157; iter: 0; batch classifier loss: 0.300973; batch adversarial loss: 0.517049\n",
      "epoch 158; iter: 0; batch classifier loss: 0.437130; batch adversarial loss: 0.626471\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385296; batch adversarial loss: 0.462009\n",
      "epoch 160; iter: 0; batch classifier loss: 0.416026; batch adversarial loss: 0.599057\n",
      "epoch 161; iter: 0; batch classifier loss: 0.359733; batch adversarial loss: 0.499219\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370640; batch adversarial loss: 0.507850\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331329; batch adversarial loss: 0.562607\n",
      "epoch 164; iter: 0; batch classifier loss: 0.436962; batch adversarial loss: 0.517722\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405202; batch adversarial loss: 0.608001\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334935; batch adversarial loss: 0.516505\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346979; batch adversarial loss: 0.489913\n",
      "epoch 168; iter: 0; batch classifier loss: 0.309974; batch adversarial loss: 0.572080\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357282; batch adversarial loss: 0.517037\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352615; batch adversarial loss: 0.544233\n",
      "epoch 171; iter: 0; batch classifier loss: 0.367180; batch adversarial loss: 0.480442\n",
      "epoch 172; iter: 0; batch classifier loss: 0.386757; batch adversarial loss: 0.572463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351610; batch adversarial loss: 0.516819\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340905; batch adversarial loss: 0.517659\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346157; batch adversarial loss: 0.499147\n",
      "epoch 176; iter: 0; batch classifier loss: 0.305672; batch adversarial loss: 0.572014\n",
      "epoch 177; iter: 0; batch classifier loss: 0.288945; batch adversarial loss: 0.462676\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363937; batch adversarial loss: 0.517029\n",
      "epoch 179; iter: 0; batch classifier loss: 0.405908; batch adversarial loss: 0.526031\n",
      "epoch 180; iter: 0; batch classifier loss: 0.394233; batch adversarial loss: 0.535615\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387331; batch adversarial loss: 0.517369\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359120; batch adversarial loss: 0.553590\n",
      "epoch 183; iter: 0; batch classifier loss: 0.403412; batch adversarial loss: 0.599229\n",
      "epoch 184; iter: 0; batch classifier loss: 0.450411; batch adversarial loss: 0.617178\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379964; batch adversarial loss: 0.580828\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386602; batch adversarial loss: 0.535882\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367302; batch adversarial loss: 0.526471\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355092; batch adversarial loss: 0.644452\n",
      "epoch 189; iter: 0; batch classifier loss: 0.324812; batch adversarial loss: 0.544383\n",
      "epoch 190; iter: 0; batch classifier loss: 0.377421; batch adversarial loss: 0.562783\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351974; batch adversarial loss: 0.480919\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298979; batch adversarial loss: 0.517199\n",
      "epoch 193; iter: 0; batch classifier loss: 0.346638; batch adversarial loss: 0.553751\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360090; batch adversarial loss: 0.544541\n",
      "epoch 195; iter: 0; batch classifier loss: 0.293520; batch adversarial loss: 0.507889\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346759; batch adversarial loss: 0.572336\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353742; batch adversarial loss: 0.580892\n",
      "epoch 198; iter: 0; batch classifier loss: 0.441585; batch adversarial loss: 0.599233\n",
      "epoch 199; iter: 0; batch classifier loss: 0.402452; batch adversarial loss: 0.598808\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717843; batch adversarial loss: 0.742492\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587668; batch adversarial loss: 0.723282\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579555; batch adversarial loss: 0.673374\n",
      "epoch 3; iter: 0; batch classifier loss: 0.528099; batch adversarial loss: 0.642561\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557902; batch adversarial loss: 0.633661\n",
      "epoch 5; iter: 0; batch classifier loss: 0.503606; batch adversarial loss: 0.643929\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521195; batch adversarial loss: 0.610622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517426; batch adversarial loss: 0.605064\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526323; batch adversarial loss: 0.591112\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480574; batch adversarial loss: 0.551529\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579098; batch adversarial loss: 0.522955\n",
      "epoch 11; iter: 0; batch classifier loss: 0.488817; batch adversarial loss: 0.561991\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480188; batch adversarial loss: 0.536208\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508368; batch adversarial loss: 0.579574\n",
      "epoch 14; iter: 0; batch classifier loss: 0.536959; batch adversarial loss: 0.531684\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537516; batch adversarial loss: 0.616782\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504655; batch adversarial loss: 0.514287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.492759; batch adversarial loss: 0.618379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545910; batch adversarial loss: 0.645623\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532391; batch adversarial loss: 0.562102\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468876; batch adversarial loss: 0.568080\n",
      "epoch 21; iter: 0; batch classifier loss: 0.412868; batch adversarial loss: 0.514982\n",
      "epoch 22; iter: 0; batch classifier loss: 0.505369; batch adversarial loss: 0.564317\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474871; batch adversarial loss: 0.551287\n",
      "epoch 24; iter: 0; batch classifier loss: 0.510904; batch adversarial loss: 0.549058\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527353; batch adversarial loss: 0.507316\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471374; batch adversarial loss: 0.545759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461283; batch adversarial loss: 0.605698\n",
      "epoch 28; iter: 0; batch classifier loss: 0.458528; batch adversarial loss: 0.549479\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492778; batch adversarial loss: 0.531649\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457265; batch adversarial loss: 0.514106\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469750; batch adversarial loss: 0.579035\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484772; batch adversarial loss: 0.554478\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462420; batch adversarial loss: 0.595027\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427549; batch adversarial loss: 0.457509\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448570; batch adversarial loss: 0.545103\n",
      "epoch 36; iter: 0; batch classifier loss: 0.431607; batch adversarial loss: 0.528152\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438013; batch adversarial loss: 0.573166\n",
      "epoch 38; iter: 0; batch classifier loss: 0.525802; batch adversarial loss: 0.536052\n",
      "epoch 39; iter: 0; batch classifier loss: 0.375325; batch adversarial loss: 0.563374\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419181; batch adversarial loss: 0.442191\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397981; batch adversarial loss: 0.504493\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423474; batch adversarial loss: 0.515881\n",
      "epoch 43; iter: 0; batch classifier loss: 0.392829; batch adversarial loss: 0.614506\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422128; batch adversarial loss: 0.547741\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435321; batch adversarial loss: 0.544326\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467043; batch adversarial loss: 0.574361\n",
      "epoch 47; iter: 0; batch classifier loss: 0.448849; batch adversarial loss: 0.535540\n",
      "epoch 48; iter: 0; batch classifier loss: 0.394150; batch adversarial loss: 0.544497\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400106; batch adversarial loss: 0.542468\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468280; batch adversarial loss: 0.545951\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426383; batch adversarial loss: 0.554658\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385176; batch adversarial loss: 0.537558\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444149; batch adversarial loss: 0.506735\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431994; batch adversarial loss: 0.568913\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402234; batch adversarial loss: 0.617768\n",
      "epoch 56; iter: 0; batch classifier loss: 0.343586; batch adversarial loss: 0.437621\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392411; batch adversarial loss: 0.507818\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395375; batch adversarial loss: 0.553597\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433174; batch adversarial loss: 0.577371\n",
      "epoch 60; iter: 0; batch classifier loss: 0.344189; batch adversarial loss: 0.647158\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389019; batch adversarial loss: 0.499210\n",
      "epoch 62; iter: 0; batch classifier loss: 0.337816; batch adversarial loss: 0.512486\n",
      "epoch 63; iter: 0; batch classifier loss: 0.368931; batch adversarial loss: 0.498405\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397485; batch adversarial loss: 0.506958\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428895; batch adversarial loss: 0.524404\n",
      "epoch 66; iter: 0; batch classifier loss: 0.370157; batch adversarial loss: 0.629440\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395112; batch adversarial loss: 0.580901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.446217; batch adversarial loss: 0.647845\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358139; batch adversarial loss: 0.563274\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443209; batch adversarial loss: 0.525188\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407038; batch adversarial loss: 0.546786\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381043; batch adversarial loss: 0.560923\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424671; batch adversarial loss: 0.561887\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406154; batch adversarial loss: 0.459900\n",
      "epoch 75; iter: 0; batch classifier loss: 0.332007; batch adversarial loss: 0.617890\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371839; batch adversarial loss: 0.536768\n",
      "epoch 77; iter: 0; batch classifier loss: 0.353118; batch adversarial loss: 0.518360\n",
      "epoch 78; iter: 0; batch classifier loss: 0.461430; batch adversarial loss: 0.451052\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349180; batch adversarial loss: 0.598762\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389970; batch adversarial loss: 0.498843\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367476; batch adversarial loss: 0.553777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371878; batch adversarial loss: 0.550291\n",
      "epoch 83; iter: 0; batch classifier loss: 0.529480; batch adversarial loss: 0.543070\n",
      "epoch 84; iter: 0; batch classifier loss: 0.340021; batch adversarial loss: 0.493033\n",
      "epoch 85; iter: 0; batch classifier loss: 0.341221; batch adversarial loss: 0.552990\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378965; batch adversarial loss: 0.550803\n",
      "epoch 87; iter: 0; batch classifier loss: 0.381062; batch adversarial loss: 0.541605\n",
      "epoch 88; iter: 0; batch classifier loss: 0.449251; batch adversarial loss: 0.487276\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402521; batch adversarial loss: 0.431240\n",
      "epoch 90; iter: 0; batch classifier loss: 0.400572; batch adversarial loss: 0.503601\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390917; batch adversarial loss: 0.599914\n",
      "epoch 92; iter: 0; batch classifier loss: 0.347272; batch adversarial loss: 0.524763\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381532; batch adversarial loss: 0.562032\n",
      "epoch 94; iter: 0; batch classifier loss: 0.359844; batch adversarial loss: 0.517090\n",
      "epoch 95; iter: 0; batch classifier loss: 0.386023; batch adversarial loss: 0.507032\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399068; batch adversarial loss: 0.535096\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394126; batch adversarial loss: 0.524324\n",
      "epoch 98; iter: 0; batch classifier loss: 0.430779; batch adversarial loss: 0.583932\n",
      "epoch 99; iter: 0; batch classifier loss: 0.463260; batch adversarial loss: 0.574375\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360222; batch adversarial loss: 0.516507\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384514; batch adversarial loss: 0.527473\n",
      "epoch 102; iter: 0; batch classifier loss: 0.462558; batch adversarial loss: 0.543354\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361036; batch adversarial loss: 0.431550\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344724; batch adversarial loss: 0.611805\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362037; batch adversarial loss: 0.567019\n",
      "epoch 106; iter: 0; batch classifier loss: 0.293694; batch adversarial loss: 0.441619\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407835; batch adversarial loss: 0.561280\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327549; batch adversarial loss: 0.441107\n",
      "epoch 109; iter: 0; batch classifier loss: 0.314155; batch adversarial loss: 0.563056\n",
      "epoch 110; iter: 0; batch classifier loss: 0.292679; batch adversarial loss: 0.519370\n",
      "epoch 111; iter: 0; batch classifier loss: 0.470105; batch adversarial loss: 0.571053\n",
      "epoch 112; iter: 0; batch classifier loss: 0.450686; batch adversarial loss: 0.535002\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354958; batch adversarial loss: 0.551879\n",
      "epoch 114; iter: 0; batch classifier loss: 0.308578; batch adversarial loss: 0.574376\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405978; batch adversarial loss: 0.514927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.401306; batch adversarial loss: 0.574870\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389221; batch adversarial loss: 0.571805\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397797; batch adversarial loss: 0.543357\n",
      "epoch 119; iter: 0; batch classifier loss: 0.400239; batch adversarial loss: 0.385060\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337127; batch adversarial loss: 0.496372\n",
      "epoch 121; iter: 0; batch classifier loss: 0.479372; batch adversarial loss: 0.571870\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361506; batch adversarial loss: 0.600937\n",
      "epoch 123; iter: 0; batch classifier loss: 0.430195; batch adversarial loss: 0.562140\n",
      "epoch 124; iter: 0; batch classifier loss: 0.384240; batch adversarial loss: 0.535013\n",
      "epoch 125; iter: 0; batch classifier loss: 0.423310; batch adversarial loss: 0.515784\n",
      "epoch 126; iter: 0; batch classifier loss: 0.331436; batch adversarial loss: 0.622289\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349296; batch adversarial loss: 0.553279\n",
      "epoch 128; iter: 0; batch classifier loss: 0.426530; batch adversarial loss: 0.591843\n",
      "epoch 129; iter: 0; batch classifier loss: 0.297043; batch adversarial loss: 0.544277\n",
      "epoch 130; iter: 0; batch classifier loss: 0.303022; batch adversarial loss: 0.514644\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365977; batch adversarial loss: 0.505163\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431086; batch adversarial loss: 0.583129\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354113; batch adversarial loss: 0.543764\n",
      "epoch 134; iter: 0; batch classifier loss: 0.288164; batch adversarial loss: 0.535051\n",
      "epoch 135; iter: 0; batch classifier loss: 0.383764; batch adversarial loss: 0.573213\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366657; batch adversarial loss: 0.518372\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384307; batch adversarial loss: 0.503065\n",
      "epoch 138; iter: 0; batch classifier loss: 0.422835; batch adversarial loss: 0.580911\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344921; batch adversarial loss: 0.553337\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400553; batch adversarial loss: 0.516042\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367013; batch adversarial loss: 0.515474\n",
      "epoch 142; iter: 0; batch classifier loss: 0.443074; batch adversarial loss: 0.477242\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405648; batch adversarial loss: 0.498177\n",
      "epoch 144; iter: 0; batch classifier loss: 0.397339; batch adversarial loss: 0.543435\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364197; batch adversarial loss: 0.535501\n",
      "epoch 146; iter: 0; batch classifier loss: 0.386055; batch adversarial loss: 0.523117\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362224; batch adversarial loss: 0.534636\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389322; batch adversarial loss: 0.565256\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344875; batch adversarial loss: 0.535464\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391387; batch adversarial loss: 0.534491\n",
      "epoch 151; iter: 0; batch classifier loss: 0.385113; batch adversarial loss: 0.543719\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372992; batch adversarial loss: 0.584260\n",
      "epoch 153; iter: 0; batch classifier loss: 0.443455; batch adversarial loss: 0.554794\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349902; batch adversarial loss: 0.535144\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341832; batch adversarial loss: 0.552254\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361432; batch adversarial loss: 0.590004\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403665; batch adversarial loss: 0.592128\n",
      "epoch 158; iter: 0; batch classifier loss: 0.421723; batch adversarial loss: 0.536408\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342195; batch adversarial loss: 0.564614\n",
      "epoch 160; iter: 0; batch classifier loss: 0.322908; batch adversarial loss: 0.609476\n",
      "epoch 161; iter: 0; batch classifier loss: 0.244378; batch adversarial loss: 0.506631\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379814; batch adversarial loss: 0.554697\n",
      "epoch 163; iter: 0; batch classifier loss: 0.323806; batch adversarial loss: 0.545680\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328750; batch adversarial loss: 0.534379\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318472; batch adversarial loss: 0.478832\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373968; batch adversarial loss: 0.563864\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366618; batch adversarial loss: 0.504263\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344136; batch adversarial loss: 0.591721\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334652; batch adversarial loss: 0.554364\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353931; batch adversarial loss: 0.495673\n",
      "epoch 171; iter: 0; batch classifier loss: 0.413876; batch adversarial loss: 0.498840\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368876; batch adversarial loss: 0.554992\n",
      "epoch 173; iter: 0; batch classifier loss: 0.439207; batch adversarial loss: 0.573181\n",
      "epoch 174; iter: 0; batch classifier loss: 0.352885; batch adversarial loss: 0.512739\n",
      "epoch 175; iter: 0; batch classifier loss: 0.402082; batch adversarial loss: 0.580894\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339645; batch adversarial loss: 0.546425\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343126; batch adversarial loss: 0.608772\n",
      "epoch 178; iter: 0; batch classifier loss: 0.398951; batch adversarial loss: 0.489257\n",
      "epoch 179; iter: 0; batch classifier loss: 0.403735; batch adversarial loss: 0.637075\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359463; batch adversarial loss: 0.543996\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323684; batch adversarial loss: 0.545883\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376753; batch adversarial loss: 0.513580\n",
      "epoch 183; iter: 0; batch classifier loss: 0.310367; batch adversarial loss: 0.599927\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342858; batch adversarial loss: 0.507097\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392313; batch adversarial loss: 0.554685\n",
      "epoch 186; iter: 0; batch classifier loss: 0.433794; batch adversarial loss: 0.498092\n",
      "epoch 187; iter: 0; batch classifier loss: 0.384349; batch adversarial loss: 0.544199\n",
      "epoch 188; iter: 0; batch classifier loss: 0.276402; batch adversarial loss: 0.488482\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333032; batch adversarial loss: 0.432625\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407890; batch adversarial loss: 0.536780\n",
      "epoch 191; iter: 0; batch classifier loss: 0.299801; batch adversarial loss: 0.441197\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362841; batch adversarial loss: 0.561766\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320353; batch adversarial loss: 0.600872\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343844; batch adversarial loss: 0.431308\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335756; batch adversarial loss: 0.504797\n",
      "epoch 196; iter: 0; batch classifier loss: 0.329660; batch adversarial loss: 0.544197\n",
      "epoch 197; iter: 0; batch classifier loss: 0.293800; batch adversarial loss: 0.572703\n",
      "epoch 198; iter: 0; batch classifier loss: 0.288804; batch adversarial loss: 0.477951\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351966; batch adversarial loss: 0.515205\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690779; batch adversarial loss: 0.654906\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587980; batch adversarial loss: 0.650468\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578257; batch adversarial loss: 0.701875\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538888; batch adversarial loss: 0.608414\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621803; batch adversarial loss: 0.592979\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621559; batch adversarial loss: 0.626431\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559080; batch adversarial loss: 0.605304\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514075; batch adversarial loss: 0.540599\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530097; batch adversarial loss: 0.643561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589088; batch adversarial loss: 0.650277\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567252; batch adversarial loss: 0.626393\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490068; batch adversarial loss: 0.617262\n",
      "epoch 12; iter: 0; batch classifier loss: 0.486679; batch adversarial loss: 0.617614\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567484; batch adversarial loss: 0.549483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.549471; batch adversarial loss: 0.485003\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494279; batch adversarial loss: 0.528475\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502627; batch adversarial loss: 0.539576\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451341; batch adversarial loss: 0.538613\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506693; batch adversarial loss: 0.546330\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542833; batch adversarial loss: 0.472109\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496269; batch adversarial loss: 0.547006\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499367; batch adversarial loss: 0.555641\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500914; batch adversarial loss: 0.473727\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455131; batch adversarial loss: 0.593065\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434638; batch adversarial loss: 0.505209\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471557; batch adversarial loss: 0.575132\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491152; batch adversarial loss: 0.508408\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470039; batch adversarial loss: 0.486236\n",
      "epoch 28; iter: 0; batch classifier loss: 0.555885; batch adversarial loss: 0.522917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509337; batch adversarial loss: 0.492469\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504003; batch adversarial loss: 0.517878\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473130; batch adversarial loss: 0.556684\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490903; batch adversarial loss: 0.510038\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441494; batch adversarial loss: 0.540224\n",
      "epoch 34; iter: 0; batch classifier loss: 0.424481; batch adversarial loss: 0.540149\n",
      "epoch 35; iter: 0; batch classifier loss: 0.611714; batch adversarial loss: 0.548363\n",
      "epoch 36; iter: 0; batch classifier loss: 0.370469; batch adversarial loss: 0.606634\n",
      "epoch 37; iter: 0; batch classifier loss: 0.478384; batch adversarial loss: 0.517753\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408525; batch adversarial loss: 0.454038\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430312; batch adversarial loss: 0.585105\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403326; batch adversarial loss: 0.524110\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459268; batch adversarial loss: 0.566069\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423879; batch adversarial loss: 0.520354\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459471; batch adversarial loss: 0.572880\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460425; batch adversarial loss: 0.590310\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435510; batch adversarial loss: 0.515414\n",
      "epoch 46; iter: 0; batch classifier loss: 0.498632; batch adversarial loss: 0.524440\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433540; batch adversarial loss: 0.563912\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445515; batch adversarial loss: 0.523099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452291; batch adversarial loss: 0.574495\n",
      "epoch 50; iter: 0; batch classifier loss: 0.500226; batch adversarial loss: 0.476957\n",
      "epoch 51; iter: 0; batch classifier loss: 0.460356; batch adversarial loss: 0.525063\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434561; batch adversarial loss: 0.506324\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405018; batch adversarial loss: 0.525902\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474833; batch adversarial loss: 0.592883\n",
      "epoch 55; iter: 0; batch classifier loss: 0.355483; batch adversarial loss: 0.554606\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448213; batch adversarial loss: 0.572370\n",
      "epoch 57; iter: 0; batch classifier loss: 0.361225; batch adversarial loss: 0.562738\n",
      "epoch 58; iter: 0; batch classifier loss: 0.457947; batch adversarial loss: 0.623029\n",
      "epoch 59; iter: 0; batch classifier loss: 0.477709; batch adversarial loss: 0.573068\n",
      "epoch 60; iter: 0; batch classifier loss: 0.478661; batch adversarial loss: 0.506647\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424345; batch adversarial loss: 0.583022\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388044; batch adversarial loss: 0.534181\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442981; batch adversarial loss: 0.524794\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424442; batch adversarial loss: 0.601312\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457782; batch adversarial loss: 0.496974\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403012; batch adversarial loss: 0.582782\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351707; batch adversarial loss: 0.583440\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415914; batch adversarial loss: 0.563274\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376330; batch adversarial loss: 0.554888\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433859; batch adversarial loss: 0.553394\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437148; batch adversarial loss: 0.631483\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358519; batch adversarial loss: 0.506054\n",
      "epoch 73; iter: 0; batch classifier loss: 0.489960; batch adversarial loss: 0.426711\n",
      "epoch 74; iter: 0; batch classifier loss: 0.492082; batch adversarial loss: 0.542354\n",
      "epoch 75; iter: 0; batch classifier loss: 0.460133; batch adversarial loss: 0.553566\n",
      "epoch 76; iter: 0; batch classifier loss: 0.497693; batch adversarial loss: 0.544566\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385883; batch adversarial loss: 0.552717\n",
      "epoch 78; iter: 0; batch classifier loss: 0.467238; batch adversarial loss: 0.544627\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354004; batch adversarial loss: 0.494041\n",
      "epoch 80; iter: 0; batch classifier loss: 0.513386; batch adversarial loss: 0.463722\n",
      "epoch 81; iter: 0; batch classifier loss: 0.331600; batch adversarial loss: 0.496021\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406859; batch adversarial loss: 0.522300\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422831; batch adversarial loss: 0.571673\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375335; batch adversarial loss: 0.499428\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370943; batch adversarial loss: 0.529600\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425788; batch adversarial loss: 0.591012\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413821; batch adversarial loss: 0.547886\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367876; batch adversarial loss: 0.603688\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417465; batch adversarial loss: 0.574387\n",
      "epoch 90; iter: 0; batch classifier loss: 0.437459; batch adversarial loss: 0.431863\n",
      "epoch 91; iter: 0; batch classifier loss: 0.335451; batch adversarial loss: 0.544910\n",
      "epoch 92; iter: 0; batch classifier loss: 0.343528; batch adversarial loss: 0.549767\n",
      "epoch 93; iter: 0; batch classifier loss: 0.444820; batch adversarial loss: 0.516049\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425215; batch adversarial loss: 0.507510\n",
      "epoch 95; iter: 0; batch classifier loss: 0.332717; batch adversarial loss: 0.524732\n",
      "epoch 96; iter: 0; batch classifier loss: 0.454656; batch adversarial loss: 0.564904\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358157; batch adversarial loss: 0.535523\n",
      "epoch 98; iter: 0; batch classifier loss: 0.444173; batch adversarial loss: 0.459640\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384088; batch adversarial loss: 0.553313\n",
      "epoch 100; iter: 0; batch classifier loss: 0.379687; batch adversarial loss: 0.526236\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359191; batch adversarial loss: 0.506959\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332464; batch adversarial loss: 0.478104\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399331; batch adversarial loss: 0.554094\n",
      "epoch 104; iter: 0; batch classifier loss: 0.330870; batch adversarial loss: 0.516017\n",
      "epoch 105; iter: 0; batch classifier loss: 0.336977; batch adversarial loss: 0.563725\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376151; batch adversarial loss: 0.486584\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375988; batch adversarial loss: 0.543831\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388079; batch adversarial loss: 0.620540\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357742; batch adversarial loss: 0.477705\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429676; batch adversarial loss: 0.437966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433671; batch adversarial loss: 0.564029\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402308; batch adversarial loss: 0.565226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.333318; batch adversarial loss: 0.534824\n",
      "epoch 114; iter: 0; batch classifier loss: 0.436483; batch adversarial loss: 0.544315\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364672; batch adversarial loss: 0.515835\n",
      "epoch 116; iter: 0; batch classifier loss: 0.419066; batch adversarial loss: 0.592409\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392949; batch adversarial loss: 0.516296\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343835; batch adversarial loss: 0.535378\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394125; batch adversarial loss: 0.515959\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375894; batch adversarial loss: 0.478022\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360802; batch adversarial loss: 0.515286\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345517; batch adversarial loss: 0.458388\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369475; batch adversarial loss: 0.516120\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368421; batch adversarial loss: 0.515677\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369260; batch adversarial loss: 0.574406\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391782; batch adversarial loss: 0.458685\n",
      "epoch 127; iter: 0; batch classifier loss: 0.460194; batch adversarial loss: 0.468500\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346562; batch adversarial loss: 0.563554\n",
      "epoch 129; iter: 0; batch classifier loss: 0.349889; batch adversarial loss: 0.563511\n",
      "epoch 130; iter: 0; batch classifier loss: 0.453052; batch adversarial loss: 0.516067\n",
      "epoch 131; iter: 0; batch classifier loss: 0.397836; batch adversarial loss: 0.506358\n",
      "epoch 132; iter: 0; batch classifier loss: 0.410776; batch adversarial loss: 0.476872\n",
      "epoch 133; iter: 0; batch classifier loss: 0.484613; batch adversarial loss: 0.612472\n",
      "epoch 134; iter: 0; batch classifier loss: 0.317626; batch adversarial loss: 0.525535\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325701; batch adversarial loss: 0.659815\n",
      "epoch 136; iter: 0; batch classifier loss: 0.335227; batch adversarial loss: 0.467762\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354462; batch adversarial loss: 0.564786\n",
      "epoch 138; iter: 0; batch classifier loss: 0.439776; batch adversarial loss: 0.583176\n",
      "epoch 139; iter: 0; batch classifier loss: 0.385175; batch adversarial loss: 0.660706\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399615; batch adversarial loss: 0.535663\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357582; batch adversarial loss: 0.525314\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361447; batch adversarial loss: 0.515835\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408244; batch adversarial loss: 0.477606\n",
      "epoch 144; iter: 0; batch classifier loss: 0.455092; batch adversarial loss: 0.601908\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383878; batch adversarial loss: 0.554297\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385755; batch adversarial loss: 0.563798\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383671; batch adversarial loss: 0.515858\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338924; batch adversarial loss: 0.593453\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384658; batch adversarial loss: 0.603084\n",
      "epoch 150; iter: 0; batch classifier loss: 0.445687; batch adversarial loss: 0.495169\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409496; batch adversarial loss: 0.603121\n",
      "epoch 152; iter: 0; batch classifier loss: 0.409386; batch adversarial loss: 0.583834\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383606; batch adversarial loss: 0.497452\n",
      "epoch 154; iter: 0; batch classifier loss: 0.490681; batch adversarial loss: 0.535333\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406088; batch adversarial loss: 0.486483\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357371; batch adversarial loss: 0.544988\n",
      "epoch 157; iter: 0; batch classifier loss: 0.345419; batch adversarial loss: 0.544333\n",
      "epoch 158; iter: 0; batch classifier loss: 0.422978; batch adversarial loss: 0.487385\n",
      "epoch 159; iter: 0; batch classifier loss: 0.285543; batch adversarial loss: 0.497500\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314494; batch adversarial loss: 0.563577\n",
      "epoch 161; iter: 0; batch classifier loss: 0.428874; batch adversarial loss: 0.505682\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328582; batch adversarial loss: 0.515908\n",
      "epoch 163; iter: 0; batch classifier loss: 0.393410; batch adversarial loss: 0.505978\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387418; batch adversarial loss: 0.563195\n",
      "epoch 165; iter: 0; batch classifier loss: 0.413598; batch adversarial loss: 0.409763\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388897; batch adversarial loss: 0.525169\n",
      "epoch 167; iter: 0; batch classifier loss: 0.435378; batch adversarial loss: 0.544752\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377835; batch adversarial loss: 0.439467\n",
      "epoch 169; iter: 0; batch classifier loss: 0.365813; batch adversarial loss: 0.525583\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397174; batch adversarial loss: 0.477663\n",
      "epoch 171; iter: 0; batch classifier loss: 0.309477; batch adversarial loss: 0.477545\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345888; batch adversarial loss: 0.601897\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340126; batch adversarial loss: 0.419550\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340546; batch adversarial loss: 0.604014\n",
      "epoch 175; iter: 0; batch classifier loss: 0.456881; batch adversarial loss: 0.534512\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336209; batch adversarial loss: 0.486603\n",
      "epoch 177; iter: 0; batch classifier loss: 0.296275; batch adversarial loss: 0.516046\n",
      "epoch 178; iter: 0; batch classifier loss: 0.375992; batch adversarial loss: 0.544834\n",
      "epoch 179; iter: 0; batch classifier loss: 0.415132; batch adversarial loss: 0.506342\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350814; batch adversarial loss: 0.592266\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333167; batch adversarial loss: 0.525943\n",
      "epoch 182; iter: 0; batch classifier loss: 0.388639; batch adversarial loss: 0.534979\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371359; batch adversarial loss: 0.601759\n",
      "epoch 184; iter: 0; batch classifier loss: 0.341508; batch adversarial loss: 0.554233\n",
      "epoch 185; iter: 0; batch classifier loss: 0.437955; batch adversarial loss: 0.515968\n",
      "epoch 186; iter: 0; batch classifier loss: 0.401667; batch adversarial loss: 0.544599\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389385; batch adversarial loss: 0.592065\n",
      "epoch 188; iter: 0; batch classifier loss: 0.406249; batch adversarial loss: 0.525107\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368503; batch adversarial loss: 0.497294\n",
      "epoch 190; iter: 0; batch classifier loss: 0.434495; batch adversarial loss: 0.544539\n",
      "epoch 191; iter: 0; batch classifier loss: 0.422504; batch adversarial loss: 0.563562\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313054; batch adversarial loss: 0.497309\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364585; batch adversarial loss: 0.448262\n",
      "epoch 194; iter: 0; batch classifier loss: 0.389776; batch adversarial loss: 0.651308\n",
      "epoch 195; iter: 0; batch classifier loss: 0.546083; batch adversarial loss: 0.535175\n",
      "epoch 196; iter: 0; batch classifier loss: 0.367008; batch adversarial loss: 0.563736\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357322; batch adversarial loss: 0.563768\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383383; batch adversarial loss: 0.564041\n",
      "epoch 199; iter: 0; batch classifier loss: 0.420400; batch adversarial loss: 0.534879\n",
      "epoch 0; iter: 0; batch classifier loss: 0.813795; batch adversarial loss: 0.806529\n",
      "epoch 1; iter: 0; batch classifier loss: 0.765869; batch adversarial loss: 0.781427\n",
      "epoch 2; iter: 0; batch classifier loss: 0.787668; batch adversarial loss: 0.718596\n",
      "epoch 3; iter: 0; batch classifier loss: 0.669601; batch adversarial loss: 0.652452\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590649; batch adversarial loss: 0.613207\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566899; batch adversarial loss: 0.607743\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550590; batch adversarial loss: 0.607719\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529877; batch adversarial loss: 0.590259\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532391; batch adversarial loss: 0.616522\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547109; batch adversarial loss: 0.589914\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502424; batch adversarial loss: 0.595226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.560629; batch adversarial loss: 0.609329\n",
      "epoch 12; iter: 0; batch classifier loss: 0.446776; batch adversarial loss: 0.620570\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495279; batch adversarial loss: 0.531420\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478823; batch adversarial loss: 0.593037\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502071; batch adversarial loss: 0.518163\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482564; batch adversarial loss: 0.597374\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485535; batch adversarial loss: 0.554910\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522450; batch adversarial loss: 0.536170\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462418; batch adversarial loss: 0.552123\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519968; batch adversarial loss: 0.571722\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513934; batch adversarial loss: 0.559479\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501789; batch adversarial loss: 0.580475\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470152; batch adversarial loss: 0.650483\n",
      "epoch 24; iter: 0; batch classifier loss: 0.537399; batch adversarial loss: 0.526030\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470147; batch adversarial loss: 0.572652\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491827; batch adversarial loss: 0.539720\n",
      "epoch 27; iter: 0; batch classifier loss: 0.504657; batch adversarial loss: 0.567256\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452745; batch adversarial loss: 0.577060\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496827; batch adversarial loss: 0.584511\n",
      "epoch 30; iter: 0; batch classifier loss: 0.460121; batch adversarial loss: 0.604352\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474980; batch adversarial loss: 0.642014\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454110; batch adversarial loss: 0.567770\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406094; batch adversarial loss: 0.565951\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453710; batch adversarial loss: 0.596761\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433385; batch adversarial loss: 0.506355\n",
      "epoch 36; iter: 0; batch classifier loss: 0.467027; batch adversarial loss: 0.511399\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431655; batch adversarial loss: 0.545028\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432112; batch adversarial loss: 0.543906\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497634; batch adversarial loss: 0.555921\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445630; batch adversarial loss: 0.527856\n",
      "epoch 41; iter: 0; batch classifier loss: 0.488846; batch adversarial loss: 0.514581\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472203; batch adversarial loss: 0.471321\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438262; batch adversarial loss: 0.479562\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451695; batch adversarial loss: 0.504153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442313; batch adversarial loss: 0.572696\n",
      "epoch 46; iter: 0; batch classifier loss: 0.373670; batch adversarial loss: 0.557500\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466936; batch adversarial loss: 0.499569\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468777; batch adversarial loss: 0.490453\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413766; batch adversarial loss: 0.553778\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413797; batch adversarial loss: 0.526424\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392707; batch adversarial loss: 0.535364\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429561; batch adversarial loss: 0.590908\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421380; batch adversarial loss: 0.553799\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394887; batch adversarial loss: 0.572538\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403795; batch adversarial loss: 0.535115\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414890; batch adversarial loss: 0.534991\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438813; batch adversarial loss: 0.544741\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426596; batch adversarial loss: 0.516581\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435142; batch adversarial loss: 0.516169\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416848; batch adversarial loss: 0.516211\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417657; batch adversarial loss: 0.544290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.514522; batch adversarial loss: 0.487597\n",
      "epoch 63; iter: 0; batch classifier loss: 0.349959; batch adversarial loss: 0.507029\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362526; batch adversarial loss: 0.506089\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450829; batch adversarial loss: 0.563021\n",
      "epoch 66; iter: 0; batch classifier loss: 0.355279; batch adversarial loss: 0.544309\n",
      "epoch 67; iter: 0; batch classifier loss: 0.330405; batch adversarial loss: 0.449460\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381901; batch adversarial loss: 0.602133\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400227; batch adversarial loss: 0.534600\n",
      "epoch 70; iter: 0; batch classifier loss: 0.363807; batch adversarial loss: 0.572632\n",
      "epoch 71; iter: 0; batch classifier loss: 0.351770; batch adversarial loss: 0.543026\n",
      "epoch 72; iter: 0; batch classifier loss: 0.347664; batch adversarial loss: 0.524699\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374342; batch adversarial loss: 0.506398\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412043; batch adversarial loss: 0.621651\n",
      "epoch 75; iter: 0; batch classifier loss: 0.439150; batch adversarial loss: 0.535570\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367408; batch adversarial loss: 0.525084\n",
      "epoch 77; iter: 0; batch classifier loss: 0.318933; batch adversarial loss: 0.517043\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444265; batch adversarial loss: 0.545622\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419063; batch adversarial loss: 0.572732\n",
      "epoch 80; iter: 0; batch classifier loss: 0.350295; batch adversarial loss: 0.620995\n",
      "epoch 81; iter: 0; batch classifier loss: 0.352207; batch adversarial loss: 0.571880\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394228; batch adversarial loss: 0.581534\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371136; batch adversarial loss: 0.524636\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426672; batch adversarial loss: 0.517103\n",
      "epoch 85; iter: 0; batch classifier loss: 0.353313; batch adversarial loss: 0.591623\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415329; batch adversarial loss: 0.477937\n",
      "epoch 87; iter: 0; batch classifier loss: 0.414061; batch adversarial loss: 0.459351\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429872; batch adversarial loss: 0.478347\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415641; batch adversarial loss: 0.440693\n",
      "epoch 90; iter: 0; batch classifier loss: 0.382542; batch adversarial loss: 0.554066\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376809; batch adversarial loss: 0.572675\n",
      "epoch 92; iter: 0; batch classifier loss: 0.337616; batch adversarial loss: 0.592574\n",
      "epoch 93; iter: 0; batch classifier loss: 0.323719; batch adversarial loss: 0.451689\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381425; batch adversarial loss: 0.571791\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401051; batch adversarial loss: 0.542746\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336599; batch adversarial loss: 0.562553\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390532; batch adversarial loss: 0.574482\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393379; batch adversarial loss: 0.468197\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400032; batch adversarial loss: 0.592255\n",
      "epoch 100; iter: 0; batch classifier loss: 0.320088; batch adversarial loss: 0.609174\n",
      "epoch 101; iter: 0; batch classifier loss: 0.377878; batch adversarial loss: 0.600122\n",
      "epoch 102; iter: 0; batch classifier loss: 0.339343; batch adversarial loss: 0.515677\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391535; batch adversarial loss: 0.554343\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377927; batch adversarial loss: 0.545878\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388214; batch adversarial loss: 0.582156\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334431; batch adversarial loss: 0.572109\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393482; batch adversarial loss: 0.515956\n",
      "epoch 108; iter: 0; batch classifier loss: 0.312282; batch adversarial loss: 0.506246\n",
      "epoch 109; iter: 0; batch classifier loss: 0.369490; batch adversarial loss: 0.543052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.427404; batch adversarial loss: 0.460348\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359865; batch adversarial loss: 0.562551\n",
      "epoch 112; iter: 0; batch classifier loss: 0.316548; batch adversarial loss: 0.535617\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350943; batch adversarial loss: 0.544887\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375143; batch adversarial loss: 0.609489\n",
      "epoch 115; iter: 0; batch classifier loss: 0.415597; batch adversarial loss: 0.571078\n",
      "epoch 116; iter: 0; batch classifier loss: 0.362085; batch adversarial loss: 0.562060\n",
      "epoch 117; iter: 0; batch classifier loss: 0.420929; batch adversarial loss: 0.583609\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355871; batch adversarial loss: 0.516304\n",
      "epoch 119; iter: 0; batch classifier loss: 0.445920; batch adversarial loss: 0.535136\n",
      "epoch 120; iter: 0; batch classifier loss: 0.335041; batch adversarial loss: 0.543727\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347655; batch adversarial loss: 0.459136\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397839; batch adversarial loss: 0.515716\n",
      "epoch 123; iter: 0; batch classifier loss: 0.347666; batch adversarial loss: 0.608996\n",
      "epoch 124; iter: 0; batch classifier loss: 0.429237; batch adversarial loss: 0.601597\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377023; batch adversarial loss: 0.524597\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413389; batch adversarial loss: 0.598972\n",
      "epoch 127; iter: 0; batch classifier loss: 0.438261; batch adversarial loss: 0.573071\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313210; batch adversarial loss: 0.572615\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374690; batch adversarial loss: 0.629226\n",
      "epoch 130; iter: 0; batch classifier loss: 0.347013; batch adversarial loss: 0.600627\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364078; batch adversarial loss: 0.488145\n",
      "epoch 132; iter: 0; batch classifier loss: 0.239163; batch adversarial loss: 0.562713\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392216; batch adversarial loss: 0.572461\n",
      "epoch 134; iter: 0; batch classifier loss: 0.328242; batch adversarial loss: 0.516663\n",
      "epoch 135; iter: 0; batch classifier loss: 0.451183; batch adversarial loss: 0.505948\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387782; batch adversarial loss: 0.592402\n",
      "epoch 137; iter: 0; batch classifier loss: 0.317570; batch adversarial loss: 0.573924\n",
      "epoch 138; iter: 0; batch classifier loss: 0.351970; batch adversarial loss: 0.422770\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362342; batch adversarial loss: 0.487378\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366968; batch adversarial loss: 0.535540\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356505; batch adversarial loss: 0.544244\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355365; batch adversarial loss: 0.506653\n",
      "epoch 143; iter: 0; batch classifier loss: 0.435518; batch adversarial loss: 0.516704\n",
      "epoch 144; iter: 0; batch classifier loss: 0.320014; batch adversarial loss: 0.535257\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359721; batch adversarial loss: 0.553183\n",
      "epoch 146; iter: 0; batch classifier loss: 0.316411; batch adversarial loss: 0.591655\n",
      "epoch 147; iter: 0; batch classifier loss: 0.423680; batch adversarial loss: 0.545448\n",
      "epoch 148; iter: 0; batch classifier loss: 0.309926; batch adversarial loss: 0.487932\n",
      "epoch 149; iter: 0; batch classifier loss: 0.386528; batch adversarial loss: 0.449834\n",
      "epoch 150; iter: 0; batch classifier loss: 0.366212; batch adversarial loss: 0.526089\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390692; batch adversarial loss: 0.601101\n",
      "epoch 152; iter: 0; batch classifier loss: 0.329073; batch adversarial loss: 0.619823\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324593; batch adversarial loss: 0.545052\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390015; batch adversarial loss: 0.497352\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341057; batch adversarial loss: 0.544468\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348856; batch adversarial loss: 0.516636\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356900; batch adversarial loss: 0.647508\n",
      "epoch 158; iter: 0; batch classifier loss: 0.432224; batch adversarial loss: 0.515733\n",
      "epoch 159; iter: 0; batch classifier loss: 0.326009; batch adversarial loss: 0.544054\n",
      "epoch 160; iter: 0; batch classifier loss: 0.396371; batch adversarial loss: 0.562510\n",
      "epoch 161; iter: 0; batch classifier loss: 0.306219; batch adversarial loss: 0.554307\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311550; batch adversarial loss: 0.618554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.264617; batch adversarial loss: 0.525609\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335635; batch adversarial loss: 0.563093\n",
      "epoch 165; iter: 0; batch classifier loss: 0.294864; batch adversarial loss: 0.496710\n",
      "epoch 166; iter: 0; batch classifier loss: 0.288752; batch adversarial loss: 0.535365\n",
      "epoch 167; iter: 0; batch classifier loss: 0.402987; batch adversarial loss: 0.526412\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380416; batch adversarial loss: 0.497307\n",
      "epoch 169; iter: 0; batch classifier loss: 0.411212; batch adversarial loss: 0.591560\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361586; batch adversarial loss: 0.554625\n",
      "epoch 171; iter: 0; batch classifier loss: 0.289331; batch adversarial loss: 0.543631\n",
      "epoch 172; iter: 0; batch classifier loss: 0.338700; batch adversarial loss: 0.487995\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369802; batch adversarial loss: 0.572421\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396862; batch adversarial loss: 0.516704\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338144; batch adversarial loss: 0.497011\n",
      "epoch 176; iter: 0; batch classifier loss: 0.416228; batch adversarial loss: 0.572677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340999; batch adversarial loss: 0.535754\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381839; batch adversarial loss: 0.534054\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323393; batch adversarial loss: 0.564050\n",
      "epoch 180; iter: 0; batch classifier loss: 0.336072; batch adversarial loss: 0.582316\n",
      "epoch 181; iter: 0; batch classifier loss: 0.449416; batch adversarial loss: 0.450878\n",
      "epoch 182; iter: 0; batch classifier loss: 0.392728; batch adversarial loss: 0.574572\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355512; batch adversarial loss: 0.487316\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357909; batch adversarial loss: 0.525792\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326456; batch adversarial loss: 0.601622\n",
      "epoch 186; iter: 0; batch classifier loss: 0.440323; batch adversarial loss: 0.543528\n",
      "epoch 187; iter: 0; batch classifier loss: 0.298072; batch adversarial loss: 0.534680\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318320; batch adversarial loss: 0.638325\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305798; batch adversarial loss: 0.441207\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365442; batch adversarial loss: 0.554366\n",
      "epoch 191; iter: 0; batch classifier loss: 0.405793; batch adversarial loss: 0.601435\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320880; batch adversarial loss: 0.479666\n",
      "epoch 193; iter: 0; batch classifier loss: 0.322322; batch adversarial loss: 0.620468\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399326; batch adversarial loss: 0.571998\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393151; batch adversarial loss: 0.637592\n",
      "epoch 196; iter: 0; batch classifier loss: 0.287986; batch adversarial loss: 0.590453\n",
      "epoch 197; iter: 0; batch classifier loss: 0.405412; batch adversarial loss: 0.468553\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356023; batch adversarial loss: 0.553126\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315972; batch adversarial loss: 0.601865\n",
      "epoch 0; iter: 0; batch classifier loss: 0.744660; batch adversarial loss: 0.639571\n",
      "epoch 1; iter: 0; batch classifier loss: 0.617570; batch adversarial loss: 0.673892\n",
      "epoch 2; iter: 0; batch classifier loss: 0.523780; batch adversarial loss: 0.650460\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585501; batch adversarial loss: 0.638806\n",
      "epoch 4; iter: 0; batch classifier loss: 0.530365; batch adversarial loss: 0.644660\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580410; batch adversarial loss: 0.604003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.533581; batch adversarial loss: 0.614713\n",
      "epoch 7; iter: 0; batch classifier loss: 0.477632; batch adversarial loss: 0.560114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546640; batch adversarial loss: 0.562843\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516716; batch adversarial loss: 0.605856\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565717; batch adversarial loss: 0.569488\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533915; batch adversarial loss: 0.585126\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489430; batch adversarial loss: 0.632879\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533755; batch adversarial loss: 0.611849\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543222; batch adversarial loss: 0.568045\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468938; batch adversarial loss: 0.562234\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531204; batch adversarial loss: 0.510609\n",
      "epoch 17; iter: 0; batch classifier loss: 0.469487; batch adversarial loss: 0.521761\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465034; batch adversarial loss: 0.515374\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514672; batch adversarial loss: 0.605491\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477254; batch adversarial loss: 0.562982\n",
      "epoch 21; iter: 0; batch classifier loss: 0.427524; batch adversarial loss: 0.577593\n",
      "epoch 22; iter: 0; batch classifier loss: 0.505857; batch adversarial loss: 0.540046\n",
      "epoch 23; iter: 0; batch classifier loss: 0.417645; batch adversarial loss: 0.550256\n",
      "epoch 24; iter: 0; batch classifier loss: 0.424518; batch adversarial loss: 0.612785\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479879; batch adversarial loss: 0.537778\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512250; batch adversarial loss: 0.564743\n",
      "epoch 27; iter: 0; batch classifier loss: 0.539518; batch adversarial loss: 0.538725\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450926; batch adversarial loss: 0.580992\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405510; batch adversarial loss: 0.563594\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432436; batch adversarial loss: 0.610474\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449517; batch adversarial loss: 0.545546\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477699; batch adversarial loss: 0.523700\n",
      "epoch 33; iter: 0; batch classifier loss: 0.490554; batch adversarial loss: 0.583345\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438218; batch adversarial loss: 0.541773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.401433; batch adversarial loss: 0.580591\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403858; batch adversarial loss: 0.640025\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400973; batch adversarial loss: 0.571339\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419929; batch adversarial loss: 0.529453\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490429; batch adversarial loss: 0.542727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495168; batch adversarial loss: 0.686100\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466846; batch adversarial loss: 0.546688\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460478; batch adversarial loss: 0.546294\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375430; batch adversarial loss: 0.537099\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437353; batch adversarial loss: 0.595108\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450539; batch adversarial loss: 0.526554\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381939; batch adversarial loss: 0.529697\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430943; batch adversarial loss: 0.501948\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383761; batch adversarial loss: 0.577497\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452209; batch adversarial loss: 0.518428\n",
      "epoch 50; iter: 0; batch classifier loss: 0.452271; batch adversarial loss: 0.497799\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426490; batch adversarial loss: 0.510383\n",
      "epoch 52; iter: 0; batch classifier loss: 0.474328; batch adversarial loss: 0.480655\n",
      "epoch 53; iter: 0; batch classifier loss: 0.330601; batch adversarial loss: 0.588157\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413818; batch adversarial loss: 0.561309\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426985; batch adversarial loss: 0.520857\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456025; batch adversarial loss: 0.648816\n",
      "epoch 57; iter: 0; batch classifier loss: 0.364963; batch adversarial loss: 0.570803\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447757; batch adversarial loss: 0.534267\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407836; batch adversarial loss: 0.497694\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406441; batch adversarial loss: 0.563396\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463245; batch adversarial loss: 0.548314\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388467; batch adversarial loss: 0.532840\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410518; batch adversarial loss: 0.579256\n",
      "epoch 64; iter: 0; batch classifier loss: 0.483035; batch adversarial loss: 0.543803\n",
      "epoch 65; iter: 0; batch classifier loss: 0.341658; batch adversarial loss: 0.473147\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422763; batch adversarial loss: 0.627316\n",
      "epoch 67; iter: 0; batch classifier loss: 0.424710; batch adversarial loss: 0.574691\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445336; batch adversarial loss: 0.537746\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442500; batch adversarial loss: 0.553590\n",
      "epoch 70; iter: 0; batch classifier loss: 0.454441; batch adversarial loss: 0.527617\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412580; batch adversarial loss: 0.562812\n",
      "epoch 72; iter: 0; batch classifier loss: 0.463213; batch adversarial loss: 0.561713\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398038; batch adversarial loss: 0.597555\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390990; batch adversarial loss: 0.472669\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409861; batch adversarial loss: 0.653341\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335001; batch adversarial loss: 0.552666\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408402; batch adversarial loss: 0.605325\n",
      "epoch 78; iter: 0; batch classifier loss: 0.440519; batch adversarial loss: 0.524578\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372006; batch adversarial loss: 0.545338\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347191; batch adversarial loss: 0.597061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386553; batch adversarial loss: 0.645567\n",
      "epoch 82; iter: 0; batch classifier loss: 0.453891; batch adversarial loss: 0.567814\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370411; batch adversarial loss: 0.508866\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382079; batch adversarial loss: 0.618100\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400785; batch adversarial loss: 0.516196\n",
      "epoch 86; iter: 0; batch classifier loss: 0.354952; batch adversarial loss: 0.482594\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411885; batch adversarial loss: 0.556892\n",
      "epoch 88; iter: 0; batch classifier loss: 0.404267; batch adversarial loss: 0.526971\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404009; batch adversarial loss: 0.579301\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409838; batch adversarial loss: 0.571388\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397754; batch adversarial loss: 0.563990\n",
      "epoch 92; iter: 0; batch classifier loss: 0.358633; batch adversarial loss: 0.598950\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356731; batch adversarial loss: 0.651828\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407501; batch adversarial loss: 0.571838\n",
      "epoch 95; iter: 0; batch classifier loss: 0.470673; batch adversarial loss: 0.562353\n",
      "epoch 96; iter: 0; batch classifier loss: 0.421258; batch adversarial loss: 0.535783\n",
      "epoch 97; iter: 0; batch classifier loss: 0.339619; batch adversarial loss: 0.642404\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369829; batch adversarial loss: 0.570852\n",
      "epoch 99; iter: 0; batch classifier loss: 0.330047; batch adversarial loss: 0.588776\n",
      "epoch 100; iter: 0; batch classifier loss: 0.340163; batch adversarial loss: 0.571146\n",
      "epoch 101; iter: 0; batch classifier loss: 0.316317; batch adversarial loss: 0.570858\n",
      "epoch 102; iter: 0; batch classifier loss: 0.443340; batch adversarial loss: 0.560288\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406490; batch adversarial loss: 0.572607\n",
      "epoch 104; iter: 0; batch classifier loss: 0.314497; batch adversarial loss: 0.573249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.380904; batch adversarial loss: 0.572390\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343394; batch adversarial loss: 0.522702\n",
      "epoch 107; iter: 0; batch classifier loss: 0.409906; batch adversarial loss: 0.610853\n",
      "epoch 108; iter: 0; batch classifier loss: 0.309626; batch adversarial loss: 0.451915\n",
      "epoch 109; iter: 0; batch classifier loss: 0.429407; batch adversarial loss: 0.589932\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369590; batch adversarial loss: 0.550123\n",
      "epoch 111; iter: 0; batch classifier loss: 0.431803; batch adversarial loss: 0.560363\n",
      "epoch 112; iter: 0; batch classifier loss: 0.408900; batch adversarial loss: 0.568250\n",
      "epoch 113; iter: 0; batch classifier loss: 0.460312; batch adversarial loss: 0.545468\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363907; batch adversarial loss: 0.545503\n",
      "epoch 115; iter: 0; batch classifier loss: 0.305909; batch adversarial loss: 0.544551\n",
      "epoch 116; iter: 0; batch classifier loss: 0.510704; batch adversarial loss: 0.492234\n",
      "epoch 117; iter: 0; batch classifier loss: 0.331898; batch adversarial loss: 0.500866\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401973; batch adversarial loss: 0.598830\n",
      "epoch 119; iter: 0; batch classifier loss: 0.357262; batch adversarial loss: 0.562769\n",
      "epoch 120; iter: 0; batch classifier loss: 0.431192; batch adversarial loss: 0.589614\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388541; batch adversarial loss: 0.562678\n",
      "epoch 122; iter: 0; batch classifier loss: 0.465493; batch adversarial loss: 0.534959\n",
      "epoch 123; iter: 0; batch classifier loss: 0.393986; batch adversarial loss: 0.436747\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358405; batch adversarial loss: 0.616760\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399618; batch adversarial loss: 0.598592\n",
      "epoch 126; iter: 0; batch classifier loss: 0.320499; batch adversarial loss: 0.517949\n",
      "epoch 127; iter: 0; batch classifier loss: 0.499910; batch adversarial loss: 0.545451\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325351; batch adversarial loss: 0.526208\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354533; batch adversarial loss: 0.588254\n",
      "epoch 130; iter: 0; batch classifier loss: 0.319355; batch adversarial loss: 0.554308\n",
      "epoch 131; iter: 0; batch classifier loss: 0.341694; batch adversarial loss: 0.571872\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341468; batch adversarial loss: 0.527230\n",
      "epoch 133; iter: 0; batch classifier loss: 0.434584; batch adversarial loss: 0.573611\n",
      "epoch 134; iter: 0; batch classifier loss: 0.423810; batch adversarial loss: 0.525801\n",
      "epoch 135; iter: 0; batch classifier loss: 0.374764; batch adversarial loss: 0.552989\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378618; batch adversarial loss: 0.560163\n",
      "epoch 137; iter: 0; batch classifier loss: 0.342167; batch adversarial loss: 0.572212\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373523; batch adversarial loss: 0.543203\n",
      "epoch 139; iter: 0; batch classifier loss: 0.447361; batch adversarial loss: 0.579270\n",
      "epoch 140; iter: 0; batch classifier loss: 0.411806; batch adversarial loss: 0.626716\n",
      "epoch 141; iter: 0; batch classifier loss: 0.317329; batch adversarial loss: 0.570610\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395552; batch adversarial loss: 0.621954\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406541; batch adversarial loss: 0.579433\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396527; batch adversarial loss: 0.571367\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382647; batch adversarial loss: 0.490096\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349646; batch adversarial loss: 0.542667\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361893; batch adversarial loss: 0.535009\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410771; batch adversarial loss: 0.590603\n",
      "epoch 149; iter: 0; batch classifier loss: 0.345691; batch adversarial loss: 0.499061\n",
      "epoch 150; iter: 0; batch classifier loss: 0.343345; batch adversarial loss: 0.644877\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326128; batch adversarial loss: 0.545379\n",
      "epoch 152; iter: 0; batch classifier loss: 0.421693; batch adversarial loss: 0.581072\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320256; batch adversarial loss: 0.580605\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366588; batch adversarial loss: 0.571002\n",
      "epoch 155; iter: 0; batch classifier loss: 0.425824; batch adversarial loss: 0.571729\n",
      "epoch 156; iter: 0; batch classifier loss: 0.320232; batch adversarial loss: 0.562583\n",
      "epoch 157; iter: 0; batch classifier loss: 0.379764; batch adversarial loss: 0.597351\n",
      "epoch 158; iter: 0; batch classifier loss: 0.307380; batch adversarial loss: 0.553111\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316329; batch adversarial loss: 0.598032\n",
      "epoch 160; iter: 0; batch classifier loss: 0.309443; batch adversarial loss: 0.607556\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335015; batch adversarial loss: 0.544114\n",
      "epoch 162; iter: 0; batch classifier loss: 0.378372; batch adversarial loss: 0.543738\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369785; batch adversarial loss: 0.472814\n",
      "epoch 164; iter: 0; batch classifier loss: 0.319737; batch adversarial loss: 0.545931\n",
      "epoch 165; iter: 0; batch classifier loss: 0.299347; batch adversarial loss: 0.490880\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319303; batch adversarial loss: 0.535174\n",
      "epoch 167; iter: 0; batch classifier loss: 0.438822; batch adversarial loss: 0.508972\n",
      "epoch 168; iter: 0; batch classifier loss: 0.364800; batch adversarial loss: 0.614822\n",
      "epoch 169; iter: 0; batch classifier loss: 0.429855; batch adversarial loss: 0.535619\n",
      "epoch 170; iter: 0; batch classifier loss: 0.317916; batch adversarial loss: 0.580194\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409443; batch adversarial loss: 0.473226\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377937; batch adversarial loss: 0.625128\n",
      "epoch 173; iter: 0; batch classifier loss: 0.425427; batch adversarial loss: 0.499804\n",
      "epoch 174; iter: 0; batch classifier loss: 0.449241; batch adversarial loss: 0.563773\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383620; batch adversarial loss: 0.553748\n",
      "epoch 176; iter: 0; batch classifier loss: 0.302258; batch adversarial loss: 0.562119\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319583; batch adversarial loss: 0.553673\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387879; batch adversarial loss: 0.573071\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374682; batch adversarial loss: 0.573437\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378214; batch adversarial loss: 0.616738\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323689; batch adversarial loss: 0.617370\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324312; batch adversarial loss: 0.607800\n",
      "epoch 183; iter: 0; batch classifier loss: 0.286289; batch adversarial loss: 0.553453\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363453; batch adversarial loss: 0.526793\n",
      "epoch 185; iter: 0; batch classifier loss: 0.386420; batch adversarial loss: 0.544803\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358715; batch adversarial loss: 0.571059\n",
      "epoch 187; iter: 0; batch classifier loss: 0.422660; batch adversarial loss: 0.607691\n",
      "epoch 188; iter: 0; batch classifier loss: 0.332242; batch adversarial loss: 0.597997\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375554; batch adversarial loss: 0.607201\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349519; batch adversarial loss: 0.590542\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392754; batch adversarial loss: 0.642667\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345925; batch adversarial loss: 0.552541\n",
      "epoch 193; iter: 0; batch classifier loss: 0.409258; batch adversarial loss: 0.544943\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312159; batch adversarial loss: 0.616500\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362986; batch adversarial loss: 0.487927\n",
      "epoch 196; iter: 0; batch classifier loss: 0.413795; batch adversarial loss: 0.554289\n",
      "epoch 197; iter: 0; batch classifier loss: 0.268690; batch adversarial loss: 0.588670\n",
      "epoch 198; iter: 0; batch classifier loss: 0.395438; batch adversarial loss: 0.514084\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386170; batch adversarial loss: 0.489622\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682287; batch adversarial loss: 0.935015\n",
      "epoch 1; iter: 0; batch classifier loss: 0.827993; batch adversarial loss: 1.136115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.933352; batch adversarial loss: 1.097883\n",
      "epoch 3; iter: 0; batch classifier loss: 1.073732; batch adversarial loss: 0.997142\n",
      "epoch 4; iter: 0; batch classifier loss: 1.088106; batch adversarial loss: 0.925909\n",
      "epoch 5; iter: 0; batch classifier loss: 1.235754; batch adversarial loss: 0.847546\n",
      "epoch 6; iter: 0; batch classifier loss: 0.968316; batch adversarial loss: 0.781125\n",
      "epoch 7; iter: 0; batch classifier loss: 1.082785; batch adversarial loss: 0.722484\n",
      "epoch 8; iter: 0; batch classifier loss: 0.875660; batch adversarial loss: 0.689127\n",
      "epoch 9; iter: 0; batch classifier loss: 0.951492; batch adversarial loss: 0.636050\n",
      "epoch 10; iter: 0; batch classifier loss: 0.882695; batch adversarial loss: 0.572824\n",
      "epoch 11; iter: 0; batch classifier loss: 0.640300; batch adversarial loss: 0.555771\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564355; batch adversarial loss: 0.572259\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536990; batch adversarial loss: 0.559887\n",
      "epoch 14; iter: 0; batch classifier loss: 0.578964; batch adversarial loss: 0.539789\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509163; batch adversarial loss: 0.577852\n",
      "epoch 16; iter: 0; batch classifier loss: 0.549275; batch adversarial loss: 0.584429\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518997; batch adversarial loss: 0.508018\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541400; batch adversarial loss: 0.541593\n",
      "epoch 19; iter: 0; batch classifier loss: 0.549369; batch adversarial loss: 0.494763\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505268; batch adversarial loss: 0.597521\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520488; batch adversarial loss: 0.496862\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482289; batch adversarial loss: 0.592752\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547468; batch adversarial loss: 0.533996\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476520; batch adversarial loss: 0.512570\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518171; batch adversarial loss: 0.489373\n",
      "epoch 26; iter: 0; batch classifier loss: 0.514737; batch adversarial loss: 0.650104\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479539; batch adversarial loss: 0.547670\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482259; batch adversarial loss: 0.506064\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479457; batch adversarial loss: 0.562776\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452679; batch adversarial loss: 0.615348\n",
      "epoch 31; iter: 0; batch classifier loss: 0.408431; batch adversarial loss: 0.512125\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432615; batch adversarial loss: 0.568100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.487740; batch adversarial loss: 0.612063\n",
      "epoch 34; iter: 0; batch classifier loss: 0.361266; batch adversarial loss: 0.545635\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470385; batch adversarial loss: 0.519478\n",
      "epoch 36; iter: 0; batch classifier loss: 0.354063; batch adversarial loss: 0.467556\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461123; batch adversarial loss: 0.549161\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468206; batch adversarial loss: 0.539834\n",
      "epoch 39; iter: 0; batch classifier loss: 0.523358; batch adversarial loss: 0.551819\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418018; batch adversarial loss: 0.578000\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486317; batch adversarial loss: 0.607570\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427855; batch adversarial loss: 0.485958\n",
      "epoch 43; iter: 0; batch classifier loss: 0.495265; batch adversarial loss: 0.535553\n",
      "epoch 44; iter: 0; batch classifier loss: 0.449166; batch adversarial loss: 0.558333\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455327; batch adversarial loss: 0.517384\n",
      "epoch 46; iter: 0; batch classifier loss: 0.493574; batch adversarial loss: 0.508441\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440879; batch adversarial loss: 0.586768\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470912; batch adversarial loss: 0.523174\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443127; batch adversarial loss: 0.575036\n",
      "epoch 50; iter: 0; batch classifier loss: 0.437384; batch adversarial loss: 0.511795\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400070; batch adversarial loss: 0.545626\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449906; batch adversarial loss: 0.553828\n",
      "epoch 53; iter: 0; batch classifier loss: 0.407232; batch adversarial loss: 0.536742\n",
      "epoch 54; iter: 0; batch classifier loss: 0.505062; batch adversarial loss: 0.606662\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387033; batch adversarial loss: 0.535030\n",
      "epoch 56; iter: 0; batch classifier loss: 0.491488; batch adversarial loss: 0.634893\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403700; batch adversarial loss: 0.489271\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427685; batch adversarial loss: 0.498075\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425609; batch adversarial loss: 0.579960\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401540; batch adversarial loss: 0.534212\n",
      "epoch 61; iter: 0; batch classifier loss: 0.375098; batch adversarial loss: 0.522213\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434756; batch adversarial loss: 0.567734\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396940; batch adversarial loss: 0.417964\n",
      "epoch 64; iter: 0; batch classifier loss: 0.399962; batch adversarial loss: 0.636760\n",
      "epoch 65; iter: 0; batch classifier loss: 0.357960; batch adversarial loss: 0.653432\n",
      "epoch 66; iter: 0; batch classifier loss: 0.498715; batch adversarial loss: 0.530812\n",
      "epoch 67; iter: 0; batch classifier loss: 0.470671; batch adversarial loss: 0.491648\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410032; batch adversarial loss: 0.505931\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361728; batch adversarial loss: 0.629454\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383003; batch adversarial loss: 0.573532\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369253; batch adversarial loss: 0.576787\n",
      "epoch 72; iter: 0; batch classifier loss: 0.331609; batch adversarial loss: 0.535398\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438555; batch adversarial loss: 0.556161\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423892; batch adversarial loss: 0.553624\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364327; batch adversarial loss: 0.533112\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382091; batch adversarial loss: 0.502663\n",
      "epoch 77; iter: 0; batch classifier loss: 0.446120; batch adversarial loss: 0.526220\n",
      "epoch 78; iter: 0; batch classifier loss: 0.385528; batch adversarial loss: 0.533015\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353854; batch adversarial loss: 0.502592\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408544; batch adversarial loss: 0.594222\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427132; batch adversarial loss: 0.511868\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372060; batch adversarial loss: 0.553843\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326122; batch adversarial loss: 0.536965\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406082; batch adversarial loss: 0.521345\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402851; batch adversarial loss: 0.531899\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424055; batch adversarial loss: 0.508373\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378158; batch adversarial loss: 0.475142\n",
      "epoch 88; iter: 0; batch classifier loss: 0.496302; batch adversarial loss: 0.551682\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391746; batch adversarial loss: 0.561885\n",
      "epoch 90; iter: 0; batch classifier loss: 0.315927; batch adversarial loss: 0.544000\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396874; batch adversarial loss: 0.487638\n",
      "epoch 92; iter: 0; batch classifier loss: 0.344405; batch adversarial loss: 0.565352\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418514; batch adversarial loss: 0.501235\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433577; batch adversarial loss: 0.580625\n",
      "epoch 95; iter: 0; batch classifier loss: 0.380395; batch adversarial loss: 0.499185\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403770; batch adversarial loss: 0.571539\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425414; batch adversarial loss: 0.571366\n",
      "epoch 98; iter: 0; batch classifier loss: 0.331805; batch adversarial loss: 0.544984\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399977; batch adversarial loss: 0.506636\n",
      "epoch 100; iter: 0; batch classifier loss: 0.449555; batch adversarial loss: 0.589708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.345868; batch adversarial loss: 0.544246\n",
      "epoch 102; iter: 0; batch classifier loss: 0.411798; batch adversarial loss: 0.569738\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388191; batch adversarial loss: 0.498968\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367453; batch adversarial loss: 0.515953\n",
      "epoch 105; iter: 0; batch classifier loss: 0.333719; batch adversarial loss: 0.508179\n",
      "epoch 106; iter: 0; batch classifier loss: 0.347662; batch adversarial loss: 0.481057\n",
      "epoch 107; iter: 0; batch classifier loss: 0.303149; batch adversarial loss: 0.553331\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364551; batch adversarial loss: 0.523051\n",
      "epoch 109; iter: 0; batch classifier loss: 0.393668; batch adversarial loss: 0.481265\n",
      "epoch 110; iter: 0; batch classifier loss: 0.515911; batch adversarial loss: 0.570192\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356530; batch adversarial loss: 0.507403\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360204; batch adversarial loss: 0.507589\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374634; batch adversarial loss: 0.451983\n",
      "epoch 114; iter: 0; batch classifier loss: 0.348961; batch adversarial loss: 0.542893\n",
      "epoch 115; iter: 0; batch classifier loss: 0.377566; batch adversarial loss: 0.477060\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377109; batch adversarial loss: 0.542120\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337167; batch adversarial loss: 0.571294\n",
      "epoch 118; iter: 0; batch classifier loss: 0.318666; batch adversarial loss: 0.543755\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364827; batch adversarial loss: 0.470060\n",
      "epoch 120; iter: 0; batch classifier loss: 0.331418; batch adversarial loss: 0.554854\n",
      "epoch 121; iter: 0; batch classifier loss: 0.287820; batch adversarial loss: 0.616865\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398423; batch adversarial loss: 0.546738\n",
      "epoch 123; iter: 0; batch classifier loss: 0.309663; batch adversarial loss: 0.486843\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377366; batch adversarial loss: 0.498205\n",
      "epoch 125; iter: 0; batch classifier loss: 0.302718; batch adversarial loss: 0.573432\n",
      "epoch 126; iter: 0; batch classifier loss: 0.398498; batch adversarial loss: 0.503050\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370746; batch adversarial loss: 0.571601\n",
      "epoch 128; iter: 0; batch classifier loss: 0.336924; batch adversarial loss: 0.495105\n",
      "epoch 129; iter: 0; batch classifier loss: 0.505346; batch adversarial loss: 0.587867\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397109; batch adversarial loss: 0.550533\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336330; batch adversarial loss: 0.563058\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380349; batch adversarial loss: 0.497266\n",
      "epoch 133; iter: 0; batch classifier loss: 0.440221; batch adversarial loss: 0.526870\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356738; batch adversarial loss: 0.481324\n",
      "epoch 135; iter: 0; batch classifier loss: 0.332477; batch adversarial loss: 0.570539\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338532; batch adversarial loss: 0.520666\n",
      "epoch 137; iter: 0; batch classifier loss: 0.327145; batch adversarial loss: 0.529826\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382344; batch adversarial loss: 0.552465\n",
      "epoch 139; iter: 0; batch classifier loss: 0.311850; batch adversarial loss: 0.581889\n",
      "epoch 140; iter: 0; batch classifier loss: 0.323104; batch adversarial loss: 0.570556\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381135; batch adversarial loss: 0.629579\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379677; batch adversarial loss: 0.514063\n",
      "epoch 143; iter: 0; batch classifier loss: 0.271454; batch adversarial loss: 0.496349\n",
      "epoch 144; iter: 0; batch classifier loss: 0.318566; batch adversarial loss: 0.444547\n",
      "epoch 145; iter: 0; batch classifier loss: 0.437128; batch adversarial loss: 0.553081\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368544; batch adversarial loss: 0.525646\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350552; batch adversarial loss: 0.489364\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346704; batch adversarial loss: 0.515649\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351035; batch adversarial loss: 0.423038\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359338; batch adversarial loss: 0.499060\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387402; batch adversarial loss: 0.480555\n",
      "epoch 152; iter: 0; batch classifier loss: 0.399053; batch adversarial loss: 0.589392\n",
      "epoch 153; iter: 0; batch classifier loss: 0.347838; batch adversarial loss: 0.498188\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349403; batch adversarial loss: 0.554284\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337029; batch adversarial loss: 0.498107\n",
      "epoch 156; iter: 0; batch classifier loss: 0.300125; batch adversarial loss: 0.591192\n",
      "epoch 157; iter: 0; batch classifier loss: 0.357059; batch adversarial loss: 0.562394\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337266; batch adversarial loss: 0.471132\n",
      "epoch 159; iter: 0; batch classifier loss: 0.334390; batch adversarial loss: 0.592874\n",
      "epoch 160; iter: 0; batch classifier loss: 0.325761; batch adversarial loss: 0.571714\n",
      "epoch 161; iter: 0; batch classifier loss: 0.395481; batch adversarial loss: 0.682370\n",
      "epoch 162; iter: 0; batch classifier loss: 0.310105; batch adversarial loss: 0.570332\n",
      "epoch 163; iter: 0; batch classifier loss: 0.308415; batch adversarial loss: 0.554985\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356633; batch adversarial loss: 0.510818\n",
      "epoch 165; iter: 0; batch classifier loss: 0.382925; batch adversarial loss: 0.463037\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349290; batch adversarial loss: 0.600954\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358678; batch adversarial loss: 0.618042\n",
      "epoch 168; iter: 0; batch classifier loss: 0.405563; batch adversarial loss: 0.516929\n",
      "epoch 169; iter: 0; batch classifier loss: 0.297514; batch adversarial loss: 0.505413\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319634; batch adversarial loss: 0.564877\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295953; batch adversarial loss: 0.469552\n",
      "epoch 172; iter: 0; batch classifier loss: 0.278238; batch adversarial loss: 0.537192\n",
      "epoch 173; iter: 0; batch classifier loss: 0.298006; batch adversarial loss: 0.507392\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378242; batch adversarial loss: 0.524503\n",
      "epoch 175; iter: 0; batch classifier loss: 0.295342; batch adversarial loss: 0.464985\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372322; batch adversarial loss: 0.554480\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305826; batch adversarial loss: 0.558049\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353524; batch adversarial loss: 0.612876\n",
      "epoch 179; iter: 0; batch classifier loss: 0.301878; batch adversarial loss: 0.603203\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353655; batch adversarial loss: 0.515335\n",
      "epoch 181; iter: 0; batch classifier loss: 0.275162; batch adversarial loss: 0.580467\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339280; batch adversarial loss: 0.498345\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321007; batch adversarial loss: 0.580373\n",
      "epoch 184; iter: 0; batch classifier loss: 0.409440; batch adversarial loss: 0.553137\n",
      "epoch 185; iter: 0; batch classifier loss: 0.409127; batch adversarial loss: 0.585890\n",
      "epoch 186; iter: 0; batch classifier loss: 0.336641; batch adversarial loss: 0.561935\n",
      "epoch 187; iter: 0; batch classifier loss: 0.299127; batch adversarial loss: 0.515422\n",
      "epoch 188; iter: 0; batch classifier loss: 0.284502; batch adversarial loss: 0.646416\n",
      "epoch 189; iter: 0; batch classifier loss: 0.272648; batch adversarial loss: 0.533681\n",
      "epoch 190; iter: 0; batch classifier loss: 0.334300; batch adversarial loss: 0.591709\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386021; batch adversarial loss: 0.532145\n",
      "epoch 192; iter: 0; batch classifier loss: 0.301409; batch adversarial loss: 0.619953\n",
      "epoch 193; iter: 0; batch classifier loss: 0.247456; batch adversarial loss: 0.552590\n",
      "epoch 194; iter: 0; batch classifier loss: 0.285530; batch adversarial loss: 0.525185\n",
      "epoch 195; iter: 0; batch classifier loss: 0.284188; batch adversarial loss: 0.516895\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321709; batch adversarial loss: 0.533905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.296914; batch adversarial loss: 0.498405\n",
      "epoch 198; iter: 0; batch classifier loss: 0.305436; batch adversarial loss: 0.552989\n",
      "epoch 199; iter: 0; batch classifier loss: 0.325753; batch adversarial loss: 0.610304\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700871; batch adversarial loss: 0.736116\n",
      "epoch 1; iter: 0; batch classifier loss: 0.671460; batch adversarial loss: 0.690587\n",
      "epoch 2; iter: 0; batch classifier loss: 0.628413; batch adversarial loss: 0.665376\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579768; batch adversarial loss: 0.634192\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539638; batch adversarial loss: 0.609562\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540855; batch adversarial loss: 0.609236\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598377; batch adversarial loss: 0.585655\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606192; batch adversarial loss: 0.563176\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517999; batch adversarial loss: 0.594417\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494688; batch adversarial loss: 0.588544\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559420; batch adversarial loss: 0.588524\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521545; batch adversarial loss: 0.600206\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533287; batch adversarial loss: 0.539933\n",
      "epoch 13; iter: 0; batch classifier loss: 0.568891; batch adversarial loss: 0.550565\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499885; batch adversarial loss: 0.584790\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539045; batch adversarial loss: 0.547988\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500828; batch adversarial loss: 0.534246\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521002; batch adversarial loss: 0.560381\n",
      "epoch 18; iter: 0; batch classifier loss: 0.578883; batch adversarial loss: 0.535627\n",
      "epoch 19; iter: 0; batch classifier loss: 0.556553; batch adversarial loss: 0.536213\n",
      "epoch 20; iter: 0; batch classifier loss: 0.481421; batch adversarial loss: 0.577250\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519096; batch adversarial loss: 0.611717\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494982; batch adversarial loss: 0.582236\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497764; batch adversarial loss: 0.534855\n",
      "epoch 24; iter: 0; batch classifier loss: 0.578402; batch adversarial loss: 0.589352\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496529; batch adversarial loss: 0.515890\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505865; batch adversarial loss: 0.576249\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439047; batch adversarial loss: 0.517331\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488463; batch adversarial loss: 0.569215\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492907; batch adversarial loss: 0.564663\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475344; batch adversarial loss: 0.660800\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443277; batch adversarial loss: 0.532518\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516269; batch adversarial loss: 0.537187\n",
      "epoch 33; iter: 0; batch classifier loss: 0.553905; batch adversarial loss: 0.493037\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392235; batch adversarial loss: 0.541914\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434875; batch adversarial loss: 0.520238\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457522; batch adversarial loss: 0.530246\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458360; batch adversarial loss: 0.508774\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483015; batch adversarial loss: 0.573051\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491024; batch adversarial loss: 0.577998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522073; batch adversarial loss: 0.600263\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404102; batch adversarial loss: 0.502118\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463183; batch adversarial loss: 0.616017\n",
      "epoch 43; iter: 0; batch classifier loss: 0.416665; batch adversarial loss: 0.569020\n",
      "epoch 44; iter: 0; batch classifier loss: 0.506774; batch adversarial loss: 0.586703\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453786; batch adversarial loss: 0.564531\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431687; batch adversarial loss: 0.560899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439072; batch adversarial loss: 0.647202\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377476; batch adversarial loss: 0.511051\n",
      "epoch 49; iter: 0; batch classifier loss: 0.483047; batch adversarial loss: 0.597170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.372850; batch adversarial loss: 0.524095\n",
      "epoch 51; iter: 0; batch classifier loss: 0.492498; batch adversarial loss: 0.524422\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457091; batch adversarial loss: 0.543426\n",
      "epoch 53; iter: 0; batch classifier loss: 0.407061; batch adversarial loss: 0.542293\n",
      "epoch 54; iter: 0; batch classifier loss: 0.441769; batch adversarial loss: 0.517730\n",
      "epoch 55; iter: 0; batch classifier loss: 0.360919; batch adversarial loss: 0.516385\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444312; batch adversarial loss: 0.547686\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495527; batch adversarial loss: 0.588908\n",
      "epoch 58; iter: 0; batch classifier loss: 0.381054; batch adversarial loss: 0.610674\n",
      "epoch 59; iter: 0; batch classifier loss: 0.381506; batch adversarial loss: 0.492127\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442147; batch adversarial loss: 0.643802\n",
      "epoch 61; iter: 0; batch classifier loss: 0.472306; batch adversarial loss: 0.545048\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424392; batch adversarial loss: 0.598510\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463524; batch adversarial loss: 0.627065\n",
      "epoch 64; iter: 0; batch classifier loss: 0.462489; batch adversarial loss: 0.562596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447053; batch adversarial loss: 0.500974\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405389; batch adversarial loss: 0.488139\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404983; batch adversarial loss: 0.508944\n",
      "epoch 68; iter: 0; batch classifier loss: 0.449798; batch adversarial loss: 0.570283\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419885; batch adversarial loss: 0.491384\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411858; batch adversarial loss: 0.581794\n",
      "epoch 71; iter: 0; batch classifier loss: 0.388909; batch adversarial loss: 0.545185\n",
      "epoch 72; iter: 0; batch classifier loss: 0.327706; batch adversarial loss: 0.668522\n",
      "epoch 73; iter: 0; batch classifier loss: 0.329488; batch adversarial loss: 0.554891\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415767; batch adversarial loss: 0.552393\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369918; batch adversarial loss: 0.562276\n",
      "epoch 76; iter: 0; batch classifier loss: 0.403684; batch adversarial loss: 0.528711\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383496; batch adversarial loss: 0.516367\n",
      "epoch 78; iter: 0; batch classifier loss: 0.314956; batch adversarial loss: 0.599442\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395113; batch adversarial loss: 0.662138\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380753; batch adversarial loss: 0.629444\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413136; batch adversarial loss: 0.497509\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408650; batch adversarial loss: 0.533594\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372515; batch adversarial loss: 0.516839\n",
      "epoch 84; iter: 0; batch classifier loss: 0.503428; batch adversarial loss: 0.610876\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361099; batch adversarial loss: 0.576290\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381613; batch adversarial loss: 0.544324\n",
      "epoch 87; iter: 0; batch classifier loss: 0.432248; batch adversarial loss: 0.616085\n",
      "epoch 88; iter: 0; batch classifier loss: 0.325776; batch adversarial loss: 0.590406\n",
      "epoch 89; iter: 0; batch classifier loss: 0.418848; batch adversarial loss: 0.544225\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398326; batch adversarial loss: 0.590200\n",
      "epoch 91; iter: 0; batch classifier loss: 0.340306; batch adversarial loss: 0.552581\n",
      "epoch 92; iter: 0; batch classifier loss: 0.369099; batch adversarial loss: 0.499543\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367369; batch adversarial loss: 0.623960\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449446; batch adversarial loss: 0.543190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.436339; batch adversarial loss: 0.609495\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377335; batch adversarial loss: 0.570998\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381108; batch adversarial loss: 0.470023\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415909; batch adversarial loss: 0.588483\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410774; batch adversarial loss: 0.590205\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397665; batch adversarial loss: 0.598649\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400508; batch adversarial loss: 0.543387\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382072; batch adversarial loss: 0.588821\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378956; batch adversarial loss: 0.562653\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363362; batch adversarial loss: 0.535343\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414030; batch adversarial loss: 0.570139\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412404; batch adversarial loss: 0.580284\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399685; batch adversarial loss: 0.444854\n",
      "epoch 108; iter: 0; batch classifier loss: 0.443912; batch adversarial loss: 0.643998\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371409; batch adversarial loss: 0.562268\n",
      "epoch 110; iter: 0; batch classifier loss: 0.361784; batch adversarial loss: 0.633108\n",
      "epoch 111; iter: 0; batch classifier loss: 0.373169; batch adversarial loss: 0.623413\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376016; batch adversarial loss: 0.571468\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386286; batch adversarial loss: 0.591168\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347100; batch adversarial loss: 0.526536\n",
      "epoch 115; iter: 0; batch classifier loss: 0.361487; batch adversarial loss: 0.437156\n",
      "epoch 116; iter: 0; batch classifier loss: 0.397322; batch adversarial loss: 0.517928\n",
      "epoch 117; iter: 0; batch classifier loss: 0.380940; batch adversarial loss: 0.454585\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376068; batch adversarial loss: 0.571005\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390783; batch adversarial loss: 0.560912\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400562; batch adversarial loss: 0.507260\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373416; batch adversarial loss: 0.562839\n",
      "epoch 122; iter: 0; batch classifier loss: 0.303888; batch adversarial loss: 0.537149\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369645; batch adversarial loss: 0.517754\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392406; batch adversarial loss: 0.555819\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395068; batch adversarial loss: 0.624453\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314012; batch adversarial loss: 0.590924\n",
      "epoch 127; iter: 0; batch classifier loss: 0.410719; batch adversarial loss: 0.489887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.289043; batch adversarial loss: 0.564832\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399317; batch adversarial loss: 0.462694\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342364; batch adversarial loss: 0.554126\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335005; batch adversarial loss: 0.580626\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357347; batch adversarial loss: 0.554529\n",
      "epoch 133; iter: 0; batch classifier loss: 0.363186; batch adversarial loss: 0.545362\n",
      "epoch 134; iter: 0; batch classifier loss: 0.440233; batch adversarial loss: 0.562188\n",
      "epoch 135; iter: 0; batch classifier loss: 0.434025; batch adversarial loss: 0.526217\n",
      "epoch 136; iter: 0; batch classifier loss: 0.325263; batch adversarial loss: 0.516630\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369959; batch adversarial loss: 0.499436\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368858; batch adversarial loss: 0.436139\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352912; batch adversarial loss: 0.588794\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375567; batch adversarial loss: 0.571218\n",
      "epoch 141; iter: 0; batch classifier loss: 0.316396; batch adversarial loss: 0.481068\n",
      "epoch 142; iter: 0; batch classifier loss: 0.377571; batch adversarial loss: 0.571776\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373323; batch adversarial loss: 0.599566\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374707; batch adversarial loss: 0.517522\n",
      "epoch 145; iter: 0; batch classifier loss: 0.337727; batch adversarial loss: 0.625668\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332032; batch adversarial loss: 0.490431\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355983; batch adversarial loss: 0.516638\n",
      "epoch 148; iter: 0; batch classifier loss: 0.413089; batch adversarial loss: 0.506799\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361996; batch adversarial loss: 0.617417\n",
      "epoch 150; iter: 0; batch classifier loss: 0.411976; batch adversarial loss: 0.571564\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376068; batch adversarial loss: 0.562843\n",
      "epoch 152; iter: 0; batch classifier loss: 0.359262; batch adversarial loss: 0.643619\n",
      "epoch 153; iter: 0; batch classifier loss: 0.474223; batch adversarial loss: 0.616789\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374082; batch adversarial loss: 0.579374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.448201; batch adversarial loss: 0.528143\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399106; batch adversarial loss: 0.561212\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364914; batch adversarial loss: 0.556932\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334982; batch adversarial loss: 0.542852\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354328; batch adversarial loss: 0.554973\n",
      "epoch 160; iter: 0; batch classifier loss: 0.505333; batch adversarial loss: 0.545292\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351337; batch adversarial loss: 0.590569\n",
      "epoch 162; iter: 0; batch classifier loss: 0.320624; batch adversarial loss: 0.553816\n",
      "epoch 163; iter: 0; batch classifier loss: 0.462880; batch adversarial loss: 0.500419\n",
      "epoch 164; iter: 0; batch classifier loss: 0.278017; batch adversarial loss: 0.536184\n",
      "epoch 165; iter: 0; batch classifier loss: 0.471051; batch adversarial loss: 0.598233\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330366; batch adversarial loss: 0.483538\n",
      "epoch 167; iter: 0; batch classifier loss: 0.417122; batch adversarial loss: 0.544766\n",
      "epoch 168; iter: 0; batch classifier loss: 0.289812; batch adversarial loss: 0.544509\n",
      "epoch 169; iter: 0; batch classifier loss: 0.329670; batch adversarial loss: 0.535726\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342193; batch adversarial loss: 0.482021\n",
      "epoch 171; iter: 0; batch classifier loss: 0.300842; batch adversarial loss: 0.508836\n",
      "epoch 172; iter: 0; batch classifier loss: 0.433336; batch adversarial loss: 0.589012\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403672; batch adversarial loss: 0.533941\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371651; batch adversarial loss: 0.563258\n",
      "epoch 175; iter: 0; batch classifier loss: 0.358635; batch adversarial loss: 0.508135\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360987; batch adversarial loss: 0.507599\n",
      "epoch 177; iter: 0; batch classifier loss: 0.367803; batch adversarial loss: 0.471251\n",
      "epoch 178; iter: 0; batch classifier loss: 0.412856; batch adversarial loss: 0.607900\n",
      "epoch 179; iter: 0; batch classifier loss: 0.359118; batch adversarial loss: 0.516886\n",
      "epoch 180; iter: 0; batch classifier loss: 0.258695; batch adversarial loss: 0.551403\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353305; batch adversarial loss: 0.535715\n",
      "epoch 182; iter: 0; batch classifier loss: 0.279070; batch adversarial loss: 0.542227\n",
      "epoch 183; iter: 0; batch classifier loss: 0.308509; batch adversarial loss: 0.573657\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389648; batch adversarial loss: 0.534363\n",
      "epoch 185; iter: 0; batch classifier loss: 0.289661; batch adversarial loss: 0.578563\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315202; batch adversarial loss: 0.587918\n",
      "epoch 187; iter: 0; batch classifier loss: 0.411913; batch adversarial loss: 0.608607\n",
      "epoch 188; iter: 0; batch classifier loss: 0.277403; batch adversarial loss: 0.572261\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311447; batch adversarial loss: 0.571097\n",
      "epoch 190; iter: 0; batch classifier loss: 0.381583; batch adversarial loss: 0.597618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.357429; batch adversarial loss: 0.535399\n",
      "epoch 192; iter: 0; batch classifier loss: 0.424195; batch adversarial loss: 0.491312\n",
      "epoch 193; iter: 0; batch classifier loss: 0.340058; batch adversarial loss: 0.518059\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318257; batch adversarial loss: 0.615649\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376866; batch adversarial loss: 0.499669\n",
      "epoch 196; iter: 0; batch classifier loss: 0.409078; batch adversarial loss: 0.554303\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370587; batch adversarial loss: 0.588913\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331041; batch adversarial loss: 0.509207\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339682; batch adversarial loss: 0.544921\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706899; batch adversarial loss: 0.715269\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601889; batch adversarial loss: 0.690015\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565512; batch adversarial loss: 0.672692\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578506; batch adversarial loss: 0.640178\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605283; batch adversarial loss: 0.611199\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549454; batch adversarial loss: 0.612597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509996; batch adversarial loss: 0.598436\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546167; batch adversarial loss: 0.527570\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544222; batch adversarial loss: 0.573391\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544794; batch adversarial loss: 0.575132\n",
      "epoch 10; iter: 0; batch classifier loss: 0.482952; batch adversarial loss: 0.561897\n",
      "epoch 11; iter: 0; batch classifier loss: 0.401262; batch adversarial loss: 0.632789\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491693; batch adversarial loss: 0.591885\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499423; batch adversarial loss: 0.589168\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499029; batch adversarial loss: 0.532506\n",
      "epoch 15; iter: 0; batch classifier loss: 0.452063; batch adversarial loss: 0.542879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513433; batch adversarial loss: 0.486662\n",
      "epoch 17; iter: 0; batch classifier loss: 0.619525; batch adversarial loss: 0.614783\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541901; batch adversarial loss: 0.549700\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487010; batch adversarial loss: 0.580408\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434199; batch adversarial loss: 0.548154\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467872; batch adversarial loss: 0.511391\n",
      "epoch 22; iter: 0; batch classifier loss: 0.628869; batch adversarial loss: 0.543175\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501060; batch adversarial loss: 0.491799\n",
      "epoch 24; iter: 0; batch classifier loss: 0.556813; batch adversarial loss: 0.601926\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515312; batch adversarial loss: 0.508144\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464270; batch adversarial loss: 0.517983\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432282; batch adversarial loss: 0.556287\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454857; batch adversarial loss: 0.521005\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496713; batch adversarial loss: 0.574389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538213; batch adversarial loss: 0.533200\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431904; batch adversarial loss: 0.530642\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458401; batch adversarial loss: 0.479989\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476734; batch adversarial loss: 0.565530\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435314; batch adversarial loss: 0.491674\n",
      "epoch 35; iter: 0; batch classifier loss: 0.494458; batch adversarial loss: 0.621109\n",
      "epoch 36; iter: 0; batch classifier loss: 0.401066; batch adversarial loss: 0.573639\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423803; batch adversarial loss: 0.552935\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440664; batch adversarial loss: 0.544780\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498155; batch adversarial loss: 0.508862\n",
      "epoch 40; iter: 0; batch classifier loss: 0.384265; batch adversarial loss: 0.498414\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398060; batch adversarial loss: 0.599947\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407102; batch adversarial loss: 0.545463\n",
      "epoch 43; iter: 0; batch classifier loss: 0.485614; batch adversarial loss: 0.522677\n",
      "epoch 44; iter: 0; batch classifier loss: 0.467721; batch adversarial loss: 0.535252\n",
      "epoch 45; iter: 0; batch classifier loss: 0.497392; batch adversarial loss: 0.564999\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458717; batch adversarial loss: 0.468378\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398059; batch adversarial loss: 0.515977\n",
      "epoch 48; iter: 0; batch classifier loss: 0.506808; batch adversarial loss: 0.457386\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407126; batch adversarial loss: 0.438754\n",
      "epoch 50; iter: 0; batch classifier loss: 0.464791; batch adversarial loss: 0.589983\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462869; batch adversarial loss: 0.537736\n",
      "epoch 52; iter: 0; batch classifier loss: 0.367519; batch adversarial loss: 0.529557\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446344; batch adversarial loss: 0.507276\n",
      "epoch 54; iter: 0; batch classifier loss: 0.372626; batch adversarial loss: 0.535774\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377153; batch adversarial loss: 0.553575\n",
      "epoch 56; iter: 0; batch classifier loss: 0.400846; batch adversarial loss: 0.575735\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386422; batch adversarial loss: 0.545553\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407732; batch adversarial loss: 0.488698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428530; batch adversarial loss: 0.563094\n",
      "epoch 60; iter: 0; batch classifier loss: 0.459852; batch adversarial loss: 0.475117\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402846; batch adversarial loss: 0.516304\n",
      "epoch 62; iter: 0; batch classifier loss: 0.465828; batch adversarial loss: 0.525572\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438371; batch adversarial loss: 0.508605\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489291; batch adversarial loss: 0.484781\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410003; batch adversarial loss: 0.552669\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412709; batch adversarial loss: 0.560421\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351315; batch adversarial loss: 0.561411\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428851; batch adversarial loss: 0.467054\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402388; batch adversarial loss: 0.571565\n",
      "epoch 70; iter: 0; batch classifier loss: 0.344082; batch adversarial loss: 0.611612\n",
      "epoch 71; iter: 0; batch classifier loss: 0.342339; batch adversarial loss: 0.516904\n",
      "epoch 72; iter: 0; batch classifier loss: 0.485438; batch adversarial loss: 0.565220\n",
      "epoch 73; iter: 0; batch classifier loss: 0.464623; batch adversarial loss: 0.544098\n",
      "epoch 74; iter: 0; batch classifier loss: 0.379838; batch adversarial loss: 0.562831\n",
      "epoch 75; iter: 0; batch classifier loss: 0.337264; batch adversarial loss: 0.507194\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406285; batch adversarial loss: 0.591318\n",
      "epoch 77; iter: 0; batch classifier loss: 0.306435; batch adversarial loss: 0.488226\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457139; batch adversarial loss: 0.497707\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408108; batch adversarial loss: 0.562764\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395850; batch adversarial loss: 0.554564\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369577; batch adversarial loss: 0.534518\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394999; batch adversarial loss: 0.563093\n",
      "epoch 83; iter: 0; batch classifier loss: 0.330299; batch adversarial loss: 0.459573\n",
      "epoch 84; iter: 0; batch classifier loss: 0.433804; batch adversarial loss: 0.614074\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401416; batch adversarial loss: 0.487532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.342539; batch adversarial loss: 0.516762\n",
      "epoch 87; iter: 0; batch classifier loss: 0.354989; batch adversarial loss: 0.507305\n",
      "epoch 88; iter: 0; batch classifier loss: 0.331160; batch adversarial loss: 0.600409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.407536; batch adversarial loss: 0.535159\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405757; batch adversarial loss: 0.478044\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386652; batch adversarial loss: 0.526144\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425082; batch adversarial loss: 0.601449\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377816; batch adversarial loss: 0.507232\n",
      "epoch 94; iter: 0; batch classifier loss: 0.438650; batch adversarial loss: 0.496713\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365453; batch adversarial loss: 0.582593\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403444; batch adversarial loss: 0.448830\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363687; batch adversarial loss: 0.535574\n",
      "epoch 98; iter: 0; batch classifier loss: 0.442095; batch adversarial loss: 0.572783\n",
      "epoch 99; iter: 0; batch classifier loss: 0.318559; batch adversarial loss: 0.478422\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348115; batch adversarial loss: 0.535194\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407938; batch adversarial loss: 0.553974\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349562; batch adversarial loss: 0.506725\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394081; batch adversarial loss: 0.516223\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428471; batch adversarial loss: 0.487697\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360299; batch adversarial loss: 0.478115\n",
      "epoch 106; iter: 0; batch classifier loss: 0.414667; batch adversarial loss: 0.583049\n",
      "epoch 107; iter: 0; batch classifier loss: 0.463917; batch adversarial loss: 0.535237\n",
      "epoch 108; iter: 0; batch classifier loss: 0.315503; batch adversarial loss: 0.611238\n",
      "epoch 109; iter: 0; batch classifier loss: 0.328344; batch adversarial loss: 0.495955\n",
      "epoch 110; iter: 0; batch classifier loss: 0.360019; batch adversarial loss: 0.506599\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359008; batch adversarial loss: 0.535185\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398997; batch adversarial loss: 0.526166\n",
      "epoch 113; iter: 0; batch classifier loss: 0.402918; batch adversarial loss: 0.554028\n",
      "epoch 114; iter: 0; batch classifier loss: 0.457874; batch adversarial loss: 0.544717\n",
      "epoch 115; iter: 0; batch classifier loss: 0.335900; batch adversarial loss: 0.496765\n",
      "epoch 116; iter: 0; batch classifier loss: 0.502151; batch adversarial loss: 0.553864\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372715; batch adversarial loss: 0.582426\n",
      "epoch 118; iter: 0; batch classifier loss: 0.322177; batch adversarial loss: 0.506200\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366586; batch adversarial loss: 0.495705\n",
      "epoch 120; iter: 0; batch classifier loss: 0.301194; batch adversarial loss: 0.496919\n",
      "epoch 121; iter: 0; batch classifier loss: 0.323440; batch adversarial loss: 0.573423\n",
      "epoch 122; iter: 0; batch classifier loss: 0.439225; batch adversarial loss: 0.485948\n",
      "epoch 123; iter: 0; batch classifier loss: 0.363363; batch adversarial loss: 0.465606\n",
      "epoch 124; iter: 0; batch classifier loss: 0.384543; batch adversarial loss: 0.565352\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382194; batch adversarial loss: 0.533216\n",
      "epoch 126; iter: 0; batch classifier loss: 0.463638; batch adversarial loss: 0.533464\n",
      "epoch 127; iter: 0; batch classifier loss: 0.451933; batch adversarial loss: 0.566852\n",
      "epoch 128; iter: 0; batch classifier loss: 0.437853; batch adversarial loss: 0.546821\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364644; batch adversarial loss: 0.507316\n",
      "epoch 130; iter: 0; batch classifier loss: 0.442975; batch adversarial loss: 0.534465\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380472; batch adversarial loss: 0.490060\n",
      "epoch 132; iter: 0; batch classifier loss: 0.345971; batch adversarial loss: 0.630203\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376177; batch adversarial loss: 0.506225\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361683; batch adversarial loss: 0.478667\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334140; batch adversarial loss: 0.497856\n",
      "epoch 136; iter: 0; batch classifier loss: 0.303568; batch adversarial loss: 0.507333\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328203; batch adversarial loss: 0.469583\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342340; batch adversarial loss: 0.497665\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349659; batch adversarial loss: 0.562952\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361213; batch adversarial loss: 0.488103\n",
      "epoch 141; iter: 0; batch classifier loss: 0.447978; batch adversarial loss: 0.544527\n",
      "epoch 142; iter: 0; batch classifier loss: 0.402994; batch adversarial loss: 0.629730\n",
      "epoch 143; iter: 0; batch classifier loss: 0.457351; batch adversarial loss: 0.506676\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338096; batch adversarial loss: 0.478146\n",
      "epoch 145; iter: 0; batch classifier loss: 0.437581; batch adversarial loss: 0.497460\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359677; batch adversarial loss: 0.516231\n",
      "epoch 147; iter: 0; batch classifier loss: 0.414574; batch adversarial loss: 0.478462\n",
      "epoch 148; iter: 0; batch classifier loss: 0.385552; batch adversarial loss: 0.563346\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354537; batch adversarial loss: 0.544459\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365456; batch adversarial loss: 0.553952\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334126; batch adversarial loss: 0.592063\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403647; batch adversarial loss: 0.563570\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335275; batch adversarial loss: 0.572987\n",
      "epoch 154; iter: 0; batch classifier loss: 0.328361; batch adversarial loss: 0.515143\n",
      "epoch 155; iter: 0; batch classifier loss: 0.385678; batch adversarial loss: 0.506023\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334784; batch adversarial loss: 0.505699\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367024; batch adversarial loss: 0.525365\n",
      "epoch 158; iter: 0; batch classifier loss: 0.422294; batch adversarial loss: 0.572350\n",
      "epoch 159; iter: 0; batch classifier loss: 0.382564; batch adversarial loss: 0.611991\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352691; batch adversarial loss: 0.565784\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412045; batch adversarial loss: 0.593380\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353826; batch adversarial loss: 0.516751\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359679; batch adversarial loss: 0.535882\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344146; batch adversarial loss: 0.507189\n",
      "epoch 165; iter: 0; batch classifier loss: 0.312779; batch adversarial loss: 0.572722\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330256; batch adversarial loss: 0.525683\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372516; batch adversarial loss: 0.553680\n",
      "epoch 168; iter: 0; batch classifier loss: 0.316663; batch adversarial loss: 0.562585\n",
      "epoch 169; iter: 0; batch classifier loss: 0.420103; batch adversarial loss: 0.563214\n",
      "epoch 170; iter: 0; batch classifier loss: 0.443113; batch adversarial loss: 0.601822\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384376; batch adversarial loss: 0.581806\n",
      "epoch 172; iter: 0; batch classifier loss: 0.290462; batch adversarial loss: 0.572105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381494; batch adversarial loss: 0.572319\n",
      "epoch 174; iter: 0; batch classifier loss: 0.306229; batch adversarial loss: 0.535096\n",
      "epoch 175; iter: 0; batch classifier loss: 0.393952; batch adversarial loss: 0.536029\n",
      "epoch 176; iter: 0; batch classifier loss: 0.317499; batch adversarial loss: 0.478087\n",
      "epoch 177; iter: 0; batch classifier loss: 0.385670; batch adversarial loss: 0.478417\n",
      "epoch 178; iter: 0; batch classifier loss: 0.404999; batch adversarial loss: 0.535148\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377502; batch adversarial loss: 0.535778\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307243; batch adversarial loss: 0.516439\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337029; batch adversarial loss: 0.563086\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322986; batch adversarial loss: 0.553764\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341920; batch adversarial loss: 0.611331\n",
      "epoch 184; iter: 0; batch classifier loss: 0.412391; batch adversarial loss: 0.506311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.375329; batch adversarial loss: 0.478177\n",
      "epoch 186; iter: 0; batch classifier loss: 0.305522; batch adversarial loss: 0.534576\n",
      "epoch 187; iter: 0; batch classifier loss: 0.440828; batch adversarial loss: 0.535291\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382884; batch adversarial loss: 0.581957\n",
      "epoch 189; iter: 0; batch classifier loss: 0.342941; batch adversarial loss: 0.592991\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376042; batch adversarial loss: 0.535811\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347388; batch adversarial loss: 0.496783\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339083; batch adversarial loss: 0.639820\n",
      "epoch 193; iter: 0; batch classifier loss: 0.436962; batch adversarial loss: 0.564304\n",
      "epoch 194; iter: 0; batch classifier loss: 0.438155; batch adversarial loss: 0.496235\n",
      "epoch 195; iter: 0; batch classifier loss: 0.386850; batch adversarial loss: 0.525259\n",
      "epoch 196; iter: 0; batch classifier loss: 0.380680; batch adversarial loss: 0.506739\n",
      "epoch 197; iter: 0; batch classifier loss: 0.359534; batch adversarial loss: 0.573332\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350040; batch adversarial loss: 0.533670\n",
      "epoch 199; iter: 0; batch classifier loss: 0.344700; batch adversarial loss: 0.421020\n",
      "epoch 0; iter: 0; batch classifier loss: 0.639392; batch adversarial loss: 0.714387\n",
      "epoch 1; iter: 0; batch classifier loss: 0.626356; batch adversarial loss: 0.668518\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527005; batch adversarial loss: 0.629187\n",
      "epoch 3; iter: 0; batch classifier loss: 0.615063; batch adversarial loss: 0.638184\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544554; batch adversarial loss: 0.625099\n",
      "epoch 5; iter: 0; batch classifier loss: 0.627415; batch adversarial loss: 0.605384\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518713; batch adversarial loss: 0.571699\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556524; batch adversarial loss: 0.609345\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543927; batch adversarial loss: 0.563923\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472625; batch adversarial loss: 0.588160\n",
      "epoch 10; iter: 0; batch classifier loss: 0.577535; batch adversarial loss: 0.623721\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514282; batch adversarial loss: 0.644834\n",
      "epoch 12; iter: 0; batch classifier loss: 0.608474; batch adversarial loss: 0.591453\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563511; batch adversarial loss: 0.512838\n",
      "epoch 14; iter: 0; batch classifier loss: 0.458013; batch adversarial loss: 0.517336\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539088; batch adversarial loss: 0.564453\n",
      "epoch 16; iter: 0; batch classifier loss: 0.459053; batch adversarial loss: 0.567490\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501826; batch adversarial loss: 0.580293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.394996; batch adversarial loss: 0.551346\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488452; batch adversarial loss: 0.577242\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492422; batch adversarial loss: 0.493397\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517061; batch adversarial loss: 0.595822\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515277; batch adversarial loss: 0.576786\n",
      "epoch 23; iter: 0; batch classifier loss: 0.496751; batch adversarial loss: 0.498895\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455984; batch adversarial loss: 0.550319\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503437; batch adversarial loss: 0.518056\n",
      "epoch 26; iter: 0; batch classifier loss: 0.410205; batch adversarial loss: 0.597845\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460977; batch adversarial loss: 0.561963\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434529; batch adversarial loss: 0.590262\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430660; batch adversarial loss: 0.607460\n",
      "epoch 30; iter: 0; batch classifier loss: 0.391842; batch adversarial loss: 0.563880\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448511; batch adversarial loss: 0.502467\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454106; batch adversarial loss: 0.511886\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478424; batch adversarial loss: 0.457819\n",
      "epoch 34; iter: 0; batch classifier loss: 0.513616; batch adversarial loss: 0.519987\n",
      "epoch 35; iter: 0; batch classifier loss: 0.387063; batch adversarial loss: 0.465621\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459416; batch adversarial loss: 0.581514\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420596; batch adversarial loss: 0.590198\n",
      "epoch 38; iter: 0; batch classifier loss: 0.490621; batch adversarial loss: 0.544830\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411202; batch adversarial loss: 0.481579\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450922; batch adversarial loss: 0.553821\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445503; batch adversarial loss: 0.571982\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398285; batch adversarial loss: 0.553734\n",
      "epoch 43; iter: 0; batch classifier loss: 0.500667; batch adversarial loss: 0.616987\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420906; batch adversarial loss: 0.526325\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442332; batch adversarial loss: 0.535441\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444688; batch adversarial loss: 0.516726\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459375; batch adversarial loss: 0.526071\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445638; batch adversarial loss: 0.581218\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417887; batch adversarial loss: 0.562863\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457770; batch adversarial loss: 0.581687\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397885; batch adversarial loss: 0.544949\n",
      "epoch 52; iter: 0; batch classifier loss: 0.332625; batch adversarial loss: 0.515977\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402831; batch adversarial loss: 0.517323\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417470; batch adversarial loss: 0.534624\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436238; batch adversarial loss: 0.515459\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423029; batch adversarial loss: 0.422425\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405965; batch adversarial loss: 0.507206\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400015; batch adversarial loss: 0.580935\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414931; batch adversarial loss: 0.535658\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382473; batch adversarial loss: 0.506808\n",
      "epoch 61; iter: 0; batch classifier loss: 0.378854; batch adversarial loss: 0.562739\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457873; batch adversarial loss: 0.534307\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411326; batch adversarial loss: 0.543884\n",
      "epoch 64; iter: 0; batch classifier loss: 0.396779; batch adversarial loss: 0.554214\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397732; batch adversarial loss: 0.544311\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419279; batch adversarial loss: 0.489729\n",
      "epoch 67; iter: 0; batch classifier loss: 0.456468; batch adversarial loss: 0.449431\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401755; batch adversarial loss: 0.602806\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427955; batch adversarial loss: 0.526046\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374166; batch adversarial loss: 0.551930\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377483; batch adversarial loss: 0.488469\n",
      "epoch 72; iter: 0; batch classifier loss: 0.346359; batch adversarial loss: 0.460132\n",
      "epoch 73; iter: 0; batch classifier loss: 0.345619; batch adversarial loss: 0.635904\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381012; batch adversarial loss: 0.572988\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430523; batch adversarial loss: 0.442505\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404086; batch adversarial loss: 0.488223\n",
      "epoch 77; iter: 0; batch classifier loss: 0.461925; batch adversarial loss: 0.556257\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380098; batch adversarial loss: 0.497131\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382824; batch adversarial loss: 0.489958\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421450; batch adversarial loss: 0.572706\n",
      "epoch 81; iter: 0; batch classifier loss: 0.456193; batch adversarial loss: 0.601000\n",
      "epoch 82; iter: 0; batch classifier loss: 0.343889; batch adversarial loss: 0.507772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.400768; batch adversarial loss: 0.545621\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409806; batch adversarial loss: 0.562638\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435441; batch adversarial loss: 0.591164\n",
      "epoch 86; iter: 0; batch classifier loss: 0.396060; batch adversarial loss: 0.573028\n",
      "epoch 87; iter: 0; batch classifier loss: 0.340728; batch adversarial loss: 0.498582\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387440; batch adversarial loss: 0.516492\n",
      "epoch 89; iter: 0; batch classifier loss: 0.302966; batch adversarial loss: 0.524962\n",
      "epoch 90; iter: 0; batch classifier loss: 0.433068; batch adversarial loss: 0.561009\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413547; batch adversarial loss: 0.544314\n",
      "epoch 92; iter: 0; batch classifier loss: 0.494151; batch adversarial loss: 0.489152\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347829; batch adversarial loss: 0.533959\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385416; batch adversarial loss: 0.582154\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343490; batch adversarial loss: 0.544383\n",
      "epoch 96; iter: 0; batch classifier loss: 0.445713; batch adversarial loss: 0.581911\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361411; batch adversarial loss: 0.591195\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370843; batch adversarial loss: 0.498737\n",
      "epoch 99; iter: 0; batch classifier loss: 0.457634; batch adversarial loss: 0.553608\n",
      "epoch 100; iter: 0; batch classifier loss: 0.405767; batch adversarial loss: 0.497594\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376474; batch adversarial loss: 0.487968\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326687; batch adversarial loss: 0.434349\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356450; batch adversarial loss: 0.562791\n",
      "epoch 104; iter: 0; batch classifier loss: 0.360103; batch adversarial loss: 0.535182\n",
      "epoch 105; iter: 0; batch classifier loss: 0.375477; batch adversarial loss: 0.479378\n",
      "epoch 106; iter: 0; batch classifier loss: 0.509040; batch adversarial loss: 0.563229\n",
      "epoch 107; iter: 0; batch classifier loss: 0.330782; batch adversarial loss: 0.470967\n",
      "epoch 108; iter: 0; batch classifier loss: 0.412078; batch adversarial loss: 0.563409\n",
      "epoch 109; iter: 0; batch classifier loss: 0.420339; batch adversarial loss: 0.554457\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389078; batch adversarial loss: 0.628357\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386760; batch adversarial loss: 0.515667\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362010; batch adversarial loss: 0.545341\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382084; batch adversarial loss: 0.591472\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351596; batch adversarial loss: 0.554000\n",
      "epoch 115; iter: 0; batch classifier loss: 0.334987; batch adversarial loss: 0.517067\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368337; batch adversarial loss: 0.507301\n",
      "epoch 117; iter: 0; batch classifier loss: 0.328289; batch adversarial loss: 0.563884\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366327; batch adversarial loss: 0.582713\n",
      "epoch 119; iter: 0; batch classifier loss: 0.292416; batch adversarial loss: 0.562808\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372880; batch adversarial loss: 0.507744\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389223; batch adversarial loss: 0.545783\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382809; batch adversarial loss: 0.524758\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429431; batch adversarial loss: 0.573461\n",
      "epoch 124; iter: 0; batch classifier loss: 0.416959; batch adversarial loss: 0.468233\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367306; batch adversarial loss: 0.534203\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361821; batch adversarial loss: 0.535975\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370249; batch adversarial loss: 0.562202\n",
      "epoch 128; iter: 0; batch classifier loss: 0.380237; batch adversarial loss: 0.581264\n",
      "epoch 129; iter: 0; batch classifier loss: 0.315981; batch adversarial loss: 0.507323\n",
      "epoch 130; iter: 0; batch classifier loss: 0.344889; batch adversarial loss: 0.498409\n",
      "epoch 131; iter: 0; batch classifier loss: 0.478662; batch adversarial loss: 0.525952\n",
      "epoch 132; iter: 0; batch classifier loss: 0.285487; batch adversarial loss: 0.601105\n",
      "epoch 133; iter: 0; batch classifier loss: 0.461578; batch adversarial loss: 0.536268\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377248; batch adversarial loss: 0.561885\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364949; batch adversarial loss: 0.534143\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410622; batch adversarial loss: 0.583060\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328975; batch adversarial loss: 0.470499\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389586; batch adversarial loss: 0.571896\n",
      "epoch 139; iter: 0; batch classifier loss: 0.436586; batch adversarial loss: 0.636858\n",
      "epoch 140; iter: 0; batch classifier loss: 0.382939; batch adversarial loss: 0.536296\n",
      "epoch 141; iter: 0; batch classifier loss: 0.439031; batch adversarial loss: 0.535417\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396525; batch adversarial loss: 0.489972\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373701; batch adversarial loss: 0.497129\n",
      "epoch 144; iter: 0; batch classifier loss: 0.287001; batch adversarial loss: 0.488281\n",
      "epoch 145; iter: 0; batch classifier loss: 0.311758; batch adversarial loss: 0.535904\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373903; batch adversarial loss: 0.536091\n",
      "epoch 147; iter: 0; batch classifier loss: 0.386365; batch adversarial loss: 0.573556\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381753; batch adversarial loss: 0.543221\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335722; batch adversarial loss: 0.553647\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421578; batch adversarial loss: 0.600035\n",
      "epoch 151; iter: 0; batch classifier loss: 0.406542; batch adversarial loss: 0.581632\n",
      "epoch 152; iter: 0; batch classifier loss: 0.431743; batch adversarial loss: 0.536067\n",
      "epoch 153; iter: 0; batch classifier loss: 0.308717; batch adversarial loss: 0.618339\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369798; batch adversarial loss: 0.534770\n",
      "epoch 155; iter: 0; batch classifier loss: 0.286206; batch adversarial loss: 0.619251\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373088; batch adversarial loss: 0.470449\n",
      "epoch 157; iter: 0; batch classifier loss: 0.415548; batch adversarial loss: 0.534518\n",
      "epoch 158; iter: 0; batch classifier loss: 0.333689; batch adversarial loss: 0.470489\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356976; batch adversarial loss: 0.563593\n",
      "epoch 160; iter: 0; batch classifier loss: 0.412588; batch adversarial loss: 0.563038\n",
      "epoch 161; iter: 0; batch classifier loss: 0.326798; batch adversarial loss: 0.630496\n",
      "epoch 162; iter: 0; batch classifier loss: 0.433902; batch adversarial loss: 0.620002\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388009; batch adversarial loss: 0.554842\n",
      "epoch 164; iter: 0; batch classifier loss: 0.466212; batch adversarial loss: 0.459490\n",
      "epoch 165; iter: 0; batch classifier loss: 0.368356; batch adversarial loss: 0.573978\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342001; batch adversarial loss: 0.638078\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329335; batch adversarial loss: 0.526143\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338171; batch adversarial loss: 0.536492\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408542; batch adversarial loss: 0.563865\n",
      "epoch 170; iter: 0; batch classifier loss: 0.347261; batch adversarial loss: 0.517372\n",
      "epoch 171; iter: 0; batch classifier loss: 0.339190; batch adversarial loss: 0.516829\n",
      "epoch 172; iter: 0; batch classifier loss: 0.418218; batch adversarial loss: 0.460019\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330388; batch adversarial loss: 0.600765\n",
      "epoch 174; iter: 0; batch classifier loss: 0.389771; batch adversarial loss: 0.544057\n",
      "epoch 175; iter: 0; batch classifier loss: 0.374697; batch adversarial loss: 0.563568\n",
      "epoch 176; iter: 0; batch classifier loss: 0.405174; batch adversarial loss: 0.507445\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406786; batch adversarial loss: 0.498106\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326250; batch adversarial loss: 0.508259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.364425; batch adversarial loss: 0.507386\n",
      "epoch 180; iter: 0; batch classifier loss: 0.305339; batch adversarial loss: 0.534817\n",
      "epoch 181; iter: 0; batch classifier loss: 0.393994; batch adversarial loss: 0.554229\n",
      "epoch 182; iter: 0; batch classifier loss: 0.331209; batch adversarial loss: 0.554779\n",
      "epoch 183; iter: 0; batch classifier loss: 0.447392; batch adversarial loss: 0.498327\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370563; batch adversarial loss: 0.479403\n",
      "epoch 185; iter: 0; batch classifier loss: 0.327041; batch adversarial loss: 0.573337\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353636; batch adversarial loss: 0.526512\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375341; batch adversarial loss: 0.553015\n",
      "epoch 188; iter: 0; batch classifier loss: 0.438572; batch adversarial loss: 0.534597\n",
      "epoch 189; iter: 0; batch classifier loss: 0.353977; batch adversarial loss: 0.460020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.286422; batch adversarial loss: 0.582700\n",
      "epoch 191; iter: 0; batch classifier loss: 0.317697; batch adversarial loss: 0.516218\n",
      "epoch 192; iter: 0; batch classifier loss: 0.407632; batch adversarial loss: 0.469742\n",
      "epoch 193; iter: 0; batch classifier loss: 0.319951; batch adversarial loss: 0.534162\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342041; batch adversarial loss: 0.535674\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327990; batch adversarial loss: 0.600066\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330318; batch adversarial loss: 0.618210\n",
      "epoch 197; iter: 0; batch classifier loss: 0.291362; batch adversarial loss: 0.488491\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370584; batch adversarial loss: 0.489340\n",
      "epoch 199; iter: 0; batch classifier loss: 0.425085; batch adversarial loss: 0.544451\n",
      "epoch 0; iter: 0; batch classifier loss: 0.750685; batch adversarial loss: 0.792065\n",
      "epoch 1; iter: 0; batch classifier loss: 0.636865; batch adversarial loss: 0.743255\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585181; batch adversarial loss: 0.696123\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583355; batch adversarial loss: 0.660952\n",
      "epoch 4; iter: 0; batch classifier loss: 0.514636; batch adversarial loss: 0.640621\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566297; batch adversarial loss: 0.624207\n",
      "epoch 6; iter: 0; batch classifier loss: 0.609041; batch adversarial loss: 0.606899\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550858; batch adversarial loss: 0.608307\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574911; batch adversarial loss: 0.596522\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602908; batch adversarial loss: 0.596706\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509935; batch adversarial loss: 0.557378\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523071; batch adversarial loss: 0.565011\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506192; batch adversarial loss: 0.537310\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546582; batch adversarial loss: 0.544265\n",
      "epoch 14; iter: 0; batch classifier loss: 0.460535; batch adversarial loss: 0.562843\n",
      "epoch 15; iter: 0; batch classifier loss: 0.460302; batch adversarial loss: 0.534350\n",
      "epoch 16; iter: 0; batch classifier loss: 0.517722; batch adversarial loss: 0.559329\n",
      "epoch 17; iter: 0; batch classifier loss: 0.415506; batch adversarial loss: 0.502876\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529102; batch adversarial loss: 0.534893\n",
      "epoch 19; iter: 0; batch classifier loss: 0.604992; batch adversarial loss: 0.479679\n",
      "epoch 20; iter: 0; batch classifier loss: 0.559789; batch adversarial loss: 0.545715\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503835; batch adversarial loss: 0.531254\n",
      "epoch 22; iter: 0; batch classifier loss: 0.535410; batch adversarial loss: 0.553210\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457110; batch adversarial loss: 0.563703\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526762; batch adversarial loss: 0.532191\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474869; batch adversarial loss: 0.593009\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566543; batch adversarial loss: 0.563730\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432413; batch adversarial loss: 0.496882\n",
      "epoch 28; iter: 0; batch classifier loss: 0.398373; batch adversarial loss: 0.565927\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484290; batch adversarial loss: 0.611211\n",
      "epoch 30; iter: 0; batch classifier loss: 0.451911; batch adversarial loss: 0.572385\n",
      "epoch 31; iter: 0; batch classifier loss: 0.520061; batch adversarial loss: 0.537312\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444639; batch adversarial loss: 0.478798\n",
      "epoch 33; iter: 0; batch classifier loss: 0.529063; batch adversarial loss: 0.571431\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473984; batch adversarial loss: 0.521264\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458054; batch adversarial loss: 0.493786\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435859; batch adversarial loss: 0.561858\n",
      "epoch 37; iter: 0; batch classifier loss: 0.453228; batch adversarial loss: 0.569509\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474007; batch adversarial loss: 0.492930\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470415; batch adversarial loss: 0.526707\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453258; batch adversarial loss: 0.616256\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471392; batch adversarial loss: 0.501406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.426590; batch adversarial loss: 0.614799\n",
      "epoch 43; iter: 0; batch classifier loss: 0.374157; batch adversarial loss: 0.529119\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459299; batch adversarial loss: 0.559719\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442618; batch adversarial loss: 0.473230\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424874; batch adversarial loss: 0.597780\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431358; batch adversarial loss: 0.508428\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399502; batch adversarial loss: 0.535974\n",
      "epoch 49; iter: 0; batch classifier loss: 0.485967; batch adversarial loss: 0.599669\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386028; batch adversarial loss: 0.599762\n",
      "epoch 51; iter: 0; batch classifier loss: 0.528968; batch adversarial loss: 0.578754\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464751; batch adversarial loss: 0.515670\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431143; batch adversarial loss: 0.616130\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405577; batch adversarial loss: 0.596607\n",
      "epoch 55; iter: 0; batch classifier loss: 0.451170; batch adversarial loss: 0.543904\n",
      "epoch 56; iter: 0; batch classifier loss: 0.465540; batch adversarial loss: 0.497546\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471061; batch adversarial loss: 0.548846\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410116; batch adversarial loss: 0.538119\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414948; batch adversarial loss: 0.513364\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414661; batch adversarial loss: 0.520029\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460337; batch adversarial loss: 0.544534\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416142; batch adversarial loss: 0.517051\n",
      "epoch 63; iter: 0; batch classifier loss: 0.363696; batch adversarial loss: 0.660452\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394112; batch adversarial loss: 0.488643\n",
      "epoch 65; iter: 0; batch classifier loss: 0.373255; batch adversarial loss: 0.592706\n",
      "epoch 66; iter: 0; batch classifier loss: 0.344014; batch adversarial loss: 0.537022\n",
      "epoch 67; iter: 0; batch classifier loss: 0.503204; batch adversarial loss: 0.496920\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443126; batch adversarial loss: 0.540255\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422695; batch adversarial loss: 0.526168\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415869; batch adversarial loss: 0.497755\n",
      "epoch 71; iter: 0; batch classifier loss: 0.364581; batch adversarial loss: 0.496604\n",
      "epoch 72; iter: 0; batch classifier loss: 0.335501; batch adversarial loss: 0.540049\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389674; batch adversarial loss: 0.507074\n",
      "epoch 74; iter: 0; batch classifier loss: 0.511631; batch adversarial loss: 0.525075\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429911; batch adversarial loss: 0.574031\n",
      "epoch 76; iter: 0; batch classifier loss: 0.500599; batch adversarial loss: 0.603536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.440088; batch adversarial loss: 0.502697\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376135; batch adversarial loss: 0.621350\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415775; batch adversarial loss: 0.545730\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369575; batch adversarial loss: 0.507311\n",
      "epoch 81; iter: 0; batch classifier loss: 0.416872; batch adversarial loss: 0.534999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382277; batch adversarial loss: 0.504291\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383418; batch adversarial loss: 0.544026\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381988; batch adversarial loss: 0.490969\n",
      "epoch 85; iter: 0; batch classifier loss: 0.338856; batch adversarial loss: 0.518525\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360474; batch adversarial loss: 0.554619\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410624; batch adversarial loss: 0.572626\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433446; batch adversarial loss: 0.533738\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363109; batch adversarial loss: 0.573699\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404923; batch adversarial loss: 0.535687\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397948; batch adversarial loss: 0.605522\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413859; batch adversarial loss: 0.577159\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340449; batch adversarial loss: 0.548279\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374465; batch adversarial loss: 0.599245\n",
      "epoch 95; iter: 0; batch classifier loss: 0.323396; batch adversarial loss: 0.563546\n",
      "epoch 96; iter: 0; batch classifier loss: 0.407317; batch adversarial loss: 0.597581\n",
      "epoch 97; iter: 0; batch classifier loss: 0.380676; batch adversarial loss: 0.555486\n",
      "epoch 98; iter: 0; batch classifier loss: 0.327613; batch adversarial loss: 0.556509\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417518; batch adversarial loss: 0.581229\n",
      "epoch 100; iter: 0; batch classifier loss: 0.453618; batch adversarial loss: 0.572152\n",
      "epoch 101; iter: 0; batch classifier loss: 0.470643; batch adversarial loss: 0.607230\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363200; batch adversarial loss: 0.560243\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352437; batch adversarial loss: 0.615892\n",
      "epoch 104; iter: 0; batch classifier loss: 0.438104; batch adversarial loss: 0.498205\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405522; batch adversarial loss: 0.567302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354132; batch adversarial loss: 0.526940\n",
      "epoch 107; iter: 0; batch classifier loss: 0.474157; batch adversarial loss: 0.509108\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378938; batch adversarial loss: 0.542147\n",
      "epoch 109; iter: 0; batch classifier loss: 0.414117; batch adversarial loss: 0.507035\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378825; batch adversarial loss: 0.581656\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382094; batch adversarial loss: 0.570636\n",
      "epoch 112; iter: 0; batch classifier loss: 0.329465; batch adversarial loss: 0.548609\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347983; batch adversarial loss: 0.586648\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374236; batch adversarial loss: 0.515120\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352435; batch adversarial loss: 0.537089\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398320; batch adversarial loss: 0.587114\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362573; batch adversarial loss: 0.547772\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361898; batch adversarial loss: 0.475502\n",
      "epoch 119; iter: 0; batch classifier loss: 0.296981; batch adversarial loss: 0.552795\n",
      "epoch 120; iter: 0; batch classifier loss: 0.456504; batch adversarial loss: 0.519736\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341541; batch adversarial loss: 0.525214\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410786; batch adversarial loss: 0.435277\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415751; batch adversarial loss: 0.598512\n",
      "epoch 124; iter: 0; batch classifier loss: 0.410127; batch adversarial loss: 0.497888\n",
      "epoch 125; iter: 0; batch classifier loss: 0.348297; batch adversarial loss: 0.565295\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404607; batch adversarial loss: 0.553343\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390466; batch adversarial loss: 0.548900\n",
      "epoch 128; iter: 0; batch classifier loss: 0.335675; batch adversarial loss: 0.642415\n",
      "epoch 129; iter: 0; batch classifier loss: 0.381996; batch adversarial loss: 0.575138\n",
      "epoch 130; iter: 0; batch classifier loss: 0.327964; batch adversarial loss: 0.589704\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384856; batch adversarial loss: 0.523776\n",
      "epoch 132; iter: 0; batch classifier loss: 0.296304; batch adversarial loss: 0.534955\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369474; batch adversarial loss: 0.572150\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406455; batch adversarial loss: 0.626516\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372512; batch adversarial loss: 0.563158\n",
      "epoch 136; iter: 0; batch classifier loss: 0.296484; batch adversarial loss: 0.552785\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356434; batch adversarial loss: 0.511890\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394660; batch adversarial loss: 0.577057\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384723; batch adversarial loss: 0.618233\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389628; batch adversarial loss: 0.568031\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323037; batch adversarial loss: 0.609646\n",
      "epoch 142; iter: 0; batch classifier loss: 0.425811; batch adversarial loss: 0.543229\n",
      "epoch 143; iter: 0; batch classifier loss: 0.372404; batch adversarial loss: 0.524911\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380936; batch adversarial loss: 0.607454\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381327; batch adversarial loss: 0.532184\n",
      "epoch 146; iter: 0; batch classifier loss: 0.296257; batch adversarial loss: 0.600773\n",
      "epoch 147; iter: 0; batch classifier loss: 0.478724; batch adversarial loss: 0.534982\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365800; batch adversarial loss: 0.553490\n",
      "epoch 149; iter: 0; batch classifier loss: 0.387976; batch adversarial loss: 0.525773\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379890; batch adversarial loss: 0.481388\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370248; batch adversarial loss: 0.490100\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323738; batch adversarial loss: 0.432406\n",
      "epoch 153; iter: 0; batch classifier loss: 0.403280; batch adversarial loss: 0.580305\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373190; batch adversarial loss: 0.488832\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373316; batch adversarial loss: 0.551424\n",
      "epoch 156; iter: 0; batch classifier loss: 0.375982; batch adversarial loss: 0.614069\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393339; batch adversarial loss: 0.592147\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334363; batch adversarial loss: 0.549055\n",
      "epoch 159; iter: 0; batch classifier loss: 0.326852; batch adversarial loss: 0.526509\n",
      "epoch 160; iter: 0; batch classifier loss: 0.302777; batch adversarial loss: 0.581550\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345503; batch adversarial loss: 0.491632\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311871; batch adversarial loss: 0.463710\n",
      "epoch 163; iter: 0; batch classifier loss: 0.289135; batch adversarial loss: 0.539939\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389531; batch adversarial loss: 0.542128\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386375; batch adversarial loss: 0.607758\n",
      "epoch 166; iter: 0; batch classifier loss: 0.432235; batch adversarial loss: 0.558525\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384839; batch adversarial loss: 0.457494\n",
      "epoch 168; iter: 0; batch classifier loss: 0.443548; batch adversarial loss: 0.516768\n",
      "epoch 169; iter: 0; batch classifier loss: 0.409758; batch adversarial loss: 0.524639\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354807; batch adversarial loss: 0.539450\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396191; batch adversarial loss: 0.596097\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346649; batch adversarial loss: 0.647529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.373311; batch adversarial loss: 0.498460\n",
      "epoch 174; iter: 0; batch classifier loss: 0.308728; batch adversarial loss: 0.460674\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369429; batch adversarial loss: 0.577689\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366319; batch adversarial loss: 0.533762\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345557; batch adversarial loss: 0.510649\n",
      "epoch 178; iter: 0; batch classifier loss: 0.288663; batch adversarial loss: 0.536416\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380483; batch adversarial loss: 0.551230\n",
      "epoch 180; iter: 0; batch classifier loss: 0.349167; batch adversarial loss: 0.507987\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410792; batch adversarial loss: 0.557905\n",
      "epoch 182; iter: 0; batch classifier loss: 0.363050; batch adversarial loss: 0.551724\n",
      "epoch 183; iter: 0; batch classifier loss: 0.317977; batch adversarial loss: 0.545462\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371528; batch adversarial loss: 0.543259\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338313; batch adversarial loss: 0.569957\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392139; batch adversarial loss: 0.527949\n",
      "epoch 187; iter: 0; batch classifier loss: 0.386247; batch adversarial loss: 0.524190\n",
      "epoch 188; iter: 0; batch classifier loss: 0.342064; batch adversarial loss: 0.512275\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380591; batch adversarial loss: 0.490611\n",
      "epoch 190; iter: 0; batch classifier loss: 0.416413; batch adversarial loss: 0.519909\n",
      "epoch 191; iter: 0; batch classifier loss: 0.435853; batch adversarial loss: 0.576458\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358790; batch adversarial loss: 0.517000\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336095; batch adversarial loss: 0.569499\n",
      "epoch 194; iter: 0; batch classifier loss: 0.408857; batch adversarial loss: 0.552959\n",
      "epoch 195; iter: 0; batch classifier loss: 0.306682; batch adversarial loss: 0.491697\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383422; batch adversarial loss: 0.542399\n",
      "epoch 197; iter: 0; batch classifier loss: 0.432727; batch adversarial loss: 0.586382\n",
      "epoch 198; iter: 0; batch classifier loss: 0.270331; batch adversarial loss: 0.512483\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314453; batch adversarial loss: 0.543692\n",
      "epoch 0; iter: 0; batch classifier loss: 0.647978; batch adversarial loss: 0.616281\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599486; batch adversarial loss: 0.633183\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542898; batch adversarial loss: 0.638222\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597182; batch adversarial loss: 0.655493\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603106; batch adversarial loss: 0.582514\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557429; batch adversarial loss: 0.626336\n",
      "epoch 6; iter: 0; batch classifier loss: 0.604623; batch adversarial loss: 0.629789\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626999; batch adversarial loss: 0.694015\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602275; batch adversarial loss: 0.594458\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533731; batch adversarial loss: 0.589642\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550776; batch adversarial loss: 0.587342\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524524; batch adversarial loss: 0.623503\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552904; batch adversarial loss: 0.606111\n",
      "epoch 13; iter: 0; batch classifier loss: 0.426506; batch adversarial loss: 0.547199\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521339; batch adversarial loss: 0.559343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552513; batch adversarial loss: 0.574769\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467903; batch adversarial loss: 0.528243\n",
      "epoch 17; iter: 0; batch classifier loss: 0.581463; batch adversarial loss: 0.503825\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527420; batch adversarial loss: 0.586030\n",
      "epoch 19; iter: 0; batch classifier loss: 0.592861; batch adversarial loss: 0.526584\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490684; batch adversarial loss: 0.571369\n",
      "epoch 21; iter: 0; batch classifier loss: 0.444359; batch adversarial loss: 0.614558\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487385; batch adversarial loss: 0.512705\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531947; batch adversarial loss: 0.588198\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435645; batch adversarial loss: 0.492031\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495556; batch adversarial loss: 0.593940\n",
      "epoch 26; iter: 0; batch classifier loss: 0.551417; batch adversarial loss: 0.512460\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511957; batch adversarial loss: 0.528167\n",
      "epoch 28; iter: 0; batch classifier loss: 0.528039; batch adversarial loss: 0.571778\n",
      "epoch 29; iter: 0; batch classifier loss: 0.416845; batch adversarial loss: 0.563140\n",
      "epoch 30; iter: 0; batch classifier loss: 0.525061; batch adversarial loss: 0.577961\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507933; batch adversarial loss: 0.584299\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439180; batch adversarial loss: 0.542849\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446033; batch adversarial loss: 0.608442\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469195; batch adversarial loss: 0.501187\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454871; batch adversarial loss: 0.553115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.467669; batch adversarial loss: 0.516982\n",
      "epoch 37; iter: 0; batch classifier loss: 0.505436; batch adversarial loss: 0.583275\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486789; batch adversarial loss: 0.577339\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513378; batch adversarial loss: 0.555182\n",
      "epoch 40; iter: 0; batch classifier loss: 0.512122; batch adversarial loss: 0.530683\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473758; batch adversarial loss: 0.552087\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438025; batch adversarial loss: 0.533339\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467717; batch adversarial loss: 0.570611\n",
      "epoch 44; iter: 0; batch classifier loss: 0.520325; batch adversarial loss: 0.521012\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403526; batch adversarial loss: 0.527027\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465324; batch adversarial loss: 0.486522\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437184; batch adversarial loss: 0.576132\n",
      "epoch 48; iter: 0; batch classifier loss: 0.496884; batch adversarial loss: 0.535187\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392699; batch adversarial loss: 0.502383\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461134; batch adversarial loss: 0.610639\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470618; batch adversarial loss: 0.526025\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462269; batch adversarial loss: 0.534162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413093; batch adversarial loss: 0.544543\n",
      "epoch 54; iter: 0; batch classifier loss: 0.593688; batch adversarial loss: 0.594252\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465163; batch adversarial loss: 0.488672\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408332; batch adversarial loss: 0.518810\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413109; batch adversarial loss: 0.517123\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443520; batch adversarial loss: 0.545329\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429467; batch adversarial loss: 0.547947\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456242; batch adversarial loss: 0.597436\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467353; batch adversarial loss: 0.519189\n",
      "epoch 62; iter: 0; batch classifier loss: 0.350247; batch adversarial loss: 0.582383\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409619; batch adversarial loss: 0.600891\n",
      "epoch 64; iter: 0; batch classifier loss: 0.473007; batch adversarial loss: 0.526473\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385873; batch adversarial loss: 0.560809\n",
      "epoch 66; iter: 0; batch classifier loss: 0.325377; batch adversarial loss: 0.554803\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403598; batch adversarial loss: 0.510109\n",
      "epoch 68; iter: 0; batch classifier loss: 0.344741; batch adversarial loss: 0.625046\n",
      "epoch 69; iter: 0; batch classifier loss: 0.501890; batch adversarial loss: 0.512070\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423094; batch adversarial loss: 0.522282\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431455; batch adversarial loss: 0.528859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.460830; batch adversarial loss: 0.500071\n",
      "epoch 73; iter: 0; batch classifier loss: 0.351651; batch adversarial loss: 0.542001\n",
      "epoch 74; iter: 0; batch classifier loss: 0.468118; batch adversarial loss: 0.507462\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409495; batch adversarial loss: 0.557257\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424388; batch adversarial loss: 0.528077\n",
      "epoch 77; iter: 0; batch classifier loss: 0.463116; batch adversarial loss: 0.561166\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401202; batch adversarial loss: 0.576644\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411777; batch adversarial loss: 0.418011\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432958; batch adversarial loss: 0.546207\n",
      "epoch 81; iter: 0; batch classifier loss: 0.453851; batch adversarial loss: 0.571800\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435798; batch adversarial loss: 0.532799\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410537; batch adversarial loss: 0.556709\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418439; batch adversarial loss: 0.551919\n",
      "epoch 85; iter: 0; batch classifier loss: 0.422966; batch adversarial loss: 0.566336\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410493; batch adversarial loss: 0.505370\n",
      "epoch 87; iter: 0; batch classifier loss: 0.381526; batch adversarial loss: 0.553994\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373079; batch adversarial loss: 0.477807\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404868; batch adversarial loss: 0.580967\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405149; batch adversarial loss: 0.520085\n",
      "epoch 91; iter: 0; batch classifier loss: 0.288516; batch adversarial loss: 0.570348\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417201; batch adversarial loss: 0.515351\n",
      "epoch 93; iter: 0; batch classifier loss: 0.376344; batch adversarial loss: 0.576923\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408195; batch adversarial loss: 0.502991\n",
      "epoch 95; iter: 0; batch classifier loss: 0.367085; batch adversarial loss: 0.495930\n",
      "epoch 96; iter: 0; batch classifier loss: 0.458534; batch adversarial loss: 0.501546\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384944; batch adversarial loss: 0.569711\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415843; batch adversarial loss: 0.639028\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408932; batch adversarial loss: 0.538819\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352638; batch adversarial loss: 0.505885\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393268; batch adversarial loss: 0.552509\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409093; batch adversarial loss: 0.582395\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389798; batch adversarial loss: 0.516970\n",
      "epoch 104; iter: 0; batch classifier loss: 0.306326; batch adversarial loss: 0.535326\n",
      "epoch 105; iter: 0; batch classifier loss: 0.460919; batch adversarial loss: 0.535946\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443637; batch adversarial loss: 0.521165\n",
      "epoch 107; iter: 0; batch classifier loss: 0.401571; batch adversarial loss: 0.560001\n",
      "epoch 108; iter: 0; batch classifier loss: 0.360033; batch adversarial loss: 0.579486\n",
      "epoch 109; iter: 0; batch classifier loss: 0.442588; batch adversarial loss: 0.600068\n",
      "epoch 110; iter: 0; batch classifier loss: 0.355737; batch adversarial loss: 0.487212\n",
      "epoch 111; iter: 0; batch classifier loss: 0.480621; batch adversarial loss: 0.491542\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430524; batch adversarial loss: 0.528755\n",
      "epoch 113; iter: 0; batch classifier loss: 0.434439; batch adversarial loss: 0.499967\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412656; batch adversarial loss: 0.570961\n",
      "epoch 115; iter: 0; batch classifier loss: 0.402471; batch adversarial loss: 0.480626\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427393; batch adversarial loss: 0.527525\n",
      "epoch 117; iter: 0; batch classifier loss: 0.394829; batch adversarial loss: 0.593576\n",
      "epoch 118; iter: 0; batch classifier loss: 0.433052; batch adversarial loss: 0.482075\n",
      "epoch 119; iter: 0; batch classifier loss: 0.406219; batch adversarial loss: 0.626159\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373737; batch adversarial loss: 0.480792\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348036; batch adversarial loss: 0.564998\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358295; batch adversarial loss: 0.512822\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349302; batch adversarial loss: 0.525195\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408183; batch adversarial loss: 0.500597\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370355; batch adversarial loss: 0.546785\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367413; batch adversarial loss: 0.551858\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378067; batch adversarial loss: 0.596735\n",
      "epoch 128; iter: 0; batch classifier loss: 0.437624; batch adversarial loss: 0.469483\n",
      "epoch 129; iter: 0; batch classifier loss: 0.471160; batch adversarial loss: 0.653076\n",
      "epoch 130; iter: 0; batch classifier loss: 0.423816; batch adversarial loss: 0.478910\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351418; batch adversarial loss: 0.495140\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313724; batch adversarial loss: 0.521623\n",
      "epoch 133; iter: 0; batch classifier loss: 0.382019; batch adversarial loss: 0.509147\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399862; batch adversarial loss: 0.611076\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377110; batch adversarial loss: 0.557456\n",
      "epoch 136; iter: 0; batch classifier loss: 0.292872; batch adversarial loss: 0.547186\n",
      "epoch 137; iter: 0; batch classifier loss: 0.310650; batch adversarial loss: 0.578408\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317925; batch adversarial loss: 0.552087\n",
      "epoch 139; iter: 0; batch classifier loss: 0.432762; batch adversarial loss: 0.536230\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374378; batch adversarial loss: 0.506878\n",
      "epoch 141; iter: 0; batch classifier loss: 0.376529; batch adversarial loss: 0.583154\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379034; batch adversarial loss: 0.627856\n",
      "epoch 143; iter: 0; batch classifier loss: 0.403922; batch adversarial loss: 0.483096\n",
      "epoch 144; iter: 0; batch classifier loss: 0.320861; batch adversarial loss: 0.472350\n",
      "epoch 145; iter: 0; batch classifier loss: 0.345551; batch adversarial loss: 0.517314\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383459; batch adversarial loss: 0.544463\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322419; batch adversarial loss: 0.566047\n",
      "epoch 148; iter: 0; batch classifier loss: 0.401574; batch adversarial loss: 0.540553\n",
      "epoch 149; iter: 0; batch classifier loss: 0.360670; batch adversarial loss: 0.507425\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421274; batch adversarial loss: 0.571070\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387313; batch adversarial loss: 0.505961\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346578; batch adversarial loss: 0.620128\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363035; batch adversarial loss: 0.609326\n",
      "epoch 154; iter: 0; batch classifier loss: 0.428863; batch adversarial loss: 0.490218\n",
      "epoch 155; iter: 0; batch classifier loss: 0.399932; batch adversarial loss: 0.491037\n",
      "epoch 156; iter: 0; batch classifier loss: 0.322415; batch adversarial loss: 0.536871\n",
      "epoch 157; iter: 0; batch classifier loss: 0.299631; batch adversarial loss: 0.572394\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345189; batch adversarial loss: 0.578146\n",
      "epoch 159; iter: 0; batch classifier loss: 0.317653; batch adversarial loss: 0.530616\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401830; batch adversarial loss: 0.584940\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376044; batch adversarial loss: 0.490569\n",
      "epoch 162; iter: 0; batch classifier loss: 0.403008; batch adversarial loss: 0.618002\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341068; batch adversarial loss: 0.452192\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389341; batch adversarial loss: 0.505644\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329226; batch adversarial loss: 0.515495\n",
      "epoch 166; iter: 0; batch classifier loss: 0.295618; batch adversarial loss: 0.506148\n",
      "epoch 167; iter: 0; batch classifier loss: 0.381138; batch adversarial loss: 0.542270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.367949; batch adversarial loss: 0.498473\n",
      "epoch 169; iter: 0; batch classifier loss: 0.399535; batch adversarial loss: 0.629452\n",
      "epoch 170; iter: 0; batch classifier loss: 0.449573; batch adversarial loss: 0.618692\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409585; batch adversarial loss: 0.473889\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376311; batch adversarial loss: 0.516273\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375425; batch adversarial loss: 0.539861\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353451; batch adversarial loss: 0.512913\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362005; batch adversarial loss: 0.562619\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340633; batch adversarial loss: 0.572309\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378447; batch adversarial loss: 0.597933\n",
      "epoch 178; iter: 0; batch classifier loss: 0.237112; batch adversarial loss: 0.536113\n",
      "epoch 179; iter: 0; batch classifier loss: 0.274356; batch adversarial loss: 0.555885\n",
      "epoch 180; iter: 0; batch classifier loss: 0.308643; batch adversarial loss: 0.527389\n",
      "epoch 181; iter: 0; batch classifier loss: 0.456560; batch adversarial loss: 0.593779\n",
      "epoch 182; iter: 0; batch classifier loss: 0.413665; batch adversarial loss: 0.525307\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353806; batch adversarial loss: 0.539141\n",
      "epoch 184; iter: 0; batch classifier loss: 0.323364; batch adversarial loss: 0.533217\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336394; batch adversarial loss: 0.541576\n",
      "epoch 186; iter: 0; batch classifier loss: 0.410950; batch adversarial loss: 0.526618\n",
      "epoch 187; iter: 0; batch classifier loss: 0.394976; batch adversarial loss: 0.623350\n",
      "epoch 188; iter: 0; batch classifier loss: 0.466403; batch adversarial loss: 0.563187\n",
      "epoch 189; iter: 0; batch classifier loss: 0.399519; batch adversarial loss: 0.512024\n",
      "epoch 190; iter: 0; batch classifier loss: 0.337489; batch adversarial loss: 0.598173\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355549; batch adversarial loss: 0.505611\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330977; batch adversarial loss: 0.478155\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347836; batch adversarial loss: 0.553487\n",
      "epoch 194; iter: 0; batch classifier loss: 0.279458; batch adversarial loss: 0.541195\n",
      "epoch 195; iter: 0; batch classifier loss: 0.512855; batch adversarial loss: 0.530116\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306942; batch adversarial loss: 0.570965\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377749; batch adversarial loss: 0.616916\n",
      "epoch 198; iter: 0; batch classifier loss: 0.451554; batch adversarial loss: 0.630338\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359541; batch adversarial loss: 0.533869\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694175; batch adversarial loss: 0.650955\n",
      "epoch 1; iter: 0; batch classifier loss: 0.663555; batch adversarial loss: 0.650867\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589253; batch adversarial loss: 0.625854\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614015; batch adversarial loss: 0.599159\n",
      "epoch 4; iter: 0; batch classifier loss: 0.472404; batch adversarial loss: 0.625844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601053; batch adversarial loss: 0.583772\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543531; batch adversarial loss: 0.563064\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544938; batch adversarial loss: 0.555444\n",
      "epoch 8; iter: 0; batch classifier loss: 0.599309; batch adversarial loss: 0.558805\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513632; batch adversarial loss: 0.570857\n",
      "epoch 10; iter: 0; batch classifier loss: 0.598081; batch adversarial loss: 0.572306\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538414; batch adversarial loss: 0.592637\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599945; batch adversarial loss: 0.589116\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548223; batch adversarial loss: 0.622590\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518975; batch adversarial loss: 0.602701\n",
      "epoch 15; iter: 0; batch classifier loss: 0.651003; batch adversarial loss: 0.601007\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523072; batch adversarial loss: 0.568260\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492067; batch adversarial loss: 0.532692\n",
      "epoch 18; iter: 0; batch classifier loss: 0.586545; batch adversarial loss: 0.536448\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537526; batch adversarial loss: 0.539050\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518579; batch adversarial loss: 0.536139\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496405; batch adversarial loss: 0.520574\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453077; batch adversarial loss: 0.610920\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452938; batch adversarial loss: 0.499690\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507074; batch adversarial loss: 0.506516\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487642; batch adversarial loss: 0.503006\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466367; batch adversarial loss: 0.554520\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448701; batch adversarial loss: 0.526782\n",
      "epoch 28; iter: 0; batch classifier loss: 0.430692; batch adversarial loss: 0.475096\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435874; batch adversarial loss: 0.535753\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470114; batch adversarial loss: 0.608983\n",
      "epoch 31; iter: 0; batch classifier loss: 0.539358; batch adversarial loss: 0.589203\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488449; batch adversarial loss: 0.589316\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426863; batch adversarial loss: 0.484378\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457090; batch adversarial loss: 0.541482\n",
      "epoch 35; iter: 0; batch classifier loss: 0.418924; batch adversarial loss: 0.533562\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405199; batch adversarial loss: 0.568048\n",
      "epoch 37; iter: 0; batch classifier loss: 0.377378; batch adversarial loss: 0.591463\n",
      "epoch 38; iter: 0; batch classifier loss: 0.515902; batch adversarial loss: 0.579175\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458359; batch adversarial loss: 0.536527\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481222; batch adversarial loss: 0.485049\n",
      "epoch 41; iter: 0; batch classifier loss: 0.405774; batch adversarial loss: 0.518141\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418472; batch adversarial loss: 0.545992\n",
      "epoch 43; iter: 0; batch classifier loss: 0.452806; batch adversarial loss: 0.602447\n",
      "epoch 44; iter: 0; batch classifier loss: 0.510542; batch adversarial loss: 0.571599\n",
      "epoch 45; iter: 0; batch classifier loss: 0.406094; batch adversarial loss: 0.554211\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405025; batch adversarial loss: 0.516697\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408015; batch adversarial loss: 0.582034\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454041; batch adversarial loss: 0.526202\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390903; batch adversarial loss: 0.488601\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458129; batch adversarial loss: 0.580786\n",
      "epoch 51; iter: 0; batch classifier loss: 0.459506; batch adversarial loss: 0.666920\n",
      "epoch 52; iter: 0; batch classifier loss: 0.483670; batch adversarial loss: 0.639570\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423601; batch adversarial loss: 0.543950\n",
      "epoch 54; iter: 0; batch classifier loss: 0.490863; batch adversarial loss: 0.506959\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378095; batch adversarial loss: 0.517623\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428168; batch adversarial loss: 0.517081\n",
      "epoch 57; iter: 0; batch classifier loss: 0.353716; batch adversarial loss: 0.509094\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413562; batch adversarial loss: 0.572639\n",
      "epoch 59; iter: 0; batch classifier loss: 0.448320; batch adversarial loss: 0.516784\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403415; batch adversarial loss: 0.469619\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445387; batch adversarial loss: 0.516542\n",
      "epoch 62; iter: 0; batch classifier loss: 0.359445; batch adversarial loss: 0.563140\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402599; batch adversarial loss: 0.533694\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411415; batch adversarial loss: 0.516133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.393332; batch adversarial loss: 0.563781\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432161; batch adversarial loss: 0.562898\n",
      "epoch 67; iter: 0; batch classifier loss: 0.357095; batch adversarial loss: 0.599483\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383846; batch adversarial loss: 0.553120\n",
      "epoch 69; iter: 0; batch classifier loss: 0.399267; batch adversarial loss: 0.515646\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403795; batch adversarial loss: 0.526219\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378611; batch adversarial loss: 0.564368\n",
      "epoch 72; iter: 0; batch classifier loss: 0.389617; batch adversarial loss: 0.506795\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382952; batch adversarial loss: 0.496346\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387440; batch adversarial loss: 0.524284\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378229; batch adversarial loss: 0.564102\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381967; batch adversarial loss: 0.574473\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376461; batch adversarial loss: 0.534906\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379887; batch adversarial loss: 0.544813\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413086; batch adversarial loss: 0.572521\n",
      "epoch 80; iter: 0; batch classifier loss: 0.343495; batch adversarial loss: 0.563094\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423506; batch adversarial loss: 0.431641\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368277; batch adversarial loss: 0.535352\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378585; batch adversarial loss: 0.497466\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412747; batch adversarial loss: 0.590986\n",
      "epoch 85; iter: 0; batch classifier loss: 0.374079; batch adversarial loss: 0.498343\n",
      "epoch 86; iter: 0; batch classifier loss: 0.514658; batch adversarial loss: 0.534856\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392649; batch adversarial loss: 0.460349\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411364; batch adversarial loss: 0.469580\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429639; batch adversarial loss: 0.535184\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415416; batch adversarial loss: 0.554092\n",
      "epoch 91; iter: 0; batch classifier loss: 0.435158; batch adversarial loss: 0.507093\n",
      "epoch 92; iter: 0; batch classifier loss: 0.344923; batch adversarial loss: 0.610369\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392534; batch adversarial loss: 0.544470\n",
      "epoch 94; iter: 0; batch classifier loss: 0.417130; batch adversarial loss: 0.601552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.353834; batch adversarial loss: 0.544721\n",
      "epoch 96; iter: 0; batch classifier loss: 0.365200; batch adversarial loss: 0.620110\n",
      "epoch 97; iter: 0; batch classifier loss: 0.512427; batch adversarial loss: 0.534800\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439252; batch adversarial loss: 0.591484\n",
      "epoch 99; iter: 0; batch classifier loss: 0.374703; batch adversarial loss: 0.516438\n",
      "epoch 100; iter: 0; batch classifier loss: 0.337718; batch adversarial loss: 0.564114\n",
      "epoch 101; iter: 0; batch classifier loss: 0.333892; batch adversarial loss: 0.545027\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382625; batch adversarial loss: 0.582314\n",
      "epoch 103; iter: 0; batch classifier loss: 0.456475; batch adversarial loss: 0.516132\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362069; batch adversarial loss: 0.601306\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371112; batch adversarial loss: 0.450205\n",
      "epoch 106; iter: 0; batch classifier loss: 0.399488; batch adversarial loss: 0.554330\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368113; batch adversarial loss: 0.497286\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384327; batch adversarial loss: 0.525256\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402408; batch adversarial loss: 0.525888\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385393; batch adversarial loss: 0.525394\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374211; batch adversarial loss: 0.516395\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349799; batch adversarial loss: 0.591012\n",
      "epoch 113; iter: 0; batch classifier loss: 0.397086; batch adversarial loss: 0.535782\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362750; batch adversarial loss: 0.553833\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412583; batch adversarial loss: 0.534922\n",
      "epoch 116; iter: 0; batch classifier loss: 0.352391; batch adversarial loss: 0.582037\n",
      "epoch 117; iter: 0; batch classifier loss: 0.425035; batch adversarial loss: 0.506952\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357838; batch adversarial loss: 0.506723\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348999; batch adversarial loss: 0.554388\n",
      "epoch 120; iter: 0; batch classifier loss: 0.309656; batch adversarial loss: 0.554260\n",
      "epoch 121; iter: 0; batch classifier loss: 0.447891; batch adversarial loss: 0.450462\n",
      "epoch 122; iter: 0; batch classifier loss: 0.433498; batch adversarial loss: 0.535722\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355640; batch adversarial loss: 0.544478\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367187; batch adversarial loss: 0.506958\n",
      "epoch 125; iter: 0; batch classifier loss: 0.303933; batch adversarial loss: 0.459809\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367849; batch adversarial loss: 0.506525\n",
      "epoch 127; iter: 0; batch classifier loss: 0.295294; batch adversarial loss: 0.506940\n",
      "epoch 128; iter: 0; batch classifier loss: 0.434649; batch adversarial loss: 0.573067\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361858; batch adversarial loss: 0.573318\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360826; batch adversarial loss: 0.516401\n",
      "epoch 131; iter: 0; batch classifier loss: 0.346487; batch adversarial loss: 0.506870\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370159; batch adversarial loss: 0.526036\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408755; batch adversarial loss: 0.638940\n",
      "epoch 134; iter: 0; batch classifier loss: 0.407582; batch adversarial loss: 0.516334\n",
      "epoch 135; iter: 0; batch classifier loss: 0.428538; batch adversarial loss: 0.535053\n",
      "epoch 136; iter: 0; batch classifier loss: 0.405340; batch adversarial loss: 0.544702\n",
      "epoch 137; iter: 0; batch classifier loss: 0.323553; batch adversarial loss: 0.478717\n",
      "epoch 138; iter: 0; batch classifier loss: 0.396773; batch adversarial loss: 0.535972\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402872; batch adversarial loss: 0.506553\n",
      "epoch 140; iter: 0; batch classifier loss: 0.442776; batch adversarial loss: 0.610152\n",
      "epoch 141; iter: 0; batch classifier loss: 0.319878; batch adversarial loss: 0.430641\n",
      "epoch 142; iter: 0; batch classifier loss: 0.436369; batch adversarial loss: 0.534736\n",
      "epoch 143; iter: 0; batch classifier loss: 0.344136; batch adversarial loss: 0.573375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351018; batch adversarial loss: 0.610677\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332843; batch adversarial loss: 0.563317\n",
      "epoch 146; iter: 0; batch classifier loss: 0.392086; batch adversarial loss: 0.572506\n",
      "epoch 147; iter: 0; batch classifier loss: 0.416306; batch adversarial loss: 0.563132\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375516; batch adversarial loss: 0.516047\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402388; batch adversarial loss: 0.526017\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341706; batch adversarial loss: 0.563727\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327525; batch adversarial loss: 0.554211\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355088; batch adversarial loss: 0.544460\n",
      "epoch 153; iter: 0; batch classifier loss: 0.307888; batch adversarial loss: 0.563255\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346850; batch adversarial loss: 0.582012\n",
      "epoch 155; iter: 0; batch classifier loss: 0.305823; batch adversarial loss: 0.526328\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395419; batch adversarial loss: 0.562518\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375701; batch adversarial loss: 0.506462\n",
      "epoch 158; iter: 0; batch classifier loss: 0.328222; batch adversarial loss: 0.572723\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329549; batch adversarial loss: 0.553323\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382687; batch adversarial loss: 0.449756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.399671; batch adversarial loss: 0.516285\n",
      "epoch 162; iter: 0; batch classifier loss: 0.428814; batch adversarial loss: 0.591410\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346769; batch adversarial loss: 0.554256\n",
      "epoch 164; iter: 0; batch classifier loss: 0.424985; batch adversarial loss: 0.497012\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319757; batch adversarial loss: 0.460007\n",
      "epoch 166; iter: 0; batch classifier loss: 0.458010; batch adversarial loss: 0.544524\n",
      "epoch 167; iter: 0; batch classifier loss: 0.339541; batch adversarial loss: 0.553868\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398971; batch adversarial loss: 0.554344\n",
      "epoch 169; iter: 0; batch classifier loss: 0.304379; batch adversarial loss: 0.516121\n",
      "epoch 170; iter: 0; batch classifier loss: 0.392789; batch adversarial loss: 0.525438\n",
      "epoch 171; iter: 0; batch classifier loss: 0.325870; batch adversarial loss: 0.543926\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318151; batch adversarial loss: 0.526093\n",
      "epoch 173; iter: 0; batch classifier loss: 0.370113; batch adversarial loss: 0.449729\n",
      "epoch 174; iter: 0; batch classifier loss: 0.427681; batch adversarial loss: 0.544946\n",
      "epoch 175; iter: 0; batch classifier loss: 0.348399; batch adversarial loss: 0.609679\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381737; batch adversarial loss: 0.525875\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337521; batch adversarial loss: 0.469575\n",
      "epoch 178; iter: 0; batch classifier loss: 0.313518; batch adversarial loss: 0.516099\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367723; batch adversarial loss: 0.581842\n",
      "epoch 180; iter: 0; batch classifier loss: 0.310022; batch adversarial loss: 0.544125\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338794; batch adversarial loss: 0.515518\n",
      "epoch 182; iter: 0; batch classifier loss: 0.397473; batch adversarial loss: 0.553738\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330224; batch adversarial loss: 0.563608\n",
      "epoch 184; iter: 0; batch classifier loss: 0.405203; batch adversarial loss: 0.488189\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391406; batch adversarial loss: 0.515657\n",
      "epoch 186; iter: 0; batch classifier loss: 0.394395; batch adversarial loss: 0.486846\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326666; batch adversarial loss: 0.478383\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363900; batch adversarial loss: 0.574210\n",
      "epoch 189; iter: 0; batch classifier loss: 0.448991; batch adversarial loss: 0.544618\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368046; batch adversarial loss: 0.526262\n",
      "epoch 191; iter: 0; batch classifier loss: 0.415556; batch adversarial loss: 0.563702\n",
      "epoch 192; iter: 0; batch classifier loss: 0.354850; batch adversarial loss: 0.487631\n",
      "epoch 193; iter: 0; batch classifier loss: 0.312951; batch adversarial loss: 0.563167\n",
      "epoch 194; iter: 0; batch classifier loss: 0.373153; batch adversarial loss: 0.610301\n",
      "epoch 195; iter: 0; batch classifier loss: 0.316198; batch adversarial loss: 0.544395\n",
      "epoch 196; iter: 0; batch classifier loss: 0.303762; batch adversarial loss: 0.515545\n",
      "epoch 197; iter: 0; batch classifier loss: 0.383162; batch adversarial loss: 0.535434\n",
      "epoch 198; iter: 0; batch classifier loss: 0.421621; batch adversarial loss: 0.534834\n",
      "epoch 199; iter: 0; batch classifier loss: 0.327010; batch adversarial loss: 0.516247\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753055; batch adversarial loss: 0.832641\n",
      "epoch 1; iter: 0; batch classifier loss: 0.807396; batch adversarial loss: 0.849770\n",
      "epoch 2; iter: 0; batch classifier loss: 0.934268; batch adversarial loss: 0.781840\n",
      "epoch 3; iter: 0; batch classifier loss: 0.820364; batch adversarial loss: 0.718876\n",
      "epoch 4; iter: 0; batch classifier loss: 0.661494; batch adversarial loss: 0.660856\n",
      "epoch 5; iter: 0; batch classifier loss: 0.560736; batch adversarial loss: 0.623605\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587806; batch adversarial loss: 0.603874\n",
      "epoch 7; iter: 0; batch classifier loss: 0.551513; batch adversarial loss: 0.592469\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586874; batch adversarial loss: 0.601189\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537001; batch adversarial loss: 0.618034\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514200; batch adversarial loss: 0.574982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480020; batch adversarial loss: 0.617050\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536731; batch adversarial loss: 0.548368\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483498; batch adversarial loss: 0.590698\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512407; batch adversarial loss: 0.535578\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507750; batch adversarial loss: 0.587546\n",
      "epoch 16; iter: 0; batch classifier loss: 0.455292; batch adversarial loss: 0.610823\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463721; batch adversarial loss: 0.625208\n",
      "epoch 18; iter: 0; batch classifier loss: 0.495701; batch adversarial loss: 0.568875\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463446; batch adversarial loss: 0.534600\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465906; batch adversarial loss: 0.525892\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491272; batch adversarial loss: 0.592243\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500718; batch adversarial loss: 0.455769\n",
      "epoch 23; iter: 0; batch classifier loss: 0.496239; batch adversarial loss: 0.530132\n",
      "epoch 24; iter: 0; batch classifier loss: 0.552014; batch adversarial loss: 0.543440\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471724; batch adversarial loss: 0.518419\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499772; batch adversarial loss: 0.494796\n",
      "epoch 27; iter: 0; batch classifier loss: 0.536656; batch adversarial loss: 0.516367\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413983; batch adversarial loss: 0.494725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.423769; batch adversarial loss: 0.660536\n",
      "epoch 30; iter: 0; batch classifier loss: 0.522584; batch adversarial loss: 0.508534\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451402; batch adversarial loss: 0.598213\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517277; batch adversarial loss: 0.539923\n",
      "epoch 33; iter: 0; batch classifier loss: 0.545172; batch adversarial loss: 0.516487\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453380; batch adversarial loss: 0.544380\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453614; batch adversarial loss: 0.497995\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495462; batch adversarial loss: 0.519226\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489886; batch adversarial loss: 0.574238\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430160; batch adversarial loss: 0.628212\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455249; batch adversarial loss: 0.573986\n",
      "epoch 40; iter: 0; batch classifier loss: 0.400348; batch adversarial loss: 0.576565\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422162; batch adversarial loss: 0.604249\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378461; batch adversarial loss: 0.563341\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430666; batch adversarial loss: 0.506064\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417048; batch adversarial loss: 0.527780\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422808; batch adversarial loss: 0.565617\n",
      "epoch 46; iter: 0; batch classifier loss: 0.475510; batch adversarial loss: 0.630488\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438676; batch adversarial loss: 0.519828\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449138; batch adversarial loss: 0.525458\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424288; batch adversarial loss: 0.535418\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401928; batch adversarial loss: 0.537026\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384088; batch adversarial loss: 0.490953\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406673; batch adversarial loss: 0.466635\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431984; batch adversarial loss: 0.507885\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405286; batch adversarial loss: 0.551344\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408360; batch adversarial loss: 0.563694\n",
      "epoch 56; iter: 0; batch classifier loss: 0.464729; batch adversarial loss: 0.517064\n",
      "epoch 57; iter: 0; batch classifier loss: 0.487635; batch adversarial loss: 0.535588\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360532; batch adversarial loss: 0.563866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.455301; batch adversarial loss: 0.625540\n",
      "epoch 60; iter: 0; batch classifier loss: 0.518661; batch adversarial loss: 0.554297\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454087; batch adversarial loss: 0.543403\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438929; batch adversarial loss: 0.544110\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434791; batch adversarial loss: 0.653322\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413235; batch adversarial loss: 0.537746\n",
      "epoch 65; iter: 0; batch classifier loss: 0.387930; batch adversarial loss: 0.533977\n",
      "epoch 66; iter: 0; batch classifier loss: 0.345895; batch adversarial loss: 0.546102\n",
      "epoch 67; iter: 0; batch classifier loss: 0.345022; batch adversarial loss: 0.517831\n",
      "epoch 68; iter: 0; batch classifier loss: 0.396907; batch adversarial loss: 0.570365\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410989; batch adversarial loss: 0.552447\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411098; batch adversarial loss: 0.534681\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393167; batch adversarial loss: 0.565706\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358027; batch adversarial loss: 0.474552\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429288; batch adversarial loss: 0.535977\n",
      "epoch 74; iter: 0; batch classifier loss: 0.445051; batch adversarial loss: 0.508956\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440019; batch adversarial loss: 0.535587\n",
      "epoch 76; iter: 0; batch classifier loss: 0.472703; batch adversarial loss: 0.535393\n",
      "epoch 77; iter: 0; batch classifier loss: 0.459232; batch adversarial loss: 0.552796\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365498; batch adversarial loss: 0.535167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407147; batch adversarial loss: 0.643749\n",
      "epoch 80; iter: 0; batch classifier loss: 0.388744; batch adversarial loss: 0.625263\n",
      "epoch 81; iter: 0; batch classifier loss: 0.366573; batch adversarial loss: 0.589132\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372497; batch adversarial loss: 0.606901\n",
      "epoch 83; iter: 0; batch classifier loss: 0.459565; batch adversarial loss: 0.625330\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396520; batch adversarial loss: 0.536379\n",
      "epoch 85; iter: 0; batch classifier loss: 0.489671; batch adversarial loss: 0.526147\n",
      "epoch 86; iter: 0; batch classifier loss: 0.343627; batch adversarial loss: 0.589631\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356166; batch adversarial loss: 0.596542\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381971; batch adversarial loss: 0.527551\n",
      "epoch 89; iter: 0; batch classifier loss: 0.435375; batch adversarial loss: 0.561506\n",
      "epoch 90; iter: 0; batch classifier loss: 0.380930; batch adversarial loss: 0.491606\n",
      "epoch 91; iter: 0; batch classifier loss: 0.341187; batch adversarial loss: 0.624936\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396875; batch adversarial loss: 0.482064\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397992; batch adversarial loss: 0.543712\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401555; batch adversarial loss: 0.481695\n",
      "epoch 95; iter: 0; batch classifier loss: 0.451496; batch adversarial loss: 0.562034\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396173; batch adversarial loss: 0.508030\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386583; batch adversarial loss: 0.626600\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387882; batch adversarial loss: 0.637864\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412412; batch adversarial loss: 0.588574\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382350; batch adversarial loss: 0.607372\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403133; batch adversarial loss: 0.553813\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401519; batch adversarial loss: 0.580114\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398159; batch adversarial loss: 0.527026\n",
      "epoch 104; iter: 0; batch classifier loss: 0.336565; batch adversarial loss: 0.517309\n",
      "epoch 105; iter: 0; batch classifier loss: 0.306392; batch adversarial loss: 0.544886\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330212; batch adversarial loss: 0.526376\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362303; batch adversarial loss: 0.546706\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363413; batch adversarial loss: 0.544669\n",
      "epoch 109; iter: 0; batch classifier loss: 0.324001; batch adversarial loss: 0.535340\n",
      "epoch 110; iter: 0; batch classifier loss: 0.376936; batch adversarial loss: 0.535970\n",
      "epoch 111; iter: 0; batch classifier loss: 0.340540; batch adversarial loss: 0.554092\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360073; batch adversarial loss: 0.571210\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396780; batch adversarial loss: 0.543110\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346120; batch adversarial loss: 0.562483\n",
      "epoch 115; iter: 0; batch classifier loss: 0.375584; batch adversarial loss: 0.516550\n",
      "epoch 116; iter: 0; batch classifier loss: 0.397458; batch adversarial loss: 0.570646\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385252; batch adversarial loss: 0.563072\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375628; batch adversarial loss: 0.625548\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371130; batch adversarial loss: 0.562219\n",
      "epoch 120; iter: 0; batch classifier loss: 0.365857; batch adversarial loss: 0.545013\n",
      "epoch 121; iter: 0; batch classifier loss: 0.300429; batch adversarial loss: 0.429309\n",
      "epoch 122; iter: 0; batch classifier loss: 0.313460; batch adversarial loss: 0.527651\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396516; batch adversarial loss: 0.544703\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373478; batch adversarial loss: 0.544412\n",
      "epoch 125; iter: 0; batch classifier loss: 0.330687; batch adversarial loss: 0.563602\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334421; batch adversarial loss: 0.671063\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344694; batch adversarial loss: 0.581162\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404448; batch adversarial loss: 0.571019\n",
      "epoch 129; iter: 0; batch classifier loss: 0.459786; batch adversarial loss: 0.598702\n",
      "epoch 130; iter: 0; batch classifier loss: 0.443731; batch adversarial loss: 0.517792\n",
      "epoch 131; iter: 0; batch classifier loss: 0.323940; batch adversarial loss: 0.491150\n",
      "epoch 132; iter: 0; batch classifier loss: 0.425964; batch adversarial loss: 0.518259\n",
      "epoch 133; iter: 0; batch classifier loss: 0.381565; batch adversarial loss: 0.553179\n",
      "epoch 134; iter: 0; batch classifier loss: 0.370375; batch adversarial loss: 0.526581\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360950; batch adversarial loss: 0.615488\n",
      "epoch 136; iter: 0; batch classifier loss: 0.362482; batch adversarial loss: 0.562943\n",
      "epoch 137; iter: 0; batch classifier loss: 0.277099; batch adversarial loss: 0.580848\n",
      "epoch 138; iter: 0; batch classifier loss: 0.330322; batch adversarial loss: 0.562495\n",
      "epoch 139; iter: 0; batch classifier loss: 0.375954; batch adversarial loss: 0.589343\n",
      "epoch 140; iter: 0; batch classifier loss: 0.266160; batch adversarial loss: 0.562336\n",
      "epoch 141; iter: 0; batch classifier loss: 0.293628; batch adversarial loss: 0.561259\n",
      "epoch 142; iter: 0; batch classifier loss: 0.394606; batch adversarial loss: 0.553616\n",
      "epoch 143; iter: 0; batch classifier loss: 0.341676; batch adversarial loss: 0.553534\n",
      "epoch 144; iter: 0; batch classifier loss: 0.375919; batch adversarial loss: 0.588710\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403909; batch adversarial loss: 0.536060\n",
      "epoch 146; iter: 0; batch classifier loss: 0.393553; batch adversarial loss: 0.573010\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336306; batch adversarial loss: 0.607850\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351304; batch adversarial loss: 0.535663\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410536; batch adversarial loss: 0.598277\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384502; batch adversarial loss: 0.582018\n",
      "epoch 151; iter: 0; batch classifier loss: 0.410520; batch adversarial loss: 0.474100\n",
      "epoch 152; iter: 0; batch classifier loss: 0.309238; batch adversarial loss: 0.535703\n",
      "epoch 153; iter: 0; batch classifier loss: 0.307362; batch adversarial loss: 0.615431\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337151; batch adversarial loss: 0.524467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.278443; batch adversarial loss: 0.599275\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312793; batch adversarial loss: 0.544294\n",
      "epoch 157; iter: 0; batch classifier loss: 0.418782; batch adversarial loss: 0.606916\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364210; batch adversarial loss: 0.607683\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341266; batch adversarial loss: 0.562917\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344216; batch adversarial loss: 0.508863\n",
      "epoch 161; iter: 0; batch classifier loss: 0.309674; batch adversarial loss: 0.597560\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410399; batch adversarial loss: 0.636166\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326836; batch adversarial loss: 0.553394\n",
      "epoch 164; iter: 0; batch classifier loss: 0.311140; batch adversarial loss: 0.536895\n",
      "epoch 165; iter: 0; batch classifier loss: 0.324039; batch adversarial loss: 0.536196\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354843; batch adversarial loss: 0.599007\n",
      "epoch 167; iter: 0; batch classifier loss: 0.300599; batch adversarial loss: 0.472357\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390467; batch adversarial loss: 0.608057\n",
      "epoch 169; iter: 0; batch classifier loss: 0.286831; batch adversarial loss: 0.552313\n",
      "epoch 170; iter: 0; batch classifier loss: 0.283278; batch adversarial loss: 0.571798\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327066; batch adversarial loss: 0.507547\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359624; batch adversarial loss: 0.653142\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301822; batch adversarial loss: 0.490159\n",
      "epoch 174; iter: 0; batch classifier loss: 0.401416; batch adversarial loss: 0.572083\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342527; batch adversarial loss: 0.598765\n",
      "epoch 176; iter: 0; batch classifier loss: 0.309263; batch adversarial loss: 0.581443\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358661; batch adversarial loss: 0.500560\n",
      "epoch 178; iter: 0; batch classifier loss: 0.324354; batch adversarial loss: 0.535514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.410171; batch adversarial loss: 0.508071\n",
      "epoch 180; iter: 0; batch classifier loss: 0.407271; batch adversarial loss: 0.489823\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331468; batch adversarial loss: 0.579641\n",
      "epoch 182; iter: 0; batch classifier loss: 0.301052; batch adversarial loss: 0.590473\n",
      "epoch 183; iter: 0; batch classifier loss: 0.307926; batch adversarial loss: 0.572299\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317089; batch adversarial loss: 0.544502\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365247; batch adversarial loss: 0.626124\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334629; batch adversarial loss: 0.545785\n",
      "epoch 187; iter: 0; batch classifier loss: 0.273311; batch adversarial loss: 0.481750\n",
      "epoch 188; iter: 0; batch classifier loss: 0.312239; batch adversarial loss: 0.590686\n",
      "epoch 189; iter: 0; batch classifier loss: 0.337995; batch adversarial loss: 0.491841\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323943; batch adversarial loss: 0.535455\n",
      "epoch 191; iter: 0; batch classifier loss: 0.349202; batch adversarial loss: 0.597283\n",
      "epoch 192; iter: 0; batch classifier loss: 0.235231; batch adversarial loss: 0.597882\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364521; batch adversarial loss: 0.517097\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342464; batch adversarial loss: 0.562307\n",
      "epoch 195; iter: 0; batch classifier loss: 0.264313; batch adversarial loss: 0.552414\n",
      "epoch 196; iter: 0; batch classifier loss: 0.391330; batch adversarial loss: 0.588547\n",
      "epoch 197; iter: 0; batch classifier loss: 0.279554; batch adversarial loss: 0.533253\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358457; batch adversarial loss: 0.506756\n",
      "epoch 199; iter: 0; batch classifier loss: 0.368577; batch adversarial loss: 0.428026\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736457; batch adversarial loss: 0.886654\n",
      "epoch 1; iter: 0; batch classifier loss: 0.794073; batch adversarial loss: 1.003893\n",
      "epoch 2; iter: 0; batch classifier loss: 0.802352; batch adversarial loss: 0.941571\n",
      "epoch 3; iter: 0; batch classifier loss: 0.918681; batch adversarial loss: 0.878234\n",
      "epoch 4; iter: 0; batch classifier loss: 0.864401; batch adversarial loss: 0.789694\n",
      "epoch 5; iter: 0; batch classifier loss: 0.750605; batch adversarial loss: 0.734153\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585248; batch adversarial loss: 0.688059\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562253; batch adversarial loss: 0.640331\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583566; batch adversarial loss: 0.618033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514302; batch adversarial loss: 0.592091\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539546; batch adversarial loss: 0.595021\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526533; batch adversarial loss: 0.591560\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528860; batch adversarial loss: 0.554669\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537668; batch adversarial loss: 0.606906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533638; batch adversarial loss: 0.567158\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552728; batch adversarial loss: 0.616133\n",
      "epoch 16; iter: 0; batch classifier loss: 0.593851; batch adversarial loss: 0.575330\n",
      "epoch 17; iter: 0; batch classifier loss: 0.567376; batch adversarial loss: 0.567959\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514720; batch adversarial loss: 0.587274\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505318; batch adversarial loss: 0.592753\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538490; batch adversarial loss: 0.532283\n",
      "epoch 21; iter: 0; batch classifier loss: 0.440537; batch adversarial loss: 0.596340\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493506; batch adversarial loss: 0.514707\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528319; batch adversarial loss: 0.599131\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506119; batch adversarial loss: 0.573125\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480871; batch adversarial loss: 0.530032\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510491; batch adversarial loss: 0.623061\n",
      "epoch 27; iter: 0; batch classifier loss: 0.516976; batch adversarial loss: 0.527952\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473744; batch adversarial loss: 0.532066\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506874; batch adversarial loss: 0.480735\n",
      "epoch 30; iter: 0; batch classifier loss: 0.401868; batch adversarial loss: 0.579956\n",
      "epoch 31; iter: 0; batch classifier loss: 0.518144; batch adversarial loss: 0.511804\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513418; batch adversarial loss: 0.537878\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471064; batch adversarial loss: 0.574765\n",
      "epoch 34; iter: 0; batch classifier loss: 0.428663; batch adversarial loss: 0.497754\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479326; batch adversarial loss: 0.538707\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463010; batch adversarial loss: 0.528764\n",
      "epoch 37; iter: 0; batch classifier loss: 0.522179; batch adversarial loss: 0.563514\n",
      "epoch 38; iter: 0; batch classifier loss: 0.411895; batch adversarial loss: 0.606923\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466093; batch adversarial loss: 0.547302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444301; batch adversarial loss: 0.502923\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398375; batch adversarial loss: 0.595980\n",
      "epoch 42; iter: 0; batch classifier loss: 0.478557; batch adversarial loss: 0.605097\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420821; batch adversarial loss: 0.510645\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466813; batch adversarial loss: 0.502297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.486913; batch adversarial loss: 0.474376\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447839; batch adversarial loss: 0.527273\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466414; batch adversarial loss: 0.536151\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439829; batch adversarial loss: 0.545301\n",
      "epoch 49; iter: 0; batch classifier loss: 0.530919; batch adversarial loss: 0.587149\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411816; batch adversarial loss: 0.605948\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490647; batch adversarial loss: 0.569738\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466330; batch adversarial loss: 0.563385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.511316; batch adversarial loss: 0.562420\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402120; batch adversarial loss: 0.545583\n",
      "epoch 55; iter: 0; batch classifier loss: 0.477131; batch adversarial loss: 0.519285\n",
      "epoch 56; iter: 0; batch classifier loss: 0.402402; batch adversarial loss: 0.535977\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408770; batch adversarial loss: 0.481092\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402103; batch adversarial loss: 0.536642\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468526; batch adversarial loss: 0.561878\n",
      "epoch 60; iter: 0; batch classifier loss: 0.417264; batch adversarial loss: 0.615322\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414664; batch adversarial loss: 0.499530\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426966; batch adversarial loss: 0.553598\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446363; batch adversarial loss: 0.589134\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449683; batch adversarial loss: 0.562684\n",
      "epoch 65; iter: 0; batch classifier loss: 0.474426; batch adversarial loss: 0.598000\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439281; batch adversarial loss: 0.562896\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412147; batch adversarial loss: 0.625188\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455409; batch adversarial loss: 0.590236\n",
      "epoch 69; iter: 0; batch classifier loss: 0.488739; batch adversarial loss: 0.517731\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476544; batch adversarial loss: 0.509320\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370658; batch adversarial loss: 0.526655\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365325; batch adversarial loss: 0.509057\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373897; batch adversarial loss: 0.562194\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452480; batch adversarial loss: 0.625009\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440916; batch adversarial loss: 0.517561\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413402; batch adversarial loss: 0.562773\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400362; batch adversarial loss: 0.490886\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379165; batch adversarial loss: 0.553389\n",
      "epoch 79; iter: 0; batch classifier loss: 0.504631; batch adversarial loss: 0.553649\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371067; batch adversarial loss: 0.535519\n",
      "epoch 81; iter: 0; batch classifier loss: 0.340687; batch adversarial loss: 0.562795\n",
      "epoch 82; iter: 0; batch classifier loss: 0.439080; batch adversarial loss: 0.526767\n",
      "epoch 83; iter: 0; batch classifier loss: 0.338813; batch adversarial loss: 0.624955\n",
      "epoch 84; iter: 0; batch classifier loss: 0.427988; batch adversarial loss: 0.580660\n",
      "epoch 85; iter: 0; batch classifier loss: 0.453122; batch adversarial loss: 0.571636\n",
      "epoch 86; iter: 0; batch classifier loss: 0.429504; batch adversarial loss: 0.526858\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365864; batch adversarial loss: 0.544135\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425235; batch adversarial loss: 0.561463\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379785; batch adversarial loss: 0.524590\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386338; batch adversarial loss: 0.579844\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374165; batch adversarial loss: 0.570607\n",
      "epoch 92; iter: 0; batch classifier loss: 0.363409; batch adversarial loss: 0.519032\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399470; batch adversarial loss: 0.617577\n",
      "epoch 94; iter: 0; batch classifier loss: 0.517598; batch adversarial loss: 0.518516\n",
      "epoch 95; iter: 0; batch classifier loss: 0.405039; batch adversarial loss: 0.535812\n",
      "epoch 96; iter: 0; batch classifier loss: 0.351187; batch adversarial loss: 0.554475\n",
      "epoch 97; iter: 0; batch classifier loss: 0.327078; batch adversarial loss: 0.535763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.350607; batch adversarial loss: 0.544991\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348806; batch adversarial loss: 0.633539\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394469; batch adversarial loss: 0.571370\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394685; batch adversarial loss: 0.553121\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415027; batch adversarial loss: 0.527830\n",
      "epoch 103; iter: 0; batch classifier loss: 0.415735; batch adversarial loss: 0.571114\n",
      "epoch 104; iter: 0; batch classifier loss: 0.318454; batch adversarial loss: 0.518253\n",
      "epoch 105; iter: 0; batch classifier loss: 0.445016; batch adversarial loss: 0.571531\n",
      "epoch 106; iter: 0; batch classifier loss: 0.420740; batch adversarial loss: 0.545066\n",
      "epoch 107; iter: 0; batch classifier loss: 0.286952; batch adversarial loss: 0.580337\n",
      "epoch 108; iter: 0; batch classifier loss: 0.457327; batch adversarial loss: 0.571316\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346130; batch adversarial loss: 0.544456\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357577; batch adversarial loss: 0.535772\n",
      "epoch 111; iter: 0; batch classifier loss: 0.318976; batch adversarial loss: 0.517645\n",
      "epoch 112; iter: 0; batch classifier loss: 0.427224; batch adversarial loss: 0.535750\n",
      "epoch 113; iter: 0; batch classifier loss: 0.409088; batch adversarial loss: 0.580588\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359975; batch adversarial loss: 0.589868\n",
      "epoch 115; iter: 0; batch classifier loss: 0.321706; batch adversarial loss: 0.553436\n",
      "epoch 116; iter: 0; batch classifier loss: 0.304100; batch adversarial loss: 0.589301\n",
      "epoch 117; iter: 0; batch classifier loss: 0.341729; batch adversarial loss: 0.553719\n",
      "epoch 118; iter: 0; batch classifier loss: 0.324122; batch adversarial loss: 0.607248\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394588; batch adversarial loss: 0.553597\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401516; batch adversarial loss: 0.553634\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394863; batch adversarial loss: 0.535390\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394639; batch adversarial loss: 0.624536\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395221; batch adversarial loss: 0.526689\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372754; batch adversarial loss: 0.535614\n",
      "epoch 125; iter: 0; batch classifier loss: 0.314582; batch adversarial loss: 0.526853\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359813; batch adversarial loss: 0.517803\n",
      "epoch 127; iter: 0; batch classifier loss: 0.400389; batch adversarial loss: 0.473019\n",
      "epoch 128; iter: 0; batch classifier loss: 0.414053; batch adversarial loss: 0.500269\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379239; batch adversarial loss: 0.535675\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365859; batch adversarial loss: 0.571278\n",
      "epoch 131; iter: 0; batch classifier loss: 0.304950; batch adversarial loss: 0.526914\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317810; batch adversarial loss: 0.473185\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399339; batch adversarial loss: 0.571360\n",
      "epoch 134; iter: 0; batch classifier loss: 0.449954; batch adversarial loss: 0.526616\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395976; batch adversarial loss: 0.500126\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328418; batch adversarial loss: 0.535594\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379087; batch adversarial loss: 0.508763\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415522; batch adversarial loss: 0.553732\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367333; batch adversarial loss: 0.544710\n",
      "epoch 140; iter: 0; batch classifier loss: 0.443368; batch adversarial loss: 0.633335\n",
      "epoch 141; iter: 0; batch classifier loss: 0.354744; batch adversarial loss: 0.597590\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415865; batch adversarial loss: 0.544329\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378376; batch adversarial loss: 0.553799\n",
      "epoch 144; iter: 0; batch classifier loss: 0.353011; batch adversarial loss: 0.588612\n",
      "epoch 145; iter: 0; batch classifier loss: 0.438408; batch adversarial loss: 0.553399\n",
      "epoch 146; iter: 0; batch classifier loss: 0.296333; batch adversarial loss: 0.517967\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387696; batch adversarial loss: 0.481541\n",
      "epoch 148; iter: 0; batch classifier loss: 0.473081; batch adversarial loss: 0.571279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.379969; batch adversarial loss: 0.598555\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372216; batch adversarial loss: 0.598589\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341755; batch adversarial loss: 0.481541\n",
      "epoch 152; iter: 0; batch classifier loss: 0.401280; batch adversarial loss: 0.553794\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370259; batch adversarial loss: 0.553932\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359401; batch adversarial loss: 0.554550\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365840; batch adversarial loss: 0.543738\n",
      "epoch 156; iter: 0; batch classifier loss: 0.324339; batch adversarial loss: 0.481534\n",
      "epoch 157; iter: 0; batch classifier loss: 0.299916; batch adversarial loss: 0.580135\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368552; batch adversarial loss: 0.572322\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341278; batch adversarial loss: 0.616108\n",
      "epoch 160; iter: 0; batch classifier loss: 0.354713; batch adversarial loss: 0.571214\n",
      "epoch 161; iter: 0; batch classifier loss: 0.432598; batch adversarial loss: 0.652413\n",
      "epoch 162; iter: 0; batch classifier loss: 0.374687; batch adversarial loss: 0.571500\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326984; batch adversarial loss: 0.598294\n",
      "epoch 164; iter: 0; batch classifier loss: 0.391476; batch adversarial loss: 0.508382\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380716; batch adversarial loss: 0.562939\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370477; batch adversarial loss: 0.482999\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383973; batch adversarial loss: 0.589986\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322802; batch adversarial loss: 0.471257\n",
      "epoch 169; iter: 0; batch classifier loss: 0.423971; batch adversarial loss: 0.536354\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395938; batch adversarial loss: 0.552807\n",
      "epoch 171; iter: 0; batch classifier loss: 0.426286; batch adversarial loss: 0.535618\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373299; batch adversarial loss: 0.544923\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360395; batch adversarial loss: 0.437337\n",
      "epoch 174; iter: 0; batch classifier loss: 0.397665; batch adversarial loss: 0.571435\n",
      "epoch 175; iter: 0; batch classifier loss: 0.432439; batch adversarial loss: 0.516238\n",
      "epoch 176; iter: 0; batch classifier loss: 0.355237; batch adversarial loss: 0.632844\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376552; batch adversarial loss: 0.509432\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350949; batch adversarial loss: 0.526338\n",
      "epoch 179; iter: 0; batch classifier loss: 0.296480; batch adversarial loss: 0.553117\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362849; batch adversarial loss: 0.526904\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361392; batch adversarial loss: 0.499880\n",
      "epoch 182; iter: 0; batch classifier loss: 0.311876; batch adversarial loss: 0.508749\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345924; batch adversarial loss: 0.526464\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379096; batch adversarial loss: 0.597781\n",
      "epoch 185; iter: 0; batch classifier loss: 0.380235; batch adversarial loss: 0.625334\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348479; batch adversarial loss: 0.615543\n",
      "epoch 187; iter: 0; batch classifier loss: 0.407905; batch adversarial loss: 0.517708\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391678; batch adversarial loss: 0.652641\n",
      "epoch 189; iter: 0; batch classifier loss: 0.413569; batch adversarial loss: 0.606197\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331019; batch adversarial loss: 0.589321\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386905; batch adversarial loss: 0.599060\n",
      "epoch 192; iter: 0; batch classifier loss: 0.360458; batch adversarial loss: 0.490788\n",
      "epoch 193; iter: 0; batch classifier loss: 0.357342; batch adversarial loss: 0.554053\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368674; batch adversarial loss: 0.534564\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349720; batch adversarial loss: 0.534945\n",
      "epoch 196; iter: 0; batch classifier loss: 0.361905; batch adversarial loss: 0.473281\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387204; batch adversarial loss: 0.526165\n",
      "epoch 198; iter: 0; batch classifier loss: 0.385349; batch adversarial loss: 0.571577\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352901; batch adversarial loss: 0.617341\n",
      "epoch 0; iter: 0; batch classifier loss: 0.646628; batch adversarial loss: 0.686840\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546677; batch adversarial loss: 0.673305\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590955; batch adversarial loss: 0.621191\n",
      "epoch 3; iter: 0; batch classifier loss: 0.509355; batch adversarial loss: 0.614807\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583398; batch adversarial loss: 0.600784\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546888; batch adversarial loss: 0.583620\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562101; batch adversarial loss: 0.591679\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603330; batch adversarial loss: 0.604098\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536687; batch adversarial loss: 0.621470\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612637; batch adversarial loss: 0.643940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522807; batch adversarial loss: 0.538677\n",
      "epoch 11; iter: 0; batch classifier loss: 0.478787; batch adversarial loss: 0.573856\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457066; batch adversarial loss: 0.620729\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496224; batch adversarial loss: 0.600241\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503487; batch adversarial loss: 0.665180\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487770; batch adversarial loss: 0.577394\n",
      "epoch 16; iter: 0; batch classifier loss: 0.560293; batch adversarial loss: 0.530111\n",
      "epoch 17; iter: 0; batch classifier loss: 0.450743; batch adversarial loss: 0.566403\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476544; batch adversarial loss: 0.640092\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500454; batch adversarial loss: 0.544059\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480231; batch adversarial loss: 0.593337\n",
      "epoch 21; iter: 0; batch classifier loss: 0.529425; batch adversarial loss: 0.503497\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495387; batch adversarial loss: 0.545204\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488531; batch adversarial loss: 0.534846\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434478; batch adversarial loss: 0.610360\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515379; batch adversarial loss: 0.575407\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471349; batch adversarial loss: 0.541281\n",
      "epoch 27; iter: 0; batch classifier loss: 0.540475; batch adversarial loss: 0.625399\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416376; batch adversarial loss: 0.578225\n",
      "epoch 29; iter: 0; batch classifier loss: 0.533875; batch adversarial loss: 0.601610\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436327; batch adversarial loss: 0.635825\n",
      "epoch 31; iter: 0; batch classifier loss: 0.618021; batch adversarial loss: 0.527193\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490518; batch adversarial loss: 0.538652\n",
      "epoch 33; iter: 0; batch classifier loss: 0.566594; batch adversarial loss: 0.499228\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470066; batch adversarial loss: 0.524162\n",
      "epoch 35; iter: 0; batch classifier loss: 0.393529; batch adversarial loss: 0.499920\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459932; batch adversarial loss: 0.474645\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471113; batch adversarial loss: 0.572718\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458556; batch adversarial loss: 0.536705\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451931; batch adversarial loss: 0.525077\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425641; batch adversarial loss: 0.579281\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436228; batch adversarial loss: 0.490505\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421446; batch adversarial loss: 0.550198\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407228; batch adversarial loss: 0.624609\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477452; batch adversarial loss: 0.649746\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428968; batch adversarial loss: 0.624958\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483100; batch adversarial loss: 0.637016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.476513; batch adversarial loss: 0.523756\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412394; batch adversarial loss: 0.564601\n",
      "epoch 49; iter: 0; batch classifier loss: 0.328707; batch adversarial loss: 0.497037\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469982; batch adversarial loss: 0.606762\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435175; batch adversarial loss: 0.537708\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398637; batch adversarial loss: 0.543022\n",
      "epoch 53; iter: 0; batch classifier loss: 0.459744; batch adversarial loss: 0.597989\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433897; batch adversarial loss: 0.521327\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445607; batch adversarial loss: 0.567661\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427112; batch adversarial loss: 0.551765\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416543; batch adversarial loss: 0.528227\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414496; batch adversarial loss: 0.553969\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433257; batch adversarial loss: 0.594307\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410595; batch adversarial loss: 0.541092\n",
      "epoch 61; iter: 0; batch classifier loss: 0.394459; batch adversarial loss: 0.582638\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450730; batch adversarial loss: 0.538929\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401751; batch adversarial loss: 0.554062\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387738; batch adversarial loss: 0.547672\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436091; batch adversarial loss: 0.541945\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409591; batch adversarial loss: 0.548522\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410685; batch adversarial loss: 0.519173\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460723; batch adversarial loss: 0.552044\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407994; batch adversarial loss: 0.542213\n",
      "epoch 70; iter: 0; batch classifier loss: 0.394656; batch adversarial loss: 0.572126\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480802; batch adversarial loss: 0.517945\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455081; batch adversarial loss: 0.535392\n",
      "epoch 73; iter: 0; batch classifier loss: 0.457026; batch adversarial loss: 0.543922\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415757; batch adversarial loss: 0.598628\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389336; batch adversarial loss: 0.519735\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392910; batch adversarial loss: 0.506370\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425112; batch adversarial loss: 0.534159\n",
      "epoch 78; iter: 0; batch classifier loss: 0.425559; batch adversarial loss: 0.613280\n",
      "epoch 79; iter: 0; batch classifier loss: 0.434524; batch adversarial loss: 0.544067\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399018; batch adversarial loss: 0.599522\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392468; batch adversarial loss: 0.504944\n",
      "epoch 82; iter: 0; batch classifier loss: 0.330875; batch adversarial loss: 0.570504\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371859; batch adversarial loss: 0.536924\n",
      "epoch 84; iter: 0; batch classifier loss: 0.417860; batch adversarial loss: 0.560576\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403129; batch adversarial loss: 0.527257\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446861; batch adversarial loss: 0.460029\n",
      "epoch 87; iter: 0; batch classifier loss: 0.388988; batch adversarial loss: 0.544246\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406605; batch adversarial loss: 0.527839\n",
      "epoch 89; iter: 0; batch classifier loss: 0.477380; batch adversarial loss: 0.573890\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390503; batch adversarial loss: 0.600929\n",
      "epoch 91; iter: 0; batch classifier loss: 0.346721; batch adversarial loss: 0.537521\n",
      "epoch 92; iter: 0; batch classifier loss: 0.430711; batch adversarial loss: 0.525931\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389291; batch adversarial loss: 0.606436\n",
      "epoch 94; iter: 0; batch classifier loss: 0.418534; batch adversarial loss: 0.494537\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347149; batch adversarial loss: 0.553860\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396889; batch adversarial loss: 0.626070\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336183; batch adversarial loss: 0.591844\n",
      "epoch 98; iter: 0; batch classifier loss: 0.318256; batch adversarial loss: 0.428321\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351404; batch adversarial loss: 0.508636\n",
      "epoch 100; iter: 0; batch classifier loss: 0.340292; batch adversarial loss: 0.624294\n",
      "epoch 101; iter: 0; batch classifier loss: 0.454156; batch adversarial loss: 0.553870\n",
      "epoch 102; iter: 0; batch classifier loss: 0.389039; batch adversarial loss: 0.533953\n",
      "epoch 103; iter: 0; batch classifier loss: 0.400463; batch adversarial loss: 0.587050\n",
      "epoch 104; iter: 0; batch classifier loss: 0.355537; batch adversarial loss: 0.444322\n",
      "epoch 105; iter: 0; batch classifier loss: 0.428312; batch adversarial loss: 0.526399\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389477; batch adversarial loss: 0.548991\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365746; batch adversarial loss: 0.621548\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391663; batch adversarial loss: 0.564347\n",
      "epoch 109; iter: 0; batch classifier loss: 0.484425; batch adversarial loss: 0.500337\n",
      "epoch 110; iter: 0; batch classifier loss: 0.481916; batch adversarial loss: 0.588432\n",
      "epoch 111; iter: 0; batch classifier loss: 0.337117; batch adversarial loss: 0.535602\n",
      "epoch 112; iter: 0; batch classifier loss: 0.404793; batch adversarial loss: 0.562346\n",
      "epoch 113; iter: 0; batch classifier loss: 0.304431; batch adversarial loss: 0.526854\n",
      "epoch 114; iter: 0; batch classifier loss: 0.425778; batch adversarial loss: 0.534858\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341533; batch adversarial loss: 0.600922\n",
      "epoch 116; iter: 0; batch classifier loss: 0.362405; batch adversarial loss: 0.609004\n",
      "epoch 117; iter: 0; batch classifier loss: 0.447214; batch adversarial loss: 0.604294\n",
      "epoch 118; iter: 0; batch classifier loss: 0.328457; batch adversarial loss: 0.498229\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370069; batch adversarial loss: 0.545872\n",
      "epoch 120; iter: 0; batch classifier loss: 0.303840; batch adversarial loss: 0.527676\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370418; batch adversarial loss: 0.625947\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350464; batch adversarial loss: 0.510362\n",
      "epoch 123; iter: 0; batch classifier loss: 0.383150; batch adversarial loss: 0.506406\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379480; batch adversarial loss: 0.505113\n",
      "epoch 125; iter: 0; batch classifier loss: 0.228199; batch adversarial loss: 0.543631\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404286; batch adversarial loss: 0.498685\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333337; batch adversarial loss: 0.607154\n",
      "epoch 128; iter: 0; batch classifier loss: 0.400611; batch adversarial loss: 0.508615\n",
      "epoch 129; iter: 0; batch classifier loss: 0.446540; batch adversarial loss: 0.542823\n",
      "epoch 130; iter: 0; batch classifier loss: 0.309866; batch adversarial loss: 0.580387\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389928; batch adversarial loss: 0.506068\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335390; batch adversarial loss: 0.571506\n",
      "epoch 133; iter: 0; batch classifier loss: 0.432080; batch adversarial loss: 0.573107\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395272; batch adversarial loss: 0.624510\n",
      "epoch 135; iter: 0; batch classifier loss: 0.467281; batch adversarial loss: 0.564083\n",
      "epoch 136; iter: 0; batch classifier loss: 0.384520; batch adversarial loss: 0.490079\n",
      "epoch 137; iter: 0; batch classifier loss: 0.361700; batch adversarial loss: 0.562328\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359478; batch adversarial loss: 0.616561\n",
      "epoch 139; iter: 0; batch classifier loss: 0.441471; batch adversarial loss: 0.508241\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343704; batch adversarial loss: 0.560998\n",
      "epoch 141; iter: 0; batch classifier loss: 0.290591; batch adversarial loss: 0.562091\n",
      "epoch 142; iter: 0; batch classifier loss: 0.291515; batch adversarial loss: 0.497540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.377850; batch adversarial loss: 0.551056\n",
      "epoch 144; iter: 0; batch classifier loss: 0.322694; batch adversarial loss: 0.537799\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342994; batch adversarial loss: 0.564503\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325789; batch adversarial loss: 0.583286\n",
      "epoch 147; iter: 0; batch classifier loss: 0.442550; batch adversarial loss: 0.548109\n",
      "epoch 148; iter: 0; batch classifier loss: 0.404360; batch adversarial loss: 0.598499\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391375; batch adversarial loss: 0.563334\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349656; batch adversarial loss: 0.507025\n",
      "epoch 151; iter: 0; batch classifier loss: 0.323618; batch adversarial loss: 0.591597\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388995; batch adversarial loss: 0.553416\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376876; batch adversarial loss: 0.524444\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350799; batch adversarial loss: 0.580333\n",
      "epoch 155; iter: 0; batch classifier loss: 0.414845; batch adversarial loss: 0.577230\n",
      "epoch 156; iter: 0; batch classifier loss: 0.450313; batch adversarial loss: 0.524473\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362414; batch adversarial loss: 0.601680\n",
      "epoch 158; iter: 0; batch classifier loss: 0.432353; batch adversarial loss: 0.544870\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369721; batch adversarial loss: 0.590669\n",
      "epoch 160; iter: 0; batch classifier loss: 0.355859; batch adversarial loss: 0.552041\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368853; batch adversarial loss: 0.599897\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400444; batch adversarial loss: 0.552661\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367357; batch adversarial loss: 0.599681\n",
      "epoch 164; iter: 0; batch classifier loss: 0.465636; batch adversarial loss: 0.497710\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388712; batch adversarial loss: 0.569100\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347543; batch adversarial loss: 0.508375\n",
      "epoch 167; iter: 0; batch classifier loss: 0.422362; batch adversarial loss: 0.547839\n",
      "epoch 168; iter: 0; batch classifier loss: 0.456541; batch adversarial loss: 0.589654\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360641; batch adversarial loss: 0.544005\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329287; batch adversarial loss: 0.516979\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351756; batch adversarial loss: 0.463834\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367120; batch adversarial loss: 0.609096\n",
      "epoch 173; iter: 0; batch classifier loss: 0.423849; batch adversarial loss: 0.501168\n",
      "epoch 174; iter: 0; batch classifier loss: 0.390984; batch adversarial loss: 0.579467\n",
      "epoch 175; iter: 0; batch classifier loss: 0.289868; batch adversarial loss: 0.562962\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397977; batch adversarial loss: 0.513725\n",
      "epoch 177; iter: 0; batch classifier loss: 0.323114; batch adversarial loss: 0.522556\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309655; batch adversarial loss: 0.489450\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349906; batch adversarial loss: 0.551630\n",
      "epoch 180; iter: 0; batch classifier loss: 0.306120; batch adversarial loss: 0.524776\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350639; batch adversarial loss: 0.516273\n",
      "epoch 182; iter: 0; batch classifier loss: 0.292958; batch adversarial loss: 0.589530\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330728; batch adversarial loss: 0.559892\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325278; batch adversarial loss: 0.568498\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303791; batch adversarial loss: 0.482625\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309072; batch adversarial loss: 0.505899\n",
      "epoch 187; iter: 0; batch classifier loss: 0.429296; batch adversarial loss: 0.544455\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337805; batch adversarial loss: 0.516191\n",
      "epoch 189; iter: 0; batch classifier loss: 0.399079; batch adversarial loss: 0.587448\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344647; batch adversarial loss: 0.417396\n",
      "epoch 191; iter: 0; batch classifier loss: 0.277955; batch adversarial loss: 0.511468\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349000; batch adversarial loss: 0.541465\n",
      "epoch 193; iter: 0; batch classifier loss: 0.315222; batch adversarial loss: 0.604319\n",
      "epoch 194; iter: 0; batch classifier loss: 0.375614; batch adversarial loss: 0.580964\n",
      "epoch 195; iter: 0; batch classifier loss: 0.388882; batch adversarial loss: 0.543688\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339247; batch adversarial loss: 0.491623\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367751; batch adversarial loss: 0.600897\n",
      "epoch 198; iter: 0; batch classifier loss: 0.422558; batch adversarial loss: 0.493061\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366214; batch adversarial loss: 0.602420\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682858; batch adversarial loss: 0.647745\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618058; batch adversarial loss: 0.649137\n",
      "epoch 2; iter: 0; batch classifier loss: 0.540447; batch adversarial loss: 0.667553\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616865; batch adversarial loss: 0.617279\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587802; batch adversarial loss: 0.583075\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564976; batch adversarial loss: 0.608193\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532693; batch adversarial loss: 0.600415\n",
      "epoch 7; iter: 0; batch classifier loss: 0.640602; batch adversarial loss: 0.602611\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557943; batch adversarial loss: 0.607601\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573490; batch adversarial loss: 0.590953\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516141; batch adversarial loss: 0.537242\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579619; batch adversarial loss: 0.569176\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485127; batch adversarial loss: 0.590492\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560362; batch adversarial loss: 0.588679\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506156; batch adversarial loss: 0.611053\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549835; batch adversarial loss: 0.547256\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471041; batch adversarial loss: 0.552854\n",
      "epoch 17; iter: 0; batch classifier loss: 0.502900; batch adversarial loss: 0.601109\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453925; batch adversarial loss: 0.565676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468712; batch adversarial loss: 0.558566\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519485; batch adversarial loss: 0.526101\n",
      "epoch 21; iter: 0; batch classifier loss: 0.427438; batch adversarial loss: 0.588055\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506278; batch adversarial loss: 0.585840\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481350; batch adversarial loss: 0.579090\n",
      "epoch 24; iter: 0; batch classifier loss: 0.398710; batch adversarial loss: 0.591232\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434717; batch adversarial loss: 0.563561\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495483; batch adversarial loss: 0.606335\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495873; batch adversarial loss: 0.574022\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453669; batch adversarial loss: 0.539501\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508120; batch adversarial loss: 0.582200\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456366; batch adversarial loss: 0.575703\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506641; batch adversarial loss: 0.560127\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426052; batch adversarial loss: 0.531937\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458501; batch adversarial loss: 0.598860\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439492; batch adversarial loss: 0.614258\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521140; batch adversarial loss: 0.557128\n",
      "epoch 36; iter: 0; batch classifier loss: 0.517007; batch adversarial loss: 0.614044\n",
      "epoch 37; iter: 0; batch classifier loss: 0.405830; batch adversarial loss: 0.595158\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445015; batch adversarial loss: 0.595326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.410286; batch adversarial loss: 0.622866\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395616; batch adversarial loss: 0.528915\n",
      "epoch 41; iter: 0; batch classifier loss: 0.503017; batch adversarial loss: 0.580225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477191; batch adversarial loss: 0.494144\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393536; batch adversarial loss: 0.553969\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481050; batch adversarial loss: 0.614301\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480551; batch adversarial loss: 0.527386\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440062; batch adversarial loss: 0.501258\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398347; batch adversarial loss: 0.500806\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408400; batch adversarial loss: 0.571044\n",
      "epoch 49; iter: 0; batch classifier loss: 0.514323; batch adversarial loss: 0.509814\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390495; batch adversarial loss: 0.597269\n",
      "epoch 51; iter: 0; batch classifier loss: 0.452711; batch adversarial loss: 0.517893\n",
      "epoch 52; iter: 0; batch classifier loss: 0.495720; batch adversarial loss: 0.554173\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389689; batch adversarial loss: 0.544404\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425257; batch adversarial loss: 0.554206\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386047; batch adversarial loss: 0.598103\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473426; batch adversarial loss: 0.536588\n",
      "epoch 57; iter: 0; batch classifier loss: 0.462408; batch adversarial loss: 0.624861\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394380; batch adversarial loss: 0.553293\n",
      "epoch 59; iter: 0; batch classifier loss: 0.380323; batch adversarial loss: 0.588737\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393433; batch adversarial loss: 0.588964\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403327; batch adversarial loss: 0.596320\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484711; batch adversarial loss: 0.500955\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429996; batch adversarial loss: 0.518173\n",
      "epoch 64; iter: 0; batch classifier loss: 0.462828; batch adversarial loss: 0.536802\n",
      "epoch 65; iter: 0; batch classifier loss: 0.497929; batch adversarial loss: 0.509644\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441299; batch adversarial loss: 0.510390\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380395; batch adversarial loss: 0.552722\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422398; batch adversarial loss: 0.562338\n",
      "epoch 69; iter: 0; batch classifier loss: 0.513787; batch adversarial loss: 0.544551\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391598; batch adversarial loss: 0.526552\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423854; batch adversarial loss: 0.536618\n",
      "epoch 72; iter: 0; batch classifier loss: 0.378877; batch adversarial loss: 0.561956\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431509; batch adversarial loss: 0.509862\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460356; batch adversarial loss: 0.579100\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366266; batch adversarial loss: 0.457129\n",
      "epoch 76; iter: 0; batch classifier loss: 0.466857; batch adversarial loss: 0.534837\n",
      "epoch 77; iter: 0; batch classifier loss: 0.482427; batch adversarial loss: 0.560916\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439850; batch adversarial loss: 0.561109\n",
      "epoch 79; iter: 0; batch classifier loss: 0.356145; batch adversarial loss: 0.545573\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392474; batch adversarial loss: 0.438398\n",
      "epoch 81; iter: 0; batch classifier loss: 0.437052; batch adversarial loss: 0.606841\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410115; batch adversarial loss: 0.492608\n",
      "epoch 83; iter: 0; batch classifier loss: 0.461279; batch adversarial loss: 0.543982\n",
      "epoch 84; iter: 0; batch classifier loss: 0.335348; batch adversarial loss: 0.588910\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390063; batch adversarial loss: 0.597625\n",
      "epoch 86; iter: 0; batch classifier loss: 0.439773; batch adversarial loss: 0.616181\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433609; batch adversarial loss: 0.580689\n",
      "epoch 88; iter: 0; batch classifier loss: 0.447607; batch adversarial loss: 0.544464\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395325; batch adversarial loss: 0.588337\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384862; batch adversarial loss: 0.481916\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410667; batch adversarial loss: 0.518933\n",
      "epoch 92; iter: 0; batch classifier loss: 0.423167; batch adversarial loss: 0.579750\n",
      "epoch 93; iter: 0; batch classifier loss: 0.425974; batch adversarial loss: 0.534641\n",
      "epoch 94; iter: 0; batch classifier loss: 0.444222; batch adversarial loss: 0.510174\n",
      "epoch 95; iter: 0; batch classifier loss: 0.332889; batch adversarial loss: 0.517655\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392173; batch adversarial loss: 0.483007\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356473; batch adversarial loss: 0.561294\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358710; batch adversarial loss: 0.553586\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398415; batch adversarial loss: 0.545414\n",
      "epoch 100; iter: 0; batch classifier loss: 0.429982; batch adversarial loss: 0.490792\n",
      "epoch 101; iter: 0; batch classifier loss: 0.464638; batch adversarial loss: 0.587730\n",
      "epoch 102; iter: 0; batch classifier loss: 0.457203; batch adversarial loss: 0.598545\n",
      "epoch 103; iter: 0; batch classifier loss: 0.469369; batch adversarial loss: 0.516858\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371886; batch adversarial loss: 0.512095\n",
      "epoch 105; iter: 0; batch classifier loss: 0.483564; batch adversarial loss: 0.526431\n",
      "epoch 106; iter: 0; batch classifier loss: 0.481746; batch adversarial loss: 0.562277\n",
      "epoch 107; iter: 0; batch classifier loss: 0.429791; batch adversarial loss: 0.599211\n",
      "epoch 108; iter: 0; batch classifier loss: 0.343935; batch adversarial loss: 0.516477\n",
      "epoch 109; iter: 0; batch classifier loss: 0.428329; batch adversarial loss: 0.561463\n",
      "epoch 110; iter: 0; batch classifier loss: 0.424048; batch adversarial loss: 0.580847\n",
      "epoch 111; iter: 0; batch classifier loss: 0.428970; batch adversarial loss: 0.571503\n",
      "epoch 112; iter: 0; batch classifier loss: 0.401858; batch adversarial loss: 0.508922\n",
      "epoch 113; iter: 0; batch classifier loss: 0.376551; batch adversarial loss: 0.587732\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365638; batch adversarial loss: 0.537117\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348590; batch adversarial loss: 0.501314\n",
      "epoch 116; iter: 0; batch classifier loss: 0.322261; batch adversarial loss: 0.502535\n",
      "epoch 117; iter: 0; batch classifier loss: 0.410394; batch adversarial loss: 0.546512\n",
      "epoch 118; iter: 0; batch classifier loss: 0.372307; batch adversarial loss: 0.614126\n",
      "epoch 119; iter: 0; batch classifier loss: 0.397137; batch adversarial loss: 0.526219\n",
      "epoch 120; iter: 0; batch classifier loss: 0.450505; batch adversarial loss: 0.516075\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360328; batch adversarial loss: 0.560995\n",
      "epoch 122; iter: 0; batch classifier loss: 0.523915; batch adversarial loss: 0.500495\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367090; batch adversarial loss: 0.534683\n",
      "epoch 124; iter: 0; batch classifier loss: 0.384197; batch adversarial loss: 0.562185\n",
      "epoch 125; iter: 0; batch classifier loss: 0.467398; batch adversarial loss: 0.527396\n",
      "epoch 126; iter: 0; batch classifier loss: 0.307575; batch adversarial loss: 0.543215\n",
      "epoch 127; iter: 0; batch classifier loss: 0.438720; batch adversarial loss: 0.527419\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368604; batch adversarial loss: 0.588855\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344689; batch adversarial loss: 0.526000\n",
      "epoch 130; iter: 0; batch classifier loss: 0.331431; batch adversarial loss: 0.596845\n",
      "epoch 131; iter: 0; batch classifier loss: 0.474362; batch adversarial loss: 0.527547\n",
      "epoch 132; iter: 0; batch classifier loss: 0.418420; batch adversarial loss: 0.571214\n",
      "epoch 133; iter: 0; batch classifier loss: 0.422587; batch adversarial loss: 0.535208\n",
      "epoch 134; iter: 0; batch classifier loss: 0.391061; batch adversarial loss: 0.642176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.409545; batch adversarial loss: 0.562553\n",
      "epoch 136; iter: 0; batch classifier loss: 0.307413; batch adversarial loss: 0.535575\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382274; batch adversarial loss: 0.552835\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358466; batch adversarial loss: 0.545183\n",
      "epoch 139; iter: 0; batch classifier loss: 0.409106; batch adversarial loss: 0.517586\n",
      "epoch 140; iter: 0; batch classifier loss: 0.435223; batch adversarial loss: 0.474883\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434637; batch adversarial loss: 0.545774\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354435; batch adversarial loss: 0.525280\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367312; batch adversarial loss: 0.588817\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379576; batch adversarial loss: 0.500202\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364343; batch adversarial loss: 0.669268\n",
      "epoch 146; iter: 0; batch classifier loss: 0.426789; batch adversarial loss: 0.571043\n",
      "epoch 147; iter: 0; batch classifier loss: 0.311800; batch adversarial loss: 0.489776\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370925; batch adversarial loss: 0.631338\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322475; batch adversarial loss: 0.606482\n",
      "epoch 150; iter: 0; batch classifier loss: 0.425884; batch adversarial loss: 0.527225\n",
      "epoch 151; iter: 0; batch classifier loss: 0.416141; batch adversarial loss: 0.553251\n",
      "epoch 152; iter: 0; batch classifier loss: 0.431293; batch adversarial loss: 0.660551\n",
      "epoch 153; iter: 0; batch classifier loss: 0.305741; batch adversarial loss: 0.498690\n",
      "epoch 154; iter: 0; batch classifier loss: 0.336273; batch adversarial loss: 0.545162\n",
      "epoch 155; iter: 0; batch classifier loss: 0.381389; batch adversarial loss: 0.587083\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380586; batch adversarial loss: 0.535661\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341763; batch adversarial loss: 0.589180\n",
      "epoch 158; iter: 0; batch classifier loss: 0.422963; batch adversarial loss: 0.570783\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385041; batch adversarial loss: 0.590527\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390400; batch adversarial loss: 0.605793\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368314; batch adversarial loss: 0.660446\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326703; batch adversarial loss: 0.591085\n",
      "epoch 163; iter: 0; batch classifier loss: 0.370002; batch adversarial loss: 0.543424\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387583; batch adversarial loss: 0.624543\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348795; batch adversarial loss: 0.527133\n",
      "epoch 166; iter: 0; batch classifier loss: 0.435925; batch adversarial loss: 0.510347\n",
      "epoch 167; iter: 0; batch classifier loss: 0.284557; batch adversarial loss: 0.615601\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349262; batch adversarial loss: 0.526109\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367410; batch adversarial loss: 0.528154\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371713; batch adversarial loss: 0.482823\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344138; batch adversarial loss: 0.517888\n",
      "epoch 172; iter: 0; batch classifier loss: 0.350310; batch adversarial loss: 0.544402\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350225; batch adversarial loss: 0.571734\n",
      "epoch 174; iter: 0; batch classifier loss: 0.425826; batch adversarial loss: 0.508327\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355795; batch adversarial loss: 0.553634\n",
      "epoch 176; iter: 0; batch classifier loss: 0.317887; batch adversarial loss: 0.614043\n",
      "epoch 177; iter: 0; batch classifier loss: 0.348743; batch adversarial loss: 0.500495\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345395; batch adversarial loss: 0.582160\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370307; batch adversarial loss: 0.570707\n",
      "epoch 180; iter: 0; batch classifier loss: 0.504667; batch adversarial loss: 0.536551\n",
      "epoch 181; iter: 0; batch classifier loss: 0.435782; batch adversarial loss: 0.553066\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380091; batch adversarial loss: 0.590733\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349948; batch adversarial loss: 0.542049\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360957; batch adversarial loss: 0.570903\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391631; batch adversarial loss: 0.561064\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376540; batch adversarial loss: 0.544941\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345737; batch adversarial loss: 0.590178\n",
      "epoch 188; iter: 0; batch classifier loss: 0.431761; batch adversarial loss: 0.526411\n",
      "epoch 189; iter: 0; batch classifier loss: 0.421921; batch adversarial loss: 0.580856\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328386; batch adversarial loss: 0.500867\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379624; batch adversarial loss: 0.527540\n",
      "epoch 192; iter: 0; batch classifier loss: 0.350122; batch adversarial loss: 0.500817\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330042; batch adversarial loss: 0.535466\n",
      "epoch 194; iter: 0; batch classifier loss: 0.436318; batch adversarial loss: 0.561266\n",
      "epoch 195; iter: 0; batch classifier loss: 0.394962; batch adversarial loss: 0.580254\n",
      "epoch 196; iter: 0; batch classifier loss: 0.435945; batch adversarial loss: 0.537085\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355113; batch adversarial loss: 0.474017\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384185; batch adversarial loss: 0.562228\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329988; batch adversarial loss: 0.536814\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681936; batch adversarial loss: 0.614153\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583425; batch adversarial loss: 0.658157\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611404; batch adversarial loss: 0.637626\n",
      "epoch 3; iter: 0; batch classifier loss: 0.621709; batch adversarial loss: 0.655419\n",
      "epoch 4; iter: 0; batch classifier loss: 0.510212; batch adversarial loss: 0.613554\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621766; batch adversarial loss: 0.594168\n",
      "epoch 6; iter: 0; batch classifier loss: 0.610000; batch adversarial loss: 0.712604\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527691; batch adversarial loss: 0.619433\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557556; batch adversarial loss: 0.576989\n",
      "epoch 9; iter: 0; batch classifier loss: 0.599040; batch adversarial loss: 0.585782\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513815; batch adversarial loss: 0.559845\n",
      "epoch 11; iter: 0; batch classifier loss: 0.442592; batch adversarial loss: 0.566770\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503357; batch adversarial loss: 0.536841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.615615; batch adversarial loss: 0.612619\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540044; batch adversarial loss: 0.553504\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475073; batch adversarial loss: 0.543851\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476739; batch adversarial loss: 0.528504\n",
      "epoch 17; iter: 0; batch classifier loss: 0.447915; batch adversarial loss: 0.547269\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542480; batch adversarial loss: 0.525812\n",
      "epoch 19; iter: 0; batch classifier loss: 0.560936; batch adversarial loss: 0.561721\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430672; batch adversarial loss: 0.555879\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502165; batch adversarial loss: 0.551312\n",
      "epoch 22; iter: 0; batch classifier loss: 0.413910; batch adversarial loss: 0.579815\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527031; batch adversarial loss: 0.560993\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480802; batch adversarial loss: 0.548764\n",
      "epoch 25; iter: 0; batch classifier loss: 0.539593; batch adversarial loss: 0.505947\n",
      "epoch 26; iter: 0; batch classifier loss: 0.586921; batch adversarial loss: 0.588243\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501122; batch adversarial loss: 0.575854\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473746; batch adversarial loss: 0.562788\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430764; batch adversarial loss: 0.521550\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486759; batch adversarial loss: 0.530398\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497404; batch adversarial loss: 0.537628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.435841; batch adversarial loss: 0.536227\n",
      "epoch 33; iter: 0; batch classifier loss: 0.564377; batch adversarial loss: 0.474907\n",
      "epoch 34; iter: 0; batch classifier loss: 0.508092; batch adversarial loss: 0.492087\n",
      "epoch 35; iter: 0; batch classifier loss: 0.515494; batch adversarial loss: 0.607534\n",
      "epoch 36; iter: 0; batch classifier loss: 0.500624; batch adversarial loss: 0.571492\n",
      "epoch 37; iter: 0; batch classifier loss: 0.435116; batch adversarial loss: 0.589413\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497592; batch adversarial loss: 0.490082\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442957; batch adversarial loss: 0.526479\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457170; batch adversarial loss: 0.526062\n",
      "epoch 41; iter: 0; batch classifier loss: 0.485253; batch adversarial loss: 0.617134\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467911; batch adversarial loss: 0.616841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399207; batch adversarial loss: 0.553277\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489187; batch adversarial loss: 0.489043\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479599; batch adversarial loss: 0.599313\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487313; batch adversarial loss: 0.562609\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468514; batch adversarial loss: 0.535839\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469642; batch adversarial loss: 0.552608\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460329; batch adversarial loss: 0.507696\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417032; batch adversarial loss: 0.508015\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422695; batch adversarial loss: 0.461279\n",
      "epoch 52; iter: 0; batch classifier loss: 0.473336; batch adversarial loss: 0.581967\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452900; batch adversarial loss: 0.525888\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415342; batch adversarial loss: 0.572421\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402907; batch adversarial loss: 0.581380\n",
      "epoch 56; iter: 0; batch classifier loss: 0.510403; batch adversarial loss: 0.498441\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448671; batch adversarial loss: 0.516311\n",
      "epoch 58; iter: 0; batch classifier loss: 0.461404; batch adversarial loss: 0.526602\n",
      "epoch 59; iter: 0; batch classifier loss: 0.372823; batch adversarial loss: 0.535695\n",
      "epoch 60; iter: 0; batch classifier loss: 0.468819; batch adversarial loss: 0.581068\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416542; batch adversarial loss: 0.581362\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379047; batch adversarial loss: 0.461739\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416032; batch adversarial loss: 0.572457\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437392; batch adversarial loss: 0.508110\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453062; batch adversarial loss: 0.517080\n",
      "epoch 66; iter: 0; batch classifier loss: 0.388820; batch adversarial loss: 0.534511\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417069; batch adversarial loss: 0.638205\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412195; batch adversarial loss: 0.516360\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401396; batch adversarial loss: 0.563271\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382083; batch adversarial loss: 0.460875\n",
      "epoch 71; iter: 0; batch classifier loss: 0.445538; batch adversarial loss: 0.617829\n",
      "epoch 72; iter: 0; batch classifier loss: 0.395280; batch adversarial loss: 0.487015\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442928; batch adversarial loss: 0.636188\n",
      "epoch 74; iter: 0; batch classifier loss: 0.368970; batch adversarial loss: 0.578050\n",
      "epoch 75; iter: 0; batch classifier loss: 0.338346; batch adversarial loss: 0.602516\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418619; batch adversarial loss: 0.535463\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414526; batch adversarial loss: 0.507614\n",
      "epoch 78; iter: 0; batch classifier loss: 0.445504; batch adversarial loss: 0.488619\n",
      "epoch 79; iter: 0; batch classifier loss: 0.465288; batch adversarial loss: 0.580654\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358910; batch adversarial loss: 0.571191\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375928; batch adversarial loss: 0.600047\n",
      "epoch 82; iter: 0; batch classifier loss: 0.444494; batch adversarial loss: 0.489288\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425827; batch adversarial loss: 0.598192\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400074; batch adversarial loss: 0.645903\n",
      "epoch 85; iter: 0; batch classifier loss: 0.462728; batch adversarial loss: 0.571549\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378903; batch adversarial loss: 0.584253\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433893; batch adversarial loss: 0.523571\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401405; batch adversarial loss: 0.535414\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428296; batch adversarial loss: 0.581878\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407036; batch adversarial loss: 0.557507\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413490; batch adversarial loss: 0.479886\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411412; batch adversarial loss: 0.563591\n",
      "epoch 93; iter: 0; batch classifier loss: 0.448386; batch adversarial loss: 0.527762\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392244; batch adversarial loss: 0.571788\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399948; batch adversarial loss: 0.543824\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396969; batch adversarial loss: 0.570917\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360928; batch adversarial loss: 0.590802\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404779; batch adversarial loss: 0.518111\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456283; batch adversarial loss: 0.544441\n",
      "epoch 100; iter: 0; batch classifier loss: 0.499347; batch adversarial loss: 0.580885\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384524; batch adversarial loss: 0.526283\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426963; batch adversarial loss: 0.480605\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345911; batch adversarial loss: 0.672437\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391392; batch adversarial loss: 0.526458\n",
      "epoch 105; iter: 0; batch classifier loss: 0.504336; batch adversarial loss: 0.572528\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441828; batch adversarial loss: 0.544625\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431738; batch adversarial loss: 0.526561\n",
      "epoch 108; iter: 0; batch classifier loss: 0.317711; batch adversarial loss: 0.562048\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407969; batch adversarial loss: 0.619544\n",
      "epoch 110; iter: 0; batch classifier loss: 0.450661; batch adversarial loss: 0.562774\n",
      "epoch 111; iter: 0; batch classifier loss: 0.351538; batch adversarial loss: 0.526278\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349114; batch adversarial loss: 0.544193\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400708; batch adversarial loss: 0.553947\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394109; batch adversarial loss: 0.517353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405566; batch adversarial loss: 0.608775\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357239; batch adversarial loss: 0.562447\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379478; batch adversarial loss: 0.562228\n",
      "epoch 118; iter: 0; batch classifier loss: 0.419468; batch adversarial loss: 0.544700\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394460; batch adversarial loss: 0.619002\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407295; batch adversarial loss: 0.451550\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388101; batch adversarial loss: 0.517690\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350433; batch adversarial loss: 0.599273\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372795; batch adversarial loss: 0.508001\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365031; batch adversarial loss: 0.506050\n",
      "epoch 125; iter: 0; batch classifier loss: 0.378677; batch adversarial loss: 0.496538\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386185; batch adversarial loss: 0.553134\n",
      "epoch 127; iter: 0; batch classifier loss: 0.402407; batch adversarial loss: 0.553560\n",
      "epoch 128; iter: 0; batch classifier loss: 0.407341; batch adversarial loss: 0.565217\n",
      "epoch 129; iter: 0; batch classifier loss: 0.407999; batch adversarial loss: 0.608461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.384397; batch adversarial loss: 0.589998\n",
      "epoch 131; iter: 0; batch classifier loss: 0.410566; batch adversarial loss: 0.636277\n",
      "epoch 132; iter: 0; batch classifier loss: 0.411739; batch adversarial loss: 0.479599\n",
      "epoch 133; iter: 0; batch classifier loss: 0.415659; batch adversarial loss: 0.562971\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339151; batch adversarial loss: 0.490501\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370225; batch adversarial loss: 0.571401\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341863; batch adversarial loss: 0.517508\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328272; batch adversarial loss: 0.506317\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387245; batch adversarial loss: 0.581758\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358473; batch adversarial loss: 0.553700\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332822; batch adversarial loss: 0.565585\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334319; batch adversarial loss: 0.572915\n",
      "epoch 142; iter: 0; batch classifier loss: 0.324634; batch adversarial loss: 0.618024\n",
      "epoch 143; iter: 0; batch classifier loss: 0.482852; batch adversarial loss: 0.544393\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369261; batch adversarial loss: 0.600534\n",
      "epoch 145; iter: 0; batch classifier loss: 0.400507; batch adversarial loss: 0.599569\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368858; batch adversarial loss: 0.499449\n",
      "epoch 147; iter: 0; batch classifier loss: 0.437289; batch adversarial loss: 0.601324\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373999; batch adversarial loss: 0.580464\n",
      "epoch 149; iter: 0; batch classifier loss: 0.333414; batch adversarial loss: 0.562267\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330554; batch adversarial loss: 0.507650\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361414; batch adversarial loss: 0.535384\n",
      "epoch 152; iter: 0; batch classifier loss: 0.425382; batch adversarial loss: 0.453387\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364233; batch adversarial loss: 0.590395\n",
      "epoch 154; iter: 0; batch classifier loss: 0.425671; batch adversarial loss: 0.526294\n",
      "epoch 155; iter: 0; batch classifier loss: 0.420005; batch adversarial loss: 0.581389\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317009; batch adversarial loss: 0.535851\n",
      "epoch 157; iter: 0; batch classifier loss: 0.474564; batch adversarial loss: 0.562750\n",
      "epoch 158; iter: 0; batch classifier loss: 0.409004; batch adversarial loss: 0.563390\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391522; batch adversarial loss: 0.580893\n",
      "epoch 160; iter: 0; batch classifier loss: 0.396257; batch adversarial loss: 0.535049\n",
      "epoch 161; iter: 0; batch classifier loss: 0.427697; batch adversarial loss: 0.534566\n",
      "epoch 162; iter: 0; batch classifier loss: 0.317947; batch adversarial loss: 0.608901\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338906; batch adversarial loss: 0.535073\n",
      "epoch 164; iter: 0; batch classifier loss: 0.418251; batch adversarial loss: 0.525893\n",
      "epoch 165; iter: 0; batch classifier loss: 0.430961; batch adversarial loss: 0.572083\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366832; batch adversarial loss: 0.609057\n",
      "epoch 167; iter: 0; batch classifier loss: 0.402965; batch adversarial loss: 0.534917\n",
      "epoch 168; iter: 0; batch classifier loss: 0.391870; batch adversarial loss: 0.471185\n",
      "epoch 169; iter: 0; batch classifier loss: 0.452751; batch adversarial loss: 0.553537\n",
      "epoch 170; iter: 0; batch classifier loss: 0.401677; batch adversarial loss: 0.572463\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383902; batch adversarial loss: 0.628379\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387797; batch adversarial loss: 0.580818\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404392; batch adversarial loss: 0.470319\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400666; batch adversarial loss: 0.497270\n",
      "epoch 175; iter: 0; batch classifier loss: 0.457250; batch adversarial loss: 0.553976\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341502; batch adversarial loss: 0.479048\n",
      "epoch 177; iter: 0; batch classifier loss: 0.404615; batch adversarial loss: 0.478357\n",
      "epoch 178; iter: 0; batch classifier loss: 0.349419; batch adversarial loss: 0.471128\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351862; batch adversarial loss: 0.536322\n",
      "epoch 180; iter: 0; batch classifier loss: 0.419001; batch adversarial loss: 0.583327\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364719; batch adversarial loss: 0.535592\n",
      "epoch 182; iter: 0; batch classifier loss: 0.400115; batch adversarial loss: 0.488956\n",
      "epoch 183; iter: 0; batch classifier loss: 0.444969; batch adversarial loss: 0.489285\n",
      "epoch 184; iter: 0; batch classifier loss: 0.300014; batch adversarial loss: 0.544805\n",
      "epoch 185; iter: 0; batch classifier loss: 0.382884; batch adversarial loss: 0.627517\n",
      "epoch 186; iter: 0; batch classifier loss: 0.423550; batch adversarial loss: 0.517260\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333424; batch adversarial loss: 0.534628\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382537; batch adversarial loss: 0.563098\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384653; batch adversarial loss: 0.526154\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365955; batch adversarial loss: 0.589162\n",
      "epoch 191; iter: 0; batch classifier loss: 0.309533; batch adversarial loss: 0.581453\n",
      "epoch 192; iter: 0; batch classifier loss: 0.402043; batch adversarial loss: 0.526384\n",
      "epoch 193; iter: 0; batch classifier loss: 0.380476; batch adversarial loss: 0.562318\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385809; batch adversarial loss: 0.573903\n",
      "epoch 195; iter: 0; batch classifier loss: 0.419140; batch adversarial loss: 0.546013\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341792; batch adversarial loss: 0.581803\n",
      "epoch 197; iter: 0; batch classifier loss: 0.398279; batch adversarial loss: 0.508138\n",
      "epoch 198; iter: 0; batch classifier loss: 0.381218; batch adversarial loss: 0.590008\n",
      "epoch 199; iter: 0; batch classifier loss: 0.425459; batch adversarial loss: 0.507576\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683438; batch adversarial loss: 0.580967\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555011; batch adversarial loss: 0.669422\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614006; batch adversarial loss: 0.653395\n",
      "epoch 3; iter: 0; batch classifier loss: 0.632938; batch adversarial loss: 0.743285\n",
      "epoch 4; iter: 0; batch classifier loss: 0.551147; batch adversarial loss: 0.723240\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630530; batch adversarial loss: 0.698245\n",
      "epoch 6; iter: 0; batch classifier loss: 0.576710; batch adversarial loss: 0.663422\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601613; batch adversarial loss: 0.631013\n",
      "epoch 8; iter: 0; batch classifier loss: 0.616079; batch adversarial loss: 0.626721\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578191; batch adversarial loss: 0.592481\n",
      "epoch 10; iter: 0; batch classifier loss: 0.530809; batch adversarial loss: 0.572467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.513537; batch adversarial loss: 0.589751\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528759; batch adversarial loss: 0.548404\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524978; batch adversarial loss: 0.637357\n",
      "epoch 14; iter: 0; batch classifier loss: 0.490488; batch adversarial loss: 0.530524\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502333; batch adversarial loss: 0.545662\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528448; batch adversarial loss: 0.625435\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546419; batch adversarial loss: 0.582506\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556788; batch adversarial loss: 0.538083\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509326; batch adversarial loss: 0.523757\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473950; batch adversarial loss: 0.524311\n",
      "epoch 21; iter: 0; batch classifier loss: 0.569961; batch adversarial loss: 0.515792\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473381; batch adversarial loss: 0.547554\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520444; batch adversarial loss: 0.521947\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455603; batch adversarial loss: 0.519499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527482; batch adversarial loss: 0.561733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.516123; batch adversarial loss: 0.487094\n",
      "epoch 27; iter: 0; batch classifier loss: 0.538581; batch adversarial loss: 0.526003\n",
      "epoch 28; iter: 0; batch classifier loss: 0.509229; batch adversarial loss: 0.497701\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468347; batch adversarial loss: 0.488168\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473916; batch adversarial loss: 0.553906\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441465; batch adversarial loss: 0.596505\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490018; batch adversarial loss: 0.573964\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476160; batch adversarial loss: 0.554934\n",
      "epoch 34; iter: 0; batch classifier loss: 0.517236; batch adversarial loss: 0.489810\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410801; batch adversarial loss: 0.626025\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508054; batch adversarial loss: 0.449738\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438933; batch adversarial loss: 0.545076\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425884; batch adversarial loss: 0.555140\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465003; batch adversarial loss: 0.551837\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486124; batch adversarial loss: 0.542373\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438394; batch adversarial loss: 0.506727\n",
      "epoch 42; iter: 0; batch classifier loss: 0.355822; batch adversarial loss: 0.533447\n",
      "epoch 43; iter: 0; batch classifier loss: 0.502909; batch adversarial loss: 0.534734\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410813; batch adversarial loss: 0.516553\n",
      "epoch 45; iter: 0; batch classifier loss: 0.515516; batch adversarial loss: 0.573977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451695; batch adversarial loss: 0.555698\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430915; batch adversarial loss: 0.593391\n",
      "epoch 48; iter: 0; batch classifier loss: 0.360000; batch adversarial loss: 0.636285\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410025; batch adversarial loss: 0.480148\n",
      "epoch 50; iter: 0; batch classifier loss: 0.375298; batch adversarial loss: 0.497199\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442452; batch adversarial loss: 0.499189\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407628; batch adversarial loss: 0.535172\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379291; batch adversarial loss: 0.571987\n",
      "epoch 54; iter: 0; batch classifier loss: 0.476796; batch adversarial loss: 0.467552\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419398; batch adversarial loss: 0.553653\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448940; batch adversarial loss: 0.580750\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379213; batch adversarial loss: 0.535278\n",
      "epoch 58; iter: 0; batch classifier loss: 0.484301; batch adversarial loss: 0.527887\n",
      "epoch 59; iter: 0; batch classifier loss: 0.373157; batch adversarial loss: 0.583714\n",
      "epoch 60; iter: 0; batch classifier loss: 0.325583; batch adversarial loss: 0.582777\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412448; batch adversarial loss: 0.618277\n",
      "epoch 62; iter: 0; batch classifier loss: 0.364255; batch adversarial loss: 0.560391\n",
      "epoch 63; iter: 0; batch classifier loss: 0.455858; batch adversarial loss: 0.561546\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384997; batch adversarial loss: 0.532560\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450593; batch adversarial loss: 0.542923\n",
      "epoch 66; iter: 0; batch classifier loss: 0.457354; batch adversarial loss: 0.527063\n",
      "epoch 67; iter: 0; batch classifier loss: 0.443688; batch adversarial loss: 0.556545\n",
      "epoch 68; iter: 0; batch classifier loss: 0.429638; batch adversarial loss: 0.477436\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397202; batch adversarial loss: 0.553871\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438842; batch adversarial loss: 0.484723\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449165; batch adversarial loss: 0.525700\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448706; batch adversarial loss: 0.549932\n",
      "epoch 73; iter: 0; batch classifier loss: 0.430570; batch adversarial loss: 0.563881\n",
      "epoch 74; iter: 0; batch classifier loss: 0.511047; batch adversarial loss: 0.532770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416490; batch adversarial loss: 0.546149\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441731; batch adversarial loss: 0.606559\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429220; batch adversarial loss: 0.552859\n",
      "epoch 78; iter: 0; batch classifier loss: 0.454227; batch adversarial loss: 0.621707\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395054; batch adversarial loss: 0.502589\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429259; batch adversarial loss: 0.550024\n",
      "epoch 81; iter: 0; batch classifier loss: 0.355524; batch adversarial loss: 0.529815\n",
      "epoch 82; iter: 0; batch classifier loss: 0.450328; batch adversarial loss: 0.557752\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382377; batch adversarial loss: 0.590493\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382764; batch adversarial loss: 0.548984\n",
      "epoch 85; iter: 0; batch classifier loss: 0.486482; batch adversarial loss: 0.519608\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414910; batch adversarial loss: 0.505461\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433607; batch adversarial loss: 0.506303\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425949; batch adversarial loss: 0.578525\n",
      "epoch 89; iter: 0; batch classifier loss: 0.414349; batch adversarial loss: 0.511808\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387948; batch adversarial loss: 0.585794\n",
      "epoch 91; iter: 0; batch classifier loss: 0.450652; batch adversarial loss: 0.721433\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365649; batch adversarial loss: 0.523850\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392572; batch adversarial loss: 0.567683\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374658; batch adversarial loss: 0.507829\n",
      "epoch 95; iter: 0; batch classifier loss: 0.337106; batch adversarial loss: 0.554126\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373446; batch adversarial loss: 0.522768\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392057; batch adversarial loss: 0.469615\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387733; batch adversarial loss: 0.563273\n",
      "epoch 99; iter: 0; batch classifier loss: 0.438156; batch adversarial loss: 0.513057\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403534; batch adversarial loss: 0.499003\n",
      "epoch 101; iter: 0; batch classifier loss: 0.327782; batch adversarial loss: 0.480866\n",
      "epoch 102; iter: 0; batch classifier loss: 0.523862; batch adversarial loss: 0.582335\n",
      "epoch 103; iter: 0; batch classifier loss: 0.351717; batch adversarial loss: 0.580160\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413819; batch adversarial loss: 0.468056\n",
      "epoch 105; iter: 0; batch classifier loss: 0.332061; batch adversarial loss: 0.620088\n",
      "epoch 106; iter: 0; batch classifier loss: 0.475631; batch adversarial loss: 0.534428\n",
      "epoch 107; iter: 0; batch classifier loss: 0.463265; batch adversarial loss: 0.531763\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399259; batch adversarial loss: 0.542789\n",
      "epoch 109; iter: 0; batch classifier loss: 0.429274; batch adversarial loss: 0.573096\n",
      "epoch 110; iter: 0; batch classifier loss: 0.455769; batch adversarial loss: 0.495440\n",
      "epoch 111; iter: 0; batch classifier loss: 0.421263; batch adversarial loss: 0.545997\n",
      "epoch 112; iter: 0; batch classifier loss: 0.453681; batch adversarial loss: 0.585004\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396989; batch adversarial loss: 0.556359\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393704; batch adversarial loss: 0.525579\n",
      "epoch 115; iter: 0; batch classifier loss: 0.452336; batch adversarial loss: 0.574555\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396677; batch adversarial loss: 0.555861\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357091; batch adversarial loss: 0.487029\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405864; batch adversarial loss: 0.507255\n",
      "epoch 119; iter: 0; batch classifier loss: 0.469945; batch adversarial loss: 0.549452\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388708; batch adversarial loss: 0.574703\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420343; batch adversarial loss: 0.537302\n",
      "epoch 122; iter: 0; batch classifier loss: 0.453431; batch adversarial loss: 0.538003\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394768; batch adversarial loss: 0.572376\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372921; batch adversarial loss: 0.516692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.320494; batch adversarial loss: 0.529048\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366445; batch adversarial loss: 0.582149\n",
      "epoch 127; iter: 0; batch classifier loss: 0.375898; batch adversarial loss: 0.596071\n",
      "epoch 128; iter: 0; batch classifier loss: 0.380776; batch adversarial loss: 0.556646\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360720; batch adversarial loss: 0.630023\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371624; batch adversarial loss: 0.509679\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406629; batch adversarial loss: 0.573313\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354362; batch adversarial loss: 0.507586\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411010; batch adversarial loss: 0.544005\n",
      "epoch 134; iter: 0; batch classifier loss: 0.347689; batch adversarial loss: 0.485047\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341418; batch adversarial loss: 0.546211\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392800; batch adversarial loss: 0.485356\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401833; batch adversarial loss: 0.534203\n",
      "epoch 138; iter: 0; batch classifier loss: 0.301540; batch adversarial loss: 0.542611\n",
      "epoch 139; iter: 0; batch classifier loss: 0.405261; batch adversarial loss: 0.489199\n",
      "epoch 140; iter: 0; batch classifier loss: 0.461028; batch adversarial loss: 0.469071\n",
      "epoch 141; iter: 0; batch classifier loss: 0.384874; batch adversarial loss: 0.574612\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378148; batch adversarial loss: 0.478582\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355798; batch adversarial loss: 0.645289\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389506; batch adversarial loss: 0.565584\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364905; batch adversarial loss: 0.450139\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339673; batch adversarial loss: 0.543576\n",
      "epoch 147; iter: 0; batch classifier loss: 0.438258; batch adversarial loss: 0.477750\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360806; batch adversarial loss: 0.542205\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339614; batch adversarial loss: 0.524472\n",
      "epoch 150; iter: 0; batch classifier loss: 0.438811; batch adversarial loss: 0.520858\n",
      "epoch 151; iter: 0; batch classifier loss: 0.512210; batch adversarial loss: 0.552462\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350306; batch adversarial loss: 0.550892\n",
      "epoch 153; iter: 0; batch classifier loss: 0.458955; batch adversarial loss: 0.554703\n",
      "epoch 154; iter: 0; batch classifier loss: 0.411351; batch adversarial loss: 0.582221\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366432; batch adversarial loss: 0.431153\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385800; batch adversarial loss: 0.537131\n",
      "epoch 157; iter: 0; batch classifier loss: 0.300588; batch adversarial loss: 0.597846\n",
      "epoch 158; iter: 0; batch classifier loss: 0.340199; batch adversarial loss: 0.498769\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370814; batch adversarial loss: 0.572632\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356462; batch adversarial loss: 0.592451\n",
      "epoch 161; iter: 0; batch classifier loss: 0.382777; batch adversarial loss: 0.517650\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306624; batch adversarial loss: 0.584134\n",
      "epoch 163; iter: 0; batch classifier loss: 0.459197; batch adversarial loss: 0.534757\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378910; batch adversarial loss: 0.676957\n",
      "epoch 165; iter: 0; batch classifier loss: 0.411835; batch adversarial loss: 0.554780\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354461; batch adversarial loss: 0.544614\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382487; batch adversarial loss: 0.467071\n",
      "epoch 168; iter: 0; batch classifier loss: 0.368924; batch adversarial loss: 0.468623\n",
      "epoch 169; iter: 0; batch classifier loss: 0.313666; batch adversarial loss: 0.557616\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319291; batch adversarial loss: 0.545363\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332487; batch adversarial loss: 0.514970\n",
      "epoch 172; iter: 0; batch classifier loss: 0.451561; batch adversarial loss: 0.524713\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371566; batch adversarial loss: 0.516672\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360259; batch adversarial loss: 0.521624\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328654; batch adversarial loss: 0.541045\n",
      "epoch 176; iter: 0; batch classifier loss: 0.383439; batch adversarial loss: 0.526364\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342970; batch adversarial loss: 0.477681\n",
      "epoch 178; iter: 0; batch classifier loss: 0.396568; batch adversarial loss: 0.552395\n",
      "epoch 179; iter: 0; batch classifier loss: 0.243982; batch adversarial loss: 0.505524\n",
      "epoch 180; iter: 0; batch classifier loss: 0.409286; batch adversarial loss: 0.547205\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334952; batch adversarial loss: 0.553351\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334519; batch adversarial loss: 0.518083\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396616; batch adversarial loss: 0.536648\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366905; batch adversarial loss: 0.528353\n",
      "epoch 185; iter: 0; batch classifier loss: 0.463614; batch adversarial loss: 0.526548\n",
      "epoch 186; iter: 0; batch classifier loss: 0.430760; batch adversarial loss: 0.608818\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317520; batch adversarial loss: 0.484612\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369697; batch adversarial loss: 0.518137\n",
      "epoch 189; iter: 0; batch classifier loss: 0.316444; batch adversarial loss: 0.514244\n",
      "epoch 190; iter: 0; batch classifier loss: 0.434250; batch adversarial loss: 0.555366\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382204; batch adversarial loss: 0.640097\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384198; batch adversarial loss: 0.476006\n",
      "epoch 193; iter: 0; batch classifier loss: 0.440257; batch adversarial loss: 0.602518\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330496; batch adversarial loss: 0.587890\n",
      "epoch 195; iter: 0; batch classifier loss: 0.389010; batch adversarial loss: 0.573540\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381766; batch adversarial loss: 0.515455\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350744; batch adversarial loss: 0.466155\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352454; batch adversarial loss: 0.535287\n",
      "epoch 199; iter: 0; batch classifier loss: 0.383923; batch adversarial loss: 0.566919\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662838; batch adversarial loss: 0.657258\n",
      "epoch 1; iter: 0; batch classifier loss: 0.646501; batch adversarial loss: 0.649177\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586713; batch adversarial loss: 0.665755\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557727; batch adversarial loss: 0.633597\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591896; batch adversarial loss: 0.662587\n",
      "epoch 5; iter: 0; batch classifier loss: 0.542855; batch adversarial loss: 0.608536\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599899; batch adversarial loss: 0.585457\n",
      "epoch 7; iter: 0; batch classifier loss: 0.609370; batch adversarial loss: 0.640063\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497139; batch adversarial loss: 0.615625\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513503; batch adversarial loss: 0.607204\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517166; batch adversarial loss: 0.574644\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538771; batch adversarial loss: 0.544337\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565770; batch adversarial loss: 0.635779\n",
      "epoch 13; iter: 0; batch classifier loss: 0.582860; batch adversarial loss: 0.614846\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481478; batch adversarial loss: 0.577787\n",
      "epoch 15; iter: 0; batch classifier loss: 0.561308; batch adversarial loss: 0.552347\n",
      "epoch 16; iter: 0; batch classifier loss: 0.516748; batch adversarial loss: 0.583159\n",
      "epoch 17; iter: 0; batch classifier loss: 0.542318; batch adversarial loss: 0.520132\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497514; batch adversarial loss: 0.595734\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474260; batch adversarial loss: 0.543004\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524828; batch adversarial loss: 0.544957\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519551; batch adversarial loss: 0.591439\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483056; batch adversarial loss: 0.530743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.481779; batch adversarial loss: 0.550422\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484351; batch adversarial loss: 0.560796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533747; batch adversarial loss: 0.552152\n",
      "epoch 26; iter: 0; batch classifier loss: 0.563762; batch adversarial loss: 0.560182\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507907; batch adversarial loss: 0.524412\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455896; batch adversarial loss: 0.590816\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431686; batch adversarial loss: 0.619905\n",
      "epoch 30; iter: 0; batch classifier loss: 0.519235; batch adversarial loss: 0.517344\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472137; batch adversarial loss: 0.645543\n",
      "epoch 32; iter: 0; batch classifier loss: 0.527016; batch adversarial loss: 0.537861\n",
      "epoch 33; iter: 0; batch classifier loss: 0.573839; batch adversarial loss: 0.502326\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435643; batch adversarial loss: 0.507717\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521642; batch adversarial loss: 0.519700\n",
      "epoch 36; iter: 0; batch classifier loss: 0.519777; batch adversarial loss: 0.500920\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436623; batch adversarial loss: 0.566805\n",
      "epoch 38; iter: 0; batch classifier loss: 0.511181; batch adversarial loss: 0.496619\n",
      "epoch 39; iter: 0; batch classifier loss: 0.538266; batch adversarial loss: 0.555104\n",
      "epoch 40; iter: 0; batch classifier loss: 0.506229; batch adversarial loss: 0.563020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.500484; batch adversarial loss: 0.566539\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462705; batch adversarial loss: 0.552800\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467959; batch adversarial loss: 0.508183\n",
      "epoch 44; iter: 0; batch classifier loss: 0.425044; batch adversarial loss: 0.575413\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439796; batch adversarial loss: 0.487289\n",
      "epoch 46; iter: 0; batch classifier loss: 0.475589; batch adversarial loss: 0.621217\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461459; batch adversarial loss: 0.561556\n",
      "epoch 48; iter: 0; batch classifier loss: 0.517038; batch adversarial loss: 0.545394\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377090; batch adversarial loss: 0.583675\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438990; batch adversarial loss: 0.588796\n",
      "epoch 51; iter: 0; batch classifier loss: 0.530799; batch adversarial loss: 0.515916\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469822; batch adversarial loss: 0.589722\n",
      "epoch 53; iter: 0; batch classifier loss: 0.475085; batch adversarial loss: 0.547740\n",
      "epoch 54; iter: 0; batch classifier loss: 0.464109; batch adversarial loss: 0.489597\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422577; batch adversarial loss: 0.534941\n",
      "epoch 56; iter: 0; batch classifier loss: 0.465645; batch adversarial loss: 0.507903\n",
      "epoch 57; iter: 0; batch classifier loss: 0.469743; batch adversarial loss: 0.489350\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418010; batch adversarial loss: 0.545611\n",
      "epoch 59; iter: 0; batch classifier loss: 0.380705; batch adversarial loss: 0.517497\n",
      "epoch 60; iter: 0; batch classifier loss: 0.490079; batch adversarial loss: 0.555257\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441872; batch adversarial loss: 0.535659\n",
      "epoch 62; iter: 0; batch classifier loss: 0.488264; batch adversarial loss: 0.581232\n",
      "epoch 63; iter: 0; batch classifier loss: 0.424366; batch adversarial loss: 0.544698\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454824; batch adversarial loss: 0.505468\n",
      "epoch 65; iter: 0; batch classifier loss: 0.452398; batch adversarial loss: 0.536182\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422609; batch adversarial loss: 0.553499\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392611; batch adversarial loss: 0.489204\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405734; batch adversarial loss: 0.580342\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378198; batch adversarial loss: 0.524775\n",
      "epoch 70; iter: 0; batch classifier loss: 0.432787; batch adversarial loss: 0.570366\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426868; batch adversarial loss: 0.554852\n",
      "epoch 72; iter: 0; batch classifier loss: 0.445906; batch adversarial loss: 0.499406\n",
      "epoch 73; iter: 0; batch classifier loss: 0.483761; batch adversarial loss: 0.582095\n",
      "epoch 74; iter: 0; batch classifier loss: 0.501071; batch adversarial loss: 0.500290\n",
      "epoch 75; iter: 0; batch classifier loss: 0.451536; batch adversarial loss: 0.516726\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390182; batch adversarial loss: 0.544050\n",
      "epoch 77; iter: 0; batch classifier loss: 0.466529; batch adversarial loss: 0.544663\n",
      "epoch 78; iter: 0; batch classifier loss: 0.471521; batch adversarial loss: 0.556552\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430102; batch adversarial loss: 0.536036\n",
      "epoch 80; iter: 0; batch classifier loss: 0.474684; batch adversarial loss: 0.536451\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402985; batch adversarial loss: 0.543937\n",
      "epoch 82; iter: 0; batch classifier loss: 0.473532; batch adversarial loss: 0.563198\n",
      "epoch 83; iter: 0; batch classifier loss: 0.426652; batch adversarial loss: 0.535223\n",
      "epoch 84; iter: 0; batch classifier loss: 0.459802; batch adversarial loss: 0.580499\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411250; batch adversarial loss: 0.573186\n",
      "epoch 86; iter: 0; batch classifier loss: 0.375205; batch adversarial loss: 0.555915\n",
      "epoch 87; iter: 0; batch classifier loss: 0.471830; batch adversarial loss: 0.517785\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408815; batch adversarial loss: 0.545959\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411049; batch adversarial loss: 0.507604\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444507; batch adversarial loss: 0.535286\n",
      "epoch 91; iter: 0; batch classifier loss: 0.452532; batch adversarial loss: 0.526271\n",
      "epoch 92; iter: 0; batch classifier loss: 0.444447; batch adversarial loss: 0.581793\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389653; batch adversarial loss: 0.537000\n",
      "epoch 94; iter: 0; batch classifier loss: 0.432541; batch adversarial loss: 0.516181\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396113; batch adversarial loss: 0.542578\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372435; batch adversarial loss: 0.589167\n",
      "epoch 97; iter: 0; batch classifier loss: 0.457470; batch adversarial loss: 0.543317\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370945; batch adversarial loss: 0.534719\n",
      "epoch 99; iter: 0; batch classifier loss: 0.506454; batch adversarial loss: 0.413939\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360360; batch adversarial loss: 0.498306\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379684; batch adversarial loss: 0.498988\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369134; batch adversarial loss: 0.626904\n",
      "epoch 103; iter: 0; batch classifier loss: 0.477962; batch adversarial loss: 0.563052\n",
      "epoch 104; iter: 0; batch classifier loss: 0.458671; batch adversarial loss: 0.563553\n",
      "epoch 105; iter: 0; batch classifier loss: 0.472378; batch adversarial loss: 0.499586\n",
      "epoch 106; iter: 0; batch classifier loss: 0.481354; batch adversarial loss: 0.508588\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392864; batch adversarial loss: 0.499877\n",
      "epoch 108; iter: 0; batch classifier loss: 0.494726; batch adversarial loss: 0.498616\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413673; batch adversarial loss: 0.525630\n",
      "epoch 110; iter: 0; batch classifier loss: 0.469255; batch adversarial loss: 0.545920\n",
      "epoch 111; iter: 0; batch classifier loss: 0.494250; batch adversarial loss: 0.609132\n",
      "epoch 112; iter: 0; batch classifier loss: 0.354068; batch adversarial loss: 0.507619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.480580; batch adversarial loss: 0.582345\n",
      "epoch 114; iter: 0; batch classifier loss: 0.493057; batch adversarial loss: 0.499118\n",
      "epoch 115; iter: 0; batch classifier loss: 0.454486; batch adversarial loss: 0.563632\n",
      "epoch 116; iter: 0; batch classifier loss: 0.478940; batch adversarial loss: 0.544549\n",
      "epoch 117; iter: 0; batch classifier loss: 0.458912; batch adversarial loss: 0.563604\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370529; batch adversarial loss: 0.533998\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399144; batch adversarial loss: 0.514900\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361378; batch adversarial loss: 0.574441\n",
      "epoch 121; iter: 0; batch classifier loss: 0.322867; batch adversarial loss: 0.535656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.376075; batch adversarial loss: 0.527266\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380666; batch adversarial loss: 0.571392\n",
      "epoch 124; iter: 0; batch classifier loss: 0.350843; batch adversarial loss: 0.536280\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410855; batch adversarial loss: 0.535982\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400808; batch adversarial loss: 0.571694\n",
      "epoch 127; iter: 0; batch classifier loss: 0.502397; batch adversarial loss: 0.545181\n",
      "epoch 128; iter: 0; batch classifier loss: 0.413517; batch adversarial loss: 0.544824\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394138; batch adversarial loss: 0.553475\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413942; batch adversarial loss: 0.562830\n",
      "epoch 131; iter: 0; batch classifier loss: 0.302702; batch adversarial loss: 0.581062\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401104; batch adversarial loss: 0.516751\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329795; batch adversarial loss: 0.572534\n",
      "epoch 134; iter: 0; batch classifier loss: 0.434017; batch adversarial loss: 0.553139\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351128; batch adversarial loss: 0.471404\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340913; batch adversarial loss: 0.526406\n",
      "epoch 137; iter: 0; batch classifier loss: 0.440780; batch adversarial loss: 0.599074\n",
      "epoch 138; iter: 0; batch classifier loss: 0.419195; batch adversarial loss: 0.471654\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377544; batch adversarial loss: 0.627413\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386138; batch adversarial loss: 0.562521\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357668; batch adversarial loss: 0.526325\n",
      "epoch 142; iter: 0; batch classifier loss: 0.414271; batch adversarial loss: 0.546070\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359580; batch adversarial loss: 0.620125\n",
      "epoch 144; iter: 0; batch classifier loss: 0.412669; batch adversarial loss: 0.553807\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390759; batch adversarial loss: 0.535074\n",
      "epoch 146; iter: 0; batch classifier loss: 0.472411; batch adversarial loss: 0.498788\n",
      "epoch 147; iter: 0; batch classifier loss: 0.380843; batch adversarial loss: 0.619812\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370103; batch adversarial loss: 0.563523\n",
      "epoch 149; iter: 0; batch classifier loss: 0.399019; batch adversarial loss: 0.570707\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409798; batch adversarial loss: 0.563292\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327427; batch adversarial loss: 0.469061\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383802; batch adversarial loss: 0.479879\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371752; batch adversarial loss: 0.554900\n",
      "epoch 154; iter: 0; batch classifier loss: 0.466937; batch adversarial loss: 0.590395\n",
      "epoch 155; iter: 0; batch classifier loss: 0.463780; batch adversarial loss: 0.541970\n",
      "epoch 156; iter: 0; batch classifier loss: 0.455124; batch adversarial loss: 0.558136\n",
      "epoch 157; iter: 0; batch classifier loss: 0.406678; batch adversarial loss: 0.452190\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382283; batch adversarial loss: 0.611130\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347845; batch adversarial loss: 0.563527\n",
      "epoch 160; iter: 0; batch classifier loss: 0.440458; batch adversarial loss: 0.516404\n",
      "epoch 161; iter: 0; batch classifier loss: 0.435166; batch adversarial loss: 0.508945\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401680; batch adversarial loss: 0.551199\n",
      "epoch 163; iter: 0; batch classifier loss: 0.368512; batch adversarial loss: 0.526763\n",
      "epoch 164; iter: 0; batch classifier loss: 0.425568; batch adversarial loss: 0.563851\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418841; batch adversarial loss: 0.590988\n",
      "epoch 166; iter: 0; batch classifier loss: 0.379345; batch adversarial loss: 0.553349\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334005; batch adversarial loss: 0.617530\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388772; batch adversarial loss: 0.625792\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369180; batch adversarial loss: 0.553569\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330264; batch adversarial loss: 0.598148\n",
      "epoch 171; iter: 0; batch classifier loss: 0.436623; batch adversarial loss: 0.517517\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395132; batch adversarial loss: 0.508782\n",
      "epoch 173; iter: 0; batch classifier loss: 0.415615; batch adversarial loss: 0.562873\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376158; batch adversarial loss: 0.599023\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400209; batch adversarial loss: 0.571429\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370847; batch adversarial loss: 0.552795\n",
      "epoch 177; iter: 0; batch classifier loss: 0.398894; batch adversarial loss: 0.525726\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381388; batch adversarial loss: 0.589487\n",
      "epoch 179; iter: 0; batch classifier loss: 0.338799; batch adversarial loss: 0.562995\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340891; batch adversarial loss: 0.488942\n",
      "epoch 181; iter: 0; batch classifier loss: 0.437368; batch adversarial loss: 0.488874\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364831; batch adversarial loss: 0.562868\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384693; batch adversarial loss: 0.535244\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401425; batch adversarial loss: 0.486957\n",
      "epoch 185; iter: 0; batch classifier loss: 0.425213; batch adversarial loss: 0.555313\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375544; batch adversarial loss: 0.611834\n",
      "epoch 187; iter: 0; batch classifier loss: 0.488233; batch adversarial loss: 0.600079\n",
      "epoch 188; iter: 0; batch classifier loss: 0.446582; batch adversarial loss: 0.606322\n",
      "epoch 189; iter: 0; batch classifier loss: 0.337522; batch adversarial loss: 0.508582\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312052; batch adversarial loss: 0.497210\n",
      "epoch 191; iter: 0; batch classifier loss: 0.432069; batch adversarial loss: 0.617208\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364380; batch adversarial loss: 0.592498\n",
      "epoch 193; iter: 0; batch classifier loss: 0.340602; batch adversarial loss: 0.562111\n",
      "epoch 194; iter: 0; batch classifier loss: 0.415437; batch adversarial loss: 0.543717\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346517; batch adversarial loss: 0.566927\n",
      "epoch 196; iter: 0; batch classifier loss: 0.418150; batch adversarial loss: 0.530321\n",
      "epoch 197; iter: 0; batch classifier loss: 0.376897; batch adversarial loss: 0.556012\n",
      "epoch 198; iter: 0; batch classifier loss: 0.400298; batch adversarial loss: 0.498708\n",
      "epoch 199; iter: 0; batch classifier loss: 0.413388; batch adversarial loss: 0.616999\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705053; batch adversarial loss: 0.766480\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582430; batch adversarial loss: 0.874061\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551051; batch adversarial loss: 0.821710\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612698; batch adversarial loss: 0.707327\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595710; batch adversarial loss: 0.724380\n",
      "epoch 5; iter: 0; batch classifier loss: 0.492427; batch adversarial loss: 0.658710\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585222; batch adversarial loss: 0.682598\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532752; batch adversarial loss: 0.671583\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553711; batch adversarial loss: 0.622458\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546870; batch adversarial loss: 0.611245\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522625; batch adversarial loss: 0.583410\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490791; batch adversarial loss: 0.595269\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569241; batch adversarial loss: 0.553043\n",
      "epoch 13; iter: 0; batch classifier loss: 0.587916; batch adversarial loss: 0.597622\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540711; batch adversarial loss: 0.543231\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483497; batch adversarial loss: 0.523393\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495414; batch adversarial loss: 0.572089\n",
      "epoch 17; iter: 0; batch classifier loss: 0.452649; batch adversarial loss: 0.523633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.482512; batch adversarial loss: 0.591238\n",
      "epoch 19; iter: 0; batch classifier loss: 0.453225; batch adversarial loss: 0.581196\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466938; batch adversarial loss: 0.555775\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515239; batch adversarial loss: 0.600879\n",
      "epoch 22; iter: 0; batch classifier loss: 0.556013; batch adversarial loss: 0.509055\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436481; batch adversarial loss: 0.541695\n",
      "epoch 24; iter: 0; batch classifier loss: 0.565849; batch adversarial loss: 0.609196\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467451; batch adversarial loss: 0.550245\n",
      "epoch 26; iter: 0; batch classifier loss: 0.396028; batch adversarial loss: 0.474985\n",
      "epoch 27; iter: 0; batch classifier loss: 0.543061; batch adversarial loss: 0.525246\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492166; batch adversarial loss: 0.527892\n",
      "epoch 29; iter: 0; batch classifier loss: 0.498724; batch adversarial loss: 0.535486\n",
      "epoch 30; iter: 0; batch classifier loss: 0.546877; batch adversarial loss: 0.535073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490538; batch adversarial loss: 0.538398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.399913; batch adversarial loss: 0.575686\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460314; batch adversarial loss: 0.531702\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434710; batch adversarial loss: 0.589893\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425243; batch adversarial loss: 0.481363\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447203; batch adversarial loss: 0.574697\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459859; batch adversarial loss: 0.556872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.534704; batch adversarial loss: 0.535481\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432070; batch adversarial loss: 0.570683\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426686; batch adversarial loss: 0.540477\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414952; batch adversarial loss: 0.545247\n",
      "epoch 42; iter: 0; batch classifier loss: 0.487156; batch adversarial loss: 0.566238\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430040; batch adversarial loss: 0.502742\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427613; batch adversarial loss: 0.485435\n",
      "epoch 45; iter: 0; batch classifier loss: 0.362888; batch adversarial loss: 0.508758\n",
      "epoch 46; iter: 0; batch classifier loss: 0.450379; batch adversarial loss: 0.520151\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401714; batch adversarial loss: 0.535089\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386473; batch adversarial loss: 0.506681\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405857; batch adversarial loss: 0.561150\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411789; batch adversarial loss: 0.574851\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432258; batch adversarial loss: 0.562699\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443100; batch adversarial loss: 0.543844\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389605; batch adversarial loss: 0.488934\n",
      "epoch 54; iter: 0; batch classifier loss: 0.363742; batch adversarial loss: 0.504498\n",
      "epoch 55; iter: 0; batch classifier loss: 0.561876; batch adversarial loss: 0.634611\n",
      "epoch 56; iter: 0; batch classifier loss: 0.348724; batch adversarial loss: 0.523950\n",
      "epoch 57; iter: 0; batch classifier loss: 0.377701; batch adversarial loss: 0.592521\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441216; batch adversarial loss: 0.524523\n",
      "epoch 59; iter: 0; batch classifier loss: 0.344259; batch adversarial loss: 0.477564\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384803; batch adversarial loss: 0.535603\n",
      "epoch 61; iter: 0; batch classifier loss: 0.437533; batch adversarial loss: 0.469974\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417637; batch adversarial loss: 0.563439\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421127; batch adversarial loss: 0.581714\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398415; batch adversarial loss: 0.507548\n",
      "epoch 65; iter: 0; batch classifier loss: 0.458734; batch adversarial loss: 0.488761\n",
      "epoch 66; iter: 0; batch classifier loss: 0.465827; batch adversarial loss: 0.515453\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417836; batch adversarial loss: 0.536409\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407381; batch adversarial loss: 0.554183\n",
      "epoch 69; iter: 0; batch classifier loss: 0.476377; batch adversarial loss: 0.488671\n",
      "epoch 70; iter: 0; batch classifier loss: 0.326727; batch adversarial loss: 0.592284\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423049; batch adversarial loss: 0.526226\n",
      "epoch 72; iter: 0; batch classifier loss: 0.354277; batch adversarial loss: 0.485738\n",
      "epoch 73; iter: 0; batch classifier loss: 0.467498; batch adversarial loss: 0.469483\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417256; batch adversarial loss: 0.545434\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382823; batch adversarial loss: 0.459417\n",
      "epoch 76; iter: 0; batch classifier loss: 0.341496; batch adversarial loss: 0.525256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.460556; batch adversarial loss: 0.535194\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400868; batch adversarial loss: 0.646822\n",
      "epoch 79; iter: 0; batch classifier loss: 0.414552; batch adversarial loss: 0.506958\n",
      "epoch 80; iter: 0; batch classifier loss: 0.331326; batch adversarial loss: 0.574368\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405212; batch adversarial loss: 0.554403\n",
      "epoch 82; iter: 0; batch classifier loss: 0.428372; batch adversarial loss: 0.563540\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360507; batch adversarial loss: 0.524832\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447707; batch adversarial loss: 0.545231\n",
      "epoch 85; iter: 0; batch classifier loss: 0.322144; batch adversarial loss: 0.591032\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399206; batch adversarial loss: 0.506414\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383389; batch adversarial loss: 0.517042\n",
      "epoch 88; iter: 0; batch classifier loss: 0.517714; batch adversarial loss: 0.553990\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350717; batch adversarial loss: 0.535318\n",
      "epoch 90; iter: 0; batch classifier loss: 0.431098; batch adversarial loss: 0.572248\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379261; batch adversarial loss: 0.545111\n",
      "epoch 92; iter: 0; batch classifier loss: 0.326383; batch adversarial loss: 0.554394\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381496; batch adversarial loss: 0.625585\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406491; batch adversarial loss: 0.599724\n",
      "epoch 95; iter: 0; batch classifier loss: 0.323165; batch adversarial loss: 0.546165\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390234; batch adversarial loss: 0.607910\n",
      "epoch 97; iter: 0; batch classifier loss: 0.342172; batch adversarial loss: 0.544160\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439616; batch adversarial loss: 0.582671\n",
      "epoch 99; iter: 0; batch classifier loss: 0.309982; batch adversarial loss: 0.564316\n",
      "epoch 100; iter: 0; batch classifier loss: 0.440320; batch adversarial loss: 0.525399\n",
      "epoch 101; iter: 0; batch classifier loss: 0.449875; batch adversarial loss: 0.533017\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359230; batch adversarial loss: 0.571424\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429470; batch adversarial loss: 0.532770\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384058; batch adversarial loss: 0.543812\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394506; batch adversarial loss: 0.498237\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379090; batch adversarial loss: 0.535133\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372456; batch adversarial loss: 0.571565\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392716; batch adversarial loss: 0.469142\n",
      "epoch 109; iter: 0; batch classifier loss: 0.335319; batch adversarial loss: 0.504308\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389857; batch adversarial loss: 0.497779\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386268; batch adversarial loss: 0.422172\n",
      "epoch 112; iter: 0; batch classifier loss: 0.337472; batch adversarial loss: 0.516416\n",
      "epoch 113; iter: 0; batch classifier loss: 0.443563; batch adversarial loss: 0.517144\n",
      "epoch 114; iter: 0; batch classifier loss: 0.451180; batch adversarial loss: 0.517754\n",
      "epoch 115; iter: 0; batch classifier loss: 0.337160; batch adversarial loss: 0.563141\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335123; batch adversarial loss: 0.526879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.302539; batch adversarial loss: 0.496953\n",
      "epoch 118; iter: 0; batch classifier loss: 0.362208; batch adversarial loss: 0.516562\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323234; batch adversarial loss: 0.534645\n",
      "epoch 120; iter: 0; batch classifier loss: 0.444765; batch adversarial loss: 0.507931\n",
      "epoch 121; iter: 0; batch classifier loss: 0.326834; batch adversarial loss: 0.618866\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363374; batch adversarial loss: 0.497474\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355177; batch adversarial loss: 0.497707\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405927; batch adversarial loss: 0.508125\n",
      "epoch 125; iter: 0; batch classifier loss: 0.419065; batch adversarial loss: 0.479607\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383185; batch adversarial loss: 0.570600\n",
      "epoch 127; iter: 0; batch classifier loss: 0.435720; batch adversarial loss: 0.535420\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387701; batch adversarial loss: 0.497513\n",
      "epoch 129; iter: 0; batch classifier loss: 0.363462; batch adversarial loss: 0.517463\n",
      "epoch 130; iter: 0; batch classifier loss: 0.432764; batch adversarial loss: 0.552155\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394073; batch adversarial loss: 0.534284\n",
      "epoch 132; iter: 0; batch classifier loss: 0.296530; batch adversarial loss: 0.570688\n",
      "epoch 133; iter: 0; batch classifier loss: 0.323078; batch adversarial loss: 0.526063\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367792; batch adversarial loss: 0.470595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369643; batch adversarial loss: 0.536100\n",
      "epoch 136; iter: 0; batch classifier loss: 0.303097; batch adversarial loss: 0.469770\n",
      "epoch 137; iter: 0; batch classifier loss: 0.404594; batch adversarial loss: 0.505637\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363312; batch adversarial loss: 0.524761\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389803; batch adversarial loss: 0.508897\n",
      "epoch 140; iter: 0; batch classifier loss: 0.414113; batch adversarial loss: 0.508689\n",
      "epoch 141; iter: 0; batch classifier loss: 0.473199; batch adversarial loss: 0.553923\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379365; batch adversarial loss: 0.617869\n",
      "epoch 143; iter: 0; batch classifier loss: 0.443686; batch adversarial loss: 0.527730\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312449; batch adversarial loss: 0.524716\n",
      "epoch 145; iter: 0; batch classifier loss: 0.409449; batch adversarial loss: 0.468165\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368516; batch adversarial loss: 0.631752\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327540; batch adversarial loss: 0.450421\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358603; batch adversarial loss: 0.555218\n",
      "epoch 149; iter: 0; batch classifier loss: 0.420641; batch adversarial loss: 0.571691\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379821; batch adversarial loss: 0.542560\n",
      "epoch 151; iter: 0; batch classifier loss: 0.360879; batch adversarial loss: 0.565088\n",
      "epoch 152; iter: 0; batch classifier loss: 0.393079; batch adversarial loss: 0.625221\n",
      "epoch 153; iter: 0; batch classifier loss: 0.382795; batch adversarial loss: 0.533736\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358803; batch adversarial loss: 0.533520\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307654; batch adversarial loss: 0.499707\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396315; batch adversarial loss: 0.551542\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399360; batch adversarial loss: 0.506762\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364009; batch adversarial loss: 0.555189\n",
      "epoch 159; iter: 0; batch classifier loss: 0.381333; batch adversarial loss: 0.554133\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320722; batch adversarial loss: 0.479252\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335209; batch adversarial loss: 0.580409\n",
      "epoch 162; iter: 0; batch classifier loss: 0.422112; batch adversarial loss: 0.570869\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339469; batch adversarial loss: 0.635697\n",
      "epoch 164; iter: 0; batch classifier loss: 0.314219; batch adversarial loss: 0.524093\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379589; batch adversarial loss: 0.594675\n",
      "epoch 166; iter: 0; batch classifier loss: 0.452658; batch adversarial loss: 0.666886\n",
      "epoch 167; iter: 0; batch classifier loss: 0.277998; batch adversarial loss: 0.564721\n",
      "epoch 168; iter: 0; batch classifier loss: 0.384831; batch adversarial loss: 0.430066\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330524; batch adversarial loss: 0.527992\n",
      "epoch 170; iter: 0; batch classifier loss: 0.279084; batch adversarial loss: 0.516770\n",
      "epoch 171; iter: 0; batch classifier loss: 0.314408; batch adversarial loss: 0.488657\n",
      "epoch 172; iter: 0; batch classifier loss: 0.311325; batch adversarial loss: 0.563497\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342227; batch adversarial loss: 0.524450\n",
      "epoch 174; iter: 0; batch classifier loss: 0.406257; batch adversarial loss: 0.470208\n",
      "epoch 175; iter: 0; batch classifier loss: 0.300758; batch adversarial loss: 0.506855\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396758; batch adversarial loss: 0.571428\n",
      "epoch 177; iter: 0; batch classifier loss: 0.296089; batch adversarial loss: 0.574638\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357732; batch adversarial loss: 0.554566\n",
      "epoch 179; iter: 0; batch classifier loss: 0.419891; batch adversarial loss: 0.581270\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343707; batch adversarial loss: 0.589818\n",
      "epoch 181; iter: 0; batch classifier loss: 0.284473; batch adversarial loss: 0.545990\n",
      "epoch 182; iter: 0; batch classifier loss: 0.305558; batch adversarial loss: 0.639339\n",
      "epoch 183; iter: 0; batch classifier loss: 0.454994; batch adversarial loss: 0.488604\n",
      "epoch 184; iter: 0; batch classifier loss: 0.435554; batch adversarial loss: 0.552697\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365634; batch adversarial loss: 0.497062\n",
      "epoch 186; iter: 0; batch classifier loss: 0.419172; batch adversarial loss: 0.468352\n",
      "epoch 187; iter: 0; batch classifier loss: 0.424953; batch adversarial loss: 0.613142\n",
      "epoch 188; iter: 0; batch classifier loss: 0.409834; batch adversarial loss: 0.611220\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369046; batch adversarial loss: 0.582142\n",
      "epoch 190; iter: 0; batch classifier loss: 0.270638; batch adversarial loss: 0.556402\n",
      "epoch 191; iter: 0; batch classifier loss: 0.375461; batch adversarial loss: 0.571313\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337279; batch adversarial loss: 0.553615\n",
      "epoch 193; iter: 0; batch classifier loss: 0.291890; batch adversarial loss: 0.580209\n",
      "epoch 194; iter: 0; batch classifier loss: 0.283288; batch adversarial loss: 0.505762\n",
      "epoch 195; iter: 0; batch classifier loss: 0.380061; batch adversarial loss: 0.610041\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372548; batch adversarial loss: 0.546599\n",
      "epoch 197; iter: 0; batch classifier loss: 0.319617; batch adversarial loss: 0.552684\n",
      "epoch 198; iter: 0; batch classifier loss: 0.307818; batch adversarial loss: 0.562096\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350714; batch adversarial loss: 0.533489\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731931; batch adversarial loss: 0.826730\n",
      "epoch 1; iter: 0; batch classifier loss: 0.695826; batch adversarial loss: 0.827851\n",
      "epoch 2; iter: 0; batch classifier loss: 0.760540; batch adversarial loss: 0.816558\n",
      "epoch 3; iter: 0; batch classifier loss: 0.766214; batch adversarial loss: 0.751397\n",
      "epoch 4; iter: 0; batch classifier loss: 0.713568; batch adversarial loss: 0.692779\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548542; batch adversarial loss: 0.641985\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596159; batch adversarial loss: 0.628772\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588703; batch adversarial loss: 0.611692\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561869; batch adversarial loss: 0.580371\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534726; batch adversarial loss: 0.608077\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592519; batch adversarial loss: 0.626844\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547109; batch adversarial loss: 0.566651\n",
      "epoch 12; iter: 0; batch classifier loss: 0.613404; batch adversarial loss: 0.529096\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530806; batch adversarial loss: 0.580874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.493076; batch adversarial loss: 0.537535\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512754; batch adversarial loss: 0.568453\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482362; batch adversarial loss: 0.586729\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497524; batch adversarial loss: 0.570050\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555992; batch adversarial loss: 0.533716\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507719; batch adversarial loss: 0.502434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484518; batch adversarial loss: 0.570102\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519542; batch adversarial loss: 0.539244\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512416; batch adversarial loss: 0.564718\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538448; batch adversarial loss: 0.630344\n",
      "epoch 24; iter: 0; batch classifier loss: 0.622624; batch adversarial loss: 0.578736\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530173; batch adversarial loss: 0.565395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428553; batch adversarial loss: 0.485312\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465298; batch adversarial loss: 0.577095\n",
      "epoch 28; iter: 0; batch classifier loss: 0.509600; batch adversarial loss: 0.581022\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481289; batch adversarial loss: 0.638341\n",
      "epoch 30; iter: 0; batch classifier loss: 0.423854; batch adversarial loss: 0.463421\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496795; batch adversarial loss: 0.584700\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466706; batch adversarial loss: 0.591876\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509352; batch adversarial loss: 0.590681\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414583; batch adversarial loss: 0.573323\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475201; batch adversarial loss: 0.547240\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379649; batch adversarial loss: 0.546363\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417726; batch adversarial loss: 0.603420\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482265; batch adversarial loss: 0.520383\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458371; batch adversarial loss: 0.536730\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422092; batch adversarial loss: 0.504264\n",
      "epoch 41; iter: 0; batch classifier loss: 0.488749; batch adversarial loss: 0.558730\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480381; batch adversarial loss: 0.495515\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399378; batch adversarial loss: 0.631248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429775; batch adversarial loss: 0.585138\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413084; batch adversarial loss: 0.536276\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396954; batch adversarial loss: 0.578011\n",
      "epoch 47; iter: 0; batch classifier loss: 0.543549; batch adversarial loss: 0.605760\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415239; batch adversarial loss: 0.563807\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429735; batch adversarial loss: 0.609047\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448485; batch adversarial loss: 0.526949\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392972; batch adversarial loss: 0.509359\n",
      "epoch 52; iter: 0; batch classifier loss: 0.536901; batch adversarial loss: 0.527478\n",
      "epoch 53; iter: 0; batch classifier loss: 0.475006; batch adversarial loss: 0.599658\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450486; batch adversarial loss: 0.526020\n",
      "epoch 55; iter: 0; batch classifier loss: 0.375284; batch adversarial loss: 0.545029\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415388; batch adversarial loss: 0.535554\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435070; batch adversarial loss: 0.500232\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424610; batch adversarial loss: 0.498319\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357355; batch adversarial loss: 0.534130\n",
      "epoch 60; iter: 0; batch classifier loss: 0.491665; batch adversarial loss: 0.515071\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421327; batch adversarial loss: 0.518309\n",
      "epoch 62; iter: 0; batch classifier loss: 0.372996; batch adversarial loss: 0.553045\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449913; batch adversarial loss: 0.508782\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384656; batch adversarial loss: 0.579911\n",
      "epoch 65; iter: 0; batch classifier loss: 0.476872; batch adversarial loss: 0.562885\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397321; batch adversarial loss: 0.570256\n",
      "epoch 67; iter: 0; batch classifier loss: 0.485383; batch adversarial loss: 0.562606\n",
      "epoch 68; iter: 0; batch classifier loss: 0.433573; batch adversarial loss: 0.562347\n",
      "epoch 69; iter: 0; batch classifier loss: 0.399900; batch adversarial loss: 0.527322\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447700; batch adversarial loss: 0.518053\n",
      "epoch 71; iter: 0; batch classifier loss: 0.415337; batch adversarial loss: 0.553371\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376752; batch adversarial loss: 0.534538\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400079; batch adversarial loss: 0.580279\n",
      "epoch 74; iter: 0; batch classifier loss: 0.450185; batch adversarial loss: 0.535216\n",
      "epoch 75; iter: 0; batch classifier loss: 0.474678; batch adversarial loss: 0.562116\n",
      "epoch 76; iter: 0; batch classifier loss: 0.456739; batch adversarial loss: 0.571552\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389704; batch adversarial loss: 0.562620\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389688; batch adversarial loss: 0.499829\n",
      "epoch 79; iter: 0; batch classifier loss: 0.336121; batch adversarial loss: 0.481757\n",
      "epoch 80; iter: 0; batch classifier loss: 0.359652; batch adversarial loss: 0.571200\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368387; batch adversarial loss: 0.509638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406085; batch adversarial loss: 0.562474\n",
      "epoch 83; iter: 0; batch classifier loss: 0.306213; batch adversarial loss: 0.509435\n",
      "epoch 84; iter: 0; batch classifier loss: 0.438078; batch adversarial loss: 0.482487\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456726; batch adversarial loss: 0.517902\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405714; batch adversarial loss: 0.490757\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364390; batch adversarial loss: 0.526138\n",
      "epoch 88; iter: 0; batch classifier loss: 0.477113; batch adversarial loss: 0.545333\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422413; batch adversarial loss: 0.680135\n",
      "epoch 90; iter: 0; batch classifier loss: 0.332758; batch adversarial loss: 0.571722\n",
      "epoch 91; iter: 0; batch classifier loss: 0.424330; batch adversarial loss: 0.500255\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385504; batch adversarial loss: 0.598004\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386180; batch adversarial loss: 0.580194\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383108; batch adversarial loss: 0.562422\n",
      "epoch 95; iter: 0; batch classifier loss: 0.370836; batch adversarial loss: 0.625238\n",
      "epoch 96; iter: 0; batch classifier loss: 0.455792; batch adversarial loss: 0.526313\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375418; batch adversarial loss: 0.481948\n",
      "epoch 98; iter: 0; batch classifier loss: 0.419777; batch adversarial loss: 0.535034\n",
      "epoch 99; iter: 0; batch classifier loss: 0.370128; batch adversarial loss: 0.534655\n",
      "epoch 100; iter: 0; batch classifier loss: 0.377892; batch adversarial loss: 0.527451\n",
      "epoch 101; iter: 0; batch classifier loss: 0.349541; batch adversarial loss: 0.579590\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392669; batch adversarial loss: 0.518369\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403693; batch adversarial loss: 0.561770\n",
      "epoch 104; iter: 0; batch classifier loss: 0.443510; batch adversarial loss: 0.509491\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351411; batch adversarial loss: 0.518179\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380733; batch adversarial loss: 0.509485\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382331; batch adversarial loss: 0.482930\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377853; batch adversarial loss: 0.597900\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412613; batch adversarial loss: 0.535957\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350357; batch adversarial loss: 0.571447\n",
      "epoch 111; iter: 0; batch classifier loss: 0.360566; batch adversarial loss: 0.562248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.400608; batch adversarial loss: 0.535583\n",
      "epoch 113; iter: 0; batch classifier loss: 0.361143; batch adversarial loss: 0.553580\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350753; batch adversarial loss: 0.642472\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354668; batch adversarial loss: 0.534930\n",
      "epoch 116; iter: 0; batch classifier loss: 0.341573; batch adversarial loss: 0.486001\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346045; batch adversarial loss: 0.578594\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352982; batch adversarial loss: 0.496794\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364579; batch adversarial loss: 0.553648\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338788; batch adversarial loss: 0.519003\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403826; batch adversarial loss: 0.553729\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395645; batch adversarial loss: 0.527634\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360036; batch adversarial loss: 0.545937\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326497; batch adversarial loss: 0.482973\n",
      "epoch 125; iter: 0; batch classifier loss: 0.330682; batch adversarial loss: 0.527147\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368979; batch adversarial loss: 0.588749\n",
      "epoch 127; iter: 0; batch classifier loss: 0.306819; batch adversarial loss: 0.535961\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325912; batch adversarial loss: 0.597875\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342980; batch adversarial loss: 0.544526\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395137; batch adversarial loss: 0.446692\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371214; batch adversarial loss: 0.580545\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320070; batch adversarial loss: 0.544740\n",
      "epoch 133; iter: 0; batch classifier loss: 0.320048; batch adversarial loss: 0.607202\n",
      "epoch 134; iter: 0; batch classifier loss: 0.347843; batch adversarial loss: 0.571721\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343729; batch adversarial loss: 0.544396\n",
      "epoch 136; iter: 0; batch classifier loss: 0.427726; batch adversarial loss: 0.571411\n",
      "epoch 137; iter: 0; batch classifier loss: 0.411087; batch adversarial loss: 0.562421\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348296; batch adversarial loss: 0.535853\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388911; batch adversarial loss: 0.553484\n",
      "epoch 140; iter: 0; batch classifier loss: 0.289982; batch adversarial loss: 0.517510\n",
      "epoch 141; iter: 0; batch classifier loss: 0.299427; batch adversarial loss: 0.464252\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353015; batch adversarial loss: 0.562581\n",
      "epoch 143; iter: 0; batch classifier loss: 0.420150; batch adversarial loss: 0.499946\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408335; batch adversarial loss: 0.526660\n",
      "epoch 145; iter: 0; batch classifier loss: 0.300881; batch adversarial loss: 0.508548\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332614; batch adversarial loss: 0.615942\n",
      "epoch 147; iter: 0; batch classifier loss: 0.370672; batch adversarial loss: 0.589528\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323489; batch adversarial loss: 0.624687\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378343; batch adversarial loss: 0.472931\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413104; batch adversarial loss: 0.481503\n",
      "epoch 151; iter: 0; batch classifier loss: 0.398503; batch adversarial loss: 0.471931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387286; batch adversarial loss: 0.554501\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328835; batch adversarial loss: 0.562464\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393084; batch adversarial loss: 0.544439\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354994; batch adversarial loss: 0.526467\n",
      "epoch 156; iter: 0; batch classifier loss: 0.284663; batch adversarial loss: 0.562396\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368445; batch adversarial loss: 0.500712\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341808; batch adversarial loss: 0.534389\n",
      "epoch 159; iter: 0; batch classifier loss: 0.396128; batch adversarial loss: 0.499990\n",
      "epoch 160; iter: 0; batch classifier loss: 0.482881; batch adversarial loss: 0.544854\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372424; batch adversarial loss: 0.517457\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361206; batch adversarial loss: 0.537076\n",
      "epoch 163; iter: 0; batch classifier loss: 0.394388; batch adversarial loss: 0.535682\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350985; batch adversarial loss: 0.554362\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353594; batch adversarial loss: 0.509194\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359019; batch adversarial loss: 0.492205\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345675; batch adversarial loss: 0.607731\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333029; batch adversarial loss: 0.607250\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350014; batch adversarial loss: 0.535925\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378184; batch adversarial loss: 0.571148\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375708; batch adversarial loss: 0.536058\n",
      "epoch 172; iter: 0; batch classifier loss: 0.301864; batch adversarial loss: 0.597776\n",
      "epoch 173; iter: 0; batch classifier loss: 0.298751; batch adversarial loss: 0.589538\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356695; batch adversarial loss: 0.616066\n",
      "epoch 175; iter: 0; batch classifier loss: 0.353800; batch adversarial loss: 0.499930\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395085; batch adversarial loss: 0.562799\n",
      "epoch 177; iter: 0; batch classifier loss: 0.268840; batch adversarial loss: 0.562962\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381052; batch adversarial loss: 0.527333\n",
      "epoch 179; iter: 0; batch classifier loss: 0.408261; batch adversarial loss: 0.473230\n",
      "epoch 180; iter: 0; batch classifier loss: 0.280742; batch adversarial loss: 0.553663\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365520; batch adversarial loss: 0.535425\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339616; batch adversarial loss: 0.526987\n",
      "epoch 183; iter: 0; batch classifier loss: 0.381765; batch adversarial loss: 0.544638\n",
      "epoch 184; iter: 0; batch classifier loss: 0.429463; batch adversarial loss: 0.562962\n",
      "epoch 185; iter: 0; batch classifier loss: 0.339585; batch adversarial loss: 0.464319\n",
      "epoch 186; iter: 0; batch classifier loss: 0.449276; batch adversarial loss: 0.544686\n",
      "epoch 187; iter: 0; batch classifier loss: 0.293074; batch adversarial loss: 0.534907\n",
      "epoch 188; iter: 0; batch classifier loss: 0.403309; batch adversarial loss: 0.490522\n",
      "epoch 189; iter: 0; batch classifier loss: 0.301572; batch adversarial loss: 0.526320\n",
      "epoch 190; iter: 0; batch classifier loss: 0.382341; batch adversarial loss: 0.544877\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339621; batch adversarial loss: 0.562653\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363005; batch adversarial loss: 0.544487\n",
      "epoch 193; iter: 0; batch classifier loss: 0.415861; batch adversarial loss: 0.553226\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351690; batch adversarial loss: 0.535229\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381751; batch adversarial loss: 0.446480\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321416; batch adversarial loss: 0.535314\n",
      "epoch 197; iter: 0; batch classifier loss: 0.400900; batch adversarial loss: 0.535762\n",
      "epoch 198; iter: 0; batch classifier loss: 0.277667; batch adversarial loss: 0.571775\n",
      "epoch 199; iter: 0; batch classifier loss: 0.275202; batch adversarial loss: 0.481669\n",
      "epoch 0; iter: 0; batch classifier loss: 0.791009; batch adversarial loss: 0.706060\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586768; batch adversarial loss: 0.670032\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621972; batch adversarial loss: 0.662060\n",
      "epoch 3; iter: 0; batch classifier loss: 0.599398; batch adversarial loss: 0.617521\n",
      "epoch 4; iter: 0; batch classifier loss: 0.508884; batch adversarial loss: 0.604212\n",
      "epoch 5; iter: 0; batch classifier loss: 0.513595; batch adversarial loss: 0.596887\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501391; batch adversarial loss: 0.580940\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583479; batch adversarial loss: 0.580595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.551811; batch adversarial loss: 0.564645\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511142; batch adversarial loss: 0.599056\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508395; batch adversarial loss: 0.584215\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519423; batch adversarial loss: 0.557581\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489028; batch adversarial loss: 0.581467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583883; batch adversarial loss: 0.606596\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515454; batch adversarial loss: 0.677376\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521626; batch adversarial loss: 0.545665\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452634; batch adversarial loss: 0.572768\n",
      "epoch 17; iter: 0; batch classifier loss: 0.585949; batch adversarial loss: 0.623004\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458112; batch adversarial loss: 0.537604\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508594; batch adversarial loss: 0.533588\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465384; batch adversarial loss: 0.565902\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511811; batch adversarial loss: 0.569014\n",
      "epoch 22; iter: 0; batch classifier loss: 0.434676; batch adversarial loss: 0.551561\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400696; batch adversarial loss: 0.592336\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448802; batch adversarial loss: 0.536242\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496002; batch adversarial loss: 0.536867\n",
      "epoch 26; iter: 0; batch classifier loss: 0.488430; batch adversarial loss: 0.518308\n",
      "epoch 27; iter: 0; batch classifier loss: 0.383386; batch adversarial loss: 0.580234\n",
      "epoch 28; iter: 0; batch classifier loss: 0.428246; batch adversarial loss: 0.514592\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482131; batch adversarial loss: 0.529860\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477296; batch adversarial loss: 0.579167\n",
      "epoch 31; iter: 0; batch classifier loss: 0.426825; batch adversarial loss: 0.527809\n",
      "epoch 32; iter: 0; batch classifier loss: 0.362533; batch adversarial loss: 0.553095\n",
      "epoch 33; iter: 0; batch classifier loss: 0.410354; batch adversarial loss: 0.569725\n",
      "epoch 34; iter: 0; batch classifier loss: 0.465314; batch adversarial loss: 0.536360\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426578; batch adversarial loss: 0.622978\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466949; batch adversarial loss: 0.562171\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421180; batch adversarial loss: 0.553655\n",
      "epoch 38; iter: 0; batch classifier loss: 0.538385; batch adversarial loss: 0.472303\n",
      "epoch 39; iter: 0; batch classifier loss: 0.522456; batch adversarial loss: 0.499298\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424644; batch adversarial loss: 0.507402\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474836; batch adversarial loss: 0.599321\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448767; batch adversarial loss: 0.535584\n",
      "epoch 43; iter: 0; batch classifier loss: 0.519494; batch adversarial loss: 0.507692\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388990; batch adversarial loss: 0.524772\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412643; batch adversarial loss: 0.525918\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474825; batch adversarial loss: 0.535461\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476888; batch adversarial loss: 0.443257\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457815; batch adversarial loss: 0.616834\n",
      "epoch 49; iter: 0; batch classifier loss: 0.520961; batch adversarial loss: 0.590348\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441754; batch adversarial loss: 0.499338\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392490; batch adversarial loss: 0.545067\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423936; batch adversarial loss: 0.497968\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458731; batch adversarial loss: 0.562969\n",
      "epoch 54; iter: 0; batch classifier loss: 0.484436; batch adversarial loss: 0.516799\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460433; batch adversarial loss: 0.563140\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452170; batch adversarial loss: 0.655894\n",
      "epoch 57; iter: 0; batch classifier loss: 0.367872; batch adversarial loss: 0.535652\n",
      "epoch 58; iter: 0; batch classifier loss: 0.503837; batch adversarial loss: 0.488541\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378451; batch adversarial loss: 0.554421\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390512; batch adversarial loss: 0.563067\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416402; batch adversarial loss: 0.544642\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400682; batch adversarial loss: 0.498182\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371600; batch adversarial loss: 0.572393\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423510; batch adversarial loss: 0.461131\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400429; batch adversarial loss: 0.571736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404613; batch adversarial loss: 0.452781\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428300; batch adversarial loss: 0.608804\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421110; batch adversarial loss: 0.544579\n",
      "epoch 69; iter: 0; batch classifier loss: 0.469702; batch adversarial loss: 0.598741\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402345; batch adversarial loss: 0.600148\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372896; batch adversarial loss: 0.582349\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358609; batch adversarial loss: 0.572673\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405627; batch adversarial loss: 0.619987\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465737; batch adversarial loss: 0.525689\n",
      "epoch 75; iter: 0; batch classifier loss: 0.410787; batch adversarial loss: 0.515930\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364851; batch adversarial loss: 0.590957\n",
      "epoch 77; iter: 0; batch classifier loss: 0.482367; batch adversarial loss: 0.533681\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358998; batch adversarial loss: 0.637626\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394796; batch adversarial loss: 0.526043\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399807; batch adversarial loss: 0.618113\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426936; batch adversarial loss: 0.545169\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390096; batch adversarial loss: 0.478847\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394267; batch adversarial loss: 0.516281\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449213; batch adversarial loss: 0.516729\n",
      "epoch 85; iter: 0; batch classifier loss: 0.328104; batch adversarial loss: 0.516316\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412462; batch adversarial loss: 0.590654\n",
      "epoch 87; iter: 0; batch classifier loss: 0.339052; batch adversarial loss: 0.563253\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417655; batch adversarial loss: 0.507103\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394529; batch adversarial loss: 0.507121\n",
      "epoch 90; iter: 0; batch classifier loss: 0.382710; batch adversarial loss: 0.544626\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361010; batch adversarial loss: 0.535176\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379652; batch adversarial loss: 0.618987\n",
      "epoch 93; iter: 0; batch classifier loss: 0.359569; batch adversarial loss: 0.497733\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424996; batch adversarial loss: 0.553663\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416175; batch adversarial loss: 0.507124\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403779; batch adversarial loss: 0.525860\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374125; batch adversarial loss: 0.535305\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368864; batch adversarial loss: 0.488991\n",
      "epoch 99; iter: 0; batch classifier loss: 0.315358; batch adversarial loss: 0.636940\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370179; batch adversarial loss: 0.525979\n",
      "epoch 101; iter: 0; batch classifier loss: 0.465480; batch adversarial loss: 0.507178\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402607; batch adversarial loss: 0.572658\n",
      "epoch 103; iter: 0; batch classifier loss: 0.478856; batch adversarial loss: 0.525836\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348898; batch adversarial loss: 0.571701\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388420; batch adversarial loss: 0.581145\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352597; batch adversarial loss: 0.495884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.325482; batch adversarial loss: 0.487498\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369932; batch adversarial loss: 0.543487\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400317; batch adversarial loss: 0.618155\n",
      "epoch 110; iter: 0; batch classifier loss: 0.394826; batch adversarial loss: 0.554597\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382376; batch adversarial loss: 0.534786\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374167; batch adversarial loss: 0.573748\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421218; batch adversarial loss: 0.507789\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374783; batch adversarial loss: 0.526872\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372715; batch adversarial loss: 0.554448\n",
      "epoch 116; iter: 0; batch classifier loss: 0.414939; batch adversarial loss: 0.536901\n",
      "epoch 117; iter: 0; batch classifier loss: 0.328455; batch adversarial loss: 0.561746\n",
      "epoch 118; iter: 0; batch classifier loss: 0.430172; batch adversarial loss: 0.508258\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371793; batch adversarial loss: 0.536491\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382598; batch adversarial loss: 0.545021\n",
      "epoch 121; iter: 0; batch classifier loss: 0.342455; batch adversarial loss: 0.599440\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346237; batch adversarial loss: 0.535394\n",
      "epoch 123; iter: 0; batch classifier loss: 0.337366; batch adversarial loss: 0.618102\n",
      "epoch 124; iter: 0; batch classifier loss: 0.441110; batch adversarial loss: 0.507327\n",
      "epoch 125; iter: 0; batch classifier loss: 0.477448; batch adversarial loss: 0.562218\n",
      "epoch 126; iter: 0; batch classifier loss: 0.349736; batch adversarial loss: 0.581026\n",
      "epoch 127; iter: 0; batch classifier loss: 0.285309; batch adversarial loss: 0.562680\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369541; batch adversarial loss: 0.581657\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364251; batch adversarial loss: 0.535094\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365486; batch adversarial loss: 0.534992\n",
      "epoch 131; iter: 0; batch classifier loss: 0.296659; batch adversarial loss: 0.544399\n",
      "epoch 132; iter: 0; batch classifier loss: 0.383106; batch adversarial loss: 0.498187\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410594; batch adversarial loss: 0.572298\n",
      "epoch 134; iter: 0; batch classifier loss: 0.405847; batch adversarial loss: 0.571869\n",
      "epoch 135; iter: 0; batch classifier loss: 0.479673; batch adversarial loss: 0.423436\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378440; batch adversarial loss: 0.581936\n",
      "epoch 137; iter: 0; batch classifier loss: 0.315778; batch adversarial loss: 0.544388\n",
      "epoch 138; iter: 0; batch classifier loss: 0.352097; batch adversarial loss: 0.572489\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352410; batch adversarial loss: 0.553869\n",
      "epoch 140; iter: 0; batch classifier loss: 0.472038; batch adversarial loss: 0.572332\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365331; batch adversarial loss: 0.562884\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418616; batch adversarial loss: 0.544234\n",
      "epoch 143; iter: 0; batch classifier loss: 0.418276; batch adversarial loss: 0.571881\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376264; batch adversarial loss: 0.488508\n",
      "epoch 145; iter: 0; batch classifier loss: 0.337456; batch adversarial loss: 0.454509\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395967; batch adversarial loss: 0.479897\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350283; batch adversarial loss: 0.497420\n",
      "epoch 148; iter: 0; batch classifier loss: 0.299267; batch adversarial loss: 0.535072\n",
      "epoch 149; iter: 0; batch classifier loss: 0.428851; batch adversarial loss: 0.536237\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342596; batch adversarial loss: 0.574538\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382360; batch adversarial loss: 0.592004\n",
      "epoch 152; iter: 0; batch classifier loss: 0.358497; batch adversarial loss: 0.527296\n",
      "epoch 153; iter: 0; batch classifier loss: 0.331746; batch adversarial loss: 0.498243\n",
      "epoch 154; iter: 0; batch classifier loss: 0.347252; batch adversarial loss: 0.572455\n",
      "epoch 155; iter: 0; batch classifier loss: 0.301274; batch adversarial loss: 0.572592\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363063; batch adversarial loss: 0.507020\n",
      "epoch 157; iter: 0; batch classifier loss: 0.308685; batch adversarial loss: 0.480098\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366844; batch adversarial loss: 0.479269\n",
      "epoch 159; iter: 0; batch classifier loss: 0.395222; batch adversarial loss: 0.431869\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365554; batch adversarial loss: 0.562851\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356552; batch adversarial loss: 0.646959\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397455; batch adversarial loss: 0.535312\n",
      "epoch 163; iter: 0; batch classifier loss: 0.420363; batch adversarial loss: 0.572554\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337409; batch adversarial loss: 0.544532\n",
      "epoch 165; iter: 0; batch classifier loss: 0.384370; batch adversarial loss: 0.525849\n",
      "epoch 166; iter: 0; batch classifier loss: 0.317177; batch adversarial loss: 0.525847\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358406; batch adversarial loss: 0.535164\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323117; batch adversarial loss: 0.572487\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379991; batch adversarial loss: 0.544376\n",
      "epoch 170; iter: 0; batch classifier loss: 0.389258; batch adversarial loss: 0.553807\n",
      "epoch 171; iter: 0; batch classifier loss: 0.298819; batch adversarial loss: 0.544426\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381903; batch adversarial loss: 0.553965\n",
      "epoch 173; iter: 0; batch classifier loss: 0.352190; batch adversarial loss: 0.553486\n",
      "epoch 174; iter: 0; batch classifier loss: 0.410111; batch adversarial loss: 0.581630\n",
      "epoch 175; iter: 0; batch classifier loss: 0.410695; batch adversarial loss: 0.478161\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380476; batch adversarial loss: 0.525206\n",
      "epoch 177; iter: 0; batch classifier loss: 0.394578; batch adversarial loss: 0.627979\n",
      "epoch 178; iter: 0; batch classifier loss: 0.388431; batch adversarial loss: 0.487544\n",
      "epoch 179; iter: 0; batch classifier loss: 0.319048; batch adversarial loss: 0.479082\n",
      "epoch 180; iter: 0; batch classifier loss: 0.261111; batch adversarial loss: 0.562926\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370683; batch adversarial loss: 0.554938\n",
      "epoch 182; iter: 0; batch classifier loss: 0.293119; batch adversarial loss: 0.515852\n",
      "epoch 183; iter: 0; batch classifier loss: 0.320177; batch adversarial loss: 0.470237\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389967; batch adversarial loss: 0.516604\n",
      "epoch 185; iter: 0; batch classifier loss: 0.296345; batch adversarial loss: 0.544939\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386335; batch adversarial loss: 0.516909\n",
      "epoch 187; iter: 0; batch classifier loss: 0.447596; batch adversarial loss: 0.608975\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330820; batch adversarial loss: 0.562987\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369853; batch adversarial loss: 0.553838\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336259; batch adversarial loss: 0.563410\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344064; batch adversarial loss: 0.507935\n",
      "epoch 192; iter: 0; batch classifier loss: 0.447737; batch adversarial loss: 0.507283\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388226; batch adversarial loss: 0.553454\n",
      "epoch 194; iter: 0; batch classifier loss: 0.309527; batch adversarial loss: 0.636240\n",
      "epoch 195; iter: 0; batch classifier loss: 0.331997; batch adversarial loss: 0.470873\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370688; batch adversarial loss: 0.563149\n",
      "epoch 197; iter: 0; batch classifier loss: 0.412175; batch adversarial loss: 0.544973\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404137; batch adversarial loss: 0.498132\n",
      "epoch 199; iter: 0; batch classifier loss: 0.267491; batch adversarial loss: 0.553845\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681224; batch adversarial loss: 0.602246\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537013; batch adversarial loss: 0.662944\n",
      "epoch 2; iter: 0; batch classifier loss: 0.541117; batch adversarial loss: 0.633317\n",
      "epoch 3; iter: 0; batch classifier loss: 0.495934; batch adversarial loss: 0.633880\n",
      "epoch 4; iter: 0; batch classifier loss: 0.611336; batch adversarial loss: 0.602726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.611354; batch adversarial loss: 0.623070\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591320; batch adversarial loss: 0.612247\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565678; batch adversarial loss: 0.583062\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516318; batch adversarial loss: 0.585533\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585603; batch adversarial loss: 0.567556\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562256; batch adversarial loss: 0.514206\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490962; batch adversarial loss: 0.610390\n",
      "epoch 12; iter: 0; batch classifier loss: 0.632293; batch adversarial loss: 0.542556\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554306; batch adversarial loss: 0.577757\n",
      "epoch 14; iter: 0; batch classifier loss: 0.587665; batch adversarial loss: 0.494419\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508879; batch adversarial loss: 0.570964\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492546; batch adversarial loss: 0.565906\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485546; batch adversarial loss: 0.523258\n",
      "epoch 18; iter: 0; batch classifier loss: 0.431017; batch adversarial loss: 0.557603\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485503; batch adversarial loss: 0.530153\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480202; batch adversarial loss: 0.593209\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502452; batch adversarial loss: 0.595868\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441634; batch adversarial loss: 0.515787\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463014; batch adversarial loss: 0.553976\n",
      "epoch 24; iter: 0; batch classifier loss: 0.578182; batch adversarial loss: 0.555257\n",
      "epoch 25; iter: 0; batch classifier loss: 0.464012; batch adversarial loss: 0.468559\n",
      "epoch 26; iter: 0; batch classifier loss: 0.553504; batch adversarial loss: 0.529989\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434159; batch adversarial loss: 0.477368\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450764; batch adversarial loss: 0.518424\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450655; batch adversarial loss: 0.537222\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504552; batch adversarial loss: 0.580209\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481012; batch adversarial loss: 0.642920\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483719; batch adversarial loss: 0.562966\n",
      "epoch 33; iter: 0; batch classifier loss: 0.538403; batch adversarial loss: 0.544477\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431583; batch adversarial loss: 0.535395\n",
      "epoch 35; iter: 0; batch classifier loss: 0.416859; batch adversarial loss: 0.517084\n",
      "epoch 36; iter: 0; batch classifier loss: 0.491741; batch adversarial loss: 0.571406\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462423; batch adversarial loss: 0.586497\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523642; batch adversarial loss: 0.524737\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440884; batch adversarial loss: 0.516188\n",
      "epoch 40; iter: 0; batch classifier loss: 0.509823; batch adversarial loss: 0.508820\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469249; batch adversarial loss: 0.499854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477803; batch adversarial loss: 0.601758\n",
      "epoch 43; iter: 0; batch classifier loss: 0.529130; batch adversarial loss: 0.573273\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505018; batch adversarial loss: 0.563268\n",
      "epoch 45; iter: 0; batch classifier loss: 0.493917; batch adversarial loss: 0.477782\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448089; batch adversarial loss: 0.526826\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466311; batch adversarial loss: 0.593019\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484794; batch adversarial loss: 0.487940\n",
      "epoch 49; iter: 0; batch classifier loss: 0.478993; batch adversarial loss: 0.601530\n",
      "epoch 50; iter: 0; batch classifier loss: 0.522693; batch adversarial loss: 0.517942\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443560; batch adversarial loss: 0.542904\n",
      "epoch 52; iter: 0; batch classifier loss: 0.373648; batch adversarial loss: 0.498584\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438459; batch adversarial loss: 0.505995\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451043; batch adversarial loss: 0.506490\n",
      "epoch 55; iter: 0; batch classifier loss: 0.381940; batch adversarial loss: 0.533617\n",
      "epoch 56; iter: 0; batch classifier loss: 0.480743; batch adversarial loss: 0.532797\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435412; batch adversarial loss: 0.563752\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410412; batch adversarial loss: 0.496807\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400728; batch adversarial loss: 0.618720\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405731; batch adversarial loss: 0.554368\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424981; batch adversarial loss: 0.543808\n",
      "epoch 62; iter: 0; batch classifier loss: 0.462687; batch adversarial loss: 0.524589\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432412; batch adversarial loss: 0.543142\n",
      "epoch 64; iter: 0; batch classifier loss: 0.505126; batch adversarial loss: 0.542880\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457191; batch adversarial loss: 0.477431\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382440; batch adversarial loss: 0.507763\n",
      "epoch 67; iter: 0; batch classifier loss: 0.331070; batch adversarial loss: 0.487569\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437695; batch adversarial loss: 0.621798\n",
      "epoch 69; iter: 0; batch classifier loss: 0.370176; batch adversarial loss: 0.505247\n",
      "epoch 70; iter: 0; batch classifier loss: 0.400403; batch adversarial loss: 0.591971\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449617; batch adversarial loss: 0.554054\n",
      "epoch 72; iter: 0; batch classifier loss: 0.436226; batch adversarial loss: 0.509085\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373206; batch adversarial loss: 0.637002\n",
      "epoch 74; iter: 0; batch classifier loss: 0.427209; batch adversarial loss: 0.555679\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415220; batch adversarial loss: 0.497236\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381951; batch adversarial loss: 0.638693\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402718; batch adversarial loss: 0.498104\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437216; batch adversarial loss: 0.517996\n",
      "epoch 79; iter: 0; batch classifier loss: 0.454548; batch adversarial loss: 0.515732\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392510; batch adversarial loss: 0.600769\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426648; batch adversarial loss: 0.571942\n",
      "epoch 82; iter: 0; batch classifier loss: 0.295220; batch adversarial loss: 0.590338\n",
      "epoch 83; iter: 0; batch classifier loss: 0.439987; batch adversarial loss: 0.574037\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416663; batch adversarial loss: 0.554419\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402553; batch adversarial loss: 0.561352\n",
      "epoch 86; iter: 0; batch classifier loss: 0.396171; batch adversarial loss: 0.533213\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401036; batch adversarial loss: 0.540547\n",
      "epoch 88; iter: 0; batch classifier loss: 0.464868; batch adversarial loss: 0.489051\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369925; batch adversarial loss: 0.459807\n",
      "epoch 90; iter: 0; batch classifier loss: 0.366204; batch adversarial loss: 0.584333\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409062; batch adversarial loss: 0.495982\n",
      "epoch 92; iter: 0; batch classifier loss: 0.427492; batch adversarial loss: 0.545561\n",
      "epoch 93; iter: 0; batch classifier loss: 0.365971; batch adversarial loss: 0.535265\n",
      "epoch 94; iter: 0; batch classifier loss: 0.474608; batch adversarial loss: 0.438573\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379979; batch adversarial loss: 0.552991\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425773; batch adversarial loss: 0.505376\n",
      "epoch 97; iter: 0; batch classifier loss: 0.488033; batch adversarial loss: 0.534051\n",
      "epoch 98; iter: 0; batch classifier loss: 0.367433; batch adversarial loss: 0.562506\n",
      "epoch 99; iter: 0; batch classifier loss: 0.347263; batch adversarial loss: 0.544809\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390991; batch adversarial loss: 0.526852\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359862; batch adversarial loss: 0.506856\n",
      "epoch 102; iter: 0; batch classifier loss: 0.465790; batch adversarial loss: 0.526242\n",
      "epoch 103; iter: 0; batch classifier loss: 0.405847; batch adversarial loss: 0.524958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.357626; batch adversarial loss: 0.515981\n",
      "epoch 105; iter: 0; batch classifier loss: 0.397592; batch adversarial loss: 0.527831\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402231; batch adversarial loss: 0.507318\n",
      "epoch 107; iter: 0; batch classifier loss: 0.417304; batch adversarial loss: 0.527152\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383190; batch adversarial loss: 0.516990\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410624; batch adversarial loss: 0.591701\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397226; batch adversarial loss: 0.498054\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365133; batch adversarial loss: 0.572794\n",
      "epoch 112; iter: 0; batch classifier loss: 0.494789; batch adversarial loss: 0.525715\n",
      "epoch 113; iter: 0; batch classifier loss: 0.321393; batch adversarial loss: 0.533444\n",
      "epoch 114; iter: 0; batch classifier loss: 0.429742; batch adversarial loss: 0.544993\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374341; batch adversarial loss: 0.525363\n",
      "epoch 116; iter: 0; batch classifier loss: 0.426501; batch adversarial loss: 0.517288\n",
      "epoch 117; iter: 0; batch classifier loss: 0.412606; batch adversarial loss: 0.526633\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403629; batch adversarial loss: 0.533797\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414147; batch adversarial loss: 0.545040\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416695; batch adversarial loss: 0.621082\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406990; batch adversarial loss: 0.506769\n",
      "epoch 122; iter: 0; batch classifier loss: 0.333584; batch adversarial loss: 0.478217\n",
      "epoch 123; iter: 0; batch classifier loss: 0.432456; batch adversarial loss: 0.564779\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345848; batch adversarial loss: 0.582279\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361173; batch adversarial loss: 0.546613\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390683; batch adversarial loss: 0.574324\n",
      "epoch 127; iter: 0; batch classifier loss: 0.324436; batch adversarial loss: 0.582244\n",
      "epoch 128; iter: 0; batch classifier loss: 0.320728; batch adversarial loss: 0.506179\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336929; batch adversarial loss: 0.543606\n",
      "epoch 130; iter: 0; batch classifier loss: 0.448017; batch adversarial loss: 0.554401\n",
      "epoch 131; iter: 0; batch classifier loss: 0.413679; batch adversarial loss: 0.573054\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392848; batch adversarial loss: 0.525800\n",
      "epoch 133; iter: 0; batch classifier loss: 0.453423; batch adversarial loss: 0.564270\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329719; batch adversarial loss: 0.528540\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337375; batch adversarial loss: 0.516697\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403460; batch adversarial loss: 0.534374\n",
      "epoch 137; iter: 0; batch classifier loss: 0.317315; batch adversarial loss: 0.582863\n",
      "epoch 138; iter: 0; batch classifier loss: 0.395462; batch adversarial loss: 0.534963\n",
      "epoch 139; iter: 0; batch classifier loss: 0.330919; batch adversarial loss: 0.572235\n",
      "epoch 140; iter: 0; batch classifier loss: 0.318744; batch adversarial loss: 0.506433\n",
      "epoch 141; iter: 0; batch classifier loss: 0.451969; batch adversarial loss: 0.525054\n",
      "epoch 142; iter: 0; batch classifier loss: 0.512835; batch adversarial loss: 0.534254\n",
      "epoch 143; iter: 0; batch classifier loss: 0.416861; batch adversarial loss: 0.411833\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437544; batch adversarial loss: 0.488376\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381036; batch adversarial loss: 0.593701\n",
      "epoch 146; iter: 0; batch classifier loss: 0.315022; batch adversarial loss: 0.421224\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374601; batch adversarial loss: 0.601393\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410648; batch adversarial loss: 0.515140\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349544; batch adversarial loss: 0.572598\n",
      "epoch 150; iter: 0; batch classifier loss: 0.414022; batch adversarial loss: 0.591349\n",
      "epoch 151; iter: 0; batch classifier loss: 0.288373; batch adversarial loss: 0.497212\n",
      "epoch 152; iter: 0; batch classifier loss: 0.429482; batch adversarial loss: 0.515875\n",
      "epoch 153; iter: 0; batch classifier loss: 0.417871; batch adversarial loss: 0.516744\n",
      "epoch 154; iter: 0; batch classifier loss: 0.310250; batch adversarial loss: 0.497605\n",
      "epoch 155; iter: 0; batch classifier loss: 0.421737; batch adversarial loss: 0.496454\n",
      "epoch 156; iter: 0; batch classifier loss: 0.434875; batch adversarial loss: 0.533643\n",
      "epoch 157; iter: 0; batch classifier loss: 0.428692; batch adversarial loss: 0.534224\n",
      "epoch 158; iter: 0; batch classifier loss: 0.300140; batch adversarial loss: 0.516846\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363310; batch adversarial loss: 0.460907\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381692; batch adversarial loss: 0.496397\n",
      "epoch 161; iter: 0; batch classifier loss: 0.384702; batch adversarial loss: 0.534591\n",
      "epoch 162; iter: 0; batch classifier loss: 0.399791; batch adversarial loss: 0.535281\n",
      "epoch 163; iter: 0; batch classifier loss: 0.368846; batch adversarial loss: 0.592956\n",
      "epoch 164; iter: 0; batch classifier loss: 0.422561; batch adversarial loss: 0.591884\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385311; batch adversarial loss: 0.560360\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343840; batch adversarial loss: 0.487590\n",
      "epoch 167; iter: 0; batch classifier loss: 0.416297; batch adversarial loss: 0.537220\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401380; batch adversarial loss: 0.524620\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367603; batch adversarial loss: 0.592180\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398815; batch adversarial loss: 0.513685\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408010; batch adversarial loss: 0.487723\n",
      "epoch 172; iter: 0; batch classifier loss: 0.480250; batch adversarial loss: 0.545911\n",
      "epoch 173; iter: 0; batch classifier loss: 0.320001; batch adversarial loss: 0.516736\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364360; batch adversarial loss: 0.544699\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366610; batch adversarial loss: 0.551746\n",
      "epoch 176; iter: 0; batch classifier loss: 0.478957; batch adversarial loss: 0.552460\n",
      "epoch 177; iter: 0; batch classifier loss: 0.366834; batch adversarial loss: 0.602653\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335860; batch adversarial loss: 0.517288\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386328; batch adversarial loss: 0.498596\n",
      "epoch 180; iter: 0; batch classifier loss: 0.445564; batch adversarial loss: 0.554056\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379459; batch adversarial loss: 0.539052\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373307; batch adversarial loss: 0.610876\n",
      "epoch 183; iter: 0; batch classifier loss: 0.420755; batch adversarial loss: 0.515410\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363564; batch adversarial loss: 0.525808\n",
      "epoch 185; iter: 0; batch classifier loss: 0.280365; batch adversarial loss: 0.648136\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385732; batch adversarial loss: 0.648898\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319009; batch adversarial loss: 0.534591\n",
      "epoch 188; iter: 0; batch classifier loss: 0.299182; batch adversarial loss: 0.599880\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358012; batch adversarial loss: 0.488801\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360761; batch adversarial loss: 0.553301\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378840; batch adversarial loss: 0.536258\n",
      "epoch 192; iter: 0; batch classifier loss: 0.383938; batch adversarial loss: 0.496476\n",
      "epoch 193; iter: 0; batch classifier loss: 0.422590; batch adversarial loss: 0.523939\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403007; batch adversarial loss: 0.552811\n",
      "epoch 195; iter: 0; batch classifier loss: 0.280359; batch adversarial loss: 0.496175\n",
      "epoch 196; iter: 0; batch classifier loss: 0.391519; batch adversarial loss: 0.477340\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388823; batch adversarial loss: 0.590862\n",
      "epoch 198; iter: 0; batch classifier loss: 0.399934; batch adversarial loss: 0.525398\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348106; batch adversarial loss: 0.535389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.712578; batch adversarial loss: 0.770060\n",
      "epoch 1; iter: 0; batch classifier loss: 0.789683; batch adversarial loss: 0.820401\n",
      "epoch 2; iter: 0; batch classifier loss: 0.722609; batch adversarial loss: 0.730062\n",
      "epoch 3; iter: 0; batch classifier loss: 0.636284; batch adversarial loss: 0.664606\n",
      "epoch 4; iter: 0; batch classifier loss: 0.612906; batch adversarial loss: 0.649200\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621236; batch adversarial loss: 0.625642\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562689; batch adversarial loss: 0.621985\n",
      "epoch 7; iter: 0; batch classifier loss: 0.487215; batch adversarial loss: 0.602687\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495878; batch adversarial loss: 0.623161\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516757; batch adversarial loss: 0.634070\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569417; batch adversarial loss: 0.615033\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481904; batch adversarial loss: 0.599365\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537704; batch adversarial loss: 0.615426\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489134; batch adversarial loss: 0.594396\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500243; batch adversarial loss: 0.603535\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463104; batch adversarial loss: 0.626156\n",
      "epoch 16; iter: 0; batch classifier loss: 0.474829; batch adversarial loss: 0.543938\n",
      "epoch 17; iter: 0; batch classifier loss: 0.454919; batch adversarial loss: 0.438411\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485881; batch adversarial loss: 0.571411\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480268; batch adversarial loss: 0.632483\n",
      "epoch 20; iter: 0; batch classifier loss: 0.442673; batch adversarial loss: 0.511898\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469485; batch adversarial loss: 0.592870\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480621; batch adversarial loss: 0.563092\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486057; batch adversarial loss: 0.534244\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473362; batch adversarial loss: 0.625209\n",
      "epoch 25; iter: 0; batch classifier loss: 0.615370; batch adversarial loss: 0.574054\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477656; batch adversarial loss: 0.516866\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507345; batch adversarial loss: 0.485029\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465331; batch adversarial loss: 0.528642\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472573; batch adversarial loss: 0.565584\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422017; batch adversarial loss: 0.520207\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476254; batch adversarial loss: 0.583847\n",
      "epoch 32; iter: 0; batch classifier loss: 0.536333; batch adversarial loss: 0.591073\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518667; batch adversarial loss: 0.511869\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474503; batch adversarial loss: 0.481875\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420238; batch adversarial loss: 0.529625\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434505; batch adversarial loss: 0.510246\n",
      "epoch 37; iter: 0; batch classifier loss: 0.397125; batch adversarial loss: 0.609655\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468105; batch adversarial loss: 0.551640\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423711; batch adversarial loss: 0.568341\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484065; batch adversarial loss: 0.492351\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429758; batch adversarial loss: 0.562815\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483674; batch adversarial loss: 0.577095\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425430; batch adversarial loss: 0.650986\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434377; batch adversarial loss: 0.663897\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450804; batch adversarial loss: 0.663779\n",
      "epoch 46; iter: 0; batch classifier loss: 0.389826; batch adversarial loss: 0.554722\n",
      "epoch 47; iter: 0; batch classifier loss: 0.345769; batch adversarial loss: 0.578001\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401521; batch adversarial loss: 0.600474\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428386; batch adversarial loss: 0.451908\n",
      "epoch 50; iter: 0; batch classifier loss: 0.489732; batch adversarial loss: 0.504059\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482515; batch adversarial loss: 0.578440\n",
      "epoch 52; iter: 0; batch classifier loss: 0.350456; batch adversarial loss: 0.500892\n",
      "epoch 53; iter: 0; batch classifier loss: 0.502082; batch adversarial loss: 0.544399\n",
      "epoch 54; iter: 0; batch classifier loss: 0.383943; batch adversarial loss: 0.591141\n",
      "epoch 55; iter: 0; batch classifier loss: 0.528108; batch adversarial loss: 0.535164\n",
      "epoch 56; iter: 0; batch classifier loss: 0.375678; batch adversarial loss: 0.521159\n",
      "epoch 57; iter: 0; batch classifier loss: 0.394275; batch adversarial loss: 0.511127\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469187; batch adversarial loss: 0.518754\n",
      "epoch 59; iter: 0; batch classifier loss: 0.455501; batch adversarial loss: 0.581056\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452399; batch adversarial loss: 0.499472\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423592; batch adversarial loss: 0.596418\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406774; batch adversarial loss: 0.562036\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465322; batch adversarial loss: 0.526137\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400205; batch adversarial loss: 0.525990\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412795; batch adversarial loss: 0.607534\n",
      "epoch 66; iter: 0; batch classifier loss: 0.399573; batch adversarial loss: 0.546175\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403894; batch adversarial loss: 0.507667\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418109; batch adversarial loss: 0.553045\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396827; batch adversarial loss: 0.580563\n",
      "epoch 70; iter: 0; batch classifier loss: 0.372332; batch adversarial loss: 0.517748\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400467; batch adversarial loss: 0.580058\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429816; batch adversarial loss: 0.529225\n",
      "epoch 73; iter: 0; batch classifier loss: 0.451719; batch adversarial loss: 0.518862\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359848; batch adversarial loss: 0.553212\n",
      "epoch 75; iter: 0; batch classifier loss: 0.374275; batch adversarial loss: 0.590573\n",
      "epoch 76; iter: 0; batch classifier loss: 0.449297; batch adversarial loss: 0.464124\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441806; batch adversarial loss: 0.544003\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448851; batch adversarial loss: 0.482236\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405557; batch adversarial loss: 0.617055\n",
      "epoch 80; iter: 0; batch classifier loss: 0.352907; batch adversarial loss: 0.579672\n",
      "epoch 81; iter: 0; batch classifier loss: 0.439706; batch adversarial loss: 0.563822\n",
      "epoch 82; iter: 0; batch classifier loss: 0.478588; batch adversarial loss: 0.518141\n",
      "epoch 83; iter: 0; batch classifier loss: 0.373639; batch adversarial loss: 0.632566\n",
      "epoch 84; iter: 0; batch classifier loss: 0.438636; batch adversarial loss: 0.509503\n",
      "epoch 85; iter: 0; batch classifier loss: 0.300230; batch adversarial loss: 0.527459\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433446; batch adversarial loss: 0.563896\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417052; batch adversarial loss: 0.552060\n",
      "epoch 88; iter: 0; batch classifier loss: 0.462810; batch adversarial loss: 0.536969\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390264; batch adversarial loss: 0.525700\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463321; batch adversarial loss: 0.608139\n",
      "epoch 91; iter: 0; batch classifier loss: 0.444795; batch adversarial loss: 0.536194\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386070; batch adversarial loss: 0.599240\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417794; batch adversarial loss: 0.527717\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375209; batch adversarial loss: 0.534528\n",
      "epoch 95; iter: 0; batch classifier loss: 0.380171; batch adversarial loss: 0.553070\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402904; batch adversarial loss: 0.554272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.371463; batch adversarial loss: 0.535237\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362483; batch adversarial loss: 0.598560\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366191; batch adversarial loss: 0.500015\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381279; batch adversarial loss: 0.544684\n",
      "epoch 101; iter: 0; batch classifier loss: 0.430160; batch adversarial loss: 0.616262\n",
      "epoch 102; iter: 0; batch classifier loss: 0.353204; batch adversarial loss: 0.553881\n",
      "epoch 103; iter: 0; batch classifier loss: 0.410222; batch adversarial loss: 0.536219\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400128; batch adversarial loss: 0.597175\n",
      "epoch 105; iter: 0; batch classifier loss: 0.504512; batch adversarial loss: 0.588670\n",
      "epoch 106; iter: 0; batch classifier loss: 0.346692; batch adversarial loss: 0.563805\n",
      "epoch 107; iter: 0; batch classifier loss: 0.451068; batch adversarial loss: 0.535269\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383227; batch adversarial loss: 0.608526\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430244; batch adversarial loss: 0.662011\n",
      "epoch 110; iter: 0; batch classifier loss: 0.468162; batch adversarial loss: 0.597191\n",
      "epoch 111; iter: 0; batch classifier loss: 0.346257; batch adversarial loss: 0.482795\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410925; batch adversarial loss: 0.571199\n",
      "epoch 113; iter: 0; batch classifier loss: 0.359801; batch adversarial loss: 0.543682\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368701; batch adversarial loss: 0.543858\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352491; batch adversarial loss: 0.489436\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361700; batch adversarial loss: 0.499883\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373285; batch adversarial loss: 0.532712\n",
      "epoch 118; iter: 0; batch classifier loss: 0.369088; batch adversarial loss: 0.545227\n",
      "epoch 119; iter: 0; batch classifier loss: 0.282067; batch adversarial loss: 0.525937\n",
      "epoch 120; iter: 0; batch classifier loss: 0.305346; batch adversarial loss: 0.562777\n",
      "epoch 121; iter: 0; batch classifier loss: 0.468909; batch adversarial loss: 0.573056\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385457; batch adversarial loss: 0.580098\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362148; batch adversarial loss: 0.526567\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369981; batch adversarial loss: 0.616761\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418601; batch adversarial loss: 0.571406\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330539; batch adversarial loss: 0.439682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422354; batch adversarial loss: 0.605882\n",
      "epoch 128; iter: 0; batch classifier loss: 0.433791; batch adversarial loss: 0.510395\n",
      "epoch 129; iter: 0; batch classifier loss: 0.414182; batch adversarial loss: 0.590141\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414446; batch adversarial loss: 0.572637\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389407; batch adversarial loss: 0.526829\n",
      "epoch 132; iter: 0; batch classifier loss: 0.361424; batch adversarial loss: 0.500102\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412652; batch adversarial loss: 0.562333\n",
      "epoch 134; iter: 0; batch classifier loss: 0.436652; batch adversarial loss: 0.535056\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335718; batch adversarial loss: 0.561844\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359542; batch adversarial loss: 0.606783\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366506; batch adversarial loss: 0.535777\n",
      "epoch 138; iter: 0; batch classifier loss: 0.424662; batch adversarial loss: 0.465183\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376712; batch adversarial loss: 0.552549\n",
      "epoch 140; iter: 0; batch classifier loss: 0.336535; batch adversarial loss: 0.599561\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339131; batch adversarial loss: 0.500161\n",
      "epoch 142; iter: 0; batch classifier loss: 0.385918; batch adversarial loss: 0.634676\n",
      "epoch 143; iter: 0; batch classifier loss: 0.437932; batch adversarial loss: 0.508576\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361116; batch adversarial loss: 0.509908\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363633; batch adversarial loss: 0.483017\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368843; batch adversarial loss: 0.597392\n",
      "epoch 147; iter: 0; batch classifier loss: 0.413580; batch adversarial loss: 0.554347\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345360; batch adversarial loss: 0.598923\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384937; batch adversarial loss: 0.633893\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339397; batch adversarial loss: 0.508694\n",
      "epoch 151; iter: 0; batch classifier loss: 0.293353; batch adversarial loss: 0.526318\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349327; batch adversarial loss: 0.544609\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368948; batch adversarial loss: 0.590551\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366933; batch adversarial loss: 0.525811\n",
      "epoch 155; iter: 0; batch classifier loss: 0.437262; batch adversarial loss: 0.516255\n",
      "epoch 156; iter: 0; batch classifier loss: 0.254101; batch adversarial loss: 0.489758\n",
      "epoch 157; iter: 0; batch classifier loss: 0.289156; batch adversarial loss: 0.527200\n",
      "epoch 158; iter: 0; batch classifier loss: 0.309095; batch adversarial loss: 0.589192\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380563; batch adversarial loss: 0.553360\n",
      "epoch 160; iter: 0; batch classifier loss: 0.331650; batch adversarial loss: 0.464225\n",
      "epoch 161; iter: 0; batch classifier loss: 0.425213; batch adversarial loss: 0.491984\n",
      "epoch 162; iter: 0; batch classifier loss: 0.308868; batch adversarial loss: 0.562470\n",
      "epoch 163; iter: 0; batch classifier loss: 0.360058; batch adversarial loss: 0.598765\n",
      "epoch 164; iter: 0; batch classifier loss: 0.477894; batch adversarial loss: 0.553199\n",
      "epoch 165; iter: 0; batch classifier loss: 0.325735; batch adversarial loss: 0.535453\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367460; batch adversarial loss: 0.580383\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332005; batch adversarial loss: 0.545116\n",
      "epoch 168; iter: 0; batch classifier loss: 0.324000; batch adversarial loss: 0.545983\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385475; batch adversarial loss: 0.572746\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362655; batch adversarial loss: 0.597804\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390097; batch adversarial loss: 0.553386\n",
      "epoch 172; iter: 0; batch classifier loss: 0.399922; batch adversarial loss: 0.535069\n",
      "epoch 173; iter: 0; batch classifier loss: 0.325341; batch adversarial loss: 0.491767\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350165; batch adversarial loss: 0.562236\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364469; batch adversarial loss: 0.615953\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366113; batch adversarial loss: 0.535728\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342292; batch adversarial loss: 0.553892\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332800; batch adversarial loss: 0.580685\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377337; batch adversarial loss: 0.544211\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329465; batch adversarial loss: 0.499879\n",
      "epoch 181; iter: 0; batch classifier loss: 0.341236; batch adversarial loss: 0.562746\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374057; batch adversarial loss: 0.562119\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346990; batch adversarial loss: 0.536167\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383347; batch adversarial loss: 0.482259\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387320; batch adversarial loss: 0.472118\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385232; batch adversarial loss: 0.580159\n",
      "epoch 187; iter: 0; batch classifier loss: 0.337370; batch adversarial loss: 0.526542\n",
      "epoch 188; iter: 0; batch classifier loss: 0.302840; batch adversarial loss: 0.517664\n",
      "epoch 189; iter: 0; batch classifier loss: 0.431789; batch adversarial loss: 0.578416\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368756; batch adversarial loss: 0.565100\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344390; batch adversarial loss: 0.507568\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362852; batch adversarial loss: 0.651651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.282235; batch adversarial loss: 0.500993\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385379; batch adversarial loss: 0.518328\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354527; batch adversarial loss: 0.465254\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347972; batch adversarial loss: 0.562307\n",
      "epoch 197; iter: 0; batch classifier loss: 0.389601; batch adversarial loss: 0.507714\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383906; batch adversarial loss: 0.526368\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362604; batch adversarial loss: 0.571511\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678760; batch adversarial loss: 0.673185\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601917; batch adversarial loss: 0.665467\n",
      "epoch 2; iter: 0; batch classifier loss: 0.525783; batch adversarial loss: 0.660094\n",
      "epoch 3; iter: 0; batch classifier loss: 0.554575; batch adversarial loss: 0.628562\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557904; batch adversarial loss: 0.642707\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563416; batch adversarial loss: 0.613699\n",
      "epoch 6; iter: 0; batch classifier loss: 0.648414; batch adversarial loss: 0.554509\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592820; batch adversarial loss: 0.659127\n",
      "epoch 8; iter: 0; batch classifier loss: 0.615825; batch adversarial loss: 0.617229\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487820; batch adversarial loss: 0.572678\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536312; batch adversarial loss: 0.600629\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522669; batch adversarial loss: 0.611484\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558899; batch adversarial loss: 0.574624\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578840; batch adversarial loss: 0.593932\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470634; batch adversarial loss: 0.619591\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523758; batch adversarial loss: 0.598135\n",
      "epoch 16; iter: 0; batch classifier loss: 0.427452; batch adversarial loss: 0.602898\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443521; batch adversarial loss: 0.578936\n",
      "epoch 18; iter: 0; batch classifier loss: 0.410820; batch adversarial loss: 0.536062\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541891; batch adversarial loss: 0.605951\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487806; batch adversarial loss: 0.520708\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477845; batch adversarial loss: 0.547343\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454660; batch adversarial loss: 0.554761\n",
      "epoch 23; iter: 0; batch classifier loss: 0.556892; batch adversarial loss: 0.513381\n",
      "epoch 24; iter: 0; batch classifier loss: 0.542367; batch adversarial loss: 0.591580\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434917; batch adversarial loss: 0.527087\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511404; batch adversarial loss: 0.622956\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437923; batch adversarial loss: 0.545259\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451752; batch adversarial loss: 0.567274\n",
      "epoch 29; iter: 0; batch classifier loss: 0.522544; batch adversarial loss: 0.530844\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468630; batch adversarial loss: 0.549063\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470069; batch adversarial loss: 0.490450\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407299; batch adversarial loss: 0.607504\n",
      "epoch 33; iter: 0; batch classifier loss: 0.515533; batch adversarial loss: 0.496344\n",
      "epoch 34; iter: 0; batch classifier loss: 0.517371; batch adversarial loss: 0.457898\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411758; batch adversarial loss: 0.516805\n",
      "epoch 36; iter: 0; batch classifier loss: 0.546673; batch adversarial loss: 0.596089\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424536; batch adversarial loss: 0.474436\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447665; batch adversarial loss: 0.553313\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392339; batch adversarial loss: 0.571246\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442233; batch adversarial loss: 0.472688\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474422; batch adversarial loss: 0.527147\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459432; batch adversarial loss: 0.461303\n",
      "epoch 43; iter: 0; batch classifier loss: 0.512609; batch adversarial loss: 0.548970\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474541; batch adversarial loss: 0.517664\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448581; batch adversarial loss: 0.612059\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503644; batch adversarial loss: 0.450713\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442759; batch adversarial loss: 0.618018\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427867; batch adversarial loss: 0.524258\n",
      "epoch 49; iter: 0; batch classifier loss: 0.591348; batch adversarial loss: 0.505571\n",
      "epoch 50; iter: 0; batch classifier loss: 0.346363; batch adversarial loss: 0.555285\n",
      "epoch 51; iter: 0; batch classifier loss: 0.564435; batch adversarial loss: 0.571373\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437233; batch adversarial loss: 0.526978\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443511; batch adversarial loss: 0.533395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427126; batch adversarial loss: 0.485010\n",
      "epoch 55; iter: 0; batch classifier loss: 0.365849; batch adversarial loss: 0.555282\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404325; batch adversarial loss: 0.516068\n",
      "epoch 57; iter: 0; batch classifier loss: 0.348419; batch adversarial loss: 0.579124\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401767; batch adversarial loss: 0.609013\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432260; batch adversarial loss: 0.526608\n",
      "epoch 60; iter: 0; batch classifier loss: 0.419465; batch adversarial loss: 0.535354\n",
      "epoch 61; iter: 0; batch classifier loss: 0.384785; batch adversarial loss: 0.553882\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398233; batch adversarial loss: 0.551811\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431598; batch adversarial loss: 0.506470\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411978; batch adversarial loss: 0.505057\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386331; batch adversarial loss: 0.535674\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441346; batch adversarial loss: 0.584585\n",
      "epoch 67; iter: 0; batch classifier loss: 0.493084; batch adversarial loss: 0.591931\n",
      "epoch 68; iter: 0; batch classifier loss: 0.491494; batch adversarial loss: 0.572106\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432568; batch adversarial loss: 0.525925\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425456; batch adversarial loss: 0.535224\n",
      "epoch 71; iter: 0; batch classifier loss: 0.367565; batch adversarial loss: 0.591413\n",
      "epoch 72; iter: 0; batch classifier loss: 0.487782; batch adversarial loss: 0.580967\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407873; batch adversarial loss: 0.583292\n",
      "epoch 74; iter: 0; batch classifier loss: 0.453777; batch adversarial loss: 0.477446\n",
      "epoch 75; iter: 0; batch classifier loss: 0.531387; batch adversarial loss: 0.590448\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410621; batch adversarial loss: 0.499413\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391058; batch adversarial loss: 0.545172\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371735; batch adversarial loss: 0.478693\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416346; batch adversarial loss: 0.581132\n",
      "epoch 80; iter: 0; batch classifier loss: 0.454159; batch adversarial loss: 0.458907\n",
      "epoch 81; iter: 0; batch classifier loss: 0.354377; batch adversarial loss: 0.564520\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380954; batch adversarial loss: 0.536669\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378287; batch adversarial loss: 0.628265\n",
      "epoch 84; iter: 0; batch classifier loss: 0.316655; batch adversarial loss: 0.554447\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399121; batch adversarial loss: 0.572254\n",
      "epoch 86; iter: 0; batch classifier loss: 0.442473; batch adversarial loss: 0.544568\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393521; batch adversarial loss: 0.470671\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386547; batch adversarial loss: 0.515943\n",
      "epoch 89; iter: 0; batch classifier loss: 0.434151; batch adversarial loss: 0.507294\n",
      "epoch 90; iter: 0; batch classifier loss: 0.346594; batch adversarial loss: 0.562493\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390878; batch adversarial loss: 0.533131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.407243; batch adversarial loss: 0.515444\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413774; batch adversarial loss: 0.546471\n",
      "epoch 94; iter: 0; batch classifier loss: 0.437510; batch adversarial loss: 0.496939\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396203; batch adversarial loss: 0.468959\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380746; batch adversarial loss: 0.515522\n",
      "epoch 97; iter: 0; batch classifier loss: 0.539456; batch adversarial loss: 0.610779\n",
      "epoch 98; iter: 0; batch classifier loss: 0.434161; batch adversarial loss: 0.554195\n",
      "epoch 99; iter: 0; batch classifier loss: 0.411973; batch adversarial loss: 0.466834\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415617; batch adversarial loss: 0.524965\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393119; batch adversarial loss: 0.516384\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414007; batch adversarial loss: 0.561130\n",
      "epoch 103; iter: 0; batch classifier loss: 0.359526; batch adversarial loss: 0.563713\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413569; batch adversarial loss: 0.514942\n",
      "epoch 105; iter: 0; batch classifier loss: 0.444150; batch adversarial loss: 0.469095\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419326; batch adversarial loss: 0.571419\n",
      "epoch 107; iter: 0; batch classifier loss: 0.416538; batch adversarial loss: 0.497346\n",
      "epoch 108; iter: 0; batch classifier loss: 0.283023; batch adversarial loss: 0.469894\n",
      "epoch 109; iter: 0; batch classifier loss: 0.411548; batch adversarial loss: 0.506517\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396075; batch adversarial loss: 0.591588\n",
      "epoch 111; iter: 0; batch classifier loss: 0.364595; batch adversarial loss: 0.544131\n",
      "epoch 112; iter: 0; batch classifier loss: 0.344303; batch adversarial loss: 0.516299\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371364; batch adversarial loss: 0.564670\n",
      "epoch 114; iter: 0; batch classifier loss: 0.501170; batch adversarial loss: 0.573948\n",
      "epoch 115; iter: 0; batch classifier loss: 0.476782; batch adversarial loss: 0.496577\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390825; batch adversarial loss: 0.554706\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339746; batch adversarial loss: 0.523841\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355853; batch adversarial loss: 0.563302\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339013; batch adversarial loss: 0.555541\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354853; batch adversarial loss: 0.510287\n",
      "epoch 121; iter: 0; batch classifier loss: 0.409654; batch adversarial loss: 0.553564\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410547; batch adversarial loss: 0.544610\n",
      "epoch 123; iter: 0; batch classifier loss: 0.417361; batch adversarial loss: 0.456718\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354050; batch adversarial loss: 0.571031\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392072; batch adversarial loss: 0.581040\n",
      "epoch 126; iter: 0; batch classifier loss: 0.420113; batch adversarial loss: 0.496456\n",
      "epoch 127; iter: 0; batch classifier loss: 0.337976; batch adversarial loss: 0.469856\n",
      "epoch 128; iter: 0; batch classifier loss: 0.465415; batch adversarial loss: 0.542274\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359092; batch adversarial loss: 0.498201\n",
      "epoch 130; iter: 0; batch classifier loss: 0.433004; batch adversarial loss: 0.589843\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406170; batch adversarial loss: 0.514890\n",
      "epoch 132; iter: 0; batch classifier loss: 0.398609; batch adversarial loss: 0.554369\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344354; batch adversarial loss: 0.565506\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402860; batch adversarial loss: 0.535265\n",
      "epoch 135; iter: 0; batch classifier loss: 0.367271; batch adversarial loss: 0.554023\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392028; batch adversarial loss: 0.535003\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349784; batch adversarial loss: 0.514943\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344656; batch adversarial loss: 0.544738\n",
      "epoch 139; iter: 0; batch classifier loss: 0.339854; batch adversarial loss: 0.592156\n",
      "epoch 140; iter: 0; batch classifier loss: 0.433807; batch adversarial loss: 0.535440\n",
      "epoch 141; iter: 0; batch classifier loss: 0.418272; batch adversarial loss: 0.545519\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380390; batch adversarial loss: 0.602178\n",
      "epoch 143; iter: 0; batch classifier loss: 0.457065; batch adversarial loss: 0.640880\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356579; batch adversarial loss: 0.563826\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390214; batch adversarial loss: 0.639774\n",
      "epoch 146; iter: 0; batch classifier loss: 0.342986; batch adversarial loss: 0.468560\n",
      "epoch 147; iter: 0; batch classifier loss: 0.357525; batch adversarial loss: 0.535357\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410595; batch adversarial loss: 0.553254\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314311; batch adversarial loss: 0.551806\n",
      "epoch 150; iter: 0; batch classifier loss: 0.394413; batch adversarial loss: 0.505863\n",
      "epoch 151; iter: 0; batch classifier loss: 0.421279; batch adversarial loss: 0.449807\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386793; batch adversarial loss: 0.477759\n",
      "epoch 153; iter: 0; batch classifier loss: 0.277060; batch adversarial loss: 0.496991\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365483; batch adversarial loss: 0.440757\n",
      "epoch 155; iter: 0; batch classifier loss: 0.318516; batch adversarial loss: 0.572713\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385964; batch adversarial loss: 0.564282\n",
      "epoch 157; iter: 0; batch classifier loss: 0.355783; batch adversarial loss: 0.478254\n",
      "epoch 158; iter: 0; batch classifier loss: 0.427290; batch adversarial loss: 0.592467\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346716; batch adversarial loss: 0.562069\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350854; batch adversarial loss: 0.475985\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341105; batch adversarial loss: 0.535796\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334285; batch adversarial loss: 0.505576\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325926; batch adversarial loss: 0.534237\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397400; batch adversarial loss: 0.515383\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350223; batch adversarial loss: 0.583692\n",
      "epoch 166; iter: 0; batch classifier loss: 0.337833; batch adversarial loss: 0.478718\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302855; batch adversarial loss: 0.543807\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358878; batch adversarial loss: 0.609091\n",
      "epoch 169; iter: 0; batch classifier loss: 0.308023; batch adversarial loss: 0.535401\n",
      "epoch 170; iter: 0; batch classifier loss: 0.338953; batch adversarial loss: 0.507738\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401153; batch adversarial loss: 0.478350\n",
      "epoch 172; iter: 0; batch classifier loss: 0.302666; batch adversarial loss: 0.573160\n",
      "epoch 173; iter: 0; batch classifier loss: 0.417353; batch adversarial loss: 0.552309\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324895; batch adversarial loss: 0.534773\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369706; batch adversarial loss: 0.518358\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339600; batch adversarial loss: 0.583555\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371617; batch adversarial loss: 0.507727\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390126; batch adversarial loss: 0.574043\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368513; batch adversarial loss: 0.526357\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359363; batch adversarial loss: 0.552535\n",
      "epoch 181; iter: 0; batch classifier loss: 0.341480; batch adversarial loss: 0.468975\n",
      "epoch 182; iter: 0; batch classifier loss: 0.393599; batch adversarial loss: 0.553000\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379302; batch adversarial loss: 0.554025\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332394; batch adversarial loss: 0.478306\n",
      "epoch 185; iter: 0; batch classifier loss: 0.461640; batch adversarial loss: 0.515145\n",
      "epoch 186; iter: 0; batch classifier loss: 0.354032; batch adversarial loss: 0.517271\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355588; batch adversarial loss: 0.497253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.398047; batch adversarial loss: 0.667612\n",
      "epoch 189; iter: 0; batch classifier loss: 0.459442; batch adversarial loss: 0.440030\n",
      "epoch 190; iter: 0; batch classifier loss: 0.401886; batch adversarial loss: 0.571171\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377202; batch adversarial loss: 0.432299\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376137; batch adversarial loss: 0.465635\n",
      "epoch 193; iter: 0; batch classifier loss: 0.387105; batch adversarial loss: 0.572932\n",
      "epoch 194; iter: 0; batch classifier loss: 0.383113; batch adversarial loss: 0.553473\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335521; batch adversarial loss: 0.563522\n",
      "epoch 196; iter: 0; batch classifier loss: 0.273115; batch adversarial loss: 0.506970\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368427; batch adversarial loss: 0.487212\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353510; batch adversarial loss: 0.535146\n",
      "epoch 199; iter: 0; batch classifier loss: 0.294899; batch adversarial loss: 0.489116\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707020; batch adversarial loss: 0.612563\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559924; batch adversarial loss: 0.680989\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610326; batch adversarial loss: 0.673069\n",
      "epoch 3; iter: 0; batch classifier loss: 0.592314; batch adversarial loss: 0.627398\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546684; batch adversarial loss: 0.617898\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557592; batch adversarial loss: 0.613820\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560558; batch adversarial loss: 0.677174\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583558; batch adversarial loss: 0.592594\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533903; batch adversarial loss: 0.590412\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537943; batch adversarial loss: 0.585993\n",
      "epoch 10; iter: 0; batch classifier loss: 0.597267; batch adversarial loss: 0.594682\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506985; batch adversarial loss: 0.585749\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511707; batch adversarial loss: 0.538094\n",
      "epoch 13; iter: 0; batch classifier loss: 0.633826; batch adversarial loss: 0.540744\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512861; batch adversarial loss: 0.558538\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549711; batch adversarial loss: 0.578112\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507343; batch adversarial loss: 0.617886\n",
      "epoch 17; iter: 0; batch classifier loss: 0.452565; batch adversarial loss: 0.532200\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533487; batch adversarial loss: 0.500169\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478644; batch adversarial loss: 0.532158\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470100; batch adversarial loss: 0.589748\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499736; batch adversarial loss: 0.599874\n",
      "epoch 22; iter: 0; batch classifier loss: 0.428666; batch adversarial loss: 0.566370\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538744; batch adversarial loss: 0.447867\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497338; batch adversarial loss: 0.624452\n",
      "epoch 25; iter: 0; batch classifier loss: 0.450797; batch adversarial loss: 0.577294\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433615; batch adversarial loss: 0.475090\n",
      "epoch 27; iter: 0; batch classifier loss: 0.536892; batch adversarial loss: 0.574588\n",
      "epoch 28; iter: 0; batch classifier loss: 0.409762; batch adversarial loss: 0.484174\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458316; batch adversarial loss: 0.493850\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471144; batch adversarial loss: 0.571813\n",
      "epoch 31; iter: 0; batch classifier loss: 0.405891; batch adversarial loss: 0.465703\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484502; batch adversarial loss: 0.531289\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453148; batch adversarial loss: 0.564014\n",
      "epoch 34; iter: 0; batch classifier loss: 0.382420; batch adversarial loss: 0.465321\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484085; batch adversarial loss: 0.585136\n",
      "epoch 36; iter: 0; batch classifier loss: 0.423472; batch adversarial loss: 0.527255\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449454; batch adversarial loss: 0.480788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.423319; batch adversarial loss: 0.530755\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431371; batch adversarial loss: 0.526027\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454138; batch adversarial loss: 0.505376\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437311; batch adversarial loss: 0.555104\n",
      "epoch 42; iter: 0; batch classifier loss: 0.388416; batch adversarial loss: 0.586686\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441410; batch adversarial loss: 0.493938\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472141; batch adversarial loss: 0.608007\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438108; batch adversarial loss: 0.547026\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422100; batch adversarial loss: 0.535510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.492685; batch adversarial loss: 0.545556\n",
      "epoch 48; iter: 0; batch classifier loss: 0.343363; batch adversarial loss: 0.461786\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435148; batch adversarial loss: 0.529186\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400982; batch adversarial loss: 0.480396\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411367; batch adversarial loss: 0.534400\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404182; batch adversarial loss: 0.510074\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418354; batch adversarial loss: 0.589350\n",
      "epoch 54; iter: 0; batch classifier loss: 0.371192; batch adversarial loss: 0.618743\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465975; batch adversarial loss: 0.539516\n",
      "epoch 56; iter: 0; batch classifier loss: 0.500907; batch adversarial loss: 0.505985\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387902; batch adversarial loss: 0.632254\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423197; batch adversarial loss: 0.516945\n",
      "epoch 59; iter: 0; batch classifier loss: 0.448388; batch adversarial loss: 0.590691\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377374; batch adversarial loss: 0.557434\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449376; batch adversarial loss: 0.552816\n",
      "epoch 62; iter: 0; batch classifier loss: 0.385613; batch adversarial loss: 0.502783\n",
      "epoch 63; iter: 0; batch classifier loss: 0.464167; batch adversarial loss: 0.496586\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439884; batch adversarial loss: 0.455928\n",
      "epoch 65; iter: 0; batch classifier loss: 0.477730; batch adversarial loss: 0.445771\n",
      "epoch 66; iter: 0; batch classifier loss: 0.388650; batch adversarial loss: 0.571228\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412269; batch adversarial loss: 0.620054\n",
      "epoch 68; iter: 0; batch classifier loss: 0.354165; batch adversarial loss: 0.514059\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416603; batch adversarial loss: 0.511753\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421723; batch adversarial loss: 0.573040\n",
      "epoch 71; iter: 0; batch classifier loss: 0.385350; batch adversarial loss: 0.484763\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382604; batch adversarial loss: 0.503166\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403146; batch adversarial loss: 0.562599\n",
      "epoch 74; iter: 0; batch classifier loss: 0.338242; batch adversarial loss: 0.475066\n",
      "epoch 75; iter: 0; batch classifier loss: 0.294297; batch adversarial loss: 0.582270\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382820; batch adversarial loss: 0.583160\n",
      "epoch 77; iter: 0; batch classifier loss: 0.470017; batch adversarial loss: 0.595611\n",
      "epoch 78; iter: 0; batch classifier loss: 0.449392; batch adversarial loss: 0.594046\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374990; batch adversarial loss: 0.543168\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392116; batch adversarial loss: 0.527975\n",
      "epoch 81; iter: 0; batch classifier loss: 0.327085; batch adversarial loss: 0.487266\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386453; batch adversarial loss: 0.449005\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411936; batch adversarial loss: 0.571963\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430843; batch adversarial loss: 0.601915\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395467; batch adversarial loss: 0.532851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.422101; batch adversarial loss: 0.563140\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422383; batch adversarial loss: 0.592785\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372840; batch adversarial loss: 0.550036\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342680; batch adversarial loss: 0.515953\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409734; batch adversarial loss: 0.477154\n",
      "epoch 91; iter: 0; batch classifier loss: 0.328221; batch adversarial loss: 0.560582\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403920; batch adversarial loss: 0.552676\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412141; batch adversarial loss: 0.560611\n",
      "epoch 94; iter: 0; batch classifier loss: 0.335699; batch adversarial loss: 0.523298\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393141; batch adversarial loss: 0.568909\n",
      "epoch 96; iter: 0; batch classifier loss: 0.460715; batch adversarial loss: 0.541681\n",
      "epoch 97; iter: 0; batch classifier loss: 0.458016; batch adversarial loss: 0.523326\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357730; batch adversarial loss: 0.477978\n",
      "epoch 99; iter: 0; batch classifier loss: 0.326686; batch adversarial loss: 0.583969\n",
      "epoch 100; iter: 0; batch classifier loss: 0.362798; batch adversarial loss: 0.466225\n",
      "epoch 101; iter: 0; batch classifier loss: 0.441539; batch adversarial loss: 0.527336\n",
      "epoch 102; iter: 0; batch classifier loss: 0.378326; batch adversarial loss: 0.578334\n",
      "epoch 103; iter: 0; batch classifier loss: 0.296144; batch adversarial loss: 0.511594\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419876; batch adversarial loss: 0.544751\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408756; batch adversarial loss: 0.527742\n",
      "epoch 106; iter: 0; batch classifier loss: 0.461555; batch adversarial loss: 0.467650\n",
      "epoch 107; iter: 0; batch classifier loss: 0.423080; batch adversarial loss: 0.545124\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413465; batch adversarial loss: 0.575596\n",
      "epoch 109; iter: 0; batch classifier loss: 0.334981; batch adversarial loss: 0.503935\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348759; batch adversarial loss: 0.564322\n",
      "epoch 111; iter: 0; batch classifier loss: 0.469568; batch adversarial loss: 0.512770\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378651; batch adversarial loss: 0.623648\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415997; batch adversarial loss: 0.508585\n",
      "epoch 114; iter: 0; batch classifier loss: 0.444185; batch adversarial loss: 0.486170\n",
      "epoch 115; iter: 0; batch classifier loss: 0.330620; batch adversarial loss: 0.450208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373804; batch adversarial loss: 0.552620\n",
      "epoch 117; iter: 0; batch classifier loss: 0.455451; batch adversarial loss: 0.532335\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405495; batch adversarial loss: 0.508250\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386994; batch adversarial loss: 0.626260\n",
      "epoch 120; iter: 0; batch classifier loss: 0.498876; batch adversarial loss: 0.467001\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412263; batch adversarial loss: 0.516426\n",
      "epoch 122; iter: 0; batch classifier loss: 0.445673; batch adversarial loss: 0.590496\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334852; batch adversarial loss: 0.569239\n",
      "epoch 124; iter: 0; batch classifier loss: 0.423156; batch adversarial loss: 0.591274\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404715; batch adversarial loss: 0.524794\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363161; batch adversarial loss: 0.528033\n",
      "epoch 127; iter: 0; batch classifier loss: 0.398411; batch adversarial loss: 0.559403\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361054; batch adversarial loss: 0.599753\n",
      "epoch 129; iter: 0; batch classifier loss: 0.437986; batch adversarial loss: 0.515452\n",
      "epoch 130; iter: 0; batch classifier loss: 0.305834; batch adversarial loss: 0.506112\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406596; batch adversarial loss: 0.526970\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329236; batch adversarial loss: 0.550496\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388273; batch adversarial loss: 0.517102\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403805; batch adversarial loss: 0.556932\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363218; batch adversarial loss: 0.591137\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324039; batch adversarial loss: 0.528715\n",
      "epoch 137; iter: 0; batch classifier loss: 0.421479; batch adversarial loss: 0.497539\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340226; batch adversarial loss: 0.577494\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371197; batch adversarial loss: 0.447046\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393731; batch adversarial loss: 0.555457\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363749; batch adversarial loss: 0.589307\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353459; batch adversarial loss: 0.514139\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346834; batch adversarial loss: 0.554835\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356332; batch adversarial loss: 0.487534\n",
      "epoch 145; iter: 0; batch classifier loss: 0.388264; batch adversarial loss: 0.518604\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373313; batch adversarial loss: 0.614308\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363864; batch adversarial loss: 0.611271\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396570; batch adversarial loss: 0.555737\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384037; batch adversarial loss: 0.575018\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351918; batch adversarial loss: 0.506699\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386047; batch adversarial loss: 0.578407\n",
      "epoch 152; iter: 0; batch classifier loss: 0.408232; batch adversarial loss: 0.488074\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338461; batch adversarial loss: 0.469240\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351335; batch adversarial loss: 0.556898\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373933; batch adversarial loss: 0.509386\n",
      "epoch 156; iter: 0; batch classifier loss: 0.303192; batch adversarial loss: 0.479946\n",
      "epoch 157; iter: 0; batch classifier loss: 0.299524; batch adversarial loss: 0.489243\n",
      "epoch 158; iter: 0; batch classifier loss: 0.400749; batch adversarial loss: 0.459300\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369406; batch adversarial loss: 0.586820\n",
      "epoch 160; iter: 0; batch classifier loss: 0.295872; batch adversarial loss: 0.607781\n",
      "epoch 161; iter: 0; batch classifier loss: 0.389564; batch adversarial loss: 0.498083\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363963; batch adversarial loss: 0.570094\n",
      "epoch 163; iter: 0; batch classifier loss: 0.438881; batch adversarial loss: 0.494811\n",
      "epoch 164; iter: 0; batch classifier loss: 0.306153; batch adversarial loss: 0.537493\n",
      "epoch 165; iter: 0; batch classifier loss: 0.284171; batch adversarial loss: 0.616101\n",
      "epoch 166; iter: 0; batch classifier loss: 0.321263; batch adversarial loss: 0.547868\n",
      "epoch 167; iter: 0; batch classifier loss: 0.444872; batch adversarial loss: 0.497870\n",
      "epoch 168; iter: 0; batch classifier loss: 0.277019; batch adversarial loss: 0.587410\n",
      "epoch 169; iter: 0; batch classifier loss: 0.479267; batch adversarial loss: 0.563570\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393217; batch adversarial loss: 0.535191\n",
      "epoch 171; iter: 0; batch classifier loss: 0.307483; batch adversarial loss: 0.592522\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397555; batch adversarial loss: 0.549475\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292038; batch adversarial loss: 0.458686\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364598; batch adversarial loss: 0.634598\n",
      "epoch 175; iter: 0; batch classifier loss: 0.418521; batch adversarial loss: 0.579545\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338887; batch adversarial loss: 0.506271\n",
      "epoch 177; iter: 0; batch classifier loss: 0.271880; batch adversarial loss: 0.563539\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350679; batch adversarial loss: 0.541247\n",
      "epoch 179; iter: 0; batch classifier loss: 0.317464; batch adversarial loss: 0.534831\n",
      "epoch 180; iter: 0; batch classifier loss: 0.450317; batch adversarial loss: 0.516197\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360205; batch adversarial loss: 0.545190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.295015; batch adversarial loss: 0.448645\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356257; batch adversarial loss: 0.533279\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386189; batch adversarial loss: 0.540403\n",
      "epoch 185; iter: 0; batch classifier loss: 0.360539; batch adversarial loss: 0.512745\n",
      "epoch 186; iter: 0; batch classifier loss: 0.406853; batch adversarial loss: 0.554772\n",
      "epoch 187; iter: 0; batch classifier loss: 0.396668; batch adversarial loss: 0.586750\n",
      "epoch 188; iter: 0; batch classifier loss: 0.453233; batch adversarial loss: 0.502676\n",
      "epoch 189; iter: 0; batch classifier loss: 0.420109; batch adversarial loss: 0.488534\n",
      "epoch 190; iter: 0; batch classifier loss: 0.282804; batch adversarial loss: 0.560756\n",
      "epoch 191; iter: 0; batch classifier loss: 0.286496; batch adversarial loss: 0.556428\n",
      "epoch 192; iter: 0; batch classifier loss: 0.266154; batch adversarial loss: 0.502591\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325632; batch adversarial loss: 0.514845\n",
      "epoch 194; iter: 0; batch classifier loss: 0.391971; batch adversarial loss: 0.494662\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398602; batch adversarial loss: 0.395627\n",
      "epoch 196; iter: 0; batch classifier loss: 0.402244; batch adversarial loss: 0.524066\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352327; batch adversarial loss: 0.516025\n",
      "epoch 198; iter: 0; batch classifier loss: 0.330967; batch adversarial loss: 0.470133\n",
      "epoch 199; iter: 0; batch classifier loss: 0.407612; batch adversarial loss: 0.461581\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691962; batch adversarial loss: 0.612897\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630733; batch adversarial loss: 0.625777\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574492; batch adversarial loss: 0.680240\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541712; batch adversarial loss: 0.640229\n",
      "epoch 4; iter: 0; batch classifier loss: 0.525028; batch adversarial loss: 0.606977\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571055; batch adversarial loss: 0.654417\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541005; batch adversarial loss: 0.599215\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496840; batch adversarial loss: 0.619108\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523450; batch adversarial loss: 0.581866\n",
      "epoch 9; iter: 0; batch classifier loss: 0.550523; batch adversarial loss: 0.580835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.599826; batch adversarial loss: 0.619728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526696; batch adversarial loss: 0.554065\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523320; batch adversarial loss: 0.585597\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496998; batch adversarial loss: 0.589391\n",
      "epoch 14; iter: 0; batch classifier loss: 0.577516; batch adversarial loss: 0.561606\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537703; batch adversarial loss: 0.560180\n",
      "epoch 16; iter: 0; batch classifier loss: 0.431386; batch adversarial loss: 0.617492\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576038; batch adversarial loss: 0.546232\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540658; batch adversarial loss: 0.536304\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484626; batch adversarial loss: 0.491519\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519597; batch adversarial loss: 0.594536\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545515; batch adversarial loss: 0.605485\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486906; batch adversarial loss: 0.559367\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492738; batch adversarial loss: 0.565314\n",
      "epoch 24; iter: 0; batch classifier loss: 0.548365; batch adversarial loss: 0.428703\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453074; batch adversarial loss: 0.600697\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446966; batch adversarial loss: 0.512436\n",
      "epoch 27; iter: 0; batch classifier loss: 0.452379; batch adversarial loss: 0.572908\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470750; batch adversarial loss: 0.499651\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456692; batch adversarial loss: 0.551991\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449166; batch adversarial loss: 0.560778\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468421; batch adversarial loss: 0.440998\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419814; batch adversarial loss: 0.467826\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446199; batch adversarial loss: 0.599184\n",
      "epoch 34; iter: 0; batch classifier loss: 0.523439; batch adversarial loss: 0.581830\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482114; batch adversarial loss: 0.641794\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471715; batch adversarial loss: 0.487830\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402856; batch adversarial loss: 0.582347\n",
      "epoch 38; iter: 0; batch classifier loss: 0.421615; batch adversarial loss: 0.554031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438800; batch adversarial loss: 0.581167\n",
      "epoch 40; iter: 0; batch classifier loss: 0.487570; batch adversarial loss: 0.507281\n",
      "epoch 41; iter: 0; batch classifier loss: 0.374701; batch adversarial loss: 0.618456\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496077; batch adversarial loss: 0.515268\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390117; batch adversarial loss: 0.563064\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447323; batch adversarial loss: 0.582167\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441088; batch adversarial loss: 0.554694\n",
      "epoch 46; iter: 0; batch classifier loss: 0.475776; batch adversarial loss: 0.574629\n",
      "epoch 47; iter: 0; batch classifier loss: 0.306495; batch adversarial loss: 0.448775\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420190; batch adversarial loss: 0.583254\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442412; batch adversarial loss: 0.583609\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408936; batch adversarial loss: 0.427994\n",
      "epoch 51; iter: 0; batch classifier loss: 0.479572; batch adversarial loss: 0.506031\n",
      "epoch 52; iter: 0; batch classifier loss: 0.375374; batch adversarial loss: 0.505816\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395313; batch adversarial loss: 0.554600\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384477; batch adversarial loss: 0.563493\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468944; batch adversarial loss: 0.447261\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468721; batch adversarial loss: 0.444501\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453027; batch adversarial loss: 0.651341\n",
      "epoch 58; iter: 0; batch classifier loss: 0.397272; batch adversarial loss: 0.594076\n",
      "epoch 59; iter: 0; batch classifier loss: 0.448373; batch adversarial loss: 0.514206\n",
      "epoch 60; iter: 0; batch classifier loss: 0.458680; batch adversarial loss: 0.613680\n",
      "epoch 61; iter: 0; batch classifier loss: 0.366697; batch adversarial loss: 0.566820\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422625; batch adversarial loss: 0.582833\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438626; batch adversarial loss: 0.510044\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431571; batch adversarial loss: 0.518360\n",
      "epoch 65; iter: 0; batch classifier loss: 0.372261; batch adversarial loss: 0.622573\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428269; batch adversarial loss: 0.506262\n",
      "epoch 67; iter: 0; batch classifier loss: 0.432550; batch adversarial loss: 0.548422\n",
      "epoch 68; iter: 0; batch classifier loss: 0.450597; batch adversarial loss: 0.562744\n",
      "epoch 69; iter: 0; batch classifier loss: 0.370889; batch adversarial loss: 0.583119\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388167; batch adversarial loss: 0.562886\n",
      "epoch 71; iter: 0; batch classifier loss: 0.464952; batch adversarial loss: 0.581574\n",
      "epoch 72; iter: 0; batch classifier loss: 0.545454; batch adversarial loss: 0.516775\n",
      "epoch 73; iter: 0; batch classifier loss: 0.340708; batch adversarial loss: 0.516488\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418424; batch adversarial loss: 0.516094\n",
      "epoch 75; iter: 0; batch classifier loss: 0.334390; batch adversarial loss: 0.507071\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364826; batch adversarial loss: 0.573062\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405656; batch adversarial loss: 0.515695\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400609; batch adversarial loss: 0.515689\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408815; batch adversarial loss: 0.545085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.437777; batch adversarial loss: 0.525359\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404858; batch adversarial loss: 0.554824\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374083; batch adversarial loss: 0.592916\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367749; batch adversarial loss: 0.582697\n",
      "epoch 84; iter: 0; batch classifier loss: 0.422189; batch adversarial loss: 0.554418\n",
      "epoch 85; iter: 0; batch classifier loss: 0.334009; batch adversarial loss: 0.552944\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389249; batch adversarial loss: 0.545275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.443033; batch adversarial loss: 0.544632\n",
      "epoch 88; iter: 0; batch classifier loss: 0.347064; batch adversarial loss: 0.526099\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355587; batch adversarial loss: 0.592459\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407142; batch adversarial loss: 0.516484\n",
      "epoch 91; iter: 0; batch classifier loss: 0.517098; batch adversarial loss: 0.514813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385201; batch adversarial loss: 0.544690\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403616; batch adversarial loss: 0.498405\n",
      "epoch 94; iter: 0; batch classifier loss: 0.519055; batch adversarial loss: 0.525454\n",
      "epoch 95; iter: 0; batch classifier loss: 0.386166; batch adversarial loss: 0.582668\n",
      "epoch 96; iter: 0; batch classifier loss: 0.503127; batch adversarial loss: 0.562764\n",
      "epoch 97; iter: 0; batch classifier loss: 0.463594; batch adversarial loss: 0.572974\n",
      "epoch 98; iter: 0; batch classifier loss: 0.461939; batch adversarial loss: 0.573790\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344289; batch adversarial loss: 0.496492\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433119; batch adversarial loss: 0.582408\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362605; batch adversarial loss: 0.524073\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412528; batch adversarial loss: 0.572670\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383016; batch adversarial loss: 0.439102\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373388; batch adversarial loss: 0.495622\n",
      "epoch 105; iter: 0; batch classifier loss: 0.436120; batch adversarial loss: 0.430255\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408704; batch adversarial loss: 0.468266\n",
      "epoch 107; iter: 0; batch classifier loss: 0.410111; batch adversarial loss: 0.545158\n",
      "epoch 108; iter: 0; batch classifier loss: 0.340166; batch adversarial loss: 0.544556\n",
      "epoch 109; iter: 0; batch classifier loss: 0.308648; batch adversarial loss: 0.554954\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397786; batch adversarial loss: 0.572449\n",
      "epoch 111; iter: 0; batch classifier loss: 0.425975; batch adversarial loss: 0.448710\n",
      "epoch 112; iter: 0; batch classifier loss: 0.331992; batch adversarial loss: 0.496017\n",
      "epoch 113; iter: 0; batch classifier loss: 0.364332; batch adversarial loss: 0.525312\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376814; batch adversarial loss: 0.554385\n",
      "epoch 115; iter: 0; batch classifier loss: 0.471400; batch adversarial loss: 0.621520\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365008; batch adversarial loss: 0.573511\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339769; batch adversarial loss: 0.543899\n",
      "epoch 118; iter: 0; batch classifier loss: 0.314932; batch adversarial loss: 0.506702\n",
      "epoch 119; iter: 0; batch classifier loss: 0.391007; batch adversarial loss: 0.486082\n",
      "epoch 120; iter: 0; batch classifier loss: 0.351079; batch adversarial loss: 0.545069\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362787; batch adversarial loss: 0.592259\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365057; batch adversarial loss: 0.563139\n",
      "epoch 123; iter: 0; batch classifier loss: 0.447714; batch adversarial loss: 0.497900\n",
      "epoch 124; iter: 0; batch classifier loss: 0.335606; batch adversarial loss: 0.592493\n",
      "epoch 125; iter: 0; batch classifier loss: 0.427478; batch adversarial loss: 0.496180\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367443; batch adversarial loss: 0.573961\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379016; batch adversarial loss: 0.534669\n",
      "epoch 128; iter: 0; batch classifier loss: 0.317958; batch adversarial loss: 0.486622\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365668; batch adversarial loss: 0.573923\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322603; batch adversarial loss: 0.516106\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338580; batch adversarial loss: 0.562655\n",
      "epoch 132; iter: 0; batch classifier loss: 0.324198; batch adversarial loss: 0.554993\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410722; batch adversarial loss: 0.584631\n",
      "epoch 134; iter: 0; batch classifier loss: 0.451478; batch adversarial loss: 0.564514\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400667; batch adversarial loss: 0.526274\n",
      "epoch 136; iter: 0; batch classifier loss: 0.436578; batch adversarial loss: 0.591894\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369662; batch adversarial loss: 0.496236\n",
      "epoch 138; iter: 0; batch classifier loss: 0.374839; batch adversarial loss: 0.602913\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392675; batch adversarial loss: 0.554830\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373904; batch adversarial loss: 0.505083\n",
      "epoch 141; iter: 0; batch classifier loss: 0.448114; batch adversarial loss: 0.534520\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359190; batch adversarial loss: 0.526390\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330553; batch adversarial loss: 0.564613\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409183; batch adversarial loss: 0.543388\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377556; batch adversarial loss: 0.505907\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366225; batch adversarial loss: 0.605107\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397326; batch adversarial loss: 0.623415\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312694; batch adversarial loss: 0.563697\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367647; batch adversarial loss: 0.611743\n",
      "epoch 150; iter: 0; batch classifier loss: 0.333076; batch adversarial loss: 0.514689\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405989; batch adversarial loss: 0.543132\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362667; batch adversarial loss: 0.554265\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320379; batch adversarial loss: 0.583978\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358039; batch adversarial loss: 0.555483\n",
      "epoch 155; iter: 0; batch classifier loss: 0.433787; batch adversarial loss: 0.506432\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380930; batch adversarial loss: 0.523868\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404039; batch adversarial loss: 0.621857\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338849; batch adversarial loss: 0.525169\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394288; batch adversarial loss: 0.515660\n",
      "epoch 160; iter: 0; batch classifier loss: 0.415647; batch adversarial loss: 0.553774\n",
      "epoch 161; iter: 0; batch classifier loss: 0.307896; batch adversarial loss: 0.602586\n",
      "epoch 162; iter: 0; batch classifier loss: 0.309828; batch adversarial loss: 0.524684\n",
      "epoch 163; iter: 0; batch classifier loss: 0.365651; batch adversarial loss: 0.534387\n",
      "epoch 164; iter: 0; batch classifier loss: 0.381759; batch adversarial loss: 0.631836\n",
      "epoch 165; iter: 0; batch classifier loss: 0.340237; batch adversarial loss: 0.544426\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376988; batch adversarial loss: 0.456849\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399518; batch adversarial loss: 0.485279\n",
      "epoch 168; iter: 0; batch classifier loss: 0.364434; batch adversarial loss: 0.486189\n",
      "epoch 169; iter: 0; batch classifier loss: 0.383090; batch adversarial loss: 0.582845\n",
      "epoch 170; iter: 0; batch classifier loss: 0.326375; batch adversarial loss: 0.533582\n",
      "epoch 171; iter: 0; batch classifier loss: 0.450141; batch adversarial loss: 0.582032\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330549; batch adversarial loss: 0.515922\n",
      "epoch 173; iter: 0; batch classifier loss: 0.389230; batch adversarial loss: 0.515369\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359951; batch adversarial loss: 0.545182\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342436; batch adversarial loss: 0.591397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.377696; batch adversarial loss: 0.497437\n",
      "epoch 177; iter: 0; batch classifier loss: 0.301724; batch adversarial loss: 0.583308\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309488; batch adversarial loss: 0.592483\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384861; batch adversarial loss: 0.591566\n",
      "epoch 180; iter: 0; batch classifier loss: 0.320509; batch adversarial loss: 0.534705\n",
      "epoch 181; iter: 0; batch classifier loss: 0.372808; batch adversarial loss: 0.564699\n",
      "epoch 182; iter: 0; batch classifier loss: 0.449624; batch adversarial loss: 0.495622\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393759; batch adversarial loss: 0.534796\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370241; batch adversarial loss: 0.641341\n",
      "epoch 185; iter: 0; batch classifier loss: 0.350919; batch adversarial loss: 0.583285\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371099; batch adversarial loss: 0.467395\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345906; batch adversarial loss: 0.573804\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378343; batch adversarial loss: 0.535474\n",
      "epoch 189; iter: 0; batch classifier loss: 0.392236; batch adversarial loss: 0.534335\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385092; batch adversarial loss: 0.622017\n",
      "epoch 191; iter: 0; batch classifier loss: 0.449218; batch adversarial loss: 0.477065\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297419; batch adversarial loss: 0.515481\n",
      "epoch 193; iter: 0; batch classifier loss: 0.302240; batch adversarial loss: 0.574691\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304697; batch adversarial loss: 0.545051\n",
      "epoch 195; iter: 0; batch classifier loss: 0.307873; batch adversarial loss: 0.485992\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346388; batch adversarial loss: 0.554574\n",
      "epoch 197; iter: 0; batch classifier loss: 0.384342; batch adversarial loss: 0.563502\n",
      "epoch 198; iter: 0; batch classifier loss: 0.307109; batch adversarial loss: 0.563175\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306444; batch adversarial loss: 0.575056\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684611; batch adversarial loss: 0.993567\n",
      "epoch 1; iter: 0; batch classifier loss: 0.723948; batch adversarial loss: 1.221975\n",
      "epoch 2; iter: 0; batch classifier loss: 0.919381; batch adversarial loss: 1.187749\n",
      "epoch 3; iter: 0; batch classifier loss: 1.007859; batch adversarial loss: 1.101144\n",
      "epoch 4; iter: 0; batch classifier loss: 1.154070; batch adversarial loss: 0.989558\n",
      "epoch 5; iter: 0; batch classifier loss: 1.003812; batch adversarial loss: 0.928681\n",
      "epoch 6; iter: 0; batch classifier loss: 1.029323; batch adversarial loss: 0.835894\n",
      "epoch 7; iter: 0; batch classifier loss: 0.928100; batch adversarial loss: 0.782508\n",
      "epoch 8; iter: 0; batch classifier loss: 0.802228; batch adversarial loss: 0.755057\n",
      "epoch 9; iter: 0; batch classifier loss: 0.834208; batch adversarial loss: 0.672996\n",
      "epoch 10; iter: 0; batch classifier loss: 0.698089; batch adversarial loss: 0.679843\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526512; batch adversarial loss: 0.598256\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460799; batch adversarial loss: 0.593994\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530623; batch adversarial loss: 0.616456\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503819; batch adversarial loss: 0.574475\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535048; batch adversarial loss: 0.574523\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519613; batch adversarial loss: 0.597765\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467853; batch adversarial loss: 0.532532\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559750; batch adversarial loss: 0.510926\n",
      "epoch 19; iter: 0; batch classifier loss: 0.540755; batch adversarial loss: 0.543118\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499402; batch adversarial loss: 0.548961\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496532; batch adversarial loss: 0.525615\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453697; batch adversarial loss: 0.526536\n",
      "epoch 23; iter: 0; batch classifier loss: 0.512898; batch adversarial loss: 0.582686\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464631; batch adversarial loss: 0.543965\n",
      "epoch 25; iter: 0; batch classifier loss: 0.537194; batch adversarial loss: 0.497029\n",
      "epoch 26; iter: 0; batch classifier loss: 0.528298; batch adversarial loss: 0.474716\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434505; batch adversarial loss: 0.517947\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450518; batch adversarial loss: 0.533139\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424151; batch adversarial loss: 0.538514\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470291; batch adversarial loss: 0.529053\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447293; batch adversarial loss: 0.552507\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510036; batch adversarial loss: 0.484337\n",
      "epoch 33; iter: 0; batch classifier loss: 0.436073; batch adversarial loss: 0.568908\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401488; batch adversarial loss: 0.630275\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491604; batch adversarial loss: 0.496760\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490740; batch adversarial loss: 0.511218\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407085; batch adversarial loss: 0.545123\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451035; batch adversarial loss: 0.489651\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453338; batch adversarial loss: 0.561414\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518617; batch adversarial loss: 0.486012\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416667; batch adversarial loss: 0.531571\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456182; batch adversarial loss: 0.487449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418126; batch adversarial loss: 0.524366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456964; batch adversarial loss: 0.483253\n",
      "epoch 45; iter: 0; batch classifier loss: 0.388770; batch adversarial loss: 0.533616\n",
      "epoch 46; iter: 0; batch classifier loss: 0.375492; batch adversarial loss: 0.519463\n",
      "epoch 47; iter: 0; batch classifier loss: 0.524230; batch adversarial loss: 0.541569\n",
      "epoch 48; iter: 0; batch classifier loss: 0.413180; batch adversarial loss: 0.442036\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451355; batch adversarial loss: 0.506921\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463530; batch adversarial loss: 0.543938\n",
      "epoch 51; iter: 0; batch classifier loss: 0.507896; batch adversarial loss: 0.573342\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430340; batch adversarial loss: 0.417234\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375837; batch adversarial loss: 0.485505\n",
      "epoch 54; iter: 0; batch classifier loss: 0.468645; batch adversarial loss: 0.564323\n",
      "epoch 55; iter: 0; batch classifier loss: 0.463509; batch adversarial loss: 0.463766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.469133; batch adversarial loss: 0.436173\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413243; batch adversarial loss: 0.517755\n",
      "epoch 58; iter: 0; batch classifier loss: 0.370018; batch adversarial loss: 0.462629\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444938; batch adversarial loss: 0.517178\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422032; batch adversarial loss: 0.479882\n",
      "epoch 61; iter: 0; batch classifier loss: 0.486266; batch adversarial loss: 0.572434\n",
      "epoch 62; iter: 0; batch classifier loss: 0.356282; batch adversarial loss: 0.590018\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461695; batch adversarial loss: 0.571813\n",
      "epoch 64; iter: 0; batch classifier loss: 0.471456; batch adversarial loss: 0.525669\n",
      "epoch 65; iter: 0; batch classifier loss: 0.356254; batch adversarial loss: 0.534542\n",
      "epoch 66; iter: 0; batch classifier loss: 0.487061; batch adversarial loss: 0.525890\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340777; batch adversarial loss: 0.525903\n",
      "epoch 68; iter: 0; batch classifier loss: 0.448961; batch adversarial loss: 0.469244\n",
      "epoch 69; iter: 0; batch classifier loss: 0.335321; batch adversarial loss: 0.565528\n",
      "epoch 70; iter: 0; batch classifier loss: 0.514169; batch adversarial loss: 0.572361\n",
      "epoch 71; iter: 0; batch classifier loss: 0.351990; batch adversarial loss: 0.505651\n",
      "epoch 72; iter: 0; batch classifier loss: 0.349848; batch adversarial loss: 0.533128\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414120; batch adversarial loss: 0.516233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.383353; batch adversarial loss: 0.563442\n",
      "epoch 75; iter: 0; batch classifier loss: 0.350224; batch adversarial loss: 0.546213\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465900; batch adversarial loss: 0.527642\n",
      "epoch 77; iter: 0; batch classifier loss: 0.339865; batch adversarial loss: 0.543823\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424777; batch adversarial loss: 0.486881\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379590; batch adversarial loss: 0.541913\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374937; batch adversarial loss: 0.533941\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376429; batch adversarial loss: 0.580220\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406060; batch adversarial loss: 0.517832\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444851; batch adversarial loss: 0.600428\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398767; batch adversarial loss: 0.616875\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401743; batch adversarial loss: 0.527043\n",
      "epoch 86; iter: 0; batch classifier loss: 0.462875; batch adversarial loss: 0.478210\n",
      "epoch 87; iter: 0; batch classifier loss: 0.474367; batch adversarial loss: 0.555630\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383594; batch adversarial loss: 0.543683\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350075; batch adversarial loss: 0.567798\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443744; batch adversarial loss: 0.515353\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375662; batch adversarial loss: 0.534100\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406961; batch adversarial loss: 0.487603\n",
      "epoch 93; iter: 0; batch classifier loss: 0.359769; batch adversarial loss: 0.556595\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411078; batch adversarial loss: 0.550615\n",
      "epoch 95; iter: 0; batch classifier loss: 0.366568; batch adversarial loss: 0.526470\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408439; batch adversarial loss: 0.511090\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399723; batch adversarial loss: 0.537155\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372776; batch adversarial loss: 0.559670\n",
      "epoch 99; iter: 0; batch classifier loss: 0.431463; batch adversarial loss: 0.484806\n",
      "epoch 100; iter: 0; batch classifier loss: 0.445676; batch adversarial loss: 0.519632\n",
      "epoch 101; iter: 0; batch classifier loss: 0.475147; batch adversarial loss: 0.511203\n",
      "epoch 102; iter: 0; batch classifier loss: 0.348751; batch adversarial loss: 0.556476\n",
      "epoch 103; iter: 0; batch classifier loss: 0.349174; batch adversarial loss: 0.617662\n",
      "epoch 104; iter: 0; batch classifier loss: 0.407898; batch adversarial loss: 0.528510\n",
      "epoch 105; iter: 0; batch classifier loss: 0.331797; batch adversarial loss: 0.528495\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374756; batch adversarial loss: 0.572043\n",
      "epoch 107; iter: 0; batch classifier loss: 0.434045; batch adversarial loss: 0.604337\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362258; batch adversarial loss: 0.511711\n",
      "epoch 109; iter: 0; batch classifier loss: 0.389989; batch adversarial loss: 0.602236\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402300; batch adversarial loss: 0.551599\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394491; batch adversarial loss: 0.571801\n",
      "epoch 112; iter: 0; batch classifier loss: 0.308350; batch adversarial loss: 0.562852\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392777; batch adversarial loss: 0.525805\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346987; batch adversarial loss: 0.569286\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404483; batch adversarial loss: 0.544801\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366179; batch adversarial loss: 0.515580\n",
      "epoch 117; iter: 0; batch classifier loss: 0.425202; batch adversarial loss: 0.564488\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398195; batch adversarial loss: 0.583174\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348786; batch adversarial loss: 0.551902\n",
      "epoch 120; iter: 0; batch classifier loss: 0.396663; batch adversarial loss: 0.516248\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316906; batch adversarial loss: 0.536568\n",
      "epoch 122; iter: 0; batch classifier loss: 0.420427; batch adversarial loss: 0.553205\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352296; batch adversarial loss: 0.546640\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352094; batch adversarial loss: 0.536034\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351581; batch adversarial loss: 0.640016\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369257; batch adversarial loss: 0.507191\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334112; batch adversarial loss: 0.487295\n",
      "epoch 128; iter: 0; batch classifier loss: 0.335226; batch adversarial loss: 0.488048\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399622; batch adversarial loss: 0.534779\n",
      "epoch 130; iter: 0; batch classifier loss: 0.331001; batch adversarial loss: 0.503450\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389731; batch adversarial loss: 0.524207\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351825; batch adversarial loss: 0.508865\n",
      "epoch 133; iter: 0; batch classifier loss: 0.294605; batch adversarial loss: 0.545010\n",
      "epoch 134; iter: 0; batch classifier loss: 0.388534; batch adversarial loss: 0.525271\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371452; batch adversarial loss: 0.658592\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364463; batch adversarial loss: 0.592030\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370181; batch adversarial loss: 0.507200\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369189; batch adversarial loss: 0.466371\n",
      "epoch 139; iter: 0; batch classifier loss: 0.311707; batch adversarial loss: 0.551111\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335070; batch adversarial loss: 0.487735\n",
      "epoch 141; iter: 0; batch classifier loss: 0.306506; batch adversarial loss: 0.525726\n",
      "epoch 142; iter: 0; batch classifier loss: 0.332939; batch adversarial loss: 0.508122\n",
      "epoch 143; iter: 0; batch classifier loss: 0.320409; batch adversarial loss: 0.563107\n",
      "epoch 144; iter: 0; batch classifier loss: 0.316219; batch adversarial loss: 0.499965\n",
      "epoch 145; iter: 0; batch classifier loss: 0.322379; batch adversarial loss: 0.563453\n",
      "epoch 146; iter: 0; batch classifier loss: 0.286905; batch adversarial loss: 0.535666\n",
      "epoch 147; iter: 0; batch classifier loss: 0.301648; batch adversarial loss: 0.540166\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349489; batch adversarial loss: 0.573021\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347041; batch adversarial loss: 0.561153\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372755; batch adversarial loss: 0.526533\n",
      "epoch 151; iter: 0; batch classifier loss: 0.428115; batch adversarial loss: 0.478946\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330960; batch adversarial loss: 0.495610\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357968; batch adversarial loss: 0.533325\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397953; batch adversarial loss: 0.562402\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398924; batch adversarial loss: 0.619749\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346602; batch adversarial loss: 0.561188\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313994; batch adversarial loss: 0.523869\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376539; batch adversarial loss: 0.598252\n",
      "epoch 159; iter: 0; batch classifier loss: 0.291640; batch adversarial loss: 0.514081\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328111; batch adversarial loss: 0.556058\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376544; batch adversarial loss: 0.636782\n",
      "epoch 162; iter: 0; batch classifier loss: 0.296022; batch adversarial loss: 0.613687\n",
      "epoch 163; iter: 0; batch classifier loss: 0.412295; batch adversarial loss: 0.564797\n",
      "epoch 164; iter: 0; batch classifier loss: 0.347248; batch adversarial loss: 0.600465\n",
      "epoch 165; iter: 0; batch classifier loss: 0.331799; batch adversarial loss: 0.541625\n",
      "epoch 166; iter: 0; batch classifier loss: 0.317891; batch adversarial loss: 0.614020\n",
      "epoch 167; iter: 0; batch classifier loss: 0.326208; batch adversarial loss: 0.527086\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332156; batch adversarial loss: 0.554908\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362203; batch adversarial loss: 0.459517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.370884; batch adversarial loss: 0.496384\n",
      "epoch 171; iter: 0; batch classifier loss: 0.296200; batch adversarial loss: 0.450374\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330374; batch adversarial loss: 0.509182\n",
      "epoch 173; iter: 0; batch classifier loss: 0.347575; batch adversarial loss: 0.516203\n",
      "epoch 174; iter: 0; batch classifier loss: 0.397877; batch adversarial loss: 0.673167\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355003; batch adversarial loss: 0.486551\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377404; batch adversarial loss: 0.487199\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344003; batch adversarial loss: 0.514953\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358122; batch adversarial loss: 0.578791\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357051; batch adversarial loss: 0.613044\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324323; batch adversarial loss: 0.522945\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319412; batch adversarial loss: 0.553714\n",
      "epoch 182; iter: 0; batch classifier loss: 0.353224; batch adversarial loss: 0.514331\n",
      "epoch 183; iter: 0; batch classifier loss: 0.303152; batch adversarial loss: 0.476799\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325642; batch adversarial loss: 0.665485\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393719; batch adversarial loss: 0.541390\n",
      "epoch 186; iter: 0; batch classifier loss: 0.275657; batch adversarial loss: 0.496597\n",
      "epoch 187; iter: 0; batch classifier loss: 0.318672; batch adversarial loss: 0.581788\n",
      "epoch 188; iter: 0; batch classifier loss: 0.294710; batch adversarial loss: 0.545016\n",
      "epoch 189; iter: 0; batch classifier loss: 0.397734; batch adversarial loss: 0.608688\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344080; batch adversarial loss: 0.554364\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319509; batch adversarial loss: 0.535369\n",
      "epoch 192; iter: 0; batch classifier loss: 0.301898; batch adversarial loss: 0.623274\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348527; batch adversarial loss: 0.517790\n",
      "epoch 194; iter: 0; batch classifier loss: 0.387335; batch adversarial loss: 0.554250\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339163; batch adversarial loss: 0.591309\n",
      "epoch 196; iter: 0; batch classifier loss: 0.305565; batch adversarial loss: 0.570918\n",
      "epoch 197; iter: 0; batch classifier loss: 0.314290; batch adversarial loss: 0.505942\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365842; batch adversarial loss: 0.580763\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379212; batch adversarial loss: 0.562370\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682371; batch adversarial loss: 0.691238\n",
      "epoch 1; iter: 0; batch classifier loss: 0.570473; batch adversarial loss: 0.650196\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582319; batch adversarial loss: 0.641362\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565991; batch adversarial loss: 0.636125\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589894; batch adversarial loss: 0.618636\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577245; batch adversarial loss: 0.598888\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592642; batch adversarial loss: 0.613279\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546408; batch adversarial loss: 0.549901\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520138; batch adversarial loss: 0.596303\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525391; batch adversarial loss: 0.563569\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610201; batch adversarial loss: 0.555954\n",
      "epoch 11; iter: 0; batch classifier loss: 0.488559; batch adversarial loss: 0.569912\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467410; batch adversarial loss: 0.567303\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541452; batch adversarial loss: 0.546235\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504811; batch adversarial loss: 0.611616\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470486; batch adversarial loss: 0.590514\n",
      "epoch 16; iter: 0; batch classifier loss: 0.461042; batch adversarial loss: 0.541817\n",
      "epoch 17; iter: 0; batch classifier loss: 0.412129; batch adversarial loss: 0.599300\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522592; batch adversarial loss: 0.536432\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488334; batch adversarial loss: 0.599991\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521884; batch adversarial loss: 0.496029\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503353; batch adversarial loss: 0.515461\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472923; batch adversarial loss: 0.458023\n",
      "epoch 23; iter: 0; batch classifier loss: 0.562195; batch adversarial loss: 0.632354\n",
      "epoch 24; iter: 0; batch classifier loss: 0.438873; batch adversarial loss: 0.563896\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462002; batch adversarial loss: 0.585623\n",
      "epoch 26; iter: 0; batch classifier loss: 0.383845; batch adversarial loss: 0.521802\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449810; batch adversarial loss: 0.524257\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413910; batch adversarial loss: 0.540607\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501180; batch adversarial loss: 0.573316\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506326; batch adversarial loss: 0.451865\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468807; batch adversarial loss: 0.598741\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496249; batch adversarial loss: 0.504836\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425307; batch adversarial loss: 0.456306\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421119; batch adversarial loss: 0.610426\n",
      "epoch 35; iter: 0; batch classifier loss: 0.544973; batch adversarial loss: 0.472098\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454910; batch adversarial loss: 0.553340\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445948; batch adversarial loss: 0.481926\n",
      "epoch 38; iter: 0; batch classifier loss: 0.411656; batch adversarial loss: 0.471568\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424079; batch adversarial loss: 0.534985\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435655; batch adversarial loss: 0.581315\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441777; batch adversarial loss: 0.461597\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466865; batch adversarial loss: 0.563140\n",
      "epoch 43; iter: 0; batch classifier loss: 0.504995; batch adversarial loss: 0.609586\n",
      "epoch 44; iter: 0; batch classifier loss: 0.365881; batch adversarial loss: 0.535028\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437818; batch adversarial loss: 0.497763\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437753; batch adversarial loss: 0.564033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433410; batch adversarial loss: 0.516288\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400927; batch adversarial loss: 0.506591\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437266; batch adversarial loss: 0.478387\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455613; batch adversarial loss: 0.525220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.451913; batch adversarial loss: 0.610156\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389364; batch adversarial loss: 0.525621\n",
      "epoch 53; iter: 0; batch classifier loss: 0.456467; batch adversarial loss: 0.516030\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445634; batch adversarial loss: 0.525126\n",
      "epoch 55; iter: 0; batch classifier loss: 0.418039; batch adversarial loss: 0.497352\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433664; batch adversarial loss: 0.573252\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402634; batch adversarial loss: 0.488498\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437368; batch adversarial loss: 0.583264\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387015; batch adversarial loss: 0.467128\n",
      "epoch 60; iter: 0; batch classifier loss: 0.326347; batch adversarial loss: 0.479513\n",
      "epoch 61; iter: 0; batch classifier loss: 0.387458; batch adversarial loss: 0.582018\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428975; batch adversarial loss: 0.457841\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454001; batch adversarial loss: 0.563497\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387618; batch adversarial loss: 0.524837\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412988; batch adversarial loss: 0.525778\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415320; batch adversarial loss: 0.533283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67; iter: 0; batch classifier loss: 0.383228; batch adversarial loss: 0.508946\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438455; batch adversarial loss: 0.496052\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419102; batch adversarial loss: 0.571594\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397732; batch adversarial loss: 0.551413\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396909; batch adversarial loss: 0.515690\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442222; batch adversarial loss: 0.574062\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375190; batch adversarial loss: 0.526098\n",
      "epoch 74; iter: 0; batch classifier loss: 0.361823; batch adversarial loss: 0.536670\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358261; batch adversarial loss: 0.574471\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383011; batch adversarial loss: 0.528524\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409342; batch adversarial loss: 0.573805\n",
      "epoch 78; iter: 0; batch classifier loss: 0.313196; batch adversarial loss: 0.554550\n",
      "epoch 79; iter: 0; batch classifier loss: 0.427158; batch adversarial loss: 0.527405\n",
      "epoch 80; iter: 0; batch classifier loss: 0.346998; batch adversarial loss: 0.505983\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423017; batch adversarial loss: 0.470590\n",
      "epoch 82; iter: 0; batch classifier loss: 0.329887; batch adversarial loss: 0.555171\n",
      "epoch 83; iter: 0; batch classifier loss: 0.485763; batch adversarial loss: 0.562158\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360544; batch adversarial loss: 0.640439\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369786; batch adversarial loss: 0.591983\n",
      "epoch 86; iter: 0; batch classifier loss: 0.457978; batch adversarial loss: 0.506514\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423207; batch adversarial loss: 0.544661\n",
      "epoch 88; iter: 0; batch classifier loss: 0.341173; batch adversarial loss: 0.659143\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424502; batch adversarial loss: 0.516958\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359322; batch adversarial loss: 0.545400\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398341; batch adversarial loss: 0.563856\n",
      "epoch 92; iter: 0; batch classifier loss: 0.341108; batch adversarial loss: 0.608536\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349733; batch adversarial loss: 0.561929\n",
      "epoch 94; iter: 0; batch classifier loss: 0.342123; batch adversarial loss: 0.658256\n",
      "epoch 95; iter: 0; batch classifier loss: 0.326841; batch adversarial loss: 0.507081\n",
      "epoch 96; iter: 0; batch classifier loss: 0.424920; batch adversarial loss: 0.573540\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359070; batch adversarial loss: 0.515712\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373403; batch adversarial loss: 0.525562\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348527; batch adversarial loss: 0.448989\n",
      "epoch 100; iter: 0; batch classifier loss: 0.323043; batch adversarial loss: 0.542234\n",
      "epoch 101; iter: 0; batch classifier loss: 0.423193; batch adversarial loss: 0.524048\n",
      "epoch 102; iter: 0; batch classifier loss: 0.314285; batch adversarial loss: 0.496338\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350956; batch adversarial loss: 0.526627\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390976; batch adversarial loss: 0.487200\n",
      "epoch 105; iter: 0; batch classifier loss: 0.377301; batch adversarial loss: 0.545021\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379178; batch adversarial loss: 0.516962\n",
      "epoch 107; iter: 0; batch classifier loss: 0.395803; batch adversarial loss: 0.599246\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392707; batch adversarial loss: 0.554166\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361163; batch adversarial loss: 0.533744\n",
      "epoch 110; iter: 0; batch classifier loss: 0.394668; batch adversarial loss: 0.450066\n",
      "epoch 111; iter: 0; batch classifier loss: 0.483626; batch adversarial loss: 0.496676\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361463; batch adversarial loss: 0.515004\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358366; batch adversarial loss: 0.563305\n",
      "epoch 114; iter: 0; batch classifier loss: 0.285668; batch adversarial loss: 0.433461\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379102; batch adversarial loss: 0.593317\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346609; batch adversarial loss: 0.535928\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402309; batch adversarial loss: 0.536503\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360618; batch adversarial loss: 0.620153\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414908; batch adversarial loss: 0.544476\n",
      "epoch 120; iter: 0; batch classifier loss: 0.367789; batch adversarial loss: 0.601968\n",
      "epoch 121; iter: 0; batch classifier loss: 0.374868; batch adversarial loss: 0.542824\n",
      "epoch 122; iter: 0; batch classifier loss: 0.461797; batch adversarial loss: 0.555616\n",
      "epoch 123; iter: 0; batch classifier loss: 0.496611; batch adversarial loss: 0.400669\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398756; batch adversarial loss: 0.526284\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360361; batch adversarial loss: 0.573281\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387276; batch adversarial loss: 0.509396\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349744; batch adversarial loss: 0.497249\n",
      "epoch 128; iter: 0; batch classifier loss: 0.316539; batch adversarial loss: 0.536738\n",
      "epoch 129; iter: 0; batch classifier loss: 0.298569; batch adversarial loss: 0.468608\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421389; batch adversarial loss: 0.610153\n",
      "epoch 131; iter: 0; batch classifier loss: 0.416313; batch adversarial loss: 0.498581\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372798; batch adversarial loss: 0.592077\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397863; batch adversarial loss: 0.572565\n",
      "epoch 134; iter: 0; batch classifier loss: 0.434838; batch adversarial loss: 0.515976\n",
      "epoch 135; iter: 0; batch classifier loss: 0.491614; batch adversarial loss: 0.534377\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358620; batch adversarial loss: 0.668624\n",
      "epoch 137; iter: 0; batch classifier loss: 0.311495; batch adversarial loss: 0.509315\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356548; batch adversarial loss: 0.582203\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355424; batch adversarial loss: 0.471047\n",
      "epoch 140; iter: 0; batch classifier loss: 0.465699; batch adversarial loss: 0.506173\n",
      "epoch 141; iter: 0; batch classifier loss: 0.319400; batch adversarial loss: 0.608993\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412252; batch adversarial loss: 0.488019\n",
      "epoch 143; iter: 0; batch classifier loss: 0.459402; batch adversarial loss: 0.609513\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415891; batch adversarial loss: 0.506559\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349876; batch adversarial loss: 0.515627\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380219; batch adversarial loss: 0.487611\n",
      "epoch 147; iter: 0; batch classifier loss: 0.331762; batch adversarial loss: 0.611648\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368052; batch adversarial loss: 0.563497\n",
      "epoch 149; iter: 0; batch classifier loss: 0.380569; batch adversarial loss: 0.439404\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341830; batch adversarial loss: 0.469301\n",
      "epoch 151; iter: 0; batch classifier loss: 0.316923; batch adversarial loss: 0.535000\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330567; batch adversarial loss: 0.478396\n",
      "epoch 153; iter: 0; batch classifier loss: 0.325579; batch adversarial loss: 0.527482\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340576; batch adversarial loss: 0.543702\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359404; batch adversarial loss: 0.552294\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340580; batch adversarial loss: 0.461263\n",
      "epoch 157; iter: 0; batch classifier loss: 0.456109; batch adversarial loss: 0.459057\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375083; batch adversarial loss: 0.506168\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343803; batch adversarial loss: 0.542734\n",
      "epoch 160; iter: 0; batch classifier loss: 0.346561; batch adversarial loss: 0.545647\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372205; batch adversarial loss: 0.498168\n",
      "epoch 162; iter: 0; batch classifier loss: 0.345468; batch adversarial loss: 0.524867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 163; iter: 0; batch classifier loss: 0.382362; batch adversarial loss: 0.535441\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334876; batch adversarial loss: 0.544399\n",
      "epoch 165; iter: 0; batch classifier loss: 0.434326; batch adversarial loss: 0.526384\n",
      "epoch 166; iter: 0; batch classifier loss: 0.413634; batch adversarial loss: 0.609726\n",
      "epoch 167; iter: 0; batch classifier loss: 0.310094; batch adversarial loss: 0.601456\n",
      "epoch 168; iter: 0; batch classifier loss: 0.407090; batch adversarial loss: 0.524822\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342851; batch adversarial loss: 0.564230\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374330; batch adversarial loss: 0.526805\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409463; batch adversarial loss: 0.591691\n",
      "epoch 172; iter: 0; batch classifier loss: 0.273547; batch adversarial loss: 0.628856\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360332; batch adversarial loss: 0.572045\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325196; batch adversarial loss: 0.478262\n",
      "epoch 175; iter: 0; batch classifier loss: 0.301446; batch adversarial loss: 0.533926\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369528; batch adversarial loss: 0.563248\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354630; batch adversarial loss: 0.507848\n",
      "epoch 178; iter: 0; batch classifier loss: 0.430697; batch adversarial loss: 0.603534\n",
      "epoch 179; iter: 0; batch classifier loss: 0.312039; batch adversarial loss: 0.477646\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315727; batch adversarial loss: 0.545937\n",
      "epoch 181; iter: 0; batch classifier loss: 0.385740; batch adversarial loss: 0.515592\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357125; batch adversarial loss: 0.554743\n",
      "epoch 183; iter: 0; batch classifier loss: 0.397385; batch adversarial loss: 0.527286\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374344; batch adversarial loss: 0.564801\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333474; batch adversarial loss: 0.552157\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328541; batch adversarial loss: 0.524954\n",
      "epoch 187; iter: 0; batch classifier loss: 0.449231; batch adversarial loss: 0.508790\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391031; batch adversarial loss: 0.514917\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383270; batch adversarial loss: 0.504789\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339351; batch adversarial loss: 0.534065\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325543; batch adversarial loss: 0.564668\n",
      "epoch 192; iter: 0; batch classifier loss: 0.346732; batch adversarial loss: 0.582807\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348724; batch adversarial loss: 0.515356\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343382; batch adversarial loss: 0.555268\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312903; batch adversarial loss: 0.638832\n",
      "epoch 196; iter: 0; batch classifier loss: 0.284608; batch adversarial loss: 0.555070\n",
      "epoch 197; iter: 0; batch classifier loss: 0.468234; batch adversarial loss: 0.527570\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317871; batch adversarial loss: 0.582902\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374666; batch adversarial loss: 0.487176\n",
      "epoch 0; iter: 0; batch classifier loss: 0.643142; batch adversarial loss: 0.691053\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602107; batch adversarial loss: 0.672169\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547854; batch adversarial loss: 0.661706\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629116; batch adversarial loss: 0.647677\n",
      "epoch 4; iter: 0; batch classifier loss: 0.496248; batch adversarial loss: 0.624374\n",
      "epoch 5; iter: 0; batch classifier loss: 0.542459; batch adversarial loss: 0.622043\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504806; batch adversarial loss: 0.614194\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565477; batch adversarial loss: 0.571786\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534254; batch adversarial loss: 0.567137\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565112; batch adversarial loss: 0.553771\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487291; batch adversarial loss: 0.563583\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505689; batch adversarial loss: 0.566961\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567685; batch adversarial loss: 0.585574\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510460; batch adversarial loss: 0.549045\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477665; batch adversarial loss: 0.556043\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539139; batch adversarial loss: 0.594805\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492514; batch adversarial loss: 0.589070\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535749; batch adversarial loss: 0.620250\n",
      "epoch 18; iter: 0; batch classifier loss: 0.590490; batch adversarial loss: 0.538621\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497674; batch adversarial loss: 0.602985\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521534; batch adversarial loss: 0.577366\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455365; batch adversarial loss: 0.600755\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492746; batch adversarial loss: 0.580224\n",
      "epoch 23; iter: 0; batch classifier loss: 0.564683; batch adversarial loss: 0.562356\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507518; batch adversarial loss: 0.530417\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489631; batch adversarial loss: 0.566700\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495761; batch adversarial loss: 0.623743\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428436; batch adversarial loss: 0.588715\n",
      "epoch 28; iter: 0; batch classifier loss: 0.525186; batch adversarial loss: 0.524796\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504011; batch adversarial loss: 0.585087\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453017; batch adversarial loss: 0.552650\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501924; batch adversarial loss: 0.491409\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450186; batch adversarial loss: 0.530396\n",
      "epoch 33; iter: 0; batch classifier loss: 0.347486; batch adversarial loss: 0.565292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415122; batch adversarial loss: 0.551680\n",
      "epoch 35; iter: 0; batch classifier loss: 0.503142; batch adversarial loss: 0.573451\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455149; batch adversarial loss: 0.544436\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425213; batch adversarial loss: 0.537193\n",
      "epoch 38; iter: 0; batch classifier loss: 0.397906; batch adversarial loss: 0.509786\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497958; batch adversarial loss: 0.570709\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456925; batch adversarial loss: 0.567466\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478961; batch adversarial loss: 0.525964\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455606; batch adversarial loss: 0.524965\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435752; batch adversarial loss: 0.596356\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437103; batch adversarial loss: 0.589274\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444533; batch adversarial loss: 0.499173\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411774; batch adversarial loss: 0.555576\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395045; batch adversarial loss: 0.636691\n",
      "epoch 48; iter: 0; batch classifier loss: 0.467548; batch adversarial loss: 0.471378\n",
      "epoch 49; iter: 0; batch classifier loss: 0.426630; batch adversarial loss: 0.518046\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391479; batch adversarial loss: 0.562253\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379702; batch adversarial loss: 0.497485\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390762; batch adversarial loss: 0.571352\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418949; batch adversarial loss: 0.590414\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428885; batch adversarial loss: 0.500740\n",
      "epoch 55; iter: 0; batch classifier loss: 0.357919; batch adversarial loss: 0.527308\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473894; batch adversarial loss: 0.569745\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429344; batch adversarial loss: 0.562555\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440619; batch adversarial loss: 0.534894\n",
      "epoch 59; iter: 0; batch classifier loss: 0.480544; batch adversarial loss: 0.492639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.379629; batch adversarial loss: 0.588903\n",
      "epoch 61; iter: 0; batch classifier loss: 0.384935; batch adversarial loss: 0.580727\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427501; batch adversarial loss: 0.462047\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400170; batch adversarial loss: 0.562958\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420254; batch adversarial loss: 0.670215\n",
      "epoch 65; iter: 0; batch classifier loss: 0.335187; batch adversarial loss: 0.589649\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416573; batch adversarial loss: 0.515406\n",
      "epoch 67; iter: 0; batch classifier loss: 0.476571; batch adversarial loss: 0.534085\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430935; batch adversarial loss: 0.590194\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401250; batch adversarial loss: 0.486983\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451430; batch adversarial loss: 0.533786\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387799; batch adversarial loss: 0.500574\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388251; batch adversarial loss: 0.626035\n",
      "epoch 73; iter: 0; batch classifier loss: 0.502032; batch adversarial loss: 0.554112\n",
      "epoch 74; iter: 0; batch classifier loss: 0.463624; batch adversarial loss: 0.497862\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382081; batch adversarial loss: 0.489855\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408202; batch adversarial loss: 0.589344\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372286; batch adversarial loss: 0.626408\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402794; batch adversarial loss: 0.516097\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433836; batch adversarial loss: 0.572670\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429279; batch adversarial loss: 0.518070\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426251; batch adversarial loss: 0.509282\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407690; batch adversarial loss: 0.535061\n",
      "epoch 83; iter: 0; batch classifier loss: 0.379629; batch adversarial loss: 0.508750\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445555; batch adversarial loss: 0.462246\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408826; batch adversarial loss: 0.542424\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416521; batch adversarial loss: 0.553496\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375063; batch adversarial loss: 0.527688\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425031; batch adversarial loss: 0.554614\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398236; batch adversarial loss: 0.553657\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373416; batch adversarial loss: 0.524828\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385016; batch adversarial loss: 0.545856\n",
      "epoch 92; iter: 0; batch classifier loss: 0.335697; batch adversarial loss: 0.506395\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377476; batch adversarial loss: 0.499654\n",
      "epoch 94; iter: 0; batch classifier loss: 0.386870; batch adversarial loss: 0.698557\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384057; batch adversarial loss: 0.571841\n",
      "epoch 96; iter: 0; batch classifier loss: 0.433606; batch adversarial loss: 0.526258\n",
      "epoch 97; iter: 0; batch classifier loss: 0.403550; batch adversarial loss: 0.490408\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392183; batch adversarial loss: 0.600339\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360698; batch adversarial loss: 0.526771\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396007; batch adversarial loss: 0.462757\n",
      "epoch 101; iter: 0; batch classifier loss: 0.463044; batch adversarial loss: 0.498338\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382854; batch adversarial loss: 0.542903\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365547; batch adversarial loss: 0.509285\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348697; batch adversarial loss: 0.488581\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365588; batch adversarial loss: 0.543859\n",
      "epoch 106; iter: 0; batch classifier loss: 0.444454; batch adversarial loss: 0.589941\n",
      "epoch 107; iter: 0; batch classifier loss: 0.320140; batch adversarial loss: 0.534774\n",
      "epoch 108; iter: 0; batch classifier loss: 0.451280; batch adversarial loss: 0.608552\n",
      "epoch 109; iter: 0; batch classifier loss: 0.417928; batch adversarial loss: 0.580967\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401525; batch adversarial loss: 0.508644\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405699; batch adversarial loss: 0.635460\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383948; batch adversarial loss: 0.497915\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407703; batch adversarial loss: 0.487726\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381945; batch adversarial loss: 0.588060\n",
      "epoch 115; iter: 0; batch classifier loss: 0.320362; batch adversarial loss: 0.546496\n",
      "epoch 116; iter: 0; batch classifier loss: 0.423869; batch adversarial loss: 0.563330\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405583; batch adversarial loss: 0.625738\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412808; batch adversarial loss: 0.590517\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368025; batch adversarial loss: 0.436813\n",
      "epoch 120; iter: 0; batch classifier loss: 0.403557; batch adversarial loss: 0.535477\n",
      "epoch 121; iter: 0; batch classifier loss: 0.431557; batch adversarial loss: 0.527429\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362901; batch adversarial loss: 0.525727\n",
      "epoch 123; iter: 0; batch classifier loss: 0.422225; batch adversarial loss: 0.516915\n",
      "epoch 124; iter: 0; batch classifier loss: 0.489052; batch adversarial loss: 0.625800\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418000; batch adversarial loss: 0.618335\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354332; batch adversarial loss: 0.617723\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385407; batch adversarial loss: 0.608521\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409390; batch adversarial loss: 0.562397\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369148; batch adversarial loss: 0.571841\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345674; batch adversarial loss: 0.553140\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371721; batch adversarial loss: 0.510646\n",
      "epoch 132; iter: 0; batch classifier loss: 0.426586; batch adversarial loss: 0.616222\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398705; batch adversarial loss: 0.525473\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373815; batch adversarial loss: 0.617634\n",
      "epoch 135; iter: 0; batch classifier loss: 0.326660; batch adversarial loss: 0.562832\n",
      "epoch 136; iter: 0; batch classifier loss: 0.422912; batch adversarial loss: 0.544210\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344080; batch adversarial loss: 0.481120\n",
      "epoch 138; iter: 0; batch classifier loss: 0.440231; batch adversarial loss: 0.517149\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377531; batch adversarial loss: 0.498649\n",
      "epoch 140; iter: 0; batch classifier loss: 0.445870; batch adversarial loss: 0.489645\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371980; batch adversarial loss: 0.535181\n",
      "epoch 142; iter: 0; batch classifier loss: 0.426469; batch adversarial loss: 0.563916\n",
      "epoch 143; iter: 0; batch classifier loss: 0.450215; batch adversarial loss: 0.616368\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368395; batch adversarial loss: 0.555126\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377922; batch adversarial loss: 0.571186\n",
      "epoch 146; iter: 0; batch classifier loss: 0.457153; batch adversarial loss: 0.570794\n",
      "epoch 147; iter: 0; batch classifier loss: 0.315976; batch adversarial loss: 0.572194\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363639; batch adversarial loss: 0.644934\n",
      "epoch 149; iter: 0; batch classifier loss: 0.372926; batch adversarial loss: 0.489042\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382337; batch adversarial loss: 0.435818\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326216; batch adversarial loss: 0.553924\n",
      "epoch 152; iter: 0; batch classifier loss: 0.380201; batch adversarial loss: 0.562809\n",
      "epoch 153; iter: 0; batch classifier loss: 0.419785; batch adversarial loss: 0.535170\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389579; batch adversarial loss: 0.508070\n",
      "epoch 155; iter: 0; batch classifier loss: 0.396975; batch adversarial loss: 0.591565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.286903; batch adversarial loss: 0.544277\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319447; batch adversarial loss: 0.406928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.288703; batch adversarial loss: 0.580415\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323139; batch adversarial loss: 0.524847\n",
      "epoch 160; iter: 0; batch classifier loss: 0.434292; batch adversarial loss: 0.490772\n",
      "epoch 161; iter: 0; batch classifier loss: 0.472538; batch adversarial loss: 0.555209\n",
      "epoch 162; iter: 0; batch classifier loss: 0.342623; batch adversarial loss: 0.581872\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380877; batch adversarial loss: 0.453707\n",
      "epoch 164; iter: 0; batch classifier loss: 0.465938; batch adversarial loss: 0.633484\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373829; batch adversarial loss: 0.619903\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395869; batch adversarial loss: 0.435914\n",
      "epoch 167; iter: 0; batch classifier loss: 0.457604; batch adversarial loss: 0.572645\n",
      "epoch 168; iter: 0; batch classifier loss: 0.384321; batch adversarial loss: 0.555372\n",
      "epoch 169; iter: 0; batch classifier loss: 0.373806; batch adversarial loss: 0.536623\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369916; batch adversarial loss: 0.655153\n",
      "epoch 171; iter: 0; batch classifier loss: 0.462202; batch adversarial loss: 0.547082\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363372; batch adversarial loss: 0.516647\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375545; batch adversarial loss: 0.490244\n",
      "epoch 174; iter: 0; batch classifier loss: 0.428447; batch adversarial loss: 0.606776\n",
      "epoch 175; iter: 0; batch classifier loss: 0.411130; batch adversarial loss: 0.627284\n",
      "epoch 176; iter: 0; batch classifier loss: 0.444225; batch adversarial loss: 0.590814\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329497; batch adversarial loss: 0.545555\n",
      "epoch 178; iter: 0; batch classifier loss: 0.445286; batch adversarial loss: 0.610447\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341736; batch adversarial loss: 0.616718\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362241; batch adversarial loss: 0.608807\n",
      "epoch 181; iter: 0; batch classifier loss: 0.356642; batch adversarial loss: 0.544518\n",
      "epoch 182; iter: 0; batch classifier loss: 0.362782; batch adversarial loss: 0.590007\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391884; batch adversarial loss: 0.480725\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356640; batch adversarial loss: 0.580440\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331200; batch adversarial loss: 0.547130\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361515; batch adversarial loss: 0.529254\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362321; batch adversarial loss: 0.615337\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365697; batch adversarial loss: 0.563259\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341586; batch adversarial loss: 0.598765\n",
      "epoch 190; iter: 0; batch classifier loss: 0.387342; batch adversarial loss: 0.616966\n",
      "epoch 191; iter: 0; batch classifier loss: 0.411566; batch adversarial loss: 0.507441\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384017; batch adversarial loss: 0.526974\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345898; batch adversarial loss: 0.579776\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364122; batch adversarial loss: 0.536115\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383709; batch adversarial loss: 0.671951\n",
      "epoch 196; iter: 0; batch classifier loss: 0.382541; batch adversarial loss: 0.554974\n",
      "epoch 197; iter: 0; batch classifier loss: 0.467642; batch adversarial loss: 0.581565\n",
      "epoch 198; iter: 0; batch classifier loss: 0.421902; batch adversarial loss: 0.553740\n",
      "epoch 199; iter: 0; batch classifier loss: 0.429072; batch adversarial loss: 0.497099\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734805; batch adversarial loss: 0.833784\n",
      "epoch 1; iter: 0; batch classifier loss: 0.672733; batch adversarial loss: 0.865364\n",
      "epoch 2; iter: 0; batch classifier loss: 0.686444; batch adversarial loss: 0.836035\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573517; batch adversarial loss: 0.759168\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584632; batch adversarial loss: 0.682301\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524520; batch adversarial loss: 0.675563\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536645; batch adversarial loss: 0.639858\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555918; batch adversarial loss: 0.648622\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544754; batch adversarial loss: 0.636472\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536178; batch adversarial loss: 0.584650\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561661; batch adversarial loss: 0.591869\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518442; batch adversarial loss: 0.579809\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553957; batch adversarial loss: 0.559889\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538748; batch adversarial loss: 0.585874\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520891; batch adversarial loss: 0.582545\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578073; batch adversarial loss: 0.629372\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553160; batch adversarial loss: 0.551672\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536815; batch adversarial loss: 0.541535\n",
      "epoch 18; iter: 0; batch classifier loss: 0.583878; batch adversarial loss: 0.580616\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478523; batch adversarial loss: 0.571494\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511287; batch adversarial loss: 0.548876\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487645; batch adversarial loss: 0.454877\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493419; batch adversarial loss: 0.521615\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540926; batch adversarial loss: 0.532489\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466738; batch adversarial loss: 0.539139\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502334; batch adversarial loss: 0.516029\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442784; batch adversarial loss: 0.565464\n",
      "epoch 27; iter: 0; batch classifier loss: 0.526862; batch adversarial loss: 0.556872\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475056; batch adversarial loss: 0.564948\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495231; batch adversarial loss: 0.544400\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461754; batch adversarial loss: 0.598270\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481465; batch adversarial loss: 0.539084\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506431; batch adversarial loss: 0.487150\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455854; batch adversarial loss: 0.610108\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427930; batch adversarial loss: 0.572274\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438378; batch adversarial loss: 0.495190\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477339; batch adversarial loss: 0.588275\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464180; batch adversarial loss: 0.528231\n",
      "epoch 38; iter: 0; batch classifier loss: 0.544475; batch adversarial loss: 0.510101\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476504; batch adversarial loss: 0.544997\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445315; batch adversarial loss: 0.598759\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426416; batch adversarial loss: 0.561796\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492920; batch adversarial loss: 0.608166\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489432; batch adversarial loss: 0.581517\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489653; batch adversarial loss: 0.598957\n",
      "epoch 45; iter: 0; batch classifier loss: 0.486643; batch adversarial loss: 0.544519\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487152; batch adversarial loss: 0.554939\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401153; batch adversarial loss: 0.582222\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433493; batch adversarial loss: 0.516094\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398791; batch adversarial loss: 0.589567\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468540; batch adversarial loss: 0.545235\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433112; batch adversarial loss: 0.555714\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441745; batch adversarial loss: 0.580536\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454853; batch adversarial loss: 0.590693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.473455; batch adversarial loss: 0.534696\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460493; batch adversarial loss: 0.554226\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394635; batch adversarial loss: 0.537078\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409528; batch adversarial loss: 0.555671\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420005; batch adversarial loss: 0.525810\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457978; batch adversarial loss: 0.549568\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403986; batch adversarial loss: 0.492148\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395046; batch adversarial loss: 0.533763\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432473; batch adversarial loss: 0.548749\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413219; batch adversarial loss: 0.617844\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427565; batch adversarial loss: 0.556198\n",
      "epoch 65; iter: 0; batch classifier loss: 0.351018; batch adversarial loss: 0.486115\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447978; batch adversarial loss: 0.527978\n",
      "epoch 67; iter: 0; batch classifier loss: 0.488739; batch adversarial loss: 0.550270\n",
      "epoch 68; iter: 0; batch classifier loss: 0.461211; batch adversarial loss: 0.512884\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382348; batch adversarial loss: 0.527391\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461251; batch adversarial loss: 0.492404\n",
      "epoch 71; iter: 0; batch classifier loss: 0.464426; batch adversarial loss: 0.502910\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400300; batch adversarial loss: 0.536147\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391068; batch adversarial loss: 0.571968\n",
      "epoch 74; iter: 0; batch classifier loss: 0.445535; batch adversarial loss: 0.562280\n",
      "epoch 75; iter: 0; batch classifier loss: 0.511860; batch adversarial loss: 0.523996\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369038; batch adversarial loss: 0.503640\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351836; batch adversarial loss: 0.575260\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447231; batch adversarial loss: 0.569633\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430321; batch adversarial loss: 0.543547\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429130; batch adversarial loss: 0.609152\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370641; batch adversarial loss: 0.498571\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363820; batch adversarial loss: 0.610568\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360289; batch adversarial loss: 0.552718\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398640; batch adversarial loss: 0.484775\n",
      "epoch 85; iter: 0; batch classifier loss: 0.422808; batch adversarial loss: 0.477017\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368692; batch adversarial loss: 0.549943\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430202; batch adversarial loss: 0.547697\n",
      "epoch 88; iter: 0; batch classifier loss: 0.329504; batch adversarial loss: 0.581169\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369557; batch adversarial loss: 0.568807\n",
      "epoch 90; iter: 0; batch classifier loss: 0.433941; batch adversarial loss: 0.454351\n",
      "epoch 91; iter: 0; batch classifier loss: 0.364680; batch adversarial loss: 0.606628\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413924; batch adversarial loss: 0.544802\n",
      "epoch 93; iter: 0; batch classifier loss: 0.443709; batch adversarial loss: 0.513241\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360145; batch adversarial loss: 0.539567\n",
      "epoch 95; iter: 0; batch classifier loss: 0.543244; batch adversarial loss: 0.498875\n",
      "epoch 96; iter: 0; batch classifier loss: 0.365393; batch adversarial loss: 0.582729\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338958; batch adversarial loss: 0.474160\n",
      "epoch 98; iter: 0; batch classifier loss: 0.435640; batch adversarial loss: 0.557627\n",
      "epoch 99; iter: 0; batch classifier loss: 0.309869; batch adversarial loss: 0.487333\n",
      "epoch 100; iter: 0; batch classifier loss: 0.424719; batch adversarial loss: 0.636361\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421847; batch adversarial loss: 0.616740\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407023; batch adversarial loss: 0.526178\n",
      "epoch 103; iter: 0; batch classifier loss: 0.344459; batch adversarial loss: 0.571843\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384036; batch adversarial loss: 0.453710\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337502; batch adversarial loss: 0.553690\n",
      "epoch 106; iter: 0; batch classifier loss: 0.405410; batch adversarial loss: 0.589082\n",
      "epoch 107; iter: 0; batch classifier loss: 0.483652; batch adversarial loss: 0.562694\n",
      "epoch 108; iter: 0; batch classifier loss: 0.322662; batch adversarial loss: 0.497615\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344649; batch adversarial loss: 0.525260\n",
      "epoch 110; iter: 0; batch classifier loss: 0.407888; batch adversarial loss: 0.570555\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359042; batch adversarial loss: 0.562090\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366286; batch adversarial loss: 0.526376\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380181; batch adversarial loss: 0.515155\n",
      "epoch 114; iter: 0; batch classifier loss: 0.353744; batch adversarial loss: 0.478935\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401946; batch adversarial loss: 0.553598\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412590; batch adversarial loss: 0.573118\n",
      "epoch 117; iter: 0; batch classifier loss: 0.483456; batch adversarial loss: 0.561749\n",
      "epoch 118; iter: 0; batch classifier loss: 0.307712; batch adversarial loss: 0.591641\n",
      "epoch 119; iter: 0; batch classifier loss: 0.361657; batch adversarial loss: 0.516431\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328996; batch adversarial loss: 0.590176\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394001; batch adversarial loss: 0.591555\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365145; batch adversarial loss: 0.513659\n",
      "epoch 123; iter: 0; batch classifier loss: 0.421563; batch adversarial loss: 0.632509\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378980; batch adversarial loss: 0.522105\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404145; batch adversarial loss: 0.525941\n",
      "epoch 126; iter: 0; batch classifier loss: 0.429958; batch adversarial loss: 0.526860\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395452; batch adversarial loss: 0.527507\n",
      "epoch 128; iter: 0; batch classifier loss: 0.337421; batch adversarial loss: 0.559785\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369914; batch adversarial loss: 0.558715\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340793; batch adversarial loss: 0.545912\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407514; batch adversarial loss: 0.518203\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404297; batch adversarial loss: 0.546679\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390967; batch adversarial loss: 0.551119\n",
      "epoch 134; iter: 0; batch classifier loss: 0.407186; batch adversarial loss: 0.553410\n",
      "epoch 135; iter: 0; batch classifier loss: 0.283705; batch adversarial loss: 0.519298\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421048; batch adversarial loss: 0.576537\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332032; batch adversarial loss: 0.564540\n",
      "epoch 138; iter: 0; batch classifier loss: 0.290044; batch adversarial loss: 0.515979\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379976; batch adversarial loss: 0.516419\n",
      "epoch 140; iter: 0; batch classifier loss: 0.447857; batch adversarial loss: 0.551748\n",
      "epoch 141; iter: 0; batch classifier loss: 0.369894; batch adversarial loss: 0.507773\n",
      "epoch 142; iter: 0; batch classifier loss: 0.248060; batch adversarial loss: 0.557221\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348814; batch adversarial loss: 0.621782\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350914; batch adversarial loss: 0.473014\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366851; batch adversarial loss: 0.554974\n",
      "epoch 146; iter: 0; batch classifier loss: 0.312763; batch adversarial loss: 0.574652\n",
      "epoch 147; iter: 0; batch classifier loss: 0.399447; batch adversarial loss: 0.499375\n",
      "epoch 148; iter: 0; batch classifier loss: 0.352912; batch adversarial loss: 0.572066\n",
      "epoch 149; iter: 0; batch classifier loss: 0.463367; batch adversarial loss: 0.554208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150; iter: 0; batch classifier loss: 0.333001; batch adversarial loss: 0.496240\n",
      "epoch 151; iter: 0; batch classifier loss: 0.388835; batch adversarial loss: 0.509252\n",
      "epoch 152; iter: 0; batch classifier loss: 0.448566; batch adversarial loss: 0.600132\n",
      "epoch 153; iter: 0; batch classifier loss: 0.307339; batch adversarial loss: 0.470078\n",
      "epoch 154; iter: 0; batch classifier loss: 0.405795; batch adversarial loss: 0.470007\n",
      "epoch 155; iter: 0; batch classifier loss: 0.460736; batch adversarial loss: 0.599149\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401644; batch adversarial loss: 0.543943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.389587; batch adversarial loss: 0.489126\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392121; batch adversarial loss: 0.497545\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380418; batch adversarial loss: 0.509543\n",
      "epoch 160; iter: 0; batch classifier loss: 0.432221; batch adversarial loss: 0.536148\n",
      "epoch 161; iter: 0; batch classifier loss: 0.365919; batch adversarial loss: 0.573215\n",
      "epoch 162; iter: 0; batch classifier loss: 0.322318; batch adversarial loss: 0.534902\n",
      "epoch 163; iter: 0; batch classifier loss: 0.404816; batch adversarial loss: 0.553662\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363733; batch adversarial loss: 0.518425\n",
      "epoch 165; iter: 0; batch classifier loss: 0.306166; batch adversarial loss: 0.553469\n",
      "epoch 166; iter: 0; batch classifier loss: 0.391433; batch adversarial loss: 0.425115\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362782; batch adversarial loss: 0.543942\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397319; batch adversarial loss: 0.625939\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360686; batch adversarial loss: 0.553481\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378908; batch adversarial loss: 0.544435\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341372; batch adversarial loss: 0.526762\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333724; batch adversarial loss: 0.435179\n",
      "epoch 173; iter: 0; batch classifier loss: 0.401132; batch adversarial loss: 0.563314\n",
      "epoch 174; iter: 0; batch classifier loss: 0.330707; batch adversarial loss: 0.495812\n",
      "epoch 175; iter: 0; batch classifier loss: 0.296053; batch adversarial loss: 0.564800\n",
      "epoch 176; iter: 0; batch classifier loss: 0.448577; batch adversarial loss: 0.507428\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433556; batch adversarial loss: 0.617400\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416312; batch adversarial loss: 0.498115\n",
      "epoch 179; iter: 0; batch classifier loss: 0.387555; batch adversarial loss: 0.497973\n",
      "epoch 180; iter: 0; batch classifier loss: 0.365176; batch adversarial loss: 0.497835\n",
      "epoch 181; iter: 0; batch classifier loss: 0.399045; batch adversarial loss: 0.516000\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377972; batch adversarial loss: 0.498699\n",
      "epoch 183; iter: 0; batch classifier loss: 0.360249; batch adversarial loss: 0.626499\n",
      "epoch 184; iter: 0; batch classifier loss: 0.402534; batch adversarial loss: 0.525828\n",
      "epoch 185; iter: 0; batch classifier loss: 0.345814; batch adversarial loss: 0.546309\n",
      "epoch 186; iter: 0; batch classifier loss: 0.388045; batch adversarial loss: 0.545805\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348279; batch adversarial loss: 0.543490\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328873; batch adversarial loss: 0.545623\n",
      "epoch 189; iter: 0; batch classifier loss: 0.276506; batch adversarial loss: 0.653370\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340242; batch adversarial loss: 0.592847\n",
      "epoch 191; iter: 0; batch classifier loss: 0.444076; batch adversarial loss: 0.581791\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365375; batch adversarial loss: 0.514819\n",
      "epoch 193; iter: 0; batch classifier loss: 0.381340; batch adversarial loss: 0.488428\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396109; batch adversarial loss: 0.570057\n",
      "epoch 195; iter: 0; batch classifier loss: 0.340892; batch adversarial loss: 0.498639\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339521; batch adversarial loss: 0.497003\n",
      "epoch 197; iter: 0; batch classifier loss: 0.425913; batch adversarial loss: 0.609651\n",
      "epoch 198; iter: 0; batch classifier loss: 0.302443; batch adversarial loss: 0.525109\n",
      "epoch 199; iter: 0; batch classifier loss: 0.472140; batch adversarial loss: 0.554998\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714419; batch adversarial loss: 0.837344\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619139; batch adversarial loss: 0.810925\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561145; batch adversarial loss: 0.728893\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609156; batch adversarial loss: 0.716978\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547548; batch adversarial loss: 0.658709\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568633; batch adversarial loss: 0.661194\n",
      "epoch 6; iter: 0; batch classifier loss: 0.506698; batch adversarial loss: 0.622997\n",
      "epoch 7; iter: 0; batch classifier loss: 0.620167; batch adversarial loss: 0.631066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537758; batch adversarial loss: 0.609585\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496048; batch adversarial loss: 0.585326\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472860; batch adversarial loss: 0.586000\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541101; batch adversarial loss: 0.581826\n",
      "epoch 12; iter: 0; batch classifier loss: 0.546000; batch adversarial loss: 0.593938\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514787; batch adversarial loss: 0.583308\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541726; batch adversarial loss: 0.506379\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546739; batch adversarial loss: 0.600030\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513619; batch adversarial loss: 0.556865\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473424; batch adversarial loss: 0.526572\n",
      "epoch 18; iter: 0; batch classifier loss: 0.410815; batch adversarial loss: 0.531889\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469223; batch adversarial loss: 0.555091\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488634; batch adversarial loss: 0.606187\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486765; batch adversarial loss: 0.553732\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472642; batch adversarial loss: 0.499990\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506332; batch adversarial loss: 0.566722\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478424; batch adversarial loss: 0.535364\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455128; batch adversarial loss: 0.477499\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485273; batch adversarial loss: 0.526304\n",
      "epoch 27; iter: 0; batch classifier loss: 0.515108; batch adversarial loss: 0.512467\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493480; batch adversarial loss: 0.479958\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506037; batch adversarial loss: 0.551375\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551440; batch adversarial loss: 0.488209\n",
      "epoch 31; iter: 0; batch classifier loss: 0.399728; batch adversarial loss: 0.481663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452145; batch adversarial loss: 0.581926\n",
      "epoch 33; iter: 0; batch classifier loss: 0.530788; batch adversarial loss: 0.591641\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455185; batch adversarial loss: 0.622223\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488501; batch adversarial loss: 0.503636\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476601; batch adversarial loss: 0.529144\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438290; batch adversarial loss: 0.532357\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483087; batch adversarial loss: 0.496961\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491290; batch adversarial loss: 0.444257\n",
      "epoch 40; iter: 0; batch classifier loss: 0.478174; batch adversarial loss: 0.640287\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469593; batch adversarial loss: 0.520318\n",
      "epoch 42; iter: 0; batch classifier loss: 0.435891; batch adversarial loss: 0.537100\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434773; batch adversarial loss: 0.545411\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409563; batch adversarial loss: 0.493209\n",
      "epoch 45; iter: 0; batch classifier loss: 0.547782; batch adversarial loss: 0.588243\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464254; batch adversarial loss: 0.500424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.513188; batch adversarial loss: 0.518492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445916; batch adversarial loss: 0.588876\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462713; batch adversarial loss: 0.580639\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441238; batch adversarial loss: 0.535637\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469036; batch adversarial loss: 0.527326\n",
      "epoch 52; iter: 0; batch classifier loss: 0.489322; batch adversarial loss: 0.580154\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466353; batch adversarial loss: 0.598904\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440684; batch adversarial loss: 0.500005\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426141; batch adversarial loss: 0.526666\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467983; batch adversarial loss: 0.490185\n",
      "epoch 57; iter: 0; batch classifier loss: 0.478301; batch adversarial loss: 0.508325\n",
      "epoch 58; iter: 0; batch classifier loss: 0.565857; batch adversarial loss: 0.454853\n",
      "epoch 59; iter: 0; batch classifier loss: 0.403279; batch adversarial loss: 0.517955\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446940; batch adversarial loss: 0.509275\n",
      "epoch 61; iter: 0; batch classifier loss: 0.481885; batch adversarial loss: 0.500442\n",
      "epoch 62; iter: 0; batch classifier loss: 0.461567; batch adversarial loss: 0.607288\n",
      "epoch 63; iter: 0; batch classifier loss: 0.474277; batch adversarial loss: 0.536550\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395146; batch adversarial loss: 0.553119\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381773; batch adversarial loss: 0.544564\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410775; batch adversarial loss: 0.508424\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431446; batch adversarial loss: 0.526595\n",
      "epoch 68; iter: 0; batch classifier loss: 0.477310; batch adversarial loss: 0.608929\n",
      "epoch 69; iter: 0; batch classifier loss: 0.362225; batch adversarial loss: 0.562842\n",
      "epoch 70; iter: 0; batch classifier loss: 0.450192; batch adversarial loss: 0.571331\n",
      "epoch 71; iter: 0; batch classifier loss: 0.457625; batch adversarial loss: 0.489121\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428645; batch adversarial loss: 0.597992\n",
      "epoch 73; iter: 0; batch classifier loss: 0.336371; batch adversarial loss: 0.545130\n",
      "epoch 74; iter: 0; batch classifier loss: 0.488818; batch adversarial loss: 0.499803\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380771; batch adversarial loss: 0.544677\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393101; batch adversarial loss: 0.544113\n",
      "epoch 77; iter: 0; batch classifier loss: 0.365765; batch adversarial loss: 0.599468\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390946; batch adversarial loss: 0.607637\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398365; batch adversarial loss: 0.553380\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402110; batch adversarial loss: 0.445793\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407992; batch adversarial loss: 0.489439\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396592; batch adversarial loss: 0.545244\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434063; batch adversarial loss: 0.590574\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395689; batch adversarial loss: 0.508533\n",
      "epoch 85; iter: 0; batch classifier loss: 0.466233; batch adversarial loss: 0.598067\n",
      "epoch 86; iter: 0; batch classifier loss: 0.341480; batch adversarial loss: 0.536622\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360899; batch adversarial loss: 0.499057\n",
      "epoch 88; iter: 0; batch classifier loss: 0.467876; batch adversarial loss: 0.508640\n",
      "epoch 89; iter: 0; batch classifier loss: 0.408695; batch adversarial loss: 0.589593\n",
      "epoch 90; iter: 0; batch classifier loss: 0.356897; batch adversarial loss: 0.544508\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390566; batch adversarial loss: 0.516445\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406232; batch adversarial loss: 0.572517\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374962; batch adversarial loss: 0.516529\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370737; batch adversarial loss: 0.454604\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343878; batch adversarial loss: 0.553088\n",
      "epoch 96; iter: 0; batch classifier loss: 0.448236; batch adversarial loss: 0.652158\n",
      "epoch 97; iter: 0; batch classifier loss: 0.444661; batch adversarial loss: 0.526149\n",
      "epoch 98; iter: 0; batch classifier loss: 0.337921; batch adversarial loss: 0.554097\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402288; batch adversarial loss: 0.633547\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385507; batch adversarial loss: 0.571279\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392583; batch adversarial loss: 0.525964\n",
      "epoch 102; iter: 0; batch classifier loss: 0.461395; batch adversarial loss: 0.527426\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411784; batch adversarial loss: 0.534896\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371259; batch adversarial loss: 0.571887\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398950; batch adversarial loss: 0.562555\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355661; batch adversarial loss: 0.544789\n",
      "epoch 107; iter: 0; batch classifier loss: 0.486918; batch adversarial loss: 0.598084\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370394; batch adversarial loss: 0.482254\n",
      "epoch 109; iter: 0; batch classifier loss: 0.373061; batch adversarial loss: 0.528259\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353893; batch adversarial loss: 0.607832\n",
      "epoch 111; iter: 0; batch classifier loss: 0.432685; batch adversarial loss: 0.490619\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383845; batch adversarial loss: 0.544406\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355833; batch adversarial loss: 0.615616\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369462; batch adversarial loss: 0.544331\n",
      "epoch 115; iter: 0; batch classifier loss: 0.470085; batch adversarial loss: 0.580613\n",
      "epoch 116; iter: 0; batch classifier loss: 0.491028; batch adversarial loss: 0.579412\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384534; batch adversarial loss: 0.561815\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347178; batch adversarial loss: 0.562323\n",
      "epoch 119; iter: 0; batch classifier loss: 0.321004; batch adversarial loss: 0.580536\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391633; batch adversarial loss: 0.571524\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364394; batch adversarial loss: 0.508701\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415624; batch adversarial loss: 0.508895\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429999; batch adversarial loss: 0.606297\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392194; batch adversarial loss: 0.534191\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386513; batch adversarial loss: 0.517993\n",
      "epoch 126; iter: 0; batch classifier loss: 0.355424; batch adversarial loss: 0.525823\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366706; batch adversarial loss: 0.482056\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383674; batch adversarial loss: 0.562518\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389875; batch adversarial loss: 0.491400\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408436; batch adversarial loss: 0.633940\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388458; batch adversarial loss: 0.591365\n",
      "epoch 132; iter: 0; batch classifier loss: 0.423792; batch adversarial loss: 0.554364\n",
      "epoch 133; iter: 0; batch classifier loss: 0.337781; batch adversarial loss: 0.516164\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394567; batch adversarial loss: 0.536279\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389015; batch adversarial loss: 0.560845\n",
      "epoch 136; iter: 0; batch classifier loss: 0.286770; batch adversarial loss: 0.499684\n",
      "epoch 137; iter: 0; batch classifier loss: 0.336838; batch adversarial loss: 0.589089\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388893; batch adversarial loss: 0.571504\n",
      "epoch 139; iter: 0; batch classifier loss: 0.322997; batch adversarial loss: 0.607377\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383929; batch adversarial loss: 0.544273\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409350; batch adversarial loss: 0.491080\n",
      "epoch 142; iter: 0; batch classifier loss: 0.417917; batch adversarial loss: 0.544249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.433916; batch adversarial loss: 0.526491\n",
      "epoch 144; iter: 0; batch classifier loss: 0.305461; batch adversarial loss: 0.527019\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367058; batch adversarial loss: 0.624318\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400733; batch adversarial loss: 0.598580\n",
      "epoch 147; iter: 0; batch classifier loss: 0.462609; batch adversarial loss: 0.518415\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363980; batch adversarial loss: 0.571397\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410933; batch adversarial loss: 0.544351\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320595; batch adversarial loss: 0.553587\n",
      "epoch 151; iter: 0; batch classifier loss: 0.385957; batch adversarial loss: 0.532530\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362799; batch adversarial loss: 0.507329\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357875; batch adversarial loss: 0.516414\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372066; batch adversarial loss: 0.527922\n",
      "epoch 155; iter: 0; batch classifier loss: 0.271517; batch adversarial loss: 0.455397\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385643; batch adversarial loss: 0.545372\n",
      "epoch 157; iter: 0; batch classifier loss: 0.354121; batch adversarial loss: 0.544977\n",
      "epoch 158; iter: 0; batch classifier loss: 0.297923; batch adversarial loss: 0.588549\n",
      "epoch 159; iter: 0; batch classifier loss: 0.335663; batch adversarial loss: 0.544781\n",
      "epoch 160; iter: 0; batch classifier loss: 0.430397; batch adversarial loss: 0.518264\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337119; batch adversarial loss: 0.580267\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348867; batch adversarial loss: 0.553076\n",
      "epoch 163; iter: 0; batch classifier loss: 0.299177; batch adversarial loss: 0.527031\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360088; batch adversarial loss: 0.590096\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405861; batch adversarial loss: 0.644051\n",
      "epoch 166; iter: 0; batch classifier loss: 0.406447; batch adversarial loss: 0.544370\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380391; batch adversarial loss: 0.598607\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389924; batch adversarial loss: 0.590206\n",
      "epoch 169; iter: 0; batch classifier loss: 0.314454; batch adversarial loss: 0.543173\n",
      "epoch 170; iter: 0; batch classifier loss: 0.309471; batch adversarial loss: 0.589649\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342233; batch adversarial loss: 0.525968\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381466; batch adversarial loss: 0.527049\n",
      "epoch 173; iter: 0; batch classifier loss: 0.420115; batch adversarial loss: 0.572324\n",
      "epoch 174; iter: 0; batch classifier loss: 0.301958; batch adversarial loss: 0.517708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313066; batch adversarial loss: 0.615851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.458347; batch adversarial loss: 0.570770\n",
      "epoch 177; iter: 0; batch classifier loss: 0.367301; batch adversarial loss: 0.516713\n",
      "epoch 178; iter: 0; batch classifier loss: 0.299141; batch adversarial loss: 0.543728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357666; batch adversarial loss: 0.508128\n",
      "epoch 180; iter: 0; batch classifier loss: 0.297992; batch adversarial loss: 0.579793\n",
      "epoch 181; iter: 0; batch classifier loss: 0.385425; batch adversarial loss: 0.508446\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408908; batch adversarial loss: 0.517670\n",
      "epoch 183; iter: 0; batch classifier loss: 0.271974; batch adversarial loss: 0.571261\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404041; batch adversarial loss: 0.616150\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398692; batch adversarial loss: 0.553852\n",
      "epoch 186; iter: 0; batch classifier loss: 0.339601; batch adversarial loss: 0.553278\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372705; batch adversarial loss: 0.579905\n",
      "epoch 188; iter: 0; batch classifier loss: 0.422427; batch adversarial loss: 0.553135\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333628; batch adversarial loss: 0.527119\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340871; batch adversarial loss: 0.526178\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357911; batch adversarial loss: 0.517327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320311; batch adversarial loss: 0.481946\n",
      "epoch 193; iter: 0; batch classifier loss: 0.394152; batch adversarial loss: 0.581566\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385671; batch adversarial loss: 0.525705\n",
      "epoch 195; iter: 0; batch classifier loss: 0.470229; batch adversarial loss: 0.507977\n",
      "epoch 196; iter: 0; batch classifier loss: 0.283879; batch adversarial loss: 0.509302\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336012; batch adversarial loss: 0.598796\n",
      "epoch 198; iter: 0; batch classifier loss: 0.379056; batch adversarial loss: 0.563261\n",
      "epoch 199; iter: 0; batch classifier loss: 0.429949; batch adversarial loss: 0.616115\n",
      "epoch 0; iter: 0; batch classifier loss: 0.751439; batch adversarial loss: 1.015736\n",
      "epoch 1; iter: 0; batch classifier loss: 0.767641; batch adversarial loss: 1.117316\n",
      "epoch 2; iter: 0; batch classifier loss: 0.901338; batch adversarial loss: 1.002924\n",
      "epoch 3; iter: 0; batch classifier loss: 0.805148; batch adversarial loss: 0.976398\n",
      "epoch 4; iter: 0; batch classifier loss: 0.777820; batch adversarial loss: 0.867015\n",
      "epoch 5; iter: 0; batch classifier loss: 0.728296; batch adversarial loss: 0.783703\n",
      "epoch 6; iter: 0; batch classifier loss: 0.600886; batch adversarial loss: 0.707054\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598546; batch adversarial loss: 0.674060\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536165; batch adversarial loss: 0.669771\n",
      "epoch 9; iter: 0; batch classifier loss: 0.662964; batch adversarial loss: 0.606921\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522992; batch adversarial loss: 0.625929\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547430; batch adversarial loss: 0.594581\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578304; batch adversarial loss: 0.578308\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533000; batch adversarial loss: 0.588798\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503735; batch adversarial loss: 0.548050\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519548; batch adversarial loss: 0.607925\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511090; batch adversarial loss: 0.593873\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535355; batch adversarial loss: 0.592070\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539536; batch adversarial loss: 0.532336\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532629; batch adversarial loss: 0.555346\n",
      "epoch 20; iter: 0; batch classifier loss: 0.596824; batch adversarial loss: 0.563566\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488233; batch adversarial loss: 0.515372\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432688; batch adversarial loss: 0.545174\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462576; batch adversarial loss: 0.614915\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490769; batch adversarial loss: 0.541906\n",
      "epoch 25; iter: 0; batch classifier loss: 0.628781; batch adversarial loss: 0.532789\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527973; batch adversarial loss: 0.558423\n",
      "epoch 27; iter: 0; batch classifier loss: 0.393069; batch adversarial loss: 0.521434\n",
      "epoch 28; iter: 0; batch classifier loss: 0.508123; batch adversarial loss: 0.545920\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511792; batch adversarial loss: 0.568084\n",
      "epoch 30; iter: 0; batch classifier loss: 0.534798; batch adversarial loss: 0.561106\n",
      "epoch 31; iter: 0; batch classifier loss: 0.555426; batch adversarial loss: 0.517214\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442903; batch adversarial loss: 0.579109\n",
      "epoch 33; iter: 0; batch classifier loss: 0.584651; batch adversarial loss: 0.549318\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485915; batch adversarial loss: 0.538867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459019; batch adversarial loss: 0.521955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.579427; batch adversarial loss: 0.555434\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466590; batch adversarial loss: 0.527752\n",
      "epoch 38; iter: 0; batch classifier loss: 0.535369; batch adversarial loss: 0.522425\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435096; batch adversarial loss: 0.546197\n",
      "epoch 40; iter: 0; batch classifier loss: 0.544549; batch adversarial loss: 0.483801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.396132; batch adversarial loss: 0.555874\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415685; batch adversarial loss: 0.560547\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482854; batch adversarial loss: 0.561968\n",
      "epoch 44; iter: 0; batch classifier loss: 0.562483; batch adversarial loss: 0.569078\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471824; batch adversarial loss: 0.599717\n",
      "epoch 46; iter: 0; batch classifier loss: 0.488939; batch adversarial loss: 0.517646\n",
      "epoch 47; iter: 0; batch classifier loss: 0.506059; batch adversarial loss: 0.547730\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485395; batch adversarial loss: 0.538755\n",
      "epoch 49; iter: 0; batch classifier loss: 0.495809; batch adversarial loss: 0.517566\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428871; batch adversarial loss: 0.608737\n",
      "epoch 51; iter: 0; batch classifier loss: 0.488205; batch adversarial loss: 0.553769\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392158; batch adversarial loss: 0.517534\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436706; batch adversarial loss: 0.460279\n",
      "epoch 54; iter: 0; batch classifier loss: 0.510545; batch adversarial loss: 0.590642\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426351; batch adversarial loss: 0.516555\n",
      "epoch 56; iter: 0; batch classifier loss: 0.512279; batch adversarial loss: 0.510144\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494734; batch adversarial loss: 0.480992\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438756; batch adversarial loss: 0.518324\n",
      "epoch 59; iter: 0; batch classifier loss: 0.482386; batch adversarial loss: 0.581294\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421221; batch adversarial loss: 0.599592\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442523; batch adversarial loss: 0.498565\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479821; batch adversarial loss: 0.589458\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416370; batch adversarial loss: 0.516346\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423639; batch adversarial loss: 0.508006\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466560; batch adversarial loss: 0.577473\n",
      "epoch 66; iter: 0; batch classifier loss: 0.448167; batch adversarial loss: 0.560625\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442249; batch adversarial loss: 0.489480\n",
      "epoch 68; iter: 0; batch classifier loss: 0.350115; batch adversarial loss: 0.619322\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413709; batch adversarial loss: 0.568611\n",
      "epoch 70; iter: 0; batch classifier loss: 0.429875; batch adversarial loss: 0.498414\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399544; batch adversarial loss: 0.472022\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404555; batch adversarial loss: 0.545004\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411952; batch adversarial loss: 0.607098\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419963; batch adversarial loss: 0.554279\n",
      "epoch 75; iter: 0; batch classifier loss: 0.419042; batch adversarial loss: 0.554290\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367166; batch adversarial loss: 0.580984\n",
      "epoch 77; iter: 0; batch classifier loss: 0.446501; batch adversarial loss: 0.515703\n",
      "epoch 78; iter: 0; batch classifier loss: 0.445197; batch adversarial loss: 0.507961\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440072; batch adversarial loss: 0.589948\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370782; batch adversarial loss: 0.527235\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417294; batch adversarial loss: 0.553639\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352545; batch adversarial loss: 0.535100\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383257; batch adversarial loss: 0.590318\n",
      "epoch 84; iter: 0; batch classifier loss: 0.466369; batch adversarial loss: 0.452580\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413760; batch adversarial loss: 0.545362\n",
      "epoch 86; iter: 0; batch classifier loss: 0.388983; batch adversarial loss: 0.509117\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394185; batch adversarial loss: 0.553546\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396357; batch adversarial loss: 0.525921\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370741; batch adversarial loss: 0.571744\n",
      "epoch 90; iter: 0; batch classifier loss: 0.334366; batch adversarial loss: 0.535910\n",
      "epoch 91; iter: 0; batch classifier loss: 0.454287; batch adversarial loss: 0.535038\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370659; batch adversarial loss: 0.535291\n",
      "epoch 93; iter: 0; batch classifier loss: 0.424143; batch adversarial loss: 0.554146\n",
      "epoch 94; iter: 0; batch classifier loss: 0.351132; batch adversarial loss: 0.634611\n",
      "epoch 95; iter: 0; batch classifier loss: 0.374243; batch adversarial loss: 0.489775\n",
      "epoch 96; iter: 0; batch classifier loss: 0.327683; batch adversarial loss: 0.634866\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344857; batch adversarial loss: 0.517065\n",
      "epoch 98; iter: 0; batch classifier loss: 0.427909; batch adversarial loss: 0.516662\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367342; batch adversarial loss: 0.626621\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403682; batch adversarial loss: 0.516951\n",
      "epoch 101; iter: 0; batch classifier loss: 0.472936; batch adversarial loss: 0.572118\n",
      "epoch 102; iter: 0; batch classifier loss: 0.473943; batch adversarial loss: 0.527559\n",
      "epoch 103; iter: 0; batch classifier loss: 0.470570; batch adversarial loss: 0.571513\n",
      "epoch 104; iter: 0; batch classifier loss: 0.424553; batch adversarial loss: 0.454742\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409187; batch adversarial loss: 0.525481\n",
      "epoch 106; iter: 0; batch classifier loss: 0.453970; batch adversarial loss: 0.626866\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393346; batch adversarial loss: 0.553090\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398435; batch adversarial loss: 0.535964\n",
      "epoch 109; iter: 0; batch classifier loss: 0.428653; batch adversarial loss: 0.588419\n",
      "epoch 110; iter: 0; batch classifier loss: 0.361907; batch adversarial loss: 0.470965\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354007; batch adversarial loss: 0.554810\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397173; batch adversarial loss: 0.553812\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400871; batch adversarial loss: 0.579764\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388108; batch adversarial loss: 0.507090\n",
      "epoch 115; iter: 0; batch classifier loss: 0.335965; batch adversarial loss: 0.532926\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379655; batch adversarial loss: 0.542641\n",
      "epoch 117; iter: 0; batch classifier loss: 0.413238; batch adversarial loss: 0.471151\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351777; batch adversarial loss: 0.571438\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387536; batch adversarial loss: 0.515687\n",
      "epoch 120; iter: 0; batch classifier loss: 0.310615; batch adversarial loss: 0.600970\n",
      "epoch 121; iter: 0; batch classifier loss: 0.396147; batch adversarial loss: 0.542352\n",
      "epoch 122; iter: 0; batch classifier loss: 0.430750; batch adversarial loss: 0.625080\n",
      "epoch 123; iter: 0; batch classifier loss: 0.311721; batch adversarial loss: 0.634974\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374802; batch adversarial loss: 0.527492\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380098; batch adversarial loss: 0.518047\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380163; batch adversarial loss: 0.581337\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401922; batch adversarial loss: 0.479384\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432400; batch adversarial loss: 0.562827\n",
      "epoch 129; iter: 0; batch classifier loss: 0.352308; batch adversarial loss: 0.581513\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356599; batch adversarial loss: 0.507803\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337904; batch adversarial loss: 0.498749\n",
      "epoch 132; iter: 0; batch classifier loss: 0.454837; batch adversarial loss: 0.498899\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362599; batch adversarial loss: 0.581015\n",
      "epoch 134; iter: 0; batch classifier loss: 0.476133; batch adversarial loss: 0.563217\n",
      "epoch 135; iter: 0; batch classifier loss: 0.453404; batch adversarial loss: 0.535044\n",
      "epoch 136; iter: 0; batch classifier loss: 0.384651; batch adversarial loss: 0.553447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.391213; batch adversarial loss: 0.617059\n",
      "epoch 138; iter: 0; batch classifier loss: 0.311273; batch adversarial loss: 0.526611\n",
      "epoch 139; iter: 0; batch classifier loss: 0.325176; batch adversarial loss: 0.489260\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381370; batch adversarial loss: 0.616672\n",
      "epoch 141; iter: 0; batch classifier loss: 0.373583; batch adversarial loss: 0.536107\n",
      "epoch 142; iter: 0; batch classifier loss: 0.469616; batch adversarial loss: 0.507583\n",
      "epoch 143; iter: 0; batch classifier loss: 0.308944; batch adversarial loss: 0.580777\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372940; batch adversarial loss: 0.589444\n",
      "epoch 145; iter: 0; batch classifier loss: 0.504218; batch adversarial loss: 0.535036\n",
      "epoch 146; iter: 0; batch classifier loss: 0.408925; batch adversarial loss: 0.616484\n",
      "epoch 147; iter: 0; batch classifier loss: 0.366137; batch adversarial loss: 0.587189\n",
      "epoch 148; iter: 0; batch classifier loss: 0.308736; batch adversarial loss: 0.526230\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349945; batch adversarial loss: 0.617270\n",
      "epoch 150; iter: 0; batch classifier loss: 0.386033; batch adversarial loss: 0.508752\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345931; batch adversarial loss: 0.579924\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362597; batch adversarial loss: 0.565777\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383959; batch adversarial loss: 0.486883\n",
      "epoch 154; iter: 0; batch classifier loss: 0.406119; batch adversarial loss: 0.521019\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357020; batch adversarial loss: 0.571258\n",
      "epoch 156; iter: 0; batch classifier loss: 0.460062; batch adversarial loss: 0.518694\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329287; batch adversarial loss: 0.619364\n",
      "epoch 158; iter: 0; batch classifier loss: 0.309540; batch adversarial loss: 0.572511\n",
      "epoch 159; iter: 0; batch classifier loss: 0.314088; batch adversarial loss: 0.526026\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372824; batch adversarial loss: 0.544308\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388491; batch adversarial loss: 0.544561\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368089; batch adversarial loss: 0.635205\n",
      "epoch 163; iter: 0; batch classifier loss: 0.404699; batch adversarial loss: 0.507836\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348147; batch adversarial loss: 0.598683\n",
      "epoch 165; iter: 0; batch classifier loss: 0.427595; batch adversarial loss: 0.579024\n",
      "epoch 166; iter: 0; batch classifier loss: 0.428083; batch adversarial loss: 0.572991\n",
      "epoch 167; iter: 0; batch classifier loss: 0.391068; batch adversarial loss: 0.554927\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340928; batch adversarial loss: 0.590069\n",
      "epoch 169; iter: 0; batch classifier loss: 0.308703; batch adversarial loss: 0.524390\n",
      "epoch 170; iter: 0; batch classifier loss: 0.469975; batch adversarial loss: 0.571035\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388227; batch adversarial loss: 0.526301\n",
      "epoch 172; iter: 0; batch classifier loss: 0.293572; batch adversarial loss: 0.536572\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345463; batch adversarial loss: 0.535182\n",
      "epoch 174; iter: 0; batch classifier loss: 0.420954; batch adversarial loss: 0.507391\n",
      "epoch 175; iter: 0; batch classifier loss: 0.373476; batch adversarial loss: 0.552880\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376998; batch adversarial loss: 0.525589\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380338; batch adversarial loss: 0.526050\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372294; batch adversarial loss: 0.571849\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383519; batch adversarial loss: 0.553818\n",
      "epoch 180; iter: 0; batch classifier loss: 0.375710; batch adversarial loss: 0.571807\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339558; batch adversarial loss: 0.581722\n",
      "epoch 182; iter: 0; batch classifier loss: 0.401301; batch adversarial loss: 0.571667\n",
      "epoch 183; iter: 0; batch classifier loss: 0.381496; batch adversarial loss: 0.507829\n",
      "epoch 184; iter: 0; batch classifier loss: 0.446216; batch adversarial loss: 0.527342\n",
      "epoch 185; iter: 0; batch classifier loss: 0.347588; batch adversarial loss: 0.616639\n",
      "epoch 186; iter: 0; batch classifier loss: 0.370354; batch adversarial loss: 0.535707\n",
      "epoch 187; iter: 0; batch classifier loss: 0.349847; batch adversarial loss: 0.535676\n",
      "epoch 188; iter: 0; batch classifier loss: 0.409008; batch adversarial loss: 0.508149\n",
      "epoch 189; iter: 0; batch classifier loss: 0.413000; batch adversarial loss: 0.552274\n",
      "epoch 190; iter: 0; batch classifier loss: 0.432277; batch adversarial loss: 0.535011\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340079; batch adversarial loss: 0.560873\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339190; batch adversarial loss: 0.517425\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370094; batch adversarial loss: 0.534472\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341327; batch adversarial loss: 0.597547\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309064; batch adversarial loss: 0.533576\n",
      "epoch 196; iter: 0; batch classifier loss: 0.422250; batch adversarial loss: 0.555783\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390042; batch adversarial loss: 0.625423\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387321; batch adversarial loss: 0.555297\n",
      "epoch 199; iter: 0; batch classifier loss: 0.372004; batch adversarial loss: 0.525969\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683230; batch adversarial loss: 0.772682\n",
      "epoch 1; iter: 0; batch classifier loss: 0.676094; batch adversarial loss: 0.858048\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625714; batch adversarial loss: 0.757968\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610050; batch adversarial loss: 0.700291\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591087; batch adversarial loss: 0.684475\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582842; batch adversarial loss: 0.656720\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558352; batch adversarial loss: 0.664723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517854; batch adversarial loss: 0.669366\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545712; batch adversarial loss: 0.625890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534448; batch adversarial loss: 0.583370\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537354; batch adversarial loss: 0.580189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526665; batch adversarial loss: 0.564593\n",
      "epoch 12; iter: 0; batch classifier loss: 0.453696; batch adversarial loss: 0.568738\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525142; batch adversarial loss: 0.534853\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473376; batch adversarial loss: 0.561235\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537295; batch adversarial loss: 0.603381\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528256; batch adversarial loss: 0.537187\n",
      "epoch 17; iter: 0; batch classifier loss: 0.449457; batch adversarial loss: 0.630114\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517705; batch adversarial loss: 0.529590\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515807; batch adversarial loss: 0.506000\n",
      "epoch 20; iter: 0; batch classifier loss: 0.606717; batch adversarial loss: 0.582004\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456168; batch adversarial loss: 0.537057\n",
      "epoch 22; iter: 0; batch classifier loss: 0.499207; batch adversarial loss: 0.596532\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513843; batch adversarial loss: 0.625310\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460622; batch adversarial loss: 0.692335\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474864; batch adversarial loss: 0.527266\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453519; batch adversarial loss: 0.555832\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517031; batch adversarial loss: 0.550877\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469456; batch adversarial loss: 0.535447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.560609; batch adversarial loss: 0.567549\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510893; batch adversarial loss: 0.571595\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449062; batch adversarial loss: 0.548602\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434317; batch adversarial loss: 0.517704\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421306; batch adversarial loss: 0.575324\n",
      "epoch 34; iter: 0; batch classifier loss: 0.507623; batch adversarial loss: 0.521605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.436241; batch adversarial loss: 0.510566\n",
      "epoch 36; iter: 0; batch classifier loss: 0.533241; batch adversarial loss: 0.599456\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493007; batch adversarial loss: 0.556727\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440812; batch adversarial loss: 0.545743\n",
      "epoch 39; iter: 0; batch classifier loss: 0.496028; batch adversarial loss: 0.589776\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442816; batch adversarial loss: 0.483406\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477169; batch adversarial loss: 0.516755\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393607; batch adversarial loss: 0.509335\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420536; batch adversarial loss: 0.506322\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427642; batch adversarial loss: 0.516420\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414115; batch adversarial loss: 0.599514\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451914; batch adversarial loss: 0.560952\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432967; batch adversarial loss: 0.572223\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397794; batch adversarial loss: 0.506868\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437281; batch adversarial loss: 0.553711\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429812; batch adversarial loss: 0.526406\n",
      "epoch 51; iter: 0; batch classifier loss: 0.389250; batch adversarial loss: 0.582142\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435074; batch adversarial loss: 0.553050\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374007; batch adversarial loss: 0.404684\n",
      "epoch 54; iter: 0; batch classifier loss: 0.328932; batch adversarial loss: 0.572431\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393653; batch adversarial loss: 0.479302\n",
      "epoch 56; iter: 0; batch classifier loss: 0.406322; batch adversarial loss: 0.497893\n",
      "epoch 57; iter: 0; batch classifier loss: 0.478695; batch adversarial loss: 0.563141\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450313; batch adversarial loss: 0.553630\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458422; batch adversarial loss: 0.461605\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444211; batch adversarial loss: 0.572644\n",
      "epoch 61; iter: 0; batch classifier loss: 0.466266; batch adversarial loss: 0.479488\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396631; batch adversarial loss: 0.525735\n",
      "epoch 63; iter: 0; batch classifier loss: 0.443570; batch adversarial loss: 0.544912\n",
      "epoch 64; iter: 0; batch classifier loss: 0.392812; batch adversarial loss: 0.441162\n",
      "epoch 65; iter: 0; batch classifier loss: 0.492239; batch adversarial loss: 0.516273\n",
      "epoch 66; iter: 0; batch classifier loss: 0.451216; batch adversarial loss: 0.582577\n",
      "epoch 67; iter: 0; batch classifier loss: 0.489369; batch adversarial loss: 0.544328\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407385; batch adversarial loss: 0.572882\n",
      "epoch 69; iter: 0; batch classifier loss: 0.503513; batch adversarial loss: 0.496850\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425934; batch adversarial loss: 0.488705\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370799; batch adversarial loss: 0.497657\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434638; batch adversarial loss: 0.460620\n",
      "epoch 73; iter: 0; batch classifier loss: 0.443848; batch adversarial loss: 0.582376\n",
      "epoch 74; iter: 0; batch classifier loss: 0.442236; batch adversarial loss: 0.564231\n",
      "epoch 75; iter: 0; batch classifier loss: 0.445728; batch adversarial loss: 0.544674\n",
      "epoch 76; iter: 0; batch classifier loss: 0.456772; batch adversarial loss: 0.673335\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393777; batch adversarial loss: 0.518113\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395379; batch adversarial loss: 0.658003\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437920; batch adversarial loss: 0.593102\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371486; batch adversarial loss: 0.469577\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398935; batch adversarial loss: 0.449295\n",
      "epoch 82; iter: 0; batch classifier loss: 0.345863; batch adversarial loss: 0.497876\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420304; batch adversarial loss: 0.488537\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449278; batch adversarial loss: 0.459771\n",
      "epoch 85; iter: 0; batch classifier loss: 0.318742; batch adversarial loss: 0.450674\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384328; batch adversarial loss: 0.525884\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402920; batch adversarial loss: 0.590051\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406589; batch adversarial loss: 0.562441\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371917; batch adversarial loss: 0.562385\n",
      "epoch 90; iter: 0; batch classifier loss: 0.437758; batch adversarial loss: 0.545068\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345647; batch adversarial loss: 0.601677\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421739; batch adversarial loss: 0.497468\n",
      "epoch 93; iter: 0; batch classifier loss: 0.388157; batch adversarial loss: 0.526000\n",
      "epoch 94; iter: 0; batch classifier loss: 0.429923; batch adversarial loss: 0.563644\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402023; batch adversarial loss: 0.496996\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402617; batch adversarial loss: 0.535143\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395065; batch adversarial loss: 0.516164\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378465; batch adversarial loss: 0.563389\n",
      "epoch 99; iter: 0; batch classifier loss: 0.437708; batch adversarial loss: 0.601186\n",
      "epoch 100; iter: 0; batch classifier loss: 0.445126; batch adversarial loss: 0.525716\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336678; batch adversarial loss: 0.553914\n",
      "epoch 102; iter: 0; batch classifier loss: 0.463083; batch adversarial loss: 0.497729\n",
      "epoch 103; iter: 0; batch classifier loss: 0.325967; batch adversarial loss: 0.535107\n",
      "epoch 104; iter: 0; batch classifier loss: 0.426063; batch adversarial loss: 0.507050\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360352; batch adversarial loss: 0.516482\n",
      "epoch 106; iter: 0; batch classifier loss: 0.495120; batch adversarial loss: 0.497505\n",
      "epoch 107; iter: 0; batch classifier loss: 0.351252; batch adversarial loss: 0.544518\n",
      "epoch 108; iter: 0; batch classifier loss: 0.412958; batch adversarial loss: 0.525660\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356626; batch adversarial loss: 0.497827\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405432; batch adversarial loss: 0.516801\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347122; batch adversarial loss: 0.554058\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378874; batch adversarial loss: 0.610968\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383999; batch adversarial loss: 0.562881\n",
      "epoch 114; iter: 0; batch classifier loss: 0.404674; batch adversarial loss: 0.525949\n",
      "epoch 115; iter: 0; batch classifier loss: 0.408654; batch adversarial loss: 0.544619\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348317; batch adversarial loss: 0.478331\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379550; batch adversarial loss: 0.592196\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427069; batch adversarial loss: 0.525470\n",
      "epoch 119; iter: 0; batch classifier loss: 0.345436; batch adversarial loss: 0.506999\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394456; batch adversarial loss: 0.478677\n",
      "epoch 121; iter: 0; batch classifier loss: 0.374971; batch adversarial loss: 0.591678\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403431; batch adversarial loss: 0.572755\n",
      "epoch 123; iter: 0; batch classifier loss: 0.325574; batch adversarial loss: 0.479007\n",
      "epoch 124; iter: 0; batch classifier loss: 0.419240; batch adversarial loss: 0.488329\n",
      "epoch 125; iter: 0; batch classifier loss: 0.333990; batch adversarial loss: 0.497886\n",
      "epoch 126; iter: 0; batch classifier loss: 0.300643; batch adversarial loss: 0.516308\n",
      "epoch 127; iter: 0; batch classifier loss: 0.364592; batch adversarial loss: 0.628881\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377380; batch adversarial loss: 0.619273\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339269; batch adversarial loss: 0.535025\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341017; batch adversarial loss: 0.572725\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362004; batch adversarial loss: 0.554118\n",
      "epoch 132; iter: 0; batch classifier loss: 0.474661; batch adversarial loss: 0.544418\n",
      "epoch 133; iter: 0; batch classifier loss: 0.373355; batch adversarial loss: 0.544825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.382513; batch adversarial loss: 0.469556\n",
      "epoch 135; iter: 0; batch classifier loss: 0.411995; batch adversarial loss: 0.497684\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416595; batch adversarial loss: 0.535019\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367891; batch adversarial loss: 0.563372\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383419; batch adversarial loss: 0.591392\n",
      "epoch 139; iter: 0; batch classifier loss: 0.398182; batch adversarial loss: 0.534735\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379031; batch adversarial loss: 0.544526\n",
      "epoch 141; iter: 0; batch classifier loss: 0.374473; batch adversarial loss: 0.544850\n",
      "epoch 142; iter: 0; batch classifier loss: 0.414391; batch adversarial loss: 0.516480\n",
      "epoch 143; iter: 0; batch classifier loss: 0.339281; batch adversarial loss: 0.516370\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368990; batch adversarial loss: 0.582081\n",
      "epoch 145; iter: 0; batch classifier loss: 0.391771; batch adversarial loss: 0.478625\n",
      "epoch 146; iter: 0; batch classifier loss: 0.432752; batch adversarial loss: 0.535206\n",
      "epoch 147; iter: 0; batch classifier loss: 0.402748; batch adversarial loss: 0.441667\n",
      "epoch 148; iter: 0; batch classifier loss: 0.419684; batch adversarial loss: 0.610076\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373671; batch adversarial loss: 0.610396\n",
      "epoch 150; iter: 0; batch classifier loss: 0.408939; batch adversarial loss: 0.544544\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356631; batch adversarial loss: 0.497759\n",
      "epoch 152; iter: 0; batch classifier loss: 0.410430; batch adversarial loss: 0.525929\n",
      "epoch 153; iter: 0; batch classifier loss: 0.432696; batch adversarial loss: 0.544321\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393770; batch adversarial loss: 0.619913\n",
      "epoch 155; iter: 0; batch classifier loss: 0.400529; batch adversarial loss: 0.591491\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352551; batch adversarial loss: 0.554129\n",
      "epoch 157; iter: 0; batch classifier loss: 0.298085; batch adversarial loss: 0.535518\n",
      "epoch 158; iter: 0; batch classifier loss: 0.292312; batch adversarial loss: 0.544525\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333191; batch adversarial loss: 0.600635\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349261; batch adversarial loss: 0.488143\n",
      "epoch 161; iter: 0; batch classifier loss: 0.321376; batch adversarial loss: 0.507106\n",
      "epoch 162; iter: 0; batch classifier loss: 0.351661; batch adversarial loss: 0.525364\n",
      "epoch 163; iter: 0; batch classifier loss: 0.327257; batch adversarial loss: 0.553699\n",
      "epoch 164; iter: 0; batch classifier loss: 0.393647; batch adversarial loss: 0.525563\n",
      "epoch 165; iter: 0; batch classifier loss: 0.300151; batch adversarial loss: 0.591931\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359172; batch adversarial loss: 0.487832\n",
      "epoch 167; iter: 0; batch classifier loss: 0.421865; batch adversarial loss: 0.591192\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335429; batch adversarial loss: 0.582039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.314137; batch adversarial loss: 0.506557\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379452; batch adversarial loss: 0.582860\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375374; batch adversarial loss: 0.535373\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322491; batch adversarial loss: 0.629014\n",
      "epoch 173; iter: 0; batch classifier loss: 0.400350; batch adversarial loss: 0.516032\n",
      "epoch 174; iter: 0; batch classifier loss: 0.406504; batch adversarial loss: 0.497416\n",
      "epoch 175; iter: 0; batch classifier loss: 0.318914; batch adversarial loss: 0.554101\n",
      "epoch 176; iter: 0; batch classifier loss: 0.299469; batch adversarial loss: 0.506963\n",
      "epoch 177; iter: 0; batch classifier loss: 0.442614; batch adversarial loss: 0.488606\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336852; batch adversarial loss: 0.591195\n",
      "epoch 179; iter: 0; batch classifier loss: 0.327657; batch adversarial loss: 0.571991\n",
      "epoch 180; iter: 0; batch classifier loss: 0.408395; batch adversarial loss: 0.450723\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319560; batch adversarial loss: 0.610224\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341432; batch adversarial loss: 0.534967\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372434; batch adversarial loss: 0.535269\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413793; batch adversarial loss: 0.544577\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319916; batch adversarial loss: 0.535110\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365687; batch adversarial loss: 0.506984\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358753; batch adversarial loss: 0.554021\n",
      "epoch 188; iter: 0; batch classifier loss: 0.415135; batch adversarial loss: 0.648043\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356983; batch adversarial loss: 0.553962\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395468; batch adversarial loss: 0.619541\n",
      "epoch 191; iter: 0; batch classifier loss: 0.384393; batch adversarial loss: 0.572923\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317860; batch adversarial loss: 0.488057\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343253; batch adversarial loss: 0.544692\n",
      "epoch 194; iter: 0; batch classifier loss: 0.414913; batch adversarial loss: 0.450710\n",
      "epoch 195; iter: 0; batch classifier loss: 0.285845; batch adversarial loss: 0.563488\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374255; batch adversarial loss: 0.460127\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370029; batch adversarial loss: 0.582166\n",
      "epoch 198; iter: 0; batch classifier loss: 0.330979; batch adversarial loss: 0.553866\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315291; batch adversarial loss: 0.563418\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731920; batch adversarial loss: 1.117523\n",
      "epoch 1; iter: 0; batch classifier loss: 0.883129; batch adversarial loss: 1.496667\n",
      "epoch 2; iter: 0; batch classifier loss: 1.105892; batch adversarial loss: 1.466994\n",
      "epoch 3; iter: 0; batch classifier loss: 1.078066; batch adversarial loss: 1.317475\n",
      "epoch 4; iter: 0; batch classifier loss: 1.120633; batch adversarial loss: 1.188390\n",
      "epoch 5; iter: 0; batch classifier loss: 1.258142; batch adversarial loss: 1.135686\n",
      "epoch 6; iter: 0; batch classifier loss: 1.250100; batch adversarial loss: 1.051573\n",
      "epoch 7; iter: 0; batch classifier loss: 1.298525; batch adversarial loss: 0.967302\n",
      "epoch 8; iter: 0; batch classifier loss: 1.320420; batch adversarial loss: 0.895457\n",
      "epoch 9; iter: 0; batch classifier loss: 1.255938; batch adversarial loss: 0.824685\n",
      "epoch 10; iter: 0; batch classifier loss: 1.206593; batch adversarial loss: 0.780618\n",
      "epoch 11; iter: 0; batch classifier loss: 1.154397; batch adversarial loss: 0.740089\n",
      "epoch 12; iter: 0; batch classifier loss: 1.052813; batch adversarial loss: 0.670495\n",
      "epoch 13; iter: 0; batch classifier loss: 0.745583; batch adversarial loss: 0.589081\n",
      "epoch 14; iter: 0; batch classifier loss: 0.631723; batch adversarial loss: 0.591130\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531206; batch adversarial loss: 0.578658\n",
      "epoch 16; iter: 0; batch classifier loss: 0.558551; batch adversarial loss: 0.592224\n",
      "epoch 17; iter: 0; batch classifier loss: 0.551610; batch adversarial loss: 0.572598\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530808; batch adversarial loss: 0.614498\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535333; batch adversarial loss: 0.563187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.501400; batch adversarial loss: 0.589358\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468847; batch adversarial loss: 0.585850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.505533; batch adversarial loss: 0.564563\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521721; batch adversarial loss: 0.509760\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501554; batch adversarial loss: 0.519479\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479305; batch adversarial loss: 0.602547\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500916; batch adversarial loss: 0.666482\n",
      "epoch 27; iter: 0; batch classifier loss: 0.416388; batch adversarial loss: 0.573584\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440714; batch adversarial loss: 0.544759\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431561; batch adversarial loss: 0.550271\n",
      "epoch 30; iter: 0; batch classifier loss: 0.542632; batch adversarial loss: 0.506872\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498269; batch adversarial loss: 0.577626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.447121; batch adversarial loss: 0.503354\n",
      "epoch 33; iter: 0; batch classifier loss: 0.407281; batch adversarial loss: 0.481657\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473793; batch adversarial loss: 0.515744\n",
      "epoch 35; iter: 0; batch classifier loss: 0.378132; batch adversarial loss: 0.536858\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496894; batch adversarial loss: 0.559476\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495997; batch adversarial loss: 0.591247\n",
      "epoch 38; iter: 0; batch classifier loss: 0.396382; batch adversarial loss: 0.579583\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466358; batch adversarial loss: 0.451700\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467401; batch adversarial loss: 0.591558\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401308; batch adversarial loss: 0.544873\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482714; batch adversarial loss: 0.518661\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470822; batch adversarial loss: 0.596912\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466832; batch adversarial loss: 0.610943\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458833; batch adversarial loss: 0.574935\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402032; batch adversarial loss: 0.597971\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437089; batch adversarial loss: 0.632488\n",
      "epoch 48; iter: 0; batch classifier loss: 0.466796; batch adversarial loss: 0.635687\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428102; batch adversarial loss: 0.521817\n",
      "epoch 50; iter: 0; batch classifier loss: 0.515204; batch adversarial loss: 0.581496\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409666; batch adversarial loss: 0.497076\n",
      "epoch 52; iter: 0; batch classifier loss: 0.479529; batch adversarial loss: 0.598476\n",
      "epoch 53; iter: 0; batch classifier loss: 0.476794; batch adversarial loss: 0.523867\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442980; batch adversarial loss: 0.529163\n",
      "epoch 55; iter: 0; batch classifier loss: 0.452012; batch adversarial loss: 0.588578\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419467; batch adversarial loss: 0.550620\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399587; batch adversarial loss: 0.504132\n",
      "epoch 58; iter: 0; batch classifier loss: 0.385718; batch adversarial loss: 0.559394\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384591; batch adversarial loss: 0.547409\n",
      "epoch 60; iter: 0; batch classifier loss: 0.419727; batch adversarial loss: 0.582847\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425083; batch adversarial loss: 0.550698\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386677; batch adversarial loss: 0.482340\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411233; batch adversarial loss: 0.520509\n",
      "epoch 64; iter: 0; batch classifier loss: 0.356480; batch adversarial loss: 0.627551\n",
      "epoch 65; iter: 0; batch classifier loss: 0.378930; batch adversarial loss: 0.527207\n",
      "epoch 66; iter: 0; batch classifier loss: 0.312337; batch adversarial loss: 0.456672\n",
      "epoch 67; iter: 0; batch classifier loss: 0.473196; batch adversarial loss: 0.625307\n",
      "epoch 68; iter: 0; batch classifier loss: 0.464224; batch adversarial loss: 0.572450\n",
      "epoch 69; iter: 0; batch classifier loss: 0.467577; batch adversarial loss: 0.527287\n",
      "epoch 70; iter: 0; batch classifier loss: 0.386130; batch adversarial loss: 0.472158\n",
      "epoch 71; iter: 0; batch classifier loss: 0.383502; batch adversarial loss: 0.508833\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355129; batch adversarial loss: 0.571567\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448318; batch adversarial loss: 0.589740\n",
      "epoch 74; iter: 0; batch classifier loss: 0.498286; batch adversarial loss: 0.526469\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438443; batch adversarial loss: 0.571722\n",
      "epoch 76; iter: 0; batch classifier loss: 0.468246; batch adversarial loss: 0.580597\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371170; batch adversarial loss: 0.625763\n",
      "epoch 78; iter: 0; batch classifier loss: 0.449143; batch adversarial loss: 0.527134\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390605; batch adversarial loss: 0.525705\n",
      "epoch 80; iter: 0; batch classifier loss: 0.428826; batch adversarial loss: 0.480899\n",
      "epoch 81; iter: 0; batch classifier loss: 0.352632; batch adversarial loss: 0.571745\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400801; batch adversarial loss: 0.634307\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421462; batch adversarial loss: 0.525332\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384357; batch adversarial loss: 0.525602\n",
      "epoch 85; iter: 0; batch classifier loss: 0.359257; batch adversarial loss: 0.579706\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446119; batch adversarial loss: 0.591672\n",
      "epoch 87; iter: 0; batch classifier loss: 0.421821; batch adversarial loss: 0.487851\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354546; batch adversarial loss: 0.598177\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373401; batch adversarial loss: 0.642801\n",
      "epoch 90; iter: 0; batch classifier loss: 0.290108; batch adversarial loss: 0.544428\n",
      "epoch 91; iter: 0; batch classifier loss: 0.328021; batch adversarial loss: 0.506677\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412637; batch adversarial loss: 0.506579\n",
      "epoch 93; iter: 0; batch classifier loss: 0.303444; batch adversarial loss: 0.528268\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387736; batch adversarial loss: 0.463123\n",
      "epoch 95; iter: 0; batch classifier loss: 0.318418; batch adversarial loss: 0.496785\n",
      "epoch 96; iter: 0; batch classifier loss: 0.354140; batch adversarial loss: 0.473705\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395135; batch adversarial loss: 0.599023\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412805; batch adversarial loss: 0.509056\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382735; batch adversarial loss: 0.556491\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397560; batch adversarial loss: 0.524145\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324242; batch adversarial loss: 0.579383\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407900; batch adversarial loss: 0.569024\n",
      "epoch 103; iter: 0; batch classifier loss: 0.336779; batch adversarial loss: 0.499115\n",
      "epoch 104; iter: 0; batch classifier loss: 0.380920; batch adversarial loss: 0.560154\n",
      "epoch 105; iter: 0; batch classifier loss: 0.329284; batch adversarial loss: 0.550931\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333989; batch adversarial loss: 0.483326\n",
      "epoch 107; iter: 0; batch classifier loss: 0.300846; batch adversarial loss: 0.660599\n",
      "epoch 108; iter: 0; batch classifier loss: 0.318215; batch adversarial loss: 0.498724\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359675; batch adversarial loss: 0.613789\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352913; batch adversarial loss: 0.499440\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382035; batch adversarial loss: 0.592327\n",
      "epoch 112; iter: 0; batch classifier loss: 0.413867; batch adversarial loss: 0.580195\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370278; batch adversarial loss: 0.614084\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364335; batch adversarial loss: 0.461568\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342561; batch adversarial loss: 0.474044\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375638; batch adversarial loss: 0.568991\n",
      "epoch 117; iter: 0; batch classifier loss: 0.251687; batch adversarial loss: 0.561802\n",
      "epoch 118; iter: 0; batch classifier loss: 0.495351; batch adversarial loss: 0.544725\n",
      "epoch 119; iter: 0; batch classifier loss: 0.411379; batch adversarial loss: 0.508657\n",
      "epoch 120; iter: 0; batch classifier loss: 0.335116; batch adversarial loss: 0.523048\n",
      "epoch 121; iter: 0; batch classifier loss: 0.324601; batch adversarial loss: 0.548356\n",
      "epoch 122; iter: 0; batch classifier loss: 0.334205; batch adversarial loss: 0.535913\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375890; batch adversarial loss: 0.564016\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346948; batch adversarial loss: 0.527264\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404012; batch adversarial loss: 0.481116\n",
      "epoch 126; iter: 0; batch classifier loss: 0.345025; batch adversarial loss: 0.656012\n",
      "epoch 127; iter: 0; batch classifier loss: 0.306670; batch adversarial loss: 0.588009\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344954; batch adversarial loss: 0.502961\n",
      "epoch 129; iter: 0; batch classifier loss: 0.326977; batch adversarial loss: 0.615092\n",
      "epoch 130; iter: 0; batch classifier loss: 0.439459; batch adversarial loss: 0.554261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.319408; batch adversarial loss: 0.580229\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317653; batch adversarial loss: 0.535072\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374600; batch adversarial loss: 0.539057\n",
      "epoch 134; iter: 0; batch classifier loss: 0.326730; batch adversarial loss: 0.461035\n",
      "epoch 135; iter: 0; batch classifier loss: 0.359623; batch adversarial loss: 0.525014\n",
      "epoch 136; iter: 0; batch classifier loss: 0.318110; batch adversarial loss: 0.585220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.414268; batch adversarial loss: 0.491138\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353070; batch adversarial loss: 0.519794\n",
      "epoch 139; iter: 0; batch classifier loss: 0.300946; batch adversarial loss: 0.526133\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374883; batch adversarial loss: 0.580084\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351338; batch adversarial loss: 0.581329\n",
      "epoch 142; iter: 0; batch classifier loss: 0.305099; batch adversarial loss: 0.511091\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348151; batch adversarial loss: 0.514646\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340350; batch adversarial loss: 0.500587\n",
      "epoch 145; iter: 0; batch classifier loss: 0.357747; batch adversarial loss: 0.591884\n",
      "epoch 146; iter: 0; batch classifier loss: 0.302468; batch adversarial loss: 0.488861\n",
      "epoch 147; iter: 0; batch classifier loss: 0.279273; batch adversarial loss: 0.525525\n",
      "epoch 148; iter: 0; batch classifier loss: 0.320869; batch adversarial loss: 0.509540\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328253; batch adversarial loss: 0.577742\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389100; batch adversarial loss: 0.431736\n",
      "epoch 151; iter: 0; batch classifier loss: 0.301560; batch adversarial loss: 0.518721\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336201; batch adversarial loss: 0.502805\n",
      "epoch 153; iter: 0; batch classifier loss: 0.319740; batch adversarial loss: 0.533828\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343433; batch adversarial loss: 0.549133\n",
      "epoch 155; iter: 0; batch classifier loss: 0.294679; batch adversarial loss: 0.582616\n",
      "epoch 156; iter: 0; batch classifier loss: 0.296383; batch adversarial loss: 0.535512\n",
      "epoch 157; iter: 0; batch classifier loss: 0.322881; batch adversarial loss: 0.502038\n",
      "epoch 158; iter: 0; batch classifier loss: 0.425584; batch adversarial loss: 0.520027\n",
      "epoch 159; iter: 0; batch classifier loss: 0.318848; batch adversarial loss: 0.517835\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350467; batch adversarial loss: 0.537032\n",
      "epoch 161; iter: 0; batch classifier loss: 0.251229; batch adversarial loss: 0.517453\n",
      "epoch 162; iter: 0; batch classifier loss: 0.288012; batch adversarial loss: 0.570671\n",
      "epoch 163; iter: 0; batch classifier loss: 0.333774; batch adversarial loss: 0.546518\n",
      "epoch 164; iter: 0; batch classifier loss: 0.327498; batch adversarial loss: 0.535770\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327469; batch adversarial loss: 0.545216\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334339; batch adversarial loss: 0.606086\n",
      "epoch 167; iter: 0; batch classifier loss: 0.252334; batch adversarial loss: 0.525356\n",
      "epoch 168; iter: 0; batch classifier loss: 0.371156; batch adversarial loss: 0.508951\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332338; batch adversarial loss: 0.607795\n",
      "epoch 170; iter: 0; batch classifier loss: 0.311798; batch adversarial loss: 0.545616\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411331; batch adversarial loss: 0.626718\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362861; batch adversarial loss: 0.479865\n",
      "epoch 173; iter: 0; batch classifier loss: 0.255610; batch adversarial loss: 0.624576\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324381; batch adversarial loss: 0.561277\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360074; batch adversarial loss: 0.579976\n",
      "epoch 176; iter: 0; batch classifier loss: 0.297125; batch adversarial loss: 0.579060\n",
      "epoch 177; iter: 0; batch classifier loss: 0.294734; batch adversarial loss: 0.570842\n",
      "epoch 178; iter: 0; batch classifier loss: 0.290863; batch adversarial loss: 0.600269\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347770; batch adversarial loss: 0.550895\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372791; batch adversarial loss: 0.526580\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319250; batch adversarial loss: 0.611541\n",
      "epoch 182; iter: 0; batch classifier loss: 0.290828; batch adversarial loss: 0.497698\n",
      "epoch 183; iter: 0; batch classifier loss: 0.325346; batch adversarial loss: 0.617534\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331756; batch adversarial loss: 0.544528\n",
      "epoch 185; iter: 0; batch classifier loss: 0.296343; batch adversarial loss: 0.537149\n",
      "epoch 186; iter: 0; batch classifier loss: 0.408390; batch adversarial loss: 0.597338\n",
      "epoch 187; iter: 0; batch classifier loss: 0.312539; batch adversarial loss: 0.534976\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362746; batch adversarial loss: 0.582805\n",
      "epoch 189; iter: 0; batch classifier loss: 0.316586; batch adversarial loss: 0.607536\n",
      "epoch 190; iter: 0; batch classifier loss: 0.313874; batch adversarial loss: 0.515360\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322048; batch adversarial loss: 0.608947\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387888; batch adversarial loss: 0.591803\n",
      "epoch 193; iter: 0; batch classifier loss: 0.321929; batch adversarial loss: 0.567544\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353210; batch adversarial loss: 0.617541\n",
      "epoch 195; iter: 0; batch classifier loss: 0.373147; batch adversarial loss: 0.590834\n",
      "epoch 196; iter: 0; batch classifier loss: 0.300556; batch adversarial loss: 0.553060\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323995; batch adversarial loss: 0.553932\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309771; batch adversarial loss: 0.515433\n",
      "epoch 199; iter: 0; batch classifier loss: 0.347938; batch adversarial loss: 0.533739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.756774; batch adversarial loss: 0.732684\n",
      "epoch 1; iter: 0; batch classifier loss: 0.612354; batch adversarial loss: 0.671760\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605048; batch adversarial loss: 0.676802\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579937; batch adversarial loss: 0.635426\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580640; batch adversarial loss: 0.620154\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524488; batch adversarial loss: 0.586205\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563664; batch adversarial loss: 0.550531\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492445; batch adversarial loss: 0.588938\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618321; batch adversarial loss: 0.614986\n",
      "epoch 9; iter: 0; batch classifier loss: 0.623126; batch adversarial loss: 0.595306\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548876; batch adversarial loss: 0.656517\n",
      "epoch 11; iter: 0; batch classifier loss: 0.558907; batch adversarial loss: 0.534380\n",
      "epoch 12; iter: 0; batch classifier loss: 0.579580; batch adversarial loss: 0.574370\n",
      "epoch 13; iter: 0; batch classifier loss: 0.390012; batch adversarial loss: 0.613218\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449385; batch adversarial loss: 0.540511\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552719; batch adversarial loss: 0.513233\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539207; batch adversarial loss: 0.568537\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485237; batch adversarial loss: 0.562488\n",
      "epoch 18; iter: 0; batch classifier loss: 0.516281; batch adversarial loss: 0.475850\n",
      "epoch 19; iter: 0; batch classifier loss: 0.431815; batch adversarial loss: 0.552914\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517069; batch adversarial loss: 0.548614\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456103; batch adversarial loss: 0.535876\n",
      "epoch 22; iter: 0; batch classifier loss: 0.476711; batch adversarial loss: 0.536223\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418637; batch adversarial loss: 0.591927\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528837; batch adversarial loss: 0.498900\n",
      "epoch 25; iter: 0; batch classifier loss: 0.486638; batch adversarial loss: 0.552392\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527552; batch adversarial loss: 0.536696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.517620; batch adversarial loss: 0.521417\n",
      "epoch 28; iter: 0; batch classifier loss: 0.400717; batch adversarial loss: 0.520315\n",
      "epoch 29; iter: 0; batch classifier loss: 0.429672; batch adversarial loss: 0.564903\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422093; batch adversarial loss: 0.513802\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410843; batch adversarial loss: 0.508201\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436937; batch adversarial loss: 0.511503\n",
      "epoch 33; iter: 0; batch classifier loss: 0.491912; batch adversarial loss: 0.490073\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431995; batch adversarial loss: 0.551106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.417588; batch adversarial loss: 0.504077\n",
      "epoch 36; iter: 0; batch classifier loss: 0.423301; batch adversarial loss: 0.568042\n",
      "epoch 37; iter: 0; batch classifier loss: 0.358349; batch adversarial loss: 0.481537\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440552; batch adversarial loss: 0.569513\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422201; batch adversarial loss: 0.516523\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463827; batch adversarial loss: 0.534725\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419840; batch adversarial loss: 0.435630\n",
      "epoch 42; iter: 0; batch classifier loss: 0.540953; batch adversarial loss: 0.648920\n",
      "epoch 43; iter: 0; batch classifier loss: 0.378028; batch adversarial loss: 0.532803\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445644; batch adversarial loss: 0.518411\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445695; batch adversarial loss: 0.579982\n",
      "epoch 46; iter: 0; batch classifier loss: 0.404929; batch adversarial loss: 0.549642\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432650; batch adversarial loss: 0.564254\n",
      "epoch 48; iter: 0; batch classifier loss: 0.512633; batch adversarial loss: 0.483008\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419143; batch adversarial loss: 0.564464\n",
      "epoch 50; iter: 0; batch classifier loss: 0.384165; batch adversarial loss: 0.587236\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447479; batch adversarial loss: 0.525864\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425793; batch adversarial loss: 0.516245\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461776; batch adversarial loss: 0.554421\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406988; batch adversarial loss: 0.486668\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384467; batch adversarial loss: 0.486054\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457434; batch adversarial loss: 0.544732\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461701; batch adversarial loss: 0.478501\n",
      "epoch 58; iter: 0; batch classifier loss: 0.491808; batch adversarial loss: 0.481840\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425407; batch adversarial loss: 0.540133\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356610; batch adversarial loss: 0.503808\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413534; batch adversarial loss: 0.501550\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423419; batch adversarial loss: 0.501875\n",
      "epoch 63; iter: 0; batch classifier loss: 0.372571; batch adversarial loss: 0.637473\n",
      "epoch 64; iter: 0; batch classifier loss: 0.447375; batch adversarial loss: 0.531910\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369923; batch adversarial loss: 0.452084\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411280; batch adversarial loss: 0.561096\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426334; batch adversarial loss: 0.544906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.341523; batch adversarial loss: 0.515316\n",
      "epoch 69; iter: 0; batch classifier loss: 0.333145; batch adversarial loss: 0.577198\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374207; batch adversarial loss: 0.534051\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396908; batch adversarial loss: 0.602927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402411; batch adversarial loss: 0.431174\n",
      "epoch 73; iter: 0; batch classifier loss: 0.349242; batch adversarial loss: 0.453574\n",
      "epoch 74; iter: 0; batch classifier loss: 0.343860; batch adversarial loss: 0.572621\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409010; batch adversarial loss: 0.516133\n",
      "epoch 76; iter: 0; batch classifier loss: 0.508591; batch adversarial loss: 0.535840\n",
      "epoch 77; iter: 0; batch classifier loss: 0.359453; batch adversarial loss: 0.535156\n",
      "epoch 78; iter: 0; batch classifier loss: 0.420924; batch adversarial loss: 0.486963\n",
      "epoch 79; iter: 0; batch classifier loss: 0.302062; batch adversarial loss: 0.553555\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330065; batch adversarial loss: 0.574105\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426177; batch adversarial loss: 0.516027\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384043; batch adversarial loss: 0.486700\n",
      "epoch 83; iter: 0; batch classifier loss: 0.347692; batch adversarial loss: 0.494072\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371557; batch adversarial loss: 0.545080\n",
      "epoch 85; iter: 0; batch classifier loss: 0.453506; batch adversarial loss: 0.554031\n",
      "epoch 86; iter: 0; batch classifier loss: 0.330335; batch adversarial loss: 0.532348\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378875; batch adversarial loss: 0.603297\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440719; batch adversarial loss: 0.485611\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342127; batch adversarial loss: 0.607268\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411548; batch adversarial loss: 0.576853\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377888; batch adversarial loss: 0.564144\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405910; batch adversarial loss: 0.553035\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353697; batch adversarial loss: 0.554460\n",
      "epoch 94; iter: 0; batch classifier loss: 0.288446; batch adversarial loss: 0.562781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.421527; batch adversarial loss: 0.544366\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398292; batch adversarial loss: 0.535509\n",
      "epoch 97; iter: 0; batch classifier loss: 0.324643; batch adversarial loss: 0.534493\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359504; batch adversarial loss: 0.622838\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403307; batch adversarial loss: 0.523877\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400260; batch adversarial loss: 0.543947\n",
      "epoch 101; iter: 0; batch classifier loss: 0.479558; batch adversarial loss: 0.583829\n",
      "epoch 102; iter: 0; batch classifier loss: 0.445853; batch adversarial loss: 0.540670\n",
      "epoch 103; iter: 0; batch classifier loss: 0.423209; batch adversarial loss: 0.566643\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402942; batch adversarial loss: 0.516722\n",
      "epoch 105; iter: 0; batch classifier loss: 0.386741; batch adversarial loss: 0.486974\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345223; batch adversarial loss: 0.516640\n",
      "epoch 107; iter: 0; batch classifier loss: 0.448413; batch adversarial loss: 0.564550\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435986; batch adversarial loss: 0.502150\n",
      "epoch 109; iter: 0; batch classifier loss: 0.313497; batch adversarial loss: 0.546801\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344927; batch adversarial loss: 0.607716\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395825; batch adversarial loss: 0.555963\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375825; batch adversarial loss: 0.526435\n",
      "epoch 113; iter: 0; batch classifier loss: 0.443505; batch adversarial loss: 0.557777\n",
      "epoch 114; iter: 0; batch classifier loss: 0.473558; batch adversarial loss: 0.461077\n",
      "epoch 115; iter: 0; batch classifier loss: 0.435777; batch adversarial loss: 0.544595\n",
      "epoch 116; iter: 0; batch classifier loss: 0.360005; batch adversarial loss: 0.544757\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377339; batch adversarial loss: 0.648283\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333885; batch adversarial loss: 0.590247\n",
      "epoch 119; iter: 0; batch classifier loss: 0.320309; batch adversarial loss: 0.555269\n",
      "epoch 120; iter: 0; batch classifier loss: 0.308833; batch adversarial loss: 0.573492\n",
      "epoch 121; iter: 0; batch classifier loss: 0.414115; batch adversarial loss: 0.544581\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373099; batch adversarial loss: 0.564676\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341184; batch adversarial loss: 0.601880\n",
      "epoch 124; iter: 0; batch classifier loss: 0.292552; batch adversarial loss: 0.463854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.375632; batch adversarial loss: 0.524924\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358444; batch adversarial loss: 0.497816\n",
      "epoch 127; iter: 0; batch classifier loss: 0.410337; batch adversarial loss: 0.473200\n",
      "epoch 128; iter: 0; batch classifier loss: 0.426744; batch adversarial loss: 0.584816\n",
      "epoch 129; iter: 0; batch classifier loss: 0.439325; batch adversarial loss: 0.506062\n",
      "epoch 130; iter: 0; batch classifier loss: 0.446009; batch adversarial loss: 0.479678\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336160; batch adversarial loss: 0.613747\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329122; batch adversarial loss: 0.518562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354574; batch adversarial loss: 0.574098\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399053; batch adversarial loss: 0.548302\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366910; batch adversarial loss: 0.583797\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339382; batch adversarial loss: 0.536860\n",
      "epoch 137; iter: 0; batch classifier loss: 0.331360; batch adversarial loss: 0.565754\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338019; batch adversarial loss: 0.524412\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368878; batch adversarial loss: 0.524682\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333200; batch adversarial loss: 0.447572\n",
      "epoch 141; iter: 0; batch classifier loss: 0.432693; batch adversarial loss: 0.495106\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389441; batch adversarial loss: 0.515491\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414999; batch adversarial loss: 0.604139\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395307; batch adversarial loss: 0.583715\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351283; batch adversarial loss: 0.562233\n",
      "epoch 146; iter: 0; batch classifier loss: 0.392131; batch adversarial loss: 0.562386\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372498; batch adversarial loss: 0.457471\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330931; batch adversarial loss: 0.556027\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378397; batch adversarial loss: 0.503984\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325667; batch adversarial loss: 0.474847\n",
      "epoch 151; iter: 0; batch classifier loss: 0.446692; batch adversarial loss: 0.532356\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405083; batch adversarial loss: 0.536185\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371488; batch adversarial loss: 0.491354\n",
      "epoch 154; iter: 0; batch classifier loss: 0.282393; batch adversarial loss: 0.622989\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351806; batch adversarial loss: 0.567015\n",
      "epoch 156; iter: 0; batch classifier loss: 0.275246; batch adversarial loss: 0.612481\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369829; batch adversarial loss: 0.555147\n",
      "epoch 158; iter: 0; batch classifier loss: 0.442465; batch adversarial loss: 0.534096\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345048; batch adversarial loss: 0.496614\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356130; batch adversarial loss: 0.592741\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385413; batch adversarial loss: 0.601517\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334281; batch adversarial loss: 0.544298\n",
      "epoch 163; iter: 0; batch classifier loss: 0.309842; batch adversarial loss: 0.543569\n",
      "epoch 164; iter: 0; batch classifier loss: 0.364036; batch adversarial loss: 0.571585\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333283; batch adversarial loss: 0.604203\n",
      "epoch 166; iter: 0; batch classifier loss: 0.242116; batch adversarial loss: 0.622173\n",
      "epoch 167; iter: 0; batch classifier loss: 0.456314; batch adversarial loss: 0.517439\n",
      "epoch 168; iter: 0; batch classifier loss: 0.292676; batch adversarial loss: 0.475482\n",
      "epoch 169; iter: 0; batch classifier loss: 0.438046; batch adversarial loss: 0.486231\n",
      "epoch 170; iter: 0; batch classifier loss: 0.407899; batch adversarial loss: 0.544443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401322; batch adversarial loss: 0.564393\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366107; batch adversarial loss: 0.613526\n",
      "epoch 173; iter: 0; batch classifier loss: 0.406698; batch adversarial loss: 0.505810\n",
      "epoch 174; iter: 0; batch classifier loss: 0.335060; batch adversarial loss: 0.552444\n",
      "epoch 175; iter: 0; batch classifier loss: 0.256739; batch adversarial loss: 0.585936\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354681; batch adversarial loss: 0.535357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335581; batch adversarial loss: 0.552807\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381588; batch adversarial loss: 0.475233\n",
      "epoch 179; iter: 0; batch classifier loss: 0.327652; batch adversarial loss: 0.526656\n",
      "epoch 180; iter: 0; batch classifier loss: 0.440564; batch adversarial loss: 0.549512\n",
      "epoch 181; iter: 0; batch classifier loss: 0.280368; batch adversarial loss: 0.543885\n",
      "epoch 182; iter: 0; batch classifier loss: 0.284228; batch adversarial loss: 0.494730\n",
      "epoch 183; iter: 0; batch classifier loss: 0.418467; batch adversarial loss: 0.583356\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385198; batch adversarial loss: 0.482717\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361276; batch adversarial loss: 0.565173\n",
      "epoch 186; iter: 0; batch classifier loss: 0.314607; batch adversarial loss: 0.525670\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310775; batch adversarial loss: 0.565148\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385900; batch adversarial loss: 0.630176\n",
      "epoch 189; iter: 0; batch classifier loss: 0.342868; batch adversarial loss: 0.488500\n",
      "epoch 190; iter: 0; batch classifier loss: 0.377357; batch adversarial loss: 0.506876\n",
      "epoch 191; iter: 0; batch classifier loss: 0.388978; batch adversarial loss: 0.505832\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348487; batch adversarial loss: 0.564071\n",
      "epoch 193; iter: 0; batch classifier loss: 0.321442; batch adversarial loss: 0.458202\n",
      "epoch 194; iter: 0; batch classifier loss: 0.345980; batch adversarial loss: 0.543610\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351140; batch adversarial loss: 0.515855\n",
      "epoch 196; iter: 0; batch classifier loss: 0.291694; batch adversarial loss: 0.562236\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355311; batch adversarial loss: 0.465880\n",
      "epoch 198; iter: 0; batch classifier loss: 0.298381; batch adversarial loss: 0.446357\n",
      "epoch 199; iter: 0; batch classifier loss: 0.376838; batch adversarial loss: 0.554977\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676639; batch adversarial loss: 0.805781\n",
      "epoch 1; iter: 0; batch classifier loss: 0.819352; batch adversarial loss: 0.873423\n",
      "epoch 2; iter: 0; batch classifier loss: 0.932541; batch adversarial loss: 0.830196\n",
      "epoch 3; iter: 0; batch classifier loss: 0.820101; batch adversarial loss: 0.733342\n",
      "epoch 4; iter: 0; batch classifier loss: 0.915112; batch adversarial loss: 0.699259\n",
      "epoch 5; iter: 0; batch classifier loss: 0.694856; batch adversarial loss: 0.656841\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581373; batch adversarial loss: 0.600853\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546106; batch adversarial loss: 0.620996\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574342; batch adversarial loss: 0.588468\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576438; batch adversarial loss: 0.589972\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503093; batch adversarial loss: 0.573928\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571006; batch adversarial loss: 0.579255\n",
      "epoch 12; iter: 0; batch classifier loss: 0.508343; batch adversarial loss: 0.558662\n",
      "epoch 13; iter: 0; batch classifier loss: 0.574107; batch adversarial loss: 0.572182\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506784; batch adversarial loss: 0.608387\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471067; batch adversarial loss: 0.545856\n",
      "epoch 16; iter: 0; batch classifier loss: 0.427645; batch adversarial loss: 0.529988\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495300; batch adversarial loss: 0.551460\n",
      "epoch 18; iter: 0; batch classifier loss: 0.593871; batch adversarial loss: 0.584527\n",
      "epoch 19; iter: 0; batch classifier loss: 0.558930; batch adversarial loss: 0.529658\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510756; batch adversarial loss: 0.518237\n",
      "epoch 21; iter: 0; batch classifier loss: 0.445163; batch adversarial loss: 0.551151\n",
      "epoch 22; iter: 0; batch classifier loss: 0.504390; batch adversarial loss: 0.534607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.544788; batch adversarial loss: 0.542255\n",
      "epoch 24; iter: 0; batch classifier loss: 0.541936; batch adversarial loss: 0.575118\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480149; batch adversarial loss: 0.571575\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466054; batch adversarial loss: 0.582626\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447371; batch adversarial loss: 0.568168\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486640; batch adversarial loss: 0.633692\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475241; batch adversarial loss: 0.543357\n",
      "epoch 30; iter: 0; batch classifier loss: 0.407800; batch adversarial loss: 0.596967\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507569; batch adversarial loss: 0.561912\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497814; batch adversarial loss: 0.574372\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444377; batch adversarial loss: 0.545803\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390167; batch adversarial loss: 0.502259\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446308; batch adversarial loss: 0.603868\n",
      "epoch 36; iter: 0; batch classifier loss: 0.531763; batch adversarial loss: 0.585204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389215; batch adversarial loss: 0.534049\n",
      "epoch 38; iter: 0; batch classifier loss: 0.433337; batch adversarial loss: 0.604768\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450602; batch adversarial loss: 0.544946\n",
      "epoch 40; iter: 0; batch classifier loss: 0.400580; batch adversarial loss: 0.631560\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430388; batch adversarial loss: 0.532631\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427655; batch adversarial loss: 0.591796\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459130; batch adversarial loss: 0.642430\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421813; batch adversarial loss: 0.547648\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454438; batch adversarial loss: 0.573220\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455437; batch adversarial loss: 0.604236\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480819; batch adversarial loss: 0.572833\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415750; batch adversarial loss: 0.606594\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384202; batch adversarial loss: 0.494974\n",
      "epoch 50; iter: 0; batch classifier loss: 0.366632; batch adversarial loss: 0.518636\n",
      "epoch 51; iter: 0; batch classifier loss: 0.382506; batch adversarial loss: 0.613228\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475854; batch adversarial loss: 0.591705\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439745; batch adversarial loss: 0.563115\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417241; batch adversarial loss: 0.568765\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376626; batch adversarial loss: 0.579947\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416936; batch adversarial loss: 0.552186\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374089; batch adversarial loss: 0.614375\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390865; batch adversarial loss: 0.535914\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374556; batch adversarial loss: 0.569574\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446040; batch adversarial loss: 0.570509\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412532; batch adversarial loss: 0.563079\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401162; batch adversarial loss: 0.496516\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386245; batch adversarial loss: 0.559182\n",
      "epoch 64; iter: 0; batch classifier loss: 0.482538; batch adversarial loss: 0.540807\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433006; batch adversarial loss: 0.552155\n",
      "epoch 66; iter: 0; batch classifier loss: 0.338442; batch adversarial loss: 0.627709\n",
      "epoch 67; iter: 0; batch classifier loss: 0.396149; batch adversarial loss: 0.580909\n",
      "epoch 68; iter: 0; batch classifier loss: 0.327038; batch adversarial loss: 0.493636\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437333; batch adversarial loss: 0.572616\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354044; batch adversarial loss: 0.474066\n",
      "epoch 71; iter: 0; batch classifier loss: 0.329453; batch adversarial loss: 0.535920\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397403; batch adversarial loss: 0.571674\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383413; batch adversarial loss: 0.535628\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416236; batch adversarial loss: 0.535469\n",
      "epoch 75; iter: 0; batch classifier loss: 0.324670; batch adversarial loss: 0.535362\n",
      "epoch 76; iter: 0; batch classifier loss: 0.378541; batch adversarial loss: 0.598154\n",
      "epoch 77; iter: 0; batch classifier loss: 0.476559; batch adversarial loss: 0.553686\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398076; batch adversarial loss: 0.579634\n",
      "epoch 79; iter: 0; batch classifier loss: 0.443321; batch adversarial loss: 0.526913\n",
      "epoch 80; iter: 0; batch classifier loss: 0.324396; batch adversarial loss: 0.581111\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404252; batch adversarial loss: 0.517361\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375776; batch adversarial loss: 0.552640\n",
      "epoch 83; iter: 0; batch classifier loss: 0.340702; batch adversarial loss: 0.516366\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409219; batch adversarial loss: 0.589868\n",
      "epoch 85; iter: 0; batch classifier loss: 0.327799; batch adversarial loss: 0.534256\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367686; batch adversarial loss: 0.526122\n",
      "epoch 87; iter: 0; batch classifier loss: 0.415164; batch adversarial loss: 0.453705\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351620; batch adversarial loss: 0.544782\n",
      "epoch 89; iter: 0; batch classifier loss: 0.359332; batch adversarial loss: 0.535464\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365113; batch adversarial loss: 0.489855\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360604; batch adversarial loss: 0.545255\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398372; batch adversarial loss: 0.599538\n",
      "epoch 93; iter: 0; batch classifier loss: 0.294083; batch adversarial loss: 0.553583\n",
      "epoch 94; iter: 0; batch classifier loss: 0.345746; batch adversarial loss: 0.553726\n",
      "epoch 95; iter: 0; batch classifier loss: 0.296912; batch adversarial loss: 0.490036\n",
      "epoch 96; iter: 0; batch classifier loss: 0.359958; batch adversarial loss: 0.535737\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367332; batch adversarial loss: 0.489894\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383439; batch adversarial loss: 0.543015\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393297; batch adversarial loss: 0.591186\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385479; batch adversarial loss: 0.599904\n",
      "epoch 101; iter: 0; batch classifier loss: 0.388168; batch adversarial loss: 0.497429\n",
      "epoch 102; iter: 0; batch classifier loss: 0.234404; batch adversarial loss: 0.579734\n",
      "epoch 103; iter: 0; batch classifier loss: 0.400644; batch adversarial loss: 0.517164\n",
      "epoch 104; iter: 0; batch classifier loss: 0.355312; batch adversarial loss: 0.556229\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384209; batch adversarial loss: 0.553446\n",
      "epoch 106; iter: 0; batch classifier loss: 0.436060; batch adversarial loss: 0.563556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.356741; batch adversarial loss: 0.534814\n",
      "epoch 108; iter: 0; batch classifier loss: 0.344476; batch adversarial loss: 0.480151\n",
      "epoch 109; iter: 0; batch classifier loss: 0.440573; batch adversarial loss: 0.562282\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353021; batch adversarial loss: 0.599527\n",
      "epoch 111; iter: 0; batch classifier loss: 0.346609; batch adversarial loss: 0.533021\n",
      "epoch 112; iter: 0; batch classifier loss: 0.330104; batch adversarial loss: 0.506620\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386973; batch adversarial loss: 0.507293\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385426; batch adversarial loss: 0.544290\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343773; batch adversarial loss: 0.469472\n",
      "epoch 116; iter: 0; batch classifier loss: 0.363610; batch adversarial loss: 0.582293\n",
      "epoch 117; iter: 0; batch classifier loss: 0.352456; batch adversarial loss: 0.619725\n",
      "epoch 118; iter: 0; batch classifier loss: 0.380145; batch adversarial loss: 0.499177\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369757; batch adversarial loss: 0.518381\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401813; batch adversarial loss: 0.572866\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345359; batch adversarial loss: 0.489739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.402984; batch adversarial loss: 0.501274\n",
      "epoch 123; iter: 0; batch classifier loss: 0.386286; batch adversarial loss: 0.637096\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382199; batch adversarial loss: 0.534923\n",
      "epoch 125; iter: 0; batch classifier loss: 0.271481; batch adversarial loss: 0.525995\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359721; batch adversarial loss: 0.617883\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329425; batch adversarial loss: 0.527323\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338723; batch adversarial loss: 0.500114\n",
      "epoch 129; iter: 0; batch classifier loss: 0.331160; batch adversarial loss: 0.527148\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360742; batch adversarial loss: 0.535478\n",
      "epoch 131; iter: 0; batch classifier loss: 0.333431; batch adversarial loss: 0.535696\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339579; batch adversarial loss: 0.563181\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402058; batch adversarial loss: 0.616201\n",
      "epoch 134; iter: 0; batch classifier loss: 0.360690; batch adversarial loss: 0.598216\n",
      "epoch 135; iter: 0; batch classifier loss: 0.405594; batch adversarial loss: 0.643792\n",
      "epoch 136; iter: 0; batch classifier loss: 0.390193; batch adversarial loss: 0.535533\n",
      "epoch 137; iter: 0; batch classifier loss: 0.412415; batch adversarial loss: 0.507811\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379719; batch adversarial loss: 0.526931\n",
      "epoch 139; iter: 0; batch classifier loss: 0.320659; batch adversarial loss: 0.580796\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340174; batch adversarial loss: 0.544558\n",
      "epoch 141; iter: 0; batch classifier loss: 0.286194; batch adversarial loss: 0.552994\n",
      "epoch 142; iter: 0; batch classifier loss: 0.319915; batch adversarial loss: 0.554367\n",
      "epoch 143; iter: 0; batch classifier loss: 0.325999; batch adversarial loss: 0.634540\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437106; batch adversarial loss: 0.536342\n",
      "epoch 145; iter: 0; batch classifier loss: 0.396397; batch adversarial loss: 0.618077\n",
      "epoch 146; iter: 0; batch classifier loss: 0.309159; batch adversarial loss: 0.554207\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374037; batch adversarial loss: 0.590752\n",
      "epoch 148; iter: 0; batch classifier loss: 0.293936; batch adversarial loss: 0.481375\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368835; batch adversarial loss: 0.608313\n",
      "epoch 150; iter: 0; batch classifier loss: 0.346545; batch adversarial loss: 0.525254\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361035; batch adversarial loss: 0.543625\n",
      "epoch 152; iter: 0; batch classifier loss: 0.292091; batch adversarial loss: 0.526345\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349699; batch adversarial loss: 0.506413\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370845; batch adversarial loss: 0.553277\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324093; batch adversarial loss: 0.470091\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396231; batch adversarial loss: 0.599726\n",
      "epoch 157; iter: 0; batch classifier loss: 0.306735; batch adversarial loss: 0.618849\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338649; batch adversarial loss: 0.561071\n",
      "epoch 159; iter: 0; batch classifier loss: 0.311617; batch adversarial loss: 0.526649\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314778; batch adversarial loss: 0.462581\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361265; batch adversarial loss: 0.643676\n",
      "epoch 162; iter: 0; batch classifier loss: 0.292186; batch adversarial loss: 0.497962\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328883; batch adversarial loss: 0.480305\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369679; batch adversarial loss: 0.544619\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334096; batch adversarial loss: 0.600276\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367274; batch adversarial loss: 0.517098\n",
      "epoch 167; iter: 0; batch classifier loss: 0.338194; batch adversarial loss: 0.563578\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380969; batch adversarial loss: 0.499666\n",
      "epoch 169; iter: 0; batch classifier loss: 0.374834; batch adversarial loss: 0.508988\n",
      "epoch 170; iter: 0; batch classifier loss: 0.277858; batch adversarial loss: 0.510174\n",
      "epoch 171; iter: 0; batch classifier loss: 0.360579; batch adversarial loss: 0.554909\n",
      "epoch 172; iter: 0; batch classifier loss: 0.280358; batch adversarial loss: 0.571680\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302649; batch adversarial loss: 0.634679\n",
      "epoch 174; iter: 0; batch classifier loss: 0.330029; batch adversarial loss: 0.482102\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355104; batch adversarial loss: 0.499767\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413105; batch adversarial loss: 0.580299\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306862; batch adversarial loss: 0.598354\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360210; batch adversarial loss: 0.517778\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386502; batch adversarial loss: 0.571538\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334478; batch adversarial loss: 0.526644\n",
      "epoch 181; iter: 0; batch classifier loss: 0.300755; batch adversarial loss: 0.571406\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357995; batch adversarial loss: 0.516991\n",
      "epoch 183; iter: 0; batch classifier loss: 0.407732; batch adversarial loss: 0.480204\n",
      "epoch 184; iter: 0; batch classifier loss: 0.277603; batch adversarial loss: 0.581694\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346611; batch adversarial loss: 0.561684\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358843; batch adversarial loss: 0.544685\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389190; batch adversarial loss: 0.562191\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337734; batch adversarial loss: 0.598849\n",
      "epoch 189; iter: 0; batch classifier loss: 0.373850; batch adversarial loss: 0.518332\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326724; batch adversarial loss: 0.516798\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323097; batch adversarial loss: 0.635823\n",
      "epoch 192; iter: 0; batch classifier loss: 0.292809; batch adversarial loss: 0.626326\n",
      "epoch 193; iter: 0; batch classifier loss: 0.251687; batch adversarial loss: 0.526396\n",
      "epoch 194; iter: 0; batch classifier loss: 0.293383; batch adversarial loss: 0.553065\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349380; batch adversarial loss: 0.590313\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338347; batch adversarial loss: 0.626119\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351971; batch adversarial loss: 0.581362\n",
      "epoch 198; iter: 0; batch classifier loss: 0.297512; batch adversarial loss: 0.517313\n",
      "epoch 199; iter: 0; batch classifier loss: 0.219011; batch adversarial loss: 0.517418\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686369; batch adversarial loss: 1.098191\n",
      "epoch 1; iter: 0; batch classifier loss: 0.877507; batch adversarial loss: 1.368897\n",
      "epoch 2; iter: 0; batch classifier loss: 0.953715; batch adversarial loss: 1.460976\n",
      "epoch 3; iter: 0; batch classifier loss: 1.179336; batch adversarial loss: 1.373320\n",
      "epoch 4; iter: 0; batch classifier loss: 1.280207; batch adversarial loss: 1.274550\n",
      "epoch 5; iter: 0; batch classifier loss: 1.232765; batch adversarial loss: 1.184763\n",
      "epoch 6; iter: 0; batch classifier loss: 1.398151; batch adversarial loss: 1.098314\n",
      "epoch 7; iter: 0; batch classifier loss: 1.283540; batch adversarial loss: 0.994836\n",
      "epoch 8; iter: 0; batch classifier loss: 1.264207; batch adversarial loss: 0.929564\n",
      "epoch 9; iter: 0; batch classifier loss: 1.283741; batch adversarial loss: 0.854656\n",
      "epoch 10; iter: 0; batch classifier loss: 1.254975; batch adversarial loss: 0.799874\n",
      "epoch 11; iter: 0; batch classifier loss: 1.070211; batch adversarial loss: 0.739878\n",
      "epoch 12; iter: 0; batch classifier loss: 1.138256; batch adversarial loss: 0.733924\n",
      "epoch 13; iter: 0; batch classifier loss: 0.909725; batch adversarial loss: 0.675652\n",
      "epoch 14; iter: 0; batch classifier loss: 0.867051; batch adversarial loss: 0.631291\n",
      "epoch 15; iter: 0; batch classifier loss: 0.730596; batch adversarial loss: 0.592603\n",
      "epoch 16; iter: 0; batch classifier loss: 0.606960; batch adversarial loss: 0.563627\n",
      "epoch 17; iter: 0; batch classifier loss: 0.648328; batch adversarial loss: 0.631232\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517049; batch adversarial loss: 0.606201\n",
      "epoch 19; iter: 0; batch classifier loss: 0.582669; batch adversarial loss: 0.591853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.555404; batch adversarial loss: 0.645354\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488809; batch adversarial loss: 0.582968\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512579; batch adversarial loss: 0.501882\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482818; batch adversarial loss: 0.571323\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461866; batch adversarial loss: 0.591406\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457650; batch adversarial loss: 0.564699\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468866; batch adversarial loss: 0.550450\n",
      "epoch 27; iter: 0; batch classifier loss: 0.497237; batch adversarial loss: 0.587356\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486788; batch adversarial loss: 0.570893\n",
      "epoch 29; iter: 0; batch classifier loss: 0.525947; batch adversarial loss: 0.538936\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464643; batch adversarial loss: 0.589926\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456075; batch adversarial loss: 0.489632\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457544; batch adversarial loss: 0.626392\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475662; batch adversarial loss: 0.546650\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406724; batch adversarial loss: 0.609562\n",
      "epoch 35; iter: 0; batch classifier loss: 0.493412; batch adversarial loss: 0.523243\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457701; batch adversarial loss: 0.592216\n",
      "epoch 37; iter: 0; batch classifier loss: 0.531275; batch adversarial loss: 0.485904\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498373; batch adversarial loss: 0.528151\n",
      "epoch 39; iter: 0; batch classifier loss: 0.381538; batch adversarial loss: 0.580566\n",
      "epoch 40; iter: 0; batch classifier loss: 0.489494; batch adversarial loss: 0.509992\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463320; batch adversarial loss: 0.553199\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425308; batch adversarial loss: 0.564786\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433471; batch adversarial loss: 0.503384\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501544; batch adversarial loss: 0.526054\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440171; batch adversarial loss: 0.523582\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425029; batch adversarial loss: 0.609857\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443037; batch adversarial loss: 0.525944\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447071; batch adversarial loss: 0.548388\n",
      "epoch 49; iter: 0; batch classifier loss: 0.368834; batch adversarial loss: 0.593427\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407729; batch adversarial loss: 0.495990\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482558; batch adversarial loss: 0.555395\n",
      "epoch 52; iter: 0; batch classifier loss: 0.483726; batch adversarial loss: 0.454271\n",
      "epoch 53; iter: 0; batch classifier loss: 0.357336; batch adversarial loss: 0.516001\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451317; batch adversarial loss: 0.542392\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462504; batch adversarial loss: 0.533664\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390405; batch adversarial loss: 0.582847\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397950; batch adversarial loss: 0.539773\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410539; batch adversarial loss: 0.526827\n",
      "epoch 59; iter: 0; batch classifier loss: 0.506928; batch adversarial loss: 0.575631\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441950; batch adversarial loss: 0.451480\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458953; batch adversarial loss: 0.591210\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432205; batch adversarial loss: 0.503670\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449128; batch adversarial loss: 0.644094\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424597; batch adversarial loss: 0.604880\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424225; batch adversarial loss: 0.579052\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449418; batch adversarial loss: 0.503222\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381765; batch adversarial loss: 0.515821\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415126; batch adversarial loss: 0.602146\n",
      "epoch 69; iter: 0; batch classifier loss: 0.381345; batch adversarial loss: 0.545833\n",
      "epoch 70; iter: 0; batch classifier loss: 0.355063; batch adversarial loss: 0.472303\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422869; batch adversarial loss: 0.580037\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394335; batch adversarial loss: 0.562645\n",
      "epoch 73; iter: 0; batch classifier loss: 0.353081; batch adversarial loss: 0.560106\n",
      "epoch 74; iter: 0; batch classifier loss: 0.400522; batch adversarial loss: 0.575375\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433275; batch adversarial loss: 0.564093\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420110; batch adversarial loss: 0.488774\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391475; batch adversarial loss: 0.611230\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350104; batch adversarial loss: 0.546573\n",
      "epoch 79; iter: 0; batch classifier loss: 0.350850; batch adversarial loss: 0.536174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370286; batch adversarial loss: 0.564727\n",
      "epoch 81; iter: 0; batch classifier loss: 0.437569; batch adversarial loss: 0.458983\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419695; batch adversarial loss: 0.524354\n",
      "epoch 83; iter: 0; batch classifier loss: 0.445595; batch adversarial loss: 0.597802\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386088; batch adversarial loss: 0.557293\n",
      "epoch 85; iter: 0; batch classifier loss: 0.475659; batch adversarial loss: 0.512827\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344598; batch adversarial loss: 0.536819\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387293; batch adversarial loss: 0.518778\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386725; batch adversarial loss: 0.575590\n",
      "epoch 89; iter: 0; batch classifier loss: 0.346990; batch adversarial loss: 0.589276\n",
      "epoch 90; iter: 0; batch classifier loss: 0.433257; batch adversarial loss: 0.569327\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414839; batch adversarial loss: 0.531837\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404494; batch adversarial loss: 0.560279\n",
      "epoch 93; iter: 0; batch classifier loss: 0.314753; batch adversarial loss: 0.591307\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391748; batch adversarial loss: 0.591951\n",
      "epoch 95; iter: 0; batch classifier loss: 0.383983; batch adversarial loss: 0.594902\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377214; batch adversarial loss: 0.560035\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367543; batch adversarial loss: 0.519845\n",
      "epoch 98; iter: 0; batch classifier loss: 0.414514; batch adversarial loss: 0.585503\n",
      "epoch 99; iter: 0; batch classifier loss: 0.471881; batch adversarial loss: 0.514651\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388666; batch adversarial loss: 0.616958\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390978; batch adversarial loss: 0.559985\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401790; batch adversarial loss: 0.523295\n",
      "epoch 103; iter: 0; batch classifier loss: 0.433961; batch adversarial loss: 0.544699\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384910; batch adversarial loss: 0.613333\n",
      "epoch 105; iter: 0; batch classifier loss: 0.392116; batch adversarial loss: 0.461420\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365888; batch adversarial loss: 0.546701\n",
      "epoch 107; iter: 0; batch classifier loss: 0.439810; batch adversarial loss: 0.589922\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336519; batch adversarial loss: 0.535737\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383929; batch adversarial loss: 0.493501\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344669; batch adversarial loss: 0.551182\n",
      "epoch 111; iter: 0; batch classifier loss: 0.463268; batch adversarial loss: 0.485689\n",
      "epoch 112; iter: 0; batch classifier loss: 0.346136; batch adversarial loss: 0.572075\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378603; batch adversarial loss: 0.563101\n",
      "epoch 114; iter: 0; batch classifier loss: 0.399507; batch adversarial loss: 0.526713\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387584; batch adversarial loss: 0.501876\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346270; batch adversarial loss: 0.502604\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405474; batch adversarial loss: 0.570551\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395521; batch adversarial loss: 0.571405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.371199; batch adversarial loss: 0.507955\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358360; batch adversarial loss: 0.569922\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383543; batch adversarial loss: 0.543731\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335637; batch adversarial loss: 0.560149\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365467; batch adversarial loss: 0.564222\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363816; batch adversarial loss: 0.552565\n",
      "epoch 125; iter: 0; batch classifier loss: 0.406972; batch adversarial loss: 0.504523\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354296; batch adversarial loss: 0.560535\n",
      "epoch 127; iter: 0; batch classifier loss: 0.328736; batch adversarial loss: 0.532142\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383297; batch adversarial loss: 0.517522\n",
      "epoch 129; iter: 0; batch classifier loss: 0.322342; batch adversarial loss: 0.626125\n",
      "epoch 130; iter: 0; batch classifier loss: 0.329329; batch adversarial loss: 0.535105\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361399; batch adversarial loss: 0.607863\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318488; batch adversarial loss: 0.511616\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376760; batch adversarial loss: 0.528181\n",
      "epoch 134; iter: 0; batch classifier loss: 0.347845; batch adversarial loss: 0.552979\n",
      "epoch 135; iter: 0; batch classifier loss: 0.311713; batch adversarial loss: 0.535103\n",
      "epoch 136; iter: 0; batch classifier loss: 0.310592; batch adversarial loss: 0.569649\n",
      "epoch 137; iter: 0; batch classifier loss: 0.306610; batch adversarial loss: 0.497679\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387032; batch adversarial loss: 0.493367\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397447; batch adversarial loss: 0.527681\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396038; batch adversarial loss: 0.619732\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367121; batch adversarial loss: 0.544647\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415056; batch adversarial loss: 0.546684\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337009; batch adversarial loss: 0.491151\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360231; batch adversarial loss: 0.607533\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375885; batch adversarial loss: 0.526084\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339776; batch adversarial loss: 0.554664\n",
      "epoch 147; iter: 0; batch classifier loss: 0.279545; batch adversarial loss: 0.511564\n",
      "epoch 148; iter: 0; batch classifier loss: 0.419774; batch adversarial loss: 0.589348\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315300; batch adversarial loss: 0.499428\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349056; batch adversarial loss: 0.560367\n",
      "epoch 151; iter: 0; batch classifier loss: 0.287471; batch adversarial loss: 0.643060\n",
      "epoch 152; iter: 0; batch classifier loss: 0.334702; batch adversarial loss: 0.596880\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344467; batch adversarial loss: 0.474915\n",
      "epoch 154; iter: 0; batch classifier loss: 0.292105; batch adversarial loss: 0.605390\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340541; batch adversarial loss: 0.570297\n",
      "epoch 156; iter: 0; batch classifier loss: 0.369832; batch adversarial loss: 0.614271\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362923; batch adversarial loss: 0.588829\n",
      "epoch 158; iter: 0; batch classifier loss: 0.415711; batch adversarial loss: 0.571289\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316724; batch adversarial loss: 0.596517\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365118; batch adversarial loss: 0.483598\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408228; batch adversarial loss: 0.561530\n",
      "epoch 162; iter: 0; batch classifier loss: 0.333895; batch adversarial loss: 0.499934\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341765; batch adversarial loss: 0.605323\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340332; batch adversarial loss: 0.581255\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327375; batch adversarial loss: 0.537054\n",
      "epoch 166; iter: 0; batch classifier loss: 0.352530; batch adversarial loss: 0.605839\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323953; batch adversarial loss: 0.562701\n",
      "epoch 168; iter: 0; batch classifier loss: 0.339211; batch adversarial loss: 0.500752\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376491; batch adversarial loss: 0.508776\n",
      "epoch 170; iter: 0; batch classifier loss: 0.280542; batch adversarial loss: 0.607700\n",
      "epoch 171; iter: 0; batch classifier loss: 0.406284; batch adversarial loss: 0.490330\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330245; batch adversarial loss: 0.498098\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364877; batch adversarial loss: 0.510999\n",
      "epoch 174; iter: 0; batch classifier loss: 0.281741; batch adversarial loss: 0.516831\n",
      "epoch 175; iter: 0; batch classifier loss: 0.309816; batch adversarial loss: 0.595894\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344302; batch adversarial loss: 0.561855\n",
      "epoch 177; iter: 0; batch classifier loss: 0.265993; batch adversarial loss: 0.555021\n",
      "epoch 178; iter: 0; batch classifier loss: 0.281283; batch adversarial loss: 0.579257\n",
      "epoch 179; iter: 0; batch classifier loss: 0.309077; batch adversarial loss: 0.542842\n",
      "epoch 180; iter: 0; batch classifier loss: 0.385328; batch adversarial loss: 0.542937\n",
      "epoch 181; iter: 0; batch classifier loss: 0.296317; batch adversarial loss: 0.596286\n",
      "epoch 182; iter: 0; batch classifier loss: 0.308141; batch adversarial loss: 0.633217\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337086; batch adversarial loss: 0.636271\n",
      "epoch 184; iter: 0; batch classifier loss: 0.456041; batch adversarial loss: 0.619403\n",
      "epoch 185; iter: 0; batch classifier loss: 0.272884; batch adversarial loss: 0.474526\n",
      "epoch 186; iter: 0; batch classifier loss: 0.344784; batch adversarial loss: 0.458012\n",
      "epoch 187; iter: 0; batch classifier loss: 0.305481; batch adversarial loss: 0.561690\n",
      "epoch 188; iter: 0; batch classifier loss: 0.273151; batch adversarial loss: 0.473357\n",
      "epoch 189; iter: 0; batch classifier loss: 0.286271; batch adversarial loss: 0.580131\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321290; batch adversarial loss: 0.580029\n",
      "epoch 191; iter: 0; batch classifier loss: 0.353065; batch adversarial loss: 0.564553\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396380; batch adversarial loss: 0.613074\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333884; batch adversarial loss: 0.464839\n",
      "epoch 194; iter: 0; batch classifier loss: 0.306807; batch adversarial loss: 0.598164\n",
      "epoch 195; iter: 0; batch classifier loss: 0.356853; batch adversarial loss: 0.562822\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376914; batch adversarial loss: 0.526189\n",
      "epoch 197; iter: 0; batch classifier loss: 0.218522; batch adversarial loss: 0.598037\n",
      "epoch 198; iter: 0; batch classifier loss: 0.320540; batch adversarial loss: 0.589015\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342674; batch adversarial loss: 0.571104\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726126; batch adversarial loss: 0.911693\n",
      "epoch 1; iter: 0; batch classifier loss: 0.736739; batch adversarial loss: 0.868324\n",
      "epoch 2; iter: 0; batch classifier loss: 0.734478; batch adversarial loss: 0.777602\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569820; batch adversarial loss: 0.769885\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583302; batch adversarial loss: 0.701216\n",
      "epoch 5; iter: 0; batch classifier loss: 0.494401; batch adversarial loss: 0.667098\n",
      "epoch 6; iter: 0; batch classifier loss: 0.477645; batch adversarial loss: 0.637729\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548523; batch adversarial loss: 0.635369\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610921; batch adversarial loss: 0.621557\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557112; batch adversarial loss: 0.585075\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560646; batch adversarial loss: 0.601192\n",
      "epoch 11; iter: 0; batch classifier loss: 0.461415; batch adversarial loss: 0.589081\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518447; batch adversarial loss: 0.585019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547936; batch adversarial loss: 0.564680\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518623; batch adversarial loss: 0.554649\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496898; batch adversarial loss: 0.573947\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487974; batch adversarial loss: 0.575308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.473287; batch adversarial loss: 0.503850\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498833; batch adversarial loss: 0.561678\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541034; batch adversarial loss: 0.544352\n",
      "epoch 20; iter: 0; batch classifier loss: 0.497659; batch adversarial loss: 0.515574\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479873; batch adversarial loss: 0.634910\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480993; batch adversarial loss: 0.516642\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473875; batch adversarial loss: 0.499920\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475396; batch adversarial loss: 0.558993\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476612; batch adversarial loss: 0.547972\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456147; batch adversarial loss: 0.552321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.406305; batch adversarial loss: 0.539854\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469869; batch adversarial loss: 0.515457\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477489; batch adversarial loss: 0.519929\n",
      "epoch 30; iter: 0; batch classifier loss: 0.493204; batch adversarial loss: 0.588153\n",
      "epoch 31; iter: 0; batch classifier loss: 0.545391; batch adversarial loss: 0.569069\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465365; batch adversarial loss: 0.535595\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388083; batch adversarial loss: 0.530007\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449021; batch adversarial loss: 0.522151\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483453; batch adversarial loss: 0.511434\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463725; batch adversarial loss: 0.517150\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445539; batch adversarial loss: 0.493839\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407120; batch adversarial loss: 0.561915\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460003; batch adversarial loss: 0.530880\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474721; batch adversarial loss: 0.540861\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410649; batch adversarial loss: 0.509962\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425057; batch adversarial loss: 0.571745\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429772; batch adversarial loss: 0.527687\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443873; batch adversarial loss: 0.544082\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419207; batch adversarial loss: 0.572983\n",
      "epoch 46; iter: 0; batch classifier loss: 0.314267; batch adversarial loss: 0.554870\n",
      "epoch 47; iter: 0; batch classifier loss: 0.585073; batch adversarial loss: 0.573596\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381458; batch adversarial loss: 0.564814\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457617; batch adversarial loss: 0.518140\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423501; batch adversarial loss: 0.461981\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409370; batch adversarial loss: 0.472578\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380530; batch adversarial loss: 0.508502\n",
      "epoch 53; iter: 0; batch classifier loss: 0.434303; batch adversarial loss: 0.527171\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433775; batch adversarial loss: 0.515363\n",
      "epoch 55; iter: 0; batch classifier loss: 0.364893; batch adversarial loss: 0.516599\n",
      "epoch 56; iter: 0; batch classifier loss: 0.333225; batch adversarial loss: 0.583120\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400962; batch adversarial loss: 0.506615\n",
      "epoch 58; iter: 0; batch classifier loss: 0.382260; batch adversarial loss: 0.589917\n",
      "epoch 59; iter: 0; batch classifier loss: 0.485986; batch adversarial loss: 0.563899\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393853; batch adversarial loss: 0.552927\n",
      "epoch 61; iter: 0; batch classifier loss: 0.364296; batch adversarial loss: 0.525804\n",
      "epoch 62; iter: 0; batch classifier loss: 0.339101; batch adversarial loss: 0.581779\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398369; batch adversarial loss: 0.534229\n",
      "epoch 64; iter: 0; batch classifier loss: 0.351437; batch adversarial loss: 0.544116\n",
      "epoch 65; iter: 0; batch classifier loss: 0.377983; batch adversarial loss: 0.534919\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423963; batch adversarial loss: 0.507464\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431572; batch adversarial loss: 0.536035\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400916; batch adversarial loss: 0.571880\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411932; batch adversarial loss: 0.496039\n",
      "epoch 70; iter: 0; batch classifier loss: 0.325708; batch adversarial loss: 0.488679\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358299; batch adversarial loss: 0.478704\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385311; batch adversarial loss: 0.629663\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428969; batch adversarial loss: 0.525712\n",
      "epoch 74; iter: 0; batch classifier loss: 0.403150; batch adversarial loss: 0.516014\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418715; batch adversarial loss: 0.507278\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366280; batch adversarial loss: 0.609745\n",
      "epoch 77; iter: 0; batch classifier loss: 0.361937; batch adversarial loss: 0.460066\n",
      "epoch 78; iter: 0; batch classifier loss: 0.317856; batch adversarial loss: 0.515997\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430768; batch adversarial loss: 0.544355\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356048; batch adversarial loss: 0.562745\n",
      "epoch 81; iter: 0; batch classifier loss: 0.345944; batch adversarial loss: 0.497418\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408731; batch adversarial loss: 0.601298\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401496; batch adversarial loss: 0.459239\n",
      "epoch 84; iter: 0; batch classifier loss: 0.385931; batch adversarial loss: 0.516077\n",
      "epoch 85; iter: 0; batch classifier loss: 0.511007; batch adversarial loss: 0.554219\n",
      "epoch 86; iter: 0; batch classifier loss: 0.472520; batch adversarial loss: 0.553183\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369092; batch adversarial loss: 0.526207\n",
      "epoch 88; iter: 0; batch classifier loss: 0.353235; batch adversarial loss: 0.534484\n",
      "epoch 89; iter: 0; batch classifier loss: 0.346960; batch adversarial loss: 0.572986\n",
      "epoch 90; iter: 0; batch classifier loss: 0.377098; batch adversarial loss: 0.525161\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421930; batch adversarial loss: 0.535525\n",
      "epoch 92; iter: 0; batch classifier loss: 0.401358; batch adversarial loss: 0.553376\n",
      "epoch 93; iter: 0; batch classifier loss: 0.325971; batch adversarial loss: 0.535425\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414875; batch adversarial loss: 0.507199\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425948; batch adversarial loss: 0.591509\n",
      "epoch 96; iter: 0; batch classifier loss: 0.298218; batch adversarial loss: 0.544068\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382198; batch adversarial loss: 0.544481\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380083; batch adversarial loss: 0.544337\n",
      "epoch 99; iter: 0; batch classifier loss: 0.347406; batch adversarial loss: 0.620434\n",
      "epoch 100; iter: 0; batch classifier loss: 0.505537; batch adversarial loss: 0.516923\n",
      "epoch 101; iter: 0; batch classifier loss: 0.423017; batch adversarial loss: 0.582742\n",
      "epoch 102; iter: 0; batch classifier loss: 0.317621; batch adversarial loss: 0.573443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386345; batch adversarial loss: 0.526370\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365369; batch adversarial loss: 0.563469\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355131; batch adversarial loss: 0.469428\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359643; batch adversarial loss: 0.564130\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382413; batch adversarial loss: 0.469244\n",
      "epoch 108; iter: 0; batch classifier loss: 0.344454; batch adversarial loss: 0.497275\n",
      "epoch 109; iter: 0; batch classifier loss: 0.481908; batch adversarial loss: 0.535020\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353781; batch adversarial loss: 0.478758\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393208; batch adversarial loss: 0.525353\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398883; batch adversarial loss: 0.478079\n",
      "epoch 113; iter: 0; batch classifier loss: 0.327966; batch adversarial loss: 0.648241\n",
      "epoch 114; iter: 0; batch classifier loss: 0.427729; batch adversarial loss: 0.477859\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341396; batch adversarial loss: 0.591935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.466050; batch adversarial loss: 0.563708\n",
      "epoch 117; iter: 0; batch classifier loss: 0.361712; batch adversarial loss: 0.553511\n",
      "epoch 118; iter: 0; batch classifier loss: 0.408168; batch adversarial loss: 0.487893\n",
      "epoch 119; iter: 0; batch classifier loss: 0.459852; batch adversarial loss: 0.573402\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328327; batch adversarial loss: 0.487671\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419649; batch adversarial loss: 0.516095\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345277; batch adversarial loss: 0.553645\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343268; batch adversarial loss: 0.544659\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391304; batch adversarial loss: 0.544977\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369807; batch adversarial loss: 0.619787\n",
      "epoch 126; iter: 0; batch classifier loss: 0.473015; batch adversarial loss: 0.526111\n",
      "epoch 127; iter: 0; batch classifier loss: 0.345221; batch adversarial loss: 0.573067\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396344; batch adversarial loss: 0.497262\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380336; batch adversarial loss: 0.553737\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345458; batch adversarial loss: 0.581102\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371250; batch adversarial loss: 0.554250\n",
      "epoch 132; iter: 0; batch classifier loss: 0.288749; batch adversarial loss: 0.563792\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356498; batch adversarial loss: 0.535381\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402221; batch adversarial loss: 0.629546\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385349; batch adversarial loss: 0.496081\n",
      "epoch 136; iter: 0; batch classifier loss: 0.321435; batch adversarial loss: 0.534596\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353418; batch adversarial loss: 0.590620\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404649; batch adversarial loss: 0.581920\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389344; batch adversarial loss: 0.422635\n",
      "epoch 140; iter: 0; batch classifier loss: 0.344104; batch adversarial loss: 0.573177\n",
      "epoch 141; iter: 0; batch classifier loss: 0.376014; batch adversarial loss: 0.609942\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379186; batch adversarial loss: 0.479082\n",
      "epoch 143; iter: 0; batch classifier loss: 0.387333; batch adversarial loss: 0.515688\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388069; batch adversarial loss: 0.526146\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333492; batch adversarial loss: 0.496969\n",
      "epoch 146; iter: 0; batch classifier loss: 0.314595; batch adversarial loss: 0.582570\n",
      "epoch 147; iter: 0; batch classifier loss: 0.367906; batch adversarial loss: 0.582555\n",
      "epoch 148; iter: 0; batch classifier loss: 0.419540; batch adversarial loss: 0.487321\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379501; batch adversarial loss: 0.564224\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384693; batch adversarial loss: 0.497305\n",
      "epoch 151; iter: 0; batch classifier loss: 0.309132; batch adversarial loss: 0.487931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387965; batch adversarial loss: 0.582461\n",
      "epoch 153; iter: 0; batch classifier loss: 0.313751; batch adversarial loss: 0.553527\n",
      "epoch 154; iter: 0; batch classifier loss: 0.341434; batch adversarial loss: 0.545028\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323024; batch adversarial loss: 0.497054\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332093; batch adversarial loss: 0.516577\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333105; batch adversarial loss: 0.506498\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370763; batch adversarial loss: 0.554138\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346370; batch adversarial loss: 0.431652\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372438; batch adversarial loss: 0.600811\n",
      "epoch 161; iter: 0; batch classifier loss: 0.336815; batch adversarial loss: 0.535070\n",
      "epoch 162; iter: 0; batch classifier loss: 0.341058; batch adversarial loss: 0.460124\n",
      "epoch 163; iter: 0; batch classifier loss: 0.317626; batch adversarial loss: 0.571817\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342519; batch adversarial loss: 0.525509\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365561; batch adversarial loss: 0.515844\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361242; batch adversarial loss: 0.572876\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342582; batch adversarial loss: 0.562705\n",
      "epoch 168; iter: 0; batch classifier loss: 0.524886; batch adversarial loss: 0.563631\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362180; batch adversarial loss: 0.515724\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319739; batch adversarial loss: 0.535497\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389543; batch adversarial loss: 0.582029\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370702; batch adversarial loss: 0.544325\n",
      "epoch 173; iter: 0; batch classifier loss: 0.282569; batch adversarial loss: 0.572844\n",
      "epoch 174; iter: 0; batch classifier loss: 0.536865; batch adversarial loss: 0.506528\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351091; batch adversarial loss: 0.553550\n",
      "epoch 176; iter: 0; batch classifier loss: 0.333565; batch adversarial loss: 0.543712\n",
      "epoch 177; iter: 0; batch classifier loss: 0.348540; batch adversarial loss: 0.573447\n",
      "epoch 178; iter: 0; batch classifier loss: 0.293245; batch adversarial loss: 0.525610\n",
      "epoch 179; iter: 0; batch classifier loss: 0.404131; batch adversarial loss: 0.516012\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378772; batch adversarial loss: 0.572312\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314780; batch adversarial loss: 0.590797\n",
      "epoch 182; iter: 0; batch classifier loss: 0.315687; batch adversarial loss: 0.506740\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370368; batch adversarial loss: 0.544236\n",
      "epoch 184; iter: 0; batch classifier loss: 0.396924; batch adversarial loss: 0.592037\n",
      "epoch 185; iter: 0; batch classifier loss: 0.345731; batch adversarial loss: 0.459497\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383112; batch adversarial loss: 0.535012\n",
      "epoch 187; iter: 0; batch classifier loss: 0.315292; batch adversarial loss: 0.553549\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361195; batch adversarial loss: 0.564011\n",
      "epoch 189; iter: 0; batch classifier loss: 0.401114; batch adversarial loss: 0.516321\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328031; batch adversarial loss: 0.496848\n",
      "epoch 191; iter: 0; batch classifier loss: 0.333768; batch adversarial loss: 0.544481\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398447; batch adversarial loss: 0.469076\n",
      "epoch 193; iter: 0; batch classifier loss: 0.369751; batch adversarial loss: 0.517329\n",
      "epoch 194; iter: 0; batch classifier loss: 0.302529; batch adversarial loss: 0.600952\n",
      "epoch 195; iter: 0; batch classifier loss: 0.406298; batch adversarial loss: 0.497773\n",
      "epoch 196; iter: 0; batch classifier loss: 0.275994; batch adversarial loss: 0.562684\n",
      "epoch 197; iter: 0; batch classifier loss: 0.383636; batch adversarial loss: 0.516465\n",
      "epoch 198; iter: 0; batch classifier loss: 0.415631; batch adversarial loss: 0.544320\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319757; batch adversarial loss: 0.543866\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665276; batch adversarial loss: 0.684348\n",
      "epoch 1; iter: 0; batch classifier loss: 0.650231; batch adversarial loss: 0.668928\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582884; batch adversarial loss: 0.665980\n",
      "epoch 3; iter: 0; batch classifier loss: 0.600944; batch adversarial loss: 0.643071\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529664; batch adversarial loss: 0.625405\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531682; batch adversarial loss: 0.654066\n",
      "epoch 6; iter: 0; batch classifier loss: 0.474610; batch adversarial loss: 0.641606\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559486; batch adversarial loss: 0.572121\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495456; batch adversarial loss: 0.612817\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558698; batch adversarial loss: 0.577715\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519991; batch adversarial loss: 0.578531\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538125; batch adversarial loss: 0.581636\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512615; batch adversarial loss: 0.534366\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507833; batch adversarial loss: 0.560286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.457892; batch adversarial loss: 0.593443\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488721; batch adversarial loss: 0.510706\n",
      "epoch 16; iter: 0; batch classifier loss: 0.463795; batch adversarial loss: 0.505234\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485511; batch adversarial loss: 0.527402\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534411; batch adversarial loss: 0.519857\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516143; batch adversarial loss: 0.509809\n",
      "epoch 20; iter: 0; batch classifier loss: 0.563381; batch adversarial loss: 0.529034\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499308; batch adversarial loss: 0.477320\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525111; batch adversarial loss: 0.572569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506648; batch adversarial loss: 0.551923\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512658; batch adversarial loss: 0.554436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.548825; batch adversarial loss: 0.534065\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517517; batch adversarial loss: 0.570966\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491765; batch adversarial loss: 0.503138\n",
      "epoch 28; iter: 0; batch classifier loss: 0.505145; batch adversarial loss: 0.462512\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504956; batch adversarial loss: 0.541743\n",
      "epoch 30; iter: 0; batch classifier loss: 0.528843; batch adversarial loss: 0.508024\n",
      "epoch 31; iter: 0; batch classifier loss: 0.405418; batch adversarial loss: 0.602044\n",
      "epoch 32; iter: 0; batch classifier loss: 0.393340; batch adversarial loss: 0.540655\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440198; batch adversarial loss: 0.527957\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464148; batch adversarial loss: 0.577614\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465540; batch adversarial loss: 0.502238\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440369; batch adversarial loss: 0.588930\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456756; batch adversarial loss: 0.517386\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471760; batch adversarial loss: 0.498714\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434929; batch adversarial loss: 0.536449\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455891; batch adversarial loss: 0.522136\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428790; batch adversarial loss: 0.588980\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389641; batch adversarial loss: 0.536568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414042; batch adversarial loss: 0.479220\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393673; batch adversarial loss: 0.535655\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401064; batch adversarial loss: 0.629999\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398325; batch adversarial loss: 0.508049\n",
      "epoch 47; iter: 0; batch classifier loss: 0.361145; batch adversarial loss: 0.561591\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406628; batch adversarial loss: 0.527133\n",
      "epoch 49; iter: 0; batch classifier loss: 0.350702; batch adversarial loss: 0.497829\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403240; batch adversarial loss: 0.535188\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469917; batch adversarial loss: 0.535569\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414921; batch adversarial loss: 0.524885\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425519; batch adversarial loss: 0.554782\n",
      "epoch 54; iter: 0; batch classifier loss: 0.341659; batch adversarial loss: 0.507781\n",
      "epoch 55; iter: 0; batch classifier loss: 0.492343; batch adversarial loss: 0.546079\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427230; batch adversarial loss: 0.517516\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456763; batch adversarial loss: 0.496500\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423396; batch adversarial loss: 0.571750\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398023; batch adversarial loss: 0.527779\n",
      "epoch 60; iter: 0; batch classifier loss: 0.449720; batch adversarial loss: 0.561220\n",
      "epoch 61; iter: 0; batch classifier loss: 0.354614; batch adversarial loss: 0.462762\n",
      "epoch 62; iter: 0; batch classifier loss: 0.352263; batch adversarial loss: 0.574050\n",
      "epoch 63; iter: 0; batch classifier loss: 0.372436; batch adversarial loss: 0.590833\n",
      "epoch 64; iter: 0; batch classifier loss: 0.350689; batch adversarial loss: 0.498483\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398350; batch adversarial loss: 0.489793\n",
      "epoch 66; iter: 0; batch classifier loss: 0.501845; batch adversarial loss: 0.553061\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412739; batch adversarial loss: 0.535803\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400100; batch adversarial loss: 0.573338\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366963; batch adversarial loss: 0.552240\n",
      "epoch 70; iter: 0; batch classifier loss: 0.341812; batch adversarial loss: 0.644768\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403331; batch adversarial loss: 0.489305\n",
      "epoch 72; iter: 0; batch classifier loss: 0.443435; batch adversarial loss: 0.563545\n",
      "epoch 73; iter: 0; batch classifier loss: 0.363301; batch adversarial loss: 0.543021\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414639; batch adversarial loss: 0.582321\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364995; batch adversarial loss: 0.636825\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335503; batch adversarial loss: 0.571585\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426727; batch adversarial loss: 0.518250\n",
      "epoch 78; iter: 0; batch classifier loss: 0.465684; batch adversarial loss: 0.591772\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391944; batch adversarial loss: 0.535866\n",
      "epoch 80; iter: 0; batch classifier loss: 0.397677; batch adversarial loss: 0.543155\n",
      "epoch 81; iter: 0; batch classifier loss: 0.349396; batch adversarial loss: 0.489129\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396937; batch adversarial loss: 0.617147\n",
      "epoch 83; iter: 0; batch classifier loss: 0.435585; batch adversarial loss: 0.526402\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354935; batch adversarial loss: 0.479211\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343939; batch adversarial loss: 0.525945\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415870; batch adversarial loss: 0.525895\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428164; batch adversarial loss: 0.609249\n",
      "epoch 88; iter: 0; batch classifier loss: 0.469757; batch adversarial loss: 0.526780\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334677; batch adversarial loss: 0.498472\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392430; batch adversarial loss: 0.471267\n",
      "epoch 91; iter: 0; batch classifier loss: 0.337551; batch adversarial loss: 0.636078\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403315; batch adversarial loss: 0.544671\n",
      "epoch 93; iter: 0; batch classifier loss: 0.446111; batch adversarial loss: 0.535785\n",
      "epoch 94; iter: 0; batch classifier loss: 0.427990; batch adversarial loss: 0.517380\n",
      "epoch 95; iter: 0; batch classifier loss: 0.302075; batch adversarial loss: 0.617801\n",
      "epoch 96; iter: 0; batch classifier loss: 0.354159; batch adversarial loss: 0.461337\n",
      "epoch 97; iter: 0; batch classifier loss: 0.353109; batch adversarial loss: 0.526575\n",
      "epoch 98; iter: 0; batch classifier loss: 0.433194; batch adversarial loss: 0.552187\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410027; batch adversarial loss: 0.619885\n",
      "epoch 100; iter: 0; batch classifier loss: 0.305844; batch adversarial loss: 0.525884\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408667; batch adversarial loss: 0.562404\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399446; batch adversarial loss: 0.571967\n",
      "epoch 103; iter: 0; batch classifier loss: 0.431704; batch adversarial loss: 0.526245\n",
      "epoch 104; iter: 0; batch classifier loss: 0.516412; batch adversarial loss: 0.506848\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388695; batch adversarial loss: 0.534586\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369814; batch adversarial loss: 0.461346\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407153; batch adversarial loss: 0.546299\n",
      "epoch 108; iter: 0; batch classifier loss: 0.376197; batch adversarial loss: 0.545360\n",
      "epoch 109; iter: 0; batch classifier loss: 0.316986; batch adversarial loss: 0.580529\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384946; batch adversarial loss: 0.589966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367996; batch adversarial loss: 0.562839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.389514; batch adversarial loss: 0.553984\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369978; batch adversarial loss: 0.535556\n",
      "epoch 114; iter: 0; batch classifier loss: 0.356856; batch adversarial loss: 0.535459\n",
      "epoch 115; iter: 0; batch classifier loss: 0.313840; batch adversarial loss: 0.480332\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382845; batch adversarial loss: 0.636563\n",
      "epoch 117; iter: 0; batch classifier loss: 0.434130; batch adversarial loss: 0.562581\n",
      "epoch 118; iter: 0; batch classifier loss: 0.414455; batch adversarial loss: 0.499469\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392106; batch adversarial loss: 0.562912\n",
      "epoch 120; iter: 0; batch classifier loss: 0.321294; batch adversarial loss: 0.571542\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379541; batch adversarial loss: 0.562864\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343207; batch adversarial loss: 0.490125\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408845; batch adversarial loss: 0.562939\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387941; batch adversarial loss: 0.508014\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397041; batch adversarial loss: 0.543791\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390267; batch adversarial loss: 0.572270\n",
      "epoch 127; iter: 0; batch classifier loss: 0.460818; batch adversarial loss: 0.544965\n",
      "epoch 128; iter: 0; batch classifier loss: 0.434945; batch adversarial loss: 0.572069\n",
      "epoch 129; iter: 0; batch classifier loss: 0.437951; batch adversarial loss: 0.498423\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390150; batch adversarial loss: 0.508226\n",
      "epoch 131; iter: 0; batch classifier loss: 0.304175; batch adversarial loss: 0.553845\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353325; batch adversarial loss: 0.589730\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367995; batch adversarial loss: 0.581506\n",
      "epoch 134; iter: 0; batch classifier loss: 0.280894; batch adversarial loss: 0.534962\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341930; batch adversarial loss: 0.535309\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354494; batch adversarial loss: 0.471262\n",
      "epoch 137; iter: 0; batch classifier loss: 0.360857; batch adversarial loss: 0.645746\n",
      "epoch 138; iter: 0; batch classifier loss: 0.300431; batch adversarial loss: 0.517209\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346545; batch adversarial loss: 0.497853\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391510; batch adversarial loss: 0.627692\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386639; batch adversarial loss: 0.526975\n",
      "epoch 142; iter: 0; batch classifier loss: 0.342904; batch adversarial loss: 0.636587\n",
      "epoch 143; iter: 0; batch classifier loss: 0.430625; batch adversarial loss: 0.599968\n",
      "epoch 144; iter: 0; batch classifier loss: 0.313493; batch adversarial loss: 0.590564\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362292; batch adversarial loss: 0.581482\n",
      "epoch 146; iter: 0; batch classifier loss: 0.403989; batch adversarial loss: 0.452160\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351933; batch adversarial loss: 0.581624\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370790; batch adversarial loss: 0.480303\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400743; batch adversarial loss: 0.553932\n",
      "epoch 150; iter: 0; batch classifier loss: 0.430563; batch adversarial loss: 0.608254\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364450; batch adversarial loss: 0.516473\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335356; batch adversarial loss: 0.508191\n",
      "epoch 153; iter: 0; batch classifier loss: 0.311149; batch adversarial loss: 0.480297\n",
      "epoch 154; iter: 0; batch classifier loss: 0.432094; batch adversarial loss: 0.544022\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341466; batch adversarial loss: 0.516503\n",
      "epoch 156; iter: 0; batch classifier loss: 0.424621; batch adversarial loss: 0.507351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313274; batch adversarial loss: 0.497885\n",
      "epoch 158; iter: 0; batch classifier loss: 0.416121; batch adversarial loss: 0.480219\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349573; batch adversarial loss: 0.580762\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350087; batch adversarial loss: 0.498197\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369244; batch adversarial loss: 0.498116\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365383; batch adversarial loss: 0.517075\n",
      "epoch 163; iter: 0; batch classifier loss: 0.304761; batch adversarial loss: 0.516822\n",
      "epoch 164; iter: 0; batch classifier loss: 0.384607; batch adversarial loss: 0.590092\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348073; batch adversarial loss: 0.608609\n",
      "epoch 166; iter: 0; batch classifier loss: 0.336270; batch adversarial loss: 0.479415\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371827; batch adversarial loss: 0.571481\n",
      "epoch 168; iter: 0; batch classifier loss: 0.350344; batch adversarial loss: 0.489471\n",
      "epoch 169; iter: 0; batch classifier loss: 0.406589; batch adversarial loss: 0.498309\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345290; batch adversarial loss: 0.590060\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340396; batch adversarial loss: 0.581432\n",
      "epoch 172; iter: 0; batch classifier loss: 0.420363; batch adversarial loss: 0.572324\n",
      "epoch 173; iter: 0; batch classifier loss: 0.297656; batch adversarial loss: 0.554601\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353870; batch adversarial loss: 0.545155\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329436; batch adversarial loss: 0.562350\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338638; batch adversarial loss: 0.470879\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312686; batch adversarial loss: 0.600629\n",
      "epoch 178; iter: 0; batch classifier loss: 0.412241; batch adversarial loss: 0.608923\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343073; batch adversarial loss: 0.544679\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327209; batch adversarial loss: 0.480580\n",
      "epoch 181; iter: 0; batch classifier loss: 0.401118; batch adversarial loss: 0.544071\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338359; batch adversarial loss: 0.526023\n",
      "epoch 183; iter: 0; batch classifier loss: 0.449903; batch adversarial loss: 0.562736\n",
      "epoch 184; iter: 0; batch classifier loss: 0.340269; batch adversarial loss: 0.619104\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371658; batch adversarial loss: 0.562609\n",
      "epoch 186; iter: 0; batch classifier loss: 0.345464; batch adversarial loss: 0.563151\n",
      "epoch 187; iter: 0; batch classifier loss: 0.304492; batch adversarial loss: 0.526453\n",
      "epoch 188; iter: 0; batch classifier loss: 0.340030; batch adversarial loss: 0.599230\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414640; batch adversarial loss: 0.525577\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368936; batch adversarial loss: 0.554304\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392848; batch adversarial loss: 0.553572\n",
      "epoch 192; iter: 0; batch classifier loss: 0.312598; batch adversarial loss: 0.608756\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332999; batch adversarial loss: 0.525383\n",
      "epoch 194; iter: 0; batch classifier loss: 0.307067; batch adversarial loss: 0.489135\n",
      "epoch 195; iter: 0; batch classifier loss: 0.348951; batch adversarial loss: 0.581107\n",
      "epoch 196; iter: 0; batch classifier loss: 0.412375; batch adversarial loss: 0.508259\n",
      "epoch 197; iter: 0; batch classifier loss: 0.406716; batch adversarial loss: 0.581579\n",
      "epoch 198; iter: 0; batch classifier loss: 0.380718; batch adversarial loss: 0.526373\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359704; batch adversarial loss: 0.572036\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668701; batch adversarial loss: 0.651708\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647874; batch adversarial loss: 0.682701\n",
      "epoch 2; iter: 0; batch classifier loss: 0.538282; batch adversarial loss: 0.638007\n",
      "epoch 3; iter: 0; batch classifier loss: 0.635151; batch adversarial loss: 0.642995\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572742; batch adversarial loss: 0.620067\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583361; batch adversarial loss: 0.624186\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563133; batch adversarial loss: 0.606275\n",
      "epoch 7; iter: 0; batch classifier loss: 0.576644; batch adversarial loss: 0.606908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.555357; batch adversarial loss: 0.624204\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526599; batch adversarial loss: 0.637958\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498284; batch adversarial loss: 0.615203\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553998; batch adversarial loss: 0.565210\n",
      "epoch 12; iter: 0; batch classifier loss: 0.466572; batch adversarial loss: 0.603195\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477615; batch adversarial loss: 0.534284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526197; batch adversarial loss: 0.599793\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492482; batch adversarial loss: 0.610224\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480303; batch adversarial loss: 0.497857\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505787; batch adversarial loss: 0.555025\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489436; batch adversarial loss: 0.560620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.577371; batch adversarial loss: 0.596060\n",
      "epoch 20; iter: 0; batch classifier loss: 0.564865; batch adversarial loss: 0.528180\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510905; batch adversarial loss: 0.523511\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479263; batch adversarial loss: 0.628859\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461487; batch adversarial loss: 0.548624\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492145; batch adversarial loss: 0.506418\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508938; batch adversarial loss: 0.492621\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475834; batch adversarial loss: 0.597092\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414701; batch adversarial loss: 0.588731\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432513; batch adversarial loss: 0.587205\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428985; batch adversarial loss: 0.604616\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480392; batch adversarial loss: 0.521211\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456634; batch adversarial loss: 0.537404\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467750; batch adversarial loss: 0.579821\n",
      "epoch 33; iter: 0; batch classifier loss: 0.496362; batch adversarial loss: 0.629849\n",
      "epoch 34; iter: 0; batch classifier loss: 0.465988; batch adversarial loss: 0.570833\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420099; batch adversarial loss: 0.528520\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430418; batch adversarial loss: 0.502658\n",
      "epoch 37; iter: 0; batch classifier loss: 0.522594; batch adversarial loss: 0.570883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465057; batch adversarial loss: 0.545140\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405156; batch adversarial loss: 0.501679\n",
      "epoch 40; iter: 0; batch classifier loss: 0.381983; batch adversarial loss: 0.501488\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467788; batch adversarial loss: 0.536597\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405284; batch adversarial loss: 0.597267\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471456; batch adversarial loss: 0.579885\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466235; batch adversarial loss: 0.518859\n",
      "epoch 45; iter: 0; batch classifier loss: 0.507687; batch adversarial loss: 0.518861\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419779; batch adversarial loss: 0.606431\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370619; batch adversarial loss: 0.588422\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455485; batch adversarial loss: 0.544975\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476743; batch adversarial loss: 0.569802\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458278; batch adversarial loss: 0.570656\n",
      "epoch 51; iter: 0; batch classifier loss: 0.386781; batch adversarial loss: 0.605591\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426420; batch adversarial loss: 0.528154\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458465; batch adversarial loss: 0.544631\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440685; batch adversarial loss: 0.570140\n",
      "epoch 55; iter: 0; batch classifier loss: 0.333482; batch adversarial loss: 0.563777\n",
      "epoch 56; iter: 0; batch classifier loss: 0.483607; batch adversarial loss: 0.615903\n",
      "epoch 57; iter: 0; batch classifier loss: 0.449685; batch adversarial loss: 0.519023\n",
      "epoch 58; iter: 0; batch classifier loss: 0.473879; batch adversarial loss: 0.526330\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444707; batch adversarial loss: 0.526225\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381448; batch adversarial loss: 0.607379\n",
      "epoch 61; iter: 0; batch classifier loss: 0.505946; batch adversarial loss: 0.510230\n",
      "epoch 62; iter: 0; batch classifier loss: 0.464628; batch adversarial loss: 0.499396\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435331; batch adversarial loss: 0.527430\n",
      "epoch 64; iter: 0; batch classifier loss: 0.519699; batch adversarial loss: 0.598191\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449964; batch adversarial loss: 0.650292\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429708; batch adversarial loss: 0.516611\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412471; batch adversarial loss: 0.544879\n",
      "epoch 68; iter: 0; batch classifier loss: 0.398887; batch adversarial loss: 0.501657\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432985; batch adversarial loss: 0.616028\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446954; batch adversarial loss: 0.580252\n",
      "epoch 71; iter: 0; batch classifier loss: 0.339258; batch adversarial loss: 0.473612\n",
      "epoch 72; iter: 0; batch classifier loss: 0.363153; batch adversarial loss: 0.527899\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411226; batch adversarial loss: 0.529225\n",
      "epoch 74; iter: 0; batch classifier loss: 0.466955; batch adversarial loss: 0.546364\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375195; batch adversarial loss: 0.528314\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406423; batch adversarial loss: 0.553561\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433224; batch adversarial loss: 0.491190\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391789; batch adversarial loss: 0.552185\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391118; batch adversarial loss: 0.517048\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423615; batch adversarial loss: 0.596726\n",
      "epoch 81; iter: 0; batch classifier loss: 0.460864; batch adversarial loss: 0.508949\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408220; batch adversarial loss: 0.551876\n",
      "epoch 83; iter: 0; batch classifier loss: 0.333197; batch adversarial loss: 0.545552\n",
      "epoch 84; iter: 0; batch classifier loss: 0.434467; batch adversarial loss: 0.545516\n",
      "epoch 85; iter: 0; batch classifier loss: 0.372379; batch adversarial loss: 0.499757\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433527; batch adversarial loss: 0.631972\n",
      "epoch 87; iter: 0; batch classifier loss: 0.312762; batch adversarial loss: 0.544787\n",
      "epoch 88; iter: 0; batch classifier loss: 0.346548; batch adversarial loss: 0.568410\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400718; batch adversarial loss: 0.553676\n",
      "epoch 90; iter: 0; batch classifier loss: 0.315853; batch adversarial loss: 0.475808\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400092; batch adversarial loss: 0.570549\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385525; batch adversarial loss: 0.560945\n",
      "epoch 93; iter: 0; batch classifier loss: 0.493961; batch adversarial loss: 0.544782\n",
      "epoch 94; iter: 0; batch classifier loss: 0.438677; batch adversarial loss: 0.518806\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394538; batch adversarial loss: 0.501077\n",
      "epoch 96; iter: 0; batch classifier loss: 0.412702; batch adversarial loss: 0.552333\n",
      "epoch 97; iter: 0; batch classifier loss: 0.424056; batch adversarial loss: 0.568825\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359606; batch adversarial loss: 0.553239\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341645; batch adversarial loss: 0.545908\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402762; batch adversarial loss: 0.607944\n",
      "epoch 101; iter: 0; batch classifier loss: 0.348536; batch adversarial loss: 0.630839\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402137; batch adversarial loss: 0.560473\n",
      "epoch 103; iter: 0; batch classifier loss: 0.450725; batch adversarial loss: 0.668400\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389275; batch adversarial loss: 0.537478\n",
      "epoch 105; iter: 0; batch classifier loss: 0.436289; batch adversarial loss: 0.562752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.365759; batch adversarial loss: 0.519667\n",
      "epoch 107; iter: 0; batch classifier loss: 0.390162; batch adversarial loss: 0.598264\n",
      "epoch 108; iter: 0; batch classifier loss: 0.470999; batch adversarial loss: 0.536470\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384783; batch adversarial loss: 0.595078\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344172; batch adversarial loss: 0.537228\n",
      "epoch 111; iter: 0; batch classifier loss: 0.323774; batch adversarial loss: 0.536310\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405325; batch adversarial loss: 0.578694\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373849; batch adversarial loss: 0.502658\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393201; batch adversarial loss: 0.526776\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332187; batch adversarial loss: 0.597622\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398442; batch adversarial loss: 0.579283\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342825; batch adversarial loss: 0.510301\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366507; batch adversarial loss: 0.571220\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374458; batch adversarial loss: 0.554131\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399000; batch adversarial loss: 0.577936\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335976; batch adversarial loss: 0.633504\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343711; batch adversarial loss: 0.562773\n",
      "epoch 123; iter: 0; batch classifier loss: 0.451927; batch adversarial loss: 0.553933\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359766; batch adversarial loss: 0.559604\n",
      "epoch 125; iter: 0; batch classifier loss: 0.354748; batch adversarial loss: 0.544054\n",
      "epoch 126; iter: 0; batch classifier loss: 0.407512; batch adversarial loss: 0.536784\n",
      "epoch 127; iter: 0; batch classifier loss: 0.423040; batch adversarial loss: 0.494810\n",
      "epoch 128; iter: 0; batch classifier loss: 0.425399; batch adversarial loss: 0.474711\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394745; batch adversarial loss: 0.517714\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389917; batch adversarial loss: 0.581003\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356246; batch adversarial loss: 0.501614\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319243; batch adversarial loss: 0.537323\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356813; batch adversarial loss: 0.570856\n",
      "epoch 134; iter: 0; batch classifier loss: 0.440552; batch adversarial loss: 0.545633\n",
      "epoch 135; iter: 0; batch classifier loss: 0.448164; batch adversarial loss: 0.580550\n",
      "epoch 136; iter: 0; batch classifier loss: 0.430445; batch adversarial loss: 0.563244\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341226; batch adversarial loss: 0.668798\n",
      "epoch 138; iter: 0; batch classifier loss: 0.446946; batch adversarial loss: 0.517368\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341327; batch adversarial loss: 0.552841\n",
      "epoch 140; iter: 0; batch classifier loss: 0.411999; batch adversarial loss: 0.632217\n",
      "epoch 141; iter: 0; batch classifier loss: 0.401307; batch adversarial loss: 0.552440\n",
      "epoch 142; iter: 0; batch classifier loss: 0.425773; batch adversarial loss: 0.624375\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383923; batch adversarial loss: 0.625510\n",
      "epoch 144; iter: 0; batch classifier loss: 0.321881; batch adversarial loss: 0.570165\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363337; batch adversarial loss: 0.527153\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357735; batch adversarial loss: 0.586287\n",
      "epoch 147; iter: 0; batch classifier loss: 0.449481; batch adversarial loss: 0.595037\n",
      "epoch 148; iter: 0; batch classifier loss: 0.404671; batch adversarial loss: 0.518374\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350071; batch adversarial loss: 0.519211\n",
      "epoch 150; iter: 0; batch classifier loss: 0.398250; batch adversarial loss: 0.606361\n",
      "epoch 151; iter: 0; batch classifier loss: 0.418241; batch adversarial loss: 0.500185\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383763; batch adversarial loss: 0.562695\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335353; batch adversarial loss: 0.535783\n",
      "epoch 154; iter: 0; batch classifier loss: 0.415481; batch adversarial loss: 0.543450\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366761; batch adversarial loss: 0.509222\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396659; batch adversarial loss: 0.475251\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362877; batch adversarial loss: 0.527576\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334275; batch adversarial loss: 0.571906\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377047; batch adversarial loss: 0.544739\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369643; batch adversarial loss: 0.472124\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392563; batch adversarial loss: 0.640880\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368460; batch adversarial loss: 0.484446\n",
      "epoch 163; iter: 0; batch classifier loss: 0.439518; batch adversarial loss: 0.535920\n",
      "epoch 164; iter: 0; batch classifier loss: 0.417851; batch adversarial loss: 0.536376\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327981; batch adversarial loss: 0.484871\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301406; batch adversarial loss: 0.483781\n",
      "epoch 167; iter: 0; batch classifier loss: 0.410562; batch adversarial loss: 0.501360\n",
      "epoch 168; iter: 0; batch classifier loss: 0.462698; batch adversarial loss: 0.526597\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363481; batch adversarial loss: 0.466447\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335214; batch adversarial loss: 0.483737\n",
      "epoch 171; iter: 0; batch classifier loss: 0.425528; batch adversarial loss: 0.526678\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376000; batch adversarial loss: 0.545760\n",
      "epoch 173; iter: 0; batch classifier loss: 0.332016; batch adversarial loss: 0.572870\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363900; batch adversarial loss: 0.466835\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372712; batch adversarial loss: 0.569995\n",
      "epoch 176; iter: 0; batch classifier loss: 0.342422; batch adversarial loss: 0.640774\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324020; batch adversarial loss: 0.501504\n",
      "epoch 178; iter: 0; batch classifier loss: 0.406789; batch adversarial loss: 0.616767\n",
      "epoch 179; iter: 0; batch classifier loss: 0.275411; batch adversarial loss: 0.501656\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346908; batch adversarial loss: 0.553427\n",
      "epoch 181; iter: 0; batch classifier loss: 0.471425; batch adversarial loss: 0.542235\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367039; batch adversarial loss: 0.579000\n",
      "epoch 183; iter: 0; batch classifier loss: 0.404017; batch adversarial loss: 0.587119\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373545; batch adversarial loss: 0.554674\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342295; batch adversarial loss: 0.623293\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359868; batch adversarial loss: 0.564031\n",
      "epoch 187; iter: 0; batch classifier loss: 0.267972; batch adversarial loss: 0.511259\n",
      "epoch 188; iter: 0; batch classifier loss: 0.402552; batch adversarial loss: 0.501434\n",
      "epoch 189; iter: 0; batch classifier loss: 0.360184; batch adversarial loss: 0.554802\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329082; batch adversarial loss: 0.579728\n",
      "epoch 191; iter: 0; batch classifier loss: 0.402687; batch adversarial loss: 0.535504\n",
      "epoch 192; iter: 0; batch classifier loss: 0.382963; batch adversarial loss: 0.580507\n",
      "epoch 193; iter: 0; batch classifier loss: 0.409315; batch adversarial loss: 0.563399\n",
      "epoch 194; iter: 0; batch classifier loss: 0.404998; batch adversarial loss: 0.517491\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342270; batch adversarial loss: 0.562620\n",
      "epoch 196; iter: 0; batch classifier loss: 0.390585; batch adversarial loss: 0.545884\n",
      "epoch 197; iter: 0; batch classifier loss: 0.304625; batch adversarial loss: 0.502571\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331419; batch adversarial loss: 0.511983\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379812; batch adversarial loss: 0.641211\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683912; batch adversarial loss: 0.728991\n",
      "epoch 1; iter: 0; batch classifier loss: 0.720002; batch adversarial loss: 0.773458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.725045; batch adversarial loss: 0.727906\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659427; batch adversarial loss: 0.665817\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607971; batch adversarial loss: 0.626024\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575723; batch adversarial loss: 0.640604\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559965; batch adversarial loss: 0.608007\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549858; batch adversarial loss: 0.573157\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531928; batch adversarial loss: 0.611131\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527235; batch adversarial loss: 0.549132\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509001; batch adversarial loss: 0.590367\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492059; batch adversarial loss: 0.527004\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533211; batch adversarial loss: 0.579665\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550237; batch adversarial loss: 0.551125\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495735; batch adversarial loss: 0.612628\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491133; batch adversarial loss: 0.551334\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498971; batch adversarial loss: 0.561314\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546822; batch adversarial loss: 0.599881\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509355; batch adversarial loss: 0.613373\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499900; batch adversarial loss: 0.481707\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454175; batch adversarial loss: 0.522041\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450458; batch adversarial loss: 0.623979\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573275; batch adversarial loss: 0.574129\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527787; batch adversarial loss: 0.547114\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514073; batch adversarial loss: 0.546417\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500728; batch adversarial loss: 0.574993\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517813; batch adversarial loss: 0.559999\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520599; batch adversarial loss: 0.489585\n",
      "epoch 28; iter: 0; batch classifier loss: 0.403839; batch adversarial loss: 0.543932\n",
      "epoch 29; iter: 0; batch classifier loss: 0.545877; batch adversarial loss: 0.517588\n",
      "epoch 30; iter: 0; batch classifier loss: 0.537781; batch adversarial loss: 0.491329\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440000; batch adversarial loss: 0.563144\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462935; batch adversarial loss: 0.498280\n",
      "epoch 33; iter: 0; batch classifier loss: 0.427346; batch adversarial loss: 0.604314\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511163; batch adversarial loss: 0.545976\n",
      "epoch 35; iter: 0; batch classifier loss: 0.555091; batch adversarial loss: 0.467752\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424902; batch adversarial loss: 0.562073\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448946; batch adversarial loss: 0.605751\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443329; batch adversarial loss: 0.535792\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437637; batch adversarial loss: 0.554075\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436081; batch adversarial loss: 0.474075\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425782; batch adversarial loss: 0.562642\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466880; batch adversarial loss: 0.588987\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471590; batch adversarial loss: 0.499428\n",
      "epoch 44; iter: 0; batch classifier loss: 0.432810; batch adversarial loss: 0.517745\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414425; batch adversarial loss: 0.517192\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428710; batch adversarial loss: 0.534649\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422248; batch adversarial loss: 0.599001\n",
      "epoch 48; iter: 0; batch classifier loss: 0.513225; batch adversarial loss: 0.543532\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399932; batch adversarial loss: 0.554469\n",
      "epoch 50; iter: 0; batch classifier loss: 0.553081; batch adversarial loss: 0.551406\n",
      "epoch 51; iter: 0; batch classifier loss: 0.361526; batch adversarial loss: 0.560190\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444689; batch adversarial loss: 0.466568\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436279; batch adversarial loss: 0.522170\n",
      "epoch 54; iter: 0; batch classifier loss: 0.489834; batch adversarial loss: 0.541815\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419869; batch adversarial loss: 0.529926\n",
      "epoch 56; iter: 0; batch classifier loss: 0.489347; batch adversarial loss: 0.504615\n",
      "epoch 57; iter: 0; batch classifier loss: 0.508299; batch adversarial loss: 0.505364\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460260; batch adversarial loss: 0.538541\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415558; batch adversarial loss: 0.557001\n",
      "epoch 60; iter: 0; batch classifier loss: 0.364075; batch adversarial loss: 0.514875\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407409; batch adversarial loss: 0.512310\n",
      "epoch 62; iter: 0; batch classifier loss: 0.480426; batch adversarial loss: 0.563290\n",
      "epoch 63; iter: 0; batch classifier loss: 0.354720; batch adversarial loss: 0.518710\n",
      "epoch 64; iter: 0; batch classifier loss: 0.443208; batch adversarial loss: 0.526457\n",
      "epoch 65; iter: 0; batch classifier loss: 0.478329; batch adversarial loss: 0.535618\n",
      "epoch 66; iter: 0; batch classifier loss: 0.388172; batch adversarial loss: 0.582280\n",
      "epoch 67; iter: 0; batch classifier loss: 0.454220; batch adversarial loss: 0.563568\n",
      "epoch 68; iter: 0; batch classifier loss: 0.347005; batch adversarial loss: 0.491037\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393459; batch adversarial loss: 0.499575\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401157; batch adversarial loss: 0.617014\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378044; batch adversarial loss: 0.562603\n",
      "epoch 72; iter: 0; batch classifier loss: 0.425019; batch adversarial loss: 0.570588\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425722; batch adversarial loss: 0.536730\n",
      "epoch 74; iter: 0; batch classifier loss: 0.400360; batch adversarial loss: 0.581068\n",
      "epoch 75; iter: 0; batch classifier loss: 0.452713; batch adversarial loss: 0.526644\n",
      "epoch 76; iter: 0; batch classifier loss: 0.436180; batch adversarial loss: 0.470884\n",
      "epoch 77; iter: 0; batch classifier loss: 0.356896; batch adversarial loss: 0.608481\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439016; batch adversarial loss: 0.563401\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404170; batch adversarial loss: 0.581318\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416712; batch adversarial loss: 0.526732\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418920; batch adversarial loss: 0.580393\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416956; batch adversarial loss: 0.535613\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395318; batch adversarial loss: 0.582489\n",
      "epoch 84; iter: 0; batch classifier loss: 0.333810; batch adversarial loss: 0.580843\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366043; batch adversarial loss: 0.572160\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387703; batch adversarial loss: 0.526707\n",
      "epoch 87; iter: 0; batch classifier loss: 0.446704; batch adversarial loss: 0.524277\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358968; batch adversarial loss: 0.525260\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375418; batch adversarial loss: 0.469666\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452067; batch adversarial loss: 0.555015\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382350; batch adversarial loss: 0.562299\n",
      "epoch 92; iter: 0; batch classifier loss: 0.420503; batch adversarial loss: 0.497947\n",
      "epoch 93; iter: 0; batch classifier loss: 0.358788; batch adversarial loss: 0.552904\n",
      "epoch 94; iter: 0; batch classifier loss: 0.485585; batch adversarial loss: 0.608513\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407749; batch adversarial loss: 0.517491\n",
      "epoch 96; iter: 0; batch classifier loss: 0.362310; batch adversarial loss: 0.524761\n",
      "epoch 97; iter: 0; batch classifier loss: 0.403417; batch adversarial loss: 0.525159\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365259; batch adversarial loss: 0.497822\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377413; batch adversarial loss: 0.516536\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382388; batch adversarial loss: 0.480176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.414841; batch adversarial loss: 0.498046\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407301; batch adversarial loss: 0.609163\n",
      "epoch 103; iter: 0; batch classifier loss: 0.418086; batch adversarial loss: 0.506695\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422117; batch adversarial loss: 0.617141\n",
      "epoch 105; iter: 0; batch classifier loss: 0.446324; batch adversarial loss: 0.534884\n",
      "epoch 106; iter: 0; batch classifier loss: 0.356427; batch adversarial loss: 0.554115\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347759; batch adversarial loss: 0.481053\n",
      "epoch 108; iter: 0; batch classifier loss: 0.332440; batch adversarial loss: 0.535826\n",
      "epoch 109; iter: 0; batch classifier loss: 0.405351; batch adversarial loss: 0.461872\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390156; batch adversarial loss: 0.517343\n",
      "epoch 111; iter: 0; batch classifier loss: 0.317216; batch adversarial loss: 0.544125\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411051; batch adversarial loss: 0.581353\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380165; batch adversarial loss: 0.553983\n",
      "epoch 114; iter: 0; batch classifier loss: 0.439783; batch adversarial loss: 0.480685\n",
      "epoch 115; iter: 0; batch classifier loss: 0.434127; batch adversarial loss: 0.536163\n",
      "epoch 116; iter: 0; batch classifier loss: 0.441977; batch adversarial loss: 0.516992\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345170; batch adversarial loss: 0.565041\n",
      "epoch 118; iter: 0; batch classifier loss: 0.344585; batch adversarial loss: 0.544261\n",
      "epoch 119; iter: 0; batch classifier loss: 0.341417; batch adversarial loss: 0.544162\n",
      "epoch 120; iter: 0; batch classifier loss: 0.429014; batch adversarial loss: 0.470480\n",
      "epoch 121; iter: 0; batch classifier loss: 0.408113; batch adversarial loss: 0.563136\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379401; batch adversarial loss: 0.561796\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399024; batch adversarial loss: 0.552788\n",
      "epoch 124; iter: 0; batch classifier loss: 0.317197; batch adversarial loss: 0.545174\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350828; batch adversarial loss: 0.570211\n",
      "epoch 126; iter: 0; batch classifier loss: 0.337574; batch adversarial loss: 0.663187\n",
      "epoch 127; iter: 0; batch classifier loss: 0.306456; batch adversarial loss: 0.525713\n",
      "epoch 128; iter: 0; batch classifier loss: 0.303067; batch adversarial loss: 0.535057\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327893; batch adversarial loss: 0.563488\n",
      "epoch 130; iter: 0; batch classifier loss: 0.305975; batch adversarial loss: 0.534837\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336832; batch adversarial loss: 0.489384\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331753; batch adversarial loss: 0.526476\n",
      "epoch 133; iter: 0; batch classifier loss: 0.288197; batch adversarial loss: 0.571485\n",
      "epoch 134; iter: 0; batch classifier loss: 0.370446; batch adversarial loss: 0.543850\n",
      "epoch 135; iter: 0; batch classifier loss: 0.310201; batch adversarial loss: 0.553827\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328136; batch adversarial loss: 0.554585\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402053; batch adversarial loss: 0.543238\n",
      "epoch 138; iter: 0; batch classifier loss: 0.378631; batch adversarial loss: 0.553432\n",
      "epoch 139; iter: 0; batch classifier loss: 0.394123; batch adversarial loss: 0.589839\n",
      "epoch 140; iter: 0; batch classifier loss: 0.454268; batch adversarial loss: 0.627226\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322993; batch adversarial loss: 0.580552\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391213; batch adversarial loss: 0.580247\n",
      "epoch 143; iter: 0; batch classifier loss: 0.400598; batch adversarial loss: 0.627106\n",
      "epoch 144; iter: 0; batch classifier loss: 0.344804; batch adversarial loss: 0.471534\n",
      "epoch 145; iter: 0; batch classifier loss: 0.475071; batch adversarial loss: 0.490276\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371223; batch adversarial loss: 0.582332\n",
      "epoch 147; iter: 0; batch classifier loss: 0.433265; batch adversarial loss: 0.599080\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358290; batch adversarial loss: 0.470960\n",
      "epoch 149; iter: 0; batch classifier loss: 0.345690; batch adversarial loss: 0.571924\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392009; batch adversarial loss: 0.470851\n",
      "epoch 151; iter: 0; batch classifier loss: 0.358836; batch adversarial loss: 0.570435\n",
      "epoch 152; iter: 0; batch classifier loss: 0.373394; batch adversarial loss: 0.543301\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316536; batch adversarial loss: 0.582604\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374215; batch adversarial loss: 0.488980\n",
      "epoch 155; iter: 0; batch classifier loss: 0.450953; batch adversarial loss: 0.625871\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336079; batch adversarial loss: 0.599423\n",
      "epoch 157; iter: 0; batch classifier loss: 0.284200; batch adversarial loss: 0.526534\n",
      "epoch 158; iter: 0; batch classifier loss: 0.418747; batch adversarial loss: 0.535859\n",
      "epoch 159; iter: 0; batch classifier loss: 0.395260; batch adversarial loss: 0.572143\n",
      "epoch 160; iter: 0; batch classifier loss: 0.326608; batch adversarial loss: 0.552677\n",
      "epoch 161; iter: 0; batch classifier loss: 0.382099; batch adversarial loss: 0.479748\n",
      "epoch 162; iter: 0; batch classifier loss: 0.391040; batch adversarial loss: 0.544521\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328214; batch adversarial loss: 0.553226\n",
      "epoch 164; iter: 0; batch classifier loss: 0.459609; batch adversarial loss: 0.563668\n",
      "epoch 165; iter: 0; batch classifier loss: 0.325413; batch adversarial loss: 0.526979\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343636; batch adversarial loss: 0.506749\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371574; batch adversarial loss: 0.488700\n",
      "epoch 168; iter: 0; batch classifier loss: 0.328603; batch adversarial loss: 0.582422\n",
      "epoch 169; iter: 0; batch classifier loss: 0.303105; batch adversarial loss: 0.507914\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335741; batch adversarial loss: 0.462366\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355974; batch adversarial loss: 0.517639\n",
      "epoch 172; iter: 0; batch classifier loss: 0.484180; batch adversarial loss: 0.499268\n",
      "epoch 173; iter: 0; batch classifier loss: 0.389800; batch adversarial loss: 0.572369\n",
      "epoch 174; iter: 0; batch classifier loss: 0.382855; batch adversarial loss: 0.570392\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338432; batch adversarial loss: 0.609046\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370458; batch adversarial loss: 0.536087\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389930; batch adversarial loss: 0.580599\n",
      "epoch 178; iter: 0; batch classifier loss: 0.413158; batch adversarial loss: 0.608769\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358173; batch adversarial loss: 0.609075\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335240; batch adversarial loss: 0.517076\n",
      "epoch 181; iter: 0; batch classifier loss: 0.375892; batch adversarial loss: 0.591351\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383376; batch adversarial loss: 0.462009\n",
      "epoch 183; iter: 0; batch classifier loss: 0.360838; batch adversarial loss: 0.589858\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331238; batch adversarial loss: 0.626043\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371584; batch adversarial loss: 0.563932\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389588; batch adversarial loss: 0.580189\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375431; batch adversarial loss: 0.591060\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384028; batch adversarial loss: 0.570619\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315323; batch adversarial loss: 0.517712\n",
      "epoch 190; iter: 0; batch classifier loss: 0.404955; batch adversarial loss: 0.471438\n",
      "epoch 191; iter: 0; batch classifier loss: 0.436220; batch adversarial loss: 0.553191\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396530; batch adversarial loss: 0.509145\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375759; batch adversarial loss: 0.580557\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384482; batch adversarial loss: 0.609786\n",
      "epoch 195; iter: 0; batch classifier loss: 0.316881; batch adversarial loss: 0.472444\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359925; batch adversarial loss: 0.526781\n",
      "epoch 197; iter: 0; batch classifier loss: 0.437595; batch adversarial loss: 0.516512\n",
      "epoch 198; iter: 0; batch classifier loss: 0.374512; batch adversarial loss: 0.506613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.301736; batch adversarial loss: 0.489944\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676851; batch adversarial loss: 0.756307\n",
      "epoch 1; iter: 0; batch classifier loss: 0.648006; batch adversarial loss: 0.727631\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551557; batch adversarial loss: 0.686126\n",
      "epoch 3; iter: 0; batch classifier loss: 0.650999; batch adversarial loss: 0.658902\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542180; batch adversarial loss: 0.647521\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594831; batch adversarial loss: 0.640034\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582887; batch adversarial loss: 0.607042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526359; batch adversarial loss: 0.589566\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551679; batch adversarial loss: 0.572701\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541559; batch adversarial loss: 0.577241\n",
      "epoch 10; iter: 0; batch classifier loss: 0.467113; batch adversarial loss: 0.578516\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571744; batch adversarial loss: 0.547145\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511062; batch adversarial loss: 0.578020\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528912; batch adversarial loss: 0.570420\n",
      "epoch 14; iter: 0; batch classifier loss: 0.494737; batch adversarial loss: 0.563030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500703; batch adversarial loss: 0.549874\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561492; batch adversarial loss: 0.614836\n",
      "epoch 17; iter: 0; batch classifier loss: 0.455691; batch adversarial loss: 0.579636\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500285; batch adversarial loss: 0.489322\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509430; batch adversarial loss: 0.531712\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551975; batch adversarial loss: 0.569864\n",
      "epoch 21; iter: 0; batch classifier loss: 0.612113; batch adversarial loss: 0.599639\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451709; batch adversarial loss: 0.533414\n",
      "epoch 23; iter: 0; batch classifier loss: 0.558802; batch adversarial loss: 0.653934\n",
      "epoch 24; iter: 0; batch classifier loss: 0.563720; batch adversarial loss: 0.510254\n",
      "epoch 25; iter: 0; batch classifier loss: 0.584774; batch adversarial loss: 0.611017\n",
      "epoch 26; iter: 0; batch classifier loss: 0.488611; batch adversarial loss: 0.530389\n",
      "epoch 27; iter: 0; batch classifier loss: 0.579425; batch adversarial loss: 0.612148\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510856; batch adversarial loss: 0.611212\n",
      "epoch 29; iter: 0; batch classifier loss: 0.545925; batch adversarial loss: 0.532196\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458589; batch adversarial loss: 0.538461\n",
      "epoch 31; iter: 0; batch classifier loss: 0.404732; batch adversarial loss: 0.481154\n",
      "epoch 32; iter: 0; batch classifier loss: 0.511634; batch adversarial loss: 0.504640\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488415; batch adversarial loss: 0.528406\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476939; batch adversarial loss: 0.545266\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485806; batch adversarial loss: 0.588781\n",
      "epoch 36; iter: 0; batch classifier loss: 0.533616; batch adversarial loss: 0.553921\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499075; batch adversarial loss: 0.500501\n",
      "epoch 38; iter: 0; batch classifier loss: 0.517883; batch adversarial loss: 0.544808\n",
      "epoch 39; iter: 0; batch classifier loss: 0.461366; batch adversarial loss: 0.517796\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452341; batch adversarial loss: 0.499721\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472250; batch adversarial loss: 0.616521\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483172; batch adversarial loss: 0.607663\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422977; batch adversarial loss: 0.526584\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403936; batch adversarial loss: 0.526381\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453668; batch adversarial loss: 0.581250\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438238; batch adversarial loss: 0.600141\n",
      "epoch 47; iter: 0; batch classifier loss: 0.414716; batch adversarial loss: 0.599729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.504090; batch adversarial loss: 0.553535\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474118; batch adversarial loss: 0.562616\n",
      "epoch 50; iter: 0; batch classifier loss: 0.404897; batch adversarial loss: 0.571263\n",
      "epoch 51; iter: 0; batch classifier loss: 0.461356; batch adversarial loss: 0.552951\n",
      "epoch 52; iter: 0; batch classifier loss: 0.474406; batch adversarial loss: 0.571087\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396135; batch adversarial loss: 0.596098\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474389; batch adversarial loss: 0.498811\n",
      "epoch 55; iter: 0; batch classifier loss: 0.348915; batch adversarial loss: 0.522811\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435636; batch adversarial loss: 0.554221\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425027; batch adversarial loss: 0.523770\n",
      "epoch 58; iter: 0; batch classifier loss: 0.370949; batch adversarial loss: 0.579083\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422879; batch adversarial loss: 0.562362\n",
      "epoch 60; iter: 0; batch classifier loss: 0.365584; batch adversarial loss: 0.555990\n",
      "epoch 61; iter: 0; batch classifier loss: 0.453392; batch adversarial loss: 0.527710\n",
      "epoch 62; iter: 0; batch classifier loss: 0.462604; batch adversarial loss: 0.544822\n",
      "epoch 63; iter: 0; batch classifier loss: 0.487657; batch adversarial loss: 0.516322\n",
      "epoch 64; iter: 0; batch classifier loss: 0.467056; batch adversarial loss: 0.592252\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442429; batch adversarial loss: 0.450243\n",
      "epoch 66; iter: 0; batch classifier loss: 0.444620; batch adversarial loss: 0.553826\n",
      "epoch 67; iter: 0; batch classifier loss: 0.458289; batch adversarial loss: 0.544900\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409871; batch adversarial loss: 0.554186\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444716; batch adversarial loss: 0.562793\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445170; batch adversarial loss: 0.544537\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394319; batch adversarial loss: 0.562180\n",
      "epoch 72; iter: 0; batch classifier loss: 0.452986; batch adversarial loss: 0.517768\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407816; batch adversarial loss: 0.516156\n",
      "epoch 74; iter: 0; batch classifier loss: 0.427074; batch adversarial loss: 0.535514\n",
      "epoch 75; iter: 0; batch classifier loss: 0.517514; batch adversarial loss: 0.581630\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363718; batch adversarial loss: 0.569957\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400146; batch adversarial loss: 0.613446\n",
      "epoch 78; iter: 0; batch classifier loss: 0.476696; batch adversarial loss: 0.620187\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418657; batch adversarial loss: 0.556293\n",
      "epoch 80; iter: 0; batch classifier loss: 0.405494; batch adversarial loss: 0.555549\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408303; batch adversarial loss: 0.618343\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371732; batch adversarial loss: 0.601616\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386691; batch adversarial loss: 0.552522\n",
      "epoch 84; iter: 0; batch classifier loss: 0.432626; batch adversarial loss: 0.571290\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424492; batch adversarial loss: 0.524846\n",
      "epoch 86; iter: 0; batch classifier loss: 0.459228; batch adversarial loss: 0.508338\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395207; batch adversarial loss: 0.553396\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389284; batch adversarial loss: 0.481109\n",
      "epoch 89; iter: 0; batch classifier loss: 0.454946; batch adversarial loss: 0.553321\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456952; batch adversarial loss: 0.461448\n",
      "epoch 91; iter: 0; batch classifier loss: 0.340380; batch adversarial loss: 0.553905\n",
      "epoch 92; iter: 0; batch classifier loss: 0.326707; batch adversarial loss: 0.646023\n",
      "epoch 93; iter: 0; batch classifier loss: 0.525568; batch adversarial loss: 0.581494\n",
      "epoch 94; iter: 0; batch classifier loss: 0.432047; batch adversarial loss: 0.516613\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396360; batch adversarial loss: 0.590617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.436229; batch adversarial loss: 0.469449\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363196; batch adversarial loss: 0.563082\n",
      "epoch 98; iter: 0; batch classifier loss: 0.366264; batch adversarial loss: 0.562875\n",
      "epoch 99; iter: 0; batch classifier loss: 0.431704; batch adversarial loss: 0.553526\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384797; batch adversarial loss: 0.573793\n",
      "epoch 101; iter: 0; batch classifier loss: 0.423653; batch adversarial loss: 0.572016\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393104; batch adversarial loss: 0.681899\n",
      "epoch 103; iter: 0; batch classifier loss: 0.455495; batch adversarial loss: 0.554492\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409973; batch adversarial loss: 0.526261\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414819; batch adversarial loss: 0.515843\n",
      "epoch 106; iter: 0; batch classifier loss: 0.458201; batch adversarial loss: 0.532840\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405127; batch adversarial loss: 0.461200\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373157; batch adversarial loss: 0.526024\n",
      "epoch 109; iter: 0; batch classifier loss: 0.444733; batch adversarial loss: 0.580207\n",
      "epoch 110; iter: 0; batch classifier loss: 0.430240; batch adversarial loss: 0.526250\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433002; batch adversarial loss: 0.562894\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396722; batch adversarial loss: 0.452469\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343080; batch adversarial loss: 0.625780\n",
      "epoch 114; iter: 0; batch classifier loss: 0.355306; batch adversarial loss: 0.561945\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417129; batch adversarial loss: 0.497990\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406129; batch adversarial loss: 0.478106\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383820; batch adversarial loss: 0.600718\n",
      "epoch 118; iter: 0; batch classifier loss: 0.478431; batch adversarial loss: 0.544180\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375549; batch adversarial loss: 0.545550\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374021; batch adversarial loss: 0.507342\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360417; batch adversarial loss: 0.452089\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366676; batch adversarial loss: 0.526062\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409919; batch adversarial loss: 0.609855\n",
      "epoch 124; iter: 0; batch classifier loss: 0.498298; batch adversarial loss: 0.627901\n",
      "epoch 125; iter: 0; batch classifier loss: 0.436599; batch adversarial loss: 0.479604\n",
      "epoch 126; iter: 0; batch classifier loss: 0.426143; batch adversarial loss: 0.554544\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334243; batch adversarial loss: 0.542483\n",
      "epoch 128; iter: 0; batch classifier loss: 0.457188; batch adversarial loss: 0.627019\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397943; batch adversarial loss: 0.597822\n",
      "epoch 130; iter: 0; batch classifier loss: 0.313474; batch adversarial loss: 0.589712\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360365; batch adversarial loss: 0.527834\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357321; batch adversarial loss: 0.543684\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392899; batch adversarial loss: 0.462326\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.498041\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365021; batch adversarial loss: 0.545397\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382355; batch adversarial loss: 0.499283\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413543; batch adversarial loss: 0.471901\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340979; batch adversarial loss: 0.498391\n",
      "epoch 139; iter: 0; batch classifier loss: 0.412747; batch adversarial loss: 0.580872\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376371; batch adversarial loss: 0.489108\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344791; batch adversarial loss: 0.562753\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369441; batch adversarial loss: 0.517275\n",
      "epoch 143; iter: 0; batch classifier loss: 0.463024; batch adversarial loss: 0.581822\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348968; batch adversarial loss: 0.543867\n",
      "epoch 145; iter: 0; batch classifier loss: 0.361081; batch adversarial loss: 0.516534\n",
      "epoch 146; iter: 0; batch classifier loss: 0.333257; batch adversarial loss: 0.664365\n",
      "epoch 147; iter: 0; batch classifier loss: 0.489772; batch adversarial loss: 0.535043\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354960; batch adversarial loss: 0.683578\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379269; batch adversarial loss: 0.506731\n",
      "epoch 150; iter: 0; batch classifier loss: 0.418589; batch adversarial loss: 0.516897\n",
      "epoch 151; iter: 0; batch classifier loss: 0.407700; batch adversarial loss: 0.561896\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382659; batch adversarial loss: 0.543172\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405824; batch adversarial loss: 0.542498\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352492; batch adversarial loss: 0.646117\n",
      "epoch 155; iter: 0; batch classifier loss: 0.329354; batch adversarial loss: 0.536549\n",
      "epoch 156; iter: 0; batch classifier loss: 0.416722; batch adversarial loss: 0.499354\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312525; batch adversarial loss: 0.544505\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369482; batch adversarial loss: 0.551593\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347150; batch adversarial loss: 0.608330\n",
      "epoch 160; iter: 0; batch classifier loss: 0.408130; batch adversarial loss: 0.487902\n",
      "epoch 161; iter: 0; batch classifier loss: 0.466385; batch adversarial loss: 0.499003\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350868; batch adversarial loss: 0.534729\n",
      "epoch 163; iter: 0; batch classifier loss: 0.378853; batch adversarial loss: 0.482228\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345914; batch adversarial loss: 0.599826\n",
      "epoch 165; iter: 0; batch classifier loss: 0.272507; batch adversarial loss: 0.507302\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360969; batch adversarial loss: 0.535493\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379420; batch adversarial loss: 0.571534\n",
      "epoch 168; iter: 0; batch classifier loss: 0.399240; batch adversarial loss: 0.497861\n",
      "epoch 169; iter: 0; batch classifier loss: 0.431962; batch adversarial loss: 0.573805\n",
      "epoch 170; iter: 0; batch classifier loss: 0.375215; batch adversarial loss: 0.527304\n",
      "epoch 171; iter: 0; batch classifier loss: 0.430378; batch adversarial loss: 0.571041\n",
      "epoch 172; iter: 0; batch classifier loss: 0.429471; batch adversarial loss: 0.626770\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350839; batch adversarial loss: 0.464527\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345324; batch adversarial loss: 0.508182\n",
      "epoch 175; iter: 0; batch classifier loss: 0.350515; batch adversarial loss: 0.542912\n",
      "epoch 176; iter: 0; batch classifier loss: 0.314974; batch adversarial loss: 0.526348\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372427; batch adversarial loss: 0.498307\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320382; batch adversarial loss: 0.497600\n",
      "epoch 179; iter: 0; batch classifier loss: 0.460725; batch adversarial loss: 0.491814\n",
      "epoch 180; iter: 0; batch classifier loss: 0.395208; batch adversarial loss: 0.536036\n",
      "epoch 181; iter: 0; batch classifier loss: 0.424933; batch adversarial loss: 0.534054\n",
      "epoch 182; iter: 0; batch classifier loss: 0.386096; batch adversarial loss: 0.542532\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385945; batch adversarial loss: 0.524774\n",
      "epoch 184; iter: 0; batch classifier loss: 0.422072; batch adversarial loss: 0.478010\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379907; batch adversarial loss: 0.461403\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376491; batch adversarial loss: 0.545429\n",
      "epoch 187; iter: 0; batch classifier loss: 0.302806; batch adversarial loss: 0.544903\n",
      "epoch 188; iter: 0; batch classifier loss: 0.360451; batch adversarial loss: 0.572013\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336620; batch adversarial loss: 0.571120\n",
      "epoch 190; iter: 0; batch classifier loss: 0.472160; batch adversarial loss: 0.656597\n",
      "epoch 191; iter: 0; batch classifier loss: 0.422958; batch adversarial loss: 0.524487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.401344; batch adversarial loss: 0.608744\n",
      "epoch 193; iter: 0; batch classifier loss: 0.413363; batch adversarial loss: 0.517581\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308103; batch adversarial loss: 0.571068\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370864; batch adversarial loss: 0.553490\n",
      "epoch 196; iter: 0; batch classifier loss: 0.415649; batch adversarial loss: 0.609664\n",
      "epoch 197; iter: 0; batch classifier loss: 0.404926; batch adversarial loss: 0.617559\n",
      "epoch 198; iter: 0; batch classifier loss: 0.426267; batch adversarial loss: 0.534902\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388377; batch adversarial loss: 0.571986\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701419; batch adversarial loss: 0.766042\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559858; batch adversarial loss: 0.733986\n",
      "epoch 2; iter: 0; batch classifier loss: 0.657995; batch adversarial loss: 0.697551\n",
      "epoch 3; iter: 0; batch classifier loss: 0.584810; batch adversarial loss: 0.706405\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529006; batch adversarial loss: 0.642848\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555088; batch adversarial loss: 0.679488\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581367; batch adversarial loss: 0.587060\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584943; batch adversarial loss: 0.568316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529702; batch adversarial loss: 0.603992\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554279; batch adversarial loss: 0.558587\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485442; batch adversarial loss: 0.546175\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555850; batch adversarial loss: 0.533180\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521213; batch adversarial loss: 0.584298\n",
      "epoch 13; iter: 0; batch classifier loss: 0.458644; batch adversarial loss: 0.532481\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533587; batch adversarial loss: 0.506727\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578428; batch adversarial loss: 0.564221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.556538; batch adversarial loss: 0.626459\n",
      "epoch 17; iter: 0; batch classifier loss: 0.561547; batch adversarial loss: 0.597373\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458100; batch adversarial loss: 0.561140\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492865; batch adversarial loss: 0.554909\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538491; batch adversarial loss: 0.589538\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522413; batch adversarial loss: 0.624344\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482101; batch adversarial loss: 0.554174\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472859; batch adversarial loss: 0.635334\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528536; batch adversarial loss: 0.589914\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496162; batch adversarial loss: 0.568407\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476079; batch adversarial loss: 0.590968\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464033; batch adversarial loss: 0.539889\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462882; batch adversarial loss: 0.580847\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460337; batch adversarial loss: 0.529756\n",
      "epoch 30; iter: 0; batch classifier loss: 0.492077; batch adversarial loss: 0.570762\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499823; batch adversarial loss: 0.529667\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448924; batch adversarial loss: 0.575362\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441228; batch adversarial loss: 0.536906\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466612; batch adversarial loss: 0.572527\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496247; batch adversarial loss: 0.514331\n",
      "epoch 36; iter: 0; batch classifier loss: 0.513847; batch adversarial loss: 0.596327\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443286; batch adversarial loss: 0.580036\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414858; batch adversarial loss: 0.553425\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442309; batch adversarial loss: 0.511156\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423207; batch adversarial loss: 0.517101\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417394; batch adversarial loss: 0.525548\n",
      "epoch 42; iter: 0; batch classifier loss: 0.500484; batch adversarial loss: 0.589914\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412667; batch adversarial loss: 0.501881\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423548; batch adversarial loss: 0.507092\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502000; batch adversarial loss: 0.571527\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407404; batch adversarial loss: 0.466907\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459886; batch adversarial loss: 0.567377\n",
      "epoch 48; iter: 0; batch classifier loss: 0.477310; batch adversarial loss: 0.584058\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423912; batch adversarial loss: 0.556353\n",
      "epoch 50; iter: 0; batch classifier loss: 0.440370; batch adversarial loss: 0.563941\n",
      "epoch 51; iter: 0; batch classifier loss: 0.373406; batch adversarial loss: 0.531567\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455333; batch adversarial loss: 0.626191\n",
      "epoch 53; iter: 0; batch classifier loss: 0.457550; batch adversarial loss: 0.542754\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440418; batch adversarial loss: 0.547134\n",
      "epoch 55; iter: 0; batch classifier loss: 0.418840; batch adversarial loss: 0.485441\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389352; batch adversarial loss: 0.491575\n",
      "epoch 57; iter: 0; batch classifier loss: 0.433829; batch adversarial loss: 0.528029\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462155; batch adversarial loss: 0.617931\n",
      "epoch 59; iter: 0; batch classifier loss: 0.436916; batch adversarial loss: 0.586675\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386654; batch adversarial loss: 0.544502\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422053; batch adversarial loss: 0.538312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.449123; batch adversarial loss: 0.547909\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422235; batch adversarial loss: 0.542817\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412532; batch adversarial loss: 0.574683\n",
      "epoch 65; iter: 0; batch classifier loss: 0.499138; batch adversarial loss: 0.569924\n",
      "epoch 66; iter: 0; batch classifier loss: 0.508796; batch adversarial loss: 0.651997\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444346; batch adversarial loss: 0.536852\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342406; batch adversarial loss: 0.532507\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442583; batch adversarial loss: 0.590795\n",
      "epoch 70; iter: 0; batch classifier loss: 0.386358; batch adversarial loss: 0.573446\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425729; batch adversarial loss: 0.619105\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466447; batch adversarial loss: 0.539237\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428497; batch adversarial loss: 0.604651\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432681; batch adversarial loss: 0.494231\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367818; batch adversarial loss: 0.572267\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402349; batch adversarial loss: 0.571689\n",
      "epoch 77; iter: 0; batch classifier loss: 0.352969; batch adversarial loss: 0.612096\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441759; batch adversarial loss: 0.499112\n",
      "epoch 79; iter: 0; batch classifier loss: 0.435332; batch adversarial loss: 0.525788\n",
      "epoch 80; iter: 0; batch classifier loss: 0.473118; batch adversarial loss: 0.557061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430250; batch adversarial loss: 0.610934\n",
      "epoch 82; iter: 0; batch classifier loss: 0.492900; batch adversarial loss: 0.484885\n",
      "epoch 83; iter: 0; batch classifier loss: 0.442867; batch adversarial loss: 0.471955\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440711; batch adversarial loss: 0.558400\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400783; batch adversarial loss: 0.561778\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373656; batch adversarial loss: 0.529470\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393767; batch adversarial loss: 0.470125\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408858; batch adversarial loss: 0.514935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.494893; batch adversarial loss: 0.514686\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363128; batch adversarial loss: 0.541168\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411311; batch adversarial loss: 0.532421\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414139; batch adversarial loss: 0.512945\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391996; batch adversarial loss: 0.655953\n",
      "epoch 94; iter: 0; batch classifier loss: 0.463971; batch adversarial loss: 0.539102\n",
      "epoch 95; iter: 0; batch classifier loss: 0.454991; batch adversarial loss: 0.520925\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414745; batch adversarial loss: 0.597229\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390579; batch adversarial loss: 0.458993\n",
      "epoch 98; iter: 0; batch classifier loss: 0.432518; batch adversarial loss: 0.497176\n",
      "epoch 99; iter: 0; batch classifier loss: 0.337352; batch adversarial loss: 0.635529\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418860; batch adversarial loss: 0.562131\n",
      "epoch 101; iter: 0; batch classifier loss: 0.498310; batch adversarial loss: 0.527168\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365815; batch adversarial loss: 0.551833\n",
      "epoch 103; iter: 0; batch classifier loss: 0.431623; batch adversarial loss: 0.630387\n",
      "epoch 104; iter: 0; batch classifier loss: 0.436751; batch adversarial loss: 0.626719\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359369; batch adversarial loss: 0.547424\n",
      "epoch 106; iter: 0; batch classifier loss: 0.427897; batch adversarial loss: 0.523155\n",
      "epoch 107; iter: 0; batch classifier loss: 0.429990; batch adversarial loss: 0.454977\n",
      "epoch 108; iter: 0; batch classifier loss: 0.414100; batch adversarial loss: 0.483585\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344289; batch adversarial loss: 0.560988\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373835; batch adversarial loss: 0.577868\n",
      "epoch 111; iter: 0; batch classifier loss: 0.447978; batch adversarial loss: 0.542178\n",
      "epoch 112; iter: 0; batch classifier loss: 0.453013; batch adversarial loss: 0.590606\n",
      "epoch 113; iter: 0; batch classifier loss: 0.320737; batch adversarial loss: 0.557348\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357118; batch adversarial loss: 0.535776\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355030; batch adversarial loss: 0.532935\n",
      "epoch 116; iter: 0; batch classifier loss: 0.447468; batch adversarial loss: 0.561299\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373322; batch adversarial loss: 0.535387\n",
      "epoch 118; iter: 0; batch classifier loss: 0.436909; batch adversarial loss: 0.643482\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348585; batch adversarial loss: 0.606787\n",
      "epoch 120; iter: 0; batch classifier loss: 0.359463; batch adversarial loss: 0.549488\n",
      "epoch 121; iter: 0; batch classifier loss: 0.323938; batch adversarial loss: 0.566852\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367470; batch adversarial loss: 0.576337\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355500; batch adversarial loss: 0.490394\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408953; batch adversarial loss: 0.561413\n",
      "epoch 125; iter: 0; batch classifier loss: 0.440961; batch adversarial loss: 0.554746\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358094; batch adversarial loss: 0.578419\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369644; batch adversarial loss: 0.488216\n",
      "epoch 128; iter: 0; batch classifier loss: 0.324628; batch adversarial loss: 0.524864\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350752; batch adversarial loss: 0.572875\n",
      "epoch 130; iter: 0; batch classifier loss: 0.407232; batch adversarial loss: 0.533176\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400612; batch adversarial loss: 0.509509\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395137; batch adversarial loss: 0.521551\n",
      "epoch 133; iter: 0; batch classifier loss: 0.425916; batch adversarial loss: 0.496783\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368581; batch adversarial loss: 0.517125\n",
      "epoch 135; iter: 0; batch classifier loss: 0.345104; batch adversarial loss: 0.540990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340866; batch adversarial loss: 0.572228\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347240; batch adversarial loss: 0.586675\n",
      "epoch 138; iter: 0; batch classifier loss: 0.321423; batch adversarial loss: 0.464009\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390300; batch adversarial loss: 0.517418\n",
      "epoch 140; iter: 0; batch classifier loss: 0.353684; batch adversarial loss: 0.599670\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398987; batch adversarial loss: 0.512173\n",
      "epoch 142; iter: 0; batch classifier loss: 0.441398; batch adversarial loss: 0.542383\n",
      "epoch 143; iter: 0; batch classifier loss: 0.434030; batch adversarial loss: 0.598678\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374422; batch adversarial loss: 0.493228\n",
      "epoch 145; iter: 0; batch classifier loss: 0.421834; batch adversarial loss: 0.518929\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368454; batch adversarial loss: 0.518273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.313060; batch adversarial loss: 0.504465\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330411; batch adversarial loss: 0.592688\n",
      "epoch 149; iter: 0; batch classifier loss: 0.416551; batch adversarial loss: 0.474813\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338959; batch adversarial loss: 0.552782\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392780; batch adversarial loss: 0.505481\n",
      "epoch 152; iter: 0; batch classifier loss: 0.432466; batch adversarial loss: 0.518102\n",
      "epoch 153; iter: 0; batch classifier loss: 0.392634; batch adversarial loss: 0.466622\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377677; batch adversarial loss: 0.484480\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373521; batch adversarial loss: 0.489363\n",
      "epoch 156; iter: 0; batch classifier loss: 0.452507; batch adversarial loss: 0.565381\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370143; batch adversarial loss: 0.542547\n",
      "epoch 158; iter: 0; batch classifier loss: 0.335689; batch adversarial loss: 0.556680\n",
      "epoch 159; iter: 0; batch classifier loss: 0.302935; batch adversarial loss: 0.518720\n",
      "epoch 160; iter: 0; batch classifier loss: 0.444911; batch adversarial loss: 0.636447\n",
      "epoch 161; iter: 0; batch classifier loss: 0.306236; batch adversarial loss: 0.624571\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371596; batch adversarial loss: 0.588836\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364141; batch adversarial loss: 0.565544\n",
      "epoch 164; iter: 0; batch classifier loss: 0.425823; batch adversarial loss: 0.553240\n",
      "epoch 165; iter: 0; batch classifier loss: 0.426508; batch adversarial loss: 0.575726\n",
      "epoch 166; iter: 0; batch classifier loss: 0.485046; batch adversarial loss: 0.547306\n",
      "epoch 167; iter: 0; batch classifier loss: 0.339496; batch adversarial loss: 0.542581\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369383; batch adversarial loss: 0.577220\n",
      "epoch 169; iter: 0; batch classifier loss: 0.449037; batch adversarial loss: 0.615569\n",
      "epoch 170; iter: 0; batch classifier loss: 0.347065; batch adversarial loss: 0.571374\n",
      "epoch 171; iter: 0; batch classifier loss: 0.398466; batch adversarial loss: 0.492704\n",
      "epoch 172; iter: 0; batch classifier loss: 0.409361; batch adversarial loss: 0.552101\n",
      "epoch 173; iter: 0; batch classifier loss: 0.415459; batch adversarial loss: 0.590585\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371104; batch adversarial loss: 0.539891\n",
      "epoch 175; iter: 0; batch classifier loss: 0.374128; batch adversarial loss: 0.483972\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374307; batch adversarial loss: 0.685532\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377962; batch adversarial loss: 0.549613\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370143; batch adversarial loss: 0.597081\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330493; batch adversarial loss: 0.610929\n",
      "epoch 180; iter: 0; batch classifier loss: 0.400694; batch adversarial loss: 0.471247\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377275; batch adversarial loss: 0.528348\n",
      "epoch 182; iter: 0; batch classifier loss: 0.417746; batch adversarial loss: 0.565396\n",
      "epoch 183; iter: 0; batch classifier loss: 0.406921; batch adversarial loss: 0.547388\n",
      "epoch 184; iter: 0; batch classifier loss: 0.424094; batch adversarial loss: 0.546589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.376127; batch adversarial loss: 0.491950\n",
      "epoch 186; iter: 0; batch classifier loss: 0.427237; batch adversarial loss: 0.527246\n",
      "epoch 187; iter: 0; batch classifier loss: 0.344475; batch adversarial loss: 0.543953\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367758; batch adversarial loss: 0.533181\n",
      "epoch 189; iter: 0; batch classifier loss: 0.418157; batch adversarial loss: 0.509128\n",
      "epoch 190; iter: 0; batch classifier loss: 0.466036; batch adversarial loss: 0.610611\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403431; batch adversarial loss: 0.484562\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359942; batch adversarial loss: 0.438087\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349767; batch adversarial loss: 0.562428\n",
      "epoch 194; iter: 0; batch classifier loss: 0.412621; batch adversarial loss: 0.539230\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338744; batch adversarial loss: 0.608064\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370591; batch adversarial loss: 0.567707\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315315; batch adversarial loss: 0.580041\n",
      "epoch 198; iter: 0; batch classifier loss: 0.396065; batch adversarial loss: 0.509825\n",
      "epoch 199; iter: 0; batch classifier loss: 0.289233; batch adversarial loss: 0.499964\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686937; batch adversarial loss: 0.664656\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571048; batch adversarial loss: 0.640631\n",
      "epoch 2; iter: 0; batch classifier loss: 0.537737; batch adversarial loss: 0.620773\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553179; batch adversarial loss: 0.597064\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538656; batch adversarial loss: 0.599392\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567865; batch adversarial loss: 0.643778\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491592; batch adversarial loss: 0.593350\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587676; batch adversarial loss: 0.616917\n",
      "epoch 8; iter: 0; batch classifier loss: 0.482199; batch adversarial loss: 0.595271\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510806; batch adversarial loss: 0.582749\n",
      "epoch 10; iter: 0; batch classifier loss: 0.583909; batch adversarial loss: 0.549709\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526508; batch adversarial loss: 0.590515\n",
      "epoch 12; iter: 0; batch classifier loss: 0.490460; batch adversarial loss: 0.650773\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479855; batch adversarial loss: 0.622852\n",
      "epoch 14; iter: 0; batch classifier loss: 0.578123; batch adversarial loss: 0.534044\n",
      "epoch 15; iter: 0; batch classifier loss: 0.416136; batch adversarial loss: 0.582077\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481811; batch adversarial loss: 0.553213\n",
      "epoch 17; iter: 0; batch classifier loss: 0.483180; batch adversarial loss: 0.531527\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488358; batch adversarial loss: 0.560003\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496355; batch adversarial loss: 0.548533\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532196; batch adversarial loss: 0.527720\n",
      "epoch 21; iter: 0; batch classifier loss: 0.529894; batch adversarial loss: 0.585634\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485200; batch adversarial loss: 0.501171\n",
      "epoch 23; iter: 0; batch classifier loss: 0.503068; batch adversarial loss: 0.558040\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519246; batch adversarial loss: 0.572422\n",
      "epoch 25; iter: 0; batch classifier loss: 0.419644; batch adversarial loss: 0.610179\n",
      "epoch 26; iter: 0; batch classifier loss: 0.545749; batch adversarial loss: 0.499813\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427766; batch adversarial loss: 0.513945\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512060; batch adversarial loss: 0.563096\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520436; batch adversarial loss: 0.494328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458878; batch adversarial loss: 0.502909\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421026; batch adversarial loss: 0.563021\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422879; batch adversarial loss: 0.500647\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451974; batch adversarial loss: 0.519584\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394566; batch adversarial loss: 0.598489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.463369; batch adversarial loss: 0.587914\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433198; batch adversarial loss: 0.545977\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440731; batch adversarial loss: 0.471477\n",
      "epoch 38; iter: 0; batch classifier loss: 0.477212; batch adversarial loss: 0.591586\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489707; batch adversarial loss: 0.498311\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476521; batch adversarial loss: 0.518568\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458859; batch adversarial loss: 0.497757\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499239; batch adversarial loss: 0.562248\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449481; batch adversarial loss: 0.506749\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476539; batch adversarial loss: 0.517531\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457391; batch adversarial loss: 0.580557\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457017; batch adversarial loss: 0.517409\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401942; batch adversarial loss: 0.470737\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377547; batch adversarial loss: 0.535517\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418634; batch adversarial loss: 0.537604\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424684; batch adversarial loss: 0.535810\n",
      "epoch 51; iter: 0; batch classifier loss: 0.480303; batch adversarial loss: 0.481778\n",
      "epoch 52; iter: 0; batch classifier loss: 0.340903; batch adversarial loss: 0.533980\n",
      "epoch 53; iter: 0; batch classifier loss: 0.317272; batch adversarial loss: 0.506733\n",
      "epoch 54; iter: 0; batch classifier loss: 0.492306; batch adversarial loss: 0.600152\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429621; batch adversarial loss: 0.599852\n",
      "epoch 56; iter: 0; batch classifier loss: 0.492630; batch adversarial loss: 0.479318\n",
      "epoch 57; iter: 0; batch classifier loss: 0.490143; batch adversarial loss: 0.608932\n",
      "epoch 58; iter: 0; batch classifier loss: 0.416830; batch adversarial loss: 0.498516\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423999; batch adversarial loss: 0.628971\n",
      "epoch 60; iter: 0; batch classifier loss: 0.467031; batch adversarial loss: 0.488262\n",
      "epoch 61; iter: 0; batch classifier loss: 0.443805; batch adversarial loss: 0.582851\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429356; batch adversarial loss: 0.609417\n",
      "epoch 63; iter: 0; batch classifier loss: 0.467668; batch adversarial loss: 0.649689\n",
      "epoch 64; iter: 0; batch classifier loss: 0.445315; batch adversarial loss: 0.608426\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407003; batch adversarial loss: 0.506712\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396397; batch adversarial loss: 0.590491\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411605; batch adversarial loss: 0.488516\n",
      "epoch 68; iter: 0; batch classifier loss: 0.312946; batch adversarial loss: 0.617167\n",
      "epoch 69; iter: 0; batch classifier loss: 0.421081; batch adversarial loss: 0.536632\n",
      "epoch 70; iter: 0; batch classifier loss: 0.460429; batch adversarial loss: 0.589781\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446370; batch adversarial loss: 0.500110\n",
      "epoch 72; iter: 0; batch classifier loss: 0.465168; batch adversarial loss: 0.555884\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392195; batch adversarial loss: 0.571379\n",
      "epoch 74; iter: 0; batch classifier loss: 0.407133; batch adversarial loss: 0.580485\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426121; batch adversarial loss: 0.518304\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395016; batch adversarial loss: 0.571606\n",
      "epoch 77; iter: 0; batch classifier loss: 0.524592; batch adversarial loss: 0.553463\n",
      "epoch 78; iter: 0; batch classifier loss: 0.459266; batch adversarial loss: 0.527183\n",
      "epoch 79; iter: 0; batch classifier loss: 0.457817; batch adversarial loss: 0.580438\n",
      "epoch 80; iter: 0; batch classifier loss: 0.292552; batch adversarial loss: 0.518184\n",
      "epoch 81; iter: 0; batch classifier loss: 0.435040; batch adversarial loss: 0.471995\n",
      "epoch 82; iter: 0; batch classifier loss: 0.351586; batch adversarial loss: 0.535653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.398686; batch adversarial loss: 0.581405\n",
      "epoch 84; iter: 0; batch classifier loss: 0.457729; batch adversarial loss: 0.534813\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456909; batch adversarial loss: 0.490332\n",
      "epoch 86; iter: 0; batch classifier loss: 0.326687; batch adversarial loss: 0.545652\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430658; batch adversarial loss: 0.470747\n",
      "epoch 88; iter: 0; batch classifier loss: 0.526356; batch adversarial loss: 0.599755\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342454; batch adversarial loss: 0.617361\n",
      "epoch 90; iter: 0; batch classifier loss: 0.326623; batch adversarial loss: 0.543789\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397573; batch adversarial loss: 0.479079\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365976; batch adversarial loss: 0.525934\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371639; batch adversarial loss: 0.590671\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357506; batch adversarial loss: 0.535403\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358333; batch adversarial loss: 0.471078\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399728; batch adversarial loss: 0.553262\n",
      "epoch 97; iter: 0; batch classifier loss: 0.414441; batch adversarial loss: 0.608360\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368450; batch adversarial loss: 0.535714\n",
      "epoch 99; iter: 0; batch classifier loss: 0.442149; batch adversarial loss: 0.608461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431070; batch adversarial loss: 0.507398\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393579; batch adversarial loss: 0.544803\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382108; batch adversarial loss: 0.544250\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438306; batch adversarial loss: 0.572057\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376826; batch adversarial loss: 0.554444\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411942; batch adversarial loss: 0.544745\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328119; batch adversarial loss: 0.470460\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405782; batch adversarial loss: 0.590425\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354085; batch adversarial loss: 0.516732\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355347; batch adversarial loss: 0.636764\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356407; batch adversarial loss: 0.589667\n",
      "epoch 111; iter: 0; batch classifier loss: 0.330321; batch adversarial loss: 0.534829\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410014; batch adversarial loss: 0.571403\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384049; batch adversarial loss: 0.553629\n",
      "epoch 114; iter: 0; batch classifier loss: 0.420516; batch adversarial loss: 0.609469\n",
      "epoch 115; iter: 0; batch classifier loss: 0.443093; batch adversarial loss: 0.525862\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339792; batch adversarial loss: 0.516884\n",
      "epoch 117; iter: 0; batch classifier loss: 0.302196; batch adversarial loss: 0.636886\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376727; batch adversarial loss: 0.526156\n",
      "epoch 119; iter: 0; batch classifier loss: 0.432578; batch adversarial loss: 0.553547\n",
      "epoch 120; iter: 0; batch classifier loss: 0.448659; batch adversarial loss: 0.498430\n",
      "epoch 121; iter: 0; batch classifier loss: 0.325309; batch adversarial loss: 0.535434\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369172; batch adversarial loss: 0.544542\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379687; batch adversarial loss: 0.525947\n",
      "epoch 124; iter: 0; batch classifier loss: 0.421940; batch adversarial loss: 0.562967\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349999; batch adversarial loss: 0.562881\n",
      "epoch 126; iter: 0; batch classifier loss: 0.337574; batch adversarial loss: 0.581404\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383535; batch adversarial loss: 0.480213\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367007; batch adversarial loss: 0.553554\n",
      "epoch 129; iter: 0; batch classifier loss: 0.352456; batch adversarial loss: 0.489338\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342356; batch adversarial loss: 0.535468\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336466; batch adversarial loss: 0.498014\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404903; batch adversarial loss: 0.544467\n",
      "epoch 133; iter: 0; batch classifier loss: 0.304007; batch adversarial loss: 0.516988\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387587; batch adversarial loss: 0.589711\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369772; batch adversarial loss: 0.551936\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389805; batch adversarial loss: 0.627905\n",
      "epoch 137; iter: 0; batch classifier loss: 0.405068; batch adversarial loss: 0.590254\n",
      "epoch 138; iter: 0; batch classifier loss: 0.441286; batch adversarial loss: 0.528600\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344046; batch adversarial loss: 0.499755\n",
      "epoch 140; iter: 0; batch classifier loss: 0.458945; batch adversarial loss: 0.554722\n",
      "epoch 141; iter: 0; batch classifier loss: 0.308623; batch adversarial loss: 0.571925\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340672; batch adversarial loss: 0.517828\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354238; batch adversarial loss: 0.626487\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341726; batch adversarial loss: 0.589764\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334876; batch adversarial loss: 0.607661\n",
      "epoch 146; iter: 0; batch classifier loss: 0.298964; batch adversarial loss: 0.626119\n",
      "epoch 147; iter: 0; batch classifier loss: 0.437379; batch adversarial loss: 0.553719\n",
      "epoch 148; iter: 0; batch classifier loss: 0.372720; batch adversarial loss: 0.499141\n",
      "epoch 149; iter: 0; batch classifier loss: 0.276062; batch adversarial loss: 0.562855\n",
      "epoch 150; iter: 0; batch classifier loss: 0.412347; batch adversarial loss: 0.443491\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334380; batch adversarial loss: 0.581193\n",
      "epoch 152; iter: 0; batch classifier loss: 0.398961; batch adversarial loss: 0.544982\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407833; batch adversarial loss: 0.600785\n",
      "epoch 154; iter: 0; batch classifier loss: 0.439178; batch adversarial loss: 0.610172\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376098; batch adversarial loss: 0.543544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.375764; batch adversarial loss: 0.526058\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368522; batch adversarial loss: 0.611427\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386567; batch adversarial loss: 0.589534\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325950; batch adversarial loss: 0.560920\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375867; batch adversarial loss: 0.515283\n",
      "epoch 161; iter: 0; batch classifier loss: 0.298308; batch adversarial loss: 0.562392\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387441; batch adversarial loss: 0.554968\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348431; batch adversarial loss: 0.526871\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351253; batch adversarial loss: 0.553991\n",
      "epoch 165; iter: 0; batch classifier loss: 0.354021; batch adversarial loss: 0.598692\n",
      "epoch 166; iter: 0; batch classifier loss: 0.256226; batch adversarial loss: 0.598872\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384657; batch adversarial loss: 0.535488\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335104; batch adversarial loss: 0.508041\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339300; batch adversarial loss: 0.553494\n",
      "epoch 170; iter: 0; batch classifier loss: 0.388676; batch adversarial loss: 0.581057\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369057; batch adversarial loss: 0.589758\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391897; batch adversarial loss: 0.453610\n",
      "epoch 173; iter: 0; batch classifier loss: 0.398578; batch adversarial loss: 0.599081\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359821; batch adversarial loss: 0.562388\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306560; batch adversarial loss: 0.571116\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372468; batch adversarial loss: 0.517650\n",
      "epoch 177; iter: 0; batch classifier loss: 0.398120; batch adversarial loss: 0.499403\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339105; batch adversarial loss: 0.526212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.388350; batch adversarial loss: 0.480165\n",
      "epoch 180; iter: 0; batch classifier loss: 0.347012; batch adversarial loss: 0.498370\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337483; batch adversarial loss: 0.488914\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375141; batch adversarial loss: 0.571802\n",
      "epoch 183; iter: 0; batch classifier loss: 0.339221; batch adversarial loss: 0.489566\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379869; batch adversarial loss: 0.562826\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358086; batch adversarial loss: 0.507283\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365466; batch adversarial loss: 0.517131\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343894; batch adversarial loss: 0.618658\n",
      "epoch 188; iter: 0; batch classifier loss: 0.306497; batch adversarial loss: 0.517349\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383268; batch adversarial loss: 0.664194\n",
      "epoch 190; iter: 0; batch classifier loss: 0.404613; batch adversarial loss: 0.553527\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377840; batch adversarial loss: 0.589874\n",
      "epoch 192; iter: 0; batch classifier loss: 0.382683; batch adversarial loss: 0.562967\n",
      "epoch 193; iter: 0; batch classifier loss: 0.339137; batch adversarial loss: 0.507917\n",
      "epoch 194; iter: 0; batch classifier loss: 0.361692; batch adversarial loss: 0.517354\n",
      "epoch 195; iter: 0; batch classifier loss: 0.275832; batch adversarial loss: 0.572141\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354902; batch adversarial loss: 0.543728\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368113; batch adversarial loss: 0.507411\n",
      "epoch 198; iter: 0; batch classifier loss: 0.420061; batch adversarial loss: 0.562804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360483; batch adversarial loss: 0.582178\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689619; batch adversarial loss: 0.612138\n",
      "epoch 1; iter: 0; batch classifier loss: 0.562549; batch adversarial loss: 0.650935\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542311; batch adversarial loss: 0.618370\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624114; batch adversarial loss: 0.615050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.492457; batch adversarial loss: 0.631621\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552981; batch adversarial loss: 0.652677\n",
      "epoch 6; iter: 0; batch classifier loss: 0.530976; batch adversarial loss: 0.637270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591552; batch adversarial loss: 0.632790\n",
      "epoch 8; iter: 0; batch classifier loss: 0.628104; batch adversarial loss: 0.576405\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558756; batch adversarial loss: 0.607886\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487662; batch adversarial loss: 0.564402\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531723; batch adversarial loss: 0.595078\n",
      "epoch 12; iter: 0; batch classifier loss: 0.600681; batch adversarial loss: 0.580821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533626; batch adversarial loss: 0.564228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499649; batch adversarial loss: 0.593235\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540157; batch adversarial loss: 0.510307\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496535; batch adversarial loss: 0.616006\n",
      "epoch 17; iter: 0; batch classifier loss: 0.460770; batch adversarial loss: 0.560314\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456524; batch adversarial loss: 0.573762\n",
      "epoch 19; iter: 0; batch classifier loss: 0.464040; batch adversarial loss: 0.552771\n",
      "epoch 20; iter: 0; batch classifier loss: 0.598205; batch adversarial loss: 0.538775\n",
      "epoch 21; iter: 0; batch classifier loss: 0.441374; batch adversarial loss: 0.603297\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493475; batch adversarial loss: 0.597569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.412322; batch adversarial loss: 0.577663\n",
      "epoch 24; iter: 0; batch classifier loss: 0.538450; batch adversarial loss: 0.598103\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498808; batch adversarial loss: 0.564570\n",
      "epoch 26; iter: 0; batch classifier loss: 0.449339; batch adversarial loss: 0.513945\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453902; batch adversarial loss: 0.503934\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482204; batch adversarial loss: 0.561706\n",
      "epoch 29; iter: 0; batch classifier loss: 0.478093; batch adversarial loss: 0.528090\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456242; batch adversarial loss: 0.527723\n",
      "epoch 31; iter: 0; batch classifier loss: 0.393982; batch adversarial loss: 0.618656\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510810; batch adversarial loss: 0.551207\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455808; batch adversarial loss: 0.518680\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477079; batch adversarial loss: 0.451296\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435796; batch adversarial loss: 0.535401\n",
      "epoch 36; iter: 0; batch classifier loss: 0.396878; batch adversarial loss: 0.483325\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491886; batch adversarial loss: 0.608725\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453690; batch adversarial loss: 0.647299\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419149; batch adversarial loss: 0.462078\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490107; batch adversarial loss: 0.627938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474858; batch adversarial loss: 0.495939\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498669; batch adversarial loss: 0.536249\n",
      "epoch 43; iter: 0; batch classifier loss: 0.368273; batch adversarial loss: 0.489236\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458882; batch adversarial loss: 0.552946\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459186; batch adversarial loss: 0.553069\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382451; batch adversarial loss: 0.518955\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411394; batch adversarial loss: 0.572494\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424818; batch adversarial loss: 0.536058\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428626; batch adversarial loss: 0.599806\n",
      "epoch 50; iter: 0; batch classifier loss: 0.351013; batch adversarial loss: 0.536134\n",
      "epoch 51; iter: 0; batch classifier loss: 0.369616; batch adversarial loss: 0.545211\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407861; batch adversarial loss: 0.616714\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396728; batch adversarial loss: 0.487131\n",
      "epoch 54; iter: 0; batch classifier loss: 0.355873; batch adversarial loss: 0.564232\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378507; batch adversarial loss: 0.432612\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398713; batch adversarial loss: 0.628258\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495071; batch adversarial loss: 0.591904\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389930; batch adversarial loss: 0.508256\n",
      "epoch 59; iter: 0; batch classifier loss: 0.323527; batch adversarial loss: 0.469616\n",
      "epoch 60; iter: 0; batch classifier loss: 0.354061; batch adversarial loss: 0.542580\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463844; batch adversarial loss: 0.556510\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430770; batch adversarial loss: 0.599156\n",
      "epoch 63; iter: 0; batch classifier loss: 0.513220; batch adversarial loss: 0.562985\n",
      "epoch 64; iter: 0; batch classifier loss: 0.456424; batch adversarial loss: 0.553350\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385158; batch adversarial loss: 0.591788\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392958; batch adversarial loss: 0.564026\n",
      "epoch 67; iter: 0; batch classifier loss: 0.497228; batch adversarial loss: 0.564948\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383746; batch adversarial loss: 0.504659\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430789; batch adversarial loss: 0.601195\n",
      "epoch 70; iter: 0; batch classifier loss: 0.375660; batch adversarial loss: 0.544971\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417100; batch adversarial loss: 0.553205\n",
      "epoch 72; iter: 0; batch classifier loss: 0.349343; batch adversarial loss: 0.497762\n",
      "epoch 73; iter: 0; batch classifier loss: 0.475527; batch adversarial loss: 0.497887\n",
      "epoch 74; iter: 0; batch classifier loss: 0.407607; batch adversarial loss: 0.535016\n",
      "epoch 75; iter: 0; batch classifier loss: 0.394998; batch adversarial loss: 0.487743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.294925; batch adversarial loss: 0.479706\n",
      "epoch 77; iter: 0; batch classifier loss: 0.362293; batch adversarial loss: 0.526226\n",
      "epoch 78; iter: 0; batch classifier loss: 0.336562; batch adversarial loss: 0.617353\n",
      "epoch 79; iter: 0; batch classifier loss: 0.331896; batch adversarial loss: 0.526536\n",
      "epoch 80; iter: 0; batch classifier loss: 0.475910; batch adversarial loss: 0.553364\n",
      "epoch 81; iter: 0; batch classifier loss: 0.447749; batch adversarial loss: 0.609410\n",
      "epoch 82; iter: 0; batch classifier loss: 0.349165; batch adversarial loss: 0.600443\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413086; batch adversarial loss: 0.554248\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400631; batch adversarial loss: 0.572378\n",
      "epoch 85; iter: 0; batch classifier loss: 0.339505; batch adversarial loss: 0.572436\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426805; batch adversarial loss: 0.480478\n",
      "epoch 87; iter: 0; batch classifier loss: 0.488115; batch adversarial loss: 0.488506\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422293; batch adversarial loss: 0.543754\n",
      "epoch 89; iter: 0; batch classifier loss: 0.364683; batch adversarial loss: 0.507042\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412473; batch adversarial loss: 0.609851\n",
      "epoch 91; iter: 0; batch classifier loss: 0.420179; batch adversarial loss: 0.534437\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355636; batch adversarial loss: 0.618990\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366478; batch adversarial loss: 0.497842\n",
      "epoch 94; iter: 0; batch classifier loss: 0.339840; batch adversarial loss: 0.545040\n",
      "epoch 95; iter: 0; batch classifier loss: 0.447933; batch adversarial loss: 0.460676\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383811; batch adversarial loss: 0.647074\n",
      "epoch 97; iter: 0; batch classifier loss: 0.457268; batch adversarial loss: 0.507054\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351217; batch adversarial loss: 0.498134\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366316; batch adversarial loss: 0.508018\n",
      "epoch 100; iter: 0; batch classifier loss: 0.335544; batch adversarial loss: 0.497553\n",
      "epoch 101; iter: 0; batch classifier loss: 0.445242; batch adversarial loss: 0.619744\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350111; batch adversarial loss: 0.601492\n",
      "epoch 103; iter: 0; batch classifier loss: 0.321942; batch adversarial loss: 0.489755\n",
      "epoch 104; iter: 0; batch classifier loss: 0.328483; batch adversarial loss: 0.507542\n",
      "epoch 105; iter: 0; batch classifier loss: 0.402987; batch adversarial loss: 0.553941\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387748; batch adversarial loss: 0.516173\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397705; batch adversarial loss: 0.563873\n",
      "epoch 108; iter: 0; batch classifier loss: 0.453575; batch adversarial loss: 0.517047\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384699; batch adversarial loss: 0.544958\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385222; batch adversarial loss: 0.618875\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336187; batch adversarial loss: 0.506719\n",
      "epoch 112; iter: 0; batch classifier loss: 0.453539; batch adversarial loss: 0.489535\n",
      "epoch 113; iter: 0; batch classifier loss: 0.425768; batch adversarial loss: 0.507940\n",
      "epoch 114; iter: 0; batch classifier loss: 0.336621; batch adversarial loss: 0.553262\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341428; batch adversarial loss: 0.507264\n",
      "epoch 116; iter: 0; batch classifier loss: 0.433913; batch adversarial loss: 0.572946\n",
      "epoch 117; iter: 0; batch classifier loss: 0.335373; batch adversarial loss: 0.554409\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405555; batch adversarial loss: 0.526463\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402975; batch adversarial loss: 0.460739\n",
      "epoch 120; iter: 0; batch classifier loss: 0.404360; batch adversarial loss: 0.469231\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348588; batch adversarial loss: 0.497445\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371014; batch adversarial loss: 0.517440\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376440; batch adversarial loss: 0.489179\n",
      "epoch 124; iter: 0; batch classifier loss: 0.400358; batch adversarial loss: 0.535214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.385638; batch adversarial loss: 0.488609\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317396; batch adversarial loss: 0.460103\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368186; batch adversarial loss: 0.470792\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376644; batch adversarial loss: 0.582240\n",
      "epoch 129; iter: 0; batch classifier loss: 0.299954; batch adversarial loss: 0.581486\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359508; batch adversarial loss: 0.581713\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391788; batch adversarial loss: 0.563147\n",
      "epoch 132; iter: 0; batch classifier loss: 0.399838; batch adversarial loss: 0.581581\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372088; batch adversarial loss: 0.469962\n",
      "epoch 134; iter: 0; batch classifier loss: 0.415602; batch adversarial loss: 0.572073\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420156; batch adversarial loss: 0.516876\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425676; batch adversarial loss: 0.543939\n",
      "epoch 137; iter: 0; batch classifier loss: 0.274942; batch adversarial loss: 0.544514\n",
      "epoch 138; iter: 0; batch classifier loss: 0.314079; batch adversarial loss: 0.583055\n",
      "epoch 139; iter: 0; batch classifier loss: 0.462822; batch adversarial loss: 0.591482\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401879; batch adversarial loss: 0.544070\n",
      "epoch 141; iter: 0; batch classifier loss: 0.370503; batch adversarial loss: 0.460812\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380131; batch adversarial loss: 0.507773\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381761; batch adversarial loss: 0.544758\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339281; batch adversarial loss: 0.534949\n",
      "epoch 145; iter: 0; batch classifier loss: 0.424958; batch adversarial loss: 0.572693\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353143; batch adversarial loss: 0.562801\n",
      "epoch 147; iter: 0; batch classifier loss: 0.389219; batch adversarial loss: 0.480024\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396455; batch adversarial loss: 0.525873\n",
      "epoch 149; iter: 0; batch classifier loss: 0.421491; batch adversarial loss: 0.572498\n",
      "epoch 150; iter: 0; batch classifier loss: 0.333343; batch adversarial loss: 0.572146\n",
      "epoch 151; iter: 0; batch classifier loss: 0.402040; batch adversarial loss: 0.563229\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365582; batch adversarial loss: 0.572565\n",
      "epoch 153; iter: 0; batch classifier loss: 0.299935; batch adversarial loss: 0.582313\n",
      "epoch 154; iter: 0; batch classifier loss: 0.310543; batch adversarial loss: 0.554103\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373512; batch adversarial loss: 0.591279\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332313; batch adversarial loss: 0.609621\n",
      "epoch 157; iter: 0; batch classifier loss: 0.449425; batch adversarial loss: 0.525960\n",
      "epoch 158; iter: 0; batch classifier loss: 0.404559; batch adversarial loss: 0.534933\n",
      "epoch 159; iter: 0; batch classifier loss: 0.310140; batch adversarial loss: 0.507515\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348316; batch adversarial loss: 0.544549\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344299; batch adversarial loss: 0.506944\n",
      "epoch 162; iter: 0; batch classifier loss: 0.301186; batch adversarial loss: 0.516569\n",
      "epoch 163; iter: 0; batch classifier loss: 0.395696; batch adversarial loss: 0.544905\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380423; batch adversarial loss: 0.478969\n",
      "epoch 165; iter: 0; batch classifier loss: 0.311441; batch adversarial loss: 0.628768\n",
      "epoch 166; iter: 0; batch classifier loss: 0.298785; batch adversarial loss: 0.498198\n",
      "epoch 167; iter: 0; batch classifier loss: 0.311569; batch adversarial loss: 0.637634\n",
      "epoch 168; iter: 0; batch classifier loss: 0.404205; batch adversarial loss: 0.535154\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321607; batch adversarial loss: 0.525812\n",
      "epoch 170; iter: 0; batch classifier loss: 0.372203; batch adversarial loss: 0.544633\n",
      "epoch 171; iter: 0; batch classifier loss: 0.415220; batch adversarial loss: 0.591169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.325370; batch adversarial loss: 0.544540\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363141; batch adversarial loss: 0.600211\n",
      "epoch 174; iter: 0; batch classifier loss: 0.317397; batch adversarial loss: 0.535215\n",
      "epoch 175; iter: 0; batch classifier loss: 0.386742; batch adversarial loss: 0.600575\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368209; batch adversarial loss: 0.553642\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384507; batch adversarial loss: 0.628220\n",
      "epoch 178; iter: 0; batch classifier loss: 0.405443; batch adversarial loss: 0.525969\n",
      "epoch 179; iter: 0; batch classifier loss: 0.415433; batch adversarial loss: 0.545182\n",
      "epoch 180; iter: 0; batch classifier loss: 0.311483; batch adversarial loss: 0.544243\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325403; batch adversarial loss: 0.525908\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355813; batch adversarial loss: 0.533026\n",
      "epoch 183; iter: 0; batch classifier loss: 0.364720; batch adversarial loss: 0.553290\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328212; batch adversarial loss: 0.517226\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333941; batch adversarial loss: 0.561712\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315560; batch adversarial loss: 0.506834\n",
      "epoch 187; iter: 0; batch classifier loss: 0.398163; batch adversarial loss: 0.608565\n",
      "epoch 188; iter: 0; batch classifier loss: 0.303708; batch adversarial loss: 0.572126\n",
      "epoch 189; iter: 0; batch classifier loss: 0.267045; batch adversarial loss: 0.581326\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366173; batch adversarial loss: 0.535662\n",
      "epoch 191; iter: 0; batch classifier loss: 0.444281; batch adversarial loss: 0.535173\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389938; batch adversarial loss: 0.562397\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375485; batch adversarial loss: 0.534233\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368533; batch adversarial loss: 0.664669\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350766; batch adversarial loss: 0.581874\n",
      "epoch 196; iter: 0; batch classifier loss: 0.431700; batch adversarial loss: 0.534711\n",
      "epoch 197; iter: 0; batch classifier loss: 0.404086; batch adversarial loss: 0.673764\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340701; batch adversarial loss: 0.673553\n",
      "epoch 199; iter: 0; batch classifier loss: 0.353402; batch adversarial loss: 0.544551\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697485; batch adversarial loss: 0.768523\n",
      "epoch 1; iter: 0; batch classifier loss: 0.731829; batch adversarial loss: 0.807629\n",
      "epoch 2; iter: 0; batch classifier loss: 0.781354; batch adversarial loss: 0.768985\n",
      "epoch 3; iter: 0; batch classifier loss: 0.846420; batch adversarial loss: 0.707111\n",
      "epoch 4; iter: 0; batch classifier loss: 0.725854; batch adversarial loss: 0.659707\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532759; batch adversarial loss: 0.625628\n",
      "epoch 6; iter: 0; batch classifier loss: 0.594368; batch adversarial loss: 0.616590\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569578; batch adversarial loss: 0.588245\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566976; batch adversarial loss: 0.585033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539512; batch adversarial loss: 0.616327\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474181; batch adversarial loss: 0.570715\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566956; batch adversarial loss: 0.595005\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522178; batch adversarial loss: 0.622478\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541698; batch adversarial loss: 0.570654\n",
      "epoch 14; iter: 0; batch classifier loss: 0.568100; batch adversarial loss: 0.597242\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499909; batch adversarial loss: 0.594625\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473066; batch adversarial loss: 0.628048\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524138; batch adversarial loss: 0.556379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484899; batch adversarial loss: 0.544011\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507856; batch adversarial loss: 0.584631\n",
      "epoch 20; iter: 0; batch classifier loss: 0.533234; batch adversarial loss: 0.645891\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467125; batch adversarial loss: 0.619214\n",
      "epoch 22; iter: 0; batch classifier loss: 0.574843; batch adversarial loss: 0.562242\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473112; batch adversarial loss: 0.558517\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427571; batch adversarial loss: 0.522085\n",
      "epoch 25; iter: 0; batch classifier loss: 0.556342; batch adversarial loss: 0.539292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448194; batch adversarial loss: 0.504606\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505823; batch adversarial loss: 0.604889\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442098; batch adversarial loss: 0.566587\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430709; batch adversarial loss: 0.549513\n",
      "epoch 30; iter: 0; batch classifier loss: 0.397712; batch adversarial loss: 0.559555\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483264; batch adversarial loss: 0.575035\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428257; batch adversarial loss: 0.648346\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404544; batch adversarial loss: 0.639528\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544595; batch adversarial loss: 0.539398\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424869; batch adversarial loss: 0.528926\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496862; batch adversarial loss: 0.553924\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529022; batch adversarial loss: 0.542527\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451521; batch adversarial loss: 0.551583\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407726; batch adversarial loss: 0.572487\n",
      "epoch 40; iter: 0; batch classifier loss: 0.473121; batch adversarial loss: 0.546385\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466793; batch adversarial loss: 0.550514\n",
      "epoch 42; iter: 0; batch classifier loss: 0.384716; batch adversarial loss: 0.474389\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418308; batch adversarial loss: 0.598561\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410997; batch adversarial loss: 0.476377\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439193; batch adversarial loss: 0.560090\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417597; batch adversarial loss: 0.567760\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461992; batch adversarial loss: 0.544352\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335809; batch adversarial loss: 0.543195\n",
      "epoch 49; iter: 0; batch classifier loss: 0.386522; batch adversarial loss: 0.466375\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438358; batch adversarial loss: 0.429365\n",
      "epoch 51; iter: 0; batch classifier loss: 0.381478; batch adversarial loss: 0.526252\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407127; batch adversarial loss: 0.571779\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381197; batch adversarial loss: 0.563075\n",
      "epoch 54; iter: 0; batch classifier loss: 0.350756; batch adversarial loss: 0.614789\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405107; batch adversarial loss: 0.543702\n",
      "epoch 56; iter: 0; batch classifier loss: 0.406294; batch adversarial loss: 0.612275\n",
      "epoch 57; iter: 0; batch classifier loss: 0.359621; batch adversarial loss: 0.520534\n",
      "epoch 58; iter: 0; batch classifier loss: 0.451542; batch adversarial loss: 0.535051\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435429; batch adversarial loss: 0.506153\n",
      "epoch 60; iter: 0; batch classifier loss: 0.332791; batch adversarial loss: 0.536887\n",
      "epoch 61; iter: 0; batch classifier loss: 0.332890; batch adversarial loss: 0.499931\n",
      "epoch 62; iter: 0; batch classifier loss: 0.367583; batch adversarial loss: 0.524775\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461971; batch adversarial loss: 0.499624\n",
      "epoch 64; iter: 0; batch classifier loss: 0.501786; batch adversarial loss: 0.551930\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436993; batch adversarial loss: 0.512500\n",
      "epoch 66; iter: 0; batch classifier loss: 0.456973; batch adversarial loss: 0.579933\n",
      "epoch 67; iter: 0; batch classifier loss: 0.446776; batch adversarial loss: 0.534814\n",
      "epoch 68; iter: 0; batch classifier loss: 0.414626; batch adversarial loss: 0.517456\n",
      "epoch 69; iter: 0; batch classifier loss: 0.352732; batch adversarial loss: 0.562897\n",
      "epoch 70; iter: 0; batch classifier loss: 0.292083; batch adversarial loss: 0.482805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.381423; batch adversarial loss: 0.543842\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381283; batch adversarial loss: 0.596871\n",
      "epoch 73; iter: 0; batch classifier loss: 0.420172; batch adversarial loss: 0.502200\n",
      "epoch 74; iter: 0; batch classifier loss: 0.366195; batch adversarial loss: 0.563006\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400263; batch adversarial loss: 0.618253\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388879; batch adversarial loss: 0.579622\n",
      "epoch 77; iter: 0; batch classifier loss: 0.455748; batch adversarial loss: 0.542853\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427435; batch adversarial loss: 0.515777\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372314; batch adversarial loss: 0.544448\n",
      "epoch 80; iter: 0; batch classifier loss: 0.349273; batch adversarial loss: 0.464265\n",
      "epoch 81; iter: 0; batch classifier loss: 0.350391; batch adversarial loss: 0.519571\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372419; batch adversarial loss: 0.526875\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403202; batch adversarial loss: 0.554044\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392446; batch adversarial loss: 0.578447\n",
      "epoch 85; iter: 0; batch classifier loss: 0.442165; batch adversarial loss: 0.533297\n",
      "epoch 86; iter: 0; batch classifier loss: 0.331967; batch adversarial loss: 0.497100\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406666; batch adversarial loss: 0.620576\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425094; batch adversarial loss: 0.515814\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401494; batch adversarial loss: 0.544076\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405912; batch adversarial loss: 0.532215\n",
      "epoch 91; iter: 0; batch classifier loss: 0.431276; batch adversarial loss: 0.623291\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419164; batch adversarial loss: 0.503985\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387499; batch adversarial loss: 0.548339\n",
      "epoch 94; iter: 0; batch classifier loss: 0.290290; batch adversarial loss: 0.552016\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384934; batch adversarial loss: 0.587420\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384079; batch adversarial loss: 0.564195\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401196; batch adversarial loss: 0.492427\n",
      "epoch 98; iter: 0; batch classifier loss: 0.435708; batch adversarial loss: 0.466762\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377990; batch adversarial loss: 0.575696\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345068; batch adversarial loss: 0.561689\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335328; batch adversarial loss: 0.556346\n",
      "epoch 102; iter: 0; batch classifier loss: 0.430327; batch adversarial loss: 0.535287\n",
      "epoch 103; iter: 0; batch classifier loss: 0.423383; batch adversarial loss: 0.531535\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362953; batch adversarial loss: 0.490379\n",
      "epoch 105; iter: 0; batch classifier loss: 0.397187; batch adversarial loss: 0.518850\n",
      "epoch 106; iter: 0; batch classifier loss: 0.427975; batch adversarial loss: 0.519151\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397987; batch adversarial loss: 0.578713\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403722; batch adversarial loss: 0.508682\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370235; batch adversarial loss: 0.596997\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395113; batch adversarial loss: 0.580836\n",
      "epoch 111; iter: 0; batch classifier loss: 0.428038; batch adversarial loss: 0.588028\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368439; batch adversarial loss: 0.579176\n",
      "epoch 113; iter: 0; batch classifier loss: 0.410749; batch adversarial loss: 0.538014\n",
      "epoch 114; iter: 0; batch classifier loss: 0.408133; batch adversarial loss: 0.534742\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380154; batch adversarial loss: 0.515067\n",
      "epoch 116; iter: 0; batch classifier loss: 0.307087; batch adversarial loss: 0.579051\n",
      "epoch 117; iter: 0; batch classifier loss: 0.295394; batch adversarial loss: 0.565441\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375698; batch adversarial loss: 0.581566\n",
      "epoch 119; iter: 0; batch classifier loss: 0.290545; batch adversarial loss: 0.589363\n",
      "epoch 120; iter: 0; batch classifier loss: 0.457671; batch adversarial loss: 0.543581\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365079; batch adversarial loss: 0.658555\n",
      "epoch 122; iter: 0; batch classifier loss: 0.447498; batch adversarial loss: 0.616557\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387393; batch adversarial loss: 0.562522\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361415; batch adversarial loss: 0.534466\n",
      "epoch 125; iter: 0; batch classifier loss: 0.492728; batch adversarial loss: 0.516253\n",
      "epoch 126; iter: 0; batch classifier loss: 0.332689; batch adversarial loss: 0.536207\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362107; batch adversarial loss: 0.527341\n",
      "epoch 128; iter: 0; batch classifier loss: 0.439817; batch adversarial loss: 0.573392\n",
      "epoch 129; iter: 0; batch classifier loss: 0.419864; batch adversarial loss: 0.570673\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349527; batch adversarial loss: 0.563948\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336205; batch adversarial loss: 0.553667\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320466; batch adversarial loss: 0.564930\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334480; batch adversarial loss: 0.475034\n",
      "epoch 134; iter: 0; batch classifier loss: 0.325321; batch adversarial loss: 0.608379\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348623; batch adversarial loss: 0.591022\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395843; batch adversarial loss: 0.543125\n",
      "epoch 137; iter: 0; batch classifier loss: 0.338240; batch adversarial loss: 0.570949\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344726; batch adversarial loss: 0.551136\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347178; batch adversarial loss: 0.444896\n",
      "epoch 140; iter: 0; batch classifier loss: 0.394191; batch adversarial loss: 0.590423\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336933; batch adversarial loss: 0.501662\n",
      "epoch 142; iter: 0; batch classifier loss: 0.366006; batch adversarial loss: 0.516344\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381366; batch adversarial loss: 0.584486\n",
      "epoch 144; iter: 0; batch classifier loss: 0.391145; batch adversarial loss: 0.589351\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342098; batch adversarial loss: 0.535741\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383977; batch adversarial loss: 0.573403\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342604; batch adversarial loss: 0.591001\n",
      "epoch 148; iter: 0; batch classifier loss: 0.302267; batch adversarial loss: 0.544286\n",
      "epoch 149; iter: 0; batch classifier loss: 0.416044; batch adversarial loss: 0.623918\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368992; batch adversarial loss: 0.527355\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395175; batch adversarial loss: 0.545511\n",
      "epoch 152; iter: 0; batch classifier loss: 0.270539; batch adversarial loss: 0.586697\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335802; batch adversarial loss: 0.561499\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350381; batch adversarial loss: 0.632208\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392490; batch adversarial loss: 0.556008\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390787; batch adversarial loss: 0.562579\n",
      "epoch 157; iter: 0; batch classifier loss: 0.339716; batch adversarial loss: 0.572532\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319475; batch adversarial loss: 0.489900\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337447; batch adversarial loss: 0.566434\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377743; batch adversarial loss: 0.533198\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374079; batch adversarial loss: 0.499944\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306081; batch adversarial loss: 0.542304\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331264; batch adversarial loss: 0.563483\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375081; batch adversarial loss: 0.473619\n",
      "epoch 165; iter: 0; batch classifier loss: 0.427419; batch adversarial loss: 0.543081\n",
      "epoch 166; iter: 0; batch classifier loss: 0.311718; batch adversarial loss: 0.490010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.369681; batch adversarial loss: 0.455054\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357139; batch adversarial loss: 0.618325\n",
      "epoch 169; iter: 0; batch classifier loss: 0.331741; batch adversarial loss: 0.508728\n",
      "epoch 170; iter: 0; batch classifier loss: 0.431766; batch adversarial loss: 0.506245\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373166; batch adversarial loss: 0.481357\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370269; batch adversarial loss: 0.553420\n",
      "epoch 173; iter: 0; batch classifier loss: 0.347003; batch adversarial loss: 0.644464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.320085; batch adversarial loss: 0.535558\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355256; batch adversarial loss: 0.535434\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366336; batch adversarial loss: 0.606157\n",
      "epoch 177; iter: 0; batch classifier loss: 0.419511; batch adversarial loss: 0.586976\n",
      "epoch 178; iter: 0; batch classifier loss: 0.311354; batch adversarial loss: 0.508156\n",
      "epoch 179; iter: 0; batch classifier loss: 0.402508; batch adversarial loss: 0.534048\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368670; batch adversarial loss: 0.526500\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364176; batch adversarial loss: 0.526239\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370221; batch adversarial loss: 0.524691\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387589; batch adversarial loss: 0.535976\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359071; batch adversarial loss: 0.578737\n",
      "epoch 185; iter: 0; batch classifier loss: 0.394881; batch adversarial loss: 0.533678\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392605; batch adversarial loss: 0.555047\n",
      "epoch 187; iter: 0; batch classifier loss: 0.259267; batch adversarial loss: 0.554250\n",
      "epoch 188; iter: 0; batch classifier loss: 0.393675; batch adversarial loss: 0.628071\n",
      "epoch 189; iter: 0; batch classifier loss: 0.425238; batch adversarial loss: 0.581587\n",
      "epoch 190; iter: 0; batch classifier loss: 0.335967; batch adversarial loss: 0.508917\n",
      "epoch 191; iter: 0; batch classifier loss: 0.402936; batch adversarial loss: 0.517437\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327109; batch adversarial loss: 0.543245\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351231; batch adversarial loss: 0.535656\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369590; batch adversarial loss: 0.597559\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322340; batch adversarial loss: 0.564530\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309563; batch adversarial loss: 0.636536\n",
      "epoch 197; iter: 0; batch classifier loss: 0.275115; batch adversarial loss: 0.669587\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332733; batch adversarial loss: 0.552598\n",
      "epoch 199; iter: 0; batch classifier loss: 0.369861; batch adversarial loss: 0.624569\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696104; batch adversarial loss: 0.880712\n",
      "epoch 1; iter: 0; batch classifier loss: 0.866980; batch adversarial loss: 1.042265\n",
      "epoch 2; iter: 0; batch classifier loss: 0.869154; batch adversarial loss: 0.977223\n",
      "epoch 3; iter: 0; batch classifier loss: 0.875365; batch adversarial loss: 0.908630\n",
      "epoch 4; iter: 0; batch classifier loss: 0.893944; batch adversarial loss: 0.806445\n",
      "epoch 5; iter: 0; batch classifier loss: 0.675506; batch adversarial loss: 0.732003\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592373; batch adversarial loss: 0.709636\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553261; batch adversarial loss: 0.637793\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545755; batch adversarial loss: 0.639927\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531758; batch adversarial loss: 0.623560\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531891; batch adversarial loss: 0.615048\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579575; batch adversarial loss: 0.607376\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538363; batch adversarial loss: 0.616482\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541511; batch adversarial loss: 0.591103\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515587; batch adversarial loss: 0.624795\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543773; batch adversarial loss: 0.587053\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460365; batch adversarial loss: 0.548211\n",
      "epoch 17; iter: 0; batch classifier loss: 0.444810; batch adversarial loss: 0.529845\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518255; batch adversarial loss: 0.563991\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545081; batch adversarial loss: 0.514905\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504078; batch adversarial loss: 0.567211\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477990; batch adversarial loss: 0.500145\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500557; batch adversarial loss: 0.580825\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439482; batch adversarial loss: 0.538598\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467464; batch adversarial loss: 0.501494\n",
      "epoch 25; iter: 0; batch classifier loss: 0.547305; batch adversarial loss: 0.505464\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466619; batch adversarial loss: 0.548644\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465690; batch adversarial loss: 0.572353\n",
      "epoch 28; iter: 0; batch classifier loss: 0.467094; batch adversarial loss: 0.597125\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467151; batch adversarial loss: 0.547834\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486217; batch adversarial loss: 0.547258\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471422; batch adversarial loss: 0.554017\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471396; batch adversarial loss: 0.562540\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445288; batch adversarial loss: 0.632083\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448833; batch adversarial loss: 0.581730\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468721; batch adversarial loss: 0.485548\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441337; batch adversarial loss: 0.470583\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458656; batch adversarial loss: 0.614816\n",
      "epoch 38; iter: 0; batch classifier loss: 0.487926; batch adversarial loss: 0.517787\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399608; batch adversarial loss: 0.562831\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461177; batch adversarial loss: 0.582959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382607; batch adversarial loss: 0.536098\n",
      "epoch 42; iter: 0; batch classifier loss: 0.442381; batch adversarial loss: 0.579342\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423210; batch adversarial loss: 0.635679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.482017; batch adversarial loss: 0.472818\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455255; batch adversarial loss: 0.472475\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503579; batch adversarial loss: 0.534876\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412943; batch adversarial loss: 0.537201\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509619; batch adversarial loss: 0.561477\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419158; batch adversarial loss: 0.498917\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392043; batch adversarial loss: 0.535202\n",
      "epoch 51; iter: 0; batch classifier loss: 0.355126; batch adversarial loss: 0.581741\n",
      "epoch 52; iter: 0; batch classifier loss: 0.569541; batch adversarial loss: 0.572163\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412355; batch adversarial loss: 0.526117\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434231; batch adversarial loss: 0.497062\n",
      "epoch 55; iter: 0; batch classifier loss: 0.452259; batch adversarial loss: 0.507893\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445163; batch adversarial loss: 0.616261\n",
      "epoch 57; iter: 0; batch classifier loss: 0.358885; batch adversarial loss: 0.545399\n",
      "epoch 58; iter: 0; batch classifier loss: 0.473726; batch adversarial loss: 0.573828\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423372; batch adversarial loss: 0.516280\n",
      "epoch 60; iter: 0; batch classifier loss: 0.395191; batch adversarial loss: 0.598354\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403850; batch adversarial loss: 0.499962\n",
      "epoch 62; iter: 0; batch classifier loss: 0.360984; batch adversarial loss: 0.580923\n",
      "epoch 63; iter: 0; batch classifier loss: 0.393910; batch adversarial loss: 0.508603\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406874; batch adversarial loss: 0.562058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.390133; batch adversarial loss: 0.554622\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449131; batch adversarial loss: 0.589699\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444156; batch adversarial loss: 0.564603\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413173; batch adversarial loss: 0.517633\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426121; batch adversarial loss: 0.516110\n",
      "epoch 70; iter: 0; batch classifier loss: 0.316235; batch adversarial loss: 0.519042\n",
      "epoch 71; iter: 0; batch classifier loss: 0.445136; batch adversarial loss: 0.570919\n",
      "epoch 72; iter: 0; batch classifier loss: 0.406811; batch adversarial loss: 0.489386\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377784; batch adversarial loss: 0.562598\n",
      "epoch 74; iter: 0; batch classifier loss: 0.379625; batch adversarial loss: 0.534756\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426112; batch adversarial loss: 0.399403\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398939; batch adversarial loss: 0.552593\n",
      "epoch 77; iter: 0; batch classifier loss: 0.390122; batch adversarial loss: 0.517584\n",
      "epoch 78; iter: 0; batch classifier loss: 0.349562; batch adversarial loss: 0.572228\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367666; batch adversarial loss: 0.525422\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398006; batch adversarial loss: 0.553686\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384735; batch adversarial loss: 0.626400\n",
      "epoch 82; iter: 0; batch classifier loss: 0.391539; batch adversarial loss: 0.562594\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369818; batch adversarial loss: 0.561939\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367186; batch adversarial loss: 0.572146\n",
      "epoch 85; iter: 0; batch classifier loss: 0.533558; batch adversarial loss: 0.570959\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440603; batch adversarial loss: 0.526489\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382055; batch adversarial loss: 0.580466\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406553; batch adversarial loss: 0.625604\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353782; batch adversarial loss: 0.553231\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396971; batch adversarial loss: 0.599633\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380221; batch adversarial loss: 0.526178\n",
      "epoch 92; iter: 0; batch classifier loss: 0.362385; batch adversarial loss: 0.517602\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349227; batch adversarial loss: 0.572105\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424942; batch adversarial loss: 0.517818\n",
      "epoch 95; iter: 0; batch classifier loss: 0.340354; batch adversarial loss: 0.589744\n",
      "epoch 96; iter: 0; batch classifier loss: 0.444354; batch adversarial loss: 0.526554\n",
      "epoch 97; iter: 0; batch classifier loss: 0.380263; batch adversarial loss: 0.471632\n",
      "epoch 98; iter: 0; batch classifier loss: 0.421614; batch adversarial loss: 0.608442\n",
      "epoch 99; iter: 0; batch classifier loss: 0.383863; batch adversarial loss: 0.553304\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345346; batch adversarial loss: 0.563199\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386489; batch adversarial loss: 0.571635\n",
      "epoch 102; iter: 0; batch classifier loss: 0.324725; batch adversarial loss: 0.581319\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372960; batch adversarial loss: 0.571262\n",
      "epoch 104; iter: 0; batch classifier loss: 0.335698; batch adversarial loss: 0.609475\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362761; batch adversarial loss: 0.599952\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359066; batch adversarial loss: 0.490569\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319836; batch adversarial loss: 0.553110\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403247; batch adversarial loss: 0.535988\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423010; batch adversarial loss: 0.563468\n",
      "epoch 110; iter: 0; batch classifier loss: 0.415454; batch adversarial loss: 0.508540\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395996; batch adversarial loss: 0.599549\n",
      "epoch 112; iter: 0; batch classifier loss: 0.311463; batch adversarial loss: 0.572070\n",
      "epoch 113; iter: 0; batch classifier loss: 0.318334; batch adversarial loss: 0.553794\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389298; batch adversarial loss: 0.545310\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343666; batch adversarial loss: 0.580744\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348899; batch adversarial loss: 0.534878\n",
      "epoch 117; iter: 0; batch classifier loss: 0.400595; batch adversarial loss: 0.480795\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361516; batch adversarial loss: 0.517613\n",
      "epoch 119; iter: 0; batch classifier loss: 0.326622; batch adversarial loss: 0.516970\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352809; batch adversarial loss: 0.526091\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351356; batch adversarial loss: 0.480659\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358919; batch adversarial loss: 0.590783\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348240; batch adversarial loss: 0.588866\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361109; batch adversarial loss: 0.526051\n",
      "epoch 125; iter: 0; batch classifier loss: 0.462126; batch adversarial loss: 0.535537\n",
      "epoch 126; iter: 0; batch classifier loss: 0.337287; batch adversarial loss: 0.518380\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340006; batch adversarial loss: 0.599222\n",
      "epoch 128; iter: 0; batch classifier loss: 0.363996; batch adversarial loss: 0.572185\n",
      "epoch 129; iter: 0; batch classifier loss: 0.405566; batch adversarial loss: 0.562421\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387500; batch adversarial loss: 0.580518\n",
      "epoch 131; iter: 0; batch classifier loss: 0.324642; batch adversarial loss: 0.571198\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392466; batch adversarial loss: 0.572695\n",
      "epoch 133; iter: 0; batch classifier loss: 0.315871; batch adversarial loss: 0.562867\n",
      "epoch 134; iter: 0; batch classifier loss: 0.426741; batch adversarial loss: 0.561896\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394802; batch adversarial loss: 0.563242\n",
      "epoch 136; iter: 0; batch classifier loss: 0.412759; batch adversarial loss: 0.517190\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329778; batch adversarial loss: 0.534684\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414573; batch adversarial loss: 0.508368\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347816; batch adversarial loss: 0.562888\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342676; batch adversarial loss: 0.535756\n",
      "epoch 141; iter: 0; batch classifier loss: 0.295842; batch adversarial loss: 0.489649\n",
      "epoch 142; iter: 0; batch classifier loss: 0.290052; batch adversarial loss: 0.571759\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374187; batch adversarial loss: 0.508650\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372804; batch adversarial loss: 0.526891\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398667; batch adversarial loss: 0.581815\n",
      "epoch 146; iter: 0; batch classifier loss: 0.320593; batch adversarial loss: 0.571700\n",
      "epoch 147; iter: 0; batch classifier loss: 0.417077; batch adversarial loss: 0.490239\n",
      "epoch 148; iter: 0; batch classifier loss: 0.388048; batch adversarial loss: 0.544348\n",
      "epoch 149; iter: 0; batch classifier loss: 0.312830; batch adversarial loss: 0.507822\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399419; batch adversarial loss: 0.562308\n",
      "epoch 151; iter: 0; batch classifier loss: 0.318976; batch adversarial loss: 0.498962\n",
      "epoch 152; iter: 0; batch classifier loss: 0.290706; batch adversarial loss: 0.582215\n",
      "epoch 153; iter: 0; batch classifier loss: 0.382419; batch adversarial loss: 0.571571\n",
      "epoch 154; iter: 0; batch classifier loss: 0.386749; batch adversarial loss: 0.517192\n",
      "epoch 155; iter: 0; batch classifier loss: 0.328372; batch adversarial loss: 0.535112\n",
      "epoch 156; iter: 0; batch classifier loss: 0.292819; batch adversarial loss: 0.581056\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399607; batch adversarial loss: 0.508790\n",
      "epoch 158; iter: 0; batch classifier loss: 0.357090; batch adversarial loss: 0.555161\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354983; batch adversarial loss: 0.499081\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348490; batch adversarial loss: 0.571342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.416639; batch adversarial loss: 0.507951\n",
      "epoch 162; iter: 0; batch classifier loss: 0.293639; batch adversarial loss: 0.544093\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402914; batch adversarial loss: 0.489647\n",
      "epoch 164; iter: 0; batch classifier loss: 0.472850; batch adversarial loss: 0.571189\n",
      "epoch 165; iter: 0; batch classifier loss: 0.293329; batch adversarial loss: 0.499180\n",
      "epoch 166; iter: 0; batch classifier loss: 0.390081; batch adversarial loss: 0.535563\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340823; batch adversarial loss: 0.581073\n",
      "epoch 168; iter: 0; batch classifier loss: 0.315137; batch adversarial loss: 0.571381\n",
      "epoch 169; iter: 0; batch classifier loss: 0.286570; batch adversarial loss: 0.535736\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398321; batch adversarial loss: 0.535631\n",
      "epoch 171; iter: 0; batch classifier loss: 0.313307; batch adversarial loss: 0.562991\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379885; batch adversarial loss: 0.526056\n",
      "epoch 173; iter: 0; batch classifier loss: 0.320726; batch adversarial loss: 0.581293\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311816; batch adversarial loss: 0.544333\n",
      "epoch 175; iter: 0; batch classifier loss: 0.386343; batch adversarial loss: 0.536210\n",
      "epoch 176; iter: 0; batch classifier loss: 0.304710; batch adversarial loss: 0.489829\n",
      "epoch 177; iter: 0; batch classifier loss: 0.266538; batch adversarial loss: 0.608872\n",
      "epoch 178; iter: 0; batch classifier loss: 0.385838; batch adversarial loss: 0.534378\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322309; batch adversarial loss: 0.517326\n",
      "epoch 180; iter: 0; batch classifier loss: 0.325347; batch adversarial loss: 0.498999\n",
      "epoch 181; iter: 0; batch classifier loss: 0.356633; batch adversarial loss: 0.580825\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380637; batch adversarial loss: 0.563490\n",
      "epoch 183; iter: 0; batch classifier loss: 0.259604; batch adversarial loss: 0.535252\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381313; batch adversarial loss: 0.616135\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281164; batch adversarial loss: 0.562594\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341594; batch adversarial loss: 0.534980\n",
      "epoch 187; iter: 0; batch classifier loss: 0.402014; batch adversarial loss: 0.580649\n",
      "epoch 188; iter: 0; batch classifier loss: 0.302046; batch adversarial loss: 0.599445\n",
      "epoch 189; iter: 0; batch classifier loss: 0.353614; batch adversarial loss: 0.571762\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364864; batch adversarial loss: 0.598950\n",
      "epoch 191; iter: 0; batch classifier loss: 0.393616; batch adversarial loss: 0.507254\n",
      "epoch 192; iter: 0; batch classifier loss: 0.280432; batch adversarial loss: 0.535209\n",
      "epoch 193; iter: 0; batch classifier loss: 0.369866; batch adversarial loss: 0.563041\n",
      "epoch 194; iter: 0; batch classifier loss: 0.288512; batch adversarial loss: 0.507649\n",
      "epoch 195; iter: 0; batch classifier loss: 0.417352; batch adversarial loss: 0.526390\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316729; batch adversarial loss: 0.553860\n",
      "epoch 197; iter: 0; batch classifier loss: 0.422371; batch adversarial loss: 0.544582\n",
      "epoch 198; iter: 0; batch classifier loss: 0.402386; batch adversarial loss: 0.491058\n",
      "epoch 199; iter: 0; batch classifier loss: 0.373065; batch adversarial loss: 0.616756\n",
      "epoch 0; iter: 0; batch classifier loss: 0.737951; batch adversarial loss: 0.594870\n",
      "epoch 1; iter: 0; batch classifier loss: 0.547114; batch adversarial loss: 0.636008\n",
      "epoch 2; iter: 0; batch classifier loss: 0.644899; batch adversarial loss: 0.658317\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597820; batch adversarial loss: 0.658083\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585676; batch adversarial loss: 0.672277\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561311; batch adversarial loss: 0.631133\n",
      "epoch 6; iter: 0; batch classifier loss: 0.490458; batch adversarial loss: 0.587212\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552705; batch adversarial loss: 0.613608\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542871; batch adversarial loss: 0.614683\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547491; batch adversarial loss: 0.564102\n",
      "epoch 10; iter: 0; batch classifier loss: 0.624439; batch adversarial loss: 0.544214\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490093; batch adversarial loss: 0.621831\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539820; batch adversarial loss: 0.603545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525592; batch adversarial loss: 0.563140\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591144; batch adversarial loss: 0.556077\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524781; batch adversarial loss: 0.542764\n",
      "epoch 16; iter: 0; batch classifier loss: 0.567412; batch adversarial loss: 0.585668\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506830; batch adversarial loss: 0.477359\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513744; batch adversarial loss: 0.556902\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491516; batch adversarial loss: 0.531165\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543380; batch adversarial loss: 0.541718\n",
      "epoch 21; iter: 0; batch classifier loss: 0.603392; batch adversarial loss: 0.591002\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516232; batch adversarial loss: 0.569370\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493413; batch adversarial loss: 0.556383\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511387; batch adversarial loss: 0.511673\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488475; batch adversarial loss: 0.514492\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448011; batch adversarial loss: 0.569792\n",
      "epoch 27; iter: 0; batch classifier loss: 0.422244; batch adversarial loss: 0.545983\n",
      "epoch 28; iter: 0; batch classifier loss: 0.535779; batch adversarial loss: 0.571167\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474873; batch adversarial loss: 0.492010\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461299; batch adversarial loss: 0.516574\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429193; batch adversarial loss: 0.526006\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431575; batch adversarial loss: 0.518583\n",
      "epoch 33; iter: 0; batch classifier loss: 0.417311; batch adversarial loss: 0.489608\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443880; batch adversarial loss: 0.571613\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449165; batch adversarial loss: 0.481270\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496177; batch adversarial loss: 0.534710\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429278; batch adversarial loss: 0.571785\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424165; batch adversarial loss: 0.535701\n",
      "epoch 39; iter: 0; batch classifier loss: 0.385345; batch adversarial loss: 0.563035\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468526; batch adversarial loss: 0.638356\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493256; batch adversarial loss: 0.583276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433257; batch adversarial loss: 0.535418\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450007; batch adversarial loss: 0.525919\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470563; batch adversarial loss: 0.563550\n",
      "epoch 45; iter: 0; batch classifier loss: 0.312902; batch adversarial loss: 0.495499\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392434; batch adversarial loss: 0.498074\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383629; batch adversarial loss: 0.592689\n",
      "epoch 48; iter: 0; batch classifier loss: 0.384368; batch adversarial loss: 0.516130\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405250; batch adversarial loss: 0.592253\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412153; batch adversarial loss: 0.619587\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447193; batch adversarial loss: 0.563370\n",
      "epoch 52; iter: 0; batch classifier loss: 0.484047; batch adversarial loss: 0.544285\n",
      "epoch 53; iter: 0; batch classifier loss: 0.366319; batch adversarial loss: 0.563144\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395123; batch adversarial loss: 0.581797\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437968; batch adversarial loss: 0.518030\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425127; batch adversarial loss: 0.544800\n",
      "epoch 57; iter: 0; batch classifier loss: 0.385332; batch adversarial loss: 0.609774\n",
      "epoch 58; iter: 0; batch classifier loss: 0.519362; batch adversarial loss: 0.573349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.361994; batch adversarial loss: 0.573372\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435690; batch adversarial loss: 0.553503\n",
      "epoch 61; iter: 0; batch classifier loss: 0.479272; batch adversarial loss: 0.516496\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399335; batch adversarial loss: 0.583417\n",
      "epoch 63; iter: 0; batch classifier loss: 0.335514; batch adversarial loss: 0.572080\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435782; batch adversarial loss: 0.470279\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380993; batch adversarial loss: 0.533518\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435864; batch adversarial loss: 0.403371\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430882; batch adversarial loss: 0.655868\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364301; batch adversarial loss: 0.559380\n",
      "epoch 69; iter: 0; batch classifier loss: 0.398222; batch adversarial loss: 0.495479\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412893; batch adversarial loss: 0.462789\n",
      "epoch 71; iter: 0; batch classifier loss: 0.443615; batch adversarial loss: 0.522305\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404381; batch adversarial loss: 0.583912\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425654; batch adversarial loss: 0.507426\n",
      "epoch 74; iter: 0; batch classifier loss: 0.331337; batch adversarial loss: 0.467933\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426063; batch adversarial loss: 0.471502\n",
      "epoch 76; iter: 0; batch classifier loss: 0.323961; batch adversarial loss: 0.588603\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393902; batch adversarial loss: 0.514633\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389298; batch adversarial loss: 0.578940\n",
      "epoch 79; iter: 0; batch classifier loss: 0.336714; batch adversarial loss: 0.553657\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393602; batch adversarial loss: 0.584990\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422706; batch adversarial loss: 0.546611\n",
      "epoch 82; iter: 0; batch classifier loss: 0.426856; batch adversarial loss: 0.566089\n",
      "epoch 83; iter: 0; batch classifier loss: 0.348204; batch adversarial loss: 0.496116\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418671; batch adversarial loss: 0.545274\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346876; batch adversarial loss: 0.486322\n",
      "epoch 86; iter: 0; batch classifier loss: 0.465231; batch adversarial loss: 0.533744\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366053; batch adversarial loss: 0.563117\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351076; batch adversarial loss: 0.544692\n",
      "epoch 89; iter: 0; batch classifier loss: 0.337946; batch adversarial loss: 0.551879\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435785; batch adversarial loss: 0.535817\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404777; batch adversarial loss: 0.592918\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405520; batch adversarial loss: 0.478896\n",
      "epoch 93; iter: 0; batch classifier loss: 0.426172; batch adversarial loss: 0.544051\n",
      "epoch 94; iter: 0; batch classifier loss: 0.497277; batch adversarial loss: 0.525917\n",
      "epoch 95; iter: 0; batch classifier loss: 0.342634; batch adversarial loss: 0.506192\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396483; batch adversarial loss: 0.612149\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420481; batch adversarial loss: 0.582631\n",
      "epoch 98; iter: 0; batch classifier loss: 0.419002; batch adversarial loss: 0.583220\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358728; batch adversarial loss: 0.572678\n",
      "epoch 100; iter: 0; batch classifier loss: 0.363976; batch adversarial loss: 0.534397\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411200; batch adversarial loss: 0.506877\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349413; batch adversarial loss: 0.525220\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385528; batch adversarial loss: 0.563827\n",
      "epoch 104; iter: 0; batch classifier loss: 0.379027; batch adversarial loss: 0.544764\n",
      "epoch 105; iter: 0; batch classifier loss: 0.390704; batch adversarial loss: 0.621101\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387976; batch adversarial loss: 0.554467\n",
      "epoch 107; iter: 0; batch classifier loss: 0.429322; batch adversarial loss: 0.448864\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377736; batch adversarial loss: 0.535089\n",
      "epoch 109; iter: 0; batch classifier loss: 0.298399; batch adversarial loss: 0.602351\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392507; batch adversarial loss: 0.554262\n",
      "epoch 111; iter: 0; batch classifier loss: 0.302747; batch adversarial loss: 0.621126\n",
      "epoch 112; iter: 0; batch classifier loss: 0.333390; batch adversarial loss: 0.506497\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413526; batch adversarial loss: 0.572739\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350086; batch adversarial loss: 0.564198\n",
      "epoch 115; iter: 0; batch classifier loss: 0.514592; batch adversarial loss: 0.525809\n",
      "epoch 116; iter: 0; batch classifier loss: 0.415045; batch adversarial loss: 0.506258\n",
      "epoch 117; iter: 0; batch classifier loss: 0.380494; batch adversarial loss: 0.458877\n",
      "epoch 118; iter: 0; batch classifier loss: 0.364187; batch adversarial loss: 0.611289\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404748; batch adversarial loss: 0.525094\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364916; batch adversarial loss: 0.506325\n",
      "epoch 121; iter: 0; batch classifier loss: 0.372408; batch adversarial loss: 0.610810\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377010; batch adversarial loss: 0.544248\n",
      "epoch 123; iter: 0; batch classifier loss: 0.337736; batch adversarial loss: 0.468595\n",
      "epoch 124; iter: 0; batch classifier loss: 0.389376; batch adversarial loss: 0.544346\n",
      "epoch 125; iter: 0; batch classifier loss: 0.403296; batch adversarial loss: 0.554540\n",
      "epoch 126; iter: 0; batch classifier loss: 0.448101; batch adversarial loss: 0.582948\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374778; batch adversarial loss: 0.563087\n",
      "epoch 128; iter: 0; batch classifier loss: 0.323750; batch adversarial loss: 0.544567\n",
      "epoch 129; iter: 0; batch classifier loss: 0.427932; batch adversarial loss: 0.506835\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385437; batch adversarial loss: 0.620761\n",
      "epoch 131; iter: 0; batch classifier loss: 0.284197; batch adversarial loss: 0.534417\n",
      "epoch 132; iter: 0; batch classifier loss: 0.463575; batch adversarial loss: 0.506564\n",
      "epoch 133; iter: 0; batch classifier loss: 0.285659; batch adversarial loss: 0.515917\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384686; batch adversarial loss: 0.554255\n",
      "epoch 135; iter: 0; batch classifier loss: 0.379442; batch adversarial loss: 0.496880\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385382; batch adversarial loss: 0.506428\n",
      "epoch 137; iter: 0; batch classifier loss: 0.319706; batch adversarial loss: 0.592539\n",
      "epoch 138; iter: 0; batch classifier loss: 0.263684; batch adversarial loss: 0.515946\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328941; batch adversarial loss: 0.468397\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389499; batch adversarial loss: 0.602010\n",
      "epoch 141; iter: 0; batch classifier loss: 0.453727; batch adversarial loss: 0.630968\n",
      "epoch 142; iter: 0; batch classifier loss: 0.357613; batch adversarial loss: 0.563576\n",
      "epoch 143; iter: 0; batch classifier loss: 0.268601; batch adversarial loss: 0.525518\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350043; batch adversarial loss: 0.545040\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377905; batch adversarial loss: 0.506410\n",
      "epoch 146; iter: 0; batch classifier loss: 0.450674; batch adversarial loss: 0.601592\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354219; batch adversarial loss: 0.487253\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403576; batch adversarial loss: 0.525833\n",
      "epoch 149; iter: 0; batch classifier loss: 0.301426; batch adversarial loss: 0.582766\n",
      "epoch 150; iter: 0; batch classifier loss: 0.416555; batch adversarial loss: 0.506228\n",
      "epoch 151; iter: 0; batch classifier loss: 0.398637; batch adversarial loss: 0.572728\n",
      "epoch 152; iter: 0; batch classifier loss: 0.381333; batch adversarial loss: 0.554430\n",
      "epoch 153; iter: 0; batch classifier loss: 0.297798; batch adversarial loss: 0.534913\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337052; batch adversarial loss: 0.496820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.414135; batch adversarial loss: 0.544591\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359980; batch adversarial loss: 0.515909\n",
      "epoch 157; iter: 0; batch classifier loss: 0.288105; batch adversarial loss: 0.515562\n",
      "epoch 158; iter: 0; batch classifier loss: 0.295066; batch adversarial loss: 0.496637\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377695; batch adversarial loss: 0.515855\n",
      "epoch 160; iter: 0; batch classifier loss: 0.465658; batch adversarial loss: 0.592031\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351698; batch adversarial loss: 0.525608\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327002; batch adversarial loss: 0.554697\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326671; batch adversarial loss: 0.525813\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333386; batch adversarial loss: 0.497212\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327004; batch adversarial loss: 0.506317\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370961; batch adversarial loss: 0.554820\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345366; batch adversarial loss: 0.515702\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308623; batch adversarial loss: 0.477913\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356567; batch adversarial loss: 0.582191\n",
      "epoch 170; iter: 0; batch classifier loss: 0.437311; batch adversarial loss: 0.573929\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380149; batch adversarial loss: 0.534541\n",
      "epoch 172; iter: 0; batch classifier loss: 0.339541; batch adversarial loss: 0.553500\n",
      "epoch 173; iter: 0; batch classifier loss: 0.394010; batch adversarial loss: 0.515440\n",
      "epoch 174; iter: 0; batch classifier loss: 0.424749; batch adversarial loss: 0.468704\n",
      "epoch 175; iter: 0; batch classifier loss: 0.285125; batch adversarial loss: 0.535419\n",
      "epoch 176; iter: 0; batch classifier loss: 0.390042; batch adversarial loss: 0.516523\n",
      "epoch 177; iter: 0; batch classifier loss: 0.469593; batch adversarial loss: 0.487818\n",
      "epoch 178; iter: 0; batch classifier loss: 0.348955; batch adversarial loss: 0.497469\n",
      "epoch 179; iter: 0; batch classifier loss: 0.438148; batch adversarial loss: 0.515794\n",
      "epoch 180; iter: 0; batch classifier loss: 0.314447; batch adversarial loss: 0.487388\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320214; batch adversarial loss: 0.497313\n",
      "epoch 182; iter: 0; batch classifier loss: 0.395818; batch adversarial loss: 0.477901\n",
      "epoch 183; iter: 0; batch classifier loss: 0.404410; batch adversarial loss: 0.486995\n",
      "epoch 184; iter: 0; batch classifier loss: 0.400476; batch adversarial loss: 0.525440\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338014; batch adversarial loss: 0.535507\n",
      "epoch 186; iter: 0; batch classifier loss: 0.325921; batch adversarial loss: 0.515558\n",
      "epoch 187; iter: 0; batch classifier loss: 0.397089; batch adversarial loss: 0.592153\n",
      "epoch 188; iter: 0; batch classifier loss: 0.398429; batch adversarial loss: 0.497006\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311222; batch adversarial loss: 0.563265\n",
      "epoch 190; iter: 0; batch classifier loss: 0.315688; batch adversarial loss: 0.525302\n",
      "epoch 191; iter: 0; batch classifier loss: 0.399794; batch adversarial loss: 0.440407\n",
      "epoch 192; iter: 0; batch classifier loss: 0.316610; batch adversarial loss: 0.582491\n",
      "epoch 193; iter: 0; batch classifier loss: 0.339773; batch adversarial loss: 0.525282\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340162; batch adversarial loss: 0.516012\n",
      "epoch 195; iter: 0; batch classifier loss: 0.318838; batch adversarial loss: 0.582943\n",
      "epoch 196; iter: 0; batch classifier loss: 0.337209; batch adversarial loss: 0.582362\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396504; batch adversarial loss: 0.592834\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383979; batch adversarial loss: 0.535131\n",
      "epoch 199; iter: 0; batch classifier loss: 0.347545; batch adversarial loss: 0.486853\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697407; batch adversarial loss: 0.700911\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601398; batch adversarial loss: 0.675768\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583372; batch adversarial loss: 0.654605\n",
      "epoch 3; iter: 0; batch classifier loss: 0.639786; batch adversarial loss: 0.624496\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598587; batch adversarial loss: 0.603293\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593964; batch adversarial loss: 0.579420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585253; batch adversarial loss: 0.548096\n",
      "epoch 7; iter: 0; batch classifier loss: 0.609034; batch adversarial loss: 0.589602\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572122; batch adversarial loss: 0.582964\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524615; batch adversarial loss: 0.615595\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524842; batch adversarial loss: 0.572309\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518561; batch adversarial loss: 0.634786\n",
      "epoch 12; iter: 0; batch classifier loss: 0.632777; batch adversarial loss: 0.603753\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539938; batch adversarial loss: 0.596941\n",
      "epoch 14; iter: 0; batch classifier loss: 0.577224; batch adversarial loss: 0.569850\n",
      "epoch 15; iter: 0; batch classifier loss: 0.603284; batch adversarial loss: 0.607005\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484979; batch adversarial loss: 0.583405\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547875; batch adversarial loss: 0.575009\n",
      "epoch 18; iter: 0; batch classifier loss: 0.565778; batch adversarial loss: 0.563282\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536113; batch adversarial loss: 0.461777\n",
      "epoch 20; iter: 0; batch classifier loss: 0.545226; batch adversarial loss: 0.531904\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439963; batch adversarial loss: 0.564554\n",
      "epoch 22; iter: 0; batch classifier loss: 0.510817; batch adversarial loss: 0.529039\n",
      "epoch 23; iter: 0; batch classifier loss: 0.543867; batch adversarial loss: 0.579016\n",
      "epoch 24; iter: 0; batch classifier loss: 0.433482; batch adversarial loss: 0.511693\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525500; batch adversarial loss: 0.529656\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455030; batch adversarial loss: 0.497424\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470069; batch adversarial loss: 0.573276\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475598; batch adversarial loss: 0.572225\n",
      "epoch 29; iter: 0; batch classifier loss: 0.395228; batch adversarial loss: 0.529061\n",
      "epoch 30; iter: 0; batch classifier loss: 0.420046; batch adversarial loss: 0.561280\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497661; batch adversarial loss: 0.547064\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452502; batch adversarial loss: 0.526058\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478805; batch adversarial loss: 0.597584\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496780; batch adversarial loss: 0.510878\n",
      "epoch 35; iter: 0; batch classifier loss: 0.547104; batch adversarial loss: 0.581546\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415798; batch adversarial loss: 0.535857\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444465; batch adversarial loss: 0.545096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420200; batch adversarial loss: 0.544447\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463217; batch adversarial loss: 0.482067\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507290; batch adversarial loss: 0.623746\n",
      "epoch 41; iter: 0; batch classifier loss: 0.490628; batch adversarial loss: 0.553636\n",
      "epoch 42; iter: 0; batch classifier loss: 0.508335; batch adversarial loss: 0.571674\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438266; batch adversarial loss: 0.552128\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424021; batch adversarial loss: 0.552468\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472577; batch adversarial loss: 0.562785\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476247; batch adversarial loss: 0.516586\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449727; batch adversarial loss: 0.582062\n",
      "epoch 48; iter: 0; batch classifier loss: 0.356215; batch adversarial loss: 0.571987\n",
      "epoch 49; iter: 0; batch classifier loss: 0.453123; batch adversarial loss: 0.561017\n",
      "epoch 50; iter: 0; batch classifier loss: 0.379649; batch adversarial loss: 0.555054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.560791; batch adversarial loss: 0.553974\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471970; batch adversarial loss: 0.518237\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437452; batch adversarial loss: 0.518072\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435839; batch adversarial loss: 0.553675\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411190; batch adversarial loss: 0.535536\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441157; batch adversarial loss: 0.517445\n",
      "epoch 57; iter: 0; batch classifier loss: 0.498482; batch adversarial loss: 0.581227\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458898; batch adversarial loss: 0.580548\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439558; batch adversarial loss: 0.608064\n",
      "epoch 60; iter: 0; batch classifier loss: 0.340551; batch adversarial loss: 0.571792\n",
      "epoch 61; iter: 0; batch classifier loss: 0.501958; batch adversarial loss: 0.571944\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398331; batch adversarial loss: 0.571762\n",
      "epoch 63; iter: 0; batch classifier loss: 0.350036; batch adversarial loss: 0.617526\n",
      "epoch 64; iter: 0; batch classifier loss: 0.448576; batch adversarial loss: 0.462857\n",
      "epoch 65; iter: 0; batch classifier loss: 0.501878; batch adversarial loss: 0.635453\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437313; batch adversarial loss: 0.480912\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436444; batch adversarial loss: 0.552295\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388275; batch adversarial loss: 0.524949\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395881; batch adversarial loss: 0.544854\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399174; batch adversarial loss: 0.515523\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370458; batch adversarial loss: 0.535895\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365138; batch adversarial loss: 0.574037\n",
      "epoch 73; iter: 0; batch classifier loss: 0.454135; batch adversarial loss: 0.535113\n",
      "epoch 74; iter: 0; batch classifier loss: 0.442954; batch adversarial loss: 0.580867\n",
      "epoch 75; iter: 0; batch classifier loss: 0.450221; batch adversarial loss: 0.635857\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387432; batch adversarial loss: 0.527585\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426425; batch adversarial loss: 0.571879\n",
      "epoch 78; iter: 0; batch classifier loss: 0.345029; batch adversarial loss: 0.644750\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402727; batch adversarial loss: 0.535673\n",
      "epoch 80; iter: 0; batch classifier loss: 0.465515; batch adversarial loss: 0.543383\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423696; batch adversarial loss: 0.554622\n",
      "epoch 82; iter: 0; batch classifier loss: 0.449875; batch adversarial loss: 0.590387\n",
      "epoch 83; iter: 0; batch classifier loss: 0.460136; batch adversarial loss: 0.462274\n",
      "epoch 84; iter: 0; batch classifier loss: 0.518775; batch adversarial loss: 0.572203\n",
      "epoch 85; iter: 0; batch classifier loss: 0.448209; batch adversarial loss: 0.580979\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356371; batch adversarial loss: 0.592507\n",
      "epoch 87; iter: 0; batch classifier loss: 0.445160; batch adversarial loss: 0.608542\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381015; batch adversarial loss: 0.535736\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381384; batch adversarial loss: 0.633924\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394764; batch adversarial loss: 0.571754\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417007; batch adversarial loss: 0.589255\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384455; batch adversarial loss: 0.572127\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387819; batch adversarial loss: 0.598732\n",
      "epoch 94; iter: 0; batch classifier loss: 0.420494; batch adversarial loss: 0.516729\n",
      "epoch 95; iter: 0; batch classifier loss: 0.450313; batch adversarial loss: 0.553339\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410161; batch adversarial loss: 0.544430\n",
      "epoch 97; iter: 0; batch classifier loss: 0.463876; batch adversarial loss: 0.480897\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439318; batch adversarial loss: 0.535610\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351802; batch adversarial loss: 0.562175\n",
      "epoch 100; iter: 0; batch classifier loss: 0.325089; batch adversarial loss: 0.563259\n",
      "epoch 101; iter: 0; batch classifier loss: 0.361213; batch adversarial loss: 0.571261\n",
      "epoch 102; iter: 0; batch classifier loss: 0.346151; batch adversarial loss: 0.608248\n",
      "epoch 103; iter: 0; batch classifier loss: 0.340444; batch adversarial loss: 0.626126\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354847; batch adversarial loss: 0.517503\n",
      "epoch 105; iter: 0; batch classifier loss: 0.443459; batch adversarial loss: 0.544868\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390301; batch adversarial loss: 0.526128\n",
      "epoch 107; iter: 0; batch classifier loss: 0.462601; batch adversarial loss: 0.618083\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395517; batch adversarial loss: 0.545212\n",
      "epoch 109; iter: 0; batch classifier loss: 0.390328; batch adversarial loss: 0.536358\n",
      "epoch 110; iter: 0; batch classifier loss: 0.418868; batch adversarial loss: 0.463359\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409892; batch adversarial loss: 0.462442\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396334; batch adversarial loss: 0.553743\n",
      "epoch 113; iter: 0; batch classifier loss: 0.436848; batch adversarial loss: 0.479998\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401495; batch adversarial loss: 0.589653\n",
      "epoch 115; iter: 0; batch classifier loss: 0.429230; batch adversarial loss: 0.506200\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385251; batch adversarial loss: 0.536244\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358408; batch adversarial loss: 0.589473\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383881; batch adversarial loss: 0.636706\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350877; batch adversarial loss: 0.599003\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360868; batch adversarial loss: 0.544505\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380956; batch adversarial loss: 0.534900\n",
      "epoch 122; iter: 0; batch classifier loss: 0.438421; batch adversarial loss: 0.507096\n",
      "epoch 123; iter: 0; batch classifier loss: 0.495128; batch adversarial loss: 0.545867\n",
      "epoch 124; iter: 0; batch classifier loss: 0.322009; batch adversarial loss: 0.480531\n",
      "epoch 125; iter: 0; batch classifier loss: 0.293130; batch adversarial loss: 0.560523\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351941; batch adversarial loss: 0.516614\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340648; batch adversarial loss: 0.527673\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402779; batch adversarial loss: 0.589261\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370828; batch adversarial loss: 0.590381\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413310; batch adversarial loss: 0.616781\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392322; batch adversarial loss: 0.516273\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352474; batch adversarial loss: 0.554309\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376424; batch adversarial loss: 0.617822\n",
      "epoch 134; iter: 0; batch classifier loss: 0.323961; batch adversarial loss: 0.581439\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373802; batch adversarial loss: 0.534847\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370277; batch adversarial loss: 0.543155\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366051; batch adversarial loss: 0.561439\n",
      "epoch 138; iter: 0; batch classifier loss: 0.328775; batch adversarial loss: 0.563685\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360342; batch adversarial loss: 0.569613\n",
      "epoch 140; iter: 0; batch classifier loss: 0.281845; batch adversarial loss: 0.472616\n",
      "epoch 141; iter: 0; batch classifier loss: 0.385357; batch adversarial loss: 0.500025\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341841; batch adversarial loss: 0.527133\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358227; batch adversarial loss: 0.562285\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357195; batch adversarial loss: 0.544813\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362521; batch adversarial loss: 0.580606\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382744; batch adversarial loss: 0.489597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.419731; batch adversarial loss: 0.481584\n",
      "epoch 148; iter: 0; batch classifier loss: 0.409003; batch adversarial loss: 0.571872\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366266; batch adversarial loss: 0.545079\n",
      "epoch 150; iter: 0; batch classifier loss: 0.454372; batch adversarial loss: 0.544984\n",
      "epoch 151; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.645383\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386860; batch adversarial loss: 0.526369\n",
      "epoch 153; iter: 0; batch classifier loss: 0.306902; batch adversarial loss: 0.534953\n",
      "epoch 154; iter: 0; batch classifier loss: 0.435461; batch adversarial loss: 0.564131\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360144; batch adversarial loss: 0.553910\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363917; batch adversarial loss: 0.581703\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349281; batch adversarial loss: 0.498697\n",
      "epoch 158; iter: 0; batch classifier loss: 0.310541; batch adversarial loss: 0.544307\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383493; batch adversarial loss: 0.571914\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357789; batch adversarial loss: 0.571196\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369157; batch adversarial loss: 0.498238\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373353; batch adversarial loss: 0.563108\n",
      "epoch 163; iter: 0; batch classifier loss: 0.414753; batch adversarial loss: 0.525374\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337996; batch adversarial loss: 0.581278\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353785; batch adversarial loss: 0.654188\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333028; batch adversarial loss: 0.426002\n",
      "epoch 167; iter: 0; batch classifier loss: 0.453543; batch adversarial loss: 0.544858\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353645; batch adversarial loss: 0.488835\n",
      "epoch 169; iter: 0; batch classifier loss: 0.482046; batch adversarial loss: 0.526353\n",
      "epoch 170; iter: 0; batch classifier loss: 0.357544; batch adversarial loss: 0.581031\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374858; batch adversarial loss: 0.508416\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391723; batch adversarial loss: 0.418233\n",
      "epoch 173; iter: 0; batch classifier loss: 0.417558; batch adversarial loss: 0.535540\n",
      "epoch 174; iter: 0; batch classifier loss: 0.440670; batch adversarial loss: 0.535516\n",
      "epoch 175; iter: 0; batch classifier loss: 0.406396; batch adversarial loss: 0.554792\n",
      "epoch 176; iter: 0; batch classifier loss: 0.401533; batch adversarial loss: 0.562238\n",
      "epoch 177; iter: 0; batch classifier loss: 0.461545; batch adversarial loss: 0.480927\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337871; batch adversarial loss: 0.563298\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362356; batch adversarial loss: 0.535788\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396132; batch adversarial loss: 0.463503\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360182; batch adversarial loss: 0.481311\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358708; batch adversarial loss: 0.571764\n",
      "epoch 183; iter: 0; batch classifier loss: 0.362365; batch adversarial loss: 0.507750\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416044; batch adversarial loss: 0.598890\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330900; batch adversarial loss: 0.517381\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340317; batch adversarial loss: 0.562036\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319092; batch adversarial loss: 0.517285\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379531; batch adversarial loss: 0.471633\n",
      "epoch 189; iter: 0; batch classifier loss: 0.329236; batch adversarial loss: 0.562884\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390930; batch adversarial loss: 0.635570\n",
      "epoch 191; iter: 0; batch classifier loss: 0.317082; batch adversarial loss: 0.626314\n",
      "epoch 192; iter: 0; batch classifier loss: 0.309340; batch adversarial loss: 0.535783\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325129; batch adversarial loss: 0.589304\n",
      "epoch 194; iter: 0; batch classifier loss: 0.414443; batch adversarial loss: 0.564218\n",
      "epoch 195; iter: 0; batch classifier loss: 0.394980; batch adversarial loss: 0.461786\n",
      "epoch 196; iter: 0; batch classifier loss: 0.368622; batch adversarial loss: 0.517710\n",
      "epoch 197; iter: 0; batch classifier loss: 0.391401; batch adversarial loss: 0.498988\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333943; batch adversarial loss: 0.516816\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396269; batch adversarial loss: 0.517652\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711473; batch adversarial loss: 0.668693\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592324; batch adversarial loss: 0.663538\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624472; batch adversarial loss: 0.637669\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542663; batch adversarial loss: 0.643128\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552418; batch adversarial loss: 0.650535\n",
      "epoch 5; iter: 0; batch classifier loss: 0.491625; batch adversarial loss: 0.622352\n",
      "epoch 6; iter: 0; batch classifier loss: 0.444490; batch adversarial loss: 0.638507\n",
      "epoch 7; iter: 0; batch classifier loss: 0.676995; batch adversarial loss: 0.634860\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613049; batch adversarial loss: 0.595968\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549658; batch adversarial loss: 0.572374\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544702; batch adversarial loss: 0.577806\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588868; batch adversarial loss: 0.585223\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516805; batch adversarial loss: 0.567258\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537654; batch adversarial loss: 0.539284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529268; batch adversarial loss: 0.590265\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498825; batch adversarial loss: 0.609492\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489348; batch adversarial loss: 0.549672\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537424; batch adversarial loss: 0.617356\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444354; batch adversarial loss: 0.639515\n",
      "epoch 19; iter: 0; batch classifier loss: 0.582939; batch adversarial loss: 0.540394\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505933; batch adversarial loss: 0.587098\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510984; batch adversarial loss: 0.532499\n",
      "epoch 22; iter: 0; batch classifier loss: 0.558702; batch adversarial loss: 0.580610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495937; batch adversarial loss: 0.533192\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455222; batch adversarial loss: 0.568644\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461123; batch adversarial loss: 0.601026\n",
      "epoch 26; iter: 0; batch classifier loss: 0.419412; batch adversarial loss: 0.613908\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505072; batch adversarial loss: 0.581257\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489443; batch adversarial loss: 0.563041\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485538; batch adversarial loss: 0.525430\n",
      "epoch 30; iter: 0; batch classifier loss: 0.391677; batch adversarial loss: 0.533462\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476442; batch adversarial loss: 0.555399\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525920; batch adversarial loss: 0.563574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.504370; batch adversarial loss: 0.560471\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462315; batch adversarial loss: 0.558732\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437954; batch adversarial loss: 0.585720\n",
      "epoch 36; iter: 0; batch classifier loss: 0.387906; batch adversarial loss: 0.538558\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479265; batch adversarial loss: 0.585974\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430524; batch adversarial loss: 0.654136\n",
      "epoch 39; iter: 0; batch classifier loss: 0.469767; batch adversarial loss: 0.508614\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417665; batch adversarial loss: 0.573240\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487521; batch adversarial loss: 0.525870\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447219; batch adversarial loss: 0.576181\n",
      "epoch 43; iter: 0; batch classifier loss: 0.502867; batch adversarial loss: 0.626349\n",
      "epoch 44; iter: 0; batch classifier loss: 0.511350; batch adversarial loss: 0.590007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.388691; batch adversarial loss: 0.500080\n",
      "epoch 46; iter: 0; batch classifier loss: 0.477849; batch adversarial loss: 0.563460\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430881; batch adversarial loss: 0.545459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.441396; batch adversarial loss: 0.556645\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422549; batch adversarial loss: 0.516776\n",
      "epoch 50; iter: 0; batch classifier loss: 0.490631; batch adversarial loss: 0.552884\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430457; batch adversarial loss: 0.511036\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413010; batch adversarial loss: 0.513603\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432667; batch adversarial loss: 0.563165\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385873; batch adversarial loss: 0.508556\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462753; batch adversarial loss: 0.572728\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430585; batch adversarial loss: 0.623207\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429178; batch adversarial loss: 0.547436\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472668; batch adversarial loss: 0.580956\n",
      "epoch 59; iter: 0; batch classifier loss: 0.393918; batch adversarial loss: 0.528865\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405184; batch adversarial loss: 0.568836\n",
      "epoch 61; iter: 0; batch classifier loss: 0.315128; batch adversarial loss: 0.579516\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444674; batch adversarial loss: 0.484537\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423751; batch adversarial loss: 0.538126\n",
      "epoch 64; iter: 0; batch classifier loss: 0.341818; batch adversarial loss: 0.574713\n",
      "epoch 65; iter: 0; batch classifier loss: 0.330587; batch adversarial loss: 0.564946\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427235; batch adversarial loss: 0.483349\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421116; batch adversarial loss: 0.534140\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405754; batch adversarial loss: 0.554636\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422530; batch adversarial loss: 0.580424\n",
      "epoch 70; iter: 0; batch classifier loss: 0.365783; batch adversarial loss: 0.555311\n",
      "epoch 71; iter: 0; batch classifier loss: 0.510188; batch adversarial loss: 0.675194\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419164; batch adversarial loss: 0.516014\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395140; batch adversarial loss: 0.498654\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387665; batch adversarial loss: 0.540970\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358671; batch adversarial loss: 0.638945\n",
      "epoch 76; iter: 0; batch classifier loss: 0.428809; batch adversarial loss: 0.530059\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381086; batch adversarial loss: 0.579408\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358949; batch adversarial loss: 0.552460\n",
      "epoch 79; iter: 0; batch classifier loss: 0.344891; batch adversarial loss: 0.632110\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437326; batch adversarial loss: 0.544435\n",
      "epoch 81; iter: 0; batch classifier loss: 0.493151; batch adversarial loss: 0.589184\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383003; batch adversarial loss: 0.605867\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369265; batch adversarial loss: 0.585742\n",
      "epoch 84; iter: 0; batch classifier loss: 0.434303; batch adversarial loss: 0.598409\n",
      "epoch 85; iter: 0; batch classifier loss: 0.325758; batch adversarial loss: 0.563272\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427678; batch adversarial loss: 0.595880\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393749; batch adversarial loss: 0.488993\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367995; batch adversarial loss: 0.475170\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374500; batch adversarial loss: 0.494420\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386644; batch adversarial loss: 0.551023\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408795; batch adversarial loss: 0.518282\n",
      "epoch 92; iter: 0; batch classifier loss: 0.358789; batch adversarial loss: 0.547112\n",
      "epoch 93; iter: 0; batch classifier loss: 0.430113; batch adversarial loss: 0.569735\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396296; batch adversarial loss: 0.545803\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442087; batch adversarial loss: 0.587785\n",
      "epoch 96; iter: 0; batch classifier loss: 0.357356; batch adversarial loss: 0.649696\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374237; batch adversarial loss: 0.525912\n",
      "epoch 98; iter: 0; batch classifier loss: 0.311706; batch adversarial loss: 0.581149\n",
      "epoch 99; iter: 0; batch classifier loss: 0.316679; batch adversarial loss: 0.512722\n",
      "epoch 100; iter: 0; batch classifier loss: 0.320510; batch adversarial loss: 0.544500\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393481; batch adversarial loss: 0.615498\n",
      "epoch 102; iter: 0; batch classifier loss: 0.368169; batch adversarial loss: 0.666829\n",
      "epoch 103; iter: 0; batch classifier loss: 0.363184; batch adversarial loss: 0.507124\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428240; batch adversarial loss: 0.534954\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351773; batch adversarial loss: 0.481745\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359201; batch adversarial loss: 0.519414\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381353; batch adversarial loss: 0.614408\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386015; batch adversarial loss: 0.599716\n",
      "epoch 109; iter: 0; batch classifier loss: 0.322937; batch adversarial loss: 0.521264\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339443; batch adversarial loss: 0.535722\n",
      "epoch 111; iter: 0; batch classifier loss: 0.480481; batch adversarial loss: 0.508042\n",
      "epoch 112; iter: 0; batch classifier loss: 0.469465; batch adversarial loss: 0.581896\n",
      "epoch 113; iter: 0; batch classifier loss: 0.331554; batch adversarial loss: 0.569654\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402226; batch adversarial loss: 0.483412\n",
      "epoch 115; iter: 0; batch classifier loss: 0.476246; batch adversarial loss: 0.596251\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394978; batch adversarial loss: 0.595434\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374904; batch adversarial loss: 0.561513\n",
      "epoch 118; iter: 0; batch classifier loss: 0.380637; batch adversarial loss: 0.553145\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374552; batch adversarial loss: 0.460749\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378026; batch adversarial loss: 0.647259\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385716; batch adversarial loss: 0.553120\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404742; batch adversarial loss: 0.604309\n",
      "epoch 123; iter: 0; batch classifier loss: 0.413122; batch adversarial loss: 0.529760\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395678; batch adversarial loss: 0.518131\n",
      "epoch 125; iter: 0; batch classifier loss: 0.319164; batch adversarial loss: 0.533171\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391131; batch adversarial loss: 0.552864\n",
      "epoch 127; iter: 0; batch classifier loss: 0.421421; batch adversarial loss: 0.568264\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362370; batch adversarial loss: 0.533979\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380386; batch adversarial loss: 0.573863\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349354; batch adversarial loss: 0.616954\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343228; batch adversarial loss: 0.583181\n",
      "epoch 132; iter: 0; batch classifier loss: 0.387955; batch adversarial loss: 0.622883\n",
      "epoch 133; iter: 0; batch classifier loss: 0.290309; batch adversarial loss: 0.538734\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403274; batch adversarial loss: 0.537276\n",
      "epoch 135; iter: 0; batch classifier loss: 0.315793; batch adversarial loss: 0.555097\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381719; batch adversarial loss: 0.552831\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392244; batch adversarial loss: 0.562393\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349613; batch adversarial loss: 0.546119\n",
      "epoch 139; iter: 0; batch classifier loss: 0.429168; batch adversarial loss: 0.604854\n",
      "epoch 140; iter: 0; batch classifier loss: 0.483583; batch adversarial loss: 0.580319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.395435; batch adversarial loss: 0.491443\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348558; batch adversarial loss: 0.606552\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354160; batch adversarial loss: 0.571835\n",
      "epoch 144; iter: 0; batch classifier loss: 0.343515; batch adversarial loss: 0.492110\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323536; batch adversarial loss: 0.516903\n",
      "epoch 146; iter: 0; batch classifier loss: 0.441275; batch adversarial loss: 0.544757\n",
      "epoch 147; iter: 0; batch classifier loss: 0.352303; batch adversarial loss: 0.581807\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344028; batch adversarial loss: 0.642634\n",
      "epoch 149; iter: 0; batch classifier loss: 0.421239; batch adversarial loss: 0.521794\n",
      "epoch 150; iter: 0; batch classifier loss: 0.336599; batch adversarial loss: 0.611676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371131; batch adversarial loss: 0.579208\n",
      "epoch 152; iter: 0; batch classifier loss: 0.425196; batch adversarial loss: 0.648743\n",
      "epoch 153; iter: 0; batch classifier loss: 0.359350; batch adversarial loss: 0.510313\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412752; batch adversarial loss: 0.599259\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324116; batch adversarial loss: 0.604901\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346693; batch adversarial loss: 0.563148\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350377; batch adversarial loss: 0.603476\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373591; batch adversarial loss: 0.528589\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341994; batch adversarial loss: 0.523061\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381339; batch adversarial loss: 0.597302\n",
      "epoch 161; iter: 0; batch classifier loss: 0.340750; batch adversarial loss: 0.562635\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326648; batch adversarial loss: 0.537176\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391068; batch adversarial loss: 0.544992\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394114; batch adversarial loss: 0.549482\n",
      "epoch 165; iter: 0; batch classifier loss: 0.235864; batch adversarial loss: 0.614793\n",
      "epoch 166; iter: 0; batch classifier loss: 0.421246; batch adversarial loss: 0.537880\n",
      "epoch 167; iter: 0; batch classifier loss: 0.303494; batch adversarial loss: 0.544884\n",
      "epoch 168; iter: 0; batch classifier loss: 0.329758; batch adversarial loss: 0.595135\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362049; batch adversarial loss: 0.606770\n",
      "epoch 170; iter: 0; batch classifier loss: 0.442495; batch adversarial loss: 0.535661\n",
      "epoch 171; iter: 0; batch classifier loss: 0.469283; batch adversarial loss: 0.639993\n",
      "epoch 172; iter: 0; batch classifier loss: 0.312320; batch adversarial loss: 0.543847\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372984; batch adversarial loss: 0.466722\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338214; batch adversarial loss: 0.550015\n",
      "epoch 175; iter: 0; batch classifier loss: 0.309238; batch adversarial loss: 0.519512\n",
      "epoch 176; iter: 0; batch classifier loss: 0.389598; batch adversarial loss: 0.529393\n",
      "epoch 177; iter: 0; batch classifier loss: 0.334340; batch adversarial loss: 0.542945\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384522; batch adversarial loss: 0.535817\n",
      "epoch 179; iter: 0; batch classifier loss: 0.335513; batch adversarial loss: 0.554044\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346324; batch adversarial loss: 0.641501\n",
      "epoch 181; iter: 0; batch classifier loss: 0.417579; batch adversarial loss: 0.554272\n",
      "epoch 182; iter: 0; batch classifier loss: 0.460034; batch adversarial loss: 0.631044\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327016; batch adversarial loss: 0.572531\n",
      "epoch 184; iter: 0; batch classifier loss: 0.463448; batch adversarial loss: 0.596206\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390304; batch adversarial loss: 0.553853\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334336; batch adversarial loss: 0.603940\n",
      "epoch 187; iter: 0; batch classifier loss: 0.456761; batch adversarial loss: 0.537656\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376255; batch adversarial loss: 0.573369\n",
      "epoch 189; iter: 0; batch classifier loss: 0.409878; batch adversarial loss: 0.536799\n",
      "epoch 190; iter: 0; batch classifier loss: 0.313618; batch adversarial loss: 0.571884\n",
      "epoch 191; iter: 0; batch classifier loss: 0.284052; batch adversarial loss: 0.569479\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337579; batch adversarial loss: 0.552438\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361783; batch adversarial loss: 0.595090\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330120; batch adversarial loss: 0.535780\n",
      "epoch 195; iter: 0; batch classifier loss: 0.442387; batch adversarial loss: 0.563600\n",
      "epoch 196; iter: 0; batch classifier loss: 0.286020; batch adversarial loss: 0.527720\n",
      "epoch 197; iter: 0; batch classifier loss: 0.422432; batch adversarial loss: 0.614697\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356367; batch adversarial loss: 0.579368\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374012; batch adversarial loss: 0.570573\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668770; batch adversarial loss: 0.631189\n",
      "epoch 1; iter: 0; batch classifier loss: 0.541708; batch adversarial loss: 0.638324\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587065; batch adversarial loss: 0.607862\n",
      "epoch 3; iter: 0; batch classifier loss: 0.497890; batch adversarial loss: 0.588726\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539398; batch adversarial loss: 0.580283\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483001; batch adversarial loss: 0.576581\n",
      "epoch 6; iter: 0; batch classifier loss: 0.469808; batch adversarial loss: 0.594451\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534040; batch adversarial loss: 0.560516\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525026; batch adversarial loss: 0.632136\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514291; batch adversarial loss: 0.608840\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564323; batch adversarial loss: 0.598582\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592368; batch adversarial loss: 0.657767\n",
      "epoch 12; iter: 0; batch classifier loss: 0.568247; batch adversarial loss: 0.584795\n",
      "epoch 13; iter: 0; batch classifier loss: 0.606921; batch adversarial loss: 0.626078\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507281; batch adversarial loss: 0.535054\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474692; batch adversarial loss: 0.630673\n",
      "epoch 16; iter: 0; batch classifier loss: 0.576619; batch adversarial loss: 0.588619\n",
      "epoch 17; iter: 0; batch classifier loss: 0.490992; batch adversarial loss: 0.590159\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492992; batch adversarial loss: 0.579282\n",
      "epoch 19; iter: 0; batch classifier loss: 0.409613; batch adversarial loss: 0.589370\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440331; batch adversarial loss: 0.579136\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532164; batch adversarial loss: 0.558051\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463817; batch adversarial loss: 0.569297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523111; batch adversarial loss: 0.502019\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488100; batch adversarial loss: 0.481805\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511807; batch adversarial loss: 0.536871\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512481; batch adversarial loss: 0.542188\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458059; batch adversarial loss: 0.513839\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492690; batch adversarial loss: 0.572537\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472570; batch adversarial loss: 0.468116\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496523; batch adversarial loss: 0.493291\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471881; batch adversarial loss: 0.545854\n",
      "epoch 32; iter: 0; batch classifier loss: 0.413472; batch adversarial loss: 0.527612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485023; batch adversarial loss: 0.561726\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447990; batch adversarial loss: 0.535186\n",
      "epoch 35; iter: 0; batch classifier loss: 0.383730; batch adversarial loss: 0.570048\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437384; batch adversarial loss: 0.553066\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459320; batch adversarial loss: 0.504815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.420268; batch adversarial loss: 0.524038\n",
      "epoch 39; iter: 0; batch classifier loss: 0.413499; batch adversarial loss: 0.620445\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424333; batch adversarial loss: 0.553065\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444014; batch adversarial loss: 0.523024\n",
      "epoch 42; iter: 0; batch classifier loss: 0.546668; batch adversarial loss: 0.545142\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471224; batch adversarial loss: 0.468079\n",
      "epoch 44; iter: 0; batch classifier loss: 0.486528; batch adversarial loss: 0.561169\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480995; batch adversarial loss: 0.553653\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467442; batch adversarial loss: 0.576596\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416375; batch adversarial loss: 0.517086\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424162; batch adversarial loss: 0.553919\n",
      "epoch 49; iter: 0; batch classifier loss: 0.365142; batch adversarial loss: 0.485823\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412872; batch adversarial loss: 0.554404\n",
      "epoch 51; iter: 0; batch classifier loss: 0.500382; batch adversarial loss: 0.582719\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398947; batch adversarial loss: 0.561637\n",
      "epoch 53; iter: 0; batch classifier loss: 0.623458; batch adversarial loss: 0.527250\n",
      "epoch 54; iter: 0; batch classifier loss: 0.479596; batch adversarial loss: 0.553224\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410508; batch adversarial loss: 0.517172\n",
      "epoch 56; iter: 0; batch classifier loss: 0.358723; batch adversarial loss: 0.514669\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423215; batch adversarial loss: 0.553382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.361233; batch adversarial loss: 0.544188\n",
      "epoch 59; iter: 0; batch classifier loss: 0.379848; batch adversarial loss: 0.512554\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414259; batch adversarial loss: 0.458599\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416390; batch adversarial loss: 0.518556\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448743; batch adversarial loss: 0.560390\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397827; batch adversarial loss: 0.498166\n",
      "epoch 64; iter: 0; batch classifier loss: 0.456482; batch adversarial loss: 0.515769\n",
      "epoch 65; iter: 0; batch classifier loss: 0.364686; batch adversarial loss: 0.503736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.357343; batch adversarial loss: 0.533086\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395351; batch adversarial loss: 0.550691\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439610; batch adversarial loss: 0.626379\n",
      "epoch 69; iter: 0; batch classifier loss: 0.398723; batch adversarial loss: 0.519460\n",
      "epoch 70; iter: 0; batch classifier loss: 0.320491; batch adversarial loss: 0.438951\n",
      "epoch 71; iter: 0; batch classifier loss: 0.364172; batch adversarial loss: 0.568374\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391392; batch adversarial loss: 0.456190\n",
      "epoch 73; iter: 0; batch classifier loss: 0.458250; batch adversarial loss: 0.550074\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432978; batch adversarial loss: 0.505492\n",
      "epoch 75; iter: 0; batch classifier loss: 0.508424; batch adversarial loss: 0.464096\n",
      "epoch 76; iter: 0; batch classifier loss: 0.428890; batch adversarial loss: 0.439945\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426448; batch adversarial loss: 0.381094\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387894; batch adversarial loss: 0.445486\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381458; batch adversarial loss: 0.516349\n",
      "epoch 80; iter: 0; batch classifier loss: 0.376727; batch adversarial loss: 0.559327\n",
      "epoch 81; iter: 0; batch classifier loss: 0.439605; batch adversarial loss: 0.593853\n",
      "epoch 82; iter: 0; batch classifier loss: 0.482029; batch adversarial loss: 0.481652\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383238; batch adversarial loss: 0.485287\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349372; batch adversarial loss: 0.603094\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452476; batch adversarial loss: 0.574382\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402713; batch adversarial loss: 0.424355\n",
      "epoch 87; iter: 0; batch classifier loss: 0.439444; batch adversarial loss: 0.580973\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381916; batch adversarial loss: 0.572215\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368802; batch adversarial loss: 0.570406\n",
      "epoch 90; iter: 0; batch classifier loss: 0.389845; batch adversarial loss: 0.559369\n",
      "epoch 91; iter: 0; batch classifier loss: 0.340621; batch adversarial loss: 0.549880\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417835; batch adversarial loss: 0.520286\n",
      "epoch 93; iter: 0; batch classifier loss: 0.445494; batch adversarial loss: 0.553143\n",
      "epoch 94; iter: 0; batch classifier loss: 0.443224; batch adversarial loss: 0.593519\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345286; batch adversarial loss: 0.490998\n",
      "epoch 96; iter: 0; batch classifier loss: 0.439416; batch adversarial loss: 0.632504\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344642; batch adversarial loss: 0.584873\n",
      "epoch 98; iter: 0; batch classifier loss: 0.487536; batch adversarial loss: 0.610043\n",
      "epoch 99; iter: 0; batch classifier loss: 0.443701; batch adversarial loss: 0.521520\n",
      "epoch 100; iter: 0; batch classifier loss: 0.353851; batch adversarial loss: 0.473466\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358716; batch adversarial loss: 0.559108\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400683; batch adversarial loss: 0.508404\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371964; batch adversarial loss: 0.550748\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377284; batch adversarial loss: 0.481655\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405300; batch adversarial loss: 0.507061\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441064; batch adversarial loss: 0.532390\n",
      "epoch 107; iter: 0; batch classifier loss: 0.275983; batch adversarial loss: 0.502072\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417661; batch adversarial loss: 0.579264\n",
      "epoch 109; iter: 0; batch classifier loss: 0.487823; batch adversarial loss: 0.476998\n",
      "epoch 110; iter: 0; batch classifier loss: 0.438723; batch adversarial loss: 0.531682\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416359; batch adversarial loss: 0.466341\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382342; batch adversarial loss: 0.578364\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346305; batch adversarial loss: 0.546258\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360307; batch adversarial loss: 0.539381\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373928; batch adversarial loss: 0.584185\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366188; batch adversarial loss: 0.535803\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381656; batch adversarial loss: 0.488123\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377352; batch adversarial loss: 0.580369\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347191; batch adversarial loss: 0.541323\n",
      "epoch 120; iter: 0; batch classifier loss: 0.332386; batch adversarial loss: 0.565303\n",
      "epoch 121; iter: 0; batch classifier loss: 0.422326; batch adversarial loss: 0.587258\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398674; batch adversarial loss: 0.561214\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376831; batch adversarial loss: 0.541410\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380466; batch adversarial loss: 0.534598\n",
      "epoch 125; iter: 0; batch classifier loss: 0.301536; batch adversarial loss: 0.601803\n",
      "epoch 126; iter: 0; batch classifier loss: 0.349633; batch adversarial loss: 0.503025\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394610; batch adversarial loss: 0.543026\n",
      "epoch 128; iter: 0; batch classifier loss: 0.289824; batch adversarial loss: 0.564079\n",
      "epoch 129; iter: 0; batch classifier loss: 0.266546; batch adversarial loss: 0.505911\n",
      "epoch 130; iter: 0; batch classifier loss: 0.379040; batch adversarial loss: 0.561833\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374811; batch adversarial loss: 0.543210\n",
      "epoch 132; iter: 0; batch classifier loss: 0.570965; batch adversarial loss: 0.623305\n",
      "epoch 133; iter: 0; batch classifier loss: 0.299337; batch adversarial loss: 0.565151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.353042; batch adversarial loss: 0.467724\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352009; batch adversarial loss: 0.557485\n",
      "epoch 136; iter: 0; batch classifier loss: 0.287270; batch adversarial loss: 0.457618\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392494; batch adversarial loss: 0.584747\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386246; batch adversarial loss: 0.472004\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366067; batch adversarial loss: 0.485491\n",
      "epoch 140; iter: 0; batch classifier loss: 0.320255; batch adversarial loss: 0.591731\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391584; batch adversarial loss: 0.493810\n",
      "epoch 142; iter: 0; batch classifier loss: 0.382821; batch adversarial loss: 0.494945\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413003; batch adversarial loss: 0.516462\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368786; batch adversarial loss: 0.502389\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351004; batch adversarial loss: 0.576220\n",
      "epoch 146; iter: 0; batch classifier loss: 0.401011; batch adversarial loss: 0.524468\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377984; batch adversarial loss: 0.497060\n",
      "epoch 148; iter: 0; batch classifier loss: 0.315186; batch adversarial loss: 0.594920\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329577; batch adversarial loss: 0.541358\n",
      "epoch 150; iter: 0; batch classifier loss: 0.299787; batch adversarial loss: 0.544342\n",
      "epoch 151; iter: 0; batch classifier loss: 0.360657; batch adversarial loss: 0.494645\n",
      "epoch 152; iter: 0; batch classifier loss: 0.418459; batch adversarial loss: 0.525450\n",
      "epoch 153; iter: 0; batch classifier loss: 0.340573; batch adversarial loss: 0.466004\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359010; batch adversarial loss: 0.716895\n",
      "epoch 155; iter: 0; batch classifier loss: 0.299593; batch adversarial loss: 0.505238\n",
      "epoch 156; iter: 0; batch classifier loss: 0.392201; batch adversarial loss: 0.552319\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367099; batch adversarial loss: 0.485734\n",
      "epoch 158; iter: 0; batch classifier loss: 0.374328; batch adversarial loss: 0.616862\n",
      "epoch 159; iter: 0; batch classifier loss: 0.330402; batch adversarial loss: 0.577930\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390131; batch adversarial loss: 0.522210\n",
      "epoch 161; iter: 0; batch classifier loss: 0.364625; batch adversarial loss: 0.438664\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348526; batch adversarial loss: 0.584264\n",
      "epoch 163; iter: 0; batch classifier loss: 0.390103; batch adversarial loss: 0.570570\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389484; batch adversarial loss: 0.610555\n",
      "epoch 165; iter: 0; batch classifier loss: 0.415483; batch adversarial loss: 0.515470\n",
      "epoch 166; iter: 0; batch classifier loss: 0.524517; batch adversarial loss: 0.570782\n",
      "epoch 167; iter: 0; batch classifier loss: 0.432183; batch adversarial loss: 0.575510\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362661; batch adversarial loss: 0.493729\n",
      "epoch 169; iter: 0; batch classifier loss: 0.389761; batch adversarial loss: 0.526511\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397752; batch adversarial loss: 0.497533\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378220; batch adversarial loss: 0.522127\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395709; batch adversarial loss: 0.512848\n",
      "epoch 173; iter: 0; batch classifier loss: 0.406897; batch adversarial loss: 0.505234\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374050; batch adversarial loss: 0.459480\n",
      "epoch 175; iter: 0; batch classifier loss: 0.437834; batch adversarial loss: 0.446989\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369419; batch adversarial loss: 0.523595\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363535; batch adversarial loss: 0.534923\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323792; batch adversarial loss: 0.479265\n",
      "epoch 179; iter: 0; batch classifier loss: 0.398331; batch adversarial loss: 0.541868\n",
      "epoch 180; iter: 0; batch classifier loss: 0.399324; batch adversarial loss: 0.514485\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338461; batch adversarial loss: 0.594745\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358938; batch adversarial loss: 0.554588\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376879; batch adversarial loss: 0.478094\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350931; batch adversarial loss: 0.544584\n",
      "epoch 185; iter: 0; batch classifier loss: 0.334148; batch adversarial loss: 0.585193\n",
      "epoch 186; iter: 0; batch classifier loss: 0.464537; batch adversarial loss: 0.439540\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375631; batch adversarial loss: 0.543130\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387391; batch adversarial loss: 0.493545\n",
      "epoch 189; iter: 0; batch classifier loss: 0.290102; batch adversarial loss: 0.543793\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375292; batch adversarial loss: 0.482897\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355572; batch adversarial loss: 0.547990\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368309; batch adversarial loss: 0.543736\n",
      "epoch 193; iter: 0; batch classifier loss: 0.369580; batch adversarial loss: 0.515547\n",
      "epoch 194; iter: 0; batch classifier loss: 0.401298; batch adversarial loss: 0.523181\n",
      "epoch 195; iter: 0; batch classifier loss: 0.391267; batch adversarial loss: 0.446557\n",
      "epoch 196; iter: 0; batch classifier loss: 0.402582; batch adversarial loss: 0.543117\n",
      "epoch 197; iter: 0; batch classifier loss: 0.416190; batch adversarial loss: 0.498191\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341027; batch adversarial loss: 0.538594\n",
      "epoch 199; iter: 0; batch classifier loss: 0.409015; batch adversarial loss: 0.592863\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690851; batch adversarial loss: 0.661783\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621459; batch adversarial loss: 0.657576\n",
      "epoch 2; iter: 0; batch classifier loss: 0.650007; batch adversarial loss: 0.649842\n",
      "epoch 3; iter: 0; batch classifier loss: 0.627002; batch adversarial loss: 0.631924\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558285; batch adversarial loss: 0.617465\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544434; batch adversarial loss: 0.635229\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588882; batch adversarial loss: 0.601535\n",
      "epoch 7; iter: 0; batch classifier loss: 0.602702; batch adversarial loss: 0.581167\n",
      "epoch 8; iter: 0; batch classifier loss: 0.477108; batch adversarial loss: 0.590268\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520371; batch adversarial loss: 0.618153\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548331; batch adversarial loss: 0.541863\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585663; batch adversarial loss: 0.585983\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503353; batch adversarial loss: 0.563599\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530681; batch adversarial loss: 0.574266\n",
      "epoch 14; iter: 0; batch classifier loss: 0.583498; batch adversarial loss: 0.567278\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538152; batch adversarial loss: 0.522597\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504585; batch adversarial loss: 0.574101\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501048; batch adversarial loss: 0.596627\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444934; batch adversarial loss: 0.538766\n",
      "epoch 19; iter: 0; batch classifier loss: 0.553019; batch adversarial loss: 0.480575\n",
      "epoch 20; iter: 0; batch classifier loss: 0.486109; batch adversarial loss: 0.567244\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467185; batch adversarial loss: 0.498178\n",
      "epoch 22; iter: 0; batch classifier loss: 0.410145; batch adversarial loss: 0.551100\n",
      "epoch 23; iter: 0; batch classifier loss: 0.535127; batch adversarial loss: 0.559887\n",
      "epoch 24; iter: 0; batch classifier loss: 0.413000; batch adversarial loss: 0.524909\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498111; batch adversarial loss: 0.570577\n",
      "epoch 26; iter: 0; batch classifier loss: 0.558960; batch adversarial loss: 0.581209\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446586; batch adversarial loss: 0.572622\n",
      "epoch 28; iter: 0; batch classifier loss: 0.592532; batch adversarial loss: 0.535802\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485055; batch adversarial loss: 0.475042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.562720; batch adversarial loss: 0.606535\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430659; batch adversarial loss: 0.503281\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494688; batch adversarial loss: 0.543609\n",
      "epoch 33; iter: 0; batch classifier loss: 0.413991; batch adversarial loss: 0.500108\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435698; batch adversarial loss: 0.597486\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521421; batch adversarial loss: 0.580690\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433629; batch adversarial loss: 0.517891\n",
      "epoch 37; iter: 0; batch classifier loss: 0.513934; batch adversarial loss: 0.507702\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442060; batch adversarial loss: 0.544805\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467758; batch adversarial loss: 0.507842\n",
      "epoch 40; iter: 0; batch classifier loss: 0.483624; batch adversarial loss: 0.526900\n",
      "epoch 41; iter: 0; batch classifier loss: 0.359505; batch adversarial loss: 0.554045\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474985; batch adversarial loss: 0.534291\n",
      "epoch 43; iter: 0; batch classifier loss: 0.517119; batch adversarial loss: 0.517142\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450303; batch adversarial loss: 0.544151\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498454; batch adversarial loss: 0.526472\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465005; batch adversarial loss: 0.627560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406387; batch adversarial loss: 0.525197\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403229; batch adversarial loss: 0.525523\n",
      "epoch 49; iter: 0; batch classifier loss: 0.489270; batch adversarial loss: 0.590661\n",
      "epoch 50; iter: 0; batch classifier loss: 0.369987; batch adversarial loss: 0.489291\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411966; batch adversarial loss: 0.583668\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387613; batch adversarial loss: 0.563202\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391255; batch adversarial loss: 0.536993\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399999; batch adversarial loss: 0.517216\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406805; batch adversarial loss: 0.535159\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398884; batch adversarial loss: 0.526448\n",
      "epoch 57; iter: 0; batch classifier loss: 0.419520; batch adversarial loss: 0.523192\n",
      "epoch 58; iter: 0; batch classifier loss: 0.364152; batch adversarial loss: 0.556283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.354528; batch adversarial loss: 0.509232\n",
      "epoch 60; iter: 0; batch classifier loss: 0.415438; batch adversarial loss: 0.536242\n",
      "epoch 61; iter: 0; batch classifier loss: 0.443237; batch adversarial loss: 0.600715\n",
      "epoch 62; iter: 0; batch classifier loss: 0.502802; batch adversarial loss: 0.613666\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403997; batch adversarial loss: 0.498567\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412840; batch adversarial loss: 0.570887\n",
      "epoch 65; iter: 0; batch classifier loss: 0.404334; batch adversarial loss: 0.535479\n",
      "epoch 66; iter: 0; batch classifier loss: 0.338594; batch adversarial loss: 0.599097\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401606; batch adversarial loss: 0.610242\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423178; batch adversarial loss: 0.454141\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430784; batch adversarial loss: 0.583634\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438512; batch adversarial loss: 0.535116\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394270; batch adversarial loss: 0.609793\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410857; batch adversarial loss: 0.544494\n",
      "epoch 73; iter: 0; batch classifier loss: 0.444040; batch adversarial loss: 0.480655\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424250; batch adversarial loss: 0.555777\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449636; batch adversarial loss: 0.572270\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414302; batch adversarial loss: 0.533487\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392628; batch adversarial loss: 0.563889\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382443; batch adversarial loss: 0.553028\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405327; batch adversarial loss: 0.571855\n",
      "epoch 80; iter: 0; batch classifier loss: 0.382307; batch adversarial loss: 0.581298\n",
      "epoch 81; iter: 0; batch classifier loss: 0.416308; batch adversarial loss: 0.535713\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412637; batch adversarial loss: 0.533897\n",
      "epoch 83; iter: 0; batch classifier loss: 0.359751; batch adversarial loss: 0.506186\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418503; batch adversarial loss: 0.590175\n",
      "epoch 85; iter: 0; batch classifier loss: 0.520875; batch adversarial loss: 0.459898\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417246; batch adversarial loss: 0.544750\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368553; batch adversarial loss: 0.443437\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414086; batch adversarial loss: 0.544205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.506370; batch adversarial loss: 0.466676\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405763; batch adversarial loss: 0.480716\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434582; batch adversarial loss: 0.685225\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434973; batch adversarial loss: 0.478911\n",
      "epoch 93; iter: 0; batch classifier loss: 0.529420; batch adversarial loss: 0.600517\n",
      "epoch 94; iter: 0; batch classifier loss: 0.351792; batch adversarial loss: 0.580485\n",
      "epoch 95; iter: 0; batch classifier loss: 0.280342; batch adversarial loss: 0.551208\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335307; batch adversarial loss: 0.561574\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377599; batch adversarial loss: 0.591950\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389545; batch adversarial loss: 0.576034\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417404; batch adversarial loss: 0.573730\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364492; batch adversarial loss: 0.616548\n",
      "epoch 101; iter: 0; batch classifier loss: 0.321944; batch adversarial loss: 0.497188\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349173; batch adversarial loss: 0.618984\n",
      "epoch 103; iter: 0; batch classifier loss: 0.353559; batch adversarial loss: 0.516916\n",
      "epoch 104; iter: 0; batch classifier loss: 0.408771; batch adversarial loss: 0.480313\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414490; batch adversarial loss: 0.574816\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389639; batch adversarial loss: 0.480505\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354480; batch adversarial loss: 0.527589\n",
      "epoch 108; iter: 0; batch classifier loss: 0.440838; batch adversarial loss: 0.543982\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391542; batch adversarial loss: 0.524653\n",
      "epoch 110; iter: 0; batch classifier loss: 0.413916; batch adversarial loss: 0.592205\n",
      "epoch 111; iter: 0; batch classifier loss: 0.455459; batch adversarial loss: 0.439137\n",
      "epoch 112; iter: 0; batch classifier loss: 0.429098; batch adversarial loss: 0.533359\n",
      "epoch 113; iter: 0; batch classifier loss: 0.424717; batch adversarial loss: 0.498165\n",
      "epoch 114; iter: 0; batch classifier loss: 0.437533; batch adversarial loss: 0.534928\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393302; batch adversarial loss: 0.499482\n",
      "epoch 116; iter: 0; batch classifier loss: 0.404490; batch adversarial loss: 0.507492\n",
      "epoch 117; iter: 0; batch classifier loss: 0.463621; batch adversarial loss: 0.563504\n",
      "epoch 118; iter: 0; batch classifier loss: 0.424933; batch adversarial loss: 0.599140\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433551; batch adversarial loss: 0.536670\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371852; batch adversarial loss: 0.581866\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344588; batch adversarial loss: 0.572147\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377563; batch adversarial loss: 0.553238\n",
      "epoch 123; iter: 0; batch classifier loss: 0.393918; batch adversarial loss: 0.571881\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346000; batch adversarial loss: 0.553020\n",
      "epoch 125; iter: 0; batch classifier loss: 0.428132; batch adversarial loss: 0.562979\n",
      "epoch 126; iter: 0; batch classifier loss: 0.423262; batch adversarial loss: 0.544748\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344644; batch adversarial loss: 0.545830\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343459; batch adversarial loss: 0.507387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.363472; batch adversarial loss: 0.544703\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364488; batch adversarial loss: 0.580488\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380277; batch adversarial loss: 0.599831\n",
      "epoch 132; iter: 0; batch classifier loss: 0.345037; batch adversarial loss: 0.553449\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391591; batch adversarial loss: 0.592031\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374718; batch adversarial loss: 0.507325\n",
      "epoch 135; iter: 0; batch classifier loss: 0.390571; batch adversarial loss: 0.517058\n",
      "epoch 136; iter: 0; batch classifier loss: 0.292696; batch adversarial loss: 0.600225\n",
      "epoch 137; iter: 0; batch classifier loss: 0.480259; batch adversarial loss: 0.582415\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380858; batch adversarial loss: 0.535736\n",
      "epoch 139; iter: 0; batch classifier loss: 0.419810; batch adversarial loss: 0.479357\n",
      "epoch 140; iter: 0; batch classifier loss: 0.303595; batch adversarial loss: 0.535466\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366767; batch adversarial loss: 0.507361\n",
      "epoch 142; iter: 0; batch classifier loss: 0.388524; batch adversarial loss: 0.627414\n",
      "epoch 143; iter: 0; batch classifier loss: 0.431689; batch adversarial loss: 0.517410\n",
      "epoch 144; iter: 0; batch classifier loss: 0.416059; batch adversarial loss: 0.507533\n",
      "epoch 145; iter: 0; batch classifier loss: 0.441237; batch adversarial loss: 0.508065\n",
      "epoch 146; iter: 0; batch classifier loss: 0.396899; batch adversarial loss: 0.532831\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363426; batch adversarial loss: 0.469710\n",
      "epoch 148; iter: 0; batch classifier loss: 0.400410; batch adversarial loss: 0.630032\n",
      "epoch 149; iter: 0; batch classifier loss: 0.421912; batch adversarial loss: 0.551144\n",
      "epoch 150; iter: 0; batch classifier loss: 0.494638; batch adversarial loss: 0.496503\n",
      "epoch 151; iter: 0; batch classifier loss: 0.398361; batch adversarial loss: 0.563555\n",
      "epoch 152; iter: 0; batch classifier loss: 0.479640; batch adversarial loss: 0.546213\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352336; batch adversarial loss: 0.554217\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361628; batch adversarial loss: 0.524516\n",
      "epoch 155; iter: 0; batch classifier loss: 0.460572; batch adversarial loss: 0.571274\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330159; batch adversarial loss: 0.563277\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364724; batch adversarial loss: 0.544924\n",
      "epoch 158; iter: 0; batch classifier loss: 0.420153; batch adversarial loss: 0.599987\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377646; batch adversarial loss: 0.535734\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335733; batch adversarial loss: 0.572762\n",
      "epoch 161; iter: 0; batch classifier loss: 0.394648; batch adversarial loss: 0.552925\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347824; batch adversarial loss: 0.544320\n",
      "epoch 163; iter: 0; batch classifier loss: 0.313776; batch adversarial loss: 0.580839\n",
      "epoch 164; iter: 0; batch classifier loss: 0.374264; batch adversarial loss: 0.580204\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346969; batch adversarial loss: 0.508389\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318350; batch adversarial loss: 0.490105\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401844; batch adversarial loss: 0.477671\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362228; batch adversarial loss: 0.645955\n",
      "epoch 169; iter: 0; batch classifier loss: 0.413598; batch adversarial loss: 0.580123\n",
      "epoch 170; iter: 0; batch classifier loss: 0.404610; batch adversarial loss: 0.507219\n",
      "epoch 171; iter: 0; batch classifier loss: 0.402128; batch adversarial loss: 0.535434\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330773; batch adversarial loss: 0.535311\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355645; batch adversarial loss: 0.563129\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361840; batch adversarial loss: 0.544302\n",
      "epoch 175; iter: 0; batch classifier loss: 0.448601; batch adversarial loss: 0.573549\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396232; batch adversarial loss: 0.516568\n",
      "epoch 177; iter: 0; batch classifier loss: 0.454967; batch adversarial loss: 0.563845\n",
      "epoch 178; iter: 0; batch classifier loss: 0.393578; batch adversarial loss: 0.571497\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322030; batch adversarial loss: 0.507645\n",
      "epoch 180; iter: 0; batch classifier loss: 0.430621; batch adversarial loss: 0.536238\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376892; batch adversarial loss: 0.542957\n",
      "epoch 182; iter: 0; batch classifier loss: 0.330578; batch adversarial loss: 0.525516\n",
      "epoch 183; iter: 0; batch classifier loss: 0.461135; batch adversarial loss: 0.526166\n",
      "epoch 184; iter: 0; batch classifier loss: 0.387984; batch adversarial loss: 0.495843\n",
      "epoch 185; iter: 0; batch classifier loss: 0.282314; batch adversarial loss: 0.506745\n",
      "epoch 186; iter: 0; batch classifier loss: 0.289807; batch adversarial loss: 0.467910\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365256; batch adversarial loss: 0.543309\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391815; batch adversarial loss: 0.525680\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377761; batch adversarial loss: 0.495613\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306460; batch adversarial loss: 0.590342\n",
      "epoch 191; iter: 0; batch classifier loss: 0.393521; batch adversarial loss: 0.544932\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359694; batch adversarial loss: 0.580733\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390975; batch adversarial loss: 0.573494\n",
      "epoch 194; iter: 0; batch classifier loss: 0.462713; batch adversarial loss: 0.497383\n",
      "epoch 195; iter: 0; batch classifier loss: 0.340583; batch adversarial loss: 0.478387\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362048; batch adversarial loss: 0.510012\n",
      "epoch 197; iter: 0; batch classifier loss: 0.289566; batch adversarial loss: 0.572306\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359660; batch adversarial loss: 0.583162\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339452; batch adversarial loss: 0.508127\n",
      "epoch 0; iter: 0; batch classifier loss: 0.648833; batch adversarial loss: 0.828094\n",
      "epoch 1; iter: 0; batch classifier loss: 0.807874; batch adversarial loss: 1.083898\n",
      "epoch 2; iter: 0; batch classifier loss: 0.749157; batch adversarial loss: 1.077889\n",
      "epoch 3; iter: 0; batch classifier loss: 0.773590; batch adversarial loss: 0.959424\n",
      "epoch 4; iter: 0; batch classifier loss: 0.667138; batch adversarial loss: 0.882559\n",
      "epoch 5; iter: 0; batch classifier loss: 0.651935; batch adversarial loss: 0.780606\n",
      "epoch 6; iter: 0; batch classifier loss: 0.470690; batch adversarial loss: 0.735160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514908; batch adversarial loss: 0.682758\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533714; batch adversarial loss: 0.643474\n",
      "epoch 9; iter: 0; batch classifier loss: 0.603868; batch adversarial loss: 0.651956\n",
      "epoch 10; iter: 0; batch classifier loss: 0.591492; batch adversarial loss: 0.629313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511017; batch adversarial loss: 0.645134\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567111; batch adversarial loss: 0.597091\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519950; batch adversarial loss: 0.574864\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461842; batch adversarial loss: 0.585721\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489537; batch adversarial loss: 0.548291\n",
      "epoch 16; iter: 0; batch classifier loss: 0.562349; batch adversarial loss: 0.617791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509699; batch adversarial loss: 0.547636\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456519; batch adversarial loss: 0.542932\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514375; batch adversarial loss: 0.552989\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517887; batch adversarial loss: 0.594120\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514241; batch adversarial loss: 0.515545\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459710; batch adversarial loss: 0.538591\n",
      "epoch 23; iter: 0; batch classifier loss: 0.453050; batch adversarial loss: 0.569308\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511299; batch adversarial loss: 0.564240\n",
      "epoch 25; iter: 0; batch classifier loss: 0.560920; batch adversarial loss: 0.539401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.554039; batch adversarial loss: 0.556970\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465299; batch adversarial loss: 0.580693\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425272; batch adversarial loss: 0.562851\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489471; batch adversarial loss: 0.507928\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474774; batch adversarial loss: 0.592241\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400032; batch adversarial loss: 0.558247\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469164; batch adversarial loss: 0.562345\n",
      "epoch 33; iter: 0; batch classifier loss: 0.379191; batch adversarial loss: 0.589533\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491194; batch adversarial loss: 0.575183\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470904; batch adversarial loss: 0.542011\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432795; batch adversarial loss: 0.540573\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400926; batch adversarial loss: 0.532280\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473072; batch adversarial loss: 0.521149\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442960; batch adversarial loss: 0.510462\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443852; batch adversarial loss: 0.510888\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467068; batch adversarial loss: 0.529471\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448325; batch adversarial loss: 0.578822\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418111; batch adversarial loss: 0.488841\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427136; batch adversarial loss: 0.538785\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455902; batch adversarial loss: 0.489888\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392266; batch adversarial loss: 0.535710\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469244; batch adversarial loss: 0.536553\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478249; batch adversarial loss: 0.641498\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415545; batch adversarial loss: 0.502783\n",
      "epoch 50; iter: 0; batch classifier loss: 0.396782; batch adversarial loss: 0.454283\n",
      "epoch 51; iter: 0; batch classifier loss: 0.477004; batch adversarial loss: 0.571194\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401433; batch adversarial loss: 0.563034\n",
      "epoch 53; iter: 0; batch classifier loss: 0.460280; batch adversarial loss: 0.609979\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413280; batch adversarial loss: 0.516157\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441678; batch adversarial loss: 0.579181\n",
      "epoch 56; iter: 0; batch classifier loss: 0.358423; batch adversarial loss: 0.516516\n",
      "epoch 57; iter: 0; batch classifier loss: 0.385268; batch adversarial loss: 0.532614\n",
      "epoch 58; iter: 0; batch classifier loss: 0.451864; batch adversarial loss: 0.488807\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456150; batch adversarial loss: 0.561912\n",
      "epoch 60; iter: 0; batch classifier loss: 0.466404; batch adversarial loss: 0.504993\n",
      "epoch 61; iter: 0; batch classifier loss: 0.377550; batch adversarial loss: 0.609660\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393454; batch adversarial loss: 0.516721\n",
      "epoch 63; iter: 0; batch classifier loss: 0.455772; batch adversarial loss: 0.495830\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463136; batch adversarial loss: 0.524418\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381504; batch adversarial loss: 0.503976\n",
      "epoch 66; iter: 0; batch classifier loss: 0.453479; batch adversarial loss: 0.527145\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409019; batch adversarial loss: 0.545853\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424937; batch adversarial loss: 0.469558\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374233; batch adversarial loss: 0.544868\n",
      "epoch 70; iter: 0; batch classifier loss: 0.492982; batch adversarial loss: 0.655560\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417056; batch adversarial loss: 0.501916\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393989; batch adversarial loss: 0.606812\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429657; batch adversarial loss: 0.572590\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389844; batch adversarial loss: 0.535277\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404772; batch adversarial loss: 0.507693\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364733; batch adversarial loss: 0.454768\n",
      "epoch 77; iter: 0; batch classifier loss: 0.358303; batch adversarial loss: 0.561646\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355199; batch adversarial loss: 0.535417\n",
      "epoch 79; iter: 0; batch classifier loss: 0.490654; batch adversarial loss: 0.552370\n",
      "epoch 80; iter: 0; batch classifier loss: 0.424270; batch adversarial loss: 0.507186\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371596; batch adversarial loss: 0.607941\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353561; batch adversarial loss: 0.580987\n",
      "epoch 83; iter: 0; batch classifier loss: 0.515455; batch adversarial loss: 0.590871\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407378; batch adversarial loss: 0.553437\n",
      "epoch 85; iter: 0; batch classifier loss: 0.426855; batch adversarial loss: 0.491524\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374301; batch adversarial loss: 0.507927\n",
      "epoch 87; iter: 0; batch classifier loss: 0.467324; batch adversarial loss: 0.626542\n",
      "epoch 88; iter: 0; batch classifier loss: 0.435980; batch adversarial loss: 0.536951\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386537; batch adversarial loss: 0.600236\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403924; batch adversarial loss: 0.525699\n",
      "epoch 91; iter: 0; batch classifier loss: 0.437175; batch adversarial loss: 0.508443\n",
      "epoch 92; iter: 0; batch classifier loss: 0.401958; batch adversarial loss: 0.535294\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357517; batch adversarial loss: 0.563057\n",
      "epoch 94; iter: 0; batch classifier loss: 0.462194; batch adversarial loss: 0.488642\n",
      "epoch 95; iter: 0; batch classifier loss: 0.432294; batch adversarial loss: 0.507458\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335979; batch adversarial loss: 0.590243\n",
      "epoch 97; iter: 0; batch classifier loss: 0.487518; batch adversarial loss: 0.600714\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371926; batch adversarial loss: 0.489064\n",
      "epoch 99; iter: 0; batch classifier loss: 0.394085; batch adversarial loss: 0.526849\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397926; batch adversarial loss: 0.497186\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360437; batch adversarial loss: 0.547300\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326738; batch adversarial loss: 0.570779\n",
      "epoch 103; iter: 0; batch classifier loss: 0.370770; batch adversarial loss: 0.544127\n",
      "epoch 104; iter: 0; batch classifier loss: 0.494910; batch adversarial loss: 0.510564\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418936; batch adversarial loss: 0.492831\n",
      "epoch 106; iter: 0; batch classifier loss: 0.502852; batch adversarial loss: 0.580151\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371738; batch adversarial loss: 0.552390\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363444; batch adversarial loss: 0.643139\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391652; batch adversarial loss: 0.590068\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363432; batch adversarial loss: 0.555599\n",
      "epoch 111; iter: 0; batch classifier loss: 0.447697; batch adversarial loss: 0.589923\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430033; batch adversarial loss: 0.557990\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389970; batch adversarial loss: 0.519854\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344528; batch adversarial loss: 0.533975\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345495; batch adversarial loss: 0.547414\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384125; batch adversarial loss: 0.536300\n",
      "epoch 117; iter: 0; batch classifier loss: 0.398098; batch adversarial loss: 0.498890\n",
      "epoch 118; iter: 0; batch classifier loss: 0.327479; batch adversarial loss: 0.552666\n",
      "epoch 119; iter: 0; batch classifier loss: 0.316759; batch adversarial loss: 0.625213\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407812; batch adversarial loss: 0.473476\n",
      "epoch 121; iter: 0; batch classifier loss: 0.525036; batch adversarial loss: 0.527481\n",
      "epoch 122; iter: 0; batch classifier loss: 0.340396; batch adversarial loss: 0.515833\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399048; batch adversarial loss: 0.533474\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377933; batch adversarial loss: 0.592881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.380112; batch adversarial loss: 0.519171\n",
      "epoch 126; iter: 0; batch classifier loss: 0.302803; batch adversarial loss: 0.479695\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384779; batch adversarial loss: 0.550586\n",
      "epoch 128; iter: 0; batch classifier loss: 0.347696; batch adversarial loss: 0.542270\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359956; batch adversarial loss: 0.501117\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384898; batch adversarial loss: 0.563745\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353895; batch adversarial loss: 0.516993\n",
      "epoch 132; iter: 0; batch classifier loss: 0.428921; batch adversarial loss: 0.574123\n",
      "epoch 133; iter: 0; batch classifier loss: 0.360545; batch adversarial loss: 0.552908\n",
      "epoch 134; iter: 0; batch classifier loss: 0.420519; batch adversarial loss: 0.566806\n",
      "epoch 135; iter: 0; batch classifier loss: 0.308798; batch adversarial loss: 0.563173\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392695; batch adversarial loss: 0.492348\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351272; batch adversarial loss: 0.618350\n",
      "epoch 138; iter: 0; batch classifier loss: 0.354282; batch adversarial loss: 0.489685\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373295; batch adversarial loss: 0.555838\n",
      "epoch 140; iter: 0; batch classifier loss: 0.458235; batch adversarial loss: 0.570952\n",
      "epoch 141; iter: 0; batch classifier loss: 0.467852; batch adversarial loss: 0.599760\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412985; batch adversarial loss: 0.528679\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382599; batch adversarial loss: 0.544997\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379653; batch adversarial loss: 0.580469\n",
      "epoch 145; iter: 0; batch classifier loss: 0.344550; batch adversarial loss: 0.589460\n",
      "epoch 146; iter: 0; batch classifier loss: 0.408988; batch adversarial loss: 0.554650\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339320; batch adversarial loss: 0.507970\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368751; batch adversarial loss: 0.527740\n",
      "epoch 149; iter: 0; batch classifier loss: 0.356100; batch adversarial loss: 0.499547\n",
      "epoch 150; iter: 0; batch classifier loss: 0.418732; batch adversarial loss: 0.516991\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370853; batch adversarial loss: 0.553511\n",
      "epoch 152; iter: 0; batch classifier loss: 0.265835; batch adversarial loss: 0.526241\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355077; batch adversarial loss: 0.598976\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400688; batch adversarial loss: 0.572269\n",
      "epoch 155; iter: 0; batch classifier loss: 0.434165; batch adversarial loss: 0.435138\n",
      "epoch 156; iter: 0; batch classifier loss: 0.288466; batch adversarial loss: 0.571931\n",
      "epoch 157; iter: 0; batch classifier loss: 0.280822; batch adversarial loss: 0.435176\n",
      "epoch 158; iter: 0; batch classifier loss: 0.280280; batch adversarial loss: 0.607857\n",
      "epoch 159; iter: 0; batch classifier loss: 0.381393; batch adversarial loss: 0.535255\n",
      "epoch 160; iter: 0; batch classifier loss: 0.334507; batch adversarial loss: 0.580869\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354022; batch adversarial loss: 0.552940\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347824; batch adversarial loss: 0.525304\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350897; batch adversarial loss: 0.526342\n",
      "epoch 164; iter: 0; batch classifier loss: 0.313335; batch adversarial loss: 0.514035\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345211; batch adversarial loss: 0.578152\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364886; batch adversarial loss: 0.524016\n",
      "epoch 167; iter: 0; batch classifier loss: 0.339689; batch adversarial loss: 0.565691\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395731; batch adversarial loss: 0.526472\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366790; batch adversarial loss: 0.571093\n",
      "epoch 170; iter: 0; batch classifier loss: 0.409479; batch adversarial loss: 0.550023\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342807; batch adversarial loss: 0.543323\n",
      "epoch 172; iter: 0; batch classifier loss: 0.324034; batch adversarial loss: 0.487105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340203; batch adversarial loss: 0.535159\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347818; batch adversarial loss: 0.545731\n",
      "epoch 175; iter: 0; batch classifier loss: 0.387940; batch adversarial loss: 0.555028\n",
      "epoch 176; iter: 0; batch classifier loss: 0.404204; batch adversarial loss: 0.542704\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339445; batch adversarial loss: 0.644133\n",
      "epoch 178; iter: 0; batch classifier loss: 0.409049; batch adversarial loss: 0.496074\n",
      "epoch 179; iter: 0; batch classifier loss: 0.336847; batch adversarial loss: 0.486005\n",
      "epoch 180; iter: 0; batch classifier loss: 0.383603; batch adversarial loss: 0.500364\n",
      "epoch 181; iter: 0; batch classifier loss: 0.415709; batch adversarial loss: 0.553567\n",
      "epoch 182; iter: 0; batch classifier loss: 0.444827; batch adversarial loss: 0.629177\n",
      "epoch 183; iter: 0; batch classifier loss: 0.443515; batch adversarial loss: 0.558624\n",
      "epoch 184; iter: 0; batch classifier loss: 0.345219; batch adversarial loss: 0.547237\n",
      "epoch 185; iter: 0; batch classifier loss: 0.347174; batch adversarial loss: 0.523781\n",
      "epoch 186; iter: 0; batch classifier loss: 0.360073; batch adversarial loss: 0.602080\n",
      "epoch 187; iter: 0; batch classifier loss: 0.278378; batch adversarial loss: 0.542871\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335878; batch adversarial loss: 0.496557\n",
      "epoch 189; iter: 0; batch classifier loss: 0.290386; batch adversarial loss: 0.606685\n",
      "epoch 190; iter: 0; batch classifier loss: 0.374413; batch adversarial loss: 0.518122\n",
      "epoch 191; iter: 0; batch classifier loss: 0.345075; batch adversarial loss: 0.561288\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373099; batch adversarial loss: 0.498894\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343942; batch adversarial loss: 0.485248\n",
      "epoch 194; iter: 0; batch classifier loss: 0.331388; batch adversarial loss: 0.575490\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351431; batch adversarial loss: 0.525729\n",
      "epoch 196; iter: 0; batch classifier loss: 0.377307; batch adversarial loss: 0.526510\n",
      "epoch 197; iter: 0; batch classifier loss: 0.430170; batch adversarial loss: 0.551917\n",
      "epoch 198; iter: 0; batch classifier loss: 0.315136; batch adversarial loss: 0.554365\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308942; batch adversarial loss: 0.553820\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696694; batch adversarial loss: 0.717606\n",
      "epoch 1; iter: 0; batch classifier loss: 0.500329; batch adversarial loss: 0.682611\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613687; batch adversarial loss: 0.648871\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612303; batch adversarial loss: 0.633820\n",
      "epoch 4; iter: 0; batch classifier loss: 0.578043; batch adversarial loss: 0.600060\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575297; batch adversarial loss: 0.608184\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529924; batch adversarial loss: 0.604420\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601384; batch adversarial loss: 0.613177\n",
      "epoch 8; iter: 0; batch classifier loss: 0.496412; batch adversarial loss: 0.613057\n",
      "epoch 9; iter: 0; batch classifier loss: 0.626692; batch adversarial loss: 0.536415\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555917; batch adversarial loss: 0.626148\n",
      "epoch 11; iter: 0; batch classifier loss: 0.611328; batch adversarial loss: 0.555990\n",
      "epoch 12; iter: 0; batch classifier loss: 0.472441; batch adversarial loss: 0.633935\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505594; batch adversarial loss: 0.610291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.565370; batch adversarial loss: 0.554661\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552425; batch adversarial loss: 0.525146\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493553; batch adversarial loss: 0.575096\n",
      "epoch 17; iter: 0; batch classifier loss: 0.569713; batch adversarial loss: 0.535582\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534226; batch adversarial loss: 0.516246\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523189; batch adversarial loss: 0.618809\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489141; batch adversarial loss: 0.553402\n",
      "epoch 21; iter: 0; batch classifier loss: 0.575023; batch adversarial loss: 0.567306\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459493; batch adversarial loss: 0.509414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.474078; batch adversarial loss: 0.505880\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446768; batch adversarial loss: 0.564275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470496; batch adversarial loss: 0.523641\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493097; batch adversarial loss: 0.557610\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484451; batch adversarial loss: 0.588549\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494049; batch adversarial loss: 0.586709\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447384; batch adversarial loss: 0.554307\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488243; batch adversarial loss: 0.505332\n",
      "epoch 31; iter: 0; batch classifier loss: 0.519813; batch adversarial loss: 0.478719\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496929; batch adversarial loss: 0.585738\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456231; batch adversarial loss: 0.569605\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435739; batch adversarial loss: 0.558393\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438830; batch adversarial loss: 0.644992\n",
      "epoch 36; iter: 0; batch classifier loss: 0.491876; batch adversarial loss: 0.537950\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431637; batch adversarial loss: 0.574551\n",
      "epoch 38; iter: 0; batch classifier loss: 0.494914; batch adversarial loss: 0.555671\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434174; batch adversarial loss: 0.640300\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440155; batch adversarial loss: 0.481026\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421454; batch adversarial loss: 0.566722\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415226; batch adversarial loss: 0.526516\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412776; batch adversarial loss: 0.501439\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396998; batch adversarial loss: 0.599704\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405080; batch adversarial loss: 0.467039\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402069; batch adversarial loss: 0.544343\n",
      "epoch 47; iter: 0; batch classifier loss: 0.346965; batch adversarial loss: 0.510216\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440580; batch adversarial loss: 0.545530\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427352; batch adversarial loss: 0.520078\n",
      "epoch 50; iter: 0; batch classifier loss: 0.464270; batch adversarial loss: 0.545410\n",
      "epoch 51; iter: 0; batch classifier loss: 0.387531; batch adversarial loss: 0.544614\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412665; batch adversarial loss: 0.526974\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439923; batch adversarial loss: 0.544787\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434461; batch adversarial loss: 0.597419\n",
      "epoch 55; iter: 0; batch classifier loss: 0.380758; batch adversarial loss: 0.589362\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415298; batch adversarial loss: 0.501802\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400149; batch adversarial loss: 0.545369\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410398; batch adversarial loss: 0.517633\n",
      "epoch 59; iter: 0; batch classifier loss: 0.430499; batch adversarial loss: 0.535576\n",
      "epoch 60; iter: 0; batch classifier loss: 0.480182; batch adversarial loss: 0.527401\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399768; batch adversarial loss: 0.633504\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378752; batch adversarial loss: 0.561795\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449679; batch adversarial loss: 0.536272\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397547; batch adversarial loss: 0.580044\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369381; batch adversarial loss: 0.518732\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446767; batch adversarial loss: 0.570901\n",
      "epoch 67; iter: 0; batch classifier loss: 0.465624; batch adversarial loss: 0.579764\n",
      "epoch 68; iter: 0; batch classifier loss: 0.433635; batch adversarial loss: 0.536026\n",
      "epoch 69; iter: 0; batch classifier loss: 0.341126; batch adversarial loss: 0.588872\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462551; batch adversarial loss: 0.509162\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384501; batch adversarial loss: 0.624027\n",
      "epoch 72; iter: 0; batch classifier loss: 0.339616; batch adversarial loss: 0.553319\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390872; batch adversarial loss: 0.571668\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396000; batch adversarial loss: 0.518502\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396559; batch adversarial loss: 0.606305\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384808; batch adversarial loss: 0.597382\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387196; batch adversarial loss: 0.597214\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402740; batch adversarial loss: 0.580009\n",
      "epoch 79; iter: 0; batch classifier loss: 0.453996; batch adversarial loss: 0.517788\n",
      "epoch 80; iter: 0; batch classifier loss: 0.474077; batch adversarial loss: 0.562621\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432614; batch adversarial loss: 0.570974\n",
      "epoch 82; iter: 0; batch classifier loss: 0.324899; batch adversarial loss: 0.413128\n",
      "epoch 83; iter: 0; batch classifier loss: 0.436158; batch adversarial loss: 0.641451\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430534; batch adversarial loss: 0.642194\n",
      "epoch 85; iter: 0; batch classifier loss: 0.466154; batch adversarial loss: 0.509382\n",
      "epoch 86; iter: 0; batch classifier loss: 0.471552; batch adversarial loss: 0.623569\n",
      "epoch 87; iter: 0; batch classifier loss: 0.409265; batch adversarial loss: 0.625575\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383630; batch adversarial loss: 0.526882\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402919; batch adversarial loss: 0.651582\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370100; batch adversarial loss: 0.500357\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434378; batch adversarial loss: 0.571301\n",
      "epoch 92; iter: 0; batch classifier loss: 0.430533; batch adversarial loss: 0.571151\n",
      "epoch 93; iter: 0; batch classifier loss: 0.452075; batch adversarial loss: 0.571453\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381002; batch adversarial loss: 0.571678\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345422; batch adversarial loss: 0.500751\n",
      "epoch 96; iter: 0; batch classifier loss: 0.309302; batch adversarial loss: 0.633295\n",
      "epoch 97; iter: 0; batch classifier loss: 0.458475; batch adversarial loss: 0.518405\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371136; batch adversarial loss: 0.508999\n",
      "epoch 99; iter: 0; batch classifier loss: 0.455922; batch adversarial loss: 0.642541\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373436; batch adversarial loss: 0.507535\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405272; batch adversarial loss: 0.554052\n",
      "epoch 102; iter: 0; batch classifier loss: 0.424754; batch adversarial loss: 0.499942\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398582; batch adversarial loss: 0.500771\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393967; batch adversarial loss: 0.597401\n",
      "epoch 105; iter: 0; batch classifier loss: 0.323294; batch adversarial loss: 0.571116\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328491; batch adversarial loss: 0.562086\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431758; batch adversarial loss: 0.588705\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354794; batch adversarial loss: 0.536245\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421525; batch adversarial loss: 0.544953\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356467; batch adversarial loss: 0.570678\n",
      "epoch 111; iter: 0; batch classifier loss: 0.446001; batch adversarial loss: 0.614405\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412690; batch adversarial loss: 0.536154\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347342; batch adversarial loss: 0.579866\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363416; batch adversarial loss: 0.579961\n",
      "epoch 115; iter: 0; batch classifier loss: 0.369740; batch adversarial loss: 0.639484\n",
      "epoch 116; iter: 0; batch classifier loss: 0.409255; batch adversarial loss: 0.606017\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384259; batch adversarial loss: 0.509031\n",
      "epoch 118; iter: 0; batch classifier loss: 0.426628; batch adversarial loss: 0.614131\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354405; batch adversarial loss: 0.588037\n",
      "epoch 120; iter: 0; batch classifier loss: 0.336863; batch adversarial loss: 0.606983\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394739; batch adversarial loss: 0.625046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.543073; batch adversarial loss: 0.589640\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367014; batch adversarial loss: 0.643029\n",
      "epoch 124; iter: 0; batch classifier loss: 0.410170; batch adversarial loss: 0.607005\n",
      "epoch 125; iter: 0; batch classifier loss: 0.472753; batch adversarial loss: 0.447861\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360697; batch adversarial loss: 0.527753\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365940; batch adversarial loss: 0.500825\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366447; batch adversarial loss: 0.623845\n",
      "epoch 129; iter: 0; batch classifier loss: 0.285352; batch adversarial loss: 0.571287\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414284; batch adversarial loss: 0.597242\n",
      "epoch 131; iter: 0; batch classifier loss: 0.482279; batch adversarial loss: 0.536548\n",
      "epoch 132; iter: 0; batch classifier loss: 0.458273; batch adversarial loss: 0.535841\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355896; batch adversarial loss: 0.606265\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364355; batch adversarial loss: 0.440367\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382085; batch adversarial loss: 0.570708\n",
      "epoch 136; iter: 0; batch classifier loss: 0.451486; batch adversarial loss: 0.589353\n",
      "epoch 137; iter: 0; batch classifier loss: 0.322216; batch adversarial loss: 0.500259\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345916; batch adversarial loss: 0.483010\n",
      "epoch 139; iter: 0; batch classifier loss: 0.475105; batch adversarial loss: 0.596978\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397881; batch adversarial loss: 0.571391\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337233; batch adversarial loss: 0.571324\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378469; batch adversarial loss: 0.535448\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354626; batch adversarial loss: 0.553905\n",
      "epoch 144; iter: 0; batch classifier loss: 0.440070; batch adversarial loss: 0.625389\n",
      "epoch 145; iter: 0; batch classifier loss: 0.441426; batch adversarial loss: 0.634180\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359702; batch adversarial loss: 0.554024\n",
      "epoch 147; iter: 0; batch classifier loss: 0.426555; batch adversarial loss: 0.580494\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353220; batch adversarial loss: 0.492050\n",
      "epoch 149; iter: 0; batch classifier loss: 0.390310; batch adversarial loss: 0.535636\n",
      "epoch 150; iter: 0; batch classifier loss: 0.404336; batch adversarial loss: 0.553490\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363895; batch adversarial loss: 0.535828\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369770; batch adversarial loss: 0.562335\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329439; batch adversarial loss: 0.500720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382931; batch adversarial loss: 0.588759\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351936; batch adversarial loss: 0.518402\n",
      "epoch 156; iter: 0; batch classifier loss: 0.431848; batch adversarial loss: 0.597980\n",
      "epoch 157; iter: 0; batch classifier loss: 0.401600; batch adversarial loss: 0.535992\n",
      "epoch 158; iter: 0; batch classifier loss: 0.416653; batch adversarial loss: 0.509412\n",
      "epoch 159; iter: 0; batch classifier loss: 0.401590; batch adversarial loss: 0.527294\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384831; batch adversarial loss: 0.553553\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339101; batch adversarial loss: 0.571147\n",
      "epoch 162; iter: 0; batch classifier loss: 0.419346; batch adversarial loss: 0.597607\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366939; batch adversarial loss: 0.562208\n",
      "epoch 164; iter: 0; batch classifier loss: 0.314001; batch adversarial loss: 0.598071\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380347; batch adversarial loss: 0.570969\n",
      "epoch 166; iter: 0; batch classifier loss: 0.326591; batch adversarial loss: 0.597894\n",
      "epoch 167; iter: 0; batch classifier loss: 0.313219; batch adversarial loss: 0.615982\n",
      "epoch 168; iter: 0; batch classifier loss: 0.425197; batch adversarial loss: 0.588972\n",
      "epoch 169; iter: 0; batch classifier loss: 0.295746; batch adversarial loss: 0.570828\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371778; batch adversarial loss: 0.536183\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346713; batch adversarial loss: 0.553217\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366313; batch adversarial loss: 0.544912\n",
      "epoch 173; iter: 0; batch classifier loss: 0.347448; batch adversarial loss: 0.571051\n",
      "epoch 174; iter: 0; batch classifier loss: 0.420283; batch adversarial loss: 0.571152\n",
      "epoch 175; iter: 0; batch classifier loss: 0.414354; batch adversarial loss: 0.571191\n",
      "epoch 176; iter: 0; batch classifier loss: 0.565414; batch adversarial loss: 0.553665\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360688; batch adversarial loss: 0.527167\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361233; batch adversarial loss: 0.492258\n",
      "epoch 179; iter: 0; batch classifier loss: 0.427497; batch adversarial loss: 0.571157\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374397; batch adversarial loss: 0.580015\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363836; batch adversarial loss: 0.500973\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364030; batch adversarial loss: 0.579797\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352819; batch adversarial loss: 0.589007\n",
      "epoch 184; iter: 0; batch classifier loss: 0.414742; batch adversarial loss: 0.562416\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383364; batch adversarial loss: 0.526963\n",
      "epoch 186; iter: 0; batch classifier loss: 0.426620; batch adversarial loss: 0.536039\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359887; batch adversarial loss: 0.509342\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376762; batch adversarial loss: 0.562273\n",
      "epoch 189; iter: 0; batch classifier loss: 0.390266; batch adversarial loss: 0.553993\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349778; batch adversarial loss: 0.597513\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336112; batch adversarial loss: 0.508563\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367372; batch adversarial loss: 0.509180\n",
      "epoch 193; iter: 0; batch classifier loss: 0.381051; batch adversarial loss: 0.641985\n",
      "epoch 194; iter: 0; batch classifier loss: 0.275807; batch adversarial loss: 0.579980\n",
      "epoch 195; iter: 0; batch classifier loss: 0.458570; batch adversarial loss: 0.571657\n",
      "epoch 196; iter: 0; batch classifier loss: 0.353710; batch adversarial loss: 0.500966\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323832; batch adversarial loss: 0.544853\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332883; batch adversarial loss: 0.518518\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331546; batch adversarial loss: 0.535915\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688091; batch adversarial loss: 0.774970\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632819; batch adversarial loss: 0.695662\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587851; batch adversarial loss: 0.663817\n",
      "epoch 3; iter: 0; batch classifier loss: 0.599424; batch adversarial loss: 0.630736\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572703; batch adversarial loss: 0.611001\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558973; batch adversarial loss: 0.587752\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547453; batch adversarial loss: 0.590864\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580028; batch adversarial loss: 0.567501\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530021; batch adversarial loss: 0.595000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567289; batch adversarial loss: 0.554253\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492039; batch adversarial loss: 0.533985\n",
      "epoch 11; iter: 0; batch classifier loss: 0.486002; batch adversarial loss: 0.559969\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529783; batch adversarial loss: 0.566741\n",
      "epoch 13; iter: 0; batch classifier loss: 0.655559; batch adversarial loss: 0.624375\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495300; batch adversarial loss: 0.606660\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526209; batch adversarial loss: 0.543553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525613; batch adversarial loss: 0.589812\n",
      "epoch 17; iter: 0; batch classifier loss: 0.639740; batch adversarial loss: 0.613383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.442901; batch adversarial loss: 0.560401\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515041; batch adversarial loss: 0.595055\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433124; batch adversarial loss: 0.525908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.579000; batch adversarial loss: 0.568191\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433210; batch adversarial loss: 0.555843\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455667; batch adversarial loss: 0.516445\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506404; batch adversarial loss: 0.488561\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428545; batch adversarial loss: 0.476966\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472280; batch adversarial loss: 0.553489\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469104; batch adversarial loss: 0.556858\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532587; batch adversarial loss: 0.533705\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481522; batch adversarial loss: 0.598811\n",
      "epoch 30; iter: 0; batch classifier loss: 0.578035; batch adversarial loss: 0.463461\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517583; batch adversarial loss: 0.513487\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504544; batch adversarial loss: 0.550103\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488687; batch adversarial loss: 0.572023\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406380; batch adversarial loss: 0.588170\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444228; batch adversarial loss: 0.545347\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422298; batch adversarial loss: 0.450674\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461650; batch adversarial loss: 0.624678\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420098; batch adversarial loss: 0.518442\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437784; batch adversarial loss: 0.554334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.537705; batch adversarial loss: 0.527078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433040; batch adversarial loss: 0.544577\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423632; batch adversarial loss: 0.588564\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442135; batch adversarial loss: 0.454646\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382403; batch adversarial loss: 0.535532\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455965; batch adversarial loss: 0.562444\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423505; batch adversarial loss: 0.509231\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418368; batch adversarial loss: 0.508028\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418228; batch adversarial loss: 0.526137\n",
      "epoch 49; iter: 0; batch classifier loss: 0.356500; batch adversarial loss: 0.498949\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374303; batch adversarial loss: 0.627103\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424180; batch adversarial loss: 0.572861\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404678; batch adversarial loss: 0.544903\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400133; batch adversarial loss: 0.527553\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384416; batch adversarial loss: 0.544030\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397180; batch adversarial loss: 0.553851\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429382; batch adversarial loss: 0.415856\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407594; batch adversarial loss: 0.525887\n",
      "epoch 58; iter: 0; batch classifier loss: 0.374343; batch adversarial loss: 0.598666\n",
      "epoch 59; iter: 0; batch classifier loss: 0.486647; batch adversarial loss: 0.533874\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416798; batch adversarial loss: 0.581851\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379599; batch adversarial loss: 0.544481\n",
      "epoch 62; iter: 0; batch classifier loss: 0.492596; batch adversarial loss: 0.535135\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423035; batch adversarial loss: 0.617488\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361694; batch adversarial loss: 0.535406\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449602; batch adversarial loss: 0.591716\n",
      "epoch 66; iter: 0; batch classifier loss: 0.364127; batch adversarial loss: 0.564264\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372271; batch adversarial loss: 0.497151\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373742; batch adversarial loss: 0.517310\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429037; batch adversarial loss: 0.479192\n",
      "epoch 70; iter: 0; batch classifier loss: 0.367107; batch adversarial loss: 0.529540\n",
      "epoch 71; iter: 0; batch classifier loss: 0.454575; batch adversarial loss: 0.517201\n",
      "epoch 72; iter: 0; batch classifier loss: 0.364960; batch adversarial loss: 0.610182\n",
      "epoch 73; iter: 0; batch classifier loss: 0.468227; batch adversarial loss: 0.490085\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411396; batch adversarial loss: 0.609402\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384967; batch adversarial loss: 0.607937\n",
      "epoch 76; iter: 0; batch classifier loss: 0.357368; batch adversarial loss: 0.535785\n",
      "epoch 77; iter: 0; batch classifier loss: 0.439300; batch adversarial loss: 0.616908\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396717; batch adversarial loss: 0.572207\n",
      "epoch 79; iter: 0; batch classifier loss: 0.443118; batch adversarial loss: 0.608226\n",
      "epoch 80; iter: 0; batch classifier loss: 0.492768; batch adversarial loss: 0.517151\n",
      "epoch 81; iter: 0; batch classifier loss: 0.341492; batch adversarial loss: 0.535152\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443267; batch adversarial loss: 0.489225\n",
      "epoch 83; iter: 0; batch classifier loss: 0.361546; batch adversarial loss: 0.526525\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398207; batch adversarial loss: 0.517175\n",
      "epoch 85; iter: 0; batch classifier loss: 0.394523; batch adversarial loss: 0.544205\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400778; batch adversarial loss: 0.553433\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386301; batch adversarial loss: 0.544422\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396330; batch adversarial loss: 0.581309\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427839; batch adversarial loss: 0.442260\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369838; batch adversarial loss: 0.526932\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370541; batch adversarial loss: 0.535866\n",
      "epoch 92; iter: 0; batch classifier loss: 0.442092; batch adversarial loss: 0.572022\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328666; batch adversarial loss: 0.525436\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360404; batch adversarial loss: 0.479728\n",
      "epoch 95; iter: 0; batch classifier loss: 0.355869; batch adversarial loss: 0.517099\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361373; batch adversarial loss: 0.461901\n",
      "epoch 97; iter: 0; batch classifier loss: 0.481094; batch adversarial loss: 0.442974\n",
      "epoch 98; iter: 0; batch classifier loss: 0.448166; batch adversarial loss: 0.517257\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412893; batch adversarial loss: 0.544322\n",
      "epoch 100; iter: 0; batch classifier loss: 0.448410; batch adversarial loss: 0.525674\n",
      "epoch 101; iter: 0; batch classifier loss: 0.448341; batch adversarial loss: 0.535159\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372476; batch adversarial loss: 0.572049\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404418; batch adversarial loss: 0.535246\n",
      "epoch 104; iter: 0; batch classifier loss: 0.455218; batch adversarial loss: 0.507825\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388053; batch adversarial loss: 0.507461\n",
      "epoch 106; iter: 0; batch classifier loss: 0.296986; batch adversarial loss: 0.600466\n",
      "epoch 107; iter: 0; batch classifier loss: 0.478547; batch adversarial loss: 0.562695\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396778; batch adversarial loss: 0.534732\n",
      "epoch 109; iter: 0; batch classifier loss: 0.443776; batch adversarial loss: 0.526596\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398240; batch adversarial loss: 0.572490\n",
      "epoch 111; iter: 0; batch classifier loss: 0.328316; batch adversarial loss: 0.489002\n",
      "epoch 112; iter: 0; batch classifier loss: 0.456594; batch adversarial loss: 0.562928\n",
      "epoch 113; iter: 0; batch classifier loss: 0.310094; batch adversarial loss: 0.590472\n",
      "epoch 114; iter: 0; batch classifier loss: 0.338271; batch adversarial loss: 0.526122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.360717; batch adversarial loss: 0.571842\n",
      "epoch 116; iter: 0; batch classifier loss: 0.480410; batch adversarial loss: 0.581741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.423138; batch adversarial loss: 0.471050\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363103; batch adversarial loss: 0.580971\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368218; batch adversarial loss: 0.563372\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428719; batch adversarial loss: 0.572599\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404132; batch adversarial loss: 0.479053\n",
      "epoch 122; iter: 0; batch classifier loss: 0.318242; batch adversarial loss: 0.627877\n",
      "epoch 123; iter: 0; batch classifier loss: 0.413278; batch adversarial loss: 0.561932\n",
      "epoch 124; iter: 0; batch classifier loss: 0.479643; batch adversarial loss: 0.598914\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362038; batch adversarial loss: 0.516029\n",
      "epoch 126; iter: 0; batch classifier loss: 0.447065; batch adversarial loss: 0.616850\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376781; batch adversarial loss: 0.499160\n",
      "epoch 128; iter: 0; batch classifier loss: 0.405884; batch adversarial loss: 0.644060\n",
      "epoch 129; iter: 0; batch classifier loss: 0.351258; batch adversarial loss: 0.517991\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374080; batch adversarial loss: 0.617217\n",
      "epoch 131; iter: 0; batch classifier loss: 0.402995; batch adversarial loss: 0.515279\n",
      "epoch 132; iter: 0; batch classifier loss: 0.438461; batch adversarial loss: 0.555245\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370233; batch adversarial loss: 0.553546\n",
      "epoch 134; iter: 0; batch classifier loss: 0.319517; batch adversarial loss: 0.644273\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346829; batch adversarial loss: 0.573911\n",
      "epoch 136; iter: 0; batch classifier loss: 0.337239; batch adversarial loss: 0.488038\n",
      "epoch 137; iter: 0; batch classifier loss: 0.415414; batch adversarial loss: 0.500538\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364952; batch adversarial loss: 0.544720\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408552; batch adversarial loss: 0.598557\n",
      "epoch 140; iter: 0; batch classifier loss: 0.316771; batch adversarial loss: 0.553395\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348880; batch adversarial loss: 0.625949\n",
      "epoch 142; iter: 0; batch classifier loss: 0.456947; batch adversarial loss: 0.544658\n",
      "epoch 143; iter: 0; batch classifier loss: 0.448032; batch adversarial loss: 0.517273\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384379; batch adversarial loss: 0.581003\n",
      "epoch 145; iter: 0; batch classifier loss: 0.415433; batch adversarial loss: 0.544609\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339599; batch adversarial loss: 0.590232\n",
      "epoch 147; iter: 0; batch classifier loss: 0.352895; batch adversarial loss: 0.599912\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357857; batch adversarial loss: 0.572137\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415743; batch adversarial loss: 0.553943\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367194; batch adversarial loss: 0.590852\n",
      "epoch 151; iter: 0; batch classifier loss: 0.329300; batch adversarial loss: 0.480138\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356575; batch adversarial loss: 0.553669\n",
      "epoch 153; iter: 0; batch classifier loss: 0.395177; batch adversarial loss: 0.627399\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348465; batch adversarial loss: 0.553982\n",
      "epoch 155; iter: 0; batch classifier loss: 0.438552; batch adversarial loss: 0.544569\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362801; batch adversarial loss: 0.590241\n",
      "epoch 157; iter: 0; batch classifier loss: 0.396284; batch adversarial loss: 0.581156\n",
      "epoch 158; iter: 0; batch classifier loss: 0.322997; batch adversarial loss: 0.480891\n",
      "epoch 159; iter: 0; batch classifier loss: 0.428207; batch adversarial loss: 0.571522\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373978; batch adversarial loss: 0.444547\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367393; batch adversarial loss: 0.535580\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328189; batch adversarial loss: 0.499160\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373936; batch adversarial loss: 0.589860\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375285; batch adversarial loss: 0.535528\n",
      "epoch 165; iter: 0; batch classifier loss: 0.322342; batch adversarial loss: 0.517921\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350293; batch adversarial loss: 0.525429\n",
      "epoch 167; iter: 0; batch classifier loss: 0.405011; batch adversarial loss: 0.571629\n",
      "epoch 168; iter: 0; batch classifier loss: 0.297055; batch adversarial loss: 0.600745\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381201; batch adversarial loss: 0.535017\n",
      "epoch 170; iter: 0; batch classifier loss: 0.304203; batch adversarial loss: 0.609253\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392634; batch adversarial loss: 0.562869\n",
      "epoch 172; iter: 0; batch classifier loss: 0.435813; batch adversarial loss: 0.498547\n",
      "epoch 173; iter: 0; batch classifier loss: 0.303630; batch adversarial loss: 0.562131\n",
      "epoch 174; iter: 0; batch classifier loss: 0.312946; batch adversarial loss: 0.575174\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376979; batch adversarial loss: 0.437495\n",
      "epoch 176; iter: 0; batch classifier loss: 0.414019; batch adversarial loss: 0.545128\n",
      "epoch 177; iter: 0; batch classifier loss: 0.405639; batch adversarial loss: 0.489501\n",
      "epoch 178; iter: 0; batch classifier loss: 0.324287; batch adversarial loss: 0.609457\n",
      "epoch 179; iter: 0; batch classifier loss: 0.328610; batch adversarial loss: 0.516245\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414361; batch adversarial loss: 0.562543\n",
      "epoch 181; iter: 0; batch classifier loss: 0.318863; batch adversarial loss: 0.693779\n",
      "epoch 182; iter: 0; batch classifier loss: 0.447868; batch adversarial loss: 0.459204\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337986; batch adversarial loss: 0.579928\n",
      "epoch 184; iter: 0; batch classifier loss: 0.345446; batch adversarial loss: 0.518641\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330423; batch adversarial loss: 0.534879\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318932; batch adversarial loss: 0.543268\n",
      "epoch 187; iter: 0; batch classifier loss: 0.387984; batch adversarial loss: 0.553221\n",
      "epoch 188; iter: 0; batch classifier loss: 0.403905; batch adversarial loss: 0.460866\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384885; batch adversarial loss: 0.591778\n",
      "epoch 190; iter: 0; batch classifier loss: 0.356934; batch adversarial loss: 0.563331\n",
      "epoch 191; iter: 0; batch classifier loss: 0.300404; batch adversarial loss: 0.506804\n",
      "epoch 192; iter: 0; batch classifier loss: 0.443235; batch adversarial loss: 0.543636\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364637; batch adversarial loss: 0.506380\n",
      "epoch 194; iter: 0; batch classifier loss: 0.302371; batch adversarial loss: 0.562046\n",
      "epoch 195; iter: 0; batch classifier loss: 0.377183; batch adversarial loss: 0.462289\n",
      "epoch 196; iter: 0; batch classifier loss: 0.302720; batch adversarial loss: 0.562999\n",
      "epoch 197; iter: 0; batch classifier loss: 0.330327; batch adversarial loss: 0.535347\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306017; batch adversarial loss: 0.516773\n",
      "epoch 199; iter: 0; batch classifier loss: 0.400845; batch adversarial loss: 0.544704\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690425; batch adversarial loss: 0.755622\n",
      "epoch 1; iter: 0; batch classifier loss: 0.786816; batch adversarial loss: 0.908028\n",
      "epoch 2; iter: 0; batch classifier loss: 0.927819; batch adversarial loss: 0.877509\n",
      "epoch 3; iter: 0; batch classifier loss: 0.956286; batch adversarial loss: 0.804022\n",
      "epoch 4; iter: 0; batch classifier loss: 0.926096; batch adversarial loss: 0.726253\n",
      "epoch 5; iter: 0; batch classifier loss: 0.914292; batch adversarial loss: 0.683502\n",
      "epoch 6; iter: 0; batch classifier loss: 0.681227; batch adversarial loss: 0.624016\n",
      "epoch 7; iter: 0; batch classifier loss: 0.572522; batch adversarial loss: 0.603311\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550846; batch adversarial loss: 0.613066\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567300; batch adversarial loss: 0.593284\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547415; batch adversarial loss: 0.578487\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543778; batch adversarial loss: 0.574273\n",
      "epoch 12; iter: 0; batch classifier loss: 0.520480; batch adversarial loss: 0.564175\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573073; batch adversarial loss: 0.572146\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511305; batch adversarial loss: 0.635651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.532731; batch adversarial loss: 0.530892\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423039; batch adversarial loss: 0.556615\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467708; batch adversarial loss: 0.585408\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476343; batch adversarial loss: 0.546094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.450662; batch adversarial loss: 0.522314\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519355; batch adversarial loss: 0.497729\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477949; batch adversarial loss: 0.573708\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450109; batch adversarial loss: 0.539762\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511815; batch adversarial loss: 0.626519\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497241; batch adversarial loss: 0.566415\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452130; batch adversarial loss: 0.583519\n",
      "epoch 26; iter: 0; batch classifier loss: 0.404418; batch adversarial loss: 0.557041\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518735; batch adversarial loss: 0.503429\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471710; batch adversarial loss: 0.509838\n",
      "epoch 29; iter: 0; batch classifier loss: 0.449996; batch adversarial loss: 0.529721\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503959; batch adversarial loss: 0.495036\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474038; batch adversarial loss: 0.568325\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516247; batch adversarial loss: 0.483745\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450259; batch adversarial loss: 0.591138\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509465; batch adversarial loss: 0.539151\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400187; batch adversarial loss: 0.533859\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426476; batch adversarial loss: 0.583490\n",
      "epoch 37; iter: 0; batch classifier loss: 0.435189; batch adversarial loss: 0.599144\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442706; batch adversarial loss: 0.583947\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493144; batch adversarial loss: 0.560554\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452705; batch adversarial loss: 0.550107\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449699; batch adversarial loss: 0.508442\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446563; batch adversarial loss: 0.598970\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422521; batch adversarial loss: 0.657833\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390556; batch adversarial loss: 0.533699\n",
      "epoch 45; iter: 0; batch classifier loss: 0.410510; batch adversarial loss: 0.535326\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459560; batch adversarial loss: 0.520345\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437387; batch adversarial loss: 0.516542\n",
      "epoch 48; iter: 0; batch classifier loss: 0.436866; batch adversarial loss: 0.597418\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394360; batch adversarial loss: 0.564979\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426284; batch adversarial loss: 0.527662\n",
      "epoch 51; iter: 0; batch classifier loss: 0.381002; batch adversarial loss: 0.580280\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393288; batch adversarial loss: 0.551710\n",
      "epoch 53; iter: 0; batch classifier loss: 0.349010; batch adversarial loss: 0.570945\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424132; batch adversarial loss: 0.535567\n",
      "epoch 55; iter: 0; batch classifier loss: 0.337949; batch adversarial loss: 0.589188\n",
      "epoch 56; iter: 0; batch classifier loss: 0.343155; batch adversarial loss: 0.562979\n",
      "epoch 57; iter: 0; batch classifier loss: 0.479990; batch adversarial loss: 0.553339\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439498; batch adversarial loss: 0.526380\n",
      "epoch 59; iter: 0; batch classifier loss: 0.370672; batch adversarial loss: 0.635317\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398288; batch adversarial loss: 0.616937\n",
      "epoch 61; iter: 0; batch classifier loss: 0.327798; batch adversarial loss: 0.553625\n",
      "epoch 62; iter: 0; batch classifier loss: 0.476745; batch adversarial loss: 0.562560\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408598; batch adversarial loss: 0.517542\n",
      "epoch 64; iter: 0; batch classifier loss: 0.417556; batch adversarial loss: 0.580907\n",
      "epoch 65; iter: 0; batch classifier loss: 0.538766; batch adversarial loss: 0.572160\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387675; batch adversarial loss: 0.489628\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420272; batch adversarial loss: 0.553318\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426413; batch adversarial loss: 0.572133\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436761; batch adversarial loss: 0.514211\n",
      "epoch 70; iter: 0; batch classifier loss: 0.341999; batch adversarial loss: 0.507919\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366308; batch adversarial loss: 0.544988\n",
      "epoch 72; iter: 0; batch classifier loss: 0.439313; batch adversarial loss: 0.552223\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383740; batch adversarial loss: 0.571870\n",
      "epoch 74; iter: 0; batch classifier loss: 0.409719; batch adversarial loss: 0.564381\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344347; batch adversarial loss: 0.480842\n",
      "epoch 76; iter: 0; batch classifier loss: 0.347734; batch adversarial loss: 0.607866\n",
      "epoch 77; iter: 0; batch classifier loss: 0.447332; batch adversarial loss: 0.532228\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350173; batch adversarial loss: 0.481178\n",
      "epoch 79; iter: 0; batch classifier loss: 0.350544; batch adversarial loss: 0.526704\n",
      "epoch 80; iter: 0; batch classifier loss: 0.335809; batch adversarial loss: 0.534782\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391391; batch adversarial loss: 0.570002\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388926; batch adversarial loss: 0.536937\n",
      "epoch 83; iter: 0; batch classifier loss: 0.349239; batch adversarial loss: 0.544402\n",
      "epoch 84; iter: 0; batch classifier loss: 0.324313; batch adversarial loss: 0.628406\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409527; batch adversarial loss: 0.488460\n",
      "epoch 86; iter: 0; batch classifier loss: 0.347312; batch adversarial loss: 0.526073\n",
      "epoch 87; iter: 0; batch classifier loss: 0.338900; batch adversarial loss: 0.562484\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395074; batch adversarial loss: 0.562779\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394881; batch adversarial loss: 0.562487\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432988; batch adversarial loss: 0.590895\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356670; batch adversarial loss: 0.553221\n",
      "epoch 92; iter: 0; batch classifier loss: 0.338667; batch adversarial loss: 0.590449\n",
      "epoch 93; iter: 0; batch classifier loss: 0.333274; batch adversarial loss: 0.590002\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385267; batch adversarial loss: 0.554468\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398113; batch adversarial loss: 0.517054\n",
      "epoch 96; iter: 0; batch classifier loss: 0.333227; batch adversarial loss: 0.590181\n",
      "epoch 97; iter: 0; batch classifier loss: 0.352123; batch adversarial loss: 0.572864\n",
      "epoch 98; iter: 0; batch classifier loss: 0.449419; batch adversarial loss: 0.517207\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344537; batch adversarial loss: 0.590588\n",
      "epoch 100; iter: 0; batch classifier loss: 0.315055; batch adversarial loss: 0.544639\n",
      "epoch 101; iter: 0; batch classifier loss: 0.333381; batch adversarial loss: 0.561816\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376943; batch adversarial loss: 0.554242\n",
      "epoch 103; iter: 0; batch classifier loss: 0.281001; batch adversarial loss: 0.509294\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393982; batch adversarial loss: 0.480575\n",
      "epoch 105; iter: 0; batch classifier loss: 0.304778; batch adversarial loss: 0.517927\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333164; batch adversarial loss: 0.535029\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379663; batch adversarial loss: 0.499246\n",
      "epoch 108; iter: 0; batch classifier loss: 0.340882; batch adversarial loss: 0.588732\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372763; batch adversarial loss: 0.489408\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403826; batch adversarial loss: 0.572001\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367228; batch adversarial loss: 0.490494\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375223; batch adversarial loss: 0.563893\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417536; batch adversarial loss: 0.563978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.327627; batch adversarial loss: 0.554566\n",
      "epoch 115; iter: 0; batch classifier loss: 0.277868; batch adversarial loss: 0.536200\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394130; batch adversarial loss: 0.635009\n",
      "epoch 117; iter: 0; batch classifier loss: 0.284356; batch adversarial loss: 0.618151\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360083; batch adversarial loss: 0.619491\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367042; batch adversarial loss: 0.580831\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401170; batch adversarial loss: 0.526487\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398211; batch adversarial loss: 0.528293\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365825; batch adversarial loss: 0.490539\n",
      "epoch 123; iter: 0; batch classifier loss: 0.330779; batch adversarial loss: 0.608567\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401998; batch adversarial loss: 0.581181\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360881; batch adversarial loss: 0.573248\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379555; batch adversarial loss: 0.536194\n",
      "epoch 127; iter: 0; batch classifier loss: 0.302750; batch adversarial loss: 0.498077\n",
      "epoch 128; iter: 0; batch classifier loss: 0.316669; batch adversarial loss: 0.562832\n",
      "epoch 129; iter: 0; batch classifier loss: 0.278191; batch adversarial loss: 0.517314\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322683; batch adversarial loss: 0.580441\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379761; batch adversarial loss: 0.518540\n",
      "epoch 132; iter: 0; batch classifier loss: 0.294851; batch adversarial loss: 0.552290\n",
      "epoch 133; iter: 0; batch classifier loss: 0.365782; batch adversarial loss: 0.535839\n",
      "epoch 134; iter: 0; batch classifier loss: 0.295255; batch adversarial loss: 0.617197\n",
      "epoch 135; iter: 0; batch classifier loss: 0.403279; batch adversarial loss: 0.535877\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324878; batch adversarial loss: 0.570355\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358924; batch adversarial loss: 0.509206\n",
      "epoch 138; iter: 0; batch classifier loss: 0.421975; batch adversarial loss: 0.480486\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350697; batch adversarial loss: 0.591030\n",
      "epoch 140; iter: 0; batch classifier loss: 0.351538; batch adversarial loss: 0.509362\n",
      "epoch 141; iter: 0; batch classifier loss: 0.281792; batch adversarial loss: 0.580569\n",
      "epoch 142; iter: 0; batch classifier loss: 0.308046; batch adversarial loss: 0.489220\n",
      "epoch 143; iter: 0; batch classifier loss: 0.314300; batch adversarial loss: 0.579956\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389496; batch adversarial loss: 0.563470\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363171; batch adversarial loss: 0.543843\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385026; batch adversarial loss: 0.499145\n",
      "epoch 147; iter: 0; batch classifier loss: 0.401374; batch adversarial loss: 0.508520\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365752; batch adversarial loss: 0.599901\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354721; batch adversarial loss: 0.488016\n",
      "epoch 150; iter: 0; batch classifier loss: 0.318193; batch adversarial loss: 0.535557\n",
      "epoch 151; iter: 0; batch classifier loss: 0.321947; batch adversarial loss: 0.490244\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338277; batch adversarial loss: 0.555567\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360960; batch adversarial loss: 0.553098\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313746; batch adversarial loss: 0.507278\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324501; batch adversarial loss: 0.581030\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325068; batch adversarial loss: 0.626430\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344074; batch adversarial loss: 0.471007\n",
      "epoch 158; iter: 0; batch classifier loss: 0.300487; batch adversarial loss: 0.561913\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400340; batch adversarial loss: 0.499506\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340757; batch adversarial loss: 0.562289\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339067; batch adversarial loss: 0.599429\n",
      "epoch 162; iter: 0; batch classifier loss: 0.286823; batch adversarial loss: 0.516298\n",
      "epoch 163; iter: 0; batch classifier loss: 0.337510; batch adversarial loss: 0.507612\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414446; batch adversarial loss: 0.535982\n",
      "epoch 165; iter: 0; batch classifier loss: 0.284712; batch adversarial loss: 0.646151\n",
      "epoch 166; iter: 0; batch classifier loss: 0.326788; batch adversarial loss: 0.516060\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343319; batch adversarial loss: 0.572847\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330661; batch adversarial loss: 0.561803\n",
      "epoch 169; iter: 0; batch classifier loss: 0.320023; batch adversarial loss: 0.507241\n",
      "epoch 170; iter: 0; batch classifier loss: 0.271210; batch adversarial loss: 0.553545\n",
      "epoch 171; iter: 0; batch classifier loss: 0.431247; batch adversarial loss: 0.499081\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334704; batch adversarial loss: 0.443779\n",
      "epoch 173; iter: 0; batch classifier loss: 0.401210; batch adversarial loss: 0.536677\n",
      "epoch 174; iter: 0; batch classifier loss: 0.332516; batch adversarial loss: 0.526300\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336756; batch adversarial loss: 0.561394\n",
      "epoch 176; iter: 0; batch classifier loss: 0.314597; batch adversarial loss: 0.607484\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321489; batch adversarial loss: 0.617718\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333467; batch adversarial loss: 0.607282\n",
      "epoch 179; iter: 0; batch classifier loss: 0.301414; batch adversarial loss: 0.508265\n",
      "epoch 180; iter: 0; batch classifier loss: 0.269376; batch adversarial loss: 0.506582\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325505; batch adversarial loss: 0.554320\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318258; batch adversarial loss: 0.546658\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333992; batch adversarial loss: 0.479514\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309868; batch adversarial loss: 0.553750\n",
      "epoch 185; iter: 0; batch classifier loss: 0.407783; batch adversarial loss: 0.517359\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365176; batch adversarial loss: 0.582450\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310760; batch adversarial loss: 0.563214\n",
      "epoch 188; iter: 0; batch classifier loss: 0.321310; batch adversarial loss: 0.545450\n",
      "epoch 189; iter: 0; batch classifier loss: 0.334888; batch adversarial loss: 0.589162\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360551; batch adversarial loss: 0.624994\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356181; batch adversarial loss: 0.534117\n",
      "epoch 192; iter: 0; batch classifier loss: 0.282721; batch adversarial loss: 0.561572\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345842; batch adversarial loss: 0.555316\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351127; batch adversarial loss: 0.562000\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321860; batch adversarial loss: 0.543958\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357266; batch adversarial loss: 0.528233\n",
      "epoch 197; iter: 0; batch classifier loss: 0.316955; batch adversarial loss: 0.562561\n",
      "epoch 198; iter: 0; batch classifier loss: 0.239828; batch adversarial loss: 0.480158\n",
      "epoch 199; iter: 0; batch classifier loss: 0.246930; batch adversarial loss: 0.635434\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747660; batch adversarial loss: 1.133389\n",
      "epoch 1; iter: 0; batch classifier loss: 0.892555; batch adversarial loss: 1.337326\n",
      "epoch 2; iter: 0; batch classifier loss: 1.102950; batch adversarial loss: 1.267189\n",
      "epoch 3; iter: 0; batch classifier loss: 0.924572; batch adversarial loss: 1.197963\n",
      "epoch 4; iter: 0; batch classifier loss: 1.209801; batch adversarial loss: 1.168533\n",
      "epoch 5; iter: 0; batch classifier loss: 1.273004; batch adversarial loss: 1.033424\n",
      "epoch 6; iter: 0; batch classifier loss: 1.339724; batch adversarial loss: 0.970334\n",
      "epoch 7; iter: 0; batch classifier loss: 1.482169; batch adversarial loss: 0.897535\n",
      "epoch 8; iter: 0; batch classifier loss: 1.423922; batch adversarial loss: 0.842715\n",
      "epoch 9; iter: 0; batch classifier loss: 1.332234; batch adversarial loss: 0.768200\n",
      "epoch 10; iter: 0; batch classifier loss: 1.249325; batch adversarial loss: 0.735642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 1.256636; batch adversarial loss: 0.689904\n",
      "epoch 12; iter: 0; batch classifier loss: 1.135954; batch adversarial loss: 0.622534\n",
      "epoch 13; iter: 0; batch classifier loss: 0.969865; batch adversarial loss: 0.644343\n",
      "epoch 14; iter: 0; batch classifier loss: 0.759970; batch adversarial loss: 0.590720\n",
      "epoch 15; iter: 0; batch classifier loss: 0.628857; batch adversarial loss: 0.579780\n",
      "epoch 16; iter: 0; batch classifier loss: 0.583935; batch adversarial loss: 0.572462\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501576; batch adversarial loss: 0.590404\n",
      "epoch 18; iter: 0; batch classifier loss: 0.590925; batch adversarial loss: 0.551725\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495440; batch adversarial loss: 0.574678\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499948; batch adversarial loss: 0.601093\n",
      "epoch 21; iter: 0; batch classifier loss: 0.461650; batch adversarial loss: 0.581011\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481592; batch adversarial loss: 0.497244\n",
      "epoch 23; iter: 0; batch classifier loss: 0.524529; batch adversarial loss: 0.530411\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511258; batch adversarial loss: 0.566363\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532485; batch adversarial loss: 0.572321\n",
      "epoch 26; iter: 0; batch classifier loss: 0.436213; batch adversarial loss: 0.519790\n",
      "epoch 27; iter: 0; batch classifier loss: 0.587996; batch adversarial loss: 0.562557\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433010; batch adversarial loss: 0.575046\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462170; batch adversarial loss: 0.616696\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416977; batch adversarial loss: 0.497007\n",
      "epoch 31; iter: 0; batch classifier loss: 0.535864; batch adversarial loss: 0.550066\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498559; batch adversarial loss: 0.541060\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445519; batch adversarial loss: 0.587260\n",
      "epoch 34; iter: 0; batch classifier loss: 0.542574; batch adversarial loss: 0.595236\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445153; batch adversarial loss: 0.580526\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449016; batch adversarial loss: 0.549512\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444445; batch adversarial loss: 0.482587\n",
      "epoch 38; iter: 0; batch classifier loss: 0.416981; batch adversarial loss: 0.504752\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435418; batch adversarial loss: 0.595617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428557; batch adversarial loss: 0.570999\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478703; batch adversarial loss: 0.565996\n",
      "epoch 42; iter: 0; batch classifier loss: 0.520181; batch adversarial loss: 0.533831\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447108; batch adversarial loss: 0.494007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.416981; batch adversarial loss: 0.477800\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457309; batch adversarial loss: 0.560948\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461415; batch adversarial loss: 0.497367\n",
      "epoch 47; iter: 0; batch classifier loss: 0.359321; batch adversarial loss: 0.559144\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382910; batch adversarial loss: 0.471870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.499808; batch adversarial loss: 0.442619\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394590; batch adversarial loss: 0.543144\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481374; batch adversarial loss: 0.596610\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399273; batch adversarial loss: 0.560177\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428785; batch adversarial loss: 0.587944\n",
      "epoch 54; iter: 0; batch classifier loss: 0.501903; batch adversarial loss: 0.540021\n",
      "epoch 55; iter: 0; batch classifier loss: 0.368880; batch adversarial loss: 0.570359\n",
      "epoch 56; iter: 0; batch classifier loss: 0.384831; batch adversarial loss: 0.540311\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445548; batch adversarial loss: 0.507158\n",
      "epoch 58; iter: 0; batch classifier loss: 0.366249; batch adversarial loss: 0.507627\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433460; batch adversarial loss: 0.552008\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377704; batch adversarial loss: 0.517066\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399889; batch adversarial loss: 0.602673\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434780; batch adversarial loss: 0.529511\n",
      "epoch 63; iter: 0; batch classifier loss: 0.355120; batch adversarial loss: 0.559477\n",
      "epoch 64; iter: 0; batch classifier loss: 0.373703; batch adversarial loss: 0.606295\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409914; batch adversarial loss: 0.554167\n",
      "epoch 66; iter: 0; batch classifier loss: 0.365419; batch adversarial loss: 0.581876\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409548; batch adversarial loss: 0.515508\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393653; batch adversarial loss: 0.476311\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407844; batch adversarial loss: 0.487828\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385920; batch adversarial loss: 0.621366\n",
      "epoch 71; iter: 0; batch classifier loss: 0.359000; batch adversarial loss: 0.507989\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398875; batch adversarial loss: 0.450637\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401824; batch adversarial loss: 0.539427\n",
      "epoch 74; iter: 0; batch classifier loss: 0.398996; batch adversarial loss: 0.479451\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384653; batch adversarial loss: 0.629130\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392955; batch adversarial loss: 0.490079\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408368; batch adversarial loss: 0.544835\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453310; batch adversarial loss: 0.572233\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396993; batch adversarial loss: 0.542994\n",
      "epoch 80; iter: 0; batch classifier loss: 0.351530; batch adversarial loss: 0.581066\n",
      "epoch 81; iter: 0; batch classifier loss: 0.461257; batch adversarial loss: 0.619710\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396694; batch adversarial loss: 0.538952\n",
      "epoch 83; iter: 0; batch classifier loss: 0.336303; batch adversarial loss: 0.468257\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404056; batch adversarial loss: 0.525673\n",
      "epoch 85; iter: 0; batch classifier loss: 0.384720; batch adversarial loss: 0.554557\n",
      "epoch 86; iter: 0; batch classifier loss: 0.392550; batch adversarial loss: 0.591951\n",
      "epoch 87; iter: 0; batch classifier loss: 0.361440; batch adversarial loss: 0.582619\n",
      "epoch 88; iter: 0; batch classifier loss: 0.355082; batch adversarial loss: 0.552748\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369471; batch adversarial loss: 0.544380\n",
      "epoch 90; iter: 0; batch classifier loss: 0.326281; batch adversarial loss: 0.592124\n",
      "epoch 91; iter: 0; batch classifier loss: 0.306886; batch adversarial loss: 0.477656\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379254; batch adversarial loss: 0.487706\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374349; batch adversarial loss: 0.589756\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375764; batch adversarial loss: 0.584354\n",
      "epoch 95; iter: 0; batch classifier loss: 0.366911; batch adversarial loss: 0.535485\n",
      "epoch 96; iter: 0; batch classifier loss: 0.302848; batch adversarial loss: 0.563663\n",
      "epoch 97; iter: 0; batch classifier loss: 0.498554; batch adversarial loss: 0.554369\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387920; batch adversarial loss: 0.572883\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380490; batch adversarial loss: 0.591864\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389536; batch adversarial loss: 0.413555\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386818; batch adversarial loss: 0.488092\n",
      "epoch 102; iter: 0; batch classifier loss: 0.324962; batch adversarial loss: 0.573119\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367785; batch adversarial loss: 0.553216\n",
      "epoch 104; iter: 0; batch classifier loss: 0.332927; batch adversarial loss: 0.515969\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394415; batch adversarial loss: 0.506808\n",
      "epoch 106; iter: 0; batch classifier loss: 0.308866; batch adversarial loss: 0.469607\n",
      "epoch 107; iter: 0; batch classifier loss: 0.322193; batch adversarial loss: 0.572834\n",
      "epoch 108; iter: 0; batch classifier loss: 0.282643; batch adversarial loss: 0.524353\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416980; batch adversarial loss: 0.526648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.270710; batch adversarial loss: 0.450258\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374065; batch adversarial loss: 0.600380\n",
      "epoch 112; iter: 0; batch classifier loss: 0.304233; batch adversarial loss: 0.563091\n",
      "epoch 113; iter: 0; batch classifier loss: 0.324734; batch adversarial loss: 0.515621\n",
      "epoch 114; iter: 0; batch classifier loss: 0.345225; batch adversarial loss: 0.534789\n",
      "epoch 115; iter: 0; batch classifier loss: 0.311896; batch adversarial loss: 0.450460\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348516; batch adversarial loss: 0.516337\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373268; batch adversarial loss: 0.516403\n",
      "epoch 118; iter: 0; batch classifier loss: 0.337250; batch adversarial loss: 0.525672\n",
      "epoch 119; iter: 0; batch classifier loss: 0.315248; batch adversarial loss: 0.534974\n",
      "epoch 120; iter: 0; batch classifier loss: 0.320638; batch adversarial loss: 0.534507\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385886; batch adversarial loss: 0.572865\n",
      "epoch 122; iter: 0; batch classifier loss: 0.374131; batch adversarial loss: 0.554160\n",
      "epoch 123; iter: 0; batch classifier loss: 0.407617; batch adversarial loss: 0.552706\n",
      "epoch 124; iter: 0; batch classifier loss: 0.426297; batch adversarial loss: 0.591112\n",
      "epoch 125; iter: 0; batch classifier loss: 0.323529; batch adversarial loss: 0.582092\n",
      "epoch 126; iter: 0; batch classifier loss: 0.300267; batch adversarial loss: 0.497672\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377151; batch adversarial loss: 0.544138\n",
      "epoch 128; iter: 0; batch classifier loss: 0.296268; batch adversarial loss: 0.544691\n",
      "epoch 129; iter: 0; batch classifier loss: 0.329171; batch adversarial loss: 0.497494\n",
      "epoch 130; iter: 0; batch classifier loss: 0.347635; batch adversarial loss: 0.506564\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384817; batch adversarial loss: 0.525874\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395662; batch adversarial loss: 0.562461\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358263; batch adversarial loss: 0.479150\n",
      "epoch 134; iter: 0; batch classifier loss: 0.262089; batch adversarial loss: 0.516237\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366436; batch adversarial loss: 0.535818\n",
      "epoch 136; iter: 0; batch classifier loss: 0.320409; batch adversarial loss: 0.573117\n",
      "epoch 137; iter: 0; batch classifier loss: 0.280032; batch adversarial loss: 0.516155\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389534; batch adversarial loss: 0.554320\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338659; batch adversarial loss: 0.582273\n",
      "epoch 140; iter: 0; batch classifier loss: 0.283046; batch adversarial loss: 0.563365\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326126; batch adversarial loss: 0.563069\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339351; batch adversarial loss: 0.572381\n",
      "epoch 143; iter: 0; batch classifier loss: 0.345559; batch adversarial loss: 0.525936\n",
      "epoch 144; iter: 0; batch classifier loss: 0.442976; batch adversarial loss: 0.506814\n",
      "epoch 145; iter: 0; batch classifier loss: 0.301145; batch adversarial loss: 0.535297\n",
      "epoch 146; iter: 0; batch classifier loss: 0.298215; batch adversarial loss: 0.506868\n",
      "epoch 147; iter: 0; batch classifier loss: 0.292249; batch adversarial loss: 0.506482\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334415; batch adversarial loss: 0.590686\n",
      "epoch 149; iter: 0; batch classifier loss: 0.313526; batch adversarial loss: 0.488900\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360666; batch adversarial loss: 0.555159\n",
      "epoch 151; iter: 0; batch classifier loss: 0.309426; batch adversarial loss: 0.591085\n",
      "epoch 152; iter: 0; batch classifier loss: 0.315245; batch adversarial loss: 0.573425\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355457; batch adversarial loss: 0.638400\n",
      "epoch 154; iter: 0; batch classifier loss: 0.330361; batch adversarial loss: 0.563101\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347588; batch adversarial loss: 0.574097\n",
      "epoch 156; iter: 0; batch classifier loss: 0.323724; batch adversarial loss: 0.496954\n",
      "epoch 157; iter: 0; batch classifier loss: 0.241649; batch adversarial loss: 0.562022\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354207; batch adversarial loss: 0.609618\n",
      "epoch 159; iter: 0; batch classifier loss: 0.287293; batch adversarial loss: 0.703230\n",
      "epoch 160; iter: 0; batch classifier loss: 0.330938; batch adversarial loss: 0.544988\n",
      "epoch 161; iter: 0; batch classifier loss: 0.278909; batch adversarial loss: 0.512091\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312407; batch adversarial loss: 0.638564\n",
      "epoch 163; iter: 0; batch classifier loss: 0.301021; batch adversarial loss: 0.554248\n",
      "epoch 164; iter: 0; batch classifier loss: 0.314233; batch adversarial loss: 0.582056\n",
      "epoch 165; iter: 0; batch classifier loss: 0.296612; batch adversarial loss: 0.457530\n",
      "epoch 166; iter: 0; batch classifier loss: 0.424518; batch adversarial loss: 0.641016\n",
      "epoch 167; iter: 0; batch classifier loss: 0.290429; batch adversarial loss: 0.608961\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378169; batch adversarial loss: 0.572381\n",
      "epoch 169; iter: 0; batch classifier loss: 0.387464; batch adversarial loss: 0.591545\n",
      "epoch 170; iter: 0; batch classifier loss: 0.327228; batch adversarial loss: 0.525868\n",
      "epoch 171; iter: 0; batch classifier loss: 0.256954; batch adversarial loss: 0.493635\n",
      "epoch 172; iter: 0; batch classifier loss: 0.297378; batch adversarial loss: 0.583777\n",
      "epoch 173; iter: 0; batch classifier loss: 0.298070; batch adversarial loss: 0.591436\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338660; batch adversarial loss: 0.478639\n",
      "epoch 175; iter: 0; batch classifier loss: 0.324054; batch adversarial loss: 0.552223\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388811; batch adversarial loss: 0.545121\n",
      "epoch 177; iter: 0; batch classifier loss: 0.410953; batch adversarial loss: 0.556751\n",
      "epoch 178; iter: 0; batch classifier loss: 0.379560; batch adversarial loss: 0.452654\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355786; batch adversarial loss: 0.627820\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339694; batch adversarial loss: 0.581801\n",
      "epoch 181; iter: 0; batch classifier loss: 0.298226; batch adversarial loss: 0.542391\n",
      "epoch 182; iter: 0; batch classifier loss: 0.309187; batch adversarial loss: 0.583104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.266958; batch adversarial loss: 0.527053\n",
      "epoch 184; iter: 0; batch classifier loss: 0.322423; batch adversarial loss: 0.581409\n",
      "epoch 185; iter: 0; batch classifier loss: 0.248554; batch adversarial loss: 0.479185\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350870; batch adversarial loss: 0.563555\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327245; batch adversarial loss: 0.525750\n",
      "epoch 188; iter: 0; batch classifier loss: 0.394351; batch adversarial loss: 0.599723\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295226; batch adversarial loss: 0.515826\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372452; batch adversarial loss: 0.600110\n",
      "epoch 191; iter: 0; batch classifier loss: 0.396608; batch adversarial loss: 0.523618\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376942; batch adversarial loss: 0.516126\n",
      "epoch 193; iter: 0; batch classifier loss: 0.352590; batch adversarial loss: 0.477705\n",
      "epoch 194; iter: 0; batch classifier loss: 0.321038; batch adversarial loss: 0.498492\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302985; batch adversarial loss: 0.583003\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306794; batch adversarial loss: 0.562050\n",
      "epoch 197; iter: 0; batch classifier loss: 0.302003; batch adversarial loss: 0.581817\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324515; batch adversarial loss: 0.526051\n",
      "epoch 199; iter: 0; batch classifier loss: 0.296583; batch adversarial loss: 0.562673\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712784; batch adversarial loss: 0.646200\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598362; batch adversarial loss: 0.653165\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586904; batch adversarial loss: 0.636887\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568224; batch adversarial loss: 0.617039\n",
      "epoch 4; iter: 0; batch classifier loss: 0.609277; batch adversarial loss: 0.609099\n",
      "epoch 5; iter: 0; batch classifier loss: 0.463455; batch adversarial loss: 0.610390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584914; batch adversarial loss: 0.619756\n",
      "epoch 7; iter: 0; batch classifier loss: 0.599677; batch adversarial loss: 0.604869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.539491; batch adversarial loss: 0.632727\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559039; batch adversarial loss: 0.608896\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552434; batch adversarial loss: 0.578189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507954; batch adversarial loss: 0.599504\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577196; batch adversarial loss: 0.572909\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501730; batch adversarial loss: 0.579291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502843; batch adversarial loss: 0.499549\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486687; batch adversarial loss: 0.598362\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511376; batch adversarial loss: 0.596260\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519476; batch adversarial loss: 0.522349\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483296; batch adversarial loss: 0.605639\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465144; batch adversarial loss: 0.568223\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510918; batch adversarial loss: 0.549470\n",
      "epoch 21; iter: 0; batch classifier loss: 0.449169; batch adversarial loss: 0.564799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.547665; batch adversarial loss: 0.490841\n",
      "epoch 23; iter: 0; batch classifier loss: 0.545653; batch adversarial loss: 0.587553\n",
      "epoch 24; iter: 0; batch classifier loss: 0.544776; batch adversarial loss: 0.537769\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428183; batch adversarial loss: 0.533486\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473884; batch adversarial loss: 0.556103\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481150; batch adversarial loss: 0.619778\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516986; batch adversarial loss: 0.530928\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511600; batch adversarial loss: 0.584963\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472056; batch adversarial loss: 0.508638\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494220; batch adversarial loss: 0.509433\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520707; batch adversarial loss: 0.520899\n",
      "epoch 33; iter: 0; batch classifier loss: 0.417177; batch adversarial loss: 0.610634\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483386; batch adversarial loss: 0.502778\n",
      "epoch 35; iter: 0; batch classifier loss: 0.503991; batch adversarial loss: 0.599129\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418184; batch adversarial loss: 0.588690\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450508; batch adversarial loss: 0.554562\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496958; batch adversarial loss: 0.491549\n",
      "epoch 39; iter: 0; batch classifier loss: 0.378873; batch adversarial loss: 0.579876\n",
      "epoch 40; iter: 0; batch classifier loss: 0.529610; batch adversarial loss: 0.499694\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445157; batch adversarial loss: 0.516915\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464825; batch adversarial loss: 0.619518\n",
      "epoch 43; iter: 0; batch classifier loss: 0.541399; batch adversarial loss: 0.546403\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445863; batch adversarial loss: 0.571065\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376876; batch adversarial loss: 0.500048\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503544; batch adversarial loss: 0.590153\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418039; batch adversarial loss: 0.562621\n",
      "epoch 48; iter: 0; batch classifier loss: 0.342653; batch adversarial loss: 0.544554\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449007; batch adversarial loss: 0.553515\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426049; batch adversarial loss: 0.581639\n",
      "epoch 51; iter: 0; batch classifier loss: 0.497237; batch adversarial loss: 0.626672\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404814; batch adversarial loss: 0.525906\n",
      "epoch 53; iter: 0; batch classifier loss: 0.349102; batch adversarial loss: 0.553909\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418091; batch adversarial loss: 0.414957\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480629; batch adversarial loss: 0.601903\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423329; batch adversarial loss: 0.535681\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471529; batch adversarial loss: 0.647656\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386597; batch adversarial loss: 0.535676\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456724; batch adversarial loss: 0.634645\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425895; batch adversarial loss: 0.617022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424235; batch adversarial loss: 0.553172\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399024; batch adversarial loss: 0.544465\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394422; batch adversarial loss: 0.507116\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429360; batch adversarial loss: 0.544777\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448429; batch adversarial loss: 0.534682\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430109; batch adversarial loss: 0.590723\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421808; batch adversarial loss: 0.507468\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400367; batch adversarial loss: 0.517111\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425241; batch adversarial loss: 0.507391\n",
      "epoch 70; iter: 0; batch classifier loss: 0.471288; batch adversarial loss: 0.608751\n",
      "epoch 71; iter: 0; batch classifier loss: 0.421226; batch adversarial loss: 0.570445\n",
      "epoch 72; iter: 0; batch classifier loss: 0.325031; batch adversarial loss: 0.590665\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412779; batch adversarial loss: 0.589438\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413128; batch adversarial loss: 0.571646\n",
      "epoch 75; iter: 0; batch classifier loss: 0.390495; batch adversarial loss: 0.662120\n",
      "epoch 76; iter: 0; batch classifier loss: 0.500461; batch adversarial loss: 0.543913\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401005; batch adversarial loss: 0.517143\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365238; batch adversarial loss: 0.581524\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394599; batch adversarial loss: 0.562904\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371940; batch adversarial loss: 0.498259\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381431; batch adversarial loss: 0.635552\n",
      "epoch 82; iter: 0; batch classifier loss: 0.362833; batch adversarial loss: 0.580575\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388878; batch adversarial loss: 0.526548\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375343; batch adversarial loss: 0.517163\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427833; batch adversarial loss: 0.563057\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391042; batch adversarial loss: 0.627873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417722; batch adversarial loss: 0.498395\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377706; batch adversarial loss: 0.535759\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381853; batch adversarial loss: 0.562685\n",
      "epoch 90; iter: 0; batch classifier loss: 0.330285; batch adversarial loss: 0.479680\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394101; batch adversarial loss: 0.572654\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395363; batch adversarial loss: 0.553821\n",
      "epoch 93; iter: 0; batch classifier loss: 0.359593; batch adversarial loss: 0.535025\n",
      "epoch 94; iter: 0; batch classifier loss: 0.290490; batch adversarial loss: 0.608291\n",
      "epoch 95; iter: 0; batch classifier loss: 0.376033; batch adversarial loss: 0.581115\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410367; batch adversarial loss: 0.489679\n",
      "epoch 97; iter: 0; batch classifier loss: 0.457414; batch adversarial loss: 0.554158\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406080; batch adversarial loss: 0.581388\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414232; batch adversarial loss: 0.654929\n",
      "epoch 100; iter: 0; batch classifier loss: 0.380169; batch adversarial loss: 0.590759\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392280; batch adversarial loss: 0.571739\n",
      "epoch 102; iter: 0; batch classifier loss: 0.338276; batch adversarial loss: 0.498831\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354381; batch adversarial loss: 0.516400\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348643; batch adversarial loss: 0.489769\n",
      "epoch 105; iter: 0; batch classifier loss: 0.329564; batch adversarial loss: 0.498820\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345858; batch adversarial loss: 0.452093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.397202; batch adversarial loss: 0.572129\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362472; batch adversarial loss: 0.628245\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419992; batch adversarial loss: 0.544246\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382271; batch adversarial loss: 0.582311\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408002; batch adversarial loss: 0.498771\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415556; batch adversarial loss: 0.471301\n",
      "epoch 113; iter: 0; batch classifier loss: 0.292083; batch adversarial loss: 0.489493\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362748; batch adversarial loss: 0.618059\n",
      "epoch 115; iter: 0; batch classifier loss: 0.297482; batch adversarial loss: 0.553768\n",
      "epoch 116; iter: 0; batch classifier loss: 0.327415; batch adversarial loss: 0.554229\n",
      "epoch 117; iter: 0; batch classifier loss: 0.438375; batch adversarial loss: 0.600141\n",
      "epoch 118; iter: 0; batch classifier loss: 0.275937; batch adversarial loss: 0.543843\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383643; batch adversarial loss: 0.517084\n",
      "epoch 120; iter: 0; batch classifier loss: 0.410342; batch adversarial loss: 0.581533\n",
      "epoch 121; iter: 0; batch classifier loss: 0.257307; batch adversarial loss: 0.507965\n",
      "epoch 122; iter: 0; batch classifier loss: 0.440733; batch adversarial loss: 0.544044\n",
      "epoch 123; iter: 0; batch classifier loss: 0.447256; batch adversarial loss: 0.498112\n",
      "epoch 124; iter: 0; batch classifier loss: 0.442564; batch adversarial loss: 0.589977\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397027; batch adversarial loss: 0.562677\n",
      "epoch 126; iter: 0; batch classifier loss: 0.371653; batch adversarial loss: 0.553077\n",
      "epoch 127; iter: 0; batch classifier loss: 0.339950; batch adversarial loss: 0.610036\n",
      "epoch 128; iter: 0; batch classifier loss: 0.455259; batch adversarial loss: 0.600453\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397963; batch adversarial loss: 0.434044\n",
      "epoch 130; iter: 0; batch classifier loss: 0.461961; batch adversarial loss: 0.581473\n",
      "epoch 131; iter: 0; batch classifier loss: 0.296969; batch adversarial loss: 0.627637\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414635; batch adversarial loss: 0.599795\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411106; batch adversarial loss: 0.572376\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401902; batch adversarial loss: 0.609949\n",
      "epoch 135; iter: 0; batch classifier loss: 0.421571; batch adversarial loss: 0.499162\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324316; batch adversarial loss: 0.544760\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375275; batch adversarial loss: 0.516699\n",
      "epoch 138; iter: 0; batch classifier loss: 0.395161; batch adversarial loss: 0.552662\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359618; batch adversarial loss: 0.527071\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335006; batch adversarial loss: 0.516895\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381970; batch adversarial loss: 0.534731\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383369; batch adversarial loss: 0.479798\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360554; batch adversarial loss: 0.544923\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346863; batch adversarial loss: 0.564266\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335514; batch adversarial loss: 0.507857\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363057; batch adversarial loss: 0.470360\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354183; batch adversarial loss: 0.526435\n",
      "epoch 148; iter: 0; batch classifier loss: 0.384257; batch adversarial loss: 0.608780\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369744; batch adversarial loss: 0.535697\n",
      "epoch 150; iter: 0; batch classifier loss: 0.411158; batch adversarial loss: 0.617792\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372906; batch adversarial loss: 0.535752\n",
      "epoch 152; iter: 0; batch classifier loss: 0.379448; batch adversarial loss: 0.535481\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339976; batch adversarial loss: 0.515643\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356495; batch adversarial loss: 0.610834\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373152; batch adversarial loss: 0.535481\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396096; batch adversarial loss: 0.645321\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366884; batch adversarial loss: 0.535964\n",
      "epoch 158; iter: 0; batch classifier loss: 0.326469; batch adversarial loss: 0.589688\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383945; batch adversarial loss: 0.536128\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363083; batch adversarial loss: 0.507180\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344082; batch adversarial loss: 0.444996\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326311; batch adversarial loss: 0.629336\n",
      "epoch 163; iter: 0; batch classifier loss: 0.333092; batch adversarial loss: 0.571421\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350980; batch adversarial loss: 0.516289\n",
      "epoch 165; iter: 0; batch classifier loss: 0.308324; batch adversarial loss: 0.535636\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376263; batch adversarial loss: 0.563772\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319818; batch adversarial loss: 0.507092\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392272; batch adversarial loss: 0.572068\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386309; batch adversarial loss: 0.553893\n",
      "epoch 170; iter: 0; batch classifier loss: 0.312688; batch adversarial loss: 0.562430\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332066; batch adversarial loss: 0.618305\n",
      "epoch 172; iter: 0; batch classifier loss: 0.436306; batch adversarial loss: 0.516913\n",
      "epoch 173; iter: 0; batch classifier loss: 0.498856; batch adversarial loss: 0.609085\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345518; batch adversarial loss: 0.516308\n",
      "epoch 175; iter: 0; batch classifier loss: 0.320270; batch adversarial loss: 0.608083\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381732; batch adversarial loss: 0.563106\n",
      "epoch 177; iter: 0; batch classifier loss: 0.357004; batch adversarial loss: 0.452724\n",
      "epoch 178; iter: 0; batch classifier loss: 0.412355; batch adversarial loss: 0.554582\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343516; batch adversarial loss: 0.544465\n",
      "epoch 180; iter: 0; batch classifier loss: 0.345727; batch adversarial loss: 0.562931\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410012; batch adversarial loss: 0.544278\n",
      "epoch 182; iter: 0; batch classifier loss: 0.362498; batch adversarial loss: 0.460458\n",
      "epoch 183; iter: 0; batch classifier loss: 0.331100; batch adversarial loss: 0.516473\n",
      "epoch 184; iter: 0; batch classifier loss: 0.485719; batch adversarial loss: 0.581334\n",
      "epoch 185; iter: 0; batch classifier loss: 0.283164; batch adversarial loss: 0.580822\n",
      "epoch 186; iter: 0; batch classifier loss: 0.403084; batch adversarial loss: 0.508650\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351314; batch adversarial loss: 0.581551\n",
      "epoch 188; iter: 0; batch classifier loss: 0.282939; batch adversarial loss: 0.526459\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377324; batch adversarial loss: 0.562706\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364624; batch adversarial loss: 0.609542\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331890; batch adversarial loss: 0.508056\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368696; batch adversarial loss: 0.498354\n",
      "epoch 193; iter: 0; batch classifier loss: 0.319679; batch adversarial loss: 0.590033\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376524; batch adversarial loss: 0.590417\n",
      "epoch 195; iter: 0; batch classifier loss: 0.333897; batch adversarial loss: 0.479790\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400843; batch adversarial loss: 0.534815\n",
      "epoch 197; iter: 0; batch classifier loss: 0.227496; batch adversarial loss: 0.527269\n",
      "epoch 198; iter: 0; batch classifier loss: 0.318869; batch adversarial loss: 0.562799\n",
      "epoch 199; iter: 0; batch classifier loss: 0.358914; batch adversarial loss: 0.599838\n",
      "epoch 0; iter: 0; batch classifier loss: 0.751934; batch adversarial loss: 0.593282\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597853; batch adversarial loss: 0.628262\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561154; batch adversarial loss: 0.629756\n",
      "epoch 3; iter: 0; batch classifier loss: 0.636028; batch adversarial loss: 0.727836\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614697; batch adversarial loss: 0.714515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.596134; batch adversarial loss: 0.640254\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552903; batch adversarial loss: 0.636516\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583476; batch adversarial loss: 0.610797\n",
      "epoch 8; iter: 0; batch classifier loss: 0.631795; batch adversarial loss: 0.594661\n",
      "epoch 9; iter: 0; batch classifier loss: 0.653707; batch adversarial loss: 0.638506\n",
      "epoch 10; iter: 0; batch classifier loss: 0.625870; batch adversarial loss: 0.612937\n",
      "epoch 11; iter: 0; batch classifier loss: 0.578264; batch adversarial loss: 0.597019\n",
      "epoch 12; iter: 0; batch classifier loss: 0.634699; batch adversarial loss: 0.567397\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553686; batch adversarial loss: 0.600667\n",
      "epoch 14; iter: 0; batch classifier loss: 0.574549; batch adversarial loss: 0.579085\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562852; batch adversarial loss: 0.590898\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550039; batch adversarial loss: 0.508866\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520187; batch adversarial loss: 0.551209\n",
      "epoch 18; iter: 0; batch classifier loss: 0.551329; batch adversarial loss: 0.535397\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500240; batch adversarial loss: 0.626945\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462273; batch adversarial loss: 0.591556\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470882; batch adversarial loss: 0.636444\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479859; batch adversarial loss: 0.535715\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497037; batch adversarial loss: 0.590431\n",
      "epoch 24; iter: 0; batch classifier loss: 0.408352; batch adversarial loss: 0.580559\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417792; batch adversarial loss: 0.518614\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465580; batch adversarial loss: 0.484916\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489385; batch adversarial loss: 0.578596\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463444; batch adversarial loss: 0.579534\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505495; batch adversarial loss: 0.542292\n",
      "epoch 30; iter: 0; batch classifier loss: 0.514025; batch adversarial loss: 0.564677\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469713; batch adversarial loss: 0.542417\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423030; batch adversarial loss: 0.619164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439964; batch adversarial loss: 0.550087\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469821; batch adversarial loss: 0.560029\n",
      "epoch 35; iter: 0; batch classifier loss: 0.414491; batch adversarial loss: 0.559568\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469114; batch adversarial loss: 0.504469\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594990; batch adversarial loss: 0.550085\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476467; batch adversarial loss: 0.543680\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476952; batch adversarial loss: 0.629610\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449477; batch adversarial loss: 0.504233\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478050; batch adversarial loss: 0.517919\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423503; batch adversarial loss: 0.537615\n",
      "epoch 43; iter: 0; batch classifier loss: 0.476083; batch adversarial loss: 0.543587\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483730; batch adversarial loss: 0.545137\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400529; batch adversarial loss: 0.525190\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516649; batch adversarial loss: 0.569980\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442188; batch adversarial loss: 0.560939\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455068; batch adversarial loss: 0.563355\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432371; batch adversarial loss: 0.614979\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417051; batch adversarial loss: 0.615455\n",
      "epoch 51; iter: 0; batch classifier loss: 0.460141; batch adversarial loss: 0.554587\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445338; batch adversarial loss: 0.614653\n",
      "epoch 53; iter: 0; batch classifier loss: 0.366278; batch adversarial loss: 0.515574\n",
      "epoch 54; iter: 0; batch classifier loss: 0.481955; batch adversarial loss: 0.596539\n",
      "epoch 55; iter: 0; batch classifier loss: 0.399035; batch adversarial loss: 0.623792\n",
      "epoch 56; iter: 0; batch classifier loss: 0.496323; batch adversarial loss: 0.536733\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428031; batch adversarial loss: 0.605341\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435514; batch adversarial loss: 0.588803\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447125; batch adversarial loss: 0.552631\n",
      "epoch 60; iter: 0; batch classifier loss: 0.355736; batch adversarial loss: 0.521565\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389910; batch adversarial loss: 0.562658\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390749; batch adversarial loss: 0.517065\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395757; batch adversarial loss: 0.552935\n",
      "epoch 64; iter: 0; batch classifier loss: 0.354306; batch adversarial loss: 0.508852\n",
      "epoch 65; iter: 0; batch classifier loss: 0.456895; batch adversarial loss: 0.500542\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445086; batch adversarial loss: 0.526412\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374087; batch adversarial loss: 0.543413\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394723; batch adversarial loss: 0.514943\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420505; batch adversarial loss: 0.641039\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447419; batch adversarial loss: 0.516263\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426073; batch adversarial loss: 0.563362\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390184; batch adversarial loss: 0.517964\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369419; batch adversarial loss: 0.569681\n",
      "epoch 74; iter: 0; batch classifier loss: 0.456149; batch adversarial loss: 0.568733\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440576; batch adversarial loss: 0.571470\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392252; batch adversarial loss: 0.544995\n",
      "epoch 77; iter: 0; batch classifier loss: 0.447519; batch adversarial loss: 0.455419\n",
      "epoch 78; iter: 0; batch classifier loss: 0.311511; batch adversarial loss: 0.535351\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359465; batch adversarial loss: 0.598805\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412850; batch adversarial loss: 0.546146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.342895; batch adversarial loss: 0.571163\n",
      "epoch 82; iter: 0; batch classifier loss: 0.335252; batch adversarial loss: 0.564251\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384727; batch adversarial loss: 0.562041\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362430; batch adversarial loss: 0.561859\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387962; batch adversarial loss: 0.446320\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400316; batch adversarial loss: 0.546378\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350942; batch adversarial loss: 0.533116\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373880; batch adversarial loss: 0.482275\n",
      "epoch 89; iter: 0; batch classifier loss: 0.345222; batch adversarial loss: 0.606883\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392143; batch adversarial loss: 0.572302\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348391; batch adversarial loss: 0.570192\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391568; batch adversarial loss: 0.545930\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387965; batch adversarial loss: 0.546628\n",
      "epoch 94; iter: 0; batch classifier loss: 0.386360; batch adversarial loss: 0.608111\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418240; batch adversarial loss: 0.454924\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345754; batch adversarial loss: 0.543389\n",
      "epoch 97; iter: 0; batch classifier loss: 0.351027; batch adversarial loss: 0.672878\n",
      "epoch 98; iter: 0; batch classifier loss: 0.348114; batch adversarial loss: 0.560856\n",
      "epoch 99; iter: 0; batch classifier loss: 0.450317; batch adversarial loss: 0.528960\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374749; batch adversarial loss: 0.580688\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426917; batch adversarial loss: 0.541760\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399677; batch adversarial loss: 0.535094\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337038; batch adversarial loss: 0.498519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.419134; batch adversarial loss: 0.527220\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360286; batch adversarial loss: 0.607712\n",
      "epoch 106; iter: 0; batch classifier loss: 0.466551; batch adversarial loss: 0.490066\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403644; batch adversarial loss: 0.616786\n",
      "epoch 108; iter: 0; batch classifier loss: 0.408315; batch adversarial loss: 0.591418\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361134; batch adversarial loss: 0.551754\n",
      "epoch 110; iter: 0; batch classifier loss: 0.387531; batch adversarial loss: 0.570208\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359716; batch adversarial loss: 0.615466\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336694; batch adversarial loss: 0.544604\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421992; batch adversarial loss: 0.555661\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394186; batch adversarial loss: 0.554237\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423663; batch adversarial loss: 0.574732\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371870; batch adversarial loss: 0.546551\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384451; batch adversarial loss: 0.525845\n",
      "epoch 118; iter: 0; batch classifier loss: 0.338322; batch adversarial loss: 0.589131\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379893; batch adversarial loss: 0.537692\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420174; batch adversarial loss: 0.534580\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361854; batch adversarial loss: 0.571282\n",
      "epoch 122; iter: 0; batch classifier loss: 0.429351; batch adversarial loss: 0.536643\n",
      "epoch 123; iter: 0; batch classifier loss: 0.324252; batch adversarial loss: 0.577970\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407640; batch adversarial loss: 0.508183\n",
      "epoch 125; iter: 0; batch classifier loss: 0.358899; batch adversarial loss: 0.562780\n",
      "epoch 126; iter: 0; batch classifier loss: 0.451501; batch adversarial loss: 0.473645\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344384; batch adversarial loss: 0.597543\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348004; batch adversarial loss: 0.507982\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356322; batch adversarial loss: 0.625617\n",
      "epoch 130; iter: 0; batch classifier loss: 0.316048; batch adversarial loss: 0.605785\n",
      "epoch 131; iter: 0; batch classifier loss: 0.354483; batch adversarial loss: 0.644870\n",
      "epoch 132; iter: 0; batch classifier loss: 0.422582; batch adversarial loss: 0.524988\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390081; batch adversarial loss: 0.606829\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363932; batch adversarial loss: 0.554002\n",
      "epoch 135; iter: 0; batch classifier loss: 0.357447; batch adversarial loss: 0.571205\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361248; batch adversarial loss: 0.554043\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386375; batch adversarial loss: 0.561253\n",
      "epoch 138; iter: 0; batch classifier loss: 0.466201; batch adversarial loss: 0.598029\n",
      "epoch 139; iter: 0; batch classifier loss: 0.414632; batch adversarial loss: 0.535642\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371444; batch adversarial loss: 0.498696\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343911; batch adversarial loss: 0.509609\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383794; batch adversarial loss: 0.622725\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331166; batch adversarial loss: 0.570603\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401728; batch adversarial loss: 0.519049\n",
      "epoch 145; iter: 0; batch classifier loss: 0.422047; batch adversarial loss: 0.644632\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399424; batch adversarial loss: 0.539109\n",
      "epoch 147; iter: 0; batch classifier loss: 0.317904; batch adversarial loss: 0.673300\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339390; batch adversarial loss: 0.542538\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355601; batch adversarial loss: 0.596482\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339978; batch adversarial loss: 0.506819\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351705; batch adversarial loss: 0.575310\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355638; batch adversarial loss: 0.547502\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352965; batch adversarial loss: 0.591972\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385877; batch adversarial loss: 0.559220\n",
      "epoch 155; iter: 0; batch classifier loss: 0.363090; batch adversarial loss: 0.544425\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325687; batch adversarial loss: 0.498935\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352535; batch adversarial loss: 0.480859\n",
      "epoch 158; iter: 0; batch classifier loss: 0.434499; batch adversarial loss: 0.554288\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380778; batch adversarial loss: 0.561736\n",
      "epoch 160; iter: 0; batch classifier loss: 0.451478; batch adversarial loss: 0.537674\n",
      "epoch 161; iter: 0; batch classifier loss: 0.365512; batch adversarial loss: 0.508741\n",
      "epoch 162; iter: 0; batch classifier loss: 0.389504; batch adversarial loss: 0.598038\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361764; batch adversarial loss: 0.564156\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358318; batch adversarial loss: 0.562869\n",
      "epoch 165; iter: 0; batch classifier loss: 0.440994; batch adversarial loss: 0.546447\n",
      "epoch 166; iter: 0; batch classifier loss: 0.310384; batch adversarial loss: 0.570681\n",
      "epoch 167; iter: 0; batch classifier loss: 0.417308; batch adversarial loss: 0.545996\n",
      "epoch 168; iter: 0; batch classifier loss: 0.314589; batch adversarial loss: 0.579406\n",
      "epoch 169; iter: 0; batch classifier loss: 0.391972; batch adversarial loss: 0.543913\n",
      "epoch 170; iter: 0; batch classifier loss: 0.326518; batch adversarial loss: 0.509819\n",
      "epoch 171; iter: 0; batch classifier loss: 0.448436; batch adversarial loss: 0.587511\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332562; batch adversarial loss: 0.562290\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292608; batch adversarial loss: 0.581000\n",
      "epoch 174; iter: 0; batch classifier loss: 0.517499; batch adversarial loss: 0.560888\n",
      "epoch 175; iter: 0; batch classifier loss: 0.303035; batch adversarial loss: 0.579391\n",
      "epoch 176; iter: 0; batch classifier loss: 0.232261; batch adversarial loss: 0.436525\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380196; batch adversarial loss: 0.537862\n",
      "epoch 178; iter: 0; batch classifier loss: 0.393037; batch adversarial loss: 0.527433\n",
      "epoch 179; iter: 0; batch classifier loss: 0.314081; batch adversarial loss: 0.580551\n",
      "epoch 180; iter: 0; batch classifier loss: 0.306003; batch adversarial loss: 0.554148\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354800; batch adversarial loss: 0.580533\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338816; batch adversarial loss: 0.545059\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346627; batch adversarial loss: 0.508592\n",
      "epoch 184; iter: 0; batch classifier loss: 0.306050; batch adversarial loss: 0.562433\n",
      "epoch 185; iter: 0; batch classifier loss: 0.465763; batch adversarial loss: 0.548288\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361148; batch adversarial loss: 0.562194\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353801; batch adversarial loss: 0.500865\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368003; batch adversarial loss: 0.589338\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336779; batch adversarial loss: 0.488267\n",
      "epoch 190; iter: 0; batch classifier loss: 0.334615; batch adversarial loss: 0.606980\n",
      "epoch 191; iter: 0; batch classifier loss: 0.310485; batch adversarial loss: 0.526043\n",
      "epoch 192; iter: 0; batch classifier loss: 0.282957; batch adversarial loss: 0.552874\n",
      "epoch 193; iter: 0; batch classifier loss: 0.311153; batch adversarial loss: 0.596068\n",
      "epoch 194; iter: 0; batch classifier loss: 0.361994; batch adversarial loss: 0.555070\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379638; batch adversarial loss: 0.533564\n",
      "epoch 196; iter: 0; batch classifier loss: 0.283416; batch adversarial loss: 0.589163\n",
      "epoch 197; iter: 0; batch classifier loss: 0.406071; batch adversarial loss: 0.501158\n",
      "epoch 198; iter: 0; batch classifier loss: 0.357502; batch adversarial loss: 0.490196\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364887; batch adversarial loss: 0.536627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.760458; batch adversarial loss: 0.619392\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591236; batch adversarial loss: 0.621040\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576261; batch adversarial loss: 0.647435\n",
      "epoch 3; iter: 0; batch classifier loss: 0.619364; batch adversarial loss: 0.654810\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616453; batch adversarial loss: 0.667791\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569464; batch adversarial loss: 0.597873\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541974; batch adversarial loss: 0.623516\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526297; batch adversarial loss: 0.647650\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530860; batch adversarial loss: 0.616256\n",
      "epoch 9; iter: 0; batch classifier loss: 0.640378; batch adversarial loss: 0.571469\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537597; batch adversarial loss: 0.558824\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548981; batch adversarial loss: 0.578472\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497381; batch adversarial loss: 0.519242\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546019; batch adversarial loss: 0.577284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476810; batch adversarial loss: 0.525783\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494485; batch adversarial loss: 0.560795\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442533; batch adversarial loss: 0.542742\n",
      "epoch 17; iter: 0; batch classifier loss: 0.593121; batch adversarial loss: 0.545193\n",
      "epoch 18; iter: 0; batch classifier loss: 0.450675; batch adversarial loss: 0.551873\n",
      "epoch 19; iter: 0; batch classifier loss: 0.582782; batch adversarial loss: 0.434216\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492287; batch adversarial loss: 0.514049\n",
      "epoch 21; iter: 0; batch classifier loss: 0.419935; batch adversarial loss: 0.545404\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441925; batch adversarial loss: 0.499316\n",
      "epoch 23; iter: 0; batch classifier loss: 0.414959; batch adversarial loss: 0.539115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.522376; batch adversarial loss: 0.511935\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417267; batch adversarial loss: 0.546544\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459527; batch adversarial loss: 0.493524\n",
      "epoch 27; iter: 0; batch classifier loss: 0.497233; batch adversarial loss: 0.520128\n",
      "epoch 28; iter: 0; batch classifier loss: 0.430351; batch adversarial loss: 0.546889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.409639; batch adversarial loss: 0.539870\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491440; batch adversarial loss: 0.526623\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469328; batch adversarial loss: 0.560325\n",
      "epoch 32; iter: 0; batch classifier loss: 0.475446; batch adversarial loss: 0.536294\n",
      "epoch 33; iter: 0; batch classifier loss: 0.470140; batch adversarial loss: 0.543878\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411120; batch adversarial loss: 0.582874\n",
      "epoch 35; iter: 0; batch classifier loss: 0.393538; batch adversarial loss: 0.573743\n",
      "epoch 36; iter: 0; batch classifier loss: 0.529412; batch adversarial loss: 0.517117\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499201; batch adversarial loss: 0.572590\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445102; batch adversarial loss: 0.460817\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424642; batch adversarial loss: 0.600003\n",
      "epoch 40; iter: 0; batch classifier loss: 0.469616; batch adversarial loss: 0.488256\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475823; batch adversarial loss: 0.517009\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457005; batch adversarial loss: 0.506800\n",
      "epoch 43; iter: 0; batch classifier loss: 0.457285; batch adversarial loss: 0.525857\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409339; batch adversarial loss: 0.581337\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476013; batch adversarial loss: 0.535606\n",
      "epoch 46; iter: 0; batch classifier loss: 0.442559; batch adversarial loss: 0.479009\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437403; batch adversarial loss: 0.553894\n",
      "epoch 48; iter: 0; batch classifier loss: 0.352546; batch adversarial loss: 0.526141\n",
      "epoch 49; iter: 0; batch classifier loss: 0.481285; batch adversarial loss: 0.525647\n",
      "epoch 50; iter: 0; batch classifier loss: 0.474888; batch adversarial loss: 0.497579\n",
      "epoch 51; iter: 0; batch classifier loss: 0.373789; batch adversarial loss: 0.488416\n",
      "epoch 52; iter: 0; batch classifier loss: 0.483043; batch adversarial loss: 0.469463\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421002; batch adversarial loss: 0.544598\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414237; batch adversarial loss: 0.582300\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400109; batch adversarial loss: 0.525718\n",
      "epoch 56; iter: 0; batch classifier loss: 0.385521; batch adversarial loss: 0.544787\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423463; batch adversarial loss: 0.525697\n",
      "epoch 58; iter: 0; batch classifier loss: 0.369164; batch adversarial loss: 0.497191\n",
      "epoch 59; iter: 0; batch classifier loss: 0.376580; batch adversarial loss: 0.582575\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404670; batch adversarial loss: 0.630513\n",
      "epoch 61; iter: 0; batch classifier loss: 0.341842; batch adversarial loss: 0.639286\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442444; batch adversarial loss: 0.611107\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385013; batch adversarial loss: 0.544422\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409421; batch adversarial loss: 0.505639\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424427; batch adversarial loss: 0.533071\n",
      "epoch 66; iter: 0; batch classifier loss: 0.363094; batch adversarial loss: 0.622923\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434636; batch adversarial loss: 0.572572\n",
      "epoch 68; iter: 0; batch classifier loss: 0.469568; batch adversarial loss: 0.592493\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374871; batch adversarial loss: 0.428237\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410303; batch adversarial loss: 0.523231\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381946; batch adversarial loss: 0.445874\n",
      "epoch 72; iter: 0; batch classifier loss: 0.528054; batch adversarial loss: 0.577911\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417733; batch adversarial loss: 0.532553\n",
      "epoch 74; iter: 0; batch classifier loss: 0.323013; batch adversarial loss: 0.527359\n",
      "epoch 75; iter: 0; batch classifier loss: 0.437851; batch adversarial loss: 0.513470\n",
      "epoch 76; iter: 0; batch classifier loss: 0.478869; batch adversarial loss: 0.563372\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378663; batch adversarial loss: 0.568453\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370405; batch adversarial loss: 0.472329\n",
      "epoch 79; iter: 0; batch classifier loss: 0.435670; batch adversarial loss: 0.535657\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427352; batch adversarial loss: 0.502285\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361890; batch adversarial loss: 0.610296\n",
      "epoch 82; iter: 0; batch classifier loss: 0.442197; batch adversarial loss: 0.545709\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380753; batch adversarial loss: 0.516301\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371209; batch adversarial loss: 0.573446\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395825; batch adversarial loss: 0.479587\n",
      "epoch 86; iter: 0; batch classifier loss: 0.345008; batch adversarial loss: 0.562095\n",
      "epoch 87; iter: 0; batch classifier loss: 0.436724; batch adversarial loss: 0.600984\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396541; batch adversarial loss: 0.619980\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386299; batch adversarial loss: 0.535667\n",
      "epoch 90; iter: 0; batch classifier loss: 0.337816; batch adversarial loss: 0.582303\n",
      "epoch 91; iter: 0; batch classifier loss: 0.443724; batch adversarial loss: 0.564224\n",
      "epoch 92; iter: 0; batch classifier loss: 0.327951; batch adversarial loss: 0.610783\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429027; batch adversarial loss: 0.524036\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391139; batch adversarial loss: 0.553621\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422757; batch adversarial loss: 0.620072\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381933; batch adversarial loss: 0.477550\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344928; batch adversarial loss: 0.554730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.386222; batch adversarial loss: 0.527083\n",
      "epoch 99; iter: 0; batch classifier loss: 0.327932; batch adversarial loss: 0.547592\n",
      "epoch 100; iter: 0; batch classifier loss: 0.343551; batch adversarial loss: 0.550678\n",
      "epoch 101; iter: 0; batch classifier loss: 0.375766; batch adversarial loss: 0.478399\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357004; batch adversarial loss: 0.513361\n",
      "epoch 103; iter: 0; batch classifier loss: 0.316549; batch adversarial loss: 0.478993\n",
      "epoch 104; iter: 0; batch classifier loss: 0.338161; batch adversarial loss: 0.577559\n",
      "epoch 105; iter: 0; batch classifier loss: 0.403069; batch adversarial loss: 0.562120\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421190; batch adversarial loss: 0.534849\n",
      "epoch 107; iter: 0; batch classifier loss: 0.441192; batch adversarial loss: 0.602197\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388784; batch adversarial loss: 0.484439\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384978; batch adversarial loss: 0.545504\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381600; batch adversarial loss: 0.575311\n",
      "epoch 111; iter: 0; batch classifier loss: 0.287098; batch adversarial loss: 0.478940\n",
      "epoch 112; iter: 0; batch classifier loss: 0.434083; batch adversarial loss: 0.583838\n",
      "epoch 113; iter: 0; batch classifier loss: 0.435572; batch adversarial loss: 0.534600\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344125; batch adversarial loss: 0.490792\n",
      "epoch 115; iter: 0; batch classifier loss: 0.406157; batch adversarial loss: 0.516267\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335735; batch adversarial loss: 0.496167\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339888; batch adversarial loss: 0.524421\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393637; batch adversarial loss: 0.544474\n",
      "epoch 119; iter: 0; batch classifier loss: 0.303512; batch adversarial loss: 0.525167\n",
      "epoch 120; iter: 0; batch classifier loss: 0.271834; batch adversarial loss: 0.546336\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348377; batch adversarial loss: 0.553809\n",
      "epoch 122; iter: 0; batch classifier loss: 0.336219; batch adversarial loss: 0.524304\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381726; batch adversarial loss: 0.517678\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372679; batch adversarial loss: 0.535798\n",
      "epoch 125; iter: 0; batch classifier loss: 0.341352; batch adversarial loss: 0.506869\n",
      "epoch 126; iter: 0; batch classifier loss: 0.324577; batch adversarial loss: 0.545145\n",
      "epoch 127; iter: 0; batch classifier loss: 0.337836; batch adversarial loss: 0.555673\n",
      "epoch 128; iter: 0; batch classifier loss: 0.439459; batch adversarial loss: 0.565140\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327302; batch adversarial loss: 0.639504\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375661; batch adversarial loss: 0.571345\n",
      "epoch 131; iter: 0; batch classifier loss: 0.435550; batch adversarial loss: 0.516465\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389534; batch adversarial loss: 0.488796\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393671; batch adversarial loss: 0.497730\n",
      "epoch 134; iter: 0; batch classifier loss: 0.272557; batch adversarial loss: 0.562210\n",
      "epoch 135; iter: 0; batch classifier loss: 0.404195; batch adversarial loss: 0.488642\n",
      "epoch 136; iter: 0; batch classifier loss: 0.327194; batch adversarial loss: 0.487306\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349441; batch adversarial loss: 0.554164\n",
      "epoch 138; iter: 0; batch classifier loss: 0.412073; batch adversarial loss: 0.621615\n",
      "epoch 139; iter: 0; batch classifier loss: 0.316594; batch adversarial loss: 0.496421\n",
      "epoch 140; iter: 0; batch classifier loss: 0.312859; batch adversarial loss: 0.478767\n",
      "epoch 141; iter: 0; batch classifier loss: 0.427823; batch adversarial loss: 0.467058\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330661; batch adversarial loss: 0.551769\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356664; batch adversarial loss: 0.569832\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338621; batch adversarial loss: 0.506997\n",
      "epoch 145; iter: 0; batch classifier loss: 0.446318; batch adversarial loss: 0.542237\n",
      "epoch 146; iter: 0; batch classifier loss: 0.344555; batch adversarial loss: 0.523245\n",
      "epoch 147; iter: 0; batch classifier loss: 0.423398; batch adversarial loss: 0.649889\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345358; batch adversarial loss: 0.568247\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323671; batch adversarial loss: 0.475104\n",
      "epoch 150; iter: 0; batch classifier loss: 0.299697; batch adversarial loss: 0.613211\n",
      "epoch 151; iter: 0; batch classifier loss: 0.385149; batch adversarial loss: 0.507164\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344959; batch adversarial loss: 0.508706\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353458; batch adversarial loss: 0.611880\n",
      "epoch 154; iter: 0; batch classifier loss: 0.403118; batch adversarial loss: 0.497775\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364357; batch adversarial loss: 0.510647\n",
      "epoch 156; iter: 0; batch classifier loss: 0.262571; batch adversarial loss: 0.582789\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326125; batch adversarial loss: 0.656927\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384579; batch adversarial loss: 0.535521\n",
      "epoch 159; iter: 0; batch classifier loss: 0.456423; batch adversarial loss: 0.526643\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344697; batch adversarial loss: 0.524513\n",
      "epoch 161; iter: 0; batch classifier loss: 0.331576; batch adversarial loss: 0.533681\n",
      "epoch 162; iter: 0; batch classifier loss: 0.414685; batch adversarial loss: 0.555218\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340895; batch adversarial loss: 0.591560\n",
      "epoch 164; iter: 0; batch classifier loss: 0.383117; batch adversarial loss: 0.460726\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360645; batch adversarial loss: 0.545960\n",
      "epoch 166; iter: 0; batch classifier loss: 0.451837; batch adversarial loss: 0.516579\n",
      "epoch 167; iter: 0; batch classifier loss: 0.282216; batch adversarial loss: 0.461402\n",
      "epoch 168; iter: 0; batch classifier loss: 0.406973; batch adversarial loss: 0.572212\n",
      "epoch 169; iter: 0; batch classifier loss: 0.393353; batch adversarial loss: 0.488927\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383360; batch adversarial loss: 0.479272\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389272; batch adversarial loss: 0.591803\n",
      "epoch 172; iter: 0; batch classifier loss: 0.292853; batch adversarial loss: 0.534992\n",
      "epoch 173; iter: 0; batch classifier loss: 0.401185; batch adversarial loss: 0.467856\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369920; batch adversarial loss: 0.506880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355330; batch adversarial loss: 0.478308\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364232; batch adversarial loss: 0.544847\n",
      "epoch 177; iter: 0; batch classifier loss: 0.416995; batch adversarial loss: 0.449066\n",
      "epoch 178; iter: 0; batch classifier loss: 0.299512; batch adversarial loss: 0.533840\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334343; batch adversarial loss: 0.552977\n",
      "epoch 180; iter: 0; batch classifier loss: 0.395429; batch adversarial loss: 0.534858\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322597; batch adversarial loss: 0.547436\n",
      "epoch 182; iter: 0; batch classifier loss: 0.312894; batch adversarial loss: 0.552824\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324340; batch adversarial loss: 0.477620\n",
      "epoch 184; iter: 0; batch classifier loss: 0.422920; batch adversarial loss: 0.563802\n",
      "epoch 185; iter: 0; batch classifier loss: 0.255431; batch adversarial loss: 0.618708\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383252; batch adversarial loss: 0.507948\n",
      "epoch 187; iter: 0; batch classifier loss: 0.366937; batch adversarial loss: 0.478009\n",
      "epoch 188; iter: 0; batch classifier loss: 0.411216; batch adversarial loss: 0.525125\n",
      "epoch 189; iter: 0; batch classifier loss: 0.303228; batch adversarial loss: 0.565126\n",
      "epoch 190; iter: 0; batch classifier loss: 0.319345; batch adversarial loss: 0.594656\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362864; batch adversarial loss: 0.561200\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298296; batch adversarial loss: 0.647301\n",
      "epoch 193; iter: 0; batch classifier loss: 0.412726; batch adversarial loss: 0.593665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.314967; batch adversarial loss: 0.476481\n",
      "epoch 195; iter: 0; batch classifier loss: 0.279573; batch adversarial loss: 0.557390\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378888; batch adversarial loss: 0.535486\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361013; batch adversarial loss: 0.554492\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301859; batch adversarial loss: 0.639447\n",
      "epoch 199; iter: 0; batch classifier loss: 0.260548; batch adversarial loss: 0.517087\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670750; batch adversarial loss: 0.608392\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571653; batch adversarial loss: 0.613262\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571265; batch adversarial loss: 0.652599\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553279; batch adversarial loss: 0.665346\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553821; batch adversarial loss: 0.665771\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587979; batch adversarial loss: 0.636933\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524671; batch adversarial loss: 0.618121\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549300; batch adversarial loss: 0.648533\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541184; batch adversarial loss: 0.601964\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509626; batch adversarial loss: 0.573284\n",
      "epoch 10; iter: 0; batch classifier loss: 0.467423; batch adversarial loss: 0.556722\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505780; batch adversarial loss: 0.552231\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526219; batch adversarial loss: 0.606985\n",
      "epoch 13; iter: 0; batch classifier loss: 0.577003; batch adversarial loss: 0.588882\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515586; batch adversarial loss: 0.599584\n",
      "epoch 15; iter: 0; batch classifier loss: 0.443366; batch adversarial loss: 0.582829\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506647; batch adversarial loss: 0.571568\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520582; batch adversarial loss: 0.540980\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529258; batch adversarial loss: 0.597044\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530574; batch adversarial loss: 0.566376\n",
      "epoch 20; iter: 0; batch classifier loss: 0.559544; batch adversarial loss: 0.506805\n",
      "epoch 21; iter: 0; batch classifier loss: 0.466356; batch adversarial loss: 0.580139\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503528; batch adversarial loss: 0.596199\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506822; batch adversarial loss: 0.568369\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468129; batch adversarial loss: 0.568249\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483585; batch adversarial loss: 0.571066\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527496; batch adversarial loss: 0.596863\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494360; batch adversarial loss: 0.507116\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435753; batch adversarial loss: 0.573968\n",
      "epoch 29; iter: 0; batch classifier loss: 0.589499; batch adversarial loss: 0.608570\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479353; batch adversarial loss: 0.554389\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484163; batch adversarial loss: 0.566493\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483621; batch adversarial loss: 0.570498\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480392; batch adversarial loss: 0.570328\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458471; batch adversarial loss: 0.543652\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442257; batch adversarial loss: 0.582616\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451579; batch adversarial loss: 0.551684\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464819; batch adversarial loss: 0.622874\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389099; batch adversarial loss: 0.573500\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445753; batch adversarial loss: 0.510757\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396898; batch adversarial loss: 0.517676\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432574; batch adversarial loss: 0.519803\n",
      "epoch 42; iter: 0; batch classifier loss: 0.384619; batch adversarial loss: 0.537801\n",
      "epoch 43; iter: 0; batch classifier loss: 0.528303; batch adversarial loss: 0.501792\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489347; batch adversarial loss: 0.579666\n",
      "epoch 45; iter: 0; batch classifier loss: 0.514441; batch adversarial loss: 0.560747\n",
      "epoch 46; iter: 0; batch classifier loss: 0.350409; batch adversarial loss: 0.579806\n",
      "epoch 47; iter: 0; batch classifier loss: 0.538349; batch adversarial loss: 0.533780\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391575; batch adversarial loss: 0.598159\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460950; batch adversarial loss: 0.588216\n",
      "epoch 50; iter: 0; batch classifier loss: 0.501007; batch adversarial loss: 0.500092\n",
      "epoch 51; iter: 0; batch classifier loss: 0.339728; batch adversarial loss: 0.590209\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413979; batch adversarial loss: 0.518336\n",
      "epoch 53; iter: 0; batch classifier loss: 0.358797; batch adversarial loss: 0.509933\n",
      "epoch 54; iter: 0; batch classifier loss: 0.481564; batch adversarial loss: 0.545750\n",
      "epoch 55; iter: 0; batch classifier loss: 0.381556; batch adversarial loss: 0.569488\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405603; batch adversarial loss: 0.535573\n",
      "epoch 57; iter: 0; batch classifier loss: 0.458194; batch adversarial loss: 0.517861\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466337; batch adversarial loss: 0.545158\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429437; batch adversarial loss: 0.534527\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379935; batch adversarial loss: 0.535673\n",
      "epoch 61; iter: 0; batch classifier loss: 0.372160; batch adversarial loss: 0.554667\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423539; batch adversarial loss: 0.589495\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468871; batch adversarial loss: 0.553713\n",
      "epoch 64; iter: 0; batch classifier loss: 0.371018; batch adversarial loss: 0.526786\n",
      "epoch 65; iter: 0; batch classifier loss: 0.358416; batch adversarial loss: 0.509863\n",
      "epoch 66; iter: 0; batch classifier loss: 0.341998; batch adversarial loss: 0.543530\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381975; batch adversarial loss: 0.606595\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411169; batch adversarial loss: 0.571714\n",
      "epoch 69; iter: 0; batch classifier loss: 0.370629; batch adversarial loss: 0.616460\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417439; batch adversarial loss: 0.562136\n",
      "epoch 71; iter: 0; batch classifier loss: 0.413869; batch adversarial loss: 0.499168\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427181; batch adversarial loss: 0.589219\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390296; batch adversarial loss: 0.570809\n",
      "epoch 74; iter: 0; batch classifier loss: 0.370109; batch adversarial loss: 0.571865\n",
      "epoch 75; iter: 0; batch classifier loss: 0.340319; batch adversarial loss: 0.553782\n",
      "epoch 76; iter: 0; batch classifier loss: 0.448010; batch adversarial loss: 0.508550\n",
      "epoch 77; iter: 0; batch classifier loss: 0.380274; batch adversarial loss: 0.547686\n",
      "epoch 78; iter: 0; batch classifier loss: 0.411710; batch adversarial loss: 0.527680\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402617; batch adversarial loss: 0.525663\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366198; batch adversarial loss: 0.563368\n",
      "epoch 81; iter: 0; batch classifier loss: 0.292387; batch adversarial loss: 0.590007\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383040; batch adversarial loss: 0.509966\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444118; batch adversarial loss: 0.483526\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360244; batch adversarial loss: 0.579331\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392645; batch adversarial loss: 0.642634\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398592; batch adversarial loss: 0.491102\n",
      "epoch 87; iter: 0; batch classifier loss: 0.381530; batch adversarial loss: 0.517402\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401230; batch adversarial loss: 0.571285\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382050; batch adversarial loss: 0.589319\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463767; batch adversarial loss: 0.482237\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380323; batch adversarial loss: 0.605310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.422974; batch adversarial loss: 0.562111\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427199; batch adversarial loss: 0.572317\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411979; batch adversarial loss: 0.491869\n",
      "epoch 95; iter: 0; batch classifier loss: 0.405644; batch adversarial loss: 0.632815\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391369; batch adversarial loss: 0.615129\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366174; batch adversarial loss: 0.569280\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404057; batch adversarial loss: 0.518015\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416647; batch adversarial loss: 0.535522\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396772; batch adversarial loss: 0.625297\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386577; batch adversarial loss: 0.599276\n",
      "epoch 102; iter: 0; batch classifier loss: 0.481718; batch adversarial loss: 0.651678\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372138; batch adversarial loss: 0.579791\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374884; batch adversarial loss: 0.490244\n",
      "epoch 105; iter: 0; batch classifier loss: 0.449418; batch adversarial loss: 0.571926\n",
      "epoch 106; iter: 0; batch classifier loss: 0.433527; batch adversarial loss: 0.579761\n",
      "epoch 107; iter: 0; batch classifier loss: 0.425534; batch adversarial loss: 0.536357\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397295; batch adversarial loss: 0.562248\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379385; batch adversarial loss: 0.651247\n",
      "epoch 110; iter: 0; batch classifier loss: 0.440005; batch adversarial loss: 0.580789\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374734; batch adversarial loss: 0.581061\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379322; batch adversarial loss: 0.571805\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389807; batch adversarial loss: 0.537484\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376180; batch adversarial loss: 0.543241\n",
      "epoch 115; iter: 0; batch classifier loss: 0.278501; batch adversarial loss: 0.572576\n",
      "epoch 116; iter: 0; batch classifier loss: 0.342820; batch adversarial loss: 0.562889\n",
      "epoch 117; iter: 0; batch classifier loss: 0.352813; batch adversarial loss: 0.562075\n",
      "epoch 118; iter: 0; batch classifier loss: 0.447616; batch adversarial loss: 0.526377\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396624; batch adversarial loss: 0.553839\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416744; batch adversarial loss: 0.571229\n",
      "epoch 121; iter: 0; batch classifier loss: 0.305526; batch adversarial loss: 0.518163\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402556; batch adversarial loss: 0.554085\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400648; batch adversarial loss: 0.579520\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336159; batch adversarial loss: 0.608230\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390356; batch adversarial loss: 0.508824\n",
      "epoch 126; iter: 0; batch classifier loss: 0.318412; batch adversarial loss: 0.606192\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380312; batch adversarial loss: 0.561937\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338680; batch adversarial loss: 0.562576\n",
      "epoch 129; iter: 0; batch classifier loss: 0.418219; batch adversarial loss: 0.561988\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408231; batch adversarial loss: 0.597849\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335609; batch adversarial loss: 0.500337\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363091; batch adversarial loss: 0.554214\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350501; batch adversarial loss: 0.571876\n",
      "epoch 134; iter: 0; batch classifier loss: 0.398108; batch adversarial loss: 0.525362\n",
      "epoch 135; iter: 0; batch classifier loss: 0.449136; batch adversarial loss: 0.507972\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332492; batch adversarial loss: 0.535832\n",
      "epoch 137; iter: 0; batch classifier loss: 0.438586; batch adversarial loss: 0.535921\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389169; batch adversarial loss: 0.473764\n",
      "epoch 139; iter: 0; batch classifier loss: 0.326390; batch adversarial loss: 0.483573\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366677; batch adversarial loss: 0.464778\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358100; batch adversarial loss: 0.579630\n",
      "epoch 142; iter: 0; batch classifier loss: 0.307541; batch adversarial loss: 0.580271\n",
      "epoch 143; iter: 0; batch classifier loss: 0.327279; batch adversarial loss: 0.499375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.329535; batch adversarial loss: 0.508888\n",
      "epoch 145; iter: 0; batch classifier loss: 0.389077; batch adversarial loss: 0.518545\n",
      "epoch 146; iter: 0; batch classifier loss: 0.428512; batch adversarial loss: 0.597427\n",
      "epoch 147; iter: 0; batch classifier loss: 0.430354; batch adversarial loss: 0.598387\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374401; batch adversarial loss: 0.624958\n",
      "epoch 149; iter: 0; batch classifier loss: 0.380678; batch adversarial loss: 0.580331\n",
      "epoch 150; iter: 0; batch classifier loss: 0.374063; batch adversarial loss: 0.572017\n",
      "epoch 151; iter: 0; batch classifier loss: 0.319823; batch adversarial loss: 0.588400\n",
      "epoch 152; iter: 0; batch classifier loss: 0.309966; batch adversarial loss: 0.615617\n",
      "epoch 153; iter: 0; batch classifier loss: 0.409227; batch adversarial loss: 0.526381\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356401; batch adversarial loss: 0.597820\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340123; batch adversarial loss: 0.616162\n",
      "epoch 156; iter: 0; batch classifier loss: 0.364880; batch adversarial loss: 0.596858\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374081; batch adversarial loss: 0.544726\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353527; batch adversarial loss: 0.561379\n",
      "epoch 159; iter: 0; batch classifier loss: 0.424323; batch adversarial loss: 0.534559\n",
      "epoch 160; iter: 0; batch classifier loss: 0.324121; batch adversarial loss: 0.527478\n",
      "epoch 161; iter: 0; batch classifier loss: 0.353476; batch adversarial loss: 0.588879\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344070; batch adversarial loss: 0.527622\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311719; batch adversarial loss: 0.552382\n",
      "epoch 164; iter: 0; batch classifier loss: 0.294812; batch adversarial loss: 0.580353\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358003; batch adversarial loss: 0.606506\n",
      "epoch 166; iter: 0; batch classifier loss: 0.299495; batch adversarial loss: 0.543403\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372312; batch adversarial loss: 0.580379\n",
      "epoch 168; iter: 0; batch classifier loss: 0.286617; batch adversarial loss: 0.535927\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326539; batch adversarial loss: 0.588633\n",
      "epoch 170; iter: 0; batch classifier loss: 0.416855; batch adversarial loss: 0.553033\n",
      "epoch 171; iter: 0; batch classifier loss: 0.331652; batch adversarial loss: 0.554252\n",
      "epoch 172; iter: 0; batch classifier loss: 0.314930; batch adversarial loss: 0.633390\n",
      "epoch 173; iter: 0; batch classifier loss: 0.370142; batch adversarial loss: 0.490996\n",
      "epoch 174; iter: 0; batch classifier loss: 0.297957; batch adversarial loss: 0.508602\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314011; batch adversarial loss: 0.597372\n",
      "epoch 176; iter: 0; batch classifier loss: 0.373881; batch adversarial loss: 0.589634\n",
      "epoch 177; iter: 0; batch classifier loss: 0.373048; batch adversarial loss: 0.587765\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416546; batch adversarial loss: 0.562057\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303425; batch adversarial loss: 0.535142\n",
      "epoch 180; iter: 0; batch classifier loss: 0.321936; batch adversarial loss: 0.571275\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333019; batch adversarial loss: 0.624946\n",
      "epoch 182; iter: 0; batch classifier loss: 0.418152; batch adversarial loss: 0.563490\n",
      "epoch 183; iter: 0; batch classifier loss: 0.460358; batch adversarial loss: 0.580343\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374107; batch adversarial loss: 0.501083\n",
      "epoch 185; iter: 0; batch classifier loss: 0.396035; batch adversarial loss: 0.536423\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385509; batch adversarial loss: 0.562781\n",
      "epoch 187; iter: 0; batch classifier loss: 0.282571; batch adversarial loss: 0.536380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.346675; batch adversarial loss: 0.537087\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385529; batch adversarial loss: 0.562680\n",
      "epoch 190; iter: 0; batch classifier loss: 0.425275; batch adversarial loss: 0.545326\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355963; batch adversarial loss: 0.527851\n",
      "epoch 192; iter: 0; batch classifier loss: 0.383169; batch adversarial loss: 0.545360\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338554; batch adversarial loss: 0.491009\n",
      "epoch 194; iter: 0; batch classifier loss: 0.295601; batch adversarial loss: 0.570795\n",
      "epoch 195; iter: 0; batch classifier loss: 0.371646; batch adversarial loss: 0.545686\n",
      "epoch 196; iter: 0; batch classifier loss: 0.420808; batch adversarial loss: 0.667985\n",
      "epoch 197; iter: 0; batch classifier loss: 0.346196; batch adversarial loss: 0.571674\n",
      "epoch 198; iter: 0; batch classifier loss: 0.401713; batch adversarial loss: 0.580050\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338613; batch adversarial loss: 0.536135\n",
      "epoch 0; iter: 0; batch classifier loss: 0.613976; batch adversarial loss: 0.672877\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594506; batch adversarial loss: 0.656879\n",
      "epoch 2; iter: 0; batch classifier loss: 0.643283; batch adversarial loss: 0.627769\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577831; batch adversarial loss: 0.621717\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513641; batch adversarial loss: 0.586768\n",
      "epoch 5; iter: 0; batch classifier loss: 0.518925; batch adversarial loss: 0.557684\n",
      "epoch 6; iter: 0; batch classifier loss: 0.476535; batch adversarial loss: 0.584724\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606861; batch adversarial loss: 0.591883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.599273; batch adversarial loss: 0.590187\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517184; batch adversarial loss: 0.610681\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565964; batch adversarial loss: 0.601321\n",
      "epoch 11; iter: 0; batch classifier loss: 0.513808; batch adversarial loss: 0.579702\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569289; batch adversarial loss: 0.649890\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564042; batch adversarial loss: 0.628884\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541474; batch adversarial loss: 0.581125\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499336; batch adversarial loss: 0.615617\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480823; batch adversarial loss: 0.533033\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534542; batch adversarial loss: 0.532439\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539134; batch adversarial loss: 0.563582\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496914; batch adversarial loss: 0.586921\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483662; batch adversarial loss: 0.534083\n",
      "epoch 21; iter: 0; batch classifier loss: 0.596564; batch adversarial loss: 0.561648\n",
      "epoch 22; iter: 0; batch classifier loss: 0.527337; batch adversarial loss: 0.513362\n",
      "epoch 23; iter: 0; batch classifier loss: 0.514084; batch adversarial loss: 0.656537\n",
      "epoch 24; iter: 0; batch classifier loss: 0.534799; batch adversarial loss: 0.563681\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479730; batch adversarial loss: 0.543945\n",
      "epoch 26; iter: 0; batch classifier loss: 0.521314; batch adversarial loss: 0.534901\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507241; batch adversarial loss: 0.573163\n",
      "epoch 28; iter: 0; batch classifier loss: 0.505103; batch adversarial loss: 0.557016\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487033; batch adversarial loss: 0.531588\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433906; batch adversarial loss: 0.505341\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491638; batch adversarial loss: 0.604149\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417769; batch adversarial loss: 0.501750\n",
      "epoch 33; iter: 0; batch classifier loss: 0.416016; batch adversarial loss: 0.476501\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501127; batch adversarial loss: 0.578142\n",
      "epoch 35; iter: 0; batch classifier loss: 0.494767; batch adversarial loss: 0.536308\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400092; batch adversarial loss: 0.516279\n",
      "epoch 37; iter: 0; batch classifier loss: 0.437012; batch adversarial loss: 0.527438\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417774; batch adversarial loss: 0.496847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.488204; batch adversarial loss: 0.582140\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423176; batch adversarial loss: 0.563513\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484439; batch adversarial loss: 0.535521\n",
      "epoch 42; iter: 0; batch classifier loss: 0.404088; batch adversarial loss: 0.589014\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474184; batch adversarial loss: 0.563355\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463041; batch adversarial loss: 0.596591\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408608; batch adversarial loss: 0.612393\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406601; batch adversarial loss: 0.540884\n",
      "epoch 47; iter: 0; batch classifier loss: 0.394109; batch adversarial loss: 0.606622\n",
      "epoch 48; iter: 0; batch classifier loss: 0.472696; batch adversarial loss: 0.527123\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410050; batch adversarial loss: 0.521015\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389476; batch adversarial loss: 0.488409\n",
      "epoch 51; iter: 0; batch classifier loss: 0.420816; batch adversarial loss: 0.538511\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443302; batch adversarial loss: 0.488995\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446253; batch adversarial loss: 0.513439\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473040; batch adversarial loss: 0.525656\n",
      "epoch 55; iter: 0; batch classifier loss: 0.383783; batch adversarial loss: 0.556189\n",
      "epoch 56; iter: 0; batch classifier loss: 0.514017; batch adversarial loss: 0.554187\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472618; batch adversarial loss: 0.479571\n",
      "epoch 58; iter: 0; batch classifier loss: 0.492438; batch adversarial loss: 0.495137\n",
      "epoch 59; iter: 0; batch classifier loss: 0.344643; batch adversarial loss: 0.574692\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437587; batch adversarial loss: 0.574488\n",
      "epoch 61; iter: 0; batch classifier loss: 0.486879; batch adversarial loss: 0.573551\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393024; batch adversarial loss: 0.571579\n",
      "epoch 63; iter: 0; batch classifier loss: 0.462535; batch adversarial loss: 0.552499\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375412; batch adversarial loss: 0.585925\n",
      "epoch 65; iter: 0; batch classifier loss: 0.446362; batch adversarial loss: 0.535004\n",
      "epoch 66; iter: 0; batch classifier loss: 0.484556; batch adversarial loss: 0.578323\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425665; batch adversarial loss: 0.569925\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393653; batch adversarial loss: 0.580035\n",
      "epoch 69; iter: 0; batch classifier loss: 0.391857; batch adversarial loss: 0.459796\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424145; batch adversarial loss: 0.554798\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384131; batch adversarial loss: 0.558567\n",
      "epoch 72; iter: 0; batch classifier loss: 0.421354; batch adversarial loss: 0.521668\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424767; batch adversarial loss: 0.586073\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436234; batch adversarial loss: 0.576275\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422747; batch adversarial loss: 0.544591\n",
      "epoch 76; iter: 0; batch classifier loss: 0.365533; batch adversarial loss: 0.556533\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404815; batch adversarial loss: 0.543393\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457935; batch adversarial loss: 0.648177\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428590; batch adversarial loss: 0.464636\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409365; batch adversarial loss: 0.591039\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389090; batch adversarial loss: 0.553933\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387127; batch adversarial loss: 0.547175\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411014; batch adversarial loss: 0.581801\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397764; batch adversarial loss: 0.587734\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343295; batch adversarial loss: 0.572738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.401261; batch adversarial loss: 0.520179\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370473; batch adversarial loss: 0.596879\n",
      "epoch 88; iter: 0; batch classifier loss: 0.344754; batch adversarial loss: 0.545041\n",
      "epoch 89; iter: 0; batch classifier loss: 0.340133; batch adversarial loss: 0.581022\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404580; batch adversarial loss: 0.542457\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404101; batch adversarial loss: 0.523420\n",
      "epoch 92; iter: 0; batch classifier loss: 0.315406; batch adversarial loss: 0.578395\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328281; batch adversarial loss: 0.498105\n",
      "epoch 94; iter: 0; batch classifier loss: 0.351343; batch adversarial loss: 0.562429\n",
      "epoch 95; iter: 0; batch classifier loss: 0.405448; batch adversarial loss: 0.524602\n",
      "epoch 96; iter: 0; batch classifier loss: 0.437851; batch adversarial loss: 0.506331\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402996; batch adversarial loss: 0.570243\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411748; batch adversarial loss: 0.563188\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416039; batch adversarial loss: 0.560616\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370160; batch adversarial loss: 0.509818\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360961; batch adversarial loss: 0.540623\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398398; batch adversarial loss: 0.581049\n",
      "epoch 103; iter: 0; batch classifier loss: 0.387008; batch adversarial loss: 0.581248\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423983; batch adversarial loss: 0.534477\n",
      "epoch 105; iter: 0; batch classifier loss: 0.313879; batch adversarial loss: 0.546136\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389367; batch adversarial loss: 0.498071\n",
      "epoch 107; iter: 0; batch classifier loss: 0.384461; batch adversarial loss: 0.537225\n",
      "epoch 108; iter: 0; batch classifier loss: 0.412870; batch adversarial loss: 0.482042\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376645; batch adversarial loss: 0.581578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403130; batch adversarial loss: 0.496364\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369260; batch adversarial loss: 0.523449\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355045; batch adversarial loss: 0.610464\n",
      "epoch 113; iter: 0; batch classifier loss: 0.420812; batch adversarial loss: 0.584981\n",
      "epoch 114; iter: 0; batch classifier loss: 0.450072; batch adversarial loss: 0.579436\n",
      "epoch 115; iter: 0; batch classifier loss: 0.318513; batch adversarial loss: 0.459887\n",
      "epoch 116; iter: 0; batch classifier loss: 0.425882; batch adversarial loss: 0.549223\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360811; batch adversarial loss: 0.501453\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347411; batch adversarial loss: 0.560800\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417901; batch adversarial loss: 0.600378\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428333; batch adversarial loss: 0.583113\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375660; batch adversarial loss: 0.524422\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367505; batch adversarial loss: 0.547741\n",
      "epoch 123; iter: 0; batch classifier loss: 0.437302; batch adversarial loss: 0.526154\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375481; batch adversarial loss: 0.620755\n",
      "epoch 125; iter: 0; batch classifier loss: 0.422739; batch adversarial loss: 0.528451\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316632; batch adversarial loss: 0.557329\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333377; batch adversarial loss: 0.493808\n",
      "epoch 128; iter: 0; batch classifier loss: 0.423997; batch adversarial loss: 0.601204\n",
      "epoch 129; iter: 0; batch classifier loss: 0.330173; batch adversarial loss: 0.570772\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349222; batch adversarial loss: 0.572987\n",
      "epoch 131; iter: 0; batch classifier loss: 0.422242; batch adversarial loss: 0.535573\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358669; batch adversarial loss: 0.561771\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361591; batch adversarial loss: 0.524762\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337486; batch adversarial loss: 0.535834\n",
      "epoch 135; iter: 0; batch classifier loss: 0.403854; batch adversarial loss: 0.522408\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410854; batch adversarial loss: 0.553406\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377305; batch adversarial loss: 0.532507\n",
      "epoch 138; iter: 0; batch classifier loss: 0.313629; batch adversarial loss: 0.569807\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346846; batch adversarial loss: 0.599528\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371133; batch adversarial loss: 0.556013\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350860; batch adversarial loss: 0.451455\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351568; batch adversarial loss: 0.649955\n",
      "epoch 143; iter: 0; batch classifier loss: 0.476834; batch adversarial loss: 0.468844\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369173; batch adversarial loss: 0.531088\n",
      "epoch 145; iter: 0; batch classifier loss: 0.434920; batch adversarial loss: 0.508703\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368710; batch adversarial loss: 0.551893\n",
      "epoch 147; iter: 0; batch classifier loss: 0.343565; batch adversarial loss: 0.571309\n",
      "epoch 148; iter: 0; batch classifier loss: 0.429383; batch adversarial loss: 0.528009\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335689; batch adversarial loss: 0.519359\n",
      "epoch 150; iter: 0; batch classifier loss: 0.332859; batch adversarial loss: 0.523098\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432095; batch adversarial loss: 0.571935\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332767; batch adversarial loss: 0.602333\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324669; batch adversarial loss: 0.553720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.341329; batch adversarial loss: 0.569941\n",
      "epoch 155; iter: 0; batch classifier loss: 0.384863; batch adversarial loss: 0.528052\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401733; batch adversarial loss: 0.563781\n",
      "epoch 157; iter: 0; batch classifier loss: 0.316390; batch adversarial loss: 0.618678\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397660; batch adversarial loss: 0.605723\n",
      "epoch 159; iter: 0; batch classifier loss: 0.416846; batch adversarial loss: 0.581811\n",
      "epoch 160; iter: 0; batch classifier loss: 0.477607; batch adversarial loss: 0.531839\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342504; batch adversarial loss: 0.522131\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352664; batch adversarial loss: 0.532206\n",
      "epoch 163; iter: 0; batch classifier loss: 0.456271; batch adversarial loss: 0.570700\n",
      "epoch 164; iter: 0; batch classifier loss: 0.445865; batch adversarial loss: 0.563835\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387781; batch adversarial loss: 0.508727\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353737; batch adversarial loss: 0.524614\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335305; batch adversarial loss: 0.520742\n",
      "epoch 168; iter: 0; batch classifier loss: 0.374776; batch adversarial loss: 0.614798\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384910; batch adversarial loss: 0.578847\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.549948\n",
      "epoch 171; iter: 0; batch classifier loss: 0.304851; batch adversarial loss: 0.488592\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397127; batch adversarial loss: 0.564869\n",
      "epoch 173; iter: 0; batch classifier loss: 0.311617; batch adversarial loss: 0.579901\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366657; batch adversarial loss: 0.517261\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369629; batch adversarial loss: 0.509779\n",
      "epoch 176; iter: 0; batch classifier loss: 0.448233; batch adversarial loss: 0.571500\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374155; batch adversarial loss: 0.527251\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372397; batch adversarial loss: 0.543845\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407827; batch adversarial loss: 0.529169\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367795; batch adversarial loss: 0.563867\n",
      "epoch 181; iter: 0; batch classifier loss: 0.443595; batch adversarial loss: 0.600492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.317678; batch adversarial loss: 0.574621\n",
      "epoch 183; iter: 0; batch classifier loss: 0.363230; batch adversarial loss: 0.569772\n",
      "epoch 184; iter: 0; batch classifier loss: 0.302670; batch adversarial loss: 0.590273\n",
      "epoch 185; iter: 0; batch classifier loss: 0.359466; batch adversarial loss: 0.517745\n",
      "epoch 186; iter: 0; batch classifier loss: 0.319598; batch adversarial loss: 0.571580\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395461; batch adversarial loss: 0.498518\n",
      "epoch 188; iter: 0; batch classifier loss: 0.303448; batch adversarial loss: 0.546590\n",
      "epoch 189; iter: 0; batch classifier loss: 0.387303; batch adversarial loss: 0.506821\n",
      "epoch 190; iter: 0; batch classifier loss: 0.447326; batch adversarial loss: 0.646345\n",
      "epoch 191; iter: 0; batch classifier loss: 0.286220; batch adversarial loss: 0.526465\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398659; batch adversarial loss: 0.588918\n",
      "epoch 193; iter: 0; batch classifier loss: 0.399425; batch adversarial loss: 0.526253\n",
      "epoch 194; iter: 0; batch classifier loss: 0.337420; batch adversarial loss: 0.486410\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392594; batch adversarial loss: 0.583207\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306551; batch adversarial loss: 0.443589\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355204; batch adversarial loss: 0.499533\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350603; batch adversarial loss: 0.554900\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308629; batch adversarial loss: 0.516162\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714124; batch adversarial loss: 0.599602\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618449; batch adversarial loss: 0.681947\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603320; batch adversarial loss: 0.613486\n",
      "epoch 3; iter: 0; batch classifier loss: 0.634613; batch adversarial loss: 0.634532\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579421; batch adversarial loss: 0.672669\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569257; batch adversarial loss: 0.586062\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580024; batch adversarial loss: 0.609602\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568367; batch adversarial loss: 0.612588\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536762; batch adversarial loss: 0.570380\n",
      "epoch 9; iter: 0; batch classifier loss: 0.605468; batch adversarial loss: 0.608698\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568427; batch adversarial loss: 0.573831\n",
      "epoch 11; iter: 0; batch classifier loss: 0.617363; batch adversarial loss: 0.586359\n",
      "epoch 12; iter: 0; batch classifier loss: 0.595314; batch adversarial loss: 0.515046\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554968; batch adversarial loss: 0.550782\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505958; batch adversarial loss: 0.493100\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488873; batch adversarial loss: 0.503032\n",
      "epoch 16; iter: 0; batch classifier loss: 0.575934; batch adversarial loss: 0.580133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453597; batch adversarial loss: 0.536786\n",
      "epoch 18; iter: 0; batch classifier loss: 0.577522; batch adversarial loss: 0.518176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.546420; batch adversarial loss: 0.537870\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514892; batch adversarial loss: 0.590766\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482004; batch adversarial loss: 0.554765\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441450; batch adversarial loss: 0.618761\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449137; batch adversarial loss: 0.561879\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484825; batch adversarial loss: 0.546509\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517732; batch adversarial loss: 0.525750\n",
      "epoch 26; iter: 0; batch classifier loss: 0.449931; batch adversarial loss: 0.607809\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495097; batch adversarial loss: 0.550201\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499696; batch adversarial loss: 0.554681\n",
      "epoch 29; iter: 0; batch classifier loss: 0.513100; batch adversarial loss: 0.576381\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506551; batch adversarial loss: 0.629713\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444845; batch adversarial loss: 0.575192\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493169; batch adversarial loss: 0.582801\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443338; batch adversarial loss: 0.557232\n",
      "epoch 34; iter: 0; batch classifier loss: 0.405099; batch adversarial loss: 0.559373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479470; batch adversarial loss: 0.564617\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461161; batch adversarial loss: 0.518561\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451519; batch adversarial loss: 0.542606\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466350; batch adversarial loss: 0.519540\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403781; batch adversarial loss: 0.524856\n",
      "epoch 40; iter: 0; batch classifier loss: 0.479950; batch adversarial loss: 0.498702\n",
      "epoch 41; iter: 0; batch classifier loss: 0.511014; batch adversarial loss: 0.690295\n",
      "epoch 42; iter: 0; batch classifier loss: 0.311348; batch adversarial loss: 0.469331\n",
      "epoch 43; iter: 0; batch classifier loss: 0.512423; batch adversarial loss: 0.571796\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437205; batch adversarial loss: 0.552377\n",
      "epoch 45; iter: 0; batch classifier loss: 0.402838; batch adversarial loss: 0.506662\n",
      "epoch 46; iter: 0; batch classifier loss: 0.528761; batch adversarial loss: 0.571559\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375683; batch adversarial loss: 0.531707\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432102; batch adversarial loss: 0.536075\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390228; batch adversarial loss: 0.526493\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457121; batch adversarial loss: 0.516514\n",
      "epoch 51; iter: 0; batch classifier loss: 0.518841; batch adversarial loss: 0.435172\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423531; batch adversarial loss: 0.574665\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443795; batch adversarial loss: 0.552566\n",
      "epoch 54; iter: 0; batch classifier loss: 0.514067; batch adversarial loss: 0.506158\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404463; batch adversarial loss: 0.562870\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443302; batch adversarial loss: 0.571357\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386154; batch adversarial loss: 0.526895\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396174; batch adversarial loss: 0.517983\n",
      "epoch 59; iter: 0; batch classifier loss: 0.359675; batch adversarial loss: 0.534983\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396051; batch adversarial loss: 0.563447\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424651; batch adversarial loss: 0.516462\n",
      "epoch 62; iter: 0; batch classifier loss: 0.402287; batch adversarial loss: 0.480220\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404062; batch adversarial loss: 0.545007\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413160; batch adversarial loss: 0.611179\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436067; batch adversarial loss: 0.516426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.440533; batch adversarial loss: 0.497614\n",
      "epoch 67; iter: 0; batch classifier loss: 0.467027; batch adversarial loss: 0.591842\n",
      "epoch 68; iter: 0; batch classifier loss: 0.371523; batch adversarial loss: 0.552740\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444186; batch adversarial loss: 0.572961\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423072; batch adversarial loss: 0.507810\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428027; batch adversarial loss: 0.480577\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418504; batch adversarial loss: 0.545110\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389756; batch adversarial loss: 0.535710\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391544; batch adversarial loss: 0.488915\n",
      "epoch 75; iter: 0; batch classifier loss: 0.347599; batch adversarial loss: 0.626635\n",
      "epoch 76; iter: 0; batch classifier loss: 0.434870; batch adversarial loss: 0.523508\n",
      "epoch 77; iter: 0; batch classifier loss: 0.493317; batch adversarial loss: 0.515250\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441866; batch adversarial loss: 0.526121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396503; batch adversarial loss: 0.543010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.430061; batch adversarial loss: 0.551847\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403842; batch adversarial loss: 0.571847\n",
      "epoch 82; iter: 0; batch classifier loss: 0.463257; batch adversarial loss: 0.523768\n",
      "epoch 83; iter: 0; batch classifier loss: 0.361551; batch adversarial loss: 0.560245\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371107; batch adversarial loss: 0.515645\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408844; batch adversarial loss: 0.607638\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431275; batch adversarial loss: 0.513593\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396624; batch adversarial loss: 0.527506\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373211; batch adversarial loss: 0.488284\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429207; batch adversarial loss: 0.609022\n",
      "epoch 90; iter: 0; batch classifier loss: 0.366786; batch adversarial loss: 0.573047\n",
      "epoch 91; iter: 0; batch classifier loss: 0.452280; batch adversarial loss: 0.591122\n",
      "epoch 92; iter: 0; batch classifier loss: 0.331829; batch adversarial loss: 0.544322\n",
      "epoch 93; iter: 0; batch classifier loss: 0.348735; batch adversarial loss: 0.544638\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405863; batch adversarial loss: 0.517143\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287522; batch adversarial loss: 0.562804\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410421; batch adversarial loss: 0.536914\n",
      "epoch 97; iter: 0; batch classifier loss: 0.323075; batch adversarial loss: 0.608134\n",
      "epoch 98; iter: 0; batch classifier loss: 0.360532; batch adversarial loss: 0.508720\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384332; batch adversarial loss: 0.535735\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417678; batch adversarial loss: 0.545369\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413689; batch adversarial loss: 0.581450\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377094; batch adversarial loss: 0.572557\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354192; batch adversarial loss: 0.618039\n",
      "epoch 104; iter: 0; batch classifier loss: 0.295272; batch adversarial loss: 0.481110\n",
      "epoch 105; iter: 0; batch classifier loss: 0.433593; batch adversarial loss: 0.553440\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386770; batch adversarial loss: 0.572083\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407443; batch adversarial loss: 0.563891\n",
      "epoch 108; iter: 0; batch classifier loss: 0.440517; batch adversarial loss: 0.572303\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397461; batch adversarial loss: 0.544364\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405101; batch adversarial loss: 0.582215\n",
      "epoch 111; iter: 0; batch classifier loss: 0.373883; batch adversarial loss: 0.505583\n",
      "epoch 112; iter: 0; batch classifier loss: 0.428445; batch adversarial loss: 0.611004\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366367; batch adversarial loss: 0.498042\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400832; batch adversarial loss: 0.534688\n",
      "epoch 115; iter: 0; batch classifier loss: 0.397636; batch adversarial loss: 0.498177\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389357; batch adversarial loss: 0.628487\n",
      "epoch 117; iter: 0; batch classifier loss: 0.431852; batch adversarial loss: 0.451911\n",
      "epoch 118; iter: 0; batch classifier loss: 0.295113; batch adversarial loss: 0.598370\n",
      "epoch 119; iter: 0; batch classifier loss: 0.397551; batch adversarial loss: 0.599911\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338174; batch adversarial loss: 0.507479\n",
      "epoch 121; iter: 0; batch classifier loss: 0.439653; batch adversarial loss: 0.525632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.437304; batch adversarial loss: 0.498177\n",
      "epoch 123; iter: 0; batch classifier loss: 0.328290; batch adversarial loss: 0.497977\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369334; batch adversarial loss: 0.506936\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372176; batch adversarial loss: 0.534812\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367252; batch adversarial loss: 0.571883\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350042; batch adversarial loss: 0.525670\n",
      "epoch 128; iter: 0; batch classifier loss: 0.324022; batch adversarial loss: 0.526687\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347243; batch adversarial loss: 0.526143\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339923; batch adversarial loss: 0.461265\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391201; batch adversarial loss: 0.545227\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353056; batch adversarial loss: 0.534175\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375827; batch adversarial loss: 0.498413\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393891; batch adversarial loss: 0.572756\n",
      "epoch 135; iter: 0; batch classifier loss: 0.398442; batch adversarial loss: 0.516551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.449379; batch adversarial loss: 0.582622\n",
      "epoch 137; iter: 0; batch classifier loss: 0.420079; batch adversarial loss: 0.582746\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350921; batch adversarial loss: 0.583003\n",
      "epoch 139; iter: 0; batch classifier loss: 0.331594; batch adversarial loss: 0.637051\n",
      "epoch 140; iter: 0; batch classifier loss: 0.388788; batch adversarial loss: 0.637513\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344396; batch adversarial loss: 0.544902\n",
      "epoch 142; iter: 0; batch classifier loss: 0.416390; batch adversarial loss: 0.499072\n",
      "epoch 143; iter: 0; batch classifier loss: 0.441601; batch adversarial loss: 0.600672\n",
      "epoch 144; iter: 0; batch classifier loss: 0.386111; batch adversarial loss: 0.591985\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358161; batch adversarial loss: 0.535376\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411229; batch adversarial loss: 0.582488\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354565; batch adversarial loss: 0.563919\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310516; batch adversarial loss: 0.489001\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370719; batch adversarial loss: 0.589920\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373300; batch adversarial loss: 0.497790\n",
      "epoch 151; iter: 0; batch classifier loss: 0.315824; batch adversarial loss: 0.516358\n",
      "epoch 152; iter: 0; batch classifier loss: 0.329629; batch adversarial loss: 0.525188\n",
      "epoch 153; iter: 0; batch classifier loss: 0.337603; batch adversarial loss: 0.618990\n",
      "epoch 154; iter: 0; batch classifier loss: 0.415531; batch adversarial loss: 0.526442\n",
      "epoch 155; iter: 0; batch classifier loss: 0.469814; batch adversarial loss: 0.572971\n",
      "epoch 156; iter: 0; batch classifier loss: 0.416905; batch adversarial loss: 0.535478\n",
      "epoch 157; iter: 0; batch classifier loss: 0.383426; batch adversarial loss: 0.562629\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361758; batch adversarial loss: 0.553872\n",
      "epoch 159; iter: 0; batch classifier loss: 0.300631; batch adversarial loss: 0.571444\n",
      "epoch 160; iter: 0; batch classifier loss: 0.383033; batch adversarial loss: 0.544674\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333752; batch adversarial loss: 0.507842\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359396; batch adversarial loss: 0.572736\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340054; batch adversarial loss: 0.507736\n",
      "epoch 164; iter: 0; batch classifier loss: 0.429300; batch adversarial loss: 0.479787\n",
      "epoch 165; iter: 0; batch classifier loss: 0.441855; batch adversarial loss: 0.590740\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357469; batch adversarial loss: 0.582110\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366876; batch adversarial loss: 0.488872\n",
      "epoch 168; iter: 0; batch classifier loss: 0.383258; batch adversarial loss: 0.543894\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384789; batch adversarial loss: 0.582007\n",
      "epoch 170; iter: 0; batch classifier loss: 0.295272; batch adversarial loss: 0.470399\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411385; batch adversarial loss: 0.589521\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370584; batch adversarial loss: 0.461590\n",
      "epoch 173; iter: 0; batch classifier loss: 0.374124; batch adversarial loss: 0.488852\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372928; batch adversarial loss: 0.553035\n",
      "epoch 175; iter: 0; batch classifier loss: 0.250856; batch adversarial loss: 0.590513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.319438; batch adversarial loss: 0.516341\n",
      "epoch 177; iter: 0; batch classifier loss: 0.488364; batch adversarial loss: 0.562719\n",
      "epoch 178; iter: 0; batch classifier loss: 0.412507; batch adversarial loss: 0.470394\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337004; batch adversarial loss: 0.524909\n",
      "epoch 180; iter: 0; batch classifier loss: 0.403073; batch adversarial loss: 0.600524\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349004; batch adversarial loss: 0.582328\n",
      "epoch 182; iter: 0; batch classifier loss: 0.398968; batch adversarial loss: 0.563399\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344591; batch adversarial loss: 0.524046\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366826; batch adversarial loss: 0.627670\n",
      "epoch 185; iter: 0; batch classifier loss: 0.359508; batch adversarial loss: 0.598499\n",
      "epoch 186; iter: 0; batch classifier loss: 0.337764; batch adversarial loss: 0.533585\n",
      "epoch 187; iter: 0; batch classifier loss: 0.381273; batch adversarial loss: 0.516013\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381368; batch adversarial loss: 0.550875\n",
      "epoch 189; iter: 0; batch classifier loss: 0.321981; batch adversarial loss: 0.516574\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395620; batch adversarial loss: 0.543228\n",
      "epoch 191; iter: 0; batch classifier loss: 0.433235; batch adversarial loss: 0.581952\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357150; batch adversarial loss: 0.563854\n",
      "epoch 193; iter: 0; batch classifier loss: 0.418176; batch adversarial loss: 0.572535\n",
      "epoch 194; iter: 0; batch classifier loss: 0.432903; batch adversarial loss: 0.463219\n",
      "epoch 195; iter: 0; batch classifier loss: 0.358336; batch adversarial loss: 0.563449\n",
      "epoch 196; iter: 0; batch classifier loss: 0.344296; batch adversarial loss: 0.608964\n",
      "epoch 197; iter: 0; batch classifier loss: 0.420326; batch adversarial loss: 0.526478\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362627; batch adversarial loss: 0.516533\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379948; batch adversarial loss: 0.526341\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718085; batch adversarial loss: 0.640062\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598971; batch adversarial loss: 0.653736\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614929; batch adversarial loss: 0.630020\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580931; batch adversarial loss: 0.618447\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566123; batch adversarial loss: 0.608718\n",
      "epoch 5; iter: 0; batch classifier loss: 0.475734; batch adversarial loss: 0.619113\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606286; batch adversarial loss: 0.663277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566732; batch adversarial loss: 0.613573\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528986; batch adversarial loss: 0.565924\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481080; batch adversarial loss: 0.573031\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574131; batch adversarial loss: 0.579566\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577932; batch adversarial loss: 0.586688\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577103; batch adversarial loss: 0.589524\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564510; batch adversarial loss: 0.580121\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487206; batch adversarial loss: 0.591214\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496703; batch adversarial loss: 0.561150\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514357; batch adversarial loss: 0.612412\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534047; batch adversarial loss: 0.629084\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548358; batch adversarial loss: 0.580303\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468454; batch adversarial loss: 0.499873\n",
      "epoch 20; iter: 0; batch classifier loss: 0.554283; batch adversarial loss: 0.575749\n",
      "epoch 21; iter: 0; batch classifier loss: 0.461763; batch adversarial loss: 0.521511\n",
      "epoch 22; iter: 0; batch classifier loss: 0.409767; batch adversarial loss: 0.579270\n",
      "epoch 23; iter: 0; batch classifier loss: 0.576405; batch adversarial loss: 0.515154\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496896; batch adversarial loss: 0.539663\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491089; batch adversarial loss: 0.537328\n",
      "epoch 26; iter: 0; batch classifier loss: 0.409324; batch adversarial loss: 0.572449\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471933; batch adversarial loss: 0.582624\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494362; batch adversarial loss: 0.520787\n",
      "epoch 29; iter: 0; batch classifier loss: 0.416031; batch adversarial loss: 0.582667\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469222; batch adversarial loss: 0.506042\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431174; batch adversarial loss: 0.493143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.383726; batch adversarial loss: 0.493821\n",
      "epoch 33; iter: 0; batch classifier loss: 0.393166; batch adversarial loss: 0.560105\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462952; batch adversarial loss: 0.565462\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402847; batch adversarial loss: 0.454606\n",
      "epoch 36; iter: 0; batch classifier loss: 0.374701; batch adversarial loss: 0.599032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485968; batch adversarial loss: 0.534964\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381708; batch adversarial loss: 0.628418\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452977; batch adversarial loss: 0.504385\n",
      "epoch 40; iter: 0; batch classifier loss: 0.512414; batch adversarial loss: 0.505030\n",
      "epoch 41; iter: 0; batch classifier loss: 0.455403; batch adversarial loss: 0.608812\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449445; batch adversarial loss: 0.573720\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424599; batch adversarial loss: 0.488679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411742; batch adversarial loss: 0.562743\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438454; batch adversarial loss: 0.491278\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380548; batch adversarial loss: 0.669864\n",
      "epoch 47; iter: 0; batch classifier loss: 0.502662; batch adversarial loss: 0.545410\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397452; batch adversarial loss: 0.490989\n",
      "epoch 49; iter: 0; batch classifier loss: 0.498752; batch adversarial loss: 0.568731\n",
      "epoch 50; iter: 0; batch classifier loss: 0.419900; batch adversarial loss: 0.581876\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430051; batch adversarial loss: 0.454745\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393906; batch adversarial loss: 0.557223\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410326; batch adversarial loss: 0.551887\n",
      "epoch 54; iter: 0; batch classifier loss: 0.374027; batch adversarial loss: 0.585454\n",
      "epoch 55; iter: 0; batch classifier loss: 0.456849; batch adversarial loss: 0.550790\n",
      "epoch 56; iter: 0; batch classifier loss: 0.459154; batch adversarial loss: 0.507125\n",
      "epoch 57; iter: 0; batch classifier loss: 0.470386; batch adversarial loss: 0.525759\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462224; batch adversarial loss: 0.542406\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428227; batch adversarial loss: 0.479368\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423993; batch adversarial loss: 0.470032\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408580; batch adversarial loss: 0.564530\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407875; batch adversarial loss: 0.533259\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397111; batch adversarial loss: 0.528669\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422259; batch adversarial loss: 0.514528\n",
      "epoch 65; iter: 0; batch classifier loss: 0.462452; batch adversarial loss: 0.521348\n",
      "epoch 66; iter: 0; batch classifier loss: 0.457542; batch adversarial loss: 0.517366\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434401; batch adversarial loss: 0.635576\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445305; batch adversarial loss: 0.583190\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397362; batch adversarial loss: 0.551680\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397599; batch adversarial loss: 0.472355\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377099; batch adversarial loss: 0.580409\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440623; batch adversarial loss: 0.517806\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384160; batch adversarial loss: 0.616519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.365523; batch adversarial loss: 0.598646\n",
      "epoch 75; iter: 0; batch classifier loss: 0.420562; batch adversarial loss: 0.581089\n",
      "epoch 76; iter: 0; batch classifier loss: 0.473027; batch adversarial loss: 0.583488\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418818; batch adversarial loss: 0.503321\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389284; batch adversarial loss: 0.515262\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388772; batch adversarial loss: 0.578650\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370717; batch adversarial loss: 0.540747\n",
      "epoch 81; iter: 0; batch classifier loss: 0.354497; batch adversarial loss: 0.528673\n",
      "epoch 82; iter: 0; batch classifier loss: 0.432641; batch adversarial loss: 0.550680\n",
      "epoch 83; iter: 0; batch classifier loss: 0.452972; batch adversarial loss: 0.556303\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390718; batch adversarial loss: 0.611401\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392923; batch adversarial loss: 0.515054\n",
      "epoch 86; iter: 0; batch classifier loss: 0.321433; batch adversarial loss: 0.523923\n",
      "epoch 87; iter: 0; batch classifier loss: 0.361969; batch adversarial loss: 0.516960\n",
      "epoch 88; iter: 0; batch classifier loss: 0.336342; batch adversarial loss: 0.645849\n",
      "epoch 89; iter: 0; batch classifier loss: 0.351665; batch adversarial loss: 0.509041\n",
      "epoch 90; iter: 0; batch classifier loss: 0.477665; batch adversarial loss: 0.551062\n",
      "epoch 91; iter: 0; batch classifier loss: 0.325826; batch adversarial loss: 0.509016\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403414; batch adversarial loss: 0.656897\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438714; batch adversarial loss: 0.533899\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391757; batch adversarial loss: 0.536992\n",
      "epoch 95; iter: 0; batch classifier loss: 0.267320; batch adversarial loss: 0.528370\n",
      "epoch 96; iter: 0; batch classifier loss: 0.362821; batch adversarial loss: 0.488865\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379440; batch adversarial loss: 0.544752\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416924; batch adversarial loss: 0.556041\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342558; batch adversarial loss: 0.583399\n",
      "epoch 100; iter: 0; batch classifier loss: 0.391700; batch adversarial loss: 0.705695\n",
      "epoch 101; iter: 0; batch classifier loss: 0.333032; batch adversarial loss: 0.545875\n",
      "epoch 102; iter: 0; batch classifier loss: 0.453073; batch adversarial loss: 0.472102\n",
      "epoch 103; iter: 0; batch classifier loss: 0.434129; batch adversarial loss: 0.488582\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420001; batch adversarial loss: 0.563327\n",
      "epoch 105; iter: 0; batch classifier loss: 0.459048; batch adversarial loss: 0.554053\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377413; batch adversarial loss: 0.542458\n",
      "epoch 107; iter: 0; batch classifier loss: 0.411947; batch adversarial loss: 0.545369\n",
      "epoch 108; iter: 0; batch classifier loss: 0.502316; batch adversarial loss: 0.614926\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359330; batch adversarial loss: 0.564317\n",
      "epoch 110; iter: 0; batch classifier loss: 0.394221; batch adversarial loss: 0.551661\n",
      "epoch 111; iter: 0; batch classifier loss: 0.292027; batch adversarial loss: 0.552594\n",
      "epoch 112; iter: 0; batch classifier loss: 0.297753; batch adversarial loss: 0.533712\n",
      "epoch 113; iter: 0; batch classifier loss: 0.309257; batch adversarial loss: 0.544662\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366720; batch adversarial loss: 0.573699\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381028; batch adversarial loss: 0.518494\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346258; batch adversarial loss: 0.507591\n",
      "epoch 117; iter: 0; batch classifier loss: 0.452378; batch adversarial loss: 0.487651\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412509; batch adversarial loss: 0.532878\n",
      "epoch 119; iter: 0; batch classifier loss: 0.426532; batch adversarial loss: 0.476955\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401211; batch adversarial loss: 0.625767\n",
      "epoch 121; iter: 0; batch classifier loss: 0.416275; batch adversarial loss: 0.553854\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409961; batch adversarial loss: 0.545492\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366695; batch adversarial loss: 0.572348\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337392; batch adversarial loss: 0.628654\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437121; batch adversarial loss: 0.536852\n",
      "epoch 126; iter: 0; batch classifier loss: 0.304217; batch adversarial loss: 0.597747\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344745; batch adversarial loss: 0.617186\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349631; batch adversarial loss: 0.514367\n",
      "epoch 129; iter: 0; batch classifier loss: 0.320814; batch adversarial loss: 0.519062\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406412; batch adversarial loss: 0.507656\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321636; batch adversarial loss: 0.711227\n",
      "epoch 132; iter: 0; batch classifier loss: 0.374536; batch adversarial loss: 0.563555\n",
      "epoch 133; iter: 0; batch classifier loss: 0.314763; batch adversarial loss: 0.577591\n",
      "epoch 134; iter: 0; batch classifier loss: 0.306973; batch adversarial loss: 0.592189\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337072; batch adversarial loss: 0.570250\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410488; batch adversarial loss: 0.508203\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367033; batch adversarial loss: 0.544617\n",
      "epoch 138; iter: 0; batch classifier loss: 0.435623; batch adversarial loss: 0.549996\n",
      "epoch 139; iter: 0; batch classifier loss: 0.333238; batch adversarial loss: 0.519039\n",
      "epoch 140; iter: 0; batch classifier loss: 0.310704; batch adversarial loss: 0.561048\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398717; batch adversarial loss: 0.554948\n",
      "epoch 142; iter: 0; batch classifier loss: 0.419107; batch adversarial loss: 0.516285\n",
      "epoch 143; iter: 0; batch classifier loss: 0.453867; batch adversarial loss: 0.584077\n",
      "epoch 144; iter: 0; batch classifier loss: 0.318613; batch adversarial loss: 0.656757\n",
      "epoch 145; iter: 0; batch classifier loss: 0.419403; batch adversarial loss: 0.534730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.355319; batch adversarial loss: 0.525479\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326002; batch adversarial loss: 0.544614\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334546; batch adversarial loss: 0.525162\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365102; batch adversarial loss: 0.553787\n",
      "epoch 150; iter: 0; batch classifier loss: 0.318299; batch adversarial loss: 0.515670\n",
      "epoch 151; iter: 0; batch classifier loss: 0.430874; batch adversarial loss: 0.609335\n",
      "epoch 152; iter: 0; batch classifier loss: 0.334102; batch adversarial loss: 0.489887\n",
      "epoch 153; iter: 0; batch classifier loss: 0.332666; batch adversarial loss: 0.561338\n",
      "epoch 154; iter: 0; batch classifier loss: 0.305155; batch adversarial loss: 0.508778\n",
      "epoch 155; iter: 0; batch classifier loss: 0.253960; batch adversarial loss: 0.505910\n",
      "epoch 156; iter: 0; batch classifier loss: 0.319529; batch adversarial loss: 0.471643\n",
      "epoch 157; iter: 0; batch classifier loss: 0.309310; batch adversarial loss: 0.486885\n",
      "epoch 158; iter: 0; batch classifier loss: 0.517508; batch adversarial loss: 0.562561\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338311; batch adversarial loss: 0.561553\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345940; batch adversarial loss: 0.518014\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344898; batch adversarial loss: 0.555771\n",
      "epoch 162; iter: 0; batch classifier loss: 0.264115; batch adversarial loss: 0.579449\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340042; batch adversarial loss: 0.452011\n",
      "epoch 164; iter: 0; batch classifier loss: 0.279633; batch adversarial loss: 0.498088\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394796; batch adversarial loss: 0.517319\n",
      "epoch 166; iter: 0; batch classifier loss: 0.300657; batch adversarial loss: 0.535240\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382623; batch adversarial loss: 0.518704\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377399; batch adversarial loss: 0.590696\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326944; batch adversarial loss: 0.563584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.357343; batch adversarial loss: 0.554234\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374487; batch adversarial loss: 0.489730\n",
      "epoch 172; iter: 0; batch classifier loss: 0.356163; batch adversarial loss: 0.451825\n",
      "epoch 173; iter: 0; batch classifier loss: 0.257365; batch adversarial loss: 0.508395\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387602; batch adversarial loss: 0.527915\n",
      "epoch 175; iter: 0; batch classifier loss: 0.459614; batch adversarial loss: 0.544172\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334122; batch adversarial loss: 0.535166\n",
      "epoch 177; iter: 0; batch classifier loss: 0.328834; batch adversarial loss: 0.488687\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357782; batch adversarial loss: 0.535484\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340182; batch adversarial loss: 0.537490\n",
      "epoch 180; iter: 0; batch classifier loss: 0.235927; batch adversarial loss: 0.562567\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350102; batch adversarial loss: 0.454367\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365086; batch adversarial loss: 0.605796\n",
      "epoch 183; iter: 0; batch classifier loss: 0.339797; batch adversarial loss: 0.542110\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309517; batch adversarial loss: 0.563052\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351187; batch adversarial loss: 0.481334\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331348; batch adversarial loss: 0.508771\n",
      "epoch 187; iter: 0; batch classifier loss: 0.312733; batch adversarial loss: 0.507021\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369459; batch adversarial loss: 0.498643\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357655; batch adversarial loss: 0.580819\n",
      "epoch 190; iter: 0; batch classifier loss: 0.427412; batch adversarial loss: 0.544100\n",
      "epoch 191; iter: 0; batch classifier loss: 0.278466; batch adversarial loss: 0.543255\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338571; batch adversarial loss: 0.546227\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347944; batch adversarial loss: 0.498233\n",
      "epoch 194; iter: 0; batch classifier loss: 0.311838; batch adversarial loss: 0.509272\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392297; batch adversarial loss: 0.610422\n",
      "epoch 196; iter: 0; batch classifier loss: 0.361862; batch adversarial loss: 0.525993\n",
      "epoch 197; iter: 0; batch classifier loss: 0.431601; batch adversarial loss: 0.490246\n",
      "epoch 198; iter: 0; batch classifier loss: 0.283997; batch adversarial loss: 0.616415\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331561; batch adversarial loss: 0.508556\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731444; batch adversarial loss: 0.609597\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573574; batch adversarial loss: 0.664223\n",
      "epoch 2; iter: 0; batch classifier loss: 0.628747; batch adversarial loss: 0.618023\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539033; batch adversarial loss: 0.671500\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610117; batch adversarial loss: 0.603981\n",
      "epoch 5; iter: 0; batch classifier loss: 0.491751; batch adversarial loss: 0.600844\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577826; batch adversarial loss: 0.599051\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555580; batch adversarial loss: 0.643317\n",
      "epoch 8; iter: 0; batch classifier loss: 0.671416; batch adversarial loss: 0.602149\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575408; batch adversarial loss: 0.550782\n",
      "epoch 10; iter: 0; batch classifier loss: 0.608777; batch adversarial loss: 0.603658\n",
      "epoch 11; iter: 0; batch classifier loss: 0.462324; batch adversarial loss: 0.541234\n",
      "epoch 12; iter: 0; batch classifier loss: 0.459119; batch adversarial loss: 0.533908\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452922; batch adversarial loss: 0.594253\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497130; batch adversarial loss: 0.618419\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513639; batch adversarial loss: 0.582004\n",
      "epoch 16; iter: 0; batch classifier loss: 0.548748; batch adversarial loss: 0.648597\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508276; batch adversarial loss: 0.600360\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466138; batch adversarial loss: 0.571265\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505099; batch adversarial loss: 0.574500\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463390; batch adversarial loss: 0.536296\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484298; batch adversarial loss: 0.588021\n",
      "epoch 22; iter: 0; batch classifier loss: 0.534309; batch adversarial loss: 0.556683\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511076; batch adversarial loss: 0.565300\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502877; batch adversarial loss: 0.567121\n",
      "epoch 25; iter: 0; batch classifier loss: 0.463939; batch adversarial loss: 0.510815\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444682; batch adversarial loss: 0.545652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430007; batch adversarial loss: 0.557945\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487845; batch adversarial loss: 0.571708\n",
      "epoch 29; iter: 0; batch classifier loss: 0.538079; batch adversarial loss: 0.555186\n",
      "epoch 30; iter: 0; batch classifier loss: 0.418636; batch adversarial loss: 0.633795\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445210; batch adversarial loss: 0.591393\n",
      "epoch 32; iter: 0; batch classifier loss: 0.551625; batch adversarial loss: 0.616070\n",
      "epoch 33; iter: 0; batch classifier loss: 0.502448; batch adversarial loss: 0.563440\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476978; batch adversarial loss: 0.605505\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489060; batch adversarial loss: 0.583221\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452178; batch adversarial loss: 0.562454\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469440; batch adversarial loss: 0.566106\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475443; batch adversarial loss: 0.494475\n",
      "epoch 39; iter: 0; batch classifier loss: 0.502372; batch adversarial loss: 0.497681\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419223; batch adversarial loss: 0.576862\n",
      "epoch 41; iter: 0; batch classifier loss: 0.512505; batch adversarial loss: 0.613397\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471053; batch adversarial loss: 0.553356\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396089; batch adversarial loss: 0.503633\n",
      "epoch 44; iter: 0; batch classifier loss: 0.514784; batch adversarial loss: 0.612096\n",
      "epoch 45; iter: 0; batch classifier loss: 0.529559; batch adversarial loss: 0.533702\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374449; batch adversarial loss: 0.514090\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467937; batch adversarial loss: 0.601882\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392490; batch adversarial loss: 0.583947\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445321; batch adversarial loss: 0.628300\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428563; batch adversarial loss: 0.565932\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429915; batch adversarial loss: 0.527087\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464415; batch adversarial loss: 0.581239\n",
      "epoch 53; iter: 0; batch classifier loss: 0.484757; batch adversarial loss: 0.601669\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473213; batch adversarial loss: 0.605374\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433881; batch adversarial loss: 0.514005\n",
      "epoch 56; iter: 0; batch classifier loss: 0.489701; batch adversarial loss: 0.561592\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446663; batch adversarial loss: 0.503847\n",
      "epoch 58; iter: 0; batch classifier loss: 0.484550; batch adversarial loss: 0.526276\n",
      "epoch 59; iter: 0; batch classifier loss: 0.434248; batch adversarial loss: 0.516964\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404854; batch adversarial loss: 0.600739\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382406; batch adversarial loss: 0.639857\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432567; batch adversarial loss: 0.622040\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434473; batch adversarial loss: 0.528850\n",
      "epoch 64; iter: 0; batch classifier loss: 0.416112; batch adversarial loss: 0.622559\n",
      "epoch 65; iter: 0; batch classifier loss: 0.371371; batch adversarial loss: 0.568659\n",
      "epoch 66; iter: 0; batch classifier loss: 0.374610; batch adversarial loss: 0.510449\n",
      "epoch 67; iter: 0; batch classifier loss: 0.339460; batch adversarial loss: 0.574172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.398387; batch adversarial loss: 0.544119\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438632; batch adversarial loss: 0.513648\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433524; batch adversarial loss: 0.613959\n",
      "epoch 71; iter: 0; batch classifier loss: 0.460333; batch adversarial loss: 0.602319\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415531; batch adversarial loss: 0.583946\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433175; batch adversarial loss: 0.535960\n",
      "epoch 74; iter: 0; batch classifier loss: 0.429134; batch adversarial loss: 0.544803\n",
      "epoch 75; iter: 0; batch classifier loss: 0.452747; batch adversarial loss: 0.564394\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394993; batch adversarial loss: 0.519374\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427422; batch adversarial loss: 0.568201\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413946; batch adversarial loss: 0.588322\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422053; batch adversarial loss: 0.562087\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436649; batch adversarial loss: 0.624091\n",
      "epoch 81; iter: 0; batch classifier loss: 0.536448; batch adversarial loss: 0.528300\n",
      "epoch 82; iter: 0; batch classifier loss: 0.493843; batch adversarial loss: 0.587512\n",
      "epoch 83; iter: 0; batch classifier loss: 0.361243; batch adversarial loss: 0.519093\n",
      "epoch 84; iter: 0; batch classifier loss: 0.439792; batch adversarial loss: 0.531987\n",
      "epoch 85; iter: 0; batch classifier loss: 0.459601; batch adversarial loss: 0.526939\n",
      "epoch 86; iter: 0; batch classifier loss: 0.372406; batch adversarial loss: 0.481795\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433692; batch adversarial loss: 0.610838\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393157; batch adversarial loss: 0.510978\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380330; batch adversarial loss: 0.543488\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340585; batch adversarial loss: 0.569567\n",
      "epoch 91; iter: 0; batch classifier loss: 0.487431; batch adversarial loss: 0.581981\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376742; batch adversarial loss: 0.639025\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386186; batch adversarial loss: 0.625077\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336350; batch adversarial loss: 0.610655\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384093; batch adversarial loss: 0.616971\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389909; batch adversarial loss: 0.582483\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367700; batch adversarial loss: 0.638020\n",
      "epoch 98; iter: 0; batch classifier loss: 0.427619; batch adversarial loss: 0.584455\n",
      "epoch 99; iter: 0; batch classifier loss: 0.316692; batch adversarial loss: 0.508293\n",
      "epoch 100; iter: 0; batch classifier loss: 0.353735; batch adversarial loss: 0.615533\n",
      "epoch 101; iter: 0; batch classifier loss: 0.340103; batch adversarial loss: 0.612681\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362493; batch adversarial loss: 0.593206\n",
      "epoch 103; iter: 0; batch classifier loss: 0.494238; batch adversarial loss: 0.602967\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351029; batch adversarial loss: 0.559445\n",
      "epoch 105; iter: 0; batch classifier loss: 0.477651; batch adversarial loss: 0.565542\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385074; batch adversarial loss: 0.619750\n",
      "epoch 107; iter: 0; batch classifier loss: 0.434977; batch adversarial loss: 0.593584\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417545; batch adversarial loss: 0.542251\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412826; batch adversarial loss: 0.606721\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372568; batch adversarial loss: 0.562526\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416465; batch adversarial loss: 0.633358\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351589; batch adversarial loss: 0.579096\n",
      "epoch 113; iter: 0; batch classifier loss: 0.402642; batch adversarial loss: 0.556851\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350156; batch adversarial loss: 0.583801\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367772; batch adversarial loss: 0.605154\n",
      "epoch 116; iter: 0; batch classifier loss: 0.471312; batch adversarial loss: 0.558183\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338789; batch adversarial loss: 0.628817\n",
      "epoch 118; iter: 0; batch classifier loss: 0.430724; batch adversarial loss: 0.500757\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334322; batch adversarial loss: 0.562000\n",
      "epoch 120; iter: 0; batch classifier loss: 0.450209; batch adversarial loss: 0.605856\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382995; batch adversarial loss: 0.672969\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366953; batch adversarial loss: 0.612018\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390306; batch adversarial loss: 0.519271\n",
      "epoch 124; iter: 0; batch classifier loss: 0.421926; batch adversarial loss: 0.603939\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370906; batch adversarial loss: 0.547382\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373426; batch adversarial loss: 0.580256\n",
      "epoch 127; iter: 0; batch classifier loss: 0.357253; batch adversarial loss: 0.524425\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353100; batch adversarial loss: 0.550272\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370493; batch adversarial loss: 0.491745\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414182; batch adversarial loss: 0.571402\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386035; batch adversarial loss: 0.527491\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376832; batch adversarial loss: 0.534801\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326154; batch adversarial loss: 0.544029\n",
      "epoch 134; iter: 0; batch classifier loss: 0.380811; batch adversarial loss: 0.617355\n",
      "epoch 135; iter: 0; batch classifier loss: 0.446325; batch adversarial loss: 0.558934\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341229; batch adversarial loss: 0.563760\n",
      "epoch 137; iter: 0; batch classifier loss: 0.281928; batch adversarial loss: 0.557442\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342645; batch adversarial loss: 0.510942\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343660; batch adversarial loss: 0.626497\n",
      "epoch 140; iter: 0; batch classifier loss: 0.339500; batch adversarial loss: 0.570278\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336569; batch adversarial loss: 0.527101\n",
      "epoch 142; iter: 0; batch classifier loss: 0.226601; batch adversarial loss: 0.496992\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376053; batch adversarial loss: 0.666988\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408699; batch adversarial loss: 0.563030\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390421; batch adversarial loss: 0.544901\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404515; batch adversarial loss: 0.523539\n",
      "epoch 147; iter: 0; batch classifier loss: 0.437739; batch adversarial loss: 0.510455\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367598; batch adversarial loss: 0.561059\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336600; batch adversarial loss: 0.620791\n",
      "epoch 150; iter: 0; batch classifier loss: 0.343491; batch adversarial loss: 0.592557\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361441; batch adversarial loss: 0.509666\n",
      "epoch 152; iter: 0; batch classifier loss: 0.429200; batch adversarial loss: 0.649891\n",
      "epoch 153; iter: 0; batch classifier loss: 0.406094; batch adversarial loss: 0.560611\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359814; batch adversarial loss: 0.579571\n",
      "epoch 155; iter: 0; batch classifier loss: 0.411470; batch adversarial loss: 0.553990\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401777; batch adversarial loss: 0.557255\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334249; batch adversarial loss: 0.639428\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343557; batch adversarial loss: 0.559544\n",
      "epoch 159; iter: 0; batch classifier loss: 0.432605; batch adversarial loss: 0.524366\n",
      "epoch 160; iter: 0; batch classifier loss: 0.304479; batch adversarial loss: 0.578249\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414369; batch adversarial loss: 0.560111\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382589; batch adversarial loss: 0.501243\n",
      "epoch 163; iter: 0; batch classifier loss: 0.306577; batch adversarial loss: 0.529305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.397111; batch adversarial loss: 0.515880\n",
      "epoch 165; iter: 0; batch classifier loss: 0.306443; batch adversarial loss: 0.529827\n",
      "epoch 166; iter: 0; batch classifier loss: 0.315448; batch adversarial loss: 0.678985\n",
      "epoch 167; iter: 0; batch classifier loss: 0.433537; batch adversarial loss: 0.595102\n",
      "epoch 168; iter: 0; batch classifier loss: 0.365218; batch adversarial loss: 0.626587\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349298; batch adversarial loss: 0.611381\n",
      "epoch 170; iter: 0; batch classifier loss: 0.358514; batch adversarial loss: 0.511862\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420084; batch adversarial loss: 0.569933\n",
      "epoch 172; iter: 0; batch classifier loss: 0.277174; batch adversarial loss: 0.553145\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382022; batch adversarial loss: 0.576514\n",
      "epoch 174; iter: 0; batch classifier loss: 0.423019; batch adversarial loss: 0.553544\n",
      "epoch 175; iter: 0; batch classifier loss: 0.453561; batch adversarial loss: 0.506024\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308237; batch adversarial loss: 0.589922\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417150; batch adversarial loss: 0.565268\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358966; batch adversarial loss: 0.548915\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347597; batch adversarial loss: 0.507038\n",
      "epoch 180; iter: 0; batch classifier loss: 0.439923; batch adversarial loss: 0.512617\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323529; batch adversarial loss: 0.551862\n",
      "epoch 182; iter: 0; batch classifier loss: 0.438791; batch adversarial loss: 0.562546\n",
      "epoch 183; iter: 0; batch classifier loss: 0.290399; batch adversarial loss: 0.564141\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330389; batch adversarial loss: 0.581110\n",
      "epoch 185; iter: 0; batch classifier loss: 0.428321; batch adversarial loss: 0.620798\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376430; batch adversarial loss: 0.594613\n",
      "epoch 187; iter: 0; batch classifier loss: 0.427821; batch adversarial loss: 0.620202\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311266; batch adversarial loss: 0.517104\n",
      "epoch 189; iter: 0; batch classifier loss: 0.406954; batch adversarial loss: 0.553495\n",
      "epoch 190; iter: 0; batch classifier loss: 0.370048; batch adversarial loss: 0.494304\n",
      "epoch 191; iter: 0; batch classifier loss: 0.308083; batch adversarial loss: 0.556520\n",
      "epoch 192; iter: 0; batch classifier loss: 0.360736; batch adversarial loss: 0.483395\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330546; batch adversarial loss: 0.552724\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350184; batch adversarial loss: 0.541941\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387426; batch adversarial loss: 0.578582\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316946; batch adversarial loss: 0.562958\n",
      "epoch 197; iter: 0; batch classifier loss: 0.399130; batch adversarial loss: 0.561529\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390566; batch adversarial loss: 0.604104\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362753; batch adversarial loss: 0.562089\n",
      "epoch 0; iter: 0; batch classifier loss: 0.751115; batch adversarial loss: 0.597367\n",
      "epoch 1; iter: 0; batch classifier loss: 0.553305; batch adversarial loss: 0.624298\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558703; batch adversarial loss: 0.657556\n",
      "epoch 3; iter: 0; batch classifier loss: 0.687798; batch adversarial loss: 0.712693\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582295; batch adversarial loss: 0.686867\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583439; batch adversarial loss: 0.630080\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612743; batch adversarial loss: 0.639322\n",
      "epoch 7; iter: 0; batch classifier loss: 0.576509; batch adversarial loss: 0.629916\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553177; batch adversarial loss: 0.598338\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505740; batch adversarial loss: 0.606545\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556961; batch adversarial loss: 0.582484\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531612; batch adversarial loss: 0.569260\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487020; batch adversarial loss: 0.618036\n",
      "epoch 13; iter: 0; batch classifier loss: 0.604464; batch adversarial loss: 0.559516\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497780; batch adversarial loss: 0.627161\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494741; batch adversarial loss: 0.538310\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496820; batch adversarial loss: 0.552352\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533916; batch adversarial loss: 0.510056\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501296; batch adversarial loss: 0.552968\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437678; batch adversarial loss: 0.536443\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478533; batch adversarial loss: 0.582981\n",
      "epoch 21; iter: 0; batch classifier loss: 0.465502; batch adversarial loss: 0.550703\n",
      "epoch 22; iter: 0; batch classifier loss: 0.508710; batch adversarial loss: 0.573292\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490661; batch adversarial loss: 0.604296\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512976; batch adversarial loss: 0.468967\n",
      "epoch 25; iter: 0; batch classifier loss: 0.460177; batch adversarial loss: 0.546136\n",
      "epoch 26; iter: 0; batch classifier loss: 0.447993; batch adversarial loss: 0.597065\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499282; batch adversarial loss: 0.590774\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498995; batch adversarial loss: 0.483359\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444178; batch adversarial loss: 0.528484\n",
      "epoch 30; iter: 0; batch classifier loss: 0.548298; batch adversarial loss: 0.416392\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485179; batch adversarial loss: 0.608334\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506410; batch adversarial loss: 0.524870\n",
      "epoch 33; iter: 0; batch classifier loss: 0.357712; batch adversarial loss: 0.549889\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509560; batch adversarial loss: 0.519881\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429825; batch adversarial loss: 0.537485\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447186; batch adversarial loss: 0.579871\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421834; batch adversarial loss: 0.490203\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429089; batch adversarial loss: 0.544285\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410012; batch adversarial loss: 0.580775\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439811; batch adversarial loss: 0.610890\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418793; batch adversarial loss: 0.525933\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457157; batch adversarial loss: 0.509083\n",
      "epoch 43; iter: 0; batch classifier loss: 0.382785; batch adversarial loss: 0.606646\n",
      "epoch 44; iter: 0; batch classifier loss: 0.452281; batch adversarial loss: 0.534755\n",
      "epoch 45; iter: 0; batch classifier loss: 0.484341; batch adversarial loss: 0.573253\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465414; batch adversarial loss: 0.527043\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404727; batch adversarial loss: 0.498664\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455488; batch adversarial loss: 0.451968\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401725; batch adversarial loss: 0.579239\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402117; batch adversarial loss: 0.635118\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379097; batch adversarial loss: 0.497711\n",
      "epoch 52; iter: 0; batch classifier loss: 0.468355; batch adversarial loss: 0.554870\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408939; batch adversarial loss: 0.619777\n",
      "epoch 54; iter: 0; batch classifier loss: 0.468233; batch adversarial loss: 0.569819\n",
      "epoch 55; iter: 0; batch classifier loss: 0.364321; batch adversarial loss: 0.544979\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437632; batch adversarial loss: 0.610753\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472074; batch adversarial loss: 0.507864\n",
      "epoch 58; iter: 0; batch classifier loss: 0.415279; batch adversarial loss: 0.626100\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418009; batch adversarial loss: 0.518203\n",
      "epoch 60; iter: 0; batch classifier loss: 0.466005; batch adversarial loss: 0.553427\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451676; batch adversarial loss: 0.516537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.436729; batch adversarial loss: 0.507419\n",
      "epoch 63; iter: 0; batch classifier loss: 0.358671; batch adversarial loss: 0.562697\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388214; batch adversarial loss: 0.525997\n",
      "epoch 65; iter: 0; batch classifier loss: 0.509083; batch adversarial loss: 0.618263\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406428; batch adversarial loss: 0.609528\n",
      "epoch 67; iter: 0; batch classifier loss: 0.440056; batch adversarial loss: 0.534575\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426430; batch adversarial loss: 0.545114\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378928; batch adversarial loss: 0.516465\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384722; batch adversarial loss: 0.535018\n",
      "epoch 71; iter: 0; batch classifier loss: 0.490743; batch adversarial loss: 0.480875\n",
      "epoch 72; iter: 0; batch classifier loss: 0.454174; batch adversarial loss: 0.517485\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438584; batch adversarial loss: 0.545203\n",
      "epoch 74; iter: 0; batch classifier loss: 0.328657; batch adversarial loss: 0.589950\n",
      "epoch 75; iter: 0; batch classifier loss: 0.411972; batch adversarial loss: 0.552516\n",
      "epoch 76; iter: 0; batch classifier loss: 0.323435; batch adversarial loss: 0.535442\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419244; batch adversarial loss: 0.545630\n",
      "epoch 78; iter: 0; batch classifier loss: 0.357147; batch adversarial loss: 0.516643\n",
      "epoch 79; iter: 0; batch classifier loss: 0.458513; batch adversarial loss: 0.535034\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393714; batch adversarial loss: 0.572492\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403747; batch adversarial loss: 0.517704\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395689; batch adversarial loss: 0.599592\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395006; batch adversarial loss: 0.581120\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404291; batch adversarial loss: 0.554371\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412218; batch adversarial loss: 0.499317\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379505; batch adversarial loss: 0.627083\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455228; batch adversarial loss: 0.562978\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441255; batch adversarial loss: 0.497447\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406951; batch adversarial loss: 0.508358\n",
      "epoch 90; iter: 0; batch classifier loss: 0.462319; batch adversarial loss: 0.489910\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360473; batch adversarial loss: 0.499148\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383510; batch adversarial loss: 0.526635\n",
      "epoch 93; iter: 0; batch classifier loss: 0.459771; batch adversarial loss: 0.516417\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381874; batch adversarial loss: 0.489058\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379887; batch adversarial loss: 0.571899\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394669; batch adversarial loss: 0.553329\n",
      "epoch 97; iter: 0; batch classifier loss: 0.335978; batch adversarial loss: 0.517432\n",
      "epoch 98; iter: 0; batch classifier loss: 0.419093; batch adversarial loss: 0.525343\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417071; batch adversarial loss: 0.515761\n",
      "epoch 100; iter: 0; batch classifier loss: 0.493056; batch adversarial loss: 0.516270\n",
      "epoch 101; iter: 0; batch classifier loss: 0.431231; batch adversarial loss: 0.655304\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357633; batch adversarial loss: 0.480075\n",
      "epoch 103; iter: 0; batch classifier loss: 0.321582; batch adversarial loss: 0.589816\n",
      "epoch 104; iter: 0; batch classifier loss: 0.414380; batch adversarial loss: 0.545960\n",
      "epoch 105; iter: 0; batch classifier loss: 0.450365; batch adversarial loss: 0.535589\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385867; batch adversarial loss: 0.572330\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412621; batch adversarial loss: 0.508622\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420923; batch adversarial loss: 0.498307\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360652; batch adversarial loss: 0.553589\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339407; batch adversarial loss: 0.580968\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369798; batch adversarial loss: 0.635797\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349081; batch adversarial loss: 0.562940\n",
      "epoch 113; iter: 0; batch classifier loss: 0.497223; batch adversarial loss: 0.535180\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369842; batch adversarial loss: 0.571414\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367164; batch adversarial loss: 0.654937\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401611; batch adversarial loss: 0.471820\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346586; batch adversarial loss: 0.599399\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342515; batch adversarial loss: 0.626994\n",
      "epoch 119; iter: 0; batch classifier loss: 0.358772; batch adversarial loss: 0.580426\n",
      "epoch 120; iter: 0; batch classifier loss: 0.405537; batch adversarial loss: 0.508012\n",
      "epoch 121; iter: 0; batch classifier loss: 0.411576; batch adversarial loss: 0.490072\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399326; batch adversarial loss: 0.526848\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341687; batch adversarial loss: 0.552937\n",
      "epoch 124; iter: 0; batch classifier loss: 0.282987; batch adversarial loss: 0.545350\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413554; batch adversarial loss: 0.498207\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406363; batch adversarial loss: 0.536344\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383585; batch adversarial loss: 0.581272\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325757; batch adversarial loss: 0.562834\n",
      "epoch 129; iter: 0; batch classifier loss: 0.384015; batch adversarial loss: 0.544439\n",
      "epoch 130; iter: 0; batch classifier loss: 0.368472; batch adversarial loss: 0.554305\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362882; batch adversarial loss: 0.489184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.383420; batch adversarial loss: 0.516562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.310801; batch adversarial loss: 0.600261\n",
      "epoch 134; iter: 0; batch classifier loss: 0.418351; batch adversarial loss: 0.534751\n",
      "epoch 135; iter: 0; batch classifier loss: 0.427982; batch adversarial loss: 0.572322\n",
      "epoch 136; iter: 0; batch classifier loss: 0.374393; batch adversarial loss: 0.553439\n",
      "epoch 137; iter: 0; batch classifier loss: 0.395654; batch adversarial loss: 0.516820\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381296; batch adversarial loss: 0.544201\n",
      "epoch 139; iter: 0; batch classifier loss: 0.413986; batch adversarial loss: 0.480540\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333691; batch adversarial loss: 0.553101\n",
      "epoch 141; iter: 0; batch classifier loss: 0.423836; batch adversarial loss: 0.590348\n",
      "epoch 142; iter: 0; batch classifier loss: 0.427998; batch adversarial loss: 0.471869\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331718; batch adversarial loss: 0.517542\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362778; batch adversarial loss: 0.544576\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338409; batch adversarial loss: 0.572307\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382942; batch adversarial loss: 0.609004\n",
      "epoch 147; iter: 0; batch classifier loss: 0.250574; batch adversarial loss: 0.563694\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331329; batch adversarial loss: 0.498069\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323416; batch adversarial loss: 0.525090\n",
      "epoch 150; iter: 0; batch classifier loss: 0.475703; batch adversarial loss: 0.526719\n",
      "epoch 151; iter: 0; batch classifier loss: 0.393102; batch adversarial loss: 0.544475\n",
      "epoch 152; iter: 0; batch classifier loss: 0.329483; batch adversarial loss: 0.527095\n",
      "epoch 153; iter: 0; batch classifier loss: 0.341920; batch adversarial loss: 0.516196\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393666; batch adversarial loss: 0.590367\n",
      "epoch 155; iter: 0; batch classifier loss: 0.436427; batch adversarial loss: 0.480753\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402185; batch adversarial loss: 0.582068\n",
      "epoch 157; iter: 0; batch classifier loss: 0.382934; batch adversarial loss: 0.563126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.277366; batch adversarial loss: 0.526739\n",
      "epoch 159; iter: 0; batch classifier loss: 0.473990; batch adversarial loss: 0.489493\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370542; batch adversarial loss: 0.590250\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363135; batch adversarial loss: 0.544834\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327122; batch adversarial loss: 0.553498\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364394; batch adversarial loss: 0.498462\n",
      "epoch 164; iter: 0; batch classifier loss: 0.286037; batch adversarial loss: 0.526255\n",
      "epoch 165; iter: 0; batch classifier loss: 0.395671; batch adversarial loss: 0.544352\n",
      "epoch 166; iter: 0; batch classifier loss: 0.438105; batch adversarial loss: 0.562897\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343445; batch adversarial loss: 0.599519\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369118; batch adversarial loss: 0.526017\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324751; batch adversarial loss: 0.580792\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324227; batch adversarial loss: 0.544662\n",
      "epoch 171; iter: 0; batch classifier loss: 0.361804; batch adversarial loss: 0.553962\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368380; batch adversarial loss: 0.535615\n",
      "epoch 173; iter: 0; batch classifier loss: 0.353717; batch adversarial loss: 0.498373\n",
      "epoch 174; iter: 0; batch classifier loss: 0.421210; batch adversarial loss: 0.462030\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368021; batch adversarial loss: 0.572421\n",
      "epoch 176; iter: 0; batch classifier loss: 0.322920; batch adversarial loss: 0.545021\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384192; batch adversarial loss: 0.581041\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352003; batch adversarial loss: 0.544515\n",
      "epoch 179; iter: 0; batch classifier loss: 0.289433; batch adversarial loss: 0.627207\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323163; batch adversarial loss: 0.498396\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345668; batch adversarial loss: 0.443403\n",
      "epoch 182; iter: 0; batch classifier loss: 0.330308; batch adversarial loss: 0.589878\n",
      "epoch 183; iter: 0; batch classifier loss: 0.400094; batch adversarial loss: 0.599111\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366811; batch adversarial loss: 0.645662\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356408; batch adversarial loss: 0.526821\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358255; batch adversarial loss: 0.544660\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334658; batch adversarial loss: 0.544234\n",
      "epoch 188; iter: 0; batch classifier loss: 0.406598; batch adversarial loss: 0.617444\n",
      "epoch 189; iter: 0; batch classifier loss: 0.250896; batch adversarial loss: 0.516987\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309856; batch adversarial loss: 0.507478\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365915; batch adversarial loss: 0.516809\n",
      "epoch 192; iter: 0; batch classifier loss: 0.314351; batch adversarial loss: 0.626489\n",
      "epoch 193; iter: 0; batch classifier loss: 0.387247; batch adversarial loss: 0.636519\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385583; batch adversarial loss: 0.507202\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337703; batch adversarial loss: 0.535163\n",
      "epoch 196; iter: 0; batch classifier loss: 0.282885; batch adversarial loss: 0.608726\n",
      "epoch 197; iter: 0; batch classifier loss: 0.407421; batch adversarial loss: 0.516912\n",
      "epoch 198; iter: 0; batch classifier loss: 0.325928; batch adversarial loss: 0.553751\n",
      "epoch 199; iter: 0; batch classifier loss: 0.280798; batch adversarial loss: 0.581905\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717955; batch adversarial loss: 0.910991\n",
      "epoch 1; iter: 0; batch classifier loss: 0.841784; batch adversarial loss: 1.015084\n",
      "epoch 2; iter: 0; batch classifier loss: 0.953300; batch adversarial loss: 0.984783\n",
      "epoch 3; iter: 0; batch classifier loss: 0.969711; batch adversarial loss: 0.909897\n",
      "epoch 4; iter: 0; batch classifier loss: 0.909638; batch adversarial loss: 0.839769\n",
      "epoch 5; iter: 0; batch classifier loss: 1.051293; batch adversarial loss: 0.777268\n",
      "epoch 6; iter: 0; batch classifier loss: 0.932533; batch adversarial loss: 0.728582\n",
      "epoch 7; iter: 0; batch classifier loss: 0.728675; batch adversarial loss: 0.674399\n",
      "epoch 8; iter: 0; batch classifier loss: 0.624852; batch adversarial loss: 0.632688\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557629; batch adversarial loss: 0.603443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.598599; batch adversarial loss: 0.589656\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501139; batch adversarial loss: 0.623011\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523977; batch adversarial loss: 0.548752\n",
      "epoch 13; iter: 0; batch classifier loss: 0.464836; batch adversarial loss: 0.554248\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518727; batch adversarial loss: 0.541009\n",
      "epoch 15; iter: 0; batch classifier loss: 0.567485; batch adversarial loss: 0.554380\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561904; batch adversarial loss: 0.545800\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516484; batch adversarial loss: 0.572088\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535003; batch adversarial loss: 0.521618\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496011; batch adversarial loss: 0.550156\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527800; batch adversarial loss: 0.520311\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494477; batch adversarial loss: 0.560568\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503041; batch adversarial loss: 0.514455\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451226; batch adversarial loss: 0.535014\n",
      "epoch 24; iter: 0; batch classifier loss: 0.469004; batch adversarial loss: 0.525452\n",
      "epoch 25; iter: 0; batch classifier loss: 0.416606; batch adversarial loss: 0.538943\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448086; batch adversarial loss: 0.521248\n",
      "epoch 27; iter: 0; batch classifier loss: 0.541578; batch adversarial loss: 0.541203\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434495; batch adversarial loss: 0.567561\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497104; batch adversarial loss: 0.518425\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475519; batch adversarial loss: 0.533087\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492011; batch adversarial loss: 0.506691\n",
      "epoch 32; iter: 0; batch classifier loss: 0.377952; batch adversarial loss: 0.507449\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498836; batch adversarial loss: 0.429308\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417461; batch adversarial loss: 0.490577\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483485; batch adversarial loss: 0.496188\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485053; batch adversarial loss: 0.496298\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471632; batch adversarial loss: 0.611679\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446204; batch adversarial loss: 0.541500\n",
      "epoch 39; iter: 0; batch classifier loss: 0.521598; batch adversarial loss: 0.481554\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470582; batch adversarial loss: 0.618381\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478514; batch adversarial loss: 0.516785\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393732; batch adversarial loss: 0.571918\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398342; batch adversarial loss: 0.592485\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492783; batch adversarial loss: 0.555075\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393931; batch adversarial loss: 0.527754\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469654; batch adversarial loss: 0.501297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465048; batch adversarial loss: 0.527048\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478949; batch adversarial loss: 0.482182\n",
      "epoch 49; iter: 0; batch classifier loss: 0.495474; batch adversarial loss: 0.500082\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430480; batch adversarial loss: 0.581484\n",
      "epoch 51; iter: 0; batch classifier loss: 0.431327; batch adversarial loss: 0.507311\n",
      "epoch 52; iter: 0; batch classifier loss: 0.388551; batch adversarial loss: 0.572742\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413122; batch adversarial loss: 0.571211\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393971; batch adversarial loss: 0.461852\n",
      "epoch 55; iter: 0; batch classifier loss: 0.499034; batch adversarial loss: 0.600102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.425791; batch adversarial loss: 0.471502\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453691; batch adversarial loss: 0.498059\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400448; batch adversarial loss: 0.608507\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394723; batch adversarial loss: 0.572676\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445070; batch adversarial loss: 0.535617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446574; batch adversarial loss: 0.499008\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450867; batch adversarial loss: 0.600246\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400866; batch adversarial loss: 0.535450\n",
      "epoch 64; iter: 0; batch classifier loss: 0.379377; batch adversarial loss: 0.536137\n",
      "epoch 65; iter: 0; batch classifier loss: 0.329755; batch adversarial loss: 0.526351\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389692; batch adversarial loss: 0.470561\n",
      "epoch 67; iter: 0; batch classifier loss: 0.316923; batch adversarial loss: 0.515354\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356540; batch adversarial loss: 0.527443\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416607; batch adversarial loss: 0.535991\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414779; batch adversarial loss: 0.572048\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416646; batch adversarial loss: 0.488334\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440043; batch adversarial loss: 0.535729\n",
      "epoch 73; iter: 0; batch classifier loss: 0.360684; batch adversarial loss: 0.573035\n",
      "epoch 74; iter: 0; batch classifier loss: 0.421797; batch adversarial loss: 0.591337\n",
      "epoch 75; iter: 0; batch classifier loss: 0.376509; batch adversarial loss: 0.637109\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397569; batch adversarial loss: 0.536196\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360883; batch adversarial loss: 0.442873\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401713; batch adversarial loss: 0.535208\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367998; batch adversarial loss: 0.525179\n",
      "epoch 80; iter: 0; batch classifier loss: 0.351834; batch adversarial loss: 0.534130\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388541; batch adversarial loss: 0.627831\n",
      "epoch 82; iter: 0; batch classifier loss: 0.334687; batch adversarial loss: 0.618992\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382544; batch adversarial loss: 0.479289\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384994; batch adversarial loss: 0.637683\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403858; batch adversarial loss: 0.535683\n",
      "epoch 86; iter: 0; batch classifier loss: 0.392882; batch adversarial loss: 0.477700\n",
      "epoch 87; iter: 0; batch classifier loss: 0.357993; batch adversarial loss: 0.517172\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416724; batch adversarial loss: 0.535280\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384126; batch adversarial loss: 0.516949\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407887; batch adversarial loss: 0.544880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.319902; batch adversarial loss: 0.561968\n",
      "epoch 92; iter: 0; batch classifier loss: 0.338845; batch adversarial loss: 0.499274\n",
      "epoch 93; iter: 0; batch classifier loss: 0.334584; batch adversarial loss: 0.591308\n",
      "epoch 94; iter: 0; batch classifier loss: 0.428344; batch adversarial loss: 0.590347\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392205; batch adversarial loss: 0.535614\n",
      "epoch 96; iter: 0; batch classifier loss: 0.337180; batch adversarial loss: 0.554075\n",
      "epoch 97; iter: 0; batch classifier loss: 0.435313; batch adversarial loss: 0.581820\n",
      "epoch 98; iter: 0; batch classifier loss: 0.307573; batch adversarial loss: 0.563822\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410998; batch adversarial loss: 0.553847\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412709; batch adversarial loss: 0.553337\n",
      "epoch 101; iter: 0; batch classifier loss: 0.436063; batch adversarial loss: 0.479693\n",
      "epoch 102; iter: 0; batch classifier loss: 0.435223; batch adversarial loss: 0.517364\n",
      "epoch 103; iter: 0; batch classifier loss: 0.422993; batch adversarial loss: 0.534499\n",
      "epoch 104; iter: 0; batch classifier loss: 0.309807; batch adversarial loss: 0.628832\n",
      "epoch 105; iter: 0; batch classifier loss: 0.305618; batch adversarial loss: 0.517200\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402874; batch adversarial loss: 0.554761\n",
      "epoch 107; iter: 0; batch classifier loss: 0.370082; batch adversarial loss: 0.507588\n",
      "epoch 108; iter: 0; batch classifier loss: 0.412461; batch adversarial loss: 0.489267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357023; batch adversarial loss: 0.591467\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373450; batch adversarial loss: 0.562744\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403521; batch adversarial loss: 0.571807\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360787; batch adversarial loss: 0.469932\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394488; batch adversarial loss: 0.553662\n",
      "epoch 114; iter: 0; batch classifier loss: 0.510092; batch adversarial loss: 0.507497\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388519; batch adversarial loss: 0.580540\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379675; batch adversarial loss: 0.535042\n",
      "epoch 117; iter: 0; batch classifier loss: 0.300135; batch adversarial loss: 0.517080\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357633; batch adversarial loss: 0.544492\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380353; batch adversarial loss: 0.572228\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413281; batch adversarial loss: 0.479380\n",
      "epoch 121; iter: 0; batch classifier loss: 0.282990; batch adversarial loss: 0.535138\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399595; batch adversarial loss: 0.516669\n",
      "epoch 123; iter: 0; batch classifier loss: 0.285720; batch adversarial loss: 0.535428\n",
      "epoch 124; iter: 0; batch classifier loss: 0.389694; batch adversarial loss: 0.618505\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340769; batch adversarial loss: 0.470615\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383944; batch adversarial loss: 0.572722\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388560; batch adversarial loss: 0.497649\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360956; batch adversarial loss: 0.617959\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347837; batch adversarial loss: 0.507514\n",
      "epoch 130; iter: 0; batch classifier loss: 0.334018; batch adversarial loss: 0.517257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367376; batch adversarial loss: 0.545068\n",
      "epoch 132; iter: 0; batch classifier loss: 0.273492; batch adversarial loss: 0.572687\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358900; batch adversarial loss: 0.470385\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367665; batch adversarial loss: 0.517392\n",
      "epoch 135; iter: 0; batch classifier loss: 0.287501; batch adversarial loss: 0.498132\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425525; batch adversarial loss: 0.627271\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382987; batch adversarial loss: 0.478935\n",
      "epoch 138; iter: 0; batch classifier loss: 0.417000; batch adversarial loss: 0.646366\n",
      "epoch 139; iter: 0; batch classifier loss: 0.301591; batch adversarial loss: 0.552790\n",
      "epoch 140; iter: 0; batch classifier loss: 0.281049; batch adversarial loss: 0.516155\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379019; batch adversarial loss: 0.572958\n",
      "epoch 142; iter: 0; batch classifier loss: 0.298868; batch adversarial loss: 0.610088\n",
      "epoch 143; iter: 0; batch classifier loss: 0.349098; batch adversarial loss: 0.581568\n",
      "epoch 144; iter: 0; batch classifier loss: 0.310095; batch adversarial loss: 0.516664\n",
      "epoch 145; iter: 0; batch classifier loss: 0.309362; batch adversarial loss: 0.582228\n",
      "epoch 146; iter: 0; batch classifier loss: 0.290139; batch adversarial loss: 0.553235\n",
      "epoch 147; iter: 0; batch classifier loss: 0.356624; batch adversarial loss: 0.526210\n",
      "epoch 148; iter: 0; batch classifier loss: 0.284431; batch adversarial loss: 0.526612\n",
      "epoch 149; iter: 0; batch classifier loss: 0.309308; batch adversarial loss: 0.563910\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382845; batch adversarial loss: 0.507373\n",
      "epoch 151; iter: 0; batch classifier loss: 0.320767; batch adversarial loss: 0.562909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.357125; batch adversarial loss: 0.508131\n",
      "epoch 153; iter: 0; batch classifier loss: 0.373756; batch adversarial loss: 0.469887\n",
      "epoch 154; iter: 0; batch classifier loss: 0.371601; batch adversarial loss: 0.535527\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340201; batch adversarial loss: 0.553782\n",
      "epoch 156; iter: 0; batch classifier loss: 0.342715; batch adversarial loss: 0.433336\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337205; batch adversarial loss: 0.590626\n",
      "epoch 158; iter: 0; batch classifier loss: 0.311618; batch adversarial loss: 0.488745\n",
      "epoch 159; iter: 0; batch classifier loss: 0.311483; batch adversarial loss: 0.645756\n",
      "epoch 160; iter: 0; batch classifier loss: 0.471841; batch adversarial loss: 0.488934\n",
      "epoch 161; iter: 0; batch classifier loss: 0.305950; batch adversarial loss: 0.553806\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360725; batch adversarial loss: 0.461346\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382697; batch adversarial loss: 0.451807\n",
      "epoch 164; iter: 0; batch classifier loss: 0.453651; batch adversarial loss: 0.497701\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379385; batch adversarial loss: 0.562968\n",
      "epoch 166; iter: 0; batch classifier loss: 0.309013; batch adversarial loss: 0.563318\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409314; batch adversarial loss: 0.507569\n",
      "epoch 168; iter: 0; batch classifier loss: 0.279720; batch adversarial loss: 0.582105\n",
      "epoch 169; iter: 0; batch classifier loss: 0.273743; batch adversarial loss: 0.562870\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354316; batch adversarial loss: 0.517083\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321451; batch adversarial loss: 0.498284\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375843; batch adversarial loss: 0.488298\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355777; batch adversarial loss: 0.590894\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366829; batch adversarial loss: 0.507531\n",
      "epoch 175; iter: 0; batch classifier loss: 0.301386; batch adversarial loss: 0.600287\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329942; batch adversarial loss: 0.507443\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389604; batch adversarial loss: 0.572179\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326363; batch adversarial loss: 0.488745\n",
      "epoch 179; iter: 0; batch classifier loss: 0.332842; batch adversarial loss: 0.599776\n",
      "epoch 180; iter: 0; batch classifier loss: 0.330473; batch adversarial loss: 0.543908\n",
      "epoch 181; iter: 0; batch classifier loss: 0.437597; batch adversarial loss: 0.525626\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366136; batch adversarial loss: 0.572729\n",
      "epoch 183; iter: 0; batch classifier loss: 0.357588; batch adversarial loss: 0.478868\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386370; batch adversarial loss: 0.599896\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338445; batch adversarial loss: 0.609818\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358285; batch adversarial loss: 0.554033\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310613; batch adversarial loss: 0.544669\n",
      "epoch 188; iter: 0; batch classifier loss: 0.411541; batch adversarial loss: 0.488650\n",
      "epoch 189; iter: 0; batch classifier loss: 0.390326; batch adversarial loss: 0.498460\n",
      "epoch 190; iter: 0; batch classifier loss: 0.296489; batch adversarial loss: 0.581668\n",
      "epoch 191; iter: 0; batch classifier loss: 0.258375; batch adversarial loss: 0.488692\n",
      "epoch 192; iter: 0; batch classifier loss: 0.252684; batch adversarial loss: 0.553641\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318141; batch adversarial loss: 0.618582\n",
      "epoch 194; iter: 0; batch classifier loss: 0.292595; batch adversarial loss: 0.507709\n",
      "epoch 195; iter: 0; batch classifier loss: 0.256554; batch adversarial loss: 0.563213\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347027; batch adversarial loss: 0.507041\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326216; batch adversarial loss: 0.646782\n",
      "epoch 198; iter: 0; batch classifier loss: 0.280276; batch adversarial loss: 0.526292\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357305; batch adversarial loss: 0.553840\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679023; batch adversarial loss: 0.573241\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585734; batch adversarial loss: 0.666052\n",
      "epoch 2; iter: 0; batch classifier loss: 0.539575; batch adversarial loss: 0.616221\n",
      "epoch 3; iter: 0; batch classifier loss: 0.643365; batch adversarial loss: 0.685285\n",
      "epoch 4; iter: 0; batch classifier loss: 0.618850; batch adversarial loss: 0.663217\n",
      "epoch 5; iter: 0; batch classifier loss: 0.584872; batch adversarial loss: 0.658475\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517849; batch adversarial loss: 0.602448\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547837; batch adversarial loss: 0.580497\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508305; batch adversarial loss: 0.596560\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534682; batch adversarial loss: 0.632024\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503797; batch adversarial loss: 0.598783\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564263; batch adversarial loss: 0.554898\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553880; batch adversarial loss: 0.562854\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544924; batch adversarial loss: 0.546724\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510507; batch adversarial loss: 0.582136\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489557; batch adversarial loss: 0.576272\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523374; batch adversarial loss: 0.542448\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510011; batch adversarial loss: 0.589633\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529642; batch adversarial loss: 0.604801\n",
      "epoch 19; iter: 0; batch classifier loss: 0.427305; batch adversarial loss: 0.574511\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519230; batch adversarial loss: 0.548559\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462040; batch adversarial loss: 0.553767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492595; batch adversarial loss: 0.556105\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478549; batch adversarial loss: 0.560615\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462009; batch adversarial loss: 0.524976\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465317; batch adversarial loss: 0.576994\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439372; batch adversarial loss: 0.566823\n",
      "epoch 27; iter: 0; batch classifier loss: 0.417499; batch adversarial loss: 0.522545\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453312; batch adversarial loss: 0.592223\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394154; batch adversarial loss: 0.543003\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446440; batch adversarial loss: 0.499139\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444090; batch adversarial loss: 0.617786\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443976; batch adversarial loss: 0.603658\n",
      "epoch 33; iter: 0; batch classifier loss: 0.402219; batch adversarial loss: 0.540131\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433216; batch adversarial loss: 0.536458\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448442; batch adversarial loss: 0.570933\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420448; batch adversarial loss: 0.646378\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431082; batch adversarial loss: 0.582753\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465461; batch adversarial loss: 0.535882\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442082; batch adversarial loss: 0.484383\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461592; batch adversarial loss: 0.543492\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418516; batch adversarial loss: 0.548981\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391772; batch adversarial loss: 0.475599\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429187; batch adversarial loss: 0.631236\n",
      "epoch 44; iter: 0; batch classifier loss: 0.520704; batch adversarial loss: 0.538167\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438132; batch adversarial loss: 0.604529\n",
      "epoch 46; iter: 0; batch classifier loss: 0.389883; batch adversarial loss: 0.546737\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418317; batch adversarial loss: 0.528870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.382470; batch adversarial loss: 0.514483\n",
      "epoch 49; iter: 0; batch classifier loss: 0.481521; batch adversarial loss: 0.525153\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441951; batch adversarial loss: 0.561101\n",
      "epoch 51; iter: 0; batch classifier loss: 0.373161; batch adversarial loss: 0.552828\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423670; batch adversarial loss: 0.452455\n",
      "epoch 53; iter: 0; batch classifier loss: 0.435041; batch adversarial loss: 0.564674\n",
      "epoch 54; iter: 0; batch classifier loss: 0.373325; batch adversarial loss: 0.523548\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403059; batch adversarial loss: 0.506185\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390452; batch adversarial loss: 0.506836\n",
      "epoch 57; iter: 0; batch classifier loss: 0.418920; batch adversarial loss: 0.591607\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447183; batch adversarial loss: 0.532720\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428349; batch adversarial loss: 0.545007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356697; batch adversarial loss: 0.561053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419199; batch adversarial loss: 0.576711\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387289; batch adversarial loss: 0.570885\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394016; batch adversarial loss: 0.552609\n",
      "epoch 64; iter: 0; batch classifier loss: 0.354781; batch adversarial loss: 0.582055\n",
      "epoch 65; iter: 0; batch classifier loss: 0.511170; batch adversarial loss: 0.547081\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443149; batch adversarial loss: 0.607993\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388181; batch adversarial loss: 0.617274\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430189; batch adversarial loss: 0.532965\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382523; batch adversarial loss: 0.560947\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422695; batch adversarial loss: 0.641319\n",
      "epoch 71; iter: 0; batch classifier loss: 0.320151; batch adversarial loss: 0.630712\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398706; batch adversarial loss: 0.591982\n",
      "epoch 73; iter: 0; batch classifier loss: 0.507054; batch adversarial loss: 0.540971\n",
      "epoch 74; iter: 0; batch classifier loss: 0.350707; batch adversarial loss: 0.507768\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449573; batch adversarial loss: 0.551946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421390; batch adversarial loss: 0.560421\n",
      "epoch 77; iter: 0; batch classifier loss: 0.366405; batch adversarial loss: 0.449087\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379402; batch adversarial loss: 0.607313\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382943; batch adversarial loss: 0.590566\n",
      "epoch 80; iter: 0; batch classifier loss: 0.344590; batch adversarial loss: 0.645632\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391304; batch adversarial loss: 0.591902\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410571; batch adversarial loss: 0.531370\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405118; batch adversarial loss: 0.542528\n",
      "epoch 84; iter: 0; batch classifier loss: 0.394983; batch adversarial loss: 0.545614\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397177; batch adversarial loss: 0.563558\n",
      "epoch 86; iter: 0; batch classifier loss: 0.354958; batch adversarial loss: 0.609185\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420975; batch adversarial loss: 0.515832\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384715; batch adversarial loss: 0.627879\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383391; batch adversarial loss: 0.564738\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365266; batch adversarial loss: 0.554666\n",
      "epoch 91; iter: 0; batch classifier loss: 0.319910; batch adversarial loss: 0.661684\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392318; batch adversarial loss: 0.588209\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352608; batch adversarial loss: 0.536759\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415435; batch adversarial loss: 0.508752\n",
      "epoch 95; iter: 0; batch classifier loss: 0.389215; batch adversarial loss: 0.542632\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335378; batch adversarial loss: 0.653662\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383033; batch adversarial loss: 0.528928\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379246; batch adversarial loss: 0.598222\n",
      "epoch 99; iter: 0; batch classifier loss: 0.469853; batch adversarial loss: 0.561353\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417528; batch adversarial loss: 0.527035\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387546; batch adversarial loss: 0.526671\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363723; batch adversarial loss: 0.598499\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382971; batch adversarial loss: 0.535936\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390175; batch adversarial loss: 0.543988\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423269; batch adversarial loss: 0.571635\n",
      "epoch 106; iter: 0; batch classifier loss: 0.416371; batch adversarial loss: 0.581208\n",
      "epoch 107; iter: 0; batch classifier loss: 0.435384; batch adversarial loss: 0.543496\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398185; batch adversarial loss: 0.615930\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403073; batch adversarial loss: 0.561851\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353331; batch adversarial loss: 0.606793\n",
      "epoch 111; iter: 0; batch classifier loss: 0.396140; batch adversarial loss: 0.487002\n",
      "epoch 112; iter: 0; batch classifier loss: 0.400069; batch adversarial loss: 0.582245\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387078; batch adversarial loss: 0.552935\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377037; batch adversarial loss: 0.610015\n",
      "epoch 115; iter: 0; batch classifier loss: 0.395439; batch adversarial loss: 0.566332\n",
      "epoch 116; iter: 0; batch classifier loss: 0.453820; batch adversarial loss: 0.532377\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354227; batch adversarial loss: 0.553794\n",
      "epoch 118; iter: 0; batch classifier loss: 0.457971; batch adversarial loss: 0.517711\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363895; batch adversarial loss: 0.526816\n",
      "epoch 120; iter: 0; batch classifier loss: 0.397805; batch adversarial loss: 0.507122\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390640; batch adversarial loss: 0.615000\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355086; batch adversarial loss: 0.591040\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341168; batch adversarial loss: 0.543872\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336176; batch adversarial loss: 0.514391\n",
      "epoch 125; iter: 0; batch classifier loss: 0.422696; batch adversarial loss: 0.544730\n",
      "epoch 126; iter: 0; batch classifier loss: 0.352733; batch adversarial loss: 0.620843\n",
      "epoch 127; iter: 0; batch classifier loss: 0.421068; batch adversarial loss: 0.514619\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338862; batch adversarial loss: 0.535416\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342312; batch adversarial loss: 0.544921\n",
      "epoch 130; iter: 0; batch classifier loss: 0.463190; batch adversarial loss: 0.487834\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360790; batch adversarial loss: 0.497871\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339134; batch adversarial loss: 0.528168\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410291; batch adversarial loss: 0.562913\n",
      "epoch 134; iter: 0; batch classifier loss: 0.305170; batch adversarial loss: 0.572873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375485; batch adversarial loss: 0.535376\n",
      "epoch 136; iter: 0; batch classifier loss: 0.319905; batch adversarial loss: 0.554930\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329267; batch adversarial loss: 0.593803\n",
      "epoch 138; iter: 0; batch classifier loss: 0.412698; batch adversarial loss: 0.554635\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368413; batch adversarial loss: 0.645290\n",
      "epoch 140; iter: 0; batch classifier loss: 0.467801; batch adversarial loss: 0.572790\n",
      "epoch 141; iter: 0; batch classifier loss: 0.335490; batch adversarial loss: 0.562180\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376314; batch adversarial loss: 0.496804\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334176; batch adversarial loss: 0.653826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.357803; batch adversarial loss: 0.646719\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349247; batch adversarial loss: 0.607865\n",
      "epoch 146; iter: 0; batch classifier loss: 0.354834; batch adversarial loss: 0.572398\n",
      "epoch 147; iter: 0; batch classifier loss: 0.420291; batch adversarial loss: 0.570398\n",
      "epoch 148; iter: 0; batch classifier loss: 0.384643; batch adversarial loss: 0.471603\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405140; batch adversarial loss: 0.560608\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320598; batch adversarial loss: 0.536805\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357238; batch adversarial loss: 0.555899\n",
      "epoch 152; iter: 0; batch classifier loss: 0.299883; batch adversarial loss: 0.568936\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363873; batch adversarial loss: 0.496919\n",
      "epoch 154; iter: 0; batch classifier loss: 0.413564; batch adversarial loss: 0.525688\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374799; batch adversarial loss: 0.526451\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317603; batch adversarial loss: 0.525706\n",
      "epoch 157; iter: 0; batch classifier loss: 0.339630; batch adversarial loss: 0.526765\n",
      "epoch 158; iter: 0; batch classifier loss: 0.407361; batch adversarial loss: 0.551883\n",
      "epoch 159; iter: 0; batch classifier loss: 0.253679; batch adversarial loss: 0.444489\n",
      "epoch 160; iter: 0; batch classifier loss: 0.397115; batch adversarial loss: 0.573811\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342772; batch adversarial loss: 0.516745\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343362; batch adversarial loss: 0.598485\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319490; batch adversarial loss: 0.534424\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373340; batch adversarial loss: 0.570717\n",
      "epoch 165; iter: 0; batch classifier loss: 0.324339; batch adversarial loss: 0.582462\n",
      "epoch 166; iter: 0; batch classifier loss: 0.400778; batch adversarial loss: 0.543639\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340088; batch adversarial loss: 0.526201\n",
      "epoch 168; iter: 0; batch classifier loss: 0.329867; batch adversarial loss: 0.571345\n",
      "epoch 169; iter: 0; batch classifier loss: 0.413367; batch adversarial loss: 0.526540\n",
      "epoch 170; iter: 0; batch classifier loss: 0.300746; batch adversarial loss: 0.504923\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362174; batch adversarial loss: 0.630179\n",
      "epoch 172; iter: 0; batch classifier loss: 0.414489; batch adversarial loss: 0.554136\n",
      "epoch 173; iter: 0; batch classifier loss: 0.427006; batch adversarial loss: 0.574291\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370126; batch adversarial loss: 0.536662\n",
      "epoch 175; iter: 0; batch classifier loss: 0.373364; batch adversarial loss: 0.544157\n",
      "epoch 176; iter: 0; batch classifier loss: 0.299393; batch adversarial loss: 0.590638\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396756; batch adversarial loss: 0.570201\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332760; batch adversarial loss: 0.570495\n",
      "epoch 179; iter: 0; batch classifier loss: 0.342249; batch adversarial loss: 0.515169\n",
      "epoch 180; iter: 0; batch classifier loss: 0.319989; batch adversarial loss: 0.572225\n",
      "epoch 181; iter: 0; batch classifier loss: 0.321431; batch adversarial loss: 0.478678\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334068; batch adversarial loss: 0.571762\n",
      "epoch 183; iter: 0; batch classifier loss: 0.292593; batch adversarial loss: 0.541668\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383996; batch adversarial loss: 0.595393\n",
      "epoch 185; iter: 0; batch classifier loss: 0.353917; batch adversarial loss: 0.516645\n",
      "epoch 186; iter: 0; batch classifier loss: 0.370462; batch adversarial loss: 0.608813\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352343; batch adversarial loss: 0.580116\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396450; batch adversarial loss: 0.572588\n",
      "epoch 189; iter: 0; batch classifier loss: 0.373113; batch adversarial loss: 0.500371\n",
      "epoch 190; iter: 0; batch classifier loss: 0.315109; batch adversarial loss: 0.488826\n",
      "epoch 191; iter: 0; batch classifier loss: 0.265858; batch adversarial loss: 0.494339\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364414; batch adversarial loss: 0.581801\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402941; batch adversarial loss: 0.458446\n",
      "epoch 194; iter: 0; batch classifier loss: 0.394460; batch adversarial loss: 0.560571\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359655; batch adversarial loss: 0.496610\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331642; batch adversarial loss: 0.572467\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381634; batch adversarial loss: 0.583166\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319893; batch adversarial loss: 0.564736\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374165; batch adversarial loss: 0.544636\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711372; batch adversarial loss: 0.645902\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571983; batch adversarial loss: 0.641721\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611112; batch adversarial loss: 0.671254\n",
      "epoch 3; iter: 0; batch classifier loss: 0.592213; batch adversarial loss: 0.608972\n",
      "epoch 4; iter: 0; batch classifier loss: 0.504498; batch adversarial loss: 0.627454\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612149; batch adversarial loss: 0.631225\n",
      "epoch 6; iter: 0; batch classifier loss: 0.610314; batch adversarial loss: 0.624470\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527559; batch adversarial loss: 0.622030\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545642; batch adversarial loss: 0.556867\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526154; batch adversarial loss: 0.580615\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525081; batch adversarial loss: 0.630813\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553172; batch adversarial loss: 0.579544\n",
      "epoch 12; iter: 0; batch classifier loss: 0.464098; batch adversarial loss: 0.576967\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559388; batch adversarial loss: 0.523975\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502144; batch adversarial loss: 0.617514\n",
      "epoch 15; iter: 0; batch classifier loss: 0.547897; batch adversarial loss: 0.508191\n",
      "epoch 16; iter: 0; batch classifier loss: 0.603772; batch adversarial loss: 0.641096\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523051; batch adversarial loss: 0.568799\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472827; batch adversarial loss: 0.588598\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536330; batch adversarial loss: 0.587736\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518534; batch adversarial loss: 0.582682\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509615; batch adversarial loss: 0.515379\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471715; batch adversarial loss: 0.553550\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488963; batch adversarial loss: 0.524616\n",
      "epoch 24; iter: 0; batch classifier loss: 0.451822; batch adversarial loss: 0.627203\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440648; batch adversarial loss: 0.544845\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477886; batch adversarial loss: 0.542771\n",
      "epoch 27; iter: 0; batch classifier loss: 0.504821; batch adversarial loss: 0.590546\n",
      "epoch 28; iter: 0; batch classifier loss: 0.524984; batch adversarial loss: 0.597237\n",
      "epoch 29; iter: 0; batch classifier loss: 0.333177; batch adversarial loss: 0.519942\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424057; batch adversarial loss: 0.573321\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429959; batch adversarial loss: 0.524511\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453440; batch adversarial loss: 0.473402\n",
      "epoch 33; iter: 0; batch classifier loss: 0.407311; batch adversarial loss: 0.482276\n",
      "epoch 34; iter: 0; batch classifier loss: 0.349898; batch adversarial loss: 0.476903\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406727; batch adversarial loss: 0.530706\n",
      "epoch 36; iter: 0; batch classifier loss: 0.534898; batch adversarial loss: 0.508597\n",
      "epoch 37; iter: 0; batch classifier loss: 0.435435; batch adversarial loss: 0.597044\n",
      "epoch 38; iter: 0; batch classifier loss: 0.509294; batch adversarial loss: 0.525962\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470084; batch adversarial loss: 0.556536\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426626; batch adversarial loss: 0.517831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.472244; batch adversarial loss: 0.543961\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470019; batch adversarial loss: 0.581744\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447671; batch adversarial loss: 0.526429\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490456; batch adversarial loss: 0.515615\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377362; batch adversarial loss: 0.599180\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483561; batch adversarial loss: 0.489256\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410944; batch adversarial loss: 0.509458\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434063; batch adversarial loss: 0.525948\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477433; batch adversarial loss: 0.526369\n",
      "epoch 50; iter: 0; batch classifier loss: 0.409195; batch adversarial loss: 0.524476\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437756; batch adversarial loss: 0.479625\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386297; batch adversarial loss: 0.627020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.473710; batch adversarial loss: 0.525971\n",
      "epoch 54; iter: 0; batch classifier loss: 0.486956; batch adversarial loss: 0.542516\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382773; batch adversarial loss: 0.573243\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428226; batch adversarial loss: 0.580594\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396052; batch adversarial loss: 0.477782\n",
      "epoch 58; iter: 0; batch classifier loss: 0.349724; batch adversarial loss: 0.589712\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412846; batch adversarial loss: 0.556996\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421088; batch adversarial loss: 0.607427\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414937; batch adversarial loss: 0.506010\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414882; batch adversarial loss: 0.600550\n",
      "epoch 63; iter: 0; batch classifier loss: 0.475887; batch adversarial loss: 0.561857\n",
      "epoch 64; iter: 0; batch classifier loss: 0.416316; batch adversarial loss: 0.562956\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398696; batch adversarial loss: 0.561178\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416197; batch adversarial loss: 0.581819\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377037; batch adversarial loss: 0.490053\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386674; batch adversarial loss: 0.581972\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426190; batch adversarial loss: 0.600402\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461099; batch adversarial loss: 0.572733\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384044; batch adversarial loss: 0.599923\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457676; batch adversarial loss: 0.591187\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425675; batch adversarial loss: 0.580296\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437340; batch adversarial loss: 0.635614\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367630; batch adversarial loss: 0.489363\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411729; batch adversarial loss: 0.543712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.431375; batch adversarial loss: 0.609906\n",
      "epoch 78; iter: 0; batch classifier loss: 0.320664; batch adversarial loss: 0.609109\n",
      "epoch 79; iter: 0; batch classifier loss: 0.465609; batch adversarial loss: 0.461742\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395245; batch adversarial loss: 0.571159\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422814; batch adversarial loss: 0.524678\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386470; batch adversarial loss: 0.599629\n",
      "epoch 83; iter: 0; batch classifier loss: 0.418906; batch adversarial loss: 0.572461\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374177; batch adversarial loss: 0.589831\n",
      "epoch 85; iter: 0; batch classifier loss: 0.384777; batch adversarial loss: 0.543742\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378714; batch adversarial loss: 0.489814\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384422; batch adversarial loss: 0.543060\n",
      "epoch 88; iter: 0; batch classifier loss: 0.437509; batch adversarial loss: 0.553909\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374635; batch adversarial loss: 0.452756\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373923; batch adversarial loss: 0.526119\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373047; batch adversarial loss: 0.506974\n",
      "epoch 92; iter: 0; batch classifier loss: 0.342891; batch adversarial loss: 0.516838\n",
      "epoch 93; iter: 0; batch classifier loss: 0.434179; batch adversarial loss: 0.497142\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372775; batch adversarial loss: 0.470755\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424124; batch adversarial loss: 0.571154\n",
      "epoch 96; iter: 0; batch classifier loss: 0.324687; batch adversarial loss: 0.534605\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386950; batch adversarial loss: 0.554787\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402849; batch adversarial loss: 0.489211\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419168; batch adversarial loss: 0.645707\n",
      "epoch 100; iter: 0; batch classifier loss: 0.422346; batch adversarial loss: 0.600256\n",
      "epoch 101; iter: 0; batch classifier loss: 0.441568; batch adversarial loss: 0.507192\n",
      "epoch 102; iter: 0; batch classifier loss: 0.310923; batch adversarial loss: 0.479211\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404631; batch adversarial loss: 0.545534\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384053; batch adversarial loss: 0.526707\n",
      "epoch 105; iter: 0; batch classifier loss: 0.392971; batch adversarial loss: 0.516947\n",
      "epoch 106; iter: 0; batch classifier loss: 0.332635; batch adversarial loss: 0.544222\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364891; batch adversarial loss: 0.535906\n",
      "epoch 108; iter: 0; batch classifier loss: 0.394972; batch adversarial loss: 0.626947\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415411; batch adversarial loss: 0.533836\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398723; batch adversarial loss: 0.562550\n",
      "epoch 111; iter: 0; batch classifier loss: 0.297304; batch adversarial loss: 0.451225\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411044; batch adversarial loss: 0.544880\n",
      "epoch 113; iter: 0; batch classifier loss: 0.435566; batch adversarial loss: 0.505792\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368364; batch adversarial loss: 0.488878\n",
      "epoch 115; iter: 0; batch classifier loss: 0.461889; batch adversarial loss: 0.562799\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371398; batch adversarial loss: 0.570273\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379833; batch adversarial loss: 0.588627\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391096; batch adversarial loss: 0.648716\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428628; batch adversarial loss: 0.516847\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387847; batch adversarial loss: 0.519546\n",
      "epoch 121; iter: 0; batch classifier loss: 0.490409; batch adversarial loss: 0.488062\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381974; batch adversarial loss: 0.618178\n",
      "epoch 123; iter: 0; batch classifier loss: 0.419200; batch adversarial loss: 0.508317\n",
      "epoch 124; iter: 0; batch classifier loss: 0.331489; batch adversarial loss: 0.535202\n",
      "epoch 125; iter: 0; batch classifier loss: 0.457955; batch adversarial loss: 0.571941\n",
      "epoch 126; iter: 0; batch classifier loss: 0.420247; batch adversarial loss: 0.617546\n",
      "epoch 127; iter: 0; batch classifier loss: 0.418663; batch adversarial loss: 0.535112\n",
      "epoch 128; iter: 0; batch classifier loss: 0.445688; batch adversarial loss: 0.525019\n",
      "epoch 129; iter: 0; batch classifier loss: 0.352447; batch adversarial loss: 0.599499\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361679; batch adversarial loss: 0.627604\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387949; batch adversarial loss: 0.462280\n",
      "epoch 132; iter: 0; batch classifier loss: 0.479911; batch adversarial loss: 0.563608\n",
      "epoch 133; iter: 0; batch classifier loss: 0.314063; batch adversarial loss: 0.561646\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401364; batch adversarial loss: 0.498575\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413697; batch adversarial loss: 0.608371\n",
      "epoch 136; iter: 0; batch classifier loss: 0.398516; batch adversarial loss: 0.553228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.342833; batch adversarial loss: 0.545008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357218; batch adversarial loss: 0.535912\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359131; batch adversarial loss: 0.544489\n",
      "epoch 140; iter: 0; batch classifier loss: 0.469469; batch adversarial loss: 0.498513\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368940; batch adversarial loss: 0.543231\n",
      "epoch 142; iter: 0; batch classifier loss: 0.319215; batch adversarial loss: 0.571388\n",
      "epoch 143; iter: 0; batch classifier loss: 0.339159; batch adversarial loss: 0.554079\n",
      "epoch 144; iter: 0; batch classifier loss: 0.285182; batch adversarial loss: 0.471537\n",
      "epoch 145; iter: 0; batch classifier loss: 0.461209; batch adversarial loss: 0.554462\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400400; batch adversarial loss: 0.562804\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337681; batch adversarial loss: 0.516374\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395812; batch adversarial loss: 0.552691\n",
      "epoch 149; iter: 0; batch classifier loss: 0.358716; batch adversarial loss: 0.496468\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421035; batch adversarial loss: 0.561557\n",
      "epoch 151; iter: 0; batch classifier loss: 0.401292; batch adversarial loss: 0.606941\n",
      "epoch 152; iter: 0; batch classifier loss: 0.442982; batch adversarial loss: 0.571873\n",
      "epoch 153; iter: 0; batch classifier loss: 0.464875; batch adversarial loss: 0.496525\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379899; batch adversarial loss: 0.590851\n",
      "epoch 155; iter: 0; batch classifier loss: 0.304891; batch adversarial loss: 0.635045\n",
      "epoch 156; iter: 0; batch classifier loss: 0.496266; batch adversarial loss: 0.499051\n",
      "epoch 157; iter: 0; batch classifier loss: 0.414748; batch adversarial loss: 0.580694\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403755; batch adversarial loss: 0.535853\n",
      "epoch 159; iter: 0; batch classifier loss: 0.304553; batch adversarial loss: 0.551119\n",
      "epoch 160; iter: 0; batch classifier loss: 0.420043; batch adversarial loss: 0.610779\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376569; batch adversarial loss: 0.563687\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344664; batch adversarial loss: 0.548112\n",
      "epoch 163; iter: 0; batch classifier loss: 0.304088; batch adversarial loss: 0.526510\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361437; batch adversarial loss: 0.573224\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343775; batch adversarial loss: 0.508620\n",
      "epoch 166; iter: 0; batch classifier loss: 0.399387; batch adversarial loss: 0.537002\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336094; batch adversarial loss: 0.515823\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370176; batch adversarial loss: 0.562322\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356006; batch adversarial loss: 0.562503\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361065; batch adversarial loss: 0.553505\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392681; batch adversarial loss: 0.554097\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378739; batch adversarial loss: 0.517666\n",
      "epoch 173; iter: 0; batch classifier loss: 0.379726; batch adversarial loss: 0.562390\n",
      "epoch 174; iter: 0; batch classifier loss: 0.383163; batch adversarial loss: 0.581229\n",
      "epoch 175; iter: 0; batch classifier loss: 0.287942; batch adversarial loss: 0.571915\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354344; batch adversarial loss: 0.472403\n",
      "epoch 177; iter: 0; batch classifier loss: 0.412431; batch adversarial loss: 0.525770\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332015; batch adversarial loss: 0.618462\n",
      "epoch 179; iter: 0; batch classifier loss: 0.324263; batch adversarial loss: 0.544186\n",
      "epoch 180; iter: 0; batch classifier loss: 0.301669; batch adversarial loss: 0.552365\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334772; batch adversarial loss: 0.516790\n",
      "epoch 182; iter: 0; batch classifier loss: 0.306784; batch adversarial loss: 0.526250\n",
      "epoch 183; iter: 0; batch classifier loss: 0.277545; batch adversarial loss: 0.442368\n",
      "epoch 184; iter: 0; batch classifier loss: 0.302511; batch adversarial loss: 0.616617\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391409; batch adversarial loss: 0.582192\n",
      "epoch 186; iter: 0; batch classifier loss: 0.317926; batch adversarial loss: 0.591752\n",
      "epoch 187; iter: 0; batch classifier loss: 0.383528; batch adversarial loss: 0.498701\n",
      "epoch 188; iter: 0; batch classifier loss: 0.370962; batch adversarial loss: 0.516220\n",
      "epoch 189; iter: 0; batch classifier loss: 0.407060; batch adversarial loss: 0.526647\n",
      "epoch 190; iter: 0; batch classifier loss: 0.325188; batch adversarial loss: 0.535258\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306366; batch adversarial loss: 0.591032\n",
      "epoch 192; iter: 0; batch classifier loss: 0.379460; batch adversarial loss: 0.536086\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368156; batch adversarial loss: 0.562786\n",
      "epoch 194; iter: 0; batch classifier loss: 0.394580; batch adversarial loss: 0.553575\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381289; batch adversarial loss: 0.580573\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331955; batch adversarial loss: 0.571816\n",
      "epoch 197; iter: 0; batch classifier loss: 0.405918; batch adversarial loss: 0.590059\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343129; batch adversarial loss: 0.544143\n",
      "epoch 199; iter: 0; batch classifier loss: 0.371402; batch adversarial loss: 0.543872\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680665; batch adversarial loss: 0.635267\n",
      "epoch 1; iter: 0; batch classifier loss: 0.553416; batch adversarial loss: 0.648839\n",
      "epoch 2; iter: 0; batch classifier loss: 0.691393; batch adversarial loss: 0.657167\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612191; batch adversarial loss: 0.650628\n",
      "epoch 4; iter: 0; batch classifier loss: 0.623581; batch adversarial loss: 0.652698\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602915; batch adversarial loss: 0.594239\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570843; batch adversarial loss: 0.641450\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596437; batch adversarial loss: 0.578212\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588298; batch adversarial loss: 0.621624\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531924; batch adversarial loss: 0.552491\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523154; batch adversarial loss: 0.580647\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529763; batch adversarial loss: 0.576201\n",
      "epoch 12; iter: 0; batch classifier loss: 0.465558; batch adversarial loss: 0.531521\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542054; batch adversarial loss: 0.575562\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502903; batch adversarial loss: 0.548854\n",
      "epoch 15; iter: 0; batch classifier loss: 0.625007; batch adversarial loss: 0.587385\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500739; batch adversarial loss: 0.532424\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534422; batch adversarial loss: 0.572355\n",
      "epoch 18; iter: 0; batch classifier loss: 0.551373; batch adversarial loss: 0.566117\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517815; batch adversarial loss: 0.583861\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509339; batch adversarial loss: 0.542865\n",
      "epoch 21; iter: 0; batch classifier loss: 0.531532; batch adversarial loss: 0.540597\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468799; batch adversarial loss: 0.516315\n",
      "epoch 23; iter: 0; batch classifier loss: 0.562679; batch adversarial loss: 0.441851\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514414; batch adversarial loss: 0.571006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.408881; batch adversarial loss: 0.587163\n",
      "epoch 26; iter: 0; batch classifier loss: 0.426490; batch adversarial loss: 0.537241\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463500; batch adversarial loss: 0.587780\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452908; batch adversarial loss: 0.536628\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438815; batch adversarial loss: 0.502133\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459324; batch adversarial loss: 0.544828\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433384; batch adversarial loss: 0.536633\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478137; batch adversarial loss: 0.544362\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462723; batch adversarial loss: 0.569675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.489583; batch adversarial loss: 0.527879\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454047; batch adversarial loss: 0.545012\n",
      "epoch 36; iter: 0; batch classifier loss: 0.396167; batch adversarial loss: 0.499397\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455280; batch adversarial loss: 0.488360\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428758; batch adversarial loss: 0.527957\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443057; batch adversarial loss: 0.508602\n",
      "epoch 40; iter: 0; batch classifier loss: 0.475805; batch adversarial loss: 0.545132\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437888; batch adversarial loss: 0.544027\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421681; batch adversarial loss: 0.517570\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415881; batch adversarial loss: 0.636189\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485406; batch adversarial loss: 0.518748\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502593; batch adversarial loss: 0.634197\n",
      "epoch 46; iter: 0; batch classifier loss: 0.490565; batch adversarial loss: 0.541080\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439104; batch adversarial loss: 0.533593\n",
      "epoch 48; iter: 0; batch classifier loss: 0.501792; batch adversarial loss: 0.617486\n",
      "epoch 49; iter: 0; batch classifier loss: 0.512138; batch adversarial loss: 0.572892\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422707; batch adversarial loss: 0.562637\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466892; batch adversarial loss: 0.522169\n",
      "epoch 52; iter: 0; batch classifier loss: 0.502837; batch adversarial loss: 0.508385\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442980; batch adversarial loss: 0.525100\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395939; batch adversarial loss: 0.535564\n",
      "epoch 55; iter: 0; batch classifier loss: 0.463315; batch adversarial loss: 0.553257\n",
      "epoch 56; iter: 0; batch classifier loss: 0.459228; batch adversarial loss: 0.536083\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446190; batch adversarial loss: 0.561737\n",
      "epoch 58; iter: 0; batch classifier loss: 0.474132; batch adversarial loss: 0.508567\n",
      "epoch 59; iter: 0; batch classifier loss: 0.365315; batch adversarial loss: 0.524812\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398398; batch adversarial loss: 0.571719\n",
      "epoch 61; iter: 0; batch classifier loss: 0.484239; batch adversarial loss: 0.506028\n",
      "epoch 62; iter: 0; batch classifier loss: 0.482664; batch adversarial loss: 0.498701\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409934; batch adversarial loss: 0.563160\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421554; batch adversarial loss: 0.553766\n",
      "epoch 65; iter: 0; batch classifier loss: 0.461881; batch adversarial loss: 0.599055\n",
      "epoch 66; iter: 0; batch classifier loss: 0.462271; batch adversarial loss: 0.525225\n",
      "epoch 67; iter: 0; batch classifier loss: 0.396272; batch adversarial loss: 0.599052\n",
      "epoch 68; iter: 0; batch classifier loss: 0.497462; batch adversarial loss: 0.464555\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402150; batch adversarial loss: 0.496536\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397750; batch adversarial loss: 0.592199\n",
      "epoch 71; iter: 0; batch classifier loss: 0.459635; batch adversarial loss: 0.560792\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401758; batch adversarial loss: 0.581370\n",
      "epoch 73; iter: 0; batch classifier loss: 0.518068; batch adversarial loss: 0.506004\n",
      "epoch 74; iter: 0; batch classifier loss: 0.317307; batch adversarial loss: 0.561542\n",
      "epoch 75; iter: 0; batch classifier loss: 0.502818; batch adversarial loss: 0.511149\n",
      "epoch 76; iter: 0; batch classifier loss: 0.435505; batch adversarial loss: 0.487897\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386220; batch adversarial loss: 0.462713\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455650; batch adversarial loss: 0.523670\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417776; batch adversarial loss: 0.470014\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365384; batch adversarial loss: 0.576733\n",
      "epoch 81; iter: 0; batch classifier loss: 0.441749; batch adversarial loss: 0.533050\n",
      "epoch 82; iter: 0; batch classifier loss: 0.445324; batch adversarial loss: 0.542992\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407825; batch adversarial loss: 0.508243\n",
      "epoch 84; iter: 0; batch classifier loss: 0.484977; batch adversarial loss: 0.506395\n",
      "epoch 85; iter: 0; batch classifier loss: 0.468032; batch adversarial loss: 0.535680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.434763; batch adversarial loss: 0.564226\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395011; batch adversarial loss: 0.536011\n",
      "epoch 88; iter: 0; batch classifier loss: 0.432699; batch adversarial loss: 0.494398\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389682; batch adversarial loss: 0.531455\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432935; batch adversarial loss: 0.561076\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439963; batch adversarial loss: 0.535142\n",
      "epoch 92; iter: 0; batch classifier loss: 0.319149; batch adversarial loss: 0.515764\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422883; batch adversarial loss: 0.526679\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411179; batch adversarial loss: 0.490836\n",
      "epoch 95; iter: 0; batch classifier loss: 0.472115; batch adversarial loss: 0.507612\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394993; batch adversarial loss: 0.469967\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423100; batch adversarial loss: 0.551336\n",
      "epoch 98; iter: 0; batch classifier loss: 0.446853; batch adversarial loss: 0.542948\n",
      "epoch 99; iter: 0; batch classifier loss: 0.433917; batch adversarial loss: 0.498269\n",
      "epoch 100; iter: 0; batch classifier loss: 0.432708; batch adversarial loss: 0.623432\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392282; batch adversarial loss: 0.475051\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402176; batch adversarial loss: 0.481667\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406376; batch adversarial loss: 0.497238\n",
      "epoch 104; iter: 0; batch classifier loss: 0.427112; batch adversarial loss: 0.486817\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405144; batch adversarial loss: 0.536108\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407485; batch adversarial loss: 0.535002\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357479; batch adversarial loss: 0.406359\n",
      "epoch 108; iter: 0; batch classifier loss: 0.483678; batch adversarial loss: 0.623186\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360927; batch adversarial loss: 0.571355\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370196; batch adversarial loss: 0.549221\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395128; batch adversarial loss: 0.524567\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392261; batch adversarial loss: 0.652318\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374749; batch adversarial loss: 0.583253\n",
      "epoch 114; iter: 0; batch classifier loss: 0.455227; batch adversarial loss: 0.475353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.375377; batch adversarial loss: 0.525855\n",
      "epoch 116; iter: 0; batch classifier loss: 0.444679; batch adversarial loss: 0.540076\n",
      "epoch 117; iter: 0; batch classifier loss: 0.429997; batch adversarial loss: 0.545966\n",
      "epoch 118; iter: 0; batch classifier loss: 0.446467; batch adversarial loss: 0.567182\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375693; batch adversarial loss: 0.541831\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386937; batch adversarial loss: 0.532812\n",
      "epoch 121; iter: 0; batch classifier loss: 0.433948; batch adversarial loss: 0.441561\n",
      "epoch 122; iter: 0; batch classifier loss: 0.462420; batch adversarial loss: 0.639553\n",
      "epoch 123; iter: 0; batch classifier loss: 0.326566; batch adversarial loss: 0.480147\n",
      "epoch 124; iter: 0; batch classifier loss: 0.301550; batch adversarial loss: 0.610625\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374676; batch adversarial loss: 0.613553\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317541; batch adversarial loss: 0.479067\n",
      "epoch 127; iter: 0; batch classifier loss: 0.351464; batch adversarial loss: 0.600798\n",
      "epoch 128; iter: 0; batch classifier loss: 0.440692; batch adversarial loss: 0.604383\n",
      "epoch 129; iter: 0; batch classifier loss: 0.481185; batch adversarial loss: 0.536960\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341077; batch adversarial loss: 0.496083\n",
      "epoch 131; iter: 0; batch classifier loss: 0.528142; batch adversarial loss: 0.527647\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360810; batch adversarial loss: 0.543700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.373609; batch adversarial loss: 0.559492\n",
      "epoch 134; iter: 0; batch classifier loss: 0.457992; batch adversarial loss: 0.496364\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354583; batch adversarial loss: 0.501766\n",
      "epoch 136; iter: 0; batch classifier loss: 0.405844; batch adversarial loss: 0.564382\n",
      "epoch 137; iter: 0; batch classifier loss: 0.394609; batch adversarial loss: 0.497534\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377989; batch adversarial loss: 0.612005\n",
      "epoch 139; iter: 0; batch classifier loss: 0.418962; batch adversarial loss: 0.577338\n",
      "epoch 140; iter: 0; batch classifier loss: 0.503837; batch adversarial loss: 0.525929\n",
      "epoch 141; iter: 0; batch classifier loss: 0.444489; batch adversarial loss: 0.604160\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353223; batch adversarial loss: 0.568728\n",
      "epoch 143; iter: 0; batch classifier loss: 0.387084; batch adversarial loss: 0.605798\n",
      "epoch 144; iter: 0; batch classifier loss: 0.430230; batch adversarial loss: 0.485877\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339492; batch adversarial loss: 0.534879\n",
      "epoch 146; iter: 0; batch classifier loss: 0.409019; batch adversarial loss: 0.466415\n",
      "epoch 147; iter: 0; batch classifier loss: 0.380365; batch adversarial loss: 0.546262\n",
      "epoch 148; iter: 0; batch classifier loss: 0.382862; batch adversarial loss: 0.584415\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352516; batch adversarial loss: 0.469049\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368547; batch adversarial loss: 0.551857\n",
      "epoch 151; iter: 0; batch classifier loss: 0.416355; batch adversarial loss: 0.479107\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390215; batch adversarial loss: 0.508025\n",
      "epoch 153; iter: 0; batch classifier loss: 0.310600; batch adversarial loss: 0.502723\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376274; batch adversarial loss: 0.517117\n",
      "epoch 155; iter: 0; batch classifier loss: 0.440161; batch adversarial loss: 0.590449\n",
      "epoch 156; iter: 0; batch classifier loss: 0.375776; batch adversarial loss: 0.531740\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315570; batch adversarial loss: 0.436699\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384035; batch adversarial loss: 0.560524\n",
      "epoch 159; iter: 0; batch classifier loss: 0.443547; batch adversarial loss: 0.580670\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404803; batch adversarial loss: 0.597059\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354303; batch adversarial loss: 0.527555\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344812; batch adversarial loss: 0.542631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.472474; batch adversarial loss: 0.618762\n",
      "epoch 164; iter: 0; batch classifier loss: 0.487961; batch adversarial loss: 0.578416\n",
      "epoch 165; iter: 0; batch classifier loss: 0.392536; batch adversarial loss: 0.429293\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346575; batch adversarial loss: 0.591302\n",
      "epoch 167; iter: 0; batch classifier loss: 0.397344; batch adversarial loss: 0.553228\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395710; batch adversarial loss: 0.593901\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350945; batch adversarial loss: 0.543313\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360192; batch adversarial loss: 0.541784\n",
      "epoch 171; iter: 0; batch classifier loss: 0.425805; batch adversarial loss: 0.492544\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344330; batch adversarial loss: 0.689656\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392707; batch adversarial loss: 0.563982\n",
      "epoch 174; iter: 0; batch classifier loss: 0.354982; batch adversarial loss: 0.521263\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390352; batch adversarial loss: 0.557640\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395030; batch adversarial loss: 0.560181\n",
      "epoch 177; iter: 0; batch classifier loss: 0.382121; batch adversarial loss: 0.571732\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333896; batch adversarial loss: 0.508819\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389589; batch adversarial loss: 0.533709\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327526; batch adversarial loss: 0.545467\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373342; batch adversarial loss: 0.542360\n",
      "epoch 182; iter: 0; batch classifier loss: 0.422365; batch adversarial loss: 0.552945\n",
      "epoch 183; iter: 0; batch classifier loss: 0.434718; batch adversarial loss: 0.601682\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389805; batch adversarial loss: 0.588801\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379365; batch adversarial loss: 0.620944\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342815; batch adversarial loss: 0.466460\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376718; batch adversarial loss: 0.467463\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387022; batch adversarial loss: 0.517603\n",
      "epoch 189; iter: 0; batch classifier loss: 0.399648; batch adversarial loss: 0.566447\n",
      "epoch 190; iter: 0; batch classifier loss: 0.406919; batch adversarial loss: 0.522243\n",
      "epoch 191; iter: 0; batch classifier loss: 0.384737; batch adversarial loss: 0.507493\n",
      "epoch 192; iter: 0; batch classifier loss: 0.392940; batch adversarial loss: 0.497938\n",
      "epoch 193; iter: 0; batch classifier loss: 0.439276; batch adversarial loss: 0.538535\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313320; batch adversarial loss: 0.551722\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366167; batch adversarial loss: 0.560876\n",
      "epoch 196; iter: 0; batch classifier loss: 0.363851; batch adversarial loss: 0.504109\n",
      "epoch 197; iter: 0; batch classifier loss: 0.402795; batch adversarial loss: 0.505799\n",
      "epoch 198; iter: 0; batch classifier loss: 0.357354; batch adversarial loss: 0.624812\n",
      "epoch 199; iter: 0; batch classifier loss: 0.525501; batch adversarial loss: 0.552360\n",
      "epoch 0; iter: 0; batch classifier loss: 0.634660; batch adversarial loss: 0.773234\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607201; batch adversarial loss: 0.821854\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603938; batch adversarial loss: 0.767456\n",
      "epoch 3; iter: 0; batch classifier loss: 0.535861; batch adversarial loss: 0.713845\n",
      "epoch 4; iter: 0; batch classifier loss: 0.516862; batch adversarial loss: 0.678490\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598867; batch adversarial loss: 0.656628\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524688; batch adversarial loss: 0.626271\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559067; batch adversarial loss: 0.618243\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504853; batch adversarial loss: 0.596781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512940; batch adversarial loss: 0.613810\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529680; batch adversarial loss: 0.592384\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522568; batch adversarial loss: 0.612536\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522320; batch adversarial loss: 0.588561\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544748; batch adversarial loss: 0.611231\n",
      "epoch 14; iter: 0; batch classifier loss: 0.490139; batch adversarial loss: 0.605227\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490413; batch adversarial loss: 0.539306\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542567; batch adversarial loss: 0.524422\n",
      "epoch 17; iter: 0; batch classifier loss: 0.545264; batch adversarial loss: 0.528301\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507797; batch adversarial loss: 0.537954\n",
      "epoch 19; iter: 0; batch classifier loss: 0.412887; batch adversarial loss: 0.571288\n",
      "epoch 20; iter: 0; batch classifier loss: 0.526240; batch adversarial loss: 0.542449\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486578; batch adversarial loss: 0.520857\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500549; batch adversarial loss: 0.603518\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479928; batch adversarial loss: 0.505384\n",
      "epoch 24; iter: 0; batch classifier loss: 0.540816; batch adversarial loss: 0.550948\n",
      "epoch 25; iter: 0; batch classifier loss: 0.458652; batch adversarial loss: 0.577062\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485838; batch adversarial loss: 0.535416\n",
      "epoch 27; iter: 0; batch classifier loss: 0.512716; batch adversarial loss: 0.549272\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462364; batch adversarial loss: 0.492113\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440438; batch adversarial loss: 0.627461\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499176; batch adversarial loss: 0.530923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 0; batch classifier loss: 0.450508; batch adversarial loss: 0.652509\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499357; batch adversarial loss: 0.487596\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473723; batch adversarial loss: 0.523648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497322; batch adversarial loss: 0.565242\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398580; batch adversarial loss: 0.521355\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472319; batch adversarial loss: 0.529678\n",
      "epoch 37; iter: 0; batch classifier loss: 0.533249; batch adversarial loss: 0.536141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459986; batch adversarial loss: 0.528102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410381; batch adversarial loss: 0.588254\n",
      "epoch 40; iter: 0; batch classifier loss: 0.536235; batch adversarial loss: 0.517767\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452863; batch adversarial loss: 0.479966\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374375; batch adversarial loss: 0.562989\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467745; batch adversarial loss: 0.624399\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392845; batch adversarial loss: 0.516613\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408500; batch adversarial loss: 0.491991\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420040; batch adversarial loss: 0.562668\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477475; batch adversarial loss: 0.600202\n",
      "epoch 48; iter: 0; batch classifier loss: 0.398470; batch adversarial loss: 0.479467\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464418; batch adversarial loss: 0.557100\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406994; batch adversarial loss: 0.546070\n",
      "epoch 51; iter: 0; batch classifier loss: 0.396550; batch adversarial loss: 0.589265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.403091; batch adversarial loss: 0.574022\n",
      "epoch 53; iter: 0; batch classifier loss: 0.385751; batch adversarial loss: 0.518233\n",
      "epoch 54; iter: 0; batch classifier loss: 0.407273; batch adversarial loss: 0.562477\n",
      "epoch 55; iter: 0; batch classifier loss: 0.504685; batch adversarial loss: 0.558479\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437900; batch adversarial loss: 0.598968\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442805; batch adversarial loss: 0.526925\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450179; batch adversarial loss: 0.557823\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442241; batch adversarial loss: 0.592359\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411318; batch adversarial loss: 0.590148\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428718; batch adversarial loss: 0.602748\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396917; batch adversarial loss: 0.573634\n",
      "epoch 63; iter: 0; batch classifier loss: 0.514678; batch adversarial loss: 0.500201\n",
      "epoch 64; iter: 0; batch classifier loss: 0.354340; batch adversarial loss: 0.539371\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451457; batch adversarial loss: 0.516014\n",
      "epoch 66; iter: 0; batch classifier loss: 0.541776; batch adversarial loss: 0.642805\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429847; batch adversarial loss: 0.526144\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411653; batch adversarial loss: 0.580439\n",
      "epoch 69; iter: 0; batch classifier loss: 0.464108; batch adversarial loss: 0.476178\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391412; batch adversarial loss: 0.561853\n",
      "epoch 71; iter: 0; batch classifier loss: 0.444769; batch adversarial loss: 0.625897\n",
      "epoch 72; iter: 0; batch classifier loss: 0.424456; batch adversarial loss: 0.525337\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407403; batch adversarial loss: 0.659926\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356693; batch adversarial loss: 0.586666\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367759; batch adversarial loss: 0.529820\n",
      "epoch 76; iter: 0; batch classifier loss: 0.423419; batch adversarial loss: 0.541746\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415260; batch adversarial loss: 0.487697\n",
      "epoch 78; iter: 0; batch classifier loss: 0.425293; batch adversarial loss: 0.533466\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359979; batch adversarial loss: 0.541422\n",
      "epoch 80; iter: 0; batch classifier loss: 0.305023; batch adversarial loss: 0.613445\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369967; batch adversarial loss: 0.526485\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342440; batch adversarial loss: 0.512717\n",
      "epoch 83; iter: 0; batch classifier loss: 0.351600; batch adversarial loss: 0.498910\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453610; batch adversarial loss: 0.618430\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409559; batch adversarial loss: 0.571522\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379520; batch adversarial loss: 0.640798\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352213; batch adversarial loss: 0.553617\n",
      "epoch 88; iter: 0; batch classifier loss: 0.353668; batch adversarial loss: 0.605914\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397382; batch adversarial loss: 0.549761\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393491; batch adversarial loss: 0.496784\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356611; batch adversarial loss: 0.516743\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373238; batch adversarial loss: 0.573053\n",
      "epoch 93; iter: 0; batch classifier loss: 0.480157; batch adversarial loss: 0.542524\n",
      "epoch 94; iter: 0; batch classifier loss: 0.420244; batch adversarial loss: 0.569634\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395490; batch adversarial loss: 0.533939\n",
      "epoch 96; iter: 0; batch classifier loss: 0.441332; batch adversarial loss: 0.544232\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361371; batch adversarial loss: 0.524100\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438192; batch adversarial loss: 0.536967\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356718; batch adversarial loss: 0.564099\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392781; batch adversarial loss: 0.628753\n",
      "epoch 101; iter: 0; batch classifier loss: 0.312990; batch adversarial loss: 0.538740\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410356; batch adversarial loss: 0.516967\n",
      "epoch 103; iter: 0; batch classifier loss: 0.357586; batch adversarial loss: 0.544557\n",
      "epoch 104; iter: 0; batch classifier loss: 0.497571; batch adversarial loss: 0.481183\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373637; batch adversarial loss: 0.534069\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398791; batch adversarial loss: 0.634570\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382236; batch adversarial loss: 0.526023\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400753; batch adversarial loss: 0.571060\n",
      "epoch 109; iter: 0; batch classifier loss: 0.295902; batch adversarial loss: 0.451350\n",
      "epoch 110; iter: 0; batch classifier loss: 0.327491; batch adversarial loss: 0.526905\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368100; batch adversarial loss: 0.490628\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397950; batch adversarial loss: 0.522386\n",
      "epoch 113; iter: 0; batch classifier loss: 0.302802; batch adversarial loss: 0.519480\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377575; batch adversarial loss: 0.541208\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417119; batch adversarial loss: 0.590193\n",
      "epoch 116; iter: 0; batch classifier loss: 0.311783; batch adversarial loss: 0.457741\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337868; batch adversarial loss: 0.631046\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377974; batch adversarial loss: 0.607772\n",
      "epoch 119; iter: 0; batch classifier loss: 0.412109; batch adversarial loss: 0.497599\n",
      "epoch 120; iter: 0; batch classifier loss: 0.305426; batch adversarial loss: 0.460553\n",
      "epoch 121; iter: 0; batch classifier loss: 0.416533; batch adversarial loss: 0.525305\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381612; batch adversarial loss: 0.460862\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362645; batch adversarial loss: 0.518472\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375061; batch adversarial loss: 0.516556\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379828; batch adversarial loss: 0.561125\n",
      "epoch 126; iter: 0; batch classifier loss: 0.419519; batch adversarial loss: 0.544156\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329996; batch adversarial loss: 0.451269\n",
      "epoch 128; iter: 0; batch classifier loss: 0.317276; batch adversarial loss: 0.570082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.290841; batch adversarial loss: 0.526981\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375663; batch adversarial loss: 0.562215\n",
      "epoch 131; iter: 0; batch classifier loss: 0.376737; batch adversarial loss: 0.491637\n",
      "epoch 132; iter: 0; batch classifier loss: 0.362392; batch adversarial loss: 0.553274\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369583; batch adversarial loss: 0.504732\n",
      "epoch 134; iter: 0; batch classifier loss: 0.391757; batch adversarial loss: 0.527628\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352149; batch adversarial loss: 0.534029\n",
      "epoch 136; iter: 0; batch classifier loss: 0.418989; batch adversarial loss: 0.510271\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351485; batch adversarial loss: 0.498437\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340874; batch adversarial loss: 0.596191\n",
      "epoch 139; iter: 0; batch classifier loss: 0.450912; batch adversarial loss: 0.547121\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403220; batch adversarial loss: 0.543622\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323980; batch adversarial loss: 0.497868\n",
      "epoch 142; iter: 0; batch classifier loss: 0.456913; batch adversarial loss: 0.571330\n",
      "epoch 143; iter: 0; batch classifier loss: 0.502907; batch adversarial loss: 0.570662\n",
      "epoch 144; iter: 0; batch classifier loss: 0.353104; batch adversarial loss: 0.558686\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405339; batch adversarial loss: 0.479284\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376563; batch adversarial loss: 0.553234\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393176; batch adversarial loss: 0.562548\n",
      "epoch 148; iter: 0; batch classifier loss: 0.387561; batch adversarial loss: 0.554018\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377333; batch adversarial loss: 0.489277\n",
      "epoch 150; iter: 0; batch classifier loss: 0.374977; batch adversarial loss: 0.430093\n",
      "epoch 151; iter: 0; batch classifier loss: 0.312052; batch adversarial loss: 0.545527\n",
      "epoch 152; iter: 0; batch classifier loss: 0.407334; batch adversarial loss: 0.514161\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356216; batch adversarial loss: 0.534616\n",
      "epoch 154; iter: 0; batch classifier loss: 0.473768; batch adversarial loss: 0.509864\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377639; batch adversarial loss: 0.490110\n",
      "epoch 156; iter: 0; batch classifier loss: 0.300550; batch adversarial loss: 0.544318\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312187; batch adversarial loss: 0.532773\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345068; batch adversarial loss: 0.592947\n",
      "epoch 159; iter: 0; batch classifier loss: 0.402059; batch adversarial loss: 0.598163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368419; batch adversarial loss: 0.573096\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339007; batch adversarial loss: 0.579324\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364005; batch adversarial loss: 0.471637\n",
      "epoch 163; iter: 0; batch classifier loss: 0.283969; batch adversarial loss: 0.507525\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389156; batch adversarial loss: 0.618425\n",
      "epoch 165; iter: 0; batch classifier loss: 0.391640; batch adversarial loss: 0.579814\n",
      "epoch 166; iter: 0; batch classifier loss: 0.300553; batch adversarial loss: 0.535146\n",
      "epoch 167; iter: 0; batch classifier loss: 0.288416; batch adversarial loss: 0.579331\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357795; batch adversarial loss: 0.598544\n",
      "epoch 169; iter: 0; batch classifier loss: 0.306531; batch adversarial loss: 0.608783\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378131; batch adversarial loss: 0.573792\n",
      "epoch 171; iter: 0; batch classifier loss: 0.303942; batch adversarial loss: 0.579371\n",
      "epoch 172; iter: 0; batch classifier loss: 0.448879; batch adversarial loss: 0.571628\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359412; batch adversarial loss: 0.489856\n",
      "epoch 174; iter: 0; batch classifier loss: 0.319245; batch adversarial loss: 0.517782\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331737; batch adversarial loss: 0.624840\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347410; batch adversarial loss: 0.574380\n",
      "epoch 177; iter: 0; batch classifier loss: 0.283299; batch adversarial loss: 0.508045\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367351; batch adversarial loss: 0.514753\n",
      "epoch 179; iter: 0; batch classifier loss: 0.360966; batch adversarial loss: 0.601234\n",
      "epoch 180; iter: 0; batch classifier loss: 0.410519; batch adversarial loss: 0.573488\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379332; batch adversarial loss: 0.509465\n",
      "epoch 182; iter: 0; batch classifier loss: 0.469137; batch adversarial loss: 0.620766\n",
      "epoch 183; iter: 0; batch classifier loss: 0.418319; batch adversarial loss: 0.470488\n",
      "epoch 184; iter: 0; batch classifier loss: 0.290870; batch adversarial loss: 0.590217\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390212; batch adversarial loss: 0.655649\n",
      "epoch 186; iter: 0; batch classifier loss: 0.380364; batch adversarial loss: 0.562629\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313460; batch adversarial loss: 0.524265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.349258; batch adversarial loss: 0.469900\n",
      "epoch 189; iter: 0; batch classifier loss: 0.483544; batch adversarial loss: 0.662917\n",
      "epoch 190; iter: 0; batch classifier loss: 0.316120; batch adversarial loss: 0.515744\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319794; batch adversarial loss: 0.523299\n",
      "epoch 192; iter: 0; batch classifier loss: 0.437555; batch adversarial loss: 0.524696\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331103; batch adversarial loss: 0.572245\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407199; batch adversarial loss: 0.688220\n",
      "epoch 195; iter: 0; batch classifier loss: 0.364390; batch adversarial loss: 0.587700\n",
      "epoch 196; iter: 0; batch classifier loss: 0.386116; batch adversarial loss: 0.571347\n",
      "epoch 197; iter: 0; batch classifier loss: 0.407689; batch adversarial loss: 0.563157\n",
      "epoch 198; iter: 0; batch classifier loss: 0.391109; batch adversarial loss: 0.491004\n",
      "epoch 199; iter: 0; batch classifier loss: 0.358130; batch adversarial loss: 0.554821\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711009; batch adversarial loss: 0.652532\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619409; batch adversarial loss: 0.632694\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623476; batch adversarial loss: 0.653184\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581803; batch adversarial loss: 0.668035\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553709; batch adversarial loss: 0.681124\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580198; batch adversarial loss: 0.710602\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554288; batch adversarial loss: 0.634869\n",
      "epoch 7; iter: 0; batch classifier loss: 0.628078; batch adversarial loss: 0.595456\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583362; batch adversarial loss: 0.612844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582038; batch adversarial loss: 0.610502\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588251; batch adversarial loss: 0.590527\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550439; batch adversarial loss: 0.615075\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565392; batch adversarial loss: 0.613240\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539133; batch adversarial loss: 0.620844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.602749; batch adversarial loss: 0.570657\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504195; batch adversarial loss: 0.522158\n",
      "epoch 16; iter: 0; batch classifier loss: 0.618238; batch adversarial loss: 0.558378\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522108; batch adversarial loss: 0.548892\n",
      "epoch 18; iter: 0; batch classifier loss: 0.551688; batch adversarial loss: 0.587130\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471373; batch adversarial loss: 0.528168\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466464; batch adversarial loss: 0.518297\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508244; batch adversarial loss: 0.512386\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479822; batch adversarial loss: 0.596493\n",
      "epoch 23; iter: 0; batch classifier loss: 0.557285; batch adversarial loss: 0.550308\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480941; batch adversarial loss: 0.480849\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491759; batch adversarial loss: 0.537374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.517448; batch adversarial loss: 0.539027\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468091; batch adversarial loss: 0.601867\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491965; batch adversarial loss: 0.546094\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451730; batch adversarial loss: 0.532690\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513495; batch adversarial loss: 0.568154\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501071; batch adversarial loss: 0.512913\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504553; batch adversarial loss: 0.553270\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478612; batch adversarial loss: 0.535314\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414882; batch adversarial loss: 0.577694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455727; batch adversarial loss: 0.599834\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482669; batch adversarial loss: 0.546734\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427300; batch adversarial loss: 0.563856\n",
      "epoch 38; iter: 0; batch classifier loss: 0.387857; batch adversarial loss: 0.595817\n",
      "epoch 39; iter: 0; batch classifier loss: 0.515112; batch adversarial loss: 0.609407\n",
      "epoch 40; iter: 0; batch classifier loss: 0.482463; batch adversarial loss: 0.466875\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489018; batch adversarial loss: 0.595968\n",
      "epoch 42; iter: 0; batch classifier loss: 0.397719; batch adversarial loss: 0.566172\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400680; batch adversarial loss: 0.552609\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436527; batch adversarial loss: 0.545582\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364177; batch adversarial loss: 0.604170\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476256; batch adversarial loss: 0.591250\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490573; batch adversarial loss: 0.457061\n",
      "epoch 48; iter: 0; batch classifier loss: 0.462921; batch adversarial loss: 0.582251\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470676; batch adversarial loss: 0.571667\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406004; batch adversarial loss: 0.564004\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397069; batch adversarial loss: 0.489989\n",
      "epoch 52; iter: 0; batch classifier loss: 0.454004; batch adversarial loss: 0.535587\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400449; batch adversarial loss: 0.532855\n",
      "epoch 54; iter: 0; batch classifier loss: 0.548442; batch adversarial loss: 0.567273\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448632; batch adversarial loss: 0.551273\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449540; batch adversarial loss: 0.570255\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439214; batch adversarial loss: 0.578574\n",
      "epoch 58; iter: 0; batch classifier loss: 0.385916; batch adversarial loss: 0.556606\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476220; batch adversarial loss: 0.576659\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441686; batch adversarial loss: 0.543154\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435248; batch adversarial loss: 0.579632\n",
      "epoch 62; iter: 0; batch classifier loss: 0.368647; batch adversarial loss: 0.551220\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425028; batch adversarial loss: 0.523676\n",
      "epoch 64; iter: 0; batch classifier loss: 0.465503; batch adversarial loss: 0.554494\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407478; batch adversarial loss: 0.530376\n",
      "epoch 66; iter: 0; batch classifier loss: 0.337100; batch adversarial loss: 0.573270\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417048; batch adversarial loss: 0.534123\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438129; batch adversarial loss: 0.509672\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432263; batch adversarial loss: 0.553788\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410504; batch adversarial loss: 0.527589\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408954; batch adversarial loss: 0.542725\n",
      "epoch 72; iter: 0; batch classifier loss: 0.443549; batch adversarial loss: 0.517356\n",
      "epoch 73; iter: 0; batch classifier loss: 0.502851; batch adversarial loss: 0.567849\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452199; batch adversarial loss: 0.514536\n",
      "epoch 75; iter: 0; batch classifier loss: 0.459120; batch adversarial loss: 0.543801\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396723; batch adversarial loss: 0.500022\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392485; batch adversarial loss: 0.552926\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438188; batch adversarial loss: 0.563916\n",
      "epoch 79; iter: 0; batch classifier loss: 0.365028; batch adversarial loss: 0.557301\n",
      "epoch 80; iter: 0; batch classifier loss: 0.425422; batch adversarial loss: 0.530017\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410641; batch adversarial loss: 0.499005\n",
      "epoch 82; iter: 0; batch classifier loss: 0.426233; batch adversarial loss: 0.534350\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405198; batch adversarial loss: 0.542340\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404992; batch adversarial loss: 0.574563\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407020; batch adversarial loss: 0.544417\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358263; batch adversarial loss: 0.485611\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401951; batch adversarial loss: 0.545521\n",
      "epoch 88; iter: 0; batch classifier loss: 0.329272; batch adversarial loss: 0.527566\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433383; batch adversarial loss: 0.475127\n",
      "epoch 90; iter: 0; batch classifier loss: 0.323583; batch adversarial loss: 0.521654\n",
      "epoch 91; iter: 0; batch classifier loss: 0.425084; batch adversarial loss: 0.543223\n",
      "epoch 92; iter: 0; batch classifier loss: 0.334107; batch adversarial loss: 0.537453\n",
      "epoch 93; iter: 0; batch classifier loss: 0.395393; batch adversarial loss: 0.586715\n",
      "epoch 94; iter: 0; batch classifier loss: 0.463829; batch adversarial loss: 0.587840\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431501; batch adversarial loss: 0.576400\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350004; batch adversarial loss: 0.543976\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392805; batch adversarial loss: 0.490719\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389335; batch adversarial loss: 0.554439\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396407; batch adversarial loss: 0.527518\n",
      "epoch 100; iter: 0; batch classifier loss: 0.324338; batch adversarial loss: 0.526330\n",
      "epoch 101; iter: 0; batch classifier loss: 0.409026; batch adversarial loss: 0.579644\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369772; batch adversarial loss: 0.580225\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397763; batch adversarial loss: 0.509256\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363140; batch adversarial loss: 0.553926\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406674; batch adversarial loss: 0.508248\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370061; batch adversarial loss: 0.578059\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355420; batch adversarial loss: 0.526196\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348684; batch adversarial loss: 0.570648\n",
      "epoch 109; iter: 0; batch classifier loss: 0.350217; batch adversarial loss: 0.525747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.338064; batch adversarial loss: 0.509659\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372276; batch adversarial loss: 0.572001\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365965; batch adversarial loss: 0.508260\n",
      "epoch 113; iter: 0; batch classifier loss: 0.305122; batch adversarial loss: 0.501388\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401766; batch adversarial loss: 0.631471\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390281; batch adversarial loss: 0.516779\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406709; batch adversarial loss: 0.498835\n",
      "epoch 117; iter: 0; batch classifier loss: 0.314870; batch adversarial loss: 0.570704\n",
      "epoch 118; iter: 0; batch classifier loss: 0.407079; batch adversarial loss: 0.606607\n",
      "epoch 119; iter: 0; batch classifier loss: 0.469773; batch adversarial loss: 0.517171\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370557; batch adversarial loss: 0.471093\n",
      "epoch 121; iter: 0; batch classifier loss: 0.329062; batch adversarial loss: 0.527364\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385645; batch adversarial loss: 0.605316\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376993; batch adversarial loss: 0.471044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.433802; batch adversarial loss: 0.509981\n",
      "epoch 125; iter: 0; batch classifier loss: 0.407705; batch adversarial loss: 0.482339\n",
      "epoch 126; iter: 0; batch classifier loss: 0.435864; batch adversarial loss: 0.588513\n",
      "epoch 127; iter: 0; batch classifier loss: 0.462343; batch adversarial loss: 0.517569\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360608; batch adversarial loss: 0.526767\n",
      "epoch 129; iter: 0; batch classifier loss: 0.477207; batch adversarial loss: 0.535953\n",
      "epoch 130; iter: 0; batch classifier loss: 0.443677; batch adversarial loss: 0.573079\n",
      "epoch 131; iter: 0; batch classifier loss: 0.288661; batch adversarial loss: 0.571141\n",
      "epoch 132; iter: 0; batch classifier loss: 0.411158; batch adversarial loss: 0.556383\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347969; batch adversarial loss: 0.472602\n",
      "epoch 134; iter: 0; batch classifier loss: 0.456429; batch adversarial loss: 0.582458\n",
      "epoch 135; iter: 0; batch classifier loss: 0.374616; batch adversarial loss: 0.544779\n",
      "epoch 136; iter: 0; batch classifier loss: 0.415498; batch adversarial loss: 0.545091\n",
      "epoch 137; iter: 0; batch classifier loss: 0.360002; batch adversarial loss: 0.418617\n",
      "epoch 138; iter: 0; batch classifier loss: 0.314750; batch adversarial loss: 0.652322\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428747; batch adversarial loss: 0.474144\n",
      "epoch 140; iter: 0; batch classifier loss: 0.402813; batch adversarial loss: 0.510218\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400478; batch adversarial loss: 0.534786\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375099; batch adversarial loss: 0.544850\n",
      "epoch 143; iter: 0; batch classifier loss: 0.302070; batch adversarial loss: 0.625623\n",
      "epoch 144; iter: 0; batch classifier loss: 0.317634; batch adversarial loss: 0.579038\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331309; batch adversarial loss: 0.545377\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399188; batch adversarial loss: 0.601351\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394239; batch adversarial loss: 0.607152\n",
      "epoch 148; iter: 0; batch classifier loss: 0.355576; batch adversarial loss: 0.533830\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315315; batch adversarial loss: 0.517140\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350716; batch adversarial loss: 0.580475\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336493; batch adversarial loss: 0.626563\n",
      "epoch 152; iter: 0; batch classifier loss: 0.453221; batch adversarial loss: 0.545325\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389561; batch adversarial loss: 0.589024\n",
      "epoch 154; iter: 0; batch classifier loss: 0.401010; batch adversarial loss: 0.527559\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380408; batch adversarial loss: 0.561501\n",
      "epoch 156; iter: 0; batch classifier loss: 0.327786; batch adversarial loss: 0.571096\n",
      "epoch 157; iter: 0; batch classifier loss: 0.330073; batch adversarial loss: 0.509686\n",
      "epoch 158; iter: 0; batch classifier loss: 0.441812; batch adversarial loss: 0.635101\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363255; batch adversarial loss: 0.508174\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314648; batch adversarial loss: 0.615921\n",
      "epoch 161; iter: 0; batch classifier loss: 0.384884; batch adversarial loss: 0.572202\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382890; batch adversarial loss: 0.498895\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397056; batch adversarial loss: 0.545062\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378359; batch adversarial loss: 0.553908\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345140; batch adversarial loss: 0.524408\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378063; batch adversarial loss: 0.571354\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337092; batch adversarial loss: 0.482872\n",
      "epoch 168; iter: 0; batch classifier loss: 0.430960; batch adversarial loss: 0.534651\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353556; batch adversarial loss: 0.595917\n",
      "epoch 170; iter: 0; batch classifier loss: 0.434853; batch adversarial loss: 0.515775\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420082; batch adversarial loss: 0.552386\n",
      "epoch 172; iter: 0; batch classifier loss: 0.347242; batch adversarial loss: 0.606455\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315982; batch adversarial loss: 0.509020\n",
      "epoch 174; iter: 0; batch classifier loss: 0.332388; batch adversarial loss: 0.472601\n",
      "epoch 175; iter: 0; batch classifier loss: 0.294753; batch adversarial loss: 0.572924\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351358; batch adversarial loss: 0.555767\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318586; batch adversarial loss: 0.524939\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382414; batch adversarial loss: 0.498337\n",
      "epoch 179; iter: 0; batch classifier loss: 0.353829; batch adversarial loss: 0.636377\n",
      "epoch 180; iter: 0; batch classifier loss: 0.365522; batch adversarial loss: 0.472223\n",
      "epoch 181; iter: 0; batch classifier loss: 0.400902; batch adversarial loss: 0.607631\n",
      "epoch 182; iter: 0; batch classifier loss: 0.435349; batch adversarial loss: 0.571558\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355052; batch adversarial loss: 0.526621\n",
      "epoch 184; iter: 0; batch classifier loss: 0.459401; batch adversarial loss: 0.526934\n",
      "epoch 185; iter: 0; batch classifier loss: 0.339112; batch adversarial loss: 0.597853\n",
      "epoch 186; iter: 0; batch classifier loss: 0.339836; batch adversarial loss: 0.686417\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334803; batch adversarial loss: 0.472914\n",
      "epoch 188; iter: 0; batch classifier loss: 0.308662; batch adversarial loss: 0.606457\n",
      "epoch 189; iter: 0; batch classifier loss: 0.296877; batch adversarial loss: 0.543579\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332374; batch adversarial loss: 0.556138\n",
      "epoch 191; iter: 0; batch classifier loss: 0.271372; batch adversarial loss: 0.524929\n",
      "epoch 192; iter: 0; batch classifier loss: 0.299718; batch adversarial loss: 0.578474\n",
      "epoch 193; iter: 0; batch classifier loss: 0.436241; batch adversarial loss: 0.481209\n",
      "epoch 194; iter: 0; batch classifier loss: 0.456393; batch adversarial loss: 0.543633\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328937; batch adversarial loss: 0.609126\n",
      "epoch 196; iter: 0; batch classifier loss: 0.379087; batch adversarial loss: 0.562607\n",
      "epoch 197; iter: 0; batch classifier loss: 0.383466; batch adversarial loss: 0.535662\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372262; batch adversarial loss: 0.578549\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314462; batch adversarial loss: 0.590428\n",
      "epoch 0; iter: 0; batch classifier loss: 0.821463; batch adversarial loss: 0.613814\n",
      "epoch 1; iter: 0; batch classifier loss: 0.570042; batch adversarial loss: 0.634454\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582456; batch adversarial loss: 0.616019\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565122; batch adversarial loss: 0.621781\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558999; batch adversarial loss: 0.632545\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550009; batch adversarial loss: 0.576729\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559754; batch adversarial loss: 0.612360\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546401; batch adversarial loss: 0.560954\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552352; batch adversarial loss: 0.598043\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471828; batch adversarial loss: 0.511188\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552125; batch adversarial loss: 0.569329\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536028; batch adversarial loss: 0.520928\n",
      "epoch 12; iter: 0; batch classifier loss: 0.546716; batch adversarial loss: 0.557513\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524088; batch adversarial loss: 0.580261\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514113; batch adversarial loss: 0.566799\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534149; batch adversarial loss: 0.576244\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545857; batch adversarial loss: 0.575399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516891; batch adversarial loss: 0.575329\n",
      "epoch 18; iter: 0; batch classifier loss: 0.459841; batch adversarial loss: 0.582623\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517367; batch adversarial loss: 0.571629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.472002; batch adversarial loss: 0.474431\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481271; batch adversarial loss: 0.479344\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443535; batch adversarial loss: 0.548586\n",
      "epoch 23; iter: 0; batch classifier loss: 0.589407; batch adversarial loss: 0.587286\n",
      "epoch 24; iter: 0; batch classifier loss: 0.542407; batch adversarial loss: 0.568681\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494841; batch adversarial loss: 0.560822\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513068; batch adversarial loss: 0.569366\n",
      "epoch 27; iter: 0; batch classifier loss: 0.556098; batch adversarial loss: 0.475222\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496865; batch adversarial loss: 0.578416\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492420; batch adversarial loss: 0.528425\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486469; batch adversarial loss: 0.571752\n",
      "epoch 31; iter: 0; batch classifier loss: 0.508819; batch adversarial loss: 0.528233\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491148; batch adversarial loss: 0.600114\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475703; batch adversarial loss: 0.499834\n",
      "epoch 34; iter: 0; batch classifier loss: 0.407298; batch adversarial loss: 0.518503\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472938; batch adversarial loss: 0.608960\n",
      "epoch 36; iter: 0; batch classifier loss: 0.384850; batch adversarial loss: 0.529441\n",
      "epoch 37; iter: 0; batch classifier loss: 0.520266; batch adversarial loss: 0.544704\n",
      "epoch 38; iter: 0; batch classifier loss: 0.549949; batch adversarial loss: 0.583236\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481281; batch adversarial loss: 0.516163\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497395; batch adversarial loss: 0.563321\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473925; batch adversarial loss: 0.600499\n",
      "epoch 42; iter: 0; batch classifier loss: 0.399602; batch adversarial loss: 0.543245\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480905; batch adversarial loss: 0.479892\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462266; batch adversarial loss: 0.571914\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443904; batch adversarial loss: 0.490213\n",
      "epoch 46; iter: 0; batch classifier loss: 0.322247; batch adversarial loss: 0.629377\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405861; batch adversarial loss: 0.489561\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400177; batch adversarial loss: 0.564033\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431513; batch adversarial loss: 0.535453\n",
      "epoch 50; iter: 0; batch classifier loss: 0.399364; batch adversarial loss: 0.507791\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435802; batch adversarial loss: 0.505137\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406956; batch adversarial loss: 0.509368\n",
      "epoch 53; iter: 0; batch classifier loss: 0.409654; batch adversarial loss: 0.460781\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425775; batch adversarial loss: 0.535796\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412458; batch adversarial loss: 0.593178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426491; batch adversarial loss: 0.571644\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468794; batch adversarial loss: 0.534935\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465807; batch adversarial loss: 0.535789\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408055; batch adversarial loss: 0.507984\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356419; batch adversarial loss: 0.582009\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424962; batch adversarial loss: 0.552972\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440092; batch adversarial loss: 0.582093\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433831; batch adversarial loss: 0.580909\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412133; batch adversarial loss: 0.599566\n",
      "epoch 65; iter: 0; batch classifier loss: 0.359603; batch adversarial loss: 0.581230\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403261; batch adversarial loss: 0.571785\n",
      "epoch 67; iter: 0; batch classifier loss: 0.479589; batch adversarial loss: 0.507391\n",
      "epoch 68; iter: 0; batch classifier loss: 0.436064; batch adversarial loss: 0.525070\n",
      "epoch 69; iter: 0; batch classifier loss: 0.473828; batch adversarial loss: 0.664614\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416876; batch adversarial loss: 0.496378\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398383; batch adversarial loss: 0.488450\n",
      "epoch 72; iter: 0; batch classifier loss: 0.327922; batch adversarial loss: 0.516705\n",
      "epoch 73; iter: 0; batch classifier loss: 0.482354; batch adversarial loss: 0.498018\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457852; batch adversarial loss: 0.524878\n",
      "epoch 75; iter: 0; batch classifier loss: 0.500570; batch adversarial loss: 0.516886\n",
      "epoch 76; iter: 0; batch classifier loss: 0.470808; batch adversarial loss: 0.552949\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385599; batch adversarial loss: 0.592438\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387241; batch adversarial loss: 0.496121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415098; batch adversarial loss: 0.591205\n",
      "epoch 80; iter: 0; batch classifier loss: 0.450850; batch adversarial loss: 0.562184\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409814; batch adversarial loss: 0.525709\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414230; batch adversarial loss: 0.498366\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394330; batch adversarial loss: 0.537355\n",
      "epoch 84; iter: 0; batch classifier loss: 0.324916; batch adversarial loss: 0.554314\n",
      "epoch 85; iter: 0; batch classifier loss: 0.426515; batch adversarial loss: 0.553795\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371959; batch adversarial loss: 0.535680\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394629; batch adversarial loss: 0.505007\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375343; batch adversarial loss: 0.545308\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405612; batch adversarial loss: 0.589755\n",
      "epoch 90; iter: 0; batch classifier loss: 0.382379; batch adversarial loss: 0.598324\n",
      "epoch 91; iter: 0; batch classifier loss: 0.415711; batch adversarial loss: 0.638219\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391978; batch adversarial loss: 0.524194\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378791; batch adversarial loss: 0.516072\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375116; batch adversarial loss: 0.458947\n",
      "epoch 95; iter: 0; batch classifier loss: 0.360189; batch adversarial loss: 0.513138\n",
      "epoch 96; iter: 0; batch classifier loss: 0.340397; batch adversarial loss: 0.565862\n",
      "epoch 97; iter: 0; batch classifier loss: 0.319469; batch adversarial loss: 0.562839\n",
      "epoch 98; iter: 0; batch classifier loss: 0.479286; batch adversarial loss: 0.534086\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382675; batch adversarial loss: 0.505750\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384847; batch adversarial loss: 0.509989\n",
      "epoch 101; iter: 0; batch classifier loss: 0.325321; batch adversarial loss: 0.544317\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372813; batch adversarial loss: 0.551752\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369708; batch adversarial loss: 0.536900\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365364; batch adversarial loss: 0.544459\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384796; batch adversarial loss: 0.507937\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365977; batch adversarial loss: 0.451520\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407963; batch adversarial loss: 0.515661\n",
      "epoch 108; iter: 0; batch classifier loss: 0.510682; batch adversarial loss: 0.532843\n",
      "epoch 109; iter: 0; batch classifier loss: 0.349148; batch adversarial loss: 0.516568\n",
      "epoch 110; iter: 0; batch classifier loss: 0.503502; batch adversarial loss: 0.543137\n",
      "epoch 111; iter: 0; batch classifier loss: 0.377907; batch adversarial loss: 0.488804\n",
      "epoch 112; iter: 0; batch classifier loss: 0.390176; batch adversarial loss: 0.638654\n",
      "epoch 113; iter: 0; batch classifier loss: 0.412093; batch adversarial loss: 0.581761\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391341; batch adversarial loss: 0.526254\n",
      "epoch 115; iter: 0; batch classifier loss: 0.323256; batch adversarial loss: 0.581714\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373700; batch adversarial loss: 0.516257\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375096; batch adversarial loss: 0.525987\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355785; batch adversarial loss: 0.507419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.412748; batch adversarial loss: 0.553190\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373839; batch adversarial loss: 0.498724\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395119; batch adversarial loss: 0.507293\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395173; batch adversarial loss: 0.551700\n",
      "epoch 123; iter: 0; batch classifier loss: 0.435392; batch adversarial loss: 0.542270\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361670; batch adversarial loss: 0.562526\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342262; batch adversarial loss: 0.587513\n",
      "epoch 126; iter: 0; batch classifier loss: 0.416400; batch adversarial loss: 0.601709\n",
      "epoch 127; iter: 0; batch classifier loss: 0.345799; batch adversarial loss: 0.489943\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357273; batch adversarial loss: 0.581579\n",
      "epoch 129; iter: 0; batch classifier loss: 0.387316; batch adversarial loss: 0.553725\n",
      "epoch 130; iter: 0; batch classifier loss: 0.330647; batch adversarial loss: 0.544302\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398096; batch adversarial loss: 0.553732\n",
      "epoch 132; iter: 0; batch classifier loss: 0.409523; batch adversarial loss: 0.535392\n",
      "epoch 133; iter: 0; batch classifier loss: 0.322158; batch adversarial loss: 0.498075\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337064; batch adversarial loss: 0.554418\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346541; batch adversarial loss: 0.637564\n",
      "epoch 136; iter: 0; batch classifier loss: 0.460212; batch adversarial loss: 0.581227\n",
      "epoch 137; iter: 0; batch classifier loss: 0.411264; batch adversarial loss: 0.609864\n",
      "epoch 138; iter: 0; batch classifier loss: 0.374527; batch adversarial loss: 0.544568\n",
      "epoch 139; iter: 0; batch classifier loss: 0.468003; batch adversarial loss: 0.590603\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338017; batch adversarial loss: 0.498240\n",
      "epoch 141; iter: 0; batch classifier loss: 0.373707; batch adversarial loss: 0.544811\n",
      "epoch 142; iter: 0; batch classifier loss: 0.452342; batch adversarial loss: 0.581585\n",
      "epoch 143; iter: 0; batch classifier loss: 0.403148; batch adversarial loss: 0.535390\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437266; batch adversarial loss: 0.572268\n",
      "epoch 145; iter: 0; batch classifier loss: 0.275576; batch adversarial loss: 0.544373\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360149; batch adversarial loss: 0.592095\n",
      "epoch 147; iter: 0; batch classifier loss: 0.420036; batch adversarial loss: 0.497626\n",
      "epoch 148; iter: 0; batch classifier loss: 0.309292; batch adversarial loss: 0.572067\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402889; batch adversarial loss: 0.553252\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390877; batch adversarial loss: 0.479226\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409543; batch adversarial loss: 0.582741\n",
      "epoch 152; iter: 0; batch classifier loss: 0.429173; batch adversarial loss: 0.504108\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333931; batch adversarial loss: 0.470036\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321619; batch adversarial loss: 0.524642\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325231; batch adversarial loss: 0.564825\n",
      "epoch 156; iter: 0; batch classifier loss: 0.318841; batch adversarial loss: 0.546320\n",
      "epoch 157; iter: 0; batch classifier loss: 0.395384; batch adversarial loss: 0.517299\n",
      "epoch 158; iter: 0; batch classifier loss: 0.439267; batch adversarial loss: 0.480109\n",
      "epoch 159; iter: 0; batch classifier loss: 0.449933; batch adversarial loss: 0.581918\n",
      "epoch 160; iter: 0; batch classifier loss: 0.316848; batch adversarial loss: 0.516625\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362027; batch adversarial loss: 0.535714\n",
      "epoch 162; iter: 0; batch classifier loss: 0.407872; batch adversarial loss: 0.516999\n",
      "epoch 163; iter: 0; batch classifier loss: 0.438634; batch adversarial loss: 0.498856\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354974; batch adversarial loss: 0.415717\n",
      "epoch 165; iter: 0; batch classifier loss: 0.419165; batch adversarial loss: 0.517660\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350223; batch adversarial loss: 0.553643\n",
      "epoch 167; iter: 0; batch classifier loss: 0.411723; batch adversarial loss: 0.608351\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330941; batch adversarial loss: 0.489851\n",
      "epoch 169; iter: 0; batch classifier loss: 0.389739; batch adversarial loss: 0.489233\n",
      "epoch 170; iter: 0; batch classifier loss: 0.242449; batch adversarial loss: 0.618574\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384853; batch adversarial loss: 0.562870\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387488; batch adversarial loss: 0.563447\n",
      "epoch 173; iter: 0; batch classifier loss: 0.417253; batch adversarial loss: 0.526003\n",
      "epoch 174; iter: 0; batch classifier loss: 0.398156; batch adversarial loss: 0.591081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357527; batch adversarial loss: 0.535041\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374018; batch adversarial loss: 0.507559\n",
      "epoch 177; iter: 0; batch classifier loss: 0.276715; batch adversarial loss: 0.478790\n",
      "epoch 178; iter: 0; batch classifier loss: 0.366459; batch adversarial loss: 0.506785\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362230; batch adversarial loss: 0.488555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.469889; batch adversarial loss: 0.470518\n",
      "epoch 181; iter: 0; batch classifier loss: 0.295870; batch adversarial loss: 0.563497\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402362; batch adversarial loss: 0.497852\n",
      "epoch 183; iter: 0; batch classifier loss: 0.243209; batch adversarial loss: 0.544540\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384245; batch adversarial loss: 0.544297\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384009; batch adversarial loss: 0.582303\n",
      "epoch 186; iter: 0; batch classifier loss: 0.400548; batch adversarial loss: 0.525970\n",
      "epoch 187; iter: 0; batch classifier loss: 0.392939; batch adversarial loss: 0.488811\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348279; batch adversarial loss: 0.582006\n",
      "epoch 189; iter: 0; batch classifier loss: 0.415339; batch adversarial loss: 0.488371\n",
      "epoch 190; iter: 0; batch classifier loss: 0.273273; batch adversarial loss: 0.497510\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330426; batch adversarial loss: 0.562841\n",
      "epoch 192; iter: 0; batch classifier loss: 0.424952; batch adversarial loss: 0.544514\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356257; batch adversarial loss: 0.553813\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340978; batch adversarial loss: 0.516686\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365087; batch adversarial loss: 0.600029\n",
      "epoch 196; iter: 0; batch classifier loss: 0.325877; batch adversarial loss: 0.498071\n",
      "epoch 197; iter: 0; batch classifier loss: 0.408878; batch adversarial loss: 0.497833\n",
      "epoch 198; iter: 0; batch classifier loss: 0.396185; batch adversarial loss: 0.525641\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357890; batch adversarial loss: 0.619988\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699303; batch adversarial loss: 0.604813\n",
      "epoch 1; iter: 0; batch classifier loss: 0.576895; batch adversarial loss: 0.661238\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604779; batch adversarial loss: 0.649211\n",
      "epoch 3; iter: 0; batch classifier loss: 0.634483; batch adversarial loss: 0.627805\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581547; batch adversarial loss: 0.667425\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567685; batch adversarial loss: 0.593768\n",
      "epoch 6; iter: 0; batch classifier loss: 0.576804; batch adversarial loss: 0.573811\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556028; batch adversarial loss: 0.570149\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516006; batch adversarial loss: 0.557328\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521781; batch adversarial loss: 0.581924\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575563; batch adversarial loss: 0.596444\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569129; batch adversarial loss: 0.624194\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510273; batch adversarial loss: 0.549587\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457778; batch adversarial loss: 0.521840\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553071; batch adversarial loss: 0.553117\n",
      "epoch 15; iter: 0; batch classifier loss: 0.585744; batch adversarial loss: 0.535466\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445659; batch adversarial loss: 0.565428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.550817; batch adversarial loss: 0.566296\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556999; batch adversarial loss: 0.584512\n",
      "epoch 19; iter: 0; batch classifier loss: 0.587211; batch adversarial loss: 0.571112\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490330; batch adversarial loss: 0.533217\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460566; batch adversarial loss: 0.583369\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481721; batch adversarial loss: 0.537408\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449538; batch adversarial loss: 0.488681\n",
      "epoch 24; iter: 0; batch classifier loss: 0.553563; batch adversarial loss: 0.517812\n",
      "epoch 25; iter: 0; batch classifier loss: 0.486839; batch adversarial loss: 0.506385\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477169; batch adversarial loss: 0.521773\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491167; batch adversarial loss: 0.551350\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453580; batch adversarial loss: 0.475156\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472437; batch adversarial loss: 0.472524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474979; batch adversarial loss: 0.582016\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449461; batch adversarial loss: 0.475376\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417481; batch adversarial loss: 0.536730\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466334; batch adversarial loss: 0.522988\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501895; batch adversarial loss: 0.531643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469687; batch adversarial loss: 0.517861\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471823; batch adversarial loss: 0.569936\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422987; batch adversarial loss: 0.507923\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436044; batch adversarial loss: 0.537119\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457965; batch adversarial loss: 0.645123\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437990; batch adversarial loss: 0.515135\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448554; batch adversarial loss: 0.498090\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466867; batch adversarial loss: 0.545636\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390827; batch adversarial loss: 0.550080\n",
      "epoch 44; iter: 0; batch classifier loss: 0.543179; batch adversarial loss: 0.506829\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434420; batch adversarial loss: 0.464959\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396306; batch adversarial loss: 0.580416\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459609; batch adversarial loss: 0.584490\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397946; batch adversarial loss: 0.453506\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503834; batch adversarial loss: 0.581774\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455535; batch adversarial loss: 0.564045\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438969; batch adversarial loss: 0.553759\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448905; batch adversarial loss: 0.497131\n",
      "epoch 53; iter: 0; batch classifier loss: 0.435745; batch adversarial loss: 0.497726\n",
      "epoch 54; iter: 0; batch classifier loss: 0.401042; batch adversarial loss: 0.591334\n",
      "epoch 55; iter: 0; batch classifier loss: 0.352111; batch adversarial loss: 0.522127\n",
      "epoch 56; iter: 0; batch classifier loss: 0.370514; batch adversarial loss: 0.562944\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393474; batch adversarial loss: 0.552883\n",
      "epoch 58; iter: 0; batch classifier loss: 0.473794; batch adversarial loss: 0.488950\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407276; batch adversarial loss: 0.564302\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445707; batch adversarial loss: 0.562624\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407686; batch adversarial loss: 0.534114\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414872; batch adversarial loss: 0.532683\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426958; batch adversarial loss: 0.517764\n",
      "epoch 64; iter: 0; batch classifier loss: 0.368139; batch adversarial loss: 0.598646\n",
      "epoch 65; iter: 0; batch classifier loss: 0.354454; batch adversarial loss: 0.497148\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443370; batch adversarial loss: 0.555352\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406845; batch adversarial loss: 0.523677\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402678; batch adversarial loss: 0.509101\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425287; batch adversarial loss: 0.590788\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387193; batch adversarial loss: 0.519619\n",
      "epoch 71; iter: 0; batch classifier loss: 0.382391; batch adversarial loss: 0.519833\n",
      "epoch 72; iter: 0; batch classifier loss: 0.482907; batch adversarial loss: 0.470482\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373519; batch adversarial loss: 0.515168\n",
      "epoch 74; iter: 0; batch classifier loss: 0.474528; batch adversarial loss: 0.626761\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344407; batch adversarial loss: 0.601342\n",
      "epoch 76; iter: 0; batch classifier loss: 0.353834; batch adversarial loss: 0.536058\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424220; batch adversarial loss: 0.507949\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417164; batch adversarial loss: 0.535960\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382140; batch adversarial loss: 0.534591\n",
      "epoch 80; iter: 0; batch classifier loss: 0.464606; batch adversarial loss: 0.542456\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390379; batch adversarial loss: 0.500430\n",
      "epoch 82; iter: 0; batch classifier loss: 0.355801; batch adversarial loss: 0.618849\n",
      "epoch 83; iter: 0; batch classifier loss: 0.431488; batch adversarial loss: 0.551930\n",
      "epoch 84; iter: 0; batch classifier loss: 0.417949; batch adversarial loss: 0.506982\n",
      "epoch 85; iter: 0; batch classifier loss: 0.354874; batch adversarial loss: 0.544327\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397486; batch adversarial loss: 0.646183\n",
      "epoch 87; iter: 0; batch classifier loss: 0.338727; batch adversarial loss: 0.542217\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365936; batch adversarial loss: 0.516263\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432374; batch adversarial loss: 0.471269\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394335; batch adversarial loss: 0.460674\n",
      "epoch 91; iter: 0; batch classifier loss: 0.467166; batch adversarial loss: 0.589606\n",
      "epoch 92; iter: 0; batch classifier loss: 0.476693; batch adversarial loss: 0.582055\n",
      "epoch 93; iter: 0; batch classifier loss: 0.444962; batch adversarial loss: 0.555013\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431796; batch adversarial loss: 0.543838\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378515; batch adversarial loss: 0.582874\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399491; batch adversarial loss: 0.544442\n",
      "epoch 97; iter: 0; batch classifier loss: 0.459012; batch adversarial loss: 0.563659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.360532; batch adversarial loss: 0.516431\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356414; batch adversarial loss: 0.498827\n",
      "epoch 100; iter: 0; batch classifier loss: 0.307034; batch adversarial loss: 0.534920\n",
      "epoch 101; iter: 0; batch classifier loss: 0.448916; batch adversarial loss: 0.617932\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399455; batch adversarial loss: 0.469545\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367436; batch adversarial loss: 0.572819\n",
      "epoch 104; iter: 0; batch classifier loss: 0.455352; batch adversarial loss: 0.534556\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371718; batch adversarial loss: 0.515682\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335315; batch adversarial loss: 0.570214\n",
      "epoch 107; iter: 0; batch classifier loss: 0.408378; batch adversarial loss: 0.581234\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398989; batch adversarial loss: 0.563156\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421942; batch adversarial loss: 0.554737\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401715; batch adversarial loss: 0.590398\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344543; batch adversarial loss: 0.581476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.440153; batch adversarial loss: 0.526274\n",
      "epoch 113; iter: 0; batch classifier loss: 0.403384; batch adversarial loss: 0.572480\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340871; batch adversarial loss: 0.450868\n",
      "epoch 115; iter: 0; batch classifier loss: 0.392369; batch adversarial loss: 0.499224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.367139; batch adversarial loss: 0.539079\n",
      "epoch 117; iter: 0; batch classifier loss: 0.311316; batch adversarial loss: 0.543308\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358497; batch adversarial loss: 0.628778\n",
      "epoch 119; iter: 0; batch classifier loss: 0.327522; batch adversarial loss: 0.442636\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422975; batch adversarial loss: 0.552318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.457470; batch adversarial loss: 0.554714\n",
      "epoch 122; iter: 0; batch classifier loss: 0.329955; batch adversarial loss: 0.581087\n",
      "epoch 123; iter: 0; batch classifier loss: 0.283048; batch adversarial loss: 0.554984\n",
      "epoch 124; iter: 0; batch classifier loss: 0.479070; batch adversarial loss: 0.498213\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408409; batch adversarial loss: 0.582292\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402762; batch adversarial loss: 0.442473\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380665; batch adversarial loss: 0.590080\n",
      "epoch 128; iter: 0; batch classifier loss: 0.303643; batch adversarial loss: 0.556144\n",
      "epoch 129; iter: 0; batch classifier loss: 0.323612; batch adversarial loss: 0.506789\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340904; batch adversarial loss: 0.555229\n",
      "epoch 131; iter: 0; batch classifier loss: 0.354094; batch adversarial loss: 0.552755\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333135; batch adversarial loss: 0.554261\n",
      "epoch 133; iter: 0; batch classifier loss: 0.327387; batch adversarial loss: 0.591420\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401703; batch adversarial loss: 0.479667\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385398; batch adversarial loss: 0.489285\n",
      "epoch 136; iter: 0; batch classifier loss: 0.374963; batch adversarial loss: 0.553853\n",
      "epoch 137; iter: 0; batch classifier loss: 0.464812; batch adversarial loss: 0.600860\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411912; batch adversarial loss: 0.543741\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379936; batch adversarial loss: 0.619116\n",
      "epoch 140; iter: 0; batch classifier loss: 0.421955; batch adversarial loss: 0.552181\n",
      "epoch 141; iter: 0; batch classifier loss: 0.413109; batch adversarial loss: 0.442481\n",
      "epoch 142; iter: 0; batch classifier loss: 0.265581; batch adversarial loss: 0.554075\n",
      "epoch 143; iter: 0; batch classifier loss: 0.439554; batch adversarial loss: 0.508426\n",
      "epoch 144; iter: 0; batch classifier loss: 0.328161; batch adversarial loss: 0.553229\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335021; batch adversarial loss: 0.460962\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416402; batch adversarial loss: 0.490420\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342794; batch adversarial loss: 0.479126\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303075; batch adversarial loss: 0.617220\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376458; batch adversarial loss: 0.627276\n",
      "epoch 150; iter: 0; batch classifier loss: 0.347763; batch adversarial loss: 0.546435\n",
      "epoch 151; iter: 0; batch classifier loss: 0.464522; batch adversarial loss: 0.552212\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323692; batch adversarial loss: 0.506833\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354294; batch adversarial loss: 0.526154\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340418; batch adversarial loss: 0.617724\n",
      "epoch 155; iter: 0; batch classifier loss: 0.404397; batch adversarial loss: 0.515365\n",
      "epoch 156; iter: 0; batch classifier loss: 0.326689; batch adversarial loss: 0.535771\n",
      "epoch 157; iter: 0; batch classifier loss: 0.332172; batch adversarial loss: 0.564342\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323146; batch adversarial loss: 0.572676\n",
      "epoch 159; iter: 0; batch classifier loss: 0.381004; batch adversarial loss: 0.555526\n",
      "epoch 160; iter: 0; batch classifier loss: 0.331395; batch adversarial loss: 0.507969\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347796; batch adversarial loss: 0.469161\n",
      "epoch 162; iter: 0; batch classifier loss: 0.444077; batch adversarial loss: 0.556197\n",
      "epoch 163; iter: 0; batch classifier loss: 0.360873; batch adversarial loss: 0.562849\n",
      "epoch 164; iter: 0; batch classifier loss: 0.420227; batch adversarial loss: 0.666725\n",
      "epoch 165; iter: 0; batch classifier loss: 0.436321; batch adversarial loss: 0.443863\n",
      "epoch 166; iter: 0; batch classifier loss: 0.400604; batch adversarial loss: 0.488470\n",
      "epoch 167; iter: 0; batch classifier loss: 0.313723; batch adversarial loss: 0.517893\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341092; batch adversarial loss: 0.497321\n",
      "epoch 169; iter: 0; batch classifier loss: 0.398625; batch adversarial loss: 0.479885\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383072; batch adversarial loss: 0.544942\n",
      "epoch 171; iter: 0; batch classifier loss: 0.360683; batch adversarial loss: 0.561752\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377265; batch adversarial loss: 0.580205\n",
      "epoch 173; iter: 0; batch classifier loss: 0.332254; batch adversarial loss: 0.543636\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375054; batch adversarial loss: 0.564066\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357021; batch adversarial loss: 0.619250\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348876; batch adversarial loss: 0.509713\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344319; batch adversarial loss: 0.534679\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323850; batch adversarial loss: 0.665147\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406689; batch adversarial loss: 0.589734\n",
      "epoch 180; iter: 0; batch classifier loss: 0.432040; batch adversarial loss: 0.507038\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395481; batch adversarial loss: 0.536116\n",
      "epoch 182; iter: 0; batch classifier loss: 0.394279; batch adversarial loss: 0.563851\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337764; batch adversarial loss: 0.555025\n",
      "epoch 184; iter: 0; batch classifier loss: 0.286218; batch adversarial loss: 0.478252\n",
      "epoch 185; iter: 0; batch classifier loss: 0.296103; batch adversarial loss: 0.507297\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346283; batch adversarial loss: 0.506304\n",
      "epoch 187; iter: 0; batch classifier loss: 0.386246; batch adversarial loss: 0.525303\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375054; batch adversarial loss: 0.537029\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375559; batch adversarial loss: 0.469306\n",
      "epoch 190; iter: 0; batch classifier loss: 0.316117; batch adversarial loss: 0.565010\n",
      "epoch 191; iter: 0; batch classifier loss: 0.257851; batch adversarial loss: 0.487992\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359357; batch adversarial loss: 0.534751\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320527; batch adversarial loss: 0.517333\n",
      "epoch 194; iter: 0; batch classifier loss: 0.346133; batch adversarial loss: 0.610615\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382981; batch adversarial loss: 0.592557\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346427; batch adversarial loss: 0.526832\n",
      "epoch 197; iter: 0; batch classifier loss: 0.408620; batch adversarial loss: 0.581719\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382668; batch adversarial loss: 0.582299\n",
      "epoch 199; iter: 0; batch classifier loss: 0.375891; batch adversarial loss: 0.506316\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699745; batch adversarial loss: 0.704607\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603355; batch adversarial loss: 0.678260\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590276; batch adversarial loss: 0.666689\n",
      "epoch 3; iter: 0; batch classifier loss: 0.518388; batch adversarial loss: 0.611668\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566633; batch adversarial loss: 0.597145\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589157; batch adversarial loss: 0.605686\n",
      "epoch 6; iter: 0; batch classifier loss: 0.485555; batch adversarial loss: 0.621159\n",
      "epoch 7; iter: 0; batch classifier loss: 0.511513; batch adversarial loss: 0.618113\n",
      "epoch 8; iter: 0; batch classifier loss: 0.629415; batch adversarial loss: 0.580559\n",
      "epoch 9; iter: 0; batch classifier loss: 0.581005; batch adversarial loss: 0.590343\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526451; batch adversarial loss: 0.612779\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470518; batch adversarial loss: 0.588008\n",
      "epoch 12; iter: 0; batch classifier loss: 0.456459; batch adversarial loss: 0.593487\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505998; batch adversarial loss: 0.500674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.514815; batch adversarial loss: 0.526583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454216; batch adversarial loss: 0.620421\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477864; batch adversarial loss: 0.555359\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503201; batch adversarial loss: 0.559532\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472061; batch adversarial loss: 0.616136\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508932; batch adversarial loss: 0.542891\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490768; batch adversarial loss: 0.528187\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508789; batch adversarial loss: 0.567548\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503174; batch adversarial loss: 0.550452\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481933; batch adversarial loss: 0.526302\n",
      "epoch 24; iter: 0; batch classifier loss: 0.544140; batch adversarial loss: 0.604150\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451303; batch adversarial loss: 0.572178\n",
      "epoch 26; iter: 0; batch classifier loss: 0.540686; batch adversarial loss: 0.586458\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472239; batch adversarial loss: 0.465288\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478075; batch adversarial loss: 0.574354\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484821; batch adversarial loss: 0.635393\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469401; batch adversarial loss: 0.543826\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459499; batch adversarial loss: 0.568234\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506863; batch adversarial loss: 0.566604\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453023; batch adversarial loss: 0.561154\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350151; batch adversarial loss: 0.597753\n",
      "epoch 35; iter: 0; batch classifier loss: 0.577195; batch adversarial loss: 0.545813\n",
      "epoch 36; iter: 0; batch classifier loss: 0.411963; batch adversarial loss: 0.582773\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481141; batch adversarial loss: 0.476114\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431984; batch adversarial loss: 0.474600\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446652; batch adversarial loss: 0.579673\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419456; batch adversarial loss: 0.544911\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432068; batch adversarial loss: 0.561131\n",
      "epoch 42; iter: 0; batch classifier loss: 0.530105; batch adversarial loss: 0.580320\n",
      "epoch 43; iter: 0; batch classifier loss: 0.372245; batch adversarial loss: 0.599802\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400607; batch adversarial loss: 0.569146\n",
      "epoch 45; iter: 0; batch classifier loss: 0.552586; batch adversarial loss: 0.597829\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419966; batch adversarial loss: 0.536181\n",
      "epoch 47; iter: 0; batch classifier loss: 0.577811; batch adversarial loss: 0.552602\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399407; batch adversarial loss: 0.536569\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423222; batch adversarial loss: 0.658387\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389279; batch adversarial loss: 0.518767\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438587; batch adversarial loss: 0.509273\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400098; batch adversarial loss: 0.535347\n",
      "epoch 53; iter: 0; batch classifier loss: 0.398795; batch adversarial loss: 0.491470\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414194; batch adversarial loss: 0.509127\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378659; batch adversarial loss: 0.568942\n",
      "epoch 56; iter: 0; batch classifier loss: 0.503220; batch adversarial loss: 0.552342\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435150; batch adversarial loss: 0.510293\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464293; batch adversarial loss: 0.533421\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402535; batch adversarial loss: 0.560624\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420486; batch adversarial loss: 0.510056\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422663; batch adversarial loss: 0.558569\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390562; batch adversarial loss: 0.589313\n",
      "epoch 63; iter: 0; batch classifier loss: 0.477164; batch adversarial loss: 0.640710\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405387; batch adversarial loss: 0.586166\n",
      "epoch 65; iter: 0; batch classifier loss: 0.391695; batch adversarial loss: 0.507706\n",
      "epoch 66; iter: 0; batch classifier loss: 0.480752; batch adversarial loss: 0.619563\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388079; batch adversarial loss: 0.498241\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392518; batch adversarial loss: 0.516994\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359035; batch adversarial loss: 0.470641\n",
      "epoch 70; iter: 0; batch classifier loss: 0.479481; batch adversarial loss: 0.434116\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446614; batch adversarial loss: 0.535391\n",
      "epoch 72; iter: 0; batch classifier loss: 0.464547; batch adversarial loss: 0.489232\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417670; batch adversarial loss: 0.526051\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417084; batch adversarial loss: 0.490167\n",
      "epoch 75; iter: 0; batch classifier loss: 0.406671; batch adversarial loss: 0.598283\n",
      "epoch 76; iter: 0; batch classifier loss: 0.434633; batch adversarial loss: 0.517108\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424155; batch adversarial loss: 0.544448\n",
      "epoch 78; iter: 0; batch classifier loss: 0.468292; batch adversarial loss: 0.526558\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429689; batch adversarial loss: 0.490529\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375194; batch adversarial loss: 0.562493\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381511; batch adversarial loss: 0.527041\n",
      "epoch 82; iter: 0; batch classifier loss: 0.349550; batch adversarial loss: 0.607264\n",
      "epoch 83; iter: 0; batch classifier loss: 0.468969; batch adversarial loss: 0.517511\n",
      "epoch 84; iter: 0; batch classifier loss: 0.420288; batch adversarial loss: 0.491197\n",
      "epoch 85; iter: 0; batch classifier loss: 0.498281; batch adversarial loss: 0.599296\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400860; batch adversarial loss: 0.589504\n",
      "epoch 87; iter: 0; batch classifier loss: 0.466276; batch adversarial loss: 0.571472\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415900; batch adversarial loss: 0.562973\n",
      "epoch 89; iter: 0; batch classifier loss: 0.441593; batch adversarial loss: 0.553164\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350427; batch adversarial loss: 0.571539\n",
      "epoch 91; iter: 0; batch classifier loss: 0.441875; batch adversarial loss: 0.517874\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373213; batch adversarial loss: 0.553238\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447703; batch adversarial loss: 0.598603\n",
      "epoch 94; iter: 0; batch classifier loss: 0.342815; batch adversarial loss: 0.617209\n",
      "epoch 95; iter: 0; batch classifier loss: 0.390519; batch adversarial loss: 0.535864\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419289; batch adversarial loss: 0.527031\n",
      "epoch 97; iter: 0; batch classifier loss: 0.438700; batch adversarial loss: 0.580135\n",
      "epoch 98; iter: 0; batch classifier loss: 0.444359; batch adversarial loss: 0.606880\n",
      "epoch 99; iter: 0; batch classifier loss: 0.436815; batch adversarial loss: 0.634991\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399106; batch adversarial loss: 0.526586\n",
      "epoch 101; iter: 0; batch classifier loss: 0.373658; batch adversarial loss: 0.563204\n",
      "epoch 102; iter: 0; batch classifier loss: 0.434077; batch adversarial loss: 0.606936\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408814; batch adversarial loss: 0.580551\n",
      "epoch 104; iter: 0; batch classifier loss: 0.450979; batch adversarial loss: 0.562361\n",
      "epoch 105; iter: 0; batch classifier loss: 0.431508; batch adversarial loss: 0.544446\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363698; batch adversarial loss: 0.526863\n",
      "epoch 107; iter: 0; batch classifier loss: 0.425117; batch adversarial loss: 0.535320\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379750; batch adversarial loss: 0.509074\n",
      "epoch 109; iter: 0; batch classifier loss: 0.408932; batch adversarial loss: 0.606784\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398567; batch adversarial loss: 0.562745\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418228; batch adversarial loss: 0.626060\n",
      "epoch 112; iter: 0; batch classifier loss: 0.488452; batch adversarial loss: 0.535334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.497021; batch adversarial loss: 0.544651\n",
      "epoch 114; iter: 0; batch classifier loss: 0.450145; batch adversarial loss: 0.572275\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382729; batch adversarial loss: 0.544479\n",
      "epoch 116; iter: 0; batch classifier loss: 0.436116; batch adversarial loss: 0.625154\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416562; batch adversarial loss: 0.499130\n",
      "epoch 118; iter: 0; batch classifier loss: 0.362210; batch adversarial loss: 0.652899\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394614; batch adversarial loss: 0.517583\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344142; batch adversarial loss: 0.472197\n",
      "epoch 121; iter: 0; batch classifier loss: 0.329092; batch adversarial loss: 0.544793\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381409; batch adversarial loss: 0.481718\n",
      "epoch 123; iter: 0; batch classifier loss: 0.320827; batch adversarial loss: 0.590020\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373423; batch adversarial loss: 0.454349\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383133; batch adversarial loss: 0.553683\n",
      "epoch 126; iter: 0; batch classifier loss: 0.460610; batch adversarial loss: 0.544585\n",
      "epoch 127; iter: 0; batch classifier loss: 0.312368; batch adversarial loss: 0.563285\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409387; batch adversarial loss: 0.598423\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342709; batch adversarial loss: 0.526996\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376966; batch adversarial loss: 0.562999\n",
      "epoch 131; iter: 0; batch classifier loss: 0.430514; batch adversarial loss: 0.561919\n",
      "epoch 132; iter: 0; batch classifier loss: 0.348317; batch adversarial loss: 0.545092\n",
      "epoch 133; iter: 0; batch classifier loss: 0.425568; batch adversarial loss: 0.589290\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371979; batch adversarial loss: 0.589370\n",
      "epoch 135; iter: 0; batch classifier loss: 0.322550; batch adversarial loss: 0.580708\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377438; batch adversarial loss: 0.589536\n",
      "epoch 137; iter: 0; batch classifier loss: 0.394593; batch adversarial loss: 0.608167\n",
      "epoch 138; iter: 0; batch classifier loss: 0.303796; batch adversarial loss: 0.544663\n",
      "epoch 139; iter: 0; batch classifier loss: 0.400595; batch adversarial loss: 0.490743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356015; batch adversarial loss: 0.589485\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356243; batch adversarial loss: 0.616600\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363860; batch adversarial loss: 0.472641\n",
      "epoch 143; iter: 0; batch classifier loss: 0.351700; batch adversarial loss: 0.598032\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331021; batch adversarial loss: 0.499718\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398966; batch adversarial loss: 0.553732\n",
      "epoch 146; iter: 0; batch classifier loss: 0.356400; batch adversarial loss: 0.553015\n",
      "epoch 147; iter: 0; batch classifier loss: 0.324224; batch adversarial loss: 0.545139\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391780; batch adversarial loss: 0.563313\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373072; batch adversarial loss: 0.544428\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344117; batch adversarial loss: 0.588932\n",
      "epoch 151; iter: 0; batch classifier loss: 0.393587; batch adversarial loss: 0.580113\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370978; batch adversarial loss: 0.499819\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376739; batch adversarial loss: 0.527176\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376942; batch adversarial loss: 0.570554\n",
      "epoch 155; iter: 0; batch classifier loss: 0.453387; batch adversarial loss: 0.643243\n",
      "epoch 156; iter: 0; batch classifier loss: 0.419572; batch adversarial loss: 0.536078\n",
      "epoch 157; iter: 0; batch classifier loss: 0.379515; batch adversarial loss: 0.535676\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363582; batch adversarial loss: 0.517407\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363448; batch adversarial loss: 0.545064\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401563; batch adversarial loss: 0.589531\n",
      "epoch 161; iter: 0; batch classifier loss: 0.452871; batch adversarial loss: 0.499552\n",
      "epoch 162; iter: 0; batch classifier loss: 0.471180; batch adversarial loss: 0.553640\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345300; batch adversarial loss: 0.616487\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380546; batch adversarial loss: 0.562530\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388000; batch adversarial loss: 0.562396\n",
      "epoch 166; iter: 0; batch classifier loss: 0.522125; batch adversarial loss: 0.607811\n",
      "epoch 167; iter: 0; batch classifier loss: 0.290733; batch adversarial loss: 0.562218\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344200; batch adversarial loss: 0.589559\n",
      "epoch 169; iter: 0; batch classifier loss: 0.423248; batch adversarial loss: 0.500097\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380454; batch adversarial loss: 0.562847\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342578; batch adversarial loss: 0.536016\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395899; batch adversarial loss: 0.589965\n",
      "epoch 173; iter: 0; batch classifier loss: 0.454867; batch adversarial loss: 0.598722\n",
      "epoch 174; iter: 0; batch classifier loss: 0.436968; batch adversarial loss: 0.535365\n",
      "epoch 175; iter: 0; batch classifier loss: 0.479063; batch adversarial loss: 0.661559\n",
      "epoch 176; iter: 0; batch classifier loss: 0.425887; batch adversarial loss: 0.589159\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342673; batch adversarial loss: 0.463144\n",
      "epoch 178; iter: 0; batch classifier loss: 0.386896; batch adversarial loss: 0.571278\n",
      "epoch 179; iter: 0; batch classifier loss: 0.388668; batch adversarial loss: 0.607050\n",
      "epoch 180; iter: 0; batch classifier loss: 0.417269; batch adversarial loss: 0.518000\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371722; batch adversarial loss: 0.616422\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371390; batch adversarial loss: 0.670754\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342309; batch adversarial loss: 0.408715\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404753; batch adversarial loss: 0.534940\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370502; batch adversarial loss: 0.545428\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353524; batch adversarial loss: 0.535489\n",
      "epoch 187; iter: 0; batch classifier loss: 0.368640; batch adversarial loss: 0.571120\n",
      "epoch 188; iter: 0; batch classifier loss: 0.342774; batch adversarial loss: 0.544273\n",
      "epoch 189; iter: 0; batch classifier loss: 0.296929; batch adversarial loss: 0.526836\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339124; batch adversarial loss: 0.562460\n",
      "epoch 191; iter: 0; batch classifier loss: 0.342447; batch adversarial loss: 0.536253\n",
      "epoch 192; iter: 0; batch classifier loss: 0.399642; batch adversarial loss: 0.534672\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327348; batch adversarial loss: 0.517406\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376691; batch adversarial loss: 0.643780\n",
      "epoch 195; iter: 0; batch classifier loss: 0.396892; batch adversarial loss: 0.589686\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341708; batch adversarial loss: 0.508551\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366288; batch adversarial loss: 0.545208\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343374; batch adversarial loss: 0.490778\n",
      "epoch 199; iter: 0; batch classifier loss: 0.343996; batch adversarial loss: 0.544548\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685431; batch adversarial loss: 0.709742\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560534; batch adversarial loss: 0.687608\n",
      "epoch 2; iter: 0; batch classifier loss: 0.622789; batch adversarial loss: 0.672537\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531689; batch adversarial loss: 0.655224\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569425; batch adversarial loss: 0.630342\n",
      "epoch 5; iter: 0; batch classifier loss: 0.525665; batch adversarial loss: 0.605939\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482762; batch adversarial loss: 0.562539\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574765; batch adversarial loss: 0.584834\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539055; batch adversarial loss: 0.550089\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536754; batch adversarial loss: 0.636050\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565124; batch adversarial loss: 0.569361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.552851; batch adversarial loss: 0.611173\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519501; batch adversarial loss: 0.588880\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554306; batch adversarial loss: 0.568109\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510195; batch adversarial loss: 0.657479\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540833; batch adversarial loss: 0.660835\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496082; batch adversarial loss: 0.586421\n",
      "epoch 17; iter: 0; batch classifier loss: 0.593763; batch adversarial loss: 0.554675\n",
      "epoch 18; iter: 0; batch classifier loss: 0.463223; batch adversarial loss: 0.575936\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461984; batch adversarial loss: 0.548123\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556772; batch adversarial loss: 0.546818\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476447; batch adversarial loss: 0.578984\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459161; batch adversarial loss: 0.546466\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463609; batch adversarial loss: 0.539405\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518102; batch adversarial loss: 0.594265\n",
      "epoch 25; iter: 0; batch classifier loss: 0.382010; batch adversarial loss: 0.556831\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442084; batch adversarial loss: 0.539725\n",
      "epoch 27; iter: 0; batch classifier loss: 0.498405; batch adversarial loss: 0.562636\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450665; batch adversarial loss: 0.588303\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477862; batch adversarial loss: 0.612978\n",
      "epoch 30; iter: 0; batch classifier loss: 0.427693; batch adversarial loss: 0.616769\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517960; batch adversarial loss: 0.586225\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461600; batch adversarial loss: 0.529944\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498844; batch adversarial loss: 0.563699\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448909; batch adversarial loss: 0.516137\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434427; batch adversarial loss: 0.589656\n",
      "epoch 36; iter: 0; batch classifier loss: 0.488695; batch adversarial loss: 0.659279\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408889; batch adversarial loss: 0.579836\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448623; batch adversarial loss: 0.571046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438261; batch adversarial loss: 0.571388\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408506; batch adversarial loss: 0.498964\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448860; batch adversarial loss: 0.528344\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427774; batch adversarial loss: 0.552974\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439796; batch adversarial loss: 0.570184\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417343; batch adversarial loss: 0.562524\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392900; batch adversarial loss: 0.579717\n",
      "epoch 46; iter: 0; batch classifier loss: 0.522027; batch adversarial loss: 0.518549\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410442; batch adversarial loss: 0.509318\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509079; batch adversarial loss: 0.481496\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399476; batch adversarial loss: 0.508885\n",
      "epoch 50; iter: 0; batch classifier loss: 0.447291; batch adversarial loss: 0.589808\n",
      "epoch 51; iter: 0; batch classifier loss: 0.365643; batch adversarial loss: 0.580013\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424288; batch adversarial loss: 0.508510\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437645; batch adversarial loss: 0.435245\n",
      "epoch 54; iter: 0; batch classifier loss: 0.494415; batch adversarial loss: 0.526719\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448623; batch adversarial loss: 0.499183\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398389; batch adversarial loss: 0.572021\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416597; batch adversarial loss: 0.553683\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431160; batch adversarial loss: 0.436460\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442424; batch adversarial loss: 0.463861\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404960; batch adversarial loss: 0.571553\n",
      "epoch 61; iter: 0; batch classifier loss: 0.330914; batch adversarial loss: 0.517525\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410899; batch adversarial loss: 0.489816\n",
      "epoch 63; iter: 0; batch classifier loss: 0.523887; batch adversarial loss: 0.571135\n",
      "epoch 64; iter: 0; batch classifier loss: 0.354799; batch adversarial loss: 0.571739\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419483; batch adversarial loss: 0.481688\n",
      "epoch 66; iter: 0; batch classifier loss: 0.379857; batch adversarial loss: 0.553664\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374918; batch adversarial loss: 0.507968\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408374; batch adversarial loss: 0.553564\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415483; batch adversarial loss: 0.552977\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418426; batch adversarial loss: 0.470325\n",
      "epoch 71; iter: 0; batch classifier loss: 0.326318; batch adversarial loss: 0.526803\n",
      "epoch 72; iter: 0; batch classifier loss: 0.336792; batch adversarial loss: 0.552871\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431204; batch adversarial loss: 0.506652\n",
      "epoch 74; iter: 0; batch classifier loss: 0.357246; batch adversarial loss: 0.515678\n",
      "epoch 75; iter: 0; batch classifier loss: 0.480690; batch adversarial loss: 0.531704\n",
      "epoch 76; iter: 0; batch classifier loss: 0.453920; batch adversarial loss: 0.578776\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391464; batch adversarial loss: 0.574324\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397814; batch adversarial loss: 0.561414\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410046; batch adversarial loss: 0.545393\n",
      "epoch 80; iter: 0; batch classifier loss: 0.340656; batch adversarial loss: 0.481507\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351238; batch adversarial loss: 0.501051\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348029; batch adversarial loss: 0.518154\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392262; batch adversarial loss: 0.483111\n",
      "epoch 84; iter: 0; batch classifier loss: 0.417436; batch adversarial loss: 0.508618\n",
      "epoch 85; iter: 0; batch classifier loss: 0.355687; batch adversarial loss: 0.526945\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415299; batch adversarial loss: 0.490390\n",
      "epoch 87; iter: 0; batch classifier loss: 0.344197; batch adversarial loss: 0.642728\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415099; batch adversarial loss: 0.535512\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424146; batch adversarial loss: 0.625780\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394092; batch adversarial loss: 0.571933\n",
      "epoch 91; iter: 0; batch classifier loss: 0.335829; batch adversarial loss: 0.553339\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364309; batch adversarial loss: 0.553822\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352143; batch adversarial loss: 0.517747\n",
      "epoch 94; iter: 0; batch classifier loss: 0.341138; batch adversarial loss: 0.490384\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347660; batch adversarial loss: 0.580497\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396605; batch adversarial loss: 0.544881\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430392; batch adversarial loss: 0.562225\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365943; batch adversarial loss: 0.562554\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403020; batch adversarial loss: 0.580887\n",
      "epoch 100; iter: 0; batch classifier loss: 0.341678; batch adversarial loss: 0.544270\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406390; batch adversarial loss: 0.525653\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380464; batch adversarial loss: 0.471632\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406896; batch adversarial loss: 0.562659\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416176; batch adversarial loss: 0.535446\n",
      "epoch 105; iter: 0; batch classifier loss: 0.437529; batch adversarial loss: 0.608259\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404164; batch adversarial loss: 0.516988\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400164; batch adversarial loss: 0.544404\n",
      "epoch 108; iter: 0; batch classifier loss: 0.408761; batch adversarial loss: 0.480969\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363250; batch adversarial loss: 0.544310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.381740; batch adversarial loss: 0.472028\n",
      "epoch 111; iter: 0; batch classifier loss: 0.292293; batch adversarial loss: 0.544660\n",
      "epoch 112; iter: 0; batch classifier loss: 0.315792; batch adversarial loss: 0.543858\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353990; batch adversarial loss: 0.535349\n",
      "epoch 114; iter: 0; batch classifier loss: 0.403139; batch adversarial loss: 0.572043\n",
      "epoch 115; iter: 0; batch classifier loss: 0.402652; batch adversarial loss: 0.553853\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358191; batch adversarial loss: 0.553783\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362596; batch adversarial loss: 0.589998\n",
      "epoch 118; iter: 0; batch classifier loss: 0.430487; batch adversarial loss: 0.580828\n",
      "epoch 119; iter: 0; batch classifier loss: 0.457577; batch adversarial loss: 0.590018\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391066; batch adversarial loss: 0.499177\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394482; batch adversarial loss: 0.508291\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384055; batch adversarial loss: 0.607817\n",
      "epoch 123; iter: 0; batch classifier loss: 0.304468; batch adversarial loss: 0.553818\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325964; batch adversarial loss: 0.535499\n",
      "epoch 125; iter: 0; batch classifier loss: 0.449746; batch adversarial loss: 0.553340\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383327; batch adversarial loss: 0.526657\n",
      "epoch 127; iter: 0; batch classifier loss: 0.425530; batch adversarial loss: 0.536059\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352401; batch adversarial loss: 0.508547\n",
      "epoch 129; iter: 0; batch classifier loss: 0.305237; batch adversarial loss: 0.607946\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370785; batch adversarial loss: 0.589755\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375394; batch adversarial loss: 0.581247\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352443; batch adversarial loss: 0.553154\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399378; batch adversarial loss: 0.453665\n",
      "epoch 134; iter: 0; batch classifier loss: 0.298347; batch adversarial loss: 0.589406\n",
      "epoch 135; iter: 0; batch classifier loss: 0.396200; batch adversarial loss: 0.562523\n",
      "epoch 136; iter: 0; batch classifier loss: 0.384998; batch adversarial loss: 0.626875\n",
      "epoch 137; iter: 0; batch classifier loss: 0.446651; batch adversarial loss: 0.598875\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340986; batch adversarial loss: 0.472613\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338008; batch adversarial loss: 0.526350\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340695; batch adversarial loss: 0.589988\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357867; batch adversarial loss: 0.554095\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395727; batch adversarial loss: 0.580422\n",
      "epoch 143; iter: 0; batch classifier loss: 0.429838; batch adversarial loss: 0.554150\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354850; batch adversarial loss: 0.562377\n",
      "epoch 145; iter: 0; batch classifier loss: 0.290381; batch adversarial loss: 0.562894\n",
      "epoch 146; iter: 0; batch classifier loss: 0.292974; batch adversarial loss: 0.572039\n",
      "epoch 147; iter: 0; batch classifier loss: 0.302004; batch adversarial loss: 0.526436\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379882; batch adversarial loss: 0.571971\n",
      "epoch 149; iter: 0; batch classifier loss: 0.358118; batch adversarial loss: 0.598493\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352256; batch adversarial loss: 0.489810\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334520; batch adversarial loss: 0.526568\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369044; batch adversarial loss: 0.553458\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391131; batch adversarial loss: 0.481158\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354139; batch adversarial loss: 0.564095\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394580; batch adversarial loss: 0.571468\n",
      "epoch 156; iter: 0; batch classifier loss: 0.411078; batch adversarial loss: 0.545065\n",
      "epoch 157; iter: 0; batch classifier loss: 0.348612; batch adversarial loss: 0.544489\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338503; batch adversarial loss: 0.526558\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367037; batch adversarial loss: 0.517338\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382371; batch adversarial loss: 0.599664\n",
      "epoch 161; iter: 0; batch classifier loss: 0.464241; batch adversarial loss: 0.472101\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365329; batch adversarial loss: 0.536021\n",
      "epoch 163; iter: 0; batch classifier loss: 0.493861; batch adversarial loss: 0.554231\n",
      "epoch 164; iter: 0; batch classifier loss: 0.434210; batch adversarial loss: 0.481899\n",
      "epoch 165; iter: 0; batch classifier loss: 0.340279; batch adversarial loss: 0.562645\n",
      "epoch 166; iter: 0; batch classifier loss: 0.363935; batch adversarial loss: 0.571463\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336884; batch adversarial loss: 0.526367\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389642; batch adversarial loss: 0.535771\n",
      "epoch 169; iter: 0; batch classifier loss: 0.308089; batch adversarial loss: 0.607504\n",
      "epoch 170; iter: 0; batch classifier loss: 0.285679; batch adversarial loss: 0.589624\n",
      "epoch 171; iter: 0; batch classifier loss: 0.311963; batch adversarial loss: 0.526020\n",
      "epoch 172; iter: 0; batch classifier loss: 0.443471; batch adversarial loss: 0.589965\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351122; batch adversarial loss: 0.507545\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392371; batch adversarial loss: 0.507562\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382134; batch adversarial loss: 0.598295\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330315; batch adversarial loss: 0.472605\n",
      "epoch 177; iter: 0; batch classifier loss: 0.366903; batch adversarial loss: 0.662003\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326560; batch adversarial loss: 0.580753\n",
      "epoch 179; iter: 0; batch classifier loss: 0.242769; batch adversarial loss: 0.598660\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353133; batch adversarial loss: 0.545009\n",
      "epoch 181; iter: 0; batch classifier loss: 0.272201; batch adversarial loss: 0.590585\n",
      "epoch 182; iter: 0; batch classifier loss: 0.296014; batch adversarial loss: 0.480867\n",
      "epoch 183; iter: 0; batch classifier loss: 0.361856; batch adversarial loss: 0.589875\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385864; batch adversarial loss: 0.472506\n",
      "epoch 185; iter: 0; batch classifier loss: 0.313511; batch adversarial loss: 0.607816\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407927; batch adversarial loss: 0.553353\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389209; batch adversarial loss: 0.545080\n",
      "epoch 188; iter: 0; batch classifier loss: 0.339089; batch adversarial loss: 0.598302\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305936; batch adversarial loss: 0.617074\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327194; batch adversarial loss: 0.598984\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335655; batch adversarial loss: 0.553390\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358225; batch adversarial loss: 0.553576\n",
      "epoch 193; iter: 0; batch classifier loss: 0.392538; batch adversarial loss: 0.489128\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393924; batch adversarial loss: 0.590571\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390683; batch adversarial loss: 0.527094\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355166; batch adversarial loss: 0.517569\n",
      "epoch 197; iter: 0; batch classifier loss: 0.380870; batch adversarial loss: 0.617283\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342076; batch adversarial loss: 0.490383\n",
      "epoch 199; iter: 0; batch classifier loss: 0.269662; batch adversarial loss: 0.544359\n",
      "epoch 0; iter: 0; batch classifier loss: 0.819922; batch adversarial loss: 0.517456\n",
      "epoch 1; iter: 0; batch classifier loss: 0.524722; batch adversarial loss: 0.661458\n",
      "epoch 2; iter: 0; batch classifier loss: 0.669068; batch adversarial loss: 0.734355\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570947; batch adversarial loss: 0.702749\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579956; batch adversarial loss: 0.681647\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561294; batch adversarial loss: 0.616326\n",
      "epoch 6; iter: 0; batch classifier loss: 0.625074; batch adversarial loss: 0.643662\n",
      "epoch 7; iter: 0; batch classifier loss: 0.617975; batch adversarial loss: 0.633687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.591436; batch adversarial loss: 0.575585\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543158; batch adversarial loss: 0.574030\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544541; batch adversarial loss: 0.525747\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522652; batch adversarial loss: 0.585471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510478; batch adversarial loss: 0.576025\n",
      "epoch 13; iter: 0; batch classifier loss: 0.608376; batch adversarial loss: 0.597728\n",
      "epoch 14; iter: 0; batch classifier loss: 0.454347; batch adversarial loss: 0.600192\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505543; batch adversarial loss: 0.522405\n",
      "epoch 16; iter: 0; batch classifier loss: 0.517342; batch adversarial loss: 0.537362\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512858; batch adversarial loss: 0.557712\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536104; batch adversarial loss: 0.553211\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408855; batch adversarial loss: 0.528461\n",
      "epoch 20; iter: 0; batch classifier loss: 0.568191; batch adversarial loss: 0.518323\n",
      "epoch 21; iter: 0; batch classifier loss: 0.586045; batch adversarial loss: 0.501405\n",
      "epoch 22; iter: 0; batch classifier loss: 0.505026; batch adversarial loss: 0.539016\n",
      "epoch 23; iter: 0; batch classifier loss: 0.422568; batch adversarial loss: 0.570504\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460046; batch adversarial loss: 0.502926\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488862; batch adversarial loss: 0.520127\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463325; batch adversarial loss: 0.544969\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494453; batch adversarial loss: 0.474478\n",
      "epoch 28; iter: 0; batch classifier loss: 0.374524; batch adversarial loss: 0.561762\n",
      "epoch 29; iter: 0; batch classifier loss: 0.442325; batch adversarial loss: 0.480661\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469621; batch adversarial loss: 0.463716\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456588; batch adversarial loss: 0.592043\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442218; batch adversarial loss: 0.541480\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474441; batch adversarial loss: 0.524588\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544655; batch adversarial loss: 0.590170\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423253; batch adversarial loss: 0.554479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473151; batch adversarial loss: 0.561880\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429092; batch adversarial loss: 0.552815\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418525; batch adversarial loss: 0.526286\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414601; batch adversarial loss: 0.508757\n",
      "epoch 40; iter: 0; batch classifier loss: 0.483673; batch adversarial loss: 0.581589\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437408; batch adversarial loss: 0.526593\n",
      "epoch 42; iter: 0; batch classifier loss: 0.509027; batch adversarial loss: 0.581628\n",
      "epoch 43; iter: 0; batch classifier loss: 0.411944; batch adversarial loss: 0.581113\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441199; batch adversarial loss: 0.517441\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446672; batch adversarial loss: 0.535532\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465466; batch adversarial loss: 0.489589\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455366; batch adversarial loss: 0.599803\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389951; batch adversarial loss: 0.526229\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432864; batch adversarial loss: 0.444260\n",
      "epoch 50; iter: 0; batch classifier loss: 0.450952; batch adversarial loss: 0.535129\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400542; batch adversarial loss: 0.561686\n",
      "epoch 52; iter: 0; batch classifier loss: 0.507716; batch adversarial loss: 0.608237\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436145; batch adversarial loss: 0.487525\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429441; batch adversarial loss: 0.540701\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425213; batch adversarial loss: 0.601031\n",
      "epoch 56; iter: 0; batch classifier loss: 0.497668; batch adversarial loss: 0.582788\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416152; batch adversarial loss: 0.480811\n",
      "epoch 58; iter: 0; batch classifier loss: 0.332510; batch adversarial loss: 0.605010\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400376; batch adversarial loss: 0.498536\n",
      "epoch 60; iter: 0; batch classifier loss: 0.488580; batch adversarial loss: 0.497577\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422877; batch adversarial loss: 0.514089\n",
      "epoch 62; iter: 0; batch classifier loss: 0.316868; batch adversarial loss: 0.677537\n",
      "epoch 63; iter: 0; batch classifier loss: 0.488546; batch adversarial loss: 0.574810\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424279; batch adversarial loss: 0.543155\n",
      "epoch 65; iter: 0; batch classifier loss: 0.340774; batch adversarial loss: 0.592712\n",
      "epoch 66; iter: 0; batch classifier loss: 0.288025; batch adversarial loss: 0.573467\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408947; batch adversarial loss: 0.497723\n",
      "epoch 68; iter: 0; batch classifier loss: 0.444339; batch adversarial loss: 0.560795\n",
      "epoch 69; iter: 0; batch classifier loss: 0.351046; batch adversarial loss: 0.579753\n",
      "epoch 70; iter: 0; batch classifier loss: 0.364301; batch adversarial loss: 0.506200\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396019; batch adversarial loss: 0.561005\n",
      "epoch 72; iter: 0; batch classifier loss: 0.439882; batch adversarial loss: 0.517925\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393901; batch adversarial loss: 0.552839\n",
      "epoch 74; iter: 0; batch classifier loss: 0.370993; batch adversarial loss: 0.515851\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379277; batch adversarial loss: 0.563063\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375257; batch adversarial loss: 0.552990\n",
      "epoch 77; iter: 0; batch classifier loss: 0.431664; batch adversarial loss: 0.525045\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402653; batch adversarial loss: 0.517099\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422663; batch adversarial loss: 0.610972\n",
      "epoch 80; iter: 0; batch classifier loss: 0.454940; batch adversarial loss: 0.582848\n",
      "epoch 81; iter: 0; batch classifier loss: 0.431574; batch adversarial loss: 0.524478\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406644; batch adversarial loss: 0.628553\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369453; batch adversarial loss: 0.517150\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391805; batch adversarial loss: 0.534507\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361649; batch adversarial loss: 0.599877\n",
      "epoch 86; iter: 0; batch classifier loss: 0.466335; batch adversarial loss: 0.514720\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376281; batch adversarial loss: 0.535032\n",
      "epoch 88; iter: 0; batch classifier loss: 0.443521; batch adversarial loss: 0.580440\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394382; batch adversarial loss: 0.563169\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415366; batch adversarial loss: 0.507697\n",
      "epoch 91; iter: 0; batch classifier loss: 0.429040; batch adversarial loss: 0.535248\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402301; batch adversarial loss: 0.552209\n",
      "epoch 93; iter: 0; batch classifier loss: 0.446224; batch adversarial loss: 0.487186\n",
      "epoch 94; iter: 0; batch classifier loss: 0.331577; batch adversarial loss: 0.553929\n",
      "epoch 95; iter: 0; batch classifier loss: 0.453641; batch adversarial loss: 0.525005\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374005; batch adversarial loss: 0.479654\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437260; batch adversarial loss: 0.508139\n",
      "epoch 98; iter: 0; batch classifier loss: 0.480883; batch adversarial loss: 0.573401\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408886; batch adversarial loss: 0.526644\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383260; batch adversarial loss: 0.525204\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415605; batch adversarial loss: 0.517172\n",
      "epoch 102; iter: 0; batch classifier loss: 0.441711; batch adversarial loss: 0.517867\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385440; batch adversarial loss: 0.647637\n",
      "epoch 104; iter: 0; batch classifier loss: 0.345394; batch adversarial loss: 0.507559\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404459; batch adversarial loss: 0.488365\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413388; batch adversarial loss: 0.526037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.372135; batch adversarial loss: 0.543378\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375129; batch adversarial loss: 0.562305\n",
      "epoch 109; iter: 0; batch classifier loss: 0.450199; batch adversarial loss: 0.600835\n",
      "epoch 110; iter: 0; batch classifier loss: 0.477148; batch adversarial loss: 0.507594\n",
      "epoch 111; iter: 0; batch classifier loss: 0.332652; batch adversarial loss: 0.602103\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364211; batch adversarial loss: 0.582524\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333312; batch adversarial loss: 0.554393\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386290; batch adversarial loss: 0.507212\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367985; batch adversarial loss: 0.573028\n",
      "epoch 116; iter: 0; batch classifier loss: 0.425967; batch adversarial loss: 0.572925\n",
      "epoch 117; iter: 0; batch classifier loss: 0.519958; batch adversarial loss: 0.535139\n",
      "epoch 118; iter: 0; batch classifier loss: 0.400341; batch adversarial loss: 0.478963\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367721; batch adversarial loss: 0.488495\n",
      "epoch 120; iter: 0; batch classifier loss: 0.295541; batch adversarial loss: 0.553830\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391371; batch adversarial loss: 0.535171\n",
      "epoch 122; iter: 0; batch classifier loss: 0.412502; batch adversarial loss: 0.516795\n",
      "epoch 123; iter: 0; batch classifier loss: 0.460905; batch adversarial loss: 0.581910\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402817; batch adversarial loss: 0.516666\n",
      "epoch 125; iter: 0; batch classifier loss: 0.444497; batch adversarial loss: 0.544539\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386098; batch adversarial loss: 0.535359\n",
      "epoch 127; iter: 0; batch classifier loss: 0.393861; batch adversarial loss: 0.525665\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411255; batch adversarial loss: 0.498344\n",
      "epoch 129; iter: 0; batch classifier loss: 0.422915; batch adversarial loss: 0.506711\n",
      "epoch 130; iter: 0; batch classifier loss: 0.367639; batch adversarial loss: 0.562802\n",
      "epoch 131; iter: 0; batch classifier loss: 0.316162; batch adversarial loss: 0.526087\n",
      "epoch 132; iter: 0; batch classifier loss: 0.311474; batch adversarial loss: 0.544169\n",
      "epoch 133; iter: 0; batch classifier loss: 0.338473; batch adversarial loss: 0.572679\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372026; batch adversarial loss: 0.451690\n",
      "epoch 135; iter: 0; batch classifier loss: 0.327761; batch adversarial loss: 0.591281\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359776; batch adversarial loss: 0.497999\n",
      "epoch 137; iter: 0; batch classifier loss: 0.390009; batch adversarial loss: 0.637651\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384514; batch adversarial loss: 0.544073\n",
      "epoch 139; iter: 0; batch classifier loss: 0.354332; batch adversarial loss: 0.489223\n",
      "epoch 140; iter: 0; batch classifier loss: 0.434880; batch adversarial loss: 0.516094\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398857; batch adversarial loss: 0.563060\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408762; batch adversarial loss: 0.572865\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364155; batch adversarial loss: 0.545247\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376305; batch adversarial loss: 0.581772\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375800; batch adversarial loss: 0.544469\n",
      "epoch 146; iter: 0; batch classifier loss: 0.396587; batch adversarial loss: 0.497329\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381998; batch adversarial loss: 0.563145\n",
      "epoch 148; iter: 0; batch classifier loss: 0.307363; batch adversarial loss: 0.599990\n",
      "epoch 149; iter: 0; batch classifier loss: 0.267885; batch adversarial loss: 0.562943\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399683; batch adversarial loss: 0.508033\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379766; batch adversarial loss: 0.646767\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405560; batch adversarial loss: 0.507163\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316659; batch adversarial loss: 0.563665\n",
      "epoch 154; iter: 0; batch classifier loss: 0.347351; batch adversarial loss: 0.460620\n",
      "epoch 155; iter: 0; batch classifier loss: 0.352167; batch adversarial loss: 0.562605\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337573; batch adversarial loss: 0.479686\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362553; batch adversarial loss: 0.535348\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388658; batch adversarial loss: 0.469708\n",
      "epoch 159; iter: 0; batch classifier loss: 0.426970; batch adversarial loss: 0.581759\n",
      "epoch 160; iter: 0; batch classifier loss: 0.455485; batch adversarial loss: 0.535091\n",
      "epoch 161; iter: 0; batch classifier loss: 0.424833; batch adversarial loss: 0.571946\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376887; batch adversarial loss: 0.553738\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350473; batch adversarial loss: 0.553462\n",
      "epoch 164; iter: 0; batch classifier loss: 0.434498; batch adversarial loss: 0.535280\n",
      "epoch 165; iter: 0; batch classifier loss: 0.444219; batch adversarial loss: 0.553841\n",
      "epoch 166; iter: 0; batch classifier loss: 0.431025; batch adversarial loss: 0.572728\n",
      "epoch 167; iter: 0; batch classifier loss: 0.391836; batch adversarial loss: 0.478618\n",
      "epoch 168; iter: 0; batch classifier loss: 0.301580; batch adversarial loss: 0.600100\n",
      "epoch 169; iter: 0; batch classifier loss: 0.395582; batch adversarial loss: 0.581306\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345343; batch adversarial loss: 0.581158\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394470; batch adversarial loss: 0.525206\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359312; batch adversarial loss: 0.600340\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330251; batch adversarial loss: 0.590656\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385936; batch adversarial loss: 0.507135\n",
      "epoch 175; iter: 0; batch classifier loss: 0.412558; batch adversarial loss: 0.563754\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374810; batch adversarial loss: 0.562818\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396678; batch adversarial loss: 0.526281\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331453; batch adversarial loss: 0.581661\n",
      "epoch 179; iter: 0; batch classifier loss: 0.304686; batch adversarial loss: 0.553951\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350573; batch adversarial loss: 0.572598\n",
      "epoch 181; iter: 0; batch classifier loss: 0.307728; batch adversarial loss: 0.656581\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366826; batch adversarial loss: 0.479043\n",
      "epoch 183; iter: 0; batch classifier loss: 0.411404; batch adversarial loss: 0.507115\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379142; batch adversarial loss: 0.534538\n",
      "epoch 185; iter: 0; batch classifier loss: 0.423841; batch adversarial loss: 0.544378\n",
      "epoch 186; iter: 0; batch classifier loss: 0.308412; batch adversarial loss: 0.544782\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393903; batch adversarial loss: 0.553720\n",
      "epoch 188; iter: 0; batch classifier loss: 0.304787; batch adversarial loss: 0.506574\n",
      "epoch 189; iter: 0; batch classifier loss: 0.267607; batch adversarial loss: 0.618625\n",
      "epoch 190; iter: 0; batch classifier loss: 0.403700; batch adversarial loss: 0.451100\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363791; batch adversarial loss: 0.516401\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356234; batch adversarial loss: 0.563566\n",
      "epoch 193; iter: 0; batch classifier loss: 0.461867; batch adversarial loss: 0.506755\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350970; batch adversarial loss: 0.535224\n",
      "epoch 195; iter: 0; batch classifier loss: 0.407316; batch adversarial loss: 0.516826\n",
      "epoch 196; iter: 0; batch classifier loss: 0.458213; batch adversarial loss: 0.562800\n",
      "epoch 197; iter: 0; batch classifier loss: 0.431244; batch adversarial loss: 0.600282\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347029; batch adversarial loss: 0.497786\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367630; batch adversarial loss: 0.525910\n",
      "epoch 0; iter: 0; batch classifier loss: 0.630390; batch adversarial loss: 0.649347\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586255; batch adversarial loss: 0.629893\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551904; batch adversarial loss: 0.627823\n",
      "epoch 3; iter: 0; batch classifier loss: 0.552234; batch adversarial loss: 0.631547\n",
      "epoch 4; iter: 0; batch classifier loss: 0.464608; batch adversarial loss: 0.580163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.559894; batch adversarial loss: 0.607860\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550684; batch adversarial loss: 0.621697\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512319; batch adversarial loss: 0.581134\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596761; batch adversarial loss: 0.607011\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576850; batch adversarial loss: 0.627580\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548384; batch adversarial loss: 0.566956\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534742; batch adversarial loss: 0.634041\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572156; batch adversarial loss: 0.605481\n",
      "epoch 13; iter: 0; batch classifier loss: 0.562858; batch adversarial loss: 0.537496\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470272; batch adversarial loss: 0.498100\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474896; batch adversarial loss: 0.501181\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484911; batch adversarial loss: 0.526577\n",
      "epoch 17; iter: 0; batch classifier loss: 0.455013; batch adversarial loss: 0.538846\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515297; batch adversarial loss: 0.546920\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485987; batch adversarial loss: 0.584711\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480045; batch adversarial loss: 0.537769\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511156; batch adversarial loss: 0.582381\n",
      "epoch 22; iter: 0; batch classifier loss: 0.461498; batch adversarial loss: 0.504219\n",
      "epoch 23; iter: 0; batch classifier loss: 0.417006; batch adversarial loss: 0.604692\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473130; batch adversarial loss: 0.546331\n",
      "epoch 25; iter: 0; batch classifier loss: 0.563583; batch adversarial loss: 0.562234\n",
      "epoch 26; iter: 0; batch classifier loss: 0.544338; batch adversarial loss: 0.521908\n",
      "epoch 27; iter: 0; batch classifier loss: 0.407840; batch adversarial loss: 0.587672\n",
      "epoch 28; iter: 0; batch classifier loss: 0.399341; batch adversarial loss: 0.529217\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468082; batch adversarial loss: 0.543835\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462915; batch adversarial loss: 0.502087\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428560; batch adversarial loss: 0.537433\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510206; batch adversarial loss: 0.518876\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464999; batch adversarial loss: 0.498743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408014; batch adversarial loss: 0.534527\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443047; batch adversarial loss: 0.543678\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441564; batch adversarial loss: 0.535559\n",
      "epoch 37; iter: 0; batch classifier loss: 0.387828; batch adversarial loss: 0.561549\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469494; batch adversarial loss: 0.525871\n",
      "epoch 39; iter: 0; batch classifier loss: 0.389586; batch adversarial loss: 0.552830\n",
      "epoch 40; iter: 0; batch classifier loss: 0.389338; batch adversarial loss: 0.525436\n",
      "epoch 41; iter: 0; batch classifier loss: 0.513511; batch adversarial loss: 0.525743\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453725; batch adversarial loss: 0.526260\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470261; batch adversarial loss: 0.525401\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459061; batch adversarial loss: 0.508835\n",
      "epoch 45; iter: 0; batch classifier loss: 0.509531; batch adversarial loss: 0.534837\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437562; batch adversarial loss: 0.554025\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428195; batch adversarial loss: 0.553404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478972; batch adversarial loss: 0.516435\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390428; batch adversarial loss: 0.525831\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443239; batch adversarial loss: 0.563121\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465650; batch adversarial loss: 0.535447\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452647; batch adversarial loss: 0.591389\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428195; batch adversarial loss: 0.442098\n",
      "epoch 54; iter: 0; batch classifier loss: 0.517967; batch adversarial loss: 0.507104\n",
      "epoch 55; iter: 0; batch classifier loss: 0.338230; batch adversarial loss: 0.602144\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441851; batch adversarial loss: 0.496607\n",
      "epoch 57; iter: 0; batch classifier loss: 0.487143; batch adversarial loss: 0.590690\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413353; batch adversarial loss: 0.487910\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432538; batch adversarial loss: 0.526030\n",
      "epoch 60; iter: 0; batch classifier loss: 0.430649; batch adversarial loss: 0.554686\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381943; batch adversarial loss: 0.525183\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422419; batch adversarial loss: 0.554644\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411859; batch adversarial loss: 0.555584\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406234; batch adversarial loss: 0.555237\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421250; batch adversarial loss: 0.554756\n",
      "epoch 66; iter: 0; batch classifier loss: 0.336137; batch adversarial loss: 0.481719\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460430; batch adversarial loss: 0.545247\n",
      "epoch 68; iter: 0; batch classifier loss: 0.481070; batch adversarial loss: 0.644456\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422725; batch adversarial loss: 0.580847\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397408; batch adversarial loss: 0.571687\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428055; batch adversarial loss: 0.554183\n",
      "epoch 72; iter: 0; batch classifier loss: 0.368901; batch adversarial loss: 0.497898\n",
      "epoch 73; iter: 0; batch classifier loss: 0.491584; batch adversarial loss: 0.535249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436231; batch adversarial loss: 0.544139\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412006; batch adversarial loss: 0.609657\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420945; batch adversarial loss: 0.581827\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398756; batch adversarial loss: 0.564415\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424427; batch adversarial loss: 0.525367\n",
      "epoch 79; iter: 0; batch classifier loss: 0.340890; batch adversarial loss: 0.516757\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399347; batch adversarial loss: 0.498678\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368268; batch adversarial loss: 0.507510\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422734; batch adversarial loss: 0.645852\n",
      "epoch 83; iter: 0; batch classifier loss: 0.481132; batch adversarial loss: 0.507671\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395722; batch adversarial loss: 0.507313\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404233; batch adversarial loss: 0.516566\n",
      "epoch 86; iter: 0; batch classifier loss: 0.460019; batch adversarial loss: 0.609459\n",
      "epoch 87; iter: 0; batch classifier loss: 0.359893; batch adversarial loss: 0.563259\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423807; batch adversarial loss: 0.526591\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390342; batch adversarial loss: 0.609350\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369338; batch adversarial loss: 0.489202\n",
      "epoch 91; iter: 0; batch classifier loss: 0.431340; batch adversarial loss: 0.535198\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425044; batch adversarial loss: 0.516567\n",
      "epoch 93; iter: 0; batch classifier loss: 0.346715; batch adversarial loss: 0.627870\n",
      "epoch 94; iter: 0; batch classifier loss: 0.487535; batch adversarial loss: 0.489278\n",
      "epoch 95; iter: 0; batch classifier loss: 0.435061; batch adversarial loss: 0.535249\n",
      "epoch 96; iter: 0; batch classifier loss: 0.468625; batch adversarial loss: 0.553673\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381582; batch adversarial loss: 0.526224\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379020; batch adversarial loss: 0.535562\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375053; batch adversarial loss: 0.563002\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394256; batch adversarial loss: 0.488015\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415315; batch adversarial loss: 0.543361\n",
      "epoch 102; iter: 0; batch classifier loss: 0.421859; batch adversarial loss: 0.525592\n",
      "epoch 103; iter: 0; batch classifier loss: 0.418713; batch adversarial loss: 0.562468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.350210; batch adversarial loss: 0.551267\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372033; batch adversarial loss: 0.553260\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385821; batch adversarial loss: 0.598462\n",
      "epoch 107; iter: 0; batch classifier loss: 0.369297; batch adversarial loss: 0.477299\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420955; batch adversarial loss: 0.618301\n",
      "epoch 109; iter: 0; batch classifier loss: 0.445253; batch adversarial loss: 0.553866\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379409; batch adversarial loss: 0.631297\n",
      "epoch 111; iter: 0; batch classifier loss: 0.402143; batch adversarial loss: 0.528456\n",
      "epoch 112; iter: 0; batch classifier loss: 0.459016; batch adversarial loss: 0.517402\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380053; batch adversarial loss: 0.562931\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373662; batch adversarial loss: 0.564220\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419790; batch adversarial loss: 0.580869\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379607; batch adversarial loss: 0.608454\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362283; batch adversarial loss: 0.506524\n",
      "epoch 118; iter: 0; batch classifier loss: 0.281373; batch adversarial loss: 0.544089\n",
      "epoch 119; iter: 0; batch classifier loss: 0.465292; batch adversarial loss: 0.514907\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391237; batch adversarial loss: 0.563697\n",
      "epoch 121; iter: 0; batch classifier loss: 0.449409; batch adversarial loss: 0.479836\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397330; batch adversarial loss: 0.608358\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366672; batch adversarial loss: 0.552594\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358579; batch adversarial loss: 0.499800\n",
      "epoch 125; iter: 0; batch classifier loss: 0.320738; batch adversarial loss: 0.535990\n",
      "epoch 126; iter: 0; batch classifier loss: 0.466802; batch adversarial loss: 0.525863\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344274; batch adversarial loss: 0.534053\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432210; batch adversarial loss: 0.610608\n",
      "epoch 129; iter: 0; batch classifier loss: 0.431492; batch adversarial loss: 0.469618\n",
      "epoch 130; iter: 0; batch classifier loss: 0.308995; batch adversarial loss: 0.547421\n",
      "epoch 131; iter: 0; batch classifier loss: 0.313397; batch adversarial loss: 0.620249\n",
      "epoch 132; iter: 0; batch classifier loss: 0.426590; batch adversarial loss: 0.536101\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357427; batch adversarial loss: 0.535413\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338421; batch adversarial loss: 0.572275\n",
      "epoch 135; iter: 0; batch classifier loss: 0.407279; batch adversarial loss: 0.544270\n",
      "epoch 136; iter: 0; batch classifier loss: 0.353834; batch adversarial loss: 0.490588\n",
      "epoch 137; iter: 0; batch classifier loss: 0.459578; batch adversarial loss: 0.534691\n",
      "epoch 138; iter: 0; batch classifier loss: 0.481453; batch adversarial loss: 0.600529\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392458; batch adversarial loss: 0.526664\n",
      "epoch 140; iter: 0; batch classifier loss: 0.438195; batch adversarial loss: 0.544622\n",
      "epoch 141; iter: 0; batch classifier loss: 0.486141; batch adversarial loss: 0.497576\n",
      "epoch 142; iter: 0; batch classifier loss: 0.390884; batch adversarial loss: 0.598862\n",
      "epoch 143; iter: 0; batch classifier loss: 0.362492; batch adversarial loss: 0.498399\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349392; batch adversarial loss: 0.544169\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397401; batch adversarial loss: 0.507199\n",
      "epoch 146; iter: 0; batch classifier loss: 0.472060; batch adversarial loss: 0.516482\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358598; batch adversarial loss: 0.535254\n",
      "epoch 148; iter: 0; batch classifier loss: 0.415578; batch adversarial loss: 0.535528\n",
      "epoch 149; iter: 0; batch classifier loss: 0.449425; batch adversarial loss: 0.563308\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352368; batch adversarial loss: 0.442868\n",
      "epoch 151; iter: 0; batch classifier loss: 0.447219; batch adversarial loss: 0.526387\n",
      "epoch 152; iter: 0; batch classifier loss: 0.437815; batch adversarial loss: 0.479716\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333737; batch adversarial loss: 0.590594\n",
      "epoch 154; iter: 0; batch classifier loss: 0.527097; batch adversarial loss: 0.544371\n",
      "epoch 155; iter: 0; batch classifier loss: 0.393827; batch adversarial loss: 0.526048\n",
      "epoch 156; iter: 0; batch classifier loss: 0.315775; batch adversarial loss: 0.553692\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392969; batch adversarial loss: 0.609534\n",
      "epoch 158; iter: 0; batch classifier loss: 0.349824; batch adversarial loss: 0.516355\n",
      "epoch 159; iter: 0; batch classifier loss: 0.413125; batch adversarial loss: 0.618657\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401549; batch adversarial loss: 0.497565\n",
      "epoch 161; iter: 0; batch classifier loss: 0.384516; batch adversarial loss: 0.561393\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359156; batch adversarial loss: 0.544557\n",
      "epoch 163; iter: 0; batch classifier loss: 0.381005; batch adversarial loss: 0.507388\n",
      "epoch 164; iter: 0; batch classifier loss: 0.383973; batch adversarial loss: 0.562920\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345753; batch adversarial loss: 0.499117\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387404; batch adversarial loss: 0.537218\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395138; batch adversarial loss: 0.516859\n",
      "epoch 168; iter: 0; batch classifier loss: 0.421045; batch adversarial loss: 0.516162\n",
      "epoch 169; iter: 0; batch classifier loss: 0.456699; batch adversarial loss: 0.534769\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349822; batch adversarial loss: 0.610235\n",
      "epoch 171; iter: 0; batch classifier loss: 0.514851; batch adversarial loss: 0.580799\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392571; batch adversarial loss: 0.497733\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341538; batch adversarial loss: 0.497971\n",
      "epoch 174; iter: 0; batch classifier loss: 0.413304; batch adversarial loss: 0.592362\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362776; batch adversarial loss: 0.516754\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332354; batch adversarial loss: 0.573325\n",
      "epoch 177; iter: 0; batch classifier loss: 0.446292; batch adversarial loss: 0.571596\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350445; batch adversarial loss: 0.609055\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399895; batch adversarial loss: 0.590766\n",
      "epoch 180; iter: 0; batch classifier loss: 0.386573; batch adversarial loss: 0.497800\n",
      "epoch 181; iter: 0; batch classifier loss: 0.309545; batch adversarial loss: 0.599993\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349376; batch adversarial loss: 0.535288\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343283; batch adversarial loss: 0.535101\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375572; batch adversarial loss: 0.610054\n",
      "epoch 185; iter: 0; batch classifier loss: 0.411678; batch adversarial loss: 0.554079\n",
      "epoch 186; iter: 0; batch classifier loss: 0.354890; batch adversarial loss: 0.545359\n",
      "epoch 187; iter: 0; batch classifier loss: 0.402101; batch adversarial loss: 0.470770\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324462; batch adversarial loss: 0.478898\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339482; batch adversarial loss: 0.516966\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349366; batch adversarial loss: 0.627889\n",
      "epoch 191; iter: 0; batch classifier loss: 0.450330; batch adversarial loss: 0.517041\n",
      "epoch 192; iter: 0; batch classifier loss: 0.354041; batch adversarial loss: 0.479183\n",
      "epoch 193; iter: 0; batch classifier loss: 0.413456; batch adversarial loss: 0.553782\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349933; batch adversarial loss: 0.480018\n",
      "epoch 195; iter: 0; batch classifier loss: 0.358947; batch adversarial loss: 0.506271\n",
      "epoch 196; iter: 0; batch classifier loss: 0.433744; batch adversarial loss: 0.477812\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354643; batch adversarial loss: 0.590613\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340913; batch adversarial loss: 0.609104\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352705; batch adversarial loss: 0.601302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.685275; batch adversarial loss: 0.810821\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642959; batch adversarial loss: 0.910736\n",
      "epoch 2; iter: 0; batch classifier loss: 0.535097; batch adversarial loss: 0.820340\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555998; batch adversarial loss: 0.761408\n",
      "epoch 4; iter: 0; batch classifier loss: 0.524964; batch adversarial loss: 0.695892\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589939; batch adversarial loss: 0.684233\n",
      "epoch 6; iter: 0; batch classifier loss: 0.459577; batch adversarial loss: 0.630073\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588493; batch adversarial loss: 0.644865\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557388; batch adversarial loss: 0.620576\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484780; batch adversarial loss: 0.620530\n",
      "epoch 10; iter: 0; batch classifier loss: 0.473948; batch adversarial loss: 0.618385\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517190; batch adversarial loss: 0.641911\n",
      "epoch 12; iter: 0; batch classifier loss: 0.520150; batch adversarial loss: 0.613861\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520393; batch adversarial loss: 0.592340\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531584; batch adversarial loss: 0.568113\n",
      "epoch 15; iter: 0; batch classifier loss: 0.435369; batch adversarial loss: 0.606284\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532216; batch adversarial loss: 0.489561\n",
      "epoch 17; iter: 0; batch classifier loss: 0.454009; batch adversarial loss: 0.534578\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548782; batch adversarial loss: 0.543082\n",
      "epoch 19; iter: 0; batch classifier loss: 0.494350; batch adversarial loss: 0.561593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487681; batch adversarial loss: 0.587652\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495966; batch adversarial loss: 0.491957\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522469; batch adversarial loss: 0.562045\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517801; batch adversarial loss: 0.602908\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457357; batch adversarial loss: 0.615107\n",
      "epoch 25; iter: 0; batch classifier loss: 0.377181; batch adversarial loss: 0.531906\n",
      "epoch 26; iter: 0; batch classifier loss: 0.503288; batch adversarial loss: 0.524538\n",
      "epoch 27; iter: 0; batch classifier loss: 0.522892; batch adversarial loss: 0.612414\n",
      "epoch 28; iter: 0; batch classifier loss: 0.530025; batch adversarial loss: 0.492594\n",
      "epoch 29; iter: 0; batch classifier loss: 0.434879; batch adversarial loss: 0.587777\n",
      "epoch 30; iter: 0; batch classifier loss: 0.494130; batch adversarial loss: 0.572047\n",
      "epoch 31; iter: 0; batch classifier loss: 0.603993; batch adversarial loss: 0.539114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483331; batch adversarial loss: 0.593384\n",
      "epoch 33; iter: 0; batch classifier loss: 0.431476; batch adversarial loss: 0.489331\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447429; batch adversarial loss: 0.561563\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471096; batch adversarial loss: 0.585913\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474710; batch adversarial loss: 0.572322\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440396; batch adversarial loss: 0.508250\n",
      "epoch 38; iter: 0; batch classifier loss: 0.404094; batch adversarial loss: 0.564404\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463451; batch adversarial loss: 0.614824\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481948; batch adversarial loss: 0.503604\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459018; batch adversarial loss: 0.579972\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474037; batch adversarial loss: 0.610627\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423271; batch adversarial loss: 0.489225\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455227; batch adversarial loss: 0.527464\n",
      "epoch 45; iter: 0; batch classifier loss: 0.495493; batch adversarial loss: 0.583626\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433754; batch adversarial loss: 0.543839\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439997; batch adversarial loss: 0.584304\n",
      "epoch 48; iter: 0; batch classifier loss: 0.376211; batch adversarial loss: 0.501383\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446654; batch adversarial loss: 0.562123\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433500; batch adversarial loss: 0.588961\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464131; batch adversarial loss: 0.472298\n",
      "epoch 52; iter: 0; batch classifier loss: 0.472480; batch adversarial loss: 0.517368\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439795; batch adversarial loss: 0.544539\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451798; batch adversarial loss: 0.498882\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396799; batch adversarial loss: 0.508032\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427812; batch adversarial loss: 0.471689\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459716; batch adversarial loss: 0.525999\n",
      "epoch 58; iter: 0; batch classifier loss: 0.382926; batch adversarial loss: 0.571179\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387700; batch adversarial loss: 0.525750\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456949; batch adversarial loss: 0.553359\n",
      "epoch 61; iter: 0; batch classifier loss: 0.365333; batch adversarial loss: 0.526214\n",
      "epoch 62; iter: 0; batch classifier loss: 0.332207; batch adversarial loss: 0.561925\n",
      "epoch 63; iter: 0; batch classifier loss: 0.353438; batch adversarial loss: 0.554998\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409919; batch adversarial loss: 0.496788\n",
      "epoch 65; iter: 0; batch classifier loss: 0.321622; batch adversarial loss: 0.564409\n",
      "epoch 66; iter: 0; batch classifier loss: 0.500422; batch adversarial loss: 0.541966\n",
      "epoch 67; iter: 0; batch classifier loss: 0.486286; batch adversarial loss: 0.497543\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410380; batch adversarial loss: 0.544922\n",
      "epoch 69; iter: 0; batch classifier loss: 0.454013; batch adversarial loss: 0.562731\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368082; batch adversarial loss: 0.497355\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404382; batch adversarial loss: 0.582060\n",
      "epoch 72; iter: 0; batch classifier loss: 0.349191; batch adversarial loss: 0.560630\n",
      "epoch 73; iter: 0; batch classifier loss: 0.475797; batch adversarial loss: 0.581289\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393418; batch adversarial loss: 0.515876\n",
      "epoch 75; iter: 0; batch classifier loss: 0.503523; batch adversarial loss: 0.536403\n",
      "epoch 76; iter: 0; batch classifier loss: 0.429733; batch adversarial loss: 0.553024\n",
      "epoch 77; iter: 0; batch classifier loss: 0.252369; batch adversarial loss: 0.507657\n",
      "epoch 78; iter: 0; batch classifier loss: 0.333480; batch adversarial loss: 0.478108\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411909; batch adversarial loss: 0.516488\n",
      "epoch 80; iter: 0; batch classifier loss: 0.391194; batch adversarial loss: 0.532412\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378785; batch adversarial loss: 0.485682\n",
      "epoch 82; iter: 0; batch classifier loss: 0.507449; batch adversarial loss: 0.602645\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411919; batch adversarial loss: 0.536580\n",
      "epoch 84; iter: 0; batch classifier loss: 0.369123; batch adversarial loss: 0.488245\n",
      "epoch 85; iter: 0; batch classifier loss: 0.310740; batch adversarial loss: 0.534582\n",
      "epoch 86; iter: 0; batch classifier loss: 0.482833; batch adversarial loss: 0.556740\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404090; batch adversarial loss: 0.532212\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351956; batch adversarial loss: 0.570748\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386888; batch adversarial loss: 0.518933\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390061; batch adversarial loss: 0.562141\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399357; batch adversarial loss: 0.543982\n",
      "epoch 92; iter: 0; batch classifier loss: 0.495857; batch adversarial loss: 0.625974\n",
      "epoch 93; iter: 0; batch classifier loss: 0.354344; batch adversarial loss: 0.581248\n",
      "epoch 94; iter: 0; batch classifier loss: 0.500036; batch adversarial loss: 0.517142\n",
      "epoch 95; iter: 0; batch classifier loss: 0.374468; batch adversarial loss: 0.551865\n",
      "epoch 96; iter: 0; batch classifier loss: 0.483750; batch adversarial loss: 0.517034\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359317; batch adversarial loss: 0.526384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.389217; batch adversarial loss: 0.516299\n",
      "epoch 99; iter: 0; batch classifier loss: 0.299223; batch adversarial loss: 0.480960\n",
      "epoch 100; iter: 0; batch classifier loss: 0.331882; batch adversarial loss: 0.523104\n",
      "epoch 101; iter: 0; batch classifier loss: 0.375431; batch adversarial loss: 0.534437\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382276; batch adversarial loss: 0.583488\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378906; batch adversarial loss: 0.534908\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389916; batch adversarial loss: 0.495809\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347300; batch adversarial loss: 0.590045\n",
      "epoch 106; iter: 0; batch classifier loss: 0.433471; batch adversarial loss: 0.515880\n",
      "epoch 107; iter: 0; batch classifier loss: 0.416843; batch adversarial loss: 0.516801\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435153; batch adversarial loss: 0.594221\n",
      "epoch 109; iter: 0; batch classifier loss: 0.427754; batch adversarial loss: 0.571971\n",
      "epoch 110; iter: 0; batch classifier loss: 0.321166; batch adversarial loss: 0.623720\n",
      "epoch 111; iter: 0; batch classifier loss: 0.441452; batch adversarial loss: 0.523278\n",
      "epoch 112; iter: 0; batch classifier loss: 0.407838; batch adversarial loss: 0.589695\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368273; batch adversarial loss: 0.533082\n",
      "epoch 114; iter: 0; batch classifier loss: 0.455445; batch adversarial loss: 0.528323\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379082; batch adversarial loss: 0.561510\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382952; batch adversarial loss: 0.590869\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389492; batch adversarial loss: 0.554079\n",
      "epoch 118; iter: 0; batch classifier loss: 0.353331; batch adversarial loss: 0.535708\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394542; batch adversarial loss: 0.506517\n",
      "epoch 120; iter: 0; batch classifier loss: 0.333406; batch adversarial loss: 0.545147\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360981; batch adversarial loss: 0.527977\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384049; batch adversarial loss: 0.552799\n",
      "epoch 123; iter: 0; batch classifier loss: 0.304955; batch adversarial loss: 0.601190\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391351; batch adversarial loss: 0.499912\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409736; batch adversarial loss: 0.582422\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379521; batch adversarial loss: 0.543464\n",
      "epoch 127; iter: 0; batch classifier loss: 0.319486; batch adversarial loss: 0.506402\n",
      "epoch 128; iter: 0; batch classifier loss: 0.488859; batch adversarial loss: 0.620684\n",
      "epoch 129; iter: 0; batch classifier loss: 0.479560; batch adversarial loss: 0.515898\n",
      "epoch 130; iter: 0; batch classifier loss: 0.343632; batch adversarial loss: 0.543962\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347346; batch adversarial loss: 0.545232\n",
      "epoch 132; iter: 0; batch classifier loss: 0.411526; batch adversarial loss: 0.542902\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347449; batch adversarial loss: 0.496548\n",
      "epoch 134; iter: 0; batch classifier loss: 0.362484; batch adversarial loss: 0.507743\n",
      "epoch 135; iter: 0; batch classifier loss: 0.421177; batch adversarial loss: 0.546309\n",
      "epoch 136; iter: 0; batch classifier loss: 0.440267; batch adversarial loss: 0.625673\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348454; batch adversarial loss: 0.551301\n",
      "epoch 138; iter: 0; batch classifier loss: 0.423989; batch adversarial loss: 0.543662\n",
      "epoch 139; iter: 0; batch classifier loss: 0.320514; batch adversarial loss: 0.516447\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346890; batch adversarial loss: 0.495361\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348012; batch adversarial loss: 0.498087\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339366; batch adversarial loss: 0.545807\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364859; batch adversarial loss: 0.537441\n",
      "epoch 144; iter: 0; batch classifier loss: 0.274158; batch adversarial loss: 0.608073\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327653; batch adversarial loss: 0.552729\n",
      "epoch 146; iter: 0; batch classifier loss: 0.307464; batch adversarial loss: 0.499049\n",
      "epoch 147; iter: 0; batch classifier loss: 0.278502; batch adversarial loss: 0.634920\n",
      "epoch 148; iter: 0; batch classifier loss: 0.383493; batch adversarial loss: 0.601237\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314677; batch adversarial loss: 0.516305\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379767; batch adversarial loss: 0.571778\n",
      "epoch 151; iter: 0; batch classifier loss: 0.328552; batch adversarial loss: 0.571917\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341482; batch adversarial loss: 0.506400\n",
      "epoch 153; iter: 0; batch classifier loss: 0.302812; batch adversarial loss: 0.554148\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354352; batch adversarial loss: 0.533999\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392657; batch adversarial loss: 0.612223\n",
      "epoch 156; iter: 0; batch classifier loss: 0.405199; batch adversarial loss: 0.553160\n",
      "epoch 157; iter: 0; batch classifier loss: 0.402707; batch adversarial loss: 0.507445\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336468; batch adversarial loss: 0.573994\n",
      "epoch 159; iter: 0; batch classifier loss: 0.392831; batch adversarial loss: 0.526319\n",
      "epoch 160; iter: 0; batch classifier loss: 0.388012; batch adversarial loss: 0.562347\n",
      "epoch 161; iter: 0; batch classifier loss: 0.384022; batch adversarial loss: 0.579664\n",
      "epoch 162; iter: 0; batch classifier loss: 0.315525; batch adversarial loss: 0.520383\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384381; batch adversarial loss: 0.535067\n",
      "epoch 164; iter: 0; batch classifier loss: 0.446317; batch adversarial loss: 0.546170\n",
      "epoch 165; iter: 0; batch classifier loss: 0.357310; batch adversarial loss: 0.565032\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347801; batch adversarial loss: 0.461973\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345753; batch adversarial loss: 0.598843\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398330; batch adversarial loss: 0.516518\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392040; batch adversarial loss: 0.489885\n",
      "epoch 170; iter: 0; batch classifier loss: 0.446902; batch adversarial loss: 0.543107\n",
      "epoch 171; iter: 0; batch classifier loss: 0.393135; batch adversarial loss: 0.582177\n",
      "epoch 172; iter: 0; batch classifier loss: 0.340690; batch adversarial loss: 0.536321\n",
      "epoch 173; iter: 0; batch classifier loss: 0.450387; batch adversarial loss: 0.607769\n",
      "epoch 174; iter: 0; batch classifier loss: 0.352762; batch adversarial loss: 0.506658\n",
      "epoch 175; iter: 0; batch classifier loss: 0.298921; batch adversarial loss: 0.554843\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382277; batch adversarial loss: 0.508751\n",
      "epoch 177; iter: 0; batch classifier loss: 0.341220; batch adversarial loss: 0.562460\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323563; batch adversarial loss: 0.496199\n",
      "epoch 179; iter: 0; batch classifier loss: 0.326291; batch adversarial loss: 0.552381\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378121; batch adversarial loss: 0.595789\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339186; batch adversarial loss: 0.543135\n",
      "epoch 182; iter: 0; batch classifier loss: 0.388710; batch adversarial loss: 0.517517\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324132; batch adversarial loss: 0.579142\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404760; batch adversarial loss: 0.546494\n",
      "epoch 185; iter: 0; batch classifier loss: 0.344041; batch adversarial loss: 0.481812\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363675; batch adversarial loss: 0.499018\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343897; batch adversarial loss: 0.609260\n",
      "epoch 188; iter: 0; batch classifier loss: 0.397006; batch adversarial loss: 0.524639\n",
      "epoch 189; iter: 0; batch classifier loss: 0.313171; batch adversarial loss: 0.590487\n",
      "epoch 190; iter: 0; batch classifier loss: 0.400594; batch adversarial loss: 0.534532\n",
      "epoch 191; iter: 0; batch classifier loss: 0.439356; batch adversarial loss: 0.498910\n",
      "epoch 192; iter: 0; batch classifier loss: 0.285371; batch adversarial loss: 0.533266\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362204; batch adversarial loss: 0.550352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.355658; batch adversarial loss: 0.523658\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370687; batch adversarial loss: 0.592286\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358526; batch adversarial loss: 0.535579\n",
      "epoch 197; iter: 0; batch classifier loss: 0.398981; batch adversarial loss: 0.635831\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348481; batch adversarial loss: 0.572986\n",
      "epoch 199; iter: 0; batch classifier loss: 0.411463; batch adversarial loss: 0.532719\n",
      "epoch 0; iter: 0; batch classifier loss: 0.776339; batch adversarial loss: 0.775998\n",
      "epoch 1; iter: 0; batch classifier loss: 0.639363; batch adversarial loss: 0.718132\n",
      "epoch 2; iter: 0; batch classifier loss: 0.701308; batch adversarial loss: 0.682658\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558434; batch adversarial loss: 0.631528\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619301; batch adversarial loss: 0.641734\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553365; batch adversarial loss: 0.609527\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571655; batch adversarial loss: 0.604763\n",
      "epoch 7; iter: 0; batch classifier loss: 0.479288; batch adversarial loss: 0.618013\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537562; batch adversarial loss: 0.607522\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503091; batch adversarial loss: 0.548474\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503239; batch adversarial loss: 0.554642\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555569; batch adversarial loss: 0.550264\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549732; batch adversarial loss: 0.542894\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495224; batch adversarial loss: 0.588006\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491526; batch adversarial loss: 0.530881\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493744; batch adversarial loss: 0.499558\n",
      "epoch 16; iter: 0; batch classifier loss: 0.555271; batch adversarial loss: 0.557366\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503183; batch adversarial loss: 0.509103\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507113; batch adversarial loss: 0.516999\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443321; batch adversarial loss: 0.502260\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468739; batch adversarial loss: 0.541319\n",
      "epoch 21; iter: 0; batch classifier loss: 0.535284; batch adversarial loss: 0.515002\n",
      "epoch 22; iter: 0; batch classifier loss: 0.533712; batch adversarial loss: 0.544107\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488812; batch adversarial loss: 0.561471\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465247; batch adversarial loss: 0.523808\n",
      "epoch 25; iter: 0; batch classifier loss: 0.514698; batch adversarial loss: 0.536877\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478589; batch adversarial loss: 0.594079\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473058; batch adversarial loss: 0.514176\n",
      "epoch 28; iter: 0; batch classifier loss: 0.566752; batch adversarial loss: 0.565848\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460022; batch adversarial loss: 0.556483\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440696; batch adversarial loss: 0.549312\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453161; batch adversarial loss: 0.521632\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420041; batch adversarial loss: 0.557829\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509935; batch adversarial loss: 0.539160\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459284; batch adversarial loss: 0.556895\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407852; batch adversarial loss: 0.570771\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474744; batch adversarial loss: 0.571944\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460689; batch adversarial loss: 0.573825\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486703; batch adversarial loss: 0.561852\n",
      "epoch 39; iter: 0; batch classifier loss: 0.524959; batch adversarial loss: 0.510700\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435022; batch adversarial loss: 0.580387\n",
      "epoch 41; iter: 0; batch classifier loss: 0.391500; batch adversarial loss: 0.509871\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501233; batch adversarial loss: 0.544547\n",
      "epoch 43; iter: 0; batch classifier loss: 0.448309; batch adversarial loss: 0.597726\n",
      "epoch 44; iter: 0; batch classifier loss: 0.381414; batch adversarial loss: 0.598297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.344999; batch adversarial loss: 0.634654\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432362; batch adversarial loss: 0.535366\n",
      "epoch 47; iter: 0; batch classifier loss: 0.497561; batch adversarial loss: 0.490451\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445859; batch adversarial loss: 0.517379\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415603; batch adversarial loss: 0.590032\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413676; batch adversarial loss: 0.544549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.395859; batch adversarial loss: 0.590327\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437974; batch adversarial loss: 0.545010\n",
      "epoch 53; iter: 0; batch classifier loss: 0.351015; batch adversarial loss: 0.535008\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411475; batch adversarial loss: 0.444050\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426630; batch adversarial loss: 0.553154\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405274; batch adversarial loss: 0.479136\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442172; batch adversarial loss: 0.545135\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431122; batch adversarial loss: 0.570879\n",
      "epoch 59; iter: 0; batch classifier loss: 0.474480; batch adversarial loss: 0.544855\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444628; batch adversarial loss: 0.526245\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439610; batch adversarial loss: 0.526161\n",
      "epoch 62; iter: 0; batch classifier loss: 0.327450; batch adversarial loss: 0.554014\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395606; batch adversarial loss: 0.563859\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394278; batch adversarial loss: 0.490146\n",
      "epoch 65; iter: 0; batch classifier loss: 0.363509; batch adversarial loss: 0.471984\n",
      "epoch 66; iter: 0; batch classifier loss: 0.358365; batch adversarial loss: 0.507718\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363271; batch adversarial loss: 0.616592\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375965; batch adversarial loss: 0.480353\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429805; batch adversarial loss: 0.526152\n",
      "epoch 70; iter: 0; batch classifier loss: 0.348906; batch adversarial loss: 0.553040\n",
      "epoch 71; iter: 0; batch classifier loss: 0.443442; batch adversarial loss: 0.470414\n",
      "epoch 72; iter: 0; batch classifier loss: 0.378938; batch adversarial loss: 0.553185\n",
      "epoch 73; iter: 0; batch classifier loss: 0.413298; batch adversarial loss: 0.526301\n",
      "epoch 74; iter: 0; batch classifier loss: 0.358034; batch adversarial loss: 0.505904\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430788; batch adversarial loss: 0.580421\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441991; batch adversarial loss: 0.517152\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375440; batch adversarial loss: 0.545025\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368829; batch adversarial loss: 0.515889\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393675; batch adversarial loss: 0.516891\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374700; batch adversarial loss: 0.516857\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445778; batch adversarial loss: 0.580194\n",
      "epoch 82; iter: 0; batch classifier loss: 0.360129; batch adversarial loss: 0.627226\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400373; batch adversarial loss: 0.583702\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416418; batch adversarial loss: 0.492064\n",
      "epoch 85; iter: 0; batch classifier loss: 0.358126; batch adversarial loss: 0.572215\n",
      "epoch 86; iter: 0; batch classifier loss: 0.343232; batch adversarial loss: 0.589707\n",
      "epoch 87; iter: 0; batch classifier loss: 0.379098; batch adversarial loss: 0.507842\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362340; batch adversarial loss: 0.552845\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391824; batch adversarial loss: 0.524533\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390396; batch adversarial loss: 0.564219\n",
      "epoch 91; iter: 0; batch classifier loss: 0.458460; batch adversarial loss: 0.544715\n",
      "epoch 92; iter: 0; batch classifier loss: 0.460284; batch adversarial loss: 0.581206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.444597; batch adversarial loss: 0.488923\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362934; batch adversarial loss: 0.580944\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358334; batch adversarial loss: 0.535637\n",
      "epoch 96; iter: 0; batch classifier loss: 0.342632; batch adversarial loss: 0.573569\n",
      "epoch 97; iter: 0; batch classifier loss: 0.424106; batch adversarial loss: 0.536025\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364661; batch adversarial loss: 0.561684\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348353; batch adversarial loss: 0.571869\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373464; batch adversarial loss: 0.599021\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394737; batch adversarial loss: 0.544314\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365729; batch adversarial loss: 0.590589\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361940; batch adversarial loss: 0.599793\n",
      "epoch 104; iter: 0; batch classifier loss: 0.458013; batch adversarial loss: 0.489026\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442687; batch adversarial loss: 0.500529\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421199; batch adversarial loss: 0.461588\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396641; batch adversarial loss: 0.544415\n",
      "epoch 108; iter: 0; batch classifier loss: 0.365269; batch adversarial loss: 0.517125\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388982; batch adversarial loss: 0.515718\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397658; batch adversarial loss: 0.415442\n",
      "epoch 111; iter: 0; batch classifier loss: 0.338401; batch adversarial loss: 0.571813\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398657; batch adversarial loss: 0.592219\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358797; batch adversarial loss: 0.508411\n",
      "epoch 114; iter: 0; batch classifier loss: 0.409390; batch adversarial loss: 0.554086\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387293; batch adversarial loss: 0.554248\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368631; batch adversarial loss: 0.592617\n",
      "epoch 117; iter: 0; batch classifier loss: 0.437484; batch adversarial loss: 0.489280\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406059; batch adversarial loss: 0.526268\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364792; batch adversarial loss: 0.526781\n",
      "epoch 120; iter: 0; batch classifier loss: 0.324863; batch adversarial loss: 0.572896\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370675; batch adversarial loss: 0.564076\n",
      "epoch 122; iter: 0; batch classifier loss: 0.309973; batch adversarial loss: 0.488229\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367583; batch adversarial loss: 0.544716\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365364; batch adversarial loss: 0.497955\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391808; batch adversarial loss: 0.607089\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350451; batch adversarial loss: 0.525897\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355932; batch adversarial loss: 0.543882\n",
      "epoch 128; iter: 0; batch classifier loss: 0.336141; batch adversarial loss: 0.507379\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319386; batch adversarial loss: 0.589472\n",
      "epoch 130; iter: 0; batch classifier loss: 0.431017; batch adversarial loss: 0.506507\n",
      "epoch 131; iter: 0; batch classifier loss: 0.467812; batch adversarial loss: 0.497179\n",
      "epoch 132; iter: 0; batch classifier loss: 0.265505; batch adversarial loss: 0.534182\n",
      "epoch 133; iter: 0; batch classifier loss: 0.458700; batch adversarial loss: 0.489903\n",
      "epoch 134; iter: 0; batch classifier loss: 0.436184; batch adversarial loss: 0.572528\n",
      "epoch 135; iter: 0; batch classifier loss: 0.307042; batch adversarial loss: 0.572489\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358100; batch adversarial loss: 0.534351\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374594; batch adversarial loss: 0.598803\n",
      "epoch 138; iter: 0; batch classifier loss: 0.440848; batch adversarial loss: 0.663954\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334698; batch adversarial loss: 0.582961\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358917; batch adversarial loss: 0.562146\n",
      "epoch 141; iter: 0; batch classifier loss: 0.420047; batch adversarial loss: 0.498050\n",
      "epoch 142; iter: 0; batch classifier loss: 0.286718; batch adversarial loss: 0.553181\n",
      "epoch 143; iter: 0; batch classifier loss: 0.292861; batch adversarial loss: 0.506653\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341970; batch adversarial loss: 0.525241\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365342; batch adversarial loss: 0.524281\n",
      "epoch 146; iter: 0; batch classifier loss: 0.457427; batch adversarial loss: 0.572809\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327182; batch adversarial loss: 0.591643\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342037; batch adversarial loss: 0.645277\n",
      "epoch 149; iter: 0; batch classifier loss: 0.326746; batch adversarial loss: 0.526222\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358677; batch adversarial loss: 0.516684\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356049; batch adversarial loss: 0.517676\n",
      "epoch 152; iter: 0; batch classifier loss: 0.324131; batch adversarial loss: 0.498201\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371254; batch adversarial loss: 0.499558\n",
      "epoch 154; iter: 0; batch classifier loss: 0.473377; batch adversarial loss: 0.570334\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316269; batch adversarial loss: 0.516813\n",
      "epoch 156; iter: 0; batch classifier loss: 0.425078; batch adversarial loss: 0.508517\n",
      "epoch 157; iter: 0; batch classifier loss: 0.327800; batch adversarial loss: 0.570972\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329250; batch adversarial loss: 0.589110\n",
      "epoch 159; iter: 0; batch classifier loss: 0.304202; batch adversarial loss: 0.535394\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406439; batch adversarial loss: 0.499403\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357014; batch adversarial loss: 0.461984\n",
      "epoch 162; iter: 0; batch classifier loss: 0.297146; batch adversarial loss: 0.570917\n",
      "epoch 163; iter: 0; batch classifier loss: 0.415416; batch adversarial loss: 0.526433\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402882; batch adversarial loss: 0.499120\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358912; batch adversarial loss: 0.545226\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335819; batch adversarial loss: 0.498689\n",
      "epoch 167; iter: 0; batch classifier loss: 0.328717; batch adversarial loss: 0.470307\n",
      "epoch 168; iter: 0; batch classifier loss: 0.391329; batch adversarial loss: 0.488898\n",
      "epoch 169; iter: 0; batch classifier loss: 0.426973; batch adversarial loss: 0.552934\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398106; batch adversarial loss: 0.592070\n",
      "epoch 171; iter: 0; batch classifier loss: 0.350528; batch adversarial loss: 0.608990\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353915; batch adversarial loss: 0.525395\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375838; batch adversarial loss: 0.552563\n",
      "epoch 174; iter: 0; batch classifier loss: 0.330097; batch adversarial loss: 0.515898\n",
      "epoch 175; iter: 0; batch classifier loss: 0.310723; batch adversarial loss: 0.535220\n",
      "epoch 176; iter: 0; batch classifier loss: 0.309110; batch adversarial loss: 0.656995\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371121; batch adversarial loss: 0.572190\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362145; batch adversarial loss: 0.517334\n",
      "epoch 179; iter: 0; batch classifier loss: 0.308694; batch adversarial loss: 0.515506\n",
      "epoch 180; iter: 0; batch classifier loss: 0.317238; batch adversarial loss: 0.535757\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337115; batch adversarial loss: 0.534863\n",
      "epoch 182; iter: 0; batch classifier loss: 0.291552; batch adversarial loss: 0.580486\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345056; batch adversarial loss: 0.488447\n",
      "epoch 184; iter: 0; batch classifier loss: 0.295001; batch adversarial loss: 0.517695\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281866; batch adversarial loss: 0.562750\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404925; batch adversarial loss: 0.506670\n",
      "epoch 187; iter: 0; batch classifier loss: 0.299194; batch adversarial loss: 0.618624\n",
      "epoch 188; iter: 0; batch classifier loss: 0.315998; batch adversarial loss: 0.498669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.306574; batch adversarial loss: 0.599249\n",
      "epoch 190; iter: 0; batch classifier loss: 0.287620; batch adversarial loss: 0.544102\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331416; batch adversarial loss: 0.563277\n",
      "epoch 192; iter: 0; batch classifier loss: 0.346425; batch adversarial loss: 0.479539\n",
      "epoch 193; iter: 0; batch classifier loss: 0.421359; batch adversarial loss: 0.554796\n",
      "epoch 194; iter: 0; batch classifier loss: 0.337067; batch adversarial loss: 0.563699\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393144; batch adversarial loss: 0.561241\n",
      "epoch 196; iter: 0; batch classifier loss: 0.390633; batch adversarial loss: 0.479746\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347241; batch adversarial loss: 0.580477\n",
      "epoch 198; iter: 0; batch classifier loss: 0.298120; batch adversarial loss: 0.444079\n",
      "epoch 199; iter: 0; batch classifier loss: 0.344795; batch adversarial loss: 0.508587\n",
      "epoch 0; iter: 0; batch classifier loss: 0.760796; batch adversarial loss: 0.601255\n",
      "epoch 1; iter: 0; batch classifier loss: 0.652547; batch adversarial loss: 0.661342\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599894; batch adversarial loss: 0.615579\n",
      "epoch 3; iter: 0; batch classifier loss: 0.664249; batch adversarial loss: 0.649406\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586632; batch adversarial loss: 0.647856\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540758; batch adversarial loss: 0.657256\n",
      "epoch 6; iter: 0; batch classifier loss: 0.622216; batch adversarial loss: 0.660501\n",
      "epoch 7; iter: 0; batch classifier loss: 0.640263; batch adversarial loss: 0.621681\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634414; batch adversarial loss: 0.612745\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600818; batch adversarial loss: 0.596669\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569029; batch adversarial loss: 0.580220\n",
      "epoch 11; iter: 0; batch classifier loss: 0.604873; batch adversarial loss: 0.613016\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586295; batch adversarial loss: 0.605502\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536603; batch adversarial loss: 0.636644\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531883; batch adversarial loss: 0.596483\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473832; batch adversarial loss: 0.535968\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520298; batch adversarial loss: 0.597855\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524882; batch adversarial loss: 0.514731\n",
      "epoch 18; iter: 0; batch classifier loss: 0.546153; batch adversarial loss: 0.579113\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448263; batch adversarial loss: 0.524486\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509700; batch adversarial loss: 0.672181\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519251; batch adversarial loss: 0.634185\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469269; batch adversarial loss: 0.571206\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463062; batch adversarial loss: 0.545665\n",
      "epoch 24; iter: 0; batch classifier loss: 0.521397; batch adversarial loss: 0.531949\n",
      "epoch 25; iter: 0; batch classifier loss: 0.402580; batch adversarial loss: 0.643660\n",
      "epoch 26; iter: 0; batch classifier loss: 0.454825; batch adversarial loss: 0.568873\n",
      "epoch 27; iter: 0; batch classifier loss: 0.531507; batch adversarial loss: 0.497007\n",
      "epoch 28; iter: 0; batch classifier loss: 0.517920; batch adversarial loss: 0.493527\n",
      "epoch 29; iter: 0; batch classifier loss: 0.491154; batch adversarial loss: 0.484935\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467845; batch adversarial loss: 0.571112\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459200; batch adversarial loss: 0.553387\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467315; batch adversarial loss: 0.562792\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477678; batch adversarial loss: 0.581033\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473862; batch adversarial loss: 0.552597\n",
      "epoch 35; iter: 0; batch classifier loss: 0.462113; batch adversarial loss: 0.615849\n",
      "epoch 36; iter: 0; batch classifier loss: 0.519448; batch adversarial loss: 0.498820\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475669; batch adversarial loss: 0.523362\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484646; batch adversarial loss: 0.572606\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458862; batch adversarial loss: 0.556276\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468433; batch adversarial loss: 0.523783\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408779; batch adversarial loss: 0.572208\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495796; batch adversarial loss: 0.596981\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480769; batch adversarial loss: 0.606289\n",
      "epoch 44; iter: 0; batch classifier loss: 0.541474; batch adversarial loss: 0.597861\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429665; batch adversarial loss: 0.571194\n",
      "epoch 46; iter: 0; batch classifier loss: 0.449436; batch adversarial loss: 0.560936\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424009; batch adversarial loss: 0.545891\n",
      "epoch 48; iter: 0; batch classifier loss: 0.477396; batch adversarial loss: 0.520207\n",
      "epoch 49; iter: 0; batch classifier loss: 0.482216; batch adversarial loss: 0.569930\n",
      "epoch 50; iter: 0; batch classifier loss: 0.524766; batch adversarial loss: 0.571685\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430637; batch adversarial loss: 0.500569\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385518; batch adversarial loss: 0.493797\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441734; batch adversarial loss: 0.622428\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469538; batch adversarial loss: 0.546037\n",
      "epoch 55; iter: 0; batch classifier loss: 0.477309; batch adversarial loss: 0.693007\n",
      "epoch 56; iter: 0; batch classifier loss: 0.477772; batch adversarial loss: 0.536754\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426965; batch adversarial loss: 0.537152\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438564; batch adversarial loss: 0.536982\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407193; batch adversarial loss: 0.605824\n",
      "epoch 60; iter: 0; batch classifier loss: 0.463760; batch adversarial loss: 0.458080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.525066; batch adversarial loss: 0.570786\n",
      "epoch 62; iter: 0; batch classifier loss: 0.477546; batch adversarial loss: 0.570678\n",
      "epoch 63; iter: 0; batch classifier loss: 0.471635; batch adversarial loss: 0.509081\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411837; batch adversarial loss: 0.554660\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370902; batch adversarial loss: 0.544393\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404062; batch adversarial loss: 0.562060\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410270; batch adversarial loss: 0.624131\n",
      "epoch 68; iter: 0; batch classifier loss: 0.371473; batch adversarial loss: 0.597129\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393586; batch adversarial loss: 0.570466\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421466; batch adversarial loss: 0.519120\n",
      "epoch 71; iter: 0; batch classifier loss: 0.472778; batch adversarial loss: 0.527564\n",
      "epoch 72; iter: 0; batch classifier loss: 0.384232; batch adversarial loss: 0.553753\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389807; batch adversarial loss: 0.475483\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417181; batch adversarial loss: 0.605966\n",
      "epoch 75; iter: 0; batch classifier loss: 0.410084; batch adversarial loss: 0.544918\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372466; batch adversarial loss: 0.517822\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412935; batch adversarial loss: 0.606066\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362839; batch adversarial loss: 0.518430\n",
      "epoch 79; iter: 0; batch classifier loss: 0.510902; batch adversarial loss: 0.562450\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437271; batch adversarial loss: 0.553685\n",
      "epoch 81; iter: 0; batch classifier loss: 0.468222; batch adversarial loss: 0.553566\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363072; batch adversarial loss: 0.518641\n",
      "epoch 83; iter: 0; batch classifier loss: 0.477817; batch adversarial loss: 0.500529\n",
      "epoch 84; iter: 0; batch classifier loss: 0.434905; batch adversarial loss: 0.580733\n",
      "epoch 85; iter: 0; batch classifier loss: 0.319278; batch adversarial loss: 0.590042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.452345; batch adversarial loss: 0.537389\n",
      "epoch 87; iter: 0; batch classifier loss: 0.421700; batch adversarial loss: 0.562325\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389944; batch adversarial loss: 0.493549\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368406; batch adversarial loss: 0.475958\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371773; batch adversarial loss: 0.510536\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396251; batch adversarial loss: 0.536408\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418414; batch adversarial loss: 0.623122\n",
      "epoch 93; iter: 0; batch classifier loss: 0.358790; batch adversarial loss: 0.501625\n",
      "epoch 94; iter: 0; batch classifier loss: 0.468529; batch adversarial loss: 0.492126\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419770; batch adversarial loss: 0.544841\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364643; batch adversarial loss: 0.474689\n",
      "epoch 97; iter: 0; batch classifier loss: 0.455428; batch adversarial loss: 0.510442\n",
      "epoch 98; iter: 0; batch classifier loss: 0.433323; batch adversarial loss: 0.536197\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386325; batch adversarial loss: 0.622954\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348260; batch adversarial loss: 0.614587\n",
      "epoch 101; iter: 0; batch classifier loss: 0.446289; batch adversarial loss: 0.580204\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397224; batch adversarial loss: 0.553463\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409619; batch adversarial loss: 0.606503\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375274; batch adversarial loss: 0.552896\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409937; batch adversarial loss: 0.562085\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388904; batch adversarial loss: 0.484690\n",
      "epoch 107; iter: 0; batch classifier loss: 0.389403; batch adversarial loss: 0.536633\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387728; batch adversarial loss: 0.605732\n",
      "epoch 109; iter: 0; batch classifier loss: 0.328355; batch adversarial loss: 0.467088\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386232; batch adversarial loss: 0.588368\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369571; batch adversarial loss: 0.562719\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385289; batch adversarial loss: 0.518473\n",
      "epoch 113; iter: 0; batch classifier loss: 0.361599; batch adversarial loss: 0.580085\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402593; batch adversarial loss: 0.562069\n",
      "epoch 115; iter: 0; batch classifier loss: 0.450706; batch adversarial loss: 0.475652\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410214; batch adversarial loss: 0.579573\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392460; batch adversarial loss: 0.552557\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384654; batch adversarial loss: 0.614841\n",
      "epoch 119; iter: 0; batch classifier loss: 0.306069; batch adversarial loss: 0.561660\n",
      "epoch 120; iter: 0; batch classifier loss: 0.438006; batch adversarial loss: 0.588207\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383971; batch adversarial loss: 0.536291\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377621; batch adversarial loss: 0.553632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372685; batch adversarial loss: 0.553360\n",
      "epoch 124; iter: 0; batch classifier loss: 0.423831; batch adversarial loss: 0.536447\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394841; batch adversarial loss: 0.588257\n",
      "epoch 126; iter: 0; batch classifier loss: 0.465921; batch adversarial loss: 0.597734\n",
      "epoch 127; iter: 0; batch classifier loss: 0.289932; batch adversarial loss: 0.606328\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389397; batch adversarial loss: 0.571261\n",
      "epoch 129; iter: 0; batch classifier loss: 0.328319; batch adversarial loss: 0.536028\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364658; batch adversarial loss: 0.518168\n",
      "epoch 131; iter: 0; batch classifier loss: 0.390116; batch adversarial loss: 0.536368\n",
      "epoch 132; iter: 0; batch classifier loss: 0.378440; batch adversarial loss: 0.588593\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335183; batch adversarial loss: 0.598065\n",
      "epoch 134; iter: 0; batch classifier loss: 0.326232; batch adversarial loss: 0.553637\n",
      "epoch 135; iter: 0; batch classifier loss: 0.305505; batch adversarial loss: 0.580293\n",
      "epoch 136; iter: 0; batch classifier loss: 0.266170; batch adversarial loss: 0.501064\n",
      "epoch 137; iter: 0; batch classifier loss: 0.307290; batch adversarial loss: 0.543835\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365523; batch adversarial loss: 0.623512\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374895; batch adversarial loss: 0.534835\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399699; batch adversarial loss: 0.579665\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400495; batch adversarial loss: 0.544822\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320809; batch adversarial loss: 0.492664\n",
      "epoch 143; iter: 0; batch classifier loss: 0.460429; batch adversarial loss: 0.562611\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374371; batch adversarial loss: 0.510074\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390849; batch adversarial loss: 0.545038\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347955; batch adversarial loss: 0.597095\n",
      "epoch 147; iter: 0; batch classifier loss: 0.330417; batch adversarial loss: 0.554109\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370013; batch adversarial loss: 0.614972\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405720; batch adversarial loss: 0.615256\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353094; batch adversarial loss: 0.606156\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375249; batch adversarial loss: 0.588381\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357478; batch adversarial loss: 0.553490\n",
      "epoch 153; iter: 0; batch classifier loss: 0.403764; batch adversarial loss: 0.588732\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353829; batch adversarial loss: 0.623706\n",
      "epoch 155; iter: 0; batch classifier loss: 0.407068; batch adversarial loss: 0.606203\n",
      "epoch 156; iter: 0; batch classifier loss: 0.296398; batch adversarial loss: 0.579317\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324293; batch adversarial loss: 0.615160\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403030; batch adversarial loss: 0.588880\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338560; batch adversarial loss: 0.483494\n",
      "epoch 160; iter: 0; batch classifier loss: 0.355551; batch adversarial loss: 0.587708\n",
      "epoch 161; iter: 0; batch classifier loss: 0.405928; batch adversarial loss: 0.545285\n",
      "epoch 162; iter: 0; batch classifier loss: 0.290792; batch adversarial loss: 0.562613\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361371; batch adversarial loss: 0.571075\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380249; batch adversarial loss: 0.553698\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362351; batch adversarial loss: 0.614634\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369167; batch adversarial loss: 0.544538\n",
      "epoch 167; iter: 0; batch classifier loss: 0.397109; batch adversarial loss: 0.510240\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341904; batch adversarial loss: 0.614528\n",
      "epoch 169; iter: 0; batch classifier loss: 0.346978; batch adversarial loss: 0.562686\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373812; batch adversarial loss: 0.579894\n",
      "epoch 171; iter: 0; batch classifier loss: 0.331604; batch adversarial loss: 0.597372\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384053; batch adversarial loss: 0.553684\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343191; batch adversarial loss: 0.588357\n",
      "epoch 174; iter: 0; batch classifier loss: 0.352016; batch adversarial loss: 0.527598\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336562; batch adversarial loss: 0.623432\n",
      "epoch 176; iter: 0; batch classifier loss: 0.434045; batch adversarial loss: 0.562204\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389816; batch adversarial loss: 0.588490\n",
      "epoch 178; iter: 0; batch classifier loss: 0.411526; batch adversarial loss: 0.579728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.278371; batch adversarial loss: 0.518481\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327886; batch adversarial loss: 0.527535\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367966; batch adversarial loss: 0.527207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.290912; batch adversarial loss: 0.588904\n",
      "epoch 183; iter: 0; batch classifier loss: 0.380518; batch adversarial loss: 0.509859\n",
      "epoch 184; iter: 0; batch classifier loss: 0.410990; batch adversarial loss: 0.562581\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365349; batch adversarial loss: 0.596850\n",
      "epoch 186; iter: 0; batch classifier loss: 0.322217; batch adversarial loss: 0.545331\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375428; batch adversarial loss: 0.597401\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329869; batch adversarial loss: 0.588131\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358711; batch adversarial loss: 0.580028\n",
      "epoch 190; iter: 0; batch classifier loss: 0.308788; batch adversarial loss: 0.536297\n",
      "epoch 191; iter: 0; batch classifier loss: 0.401552; batch adversarial loss: 0.667515\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344696; batch adversarial loss: 0.561538\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348412; batch adversarial loss: 0.562164\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358256; batch adversarial loss: 0.570513\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338473; batch adversarial loss: 0.509317\n",
      "epoch 196; iter: 0; batch classifier loss: 0.352369; batch adversarial loss: 0.534890\n",
      "epoch 197; iter: 0; batch classifier loss: 0.391084; batch adversarial loss: 0.571851\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370862; batch adversarial loss: 0.587745\n",
      "epoch 199; iter: 0; batch classifier loss: 0.375961; batch adversarial loss: 0.571018\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715783; batch adversarial loss: 0.872608\n",
      "epoch 1; iter: 0; batch classifier loss: 0.753123; batch adversarial loss: 0.941387\n",
      "epoch 2; iter: 0; batch classifier loss: 0.869403; batch adversarial loss: 0.875560\n",
      "epoch 3; iter: 0; batch classifier loss: 0.876818; batch adversarial loss: 0.801305\n",
      "epoch 4; iter: 0; batch classifier loss: 0.911705; batch adversarial loss: 0.739753\n",
      "epoch 5; iter: 0; batch classifier loss: 0.963908; batch adversarial loss: 0.696020\n",
      "epoch 6; iter: 0; batch classifier loss: 0.697530; batch adversarial loss: 0.630720\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588870; batch adversarial loss: 0.604652\n",
      "epoch 8; iter: 0; batch classifier loss: 0.609321; batch adversarial loss: 0.604745\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512020; batch adversarial loss: 0.611921\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569360; batch adversarial loss: 0.606839\n",
      "epoch 11; iter: 0; batch classifier loss: 0.609684; batch adversarial loss: 0.551156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552674; batch adversarial loss: 0.549282\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486906; batch adversarial loss: 0.554225\n",
      "epoch 14; iter: 0; batch classifier loss: 0.599896; batch adversarial loss: 0.505553\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542906; batch adversarial loss: 0.554925\n",
      "epoch 16; iter: 0; batch classifier loss: 0.516265; batch adversarial loss: 0.542541\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507337; batch adversarial loss: 0.544878\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476908; batch adversarial loss: 0.524232\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487231; batch adversarial loss: 0.530945\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489481; batch adversarial loss: 0.533434\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477889; batch adversarial loss: 0.575920\n",
      "epoch 22; iter: 0; batch classifier loss: 0.528542; batch adversarial loss: 0.517667\n",
      "epoch 23; iter: 0; batch classifier loss: 0.398386; batch adversarial loss: 0.575204\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474768; batch adversarial loss: 0.580619\n",
      "epoch 25; iter: 0; batch classifier loss: 0.514485; batch adversarial loss: 0.569292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.412615; batch adversarial loss: 0.557862\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484807; batch adversarial loss: 0.517060\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498747; batch adversarial loss: 0.551965\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455535; batch adversarial loss: 0.521336\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432175; batch adversarial loss: 0.580159\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501870; batch adversarial loss: 0.581987\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479797; batch adversarial loss: 0.592416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460714; batch adversarial loss: 0.491879\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438840; batch adversarial loss: 0.577850\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447118; batch adversarial loss: 0.567582\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443888; batch adversarial loss: 0.601738\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459539; batch adversarial loss: 0.561338\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441210; batch adversarial loss: 0.491490\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480157; batch adversarial loss: 0.534384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448550; batch adversarial loss: 0.551021\n",
      "epoch 41; iter: 0; batch classifier loss: 0.523541; batch adversarial loss: 0.588391\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484564; batch adversarial loss: 0.506537\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430752; batch adversarial loss: 0.487120\n",
      "epoch 44; iter: 0; batch classifier loss: 0.583573; batch adversarial loss: 0.592197\n",
      "epoch 45; iter: 0; batch classifier loss: 0.468333; batch adversarial loss: 0.468139\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372465; batch adversarial loss: 0.500145\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461474; batch adversarial loss: 0.553532\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461205; batch adversarial loss: 0.551211\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442274; batch adversarial loss: 0.480756\n",
      "epoch 50; iter: 0; batch classifier loss: 0.338601; batch adversarial loss: 0.598170\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470253; batch adversarial loss: 0.545980\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441858; batch adversarial loss: 0.526043\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445585; batch adversarial loss: 0.544545\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440496; batch adversarial loss: 0.575744\n",
      "epoch 55; iter: 0; batch classifier loss: 0.497227; batch adversarial loss: 0.508194\n",
      "epoch 56; iter: 0; batch classifier loss: 0.481280; batch adversarial loss: 0.553523\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438030; batch adversarial loss: 0.564020\n",
      "epoch 58; iter: 0; batch classifier loss: 0.356064; batch adversarial loss: 0.602421\n",
      "epoch 59; iter: 0; batch classifier loss: 0.430062; batch adversarial loss: 0.490794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.518508; batch adversarial loss: 0.581275\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412600; batch adversarial loss: 0.546569\n",
      "epoch 62; iter: 0; batch classifier loss: 0.463878; batch adversarial loss: 0.564017\n",
      "epoch 63; iter: 0; batch classifier loss: 0.405834; batch adversarial loss: 0.562686\n",
      "epoch 64; iter: 0; batch classifier loss: 0.392395; batch adversarial loss: 0.525974\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427230; batch adversarial loss: 0.490200\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459710; batch adversarial loss: 0.499512\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395915; batch adversarial loss: 0.508034\n",
      "epoch 68; iter: 0; batch classifier loss: 0.429879; batch adversarial loss: 0.544819\n",
      "epoch 69; iter: 0; batch classifier loss: 0.470296; batch adversarial loss: 0.561817\n",
      "epoch 70; iter: 0; batch classifier loss: 0.381771; batch adversarial loss: 0.544675\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436206; batch adversarial loss: 0.562268\n",
      "epoch 72; iter: 0; batch classifier loss: 0.307603; batch adversarial loss: 0.589312\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419735; batch adversarial loss: 0.581369\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367235; batch adversarial loss: 0.636565\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449136; batch adversarial loss: 0.617118\n",
      "epoch 76; iter: 0; batch classifier loss: 0.348463; batch adversarial loss: 0.598645\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396834; batch adversarial loss: 0.488804\n",
      "epoch 78; iter: 0; batch classifier loss: 0.361720; batch adversarial loss: 0.516727\n",
      "epoch 79; iter: 0; batch classifier loss: 0.329182; batch adversarial loss: 0.527470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.457080; batch adversarial loss: 0.537229\n",
      "epoch 81; iter: 0; batch classifier loss: 0.343125; batch adversarial loss: 0.634689\n",
      "epoch 82; iter: 0; batch classifier loss: 0.399216; batch adversarial loss: 0.544906\n",
      "epoch 83; iter: 0; batch classifier loss: 0.343741; batch adversarial loss: 0.564564\n",
      "epoch 84; iter: 0; batch classifier loss: 0.335998; batch adversarial loss: 0.554245\n",
      "epoch 85; iter: 0; batch classifier loss: 0.429866; batch adversarial loss: 0.479765\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435411; batch adversarial loss: 0.607299\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375694; batch adversarial loss: 0.534163\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384554; batch adversarial loss: 0.544623\n",
      "epoch 89; iter: 0; batch classifier loss: 0.319048; batch adversarial loss: 0.617524\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374468; batch adversarial loss: 0.499194\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402639; batch adversarial loss: 0.481402\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418523; batch adversarial loss: 0.516670\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394424; batch adversarial loss: 0.580795\n",
      "epoch 94; iter: 0; batch classifier loss: 0.487749; batch adversarial loss: 0.582923\n",
      "epoch 95; iter: 0; batch classifier loss: 0.447586; batch adversarial loss: 0.545268\n",
      "epoch 96; iter: 0; batch classifier loss: 0.329434; batch adversarial loss: 0.580735\n",
      "epoch 97; iter: 0; batch classifier loss: 0.409807; batch adversarial loss: 0.471174\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378496; batch adversarial loss: 0.544841\n",
      "epoch 99; iter: 0; batch classifier loss: 0.458652; batch adversarial loss: 0.526386\n",
      "epoch 100; iter: 0; batch classifier loss: 0.450716; batch adversarial loss: 0.662582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.328718; batch adversarial loss: 0.535648\n",
      "epoch 102; iter: 0; batch classifier loss: 0.434620; batch adversarial loss: 0.600124\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358244; batch adversarial loss: 0.543709\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352260; batch adversarial loss: 0.580435\n",
      "epoch 105; iter: 0; batch classifier loss: 0.387765; batch adversarial loss: 0.572099\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326472; batch adversarial loss: 0.571218\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377895; batch adversarial loss: 0.435346\n",
      "epoch 108; iter: 0; batch classifier loss: 0.412814; batch adversarial loss: 0.525590\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380720; batch adversarial loss: 0.544662\n",
      "epoch 110; iter: 0; batch classifier loss: 0.380222; batch adversarial loss: 0.499579\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355518; batch adversarial loss: 0.608678\n",
      "epoch 112; iter: 0; batch classifier loss: 0.332084; batch adversarial loss: 0.516939\n",
      "epoch 113; iter: 0; batch classifier loss: 0.332705; batch adversarial loss: 0.499440\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410817; batch adversarial loss: 0.460876\n",
      "epoch 115; iter: 0; batch classifier loss: 0.316504; batch adversarial loss: 0.600661\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389959; batch adversarial loss: 0.480094\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378326; batch adversarial loss: 0.608915\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355711; batch adversarial loss: 0.498468\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339969; batch adversarial loss: 0.515854\n",
      "epoch 120; iter: 0; batch classifier loss: 0.339009; batch adversarial loss: 0.581584\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392211; batch adversarial loss: 0.635082\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398343; batch adversarial loss: 0.552768\n",
      "epoch 123; iter: 0; batch classifier loss: 0.382443; batch adversarial loss: 0.564099\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338626; batch adversarial loss: 0.555047\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399931; batch adversarial loss: 0.462111\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392684; batch adversarial loss: 0.581356\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362754; batch adversarial loss: 0.624535\n",
      "epoch 128; iter: 0; batch classifier loss: 0.339667; batch adversarial loss: 0.597622\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365551; batch adversarial loss: 0.543950\n",
      "epoch 130; iter: 0; batch classifier loss: 0.424551; batch adversarial loss: 0.500749\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360705; batch adversarial loss: 0.554216\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396333; batch adversarial loss: 0.552954\n",
      "epoch 133; iter: 0; batch classifier loss: 0.300761; batch adversarial loss: 0.589252\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333347; batch adversarial loss: 0.524059\n",
      "epoch 135; iter: 0; batch classifier loss: 0.411053; batch adversarial loss: 0.580247\n",
      "epoch 136; iter: 0; batch classifier loss: 0.327950; batch adversarial loss: 0.543832\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351440; batch adversarial loss: 0.553147\n",
      "epoch 138; iter: 0; batch classifier loss: 0.314404; batch adversarial loss: 0.462034\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360145; batch adversarial loss: 0.554015\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390213; batch adversarial loss: 0.534607\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391771; batch adversarial loss: 0.526247\n",
      "epoch 142; iter: 0; batch classifier loss: 0.309781; batch adversarial loss: 0.499073\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354213; batch adversarial loss: 0.498988\n",
      "epoch 144; iter: 0; batch classifier loss: 0.292674; batch adversarial loss: 0.489996\n",
      "epoch 145; iter: 0; batch classifier loss: 0.318140; batch adversarial loss: 0.562782\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400195; batch adversarial loss: 0.507170\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384681; batch adversarial loss: 0.505569\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370191; batch adversarial loss: 0.581722\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316656; batch adversarial loss: 0.524945\n",
      "epoch 150; iter: 0; batch classifier loss: 0.430694; batch adversarial loss: 0.517999\n",
      "epoch 151; iter: 0; batch classifier loss: 0.324326; batch adversarial loss: 0.556788\n",
      "epoch 152; iter: 0; batch classifier loss: 0.407635; batch adversarial loss: 0.543918\n",
      "epoch 153; iter: 0; batch classifier loss: 0.280228; batch adversarial loss: 0.525541\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379506; batch adversarial loss: 0.626156\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358070; batch adversarial loss: 0.525340\n",
      "epoch 156; iter: 0; batch classifier loss: 0.448883; batch adversarial loss: 0.444451\n",
      "epoch 157; iter: 0; batch classifier loss: 0.388274; batch adversarial loss: 0.544574\n",
      "epoch 158; iter: 0; batch classifier loss: 0.391412; batch adversarial loss: 0.481836\n",
      "epoch 159; iter: 0; batch classifier loss: 0.284711; batch adversarial loss: 0.488403\n",
      "epoch 160; iter: 0; batch classifier loss: 0.322428; batch adversarial loss: 0.543477\n",
      "epoch 161; iter: 0; batch classifier loss: 0.442263; batch adversarial loss: 0.497531\n",
      "epoch 162; iter: 0; batch classifier loss: 0.431697; batch adversarial loss: 0.554820\n",
      "epoch 163; iter: 0; batch classifier loss: 0.298820; batch adversarial loss: 0.469778\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368365; batch adversarial loss: 0.556764\n",
      "epoch 165; iter: 0; batch classifier loss: 0.340817; batch adversarial loss: 0.589471\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335768; batch adversarial loss: 0.545938\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363960; batch adversarial loss: 0.517301\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377798; batch adversarial loss: 0.561636\n",
      "epoch 169; iter: 0; batch classifier loss: 0.316144; batch adversarial loss: 0.514645\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360644; batch adversarial loss: 0.499324\n",
      "epoch 171; iter: 0; batch classifier loss: 0.299642; batch adversarial loss: 0.589447\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363577; batch adversarial loss: 0.515970\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380414; batch adversarial loss: 0.534798\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321980; batch adversarial loss: 0.580159\n",
      "epoch 175; iter: 0; batch classifier loss: 0.299833; batch adversarial loss: 0.571000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.305076; batch adversarial loss: 0.570677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389340; batch adversarial loss: 0.570913\n",
      "epoch 178; iter: 0; batch classifier loss: 0.401210; batch adversarial loss: 0.624990\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346139; batch adversarial loss: 0.618978\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340302; batch adversarial loss: 0.562421\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345040; batch adversarial loss: 0.608238\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348001; batch adversarial loss: 0.573056\n",
      "epoch 183; iter: 0; batch classifier loss: 0.272490; batch adversarial loss: 0.488991\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330496; batch adversarial loss: 0.581006\n",
      "epoch 185; iter: 0; batch classifier loss: 0.297160; batch adversarial loss: 0.554357\n",
      "epoch 186; iter: 0; batch classifier loss: 0.319001; batch adversarial loss: 0.588932\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340310; batch adversarial loss: 0.517592\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338980; batch adversarial loss: 0.563200\n",
      "epoch 189; iter: 0; batch classifier loss: 0.301712; batch adversarial loss: 0.563341\n",
      "epoch 190; iter: 0; batch classifier loss: 0.303871; batch adversarial loss: 0.535011\n",
      "epoch 191; iter: 0; batch classifier loss: 0.400907; batch adversarial loss: 0.608764\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404131; batch adversarial loss: 0.488849\n",
      "epoch 193; iter: 0; batch classifier loss: 0.367128; batch adversarial loss: 0.672258\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.571733\n",
      "epoch 195; iter: 0; batch classifier loss: 0.388128; batch adversarial loss: 0.544186\n",
      "epoch 196; iter: 0; batch classifier loss: 0.447309; batch adversarial loss: 0.536232\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386991; batch adversarial loss: 0.544855\n",
      "epoch 198; iter: 0; batch classifier loss: 0.506530; batch adversarial loss: 0.535780\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351767; batch adversarial loss: 0.628745\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716946; batch adversarial loss: 0.915352\n",
      "epoch 1; iter: 0; batch classifier loss: 0.714639; batch adversarial loss: 1.032117\n",
      "epoch 2; iter: 0; batch classifier loss: 0.815176; batch adversarial loss: 0.981758\n",
      "epoch 3; iter: 0; batch classifier loss: 0.849096; batch adversarial loss: 0.880827\n",
      "epoch 4; iter: 0; batch classifier loss: 0.728822; batch adversarial loss: 0.780332\n",
      "epoch 5; iter: 0; batch classifier loss: 0.661464; batch adversarial loss: 0.730299\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575084; batch adversarial loss: 0.674674\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543700; batch adversarial loss: 0.664641\n",
      "epoch 8; iter: 0; batch classifier loss: 0.637740; batch adversarial loss: 0.662393\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508643; batch adversarial loss: 0.599953\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560314; batch adversarial loss: 0.586504\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533623; batch adversarial loss: 0.575722\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551901; batch adversarial loss: 0.594535\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509398; batch adversarial loss: 0.559414\n",
      "epoch 14; iter: 0; batch classifier loss: 0.546147; batch adversarial loss: 0.593270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524601; batch adversarial loss: 0.567590\n",
      "epoch 16; iter: 0; batch classifier loss: 0.633410; batch adversarial loss: 0.547422\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515635; batch adversarial loss: 0.555559\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534072; batch adversarial loss: 0.588619\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504480; batch adversarial loss: 0.572297\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522752; batch adversarial loss: 0.526681\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480514; batch adversarial loss: 0.549947\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502657; batch adversarial loss: 0.542783\n",
      "epoch 23; iter: 0; batch classifier loss: 0.434659; batch adversarial loss: 0.514848\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491347; batch adversarial loss: 0.594105\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478360; batch adversarial loss: 0.552896\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471547; batch adversarial loss: 0.564316\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436075; batch adversarial loss: 0.510082\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481833; batch adversarial loss: 0.533253\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472965; batch adversarial loss: 0.573095\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457844; batch adversarial loss: 0.530965\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447893; batch adversarial loss: 0.568305\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435670; batch adversarial loss: 0.500948\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462441; batch adversarial loss: 0.572889\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459500; batch adversarial loss: 0.527814\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397154; batch adversarial loss: 0.536647\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442131; batch adversarial loss: 0.570285\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392192; batch adversarial loss: 0.499003\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408824; batch adversarial loss: 0.533751\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399385; batch adversarial loss: 0.535560\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403572; batch adversarial loss: 0.554197\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428763; batch adversarial loss: 0.500125\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446787; batch adversarial loss: 0.536422\n",
      "epoch 43; iter: 0; batch classifier loss: 0.417433; batch adversarial loss: 0.592125\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490586; batch adversarial loss: 0.657542\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446437; batch adversarial loss: 0.569691\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487627; batch adversarial loss: 0.516584\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471249; batch adversarial loss: 0.555069\n",
      "epoch 48; iter: 0; batch classifier loss: 0.333584; batch adversarial loss: 0.554496\n",
      "epoch 49; iter: 0; batch classifier loss: 0.453099; batch adversarial loss: 0.510159\n",
      "epoch 50; iter: 0; batch classifier loss: 0.376900; batch adversarial loss: 0.537550\n",
      "epoch 51; iter: 0; batch classifier loss: 0.391272; batch adversarial loss: 0.526696\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412819; batch adversarial loss: 0.471847\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383076; batch adversarial loss: 0.490106\n",
      "epoch 54; iter: 0; batch classifier loss: 0.485832; batch adversarial loss: 0.523772\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376653; batch adversarial loss: 0.553128\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473710; batch adversarial loss: 0.534846\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369297; batch adversarial loss: 0.554140\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384158; batch adversarial loss: 0.608751\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412882; batch adversarial loss: 0.553422\n",
      "epoch 60; iter: 0; batch classifier loss: 0.348636; batch adversarial loss: 0.534854\n",
      "epoch 61; iter: 0; batch classifier loss: 0.485692; batch adversarial loss: 0.498465\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396007; batch adversarial loss: 0.535526\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408343; batch adversarial loss: 0.553048\n",
      "epoch 64; iter: 0; batch classifier loss: 0.305106; batch adversarial loss: 0.481487\n",
      "epoch 65; iter: 0; batch classifier loss: 0.349925; batch adversarial loss: 0.490142\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392000; batch adversarial loss: 0.552559\n",
      "epoch 67; iter: 0; batch classifier loss: 0.415631; batch adversarial loss: 0.517173\n",
      "epoch 68; iter: 0; batch classifier loss: 0.343368; batch adversarial loss: 0.641938\n",
      "epoch 69; iter: 0; batch classifier loss: 0.332269; batch adversarial loss: 0.507492\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385582; batch adversarial loss: 0.626976\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391687; batch adversarial loss: 0.582873\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379966; batch adversarial loss: 0.508141\n",
      "epoch 73; iter: 0; batch classifier loss: 0.462300; batch adversarial loss: 0.553616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.299889; batch adversarial loss: 0.641970\n",
      "epoch 75; iter: 0; batch classifier loss: 0.342460; batch adversarial loss: 0.603714\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379011; batch adversarial loss: 0.557274\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413464; batch adversarial loss: 0.550825\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350157; batch adversarial loss: 0.552082\n",
      "epoch 79; iter: 0; batch classifier loss: 0.441910; batch adversarial loss: 0.486088\n",
      "epoch 80; iter: 0; batch classifier loss: 0.331593; batch adversarial loss: 0.406311\n",
      "epoch 81; iter: 0; batch classifier loss: 0.379251; batch adversarial loss: 0.597804\n",
      "epoch 82; iter: 0; batch classifier loss: 0.480905; batch adversarial loss: 0.474649\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365383; batch adversarial loss: 0.561220\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354373; batch adversarial loss: 0.518318\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397839; batch adversarial loss: 0.569713\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350364; batch adversarial loss: 0.599512\n",
      "epoch 87; iter: 0; batch classifier loss: 0.346994; batch adversarial loss: 0.562218\n",
      "epoch 88; iter: 0; batch classifier loss: 0.342369; batch adversarial loss: 0.534866\n",
      "epoch 89; iter: 0; batch classifier loss: 0.338048; batch adversarial loss: 0.545505\n",
      "epoch 90; iter: 0; batch classifier loss: 0.437284; batch adversarial loss: 0.500419\n",
      "epoch 91; iter: 0; batch classifier loss: 0.446791; batch adversarial loss: 0.481318\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425431; batch adversarial loss: 0.590903\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387840; batch adversarial loss: 0.562404\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357180; batch adversarial loss: 0.507488\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352673; batch adversarial loss: 0.525699\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371696; batch adversarial loss: 0.553711\n",
      "epoch 97; iter: 0; batch classifier loss: 0.348148; batch adversarial loss: 0.517097\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392651; batch adversarial loss: 0.581259\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358070; batch adversarial loss: 0.525432\n",
      "epoch 100; iter: 0; batch classifier loss: 0.339304; batch adversarial loss: 0.516779\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398042; batch adversarial loss: 0.525551\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345123; batch adversarial loss: 0.480576\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350511; batch adversarial loss: 0.516755\n",
      "epoch 104; iter: 0; batch classifier loss: 0.480028; batch adversarial loss: 0.635402\n",
      "epoch 105; iter: 0; batch classifier loss: 0.386809; batch adversarial loss: 0.581975\n",
      "epoch 106; iter: 0; batch classifier loss: 0.416476; batch adversarial loss: 0.535550\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364920; batch adversarial loss: 0.534226\n",
      "epoch 108; iter: 0; batch classifier loss: 0.434464; batch adversarial loss: 0.497936\n",
      "epoch 109; iter: 0; batch classifier loss: 0.464528; batch adversarial loss: 0.544762\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396640; batch adversarial loss: 0.508171\n",
      "epoch 111; iter: 0; batch classifier loss: 0.349264; batch adversarial loss: 0.627462\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359827; batch adversarial loss: 0.590696\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378660; batch adversarial loss: 0.535111\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364311; batch adversarial loss: 0.618276\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419452; batch adversarial loss: 0.516698\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382721; batch adversarial loss: 0.545581\n",
      "epoch 117; iter: 0; batch classifier loss: 0.332173; batch adversarial loss: 0.552822\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357988; batch adversarial loss: 0.508400\n",
      "epoch 119; iter: 0; batch classifier loss: 0.351219; batch adversarial loss: 0.535836\n",
      "epoch 120; iter: 0; batch classifier loss: 0.359942; batch adversarial loss: 0.552481\n",
      "epoch 121; iter: 0; batch classifier loss: 0.308612; batch adversarial loss: 0.581262\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351286; batch adversarial loss: 0.489308\n",
      "epoch 123; iter: 0; batch classifier loss: 0.291101; batch adversarial loss: 0.555724\n",
      "epoch 124; iter: 0; batch classifier loss: 0.327509; batch adversarial loss: 0.516946\n",
      "epoch 125; iter: 0; batch classifier loss: 0.316413; batch adversarial loss: 0.671270\n",
      "epoch 126; iter: 0; batch classifier loss: 0.356721; batch adversarial loss: 0.534830\n",
      "epoch 127; iter: 0; batch classifier loss: 0.312286; batch adversarial loss: 0.470953\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404225; batch adversarial loss: 0.598894\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397602; batch adversarial loss: 0.517072\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371779; batch adversarial loss: 0.490150\n",
      "epoch 131; iter: 0; batch classifier loss: 0.424365; batch adversarial loss: 0.598527\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364765; batch adversarial loss: 0.563276\n",
      "epoch 133; iter: 0; batch classifier loss: 0.404352; batch adversarial loss: 0.489259\n",
      "epoch 134; iter: 0; batch classifier loss: 0.307337; batch adversarial loss: 0.526125\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353461; batch adversarial loss: 0.599736\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363833; batch adversarial loss: 0.581965\n",
      "epoch 137; iter: 0; batch classifier loss: 0.439154; batch adversarial loss: 0.590607\n",
      "epoch 138; iter: 0; batch classifier loss: 0.343468; batch adversarial loss: 0.654479\n",
      "epoch 139; iter: 0; batch classifier loss: 0.385376; batch adversarial loss: 0.489368\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391981; batch adversarial loss: 0.526634\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353254; batch adversarial loss: 0.507683\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387596; batch adversarial loss: 0.571631\n",
      "epoch 143; iter: 0; batch classifier loss: 0.384199; batch adversarial loss: 0.590149\n",
      "epoch 144; iter: 0; batch classifier loss: 0.394677; batch adversarial loss: 0.481673\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319195; batch adversarial loss: 0.591229\n",
      "epoch 146; iter: 0; batch classifier loss: 0.296007; batch adversarial loss: 0.499301\n",
      "epoch 147; iter: 0; batch classifier loss: 0.304114; batch adversarial loss: 0.499209\n",
      "epoch 148; iter: 0; batch classifier loss: 0.301368; batch adversarial loss: 0.552788\n",
      "epoch 149; iter: 0; batch classifier loss: 0.412584; batch adversarial loss: 0.526720\n",
      "epoch 150; iter: 0; batch classifier loss: 0.306416; batch adversarial loss: 0.453035\n",
      "epoch 151; iter: 0; batch classifier loss: 0.277955; batch adversarial loss: 0.599334\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369997; batch adversarial loss: 0.581239\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348401; batch adversarial loss: 0.562520\n",
      "epoch 154; iter: 0; batch classifier loss: 0.323266; batch adversarial loss: 0.544712\n",
      "epoch 155; iter: 0; batch classifier loss: 0.321393; batch adversarial loss: 0.599359\n",
      "epoch 156; iter: 0; batch classifier loss: 0.308166; batch adversarial loss: 0.544287\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400455; batch adversarial loss: 0.553058\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327610; batch adversarial loss: 0.488244\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356977; batch adversarial loss: 0.452888\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353707; batch adversarial loss: 0.507348\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311197; batch adversarial loss: 0.535358\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364955; batch adversarial loss: 0.508417\n",
      "epoch 163; iter: 0; batch classifier loss: 0.409635; batch adversarial loss: 0.580846\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340779; batch adversarial loss: 0.581644\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326959; batch adversarial loss: 0.562643\n",
      "epoch 166; iter: 0; batch classifier loss: 0.307623; batch adversarial loss: 0.526253\n",
      "epoch 167; iter: 0; batch classifier loss: 0.320936; batch adversarial loss: 0.480571\n",
      "epoch 168; iter: 0; batch classifier loss: 0.409037; batch adversarial loss: 0.453986\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372957; batch adversarial loss: 0.471677\n",
      "epoch 170; iter: 0; batch classifier loss: 0.310115; batch adversarial loss: 0.672823\n",
      "epoch 171; iter: 0; batch classifier loss: 0.296031; batch adversarial loss: 0.526216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.379345; batch adversarial loss: 0.653747\n",
      "epoch 173; iter: 0; batch classifier loss: 0.273414; batch adversarial loss: 0.498224\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369782; batch adversarial loss: 0.553898\n",
      "epoch 175; iter: 0; batch classifier loss: 0.258590; batch adversarial loss: 0.591024\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338370; batch adversarial loss: 0.489781\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352183; batch adversarial loss: 0.525941\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416130; batch adversarial loss: 0.544101\n",
      "epoch 179; iter: 0; batch classifier loss: 0.315664; batch adversarial loss: 0.581588\n",
      "epoch 180; iter: 0; batch classifier loss: 0.309077; batch adversarial loss: 0.498104\n",
      "epoch 181; iter: 0; batch classifier loss: 0.438411; batch adversarial loss: 0.544042\n",
      "epoch 182; iter: 0; batch classifier loss: 0.303460; batch adversarial loss: 0.599300\n",
      "epoch 183; iter: 0; batch classifier loss: 0.305525; batch adversarial loss: 0.562649\n",
      "epoch 184; iter: 0; batch classifier loss: 0.307457; batch adversarial loss: 0.535514\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391154; batch adversarial loss: 0.544460\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404193; batch adversarial loss: 0.581029\n",
      "epoch 187; iter: 0; batch classifier loss: 0.304413; batch adversarial loss: 0.600058\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314720; batch adversarial loss: 0.489871\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364617; batch adversarial loss: 0.573533\n",
      "epoch 190; iter: 0; batch classifier loss: 0.267539; batch adversarial loss: 0.561751\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341527; batch adversarial loss: 0.544356\n",
      "epoch 192; iter: 0; batch classifier loss: 0.378966; batch adversarial loss: 0.542661\n",
      "epoch 193; iter: 0; batch classifier loss: 0.465563; batch adversarial loss: 0.598174\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382821; batch adversarial loss: 0.531131\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383160; batch adversarial loss: 0.579568\n",
      "epoch 196; iter: 0; batch classifier loss: 0.304611; batch adversarial loss: 0.542084\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344896; batch adversarial loss: 0.630119\n",
      "epoch 198; iter: 0; batch classifier loss: 0.315825; batch adversarial loss: 0.559422\n",
      "epoch 199; iter: 0; batch classifier loss: 0.354230; batch adversarial loss: 0.492446\n",
      "epoch 0; iter: 0; batch classifier loss: 0.645991; batch adversarial loss: 0.648187\n",
      "epoch 1; iter: 0; batch classifier loss: 0.547274; batch adversarial loss: 0.609134\n",
      "epoch 2; iter: 0; batch classifier loss: 0.627540; batch adversarial loss: 0.609456\n",
      "epoch 3; iter: 0; batch classifier loss: 0.571432; batch adversarial loss: 0.621872\n",
      "epoch 4; iter: 0; batch classifier loss: 0.491672; batch adversarial loss: 0.634819\n",
      "epoch 5; iter: 0; batch classifier loss: 0.654942; batch adversarial loss: 0.572764\n",
      "epoch 6; iter: 0; batch classifier loss: 0.475532; batch adversarial loss: 0.580567\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574003; batch adversarial loss: 0.672610\n",
      "epoch 8; iter: 0; batch classifier loss: 0.487288; batch adversarial loss: 0.664530\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557535; batch adversarial loss: 0.594301\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515980; batch adversarial loss: 0.552089\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541985; batch adversarial loss: 0.604987\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525915; batch adversarial loss: 0.608788\n",
      "epoch 13; iter: 0; batch classifier loss: 0.460373; batch adversarial loss: 0.578557\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540500; batch adversarial loss: 0.509388\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552398; batch adversarial loss: 0.549317\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450870; batch adversarial loss: 0.537547\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526090; batch adversarial loss: 0.558507\n",
      "epoch 18; iter: 0; batch classifier loss: 0.461953; batch adversarial loss: 0.498054\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501201; batch adversarial loss: 0.572381\n",
      "epoch 20; iter: 0; batch classifier loss: 0.565802; batch adversarial loss: 0.631342\n",
      "epoch 21; iter: 0; batch classifier loss: 0.449360; batch adversarial loss: 0.533661\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525259; batch adversarial loss: 0.515325\n",
      "epoch 23; iter: 0; batch classifier loss: 0.526118; batch adversarial loss: 0.527919\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511369; batch adversarial loss: 0.548136\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497310; batch adversarial loss: 0.596190\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474379; batch adversarial loss: 0.497448\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490687; batch adversarial loss: 0.525074\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487223; batch adversarial loss: 0.557567\n",
      "epoch 29; iter: 0; batch classifier loss: 0.531855; batch adversarial loss: 0.552392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477025; batch adversarial loss: 0.541021\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515231; batch adversarial loss: 0.497220\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452284; batch adversarial loss: 0.577642\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522058; batch adversarial loss: 0.528218\n",
      "epoch 34; iter: 0; batch classifier loss: 0.527902; batch adversarial loss: 0.507488\n",
      "epoch 35; iter: 0; batch classifier loss: 0.466027; batch adversarial loss: 0.489870\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446075; batch adversarial loss: 0.472251\n",
      "epoch 37; iter: 0; batch classifier loss: 0.520503; batch adversarial loss: 0.498709\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504508; batch adversarial loss: 0.563056\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392945; batch adversarial loss: 0.524966\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451614; batch adversarial loss: 0.424517\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448329; batch adversarial loss: 0.501549\n",
      "epoch 42; iter: 0; batch classifier loss: 0.494788; batch adversarial loss: 0.470808\n",
      "epoch 43; iter: 0; batch classifier loss: 0.368884; batch adversarial loss: 0.564179\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500928; batch adversarial loss: 0.544581\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444468; batch adversarial loss: 0.544266\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454571; batch adversarial loss: 0.660707\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463894; batch adversarial loss: 0.517772\n",
      "epoch 48; iter: 0; batch classifier loss: 0.493582; batch adversarial loss: 0.499018\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423472; batch adversarial loss: 0.507962\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413958; batch adversarial loss: 0.534956\n",
      "epoch 51; iter: 0; batch classifier loss: 0.372476; batch adversarial loss: 0.581318\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408614; batch adversarial loss: 0.526176\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390118; batch adversarial loss: 0.480105\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422472; batch adversarial loss: 0.562980\n",
      "epoch 55; iter: 0; batch classifier loss: 0.488790; batch adversarial loss: 0.507678\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398102; batch adversarial loss: 0.507745\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441126; batch adversarial loss: 0.562233\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414509; batch adversarial loss: 0.526304\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417475; batch adversarial loss: 0.553851\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410061; batch adversarial loss: 0.535716\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438456; batch adversarial loss: 0.580673\n",
      "epoch 62; iter: 0; batch classifier loss: 0.449589; batch adversarial loss: 0.526964\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415848; batch adversarial loss: 0.534179\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381583; batch adversarial loss: 0.617568\n",
      "epoch 65; iter: 0; batch classifier loss: 0.516886; batch adversarial loss: 0.518833\n",
      "epoch 66; iter: 0; batch classifier loss: 0.450631; batch adversarial loss: 0.480460\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420540; batch adversarial loss: 0.544627\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430289; batch adversarial loss: 0.460622\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449454; batch adversarial loss: 0.535472\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404010; batch adversarial loss: 0.554600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.407923; batch adversarial loss: 0.544645\n",
      "epoch 72; iter: 0; batch classifier loss: 0.425009; batch adversarial loss: 0.507009\n",
      "epoch 73; iter: 0; batch classifier loss: 0.497044; batch adversarial loss: 0.610652\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392260; batch adversarial loss: 0.572647\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393446; batch adversarial loss: 0.460152\n",
      "epoch 76; iter: 0; batch classifier loss: 0.447617; batch adversarial loss: 0.516503\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396516; batch adversarial loss: 0.497909\n",
      "epoch 78; iter: 0; batch classifier loss: 0.488131; batch adversarial loss: 0.590987\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401883; batch adversarial loss: 0.544783\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402910; batch adversarial loss: 0.600524\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445828; batch adversarial loss: 0.460762\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407423; batch adversarial loss: 0.590971\n",
      "epoch 83; iter: 0; batch classifier loss: 0.449815; batch adversarial loss: 0.582166\n",
      "epoch 84; iter: 0; batch classifier loss: 0.442784; batch adversarial loss: 0.562759\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428707; batch adversarial loss: 0.451640\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387916; batch adversarial loss: 0.609115\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411627; batch adversarial loss: 0.553439\n",
      "epoch 88; iter: 0; batch classifier loss: 0.336978; batch adversarial loss: 0.609459\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399965; batch adversarial loss: 0.479749\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404726; batch adversarial loss: 0.535090\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439846; batch adversarial loss: 0.572608\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368296; batch adversarial loss: 0.599829\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378463; batch adversarial loss: 0.498371\n",
      "epoch 94; iter: 0; batch classifier loss: 0.447751; batch adversarial loss: 0.571935\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440266; batch adversarial loss: 0.618582\n",
      "epoch 96; iter: 0; batch classifier loss: 0.471294; batch adversarial loss: 0.563024\n",
      "epoch 97; iter: 0; batch classifier loss: 0.441919; batch adversarial loss: 0.488912\n",
      "epoch 98; iter: 0; batch classifier loss: 0.424260; batch adversarial loss: 0.479440\n",
      "epoch 99; iter: 0; batch classifier loss: 0.447350; batch adversarial loss: 0.535616\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402313; batch adversarial loss: 0.507390\n",
      "epoch 101; iter: 0; batch classifier loss: 0.497685; batch adversarial loss: 0.562747\n",
      "epoch 102; iter: 0; batch classifier loss: 0.450875; batch adversarial loss: 0.507900\n",
      "epoch 103; iter: 0; batch classifier loss: 0.444509; batch adversarial loss: 0.516767\n",
      "epoch 104; iter: 0; batch classifier loss: 0.337112; batch adversarial loss: 0.646037\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432186; batch adversarial loss: 0.516581\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335512; batch adversarial loss: 0.535397\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382269; batch adversarial loss: 0.516496\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435607; batch adversarial loss: 0.525161\n",
      "epoch 109; iter: 0; batch classifier loss: 0.427615; batch adversarial loss: 0.581785\n",
      "epoch 110; iter: 0; batch classifier loss: 0.394577; batch adversarial loss: 0.581499\n",
      "epoch 111; iter: 0; batch classifier loss: 0.510365; batch adversarial loss: 0.524795\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409190; batch adversarial loss: 0.516926\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417052; batch adversarial loss: 0.637156\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402088; batch adversarial loss: 0.590181\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355075; batch adversarial loss: 0.563208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.378020; batch adversarial loss: 0.489728\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374252; batch adversarial loss: 0.619091\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393890; batch adversarial loss: 0.564141\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342158; batch adversarial loss: 0.535660\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415888; batch adversarial loss: 0.507205\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376288; batch adversarial loss: 0.572601\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381372; batch adversarial loss: 0.591110\n",
      "epoch 123; iter: 0; batch classifier loss: 0.446855; batch adversarial loss: 0.535726\n",
      "epoch 124; iter: 0; batch classifier loss: 0.430096; batch adversarial loss: 0.563563\n",
      "epoch 125; iter: 0; batch classifier loss: 0.292656; batch adversarial loss: 0.553366\n",
      "epoch 126; iter: 0; batch classifier loss: 0.553037; batch adversarial loss: 0.497980\n",
      "epoch 127; iter: 0; batch classifier loss: 0.453616; batch adversarial loss: 0.593055\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381108; batch adversarial loss: 0.581490\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367022; batch adversarial loss: 0.563169\n",
      "epoch 130; iter: 0; batch classifier loss: 0.320443; batch adversarial loss: 0.617633\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388288; batch adversarial loss: 0.516530\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401288; batch adversarial loss: 0.535085\n",
      "epoch 133; iter: 0; batch classifier loss: 0.516133; batch adversarial loss: 0.544865\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365828; batch adversarial loss: 0.553505\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381993; batch adversarial loss: 0.581076\n",
      "epoch 136; iter: 0; batch classifier loss: 0.422099; batch adversarial loss: 0.516995\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358445; batch adversarial loss: 0.636430\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370783; batch adversarial loss: 0.517038\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343464; batch adversarial loss: 0.535797\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405992; batch adversarial loss: 0.525258\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409020; batch adversarial loss: 0.534831\n",
      "epoch 142; iter: 0; batch classifier loss: 0.394690; batch adversarial loss: 0.581759\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405755; batch adversarial loss: 0.572495\n",
      "epoch 144; iter: 0; batch classifier loss: 0.472254; batch adversarial loss: 0.517003\n",
      "epoch 145; iter: 0; batch classifier loss: 0.408328; batch adversarial loss: 0.507200\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395182; batch adversarial loss: 0.497732\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345091; batch adversarial loss: 0.581280\n",
      "epoch 148; iter: 0; batch classifier loss: 0.454809; batch adversarial loss: 0.553047\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374064; batch adversarial loss: 0.535942\n",
      "epoch 150; iter: 0; batch classifier loss: 0.442331; batch adversarial loss: 0.516487\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350223; batch adversarial loss: 0.535042\n",
      "epoch 152; iter: 0; batch classifier loss: 0.439287; batch adversarial loss: 0.516712\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402133; batch adversarial loss: 0.442645\n",
      "epoch 154; iter: 0; batch classifier loss: 0.431605; batch adversarial loss: 0.516635\n",
      "epoch 155; iter: 0; batch classifier loss: 0.429446; batch adversarial loss: 0.470469\n",
      "epoch 156; iter: 0; batch classifier loss: 0.413241; batch adversarial loss: 0.525642\n",
      "epoch 157; iter: 0; batch classifier loss: 0.401465; batch adversarial loss: 0.572273\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403332; batch adversarial loss: 0.563001\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383363; batch adversarial loss: 0.451757\n",
      "epoch 160; iter: 0; batch classifier loss: 0.403229; batch adversarial loss: 0.470463\n",
      "epoch 161; iter: 0; batch classifier loss: 0.349293; batch adversarial loss: 0.517061\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355804; batch adversarial loss: 0.562701\n",
      "epoch 163; iter: 0; batch classifier loss: 0.408055; batch adversarial loss: 0.600568\n",
      "epoch 164; iter: 0; batch classifier loss: 0.422447; batch adversarial loss: 0.553205\n",
      "epoch 165; iter: 0; batch classifier loss: 0.402514; batch adversarial loss: 0.544270\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380452; batch adversarial loss: 0.553251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.405622; batch adversarial loss: 0.572271\n",
      "epoch 168; iter: 0; batch classifier loss: 0.451479; batch adversarial loss: 0.497580\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352904; batch adversarial loss: 0.544031\n",
      "epoch 170; iter: 0; batch classifier loss: 0.407171; batch adversarial loss: 0.536739\n",
      "epoch 171; iter: 0; batch classifier loss: 0.400004; batch adversarial loss: 0.563725\n",
      "epoch 172; iter: 0; batch classifier loss: 0.448834; batch adversarial loss: 0.554267\n",
      "epoch 173; iter: 0; batch classifier loss: 0.336428; batch adversarial loss: 0.599497\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375625; batch adversarial loss: 0.516754\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409292; batch adversarial loss: 0.562965\n",
      "epoch 176; iter: 0; batch classifier loss: 0.312794; batch adversarial loss: 0.573192\n",
      "epoch 177; iter: 0; batch classifier loss: 0.338761; batch adversarial loss: 0.544802\n",
      "epoch 178; iter: 0; batch classifier loss: 0.413318; batch adversarial loss: 0.591049\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334160; batch adversarial loss: 0.535259\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389054; batch adversarial loss: 0.498955\n",
      "epoch 181; iter: 0; batch classifier loss: 0.369827; batch adversarial loss: 0.581668\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337726; batch adversarial loss: 0.609871\n",
      "epoch 183; iter: 0; batch classifier loss: 0.283407; batch adversarial loss: 0.525940\n",
      "epoch 184; iter: 0; batch classifier loss: 0.471388; batch adversarial loss: 0.507545\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330411; batch adversarial loss: 0.544116\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367409; batch adversarial loss: 0.526025\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364428; batch adversarial loss: 0.526435\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314593; batch adversarial loss: 0.590948\n",
      "epoch 189; iter: 0; batch classifier loss: 0.451035; batch adversarial loss: 0.516766\n",
      "epoch 190; iter: 0; batch classifier loss: 0.317554; batch adversarial loss: 0.545065\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381868; batch adversarial loss: 0.562910\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334012; batch adversarial loss: 0.461481\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348296; batch adversarial loss: 0.507998\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384623; batch adversarial loss: 0.479327\n",
      "epoch 195; iter: 0; batch classifier loss: 0.425605; batch adversarial loss: 0.562678\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366380; batch adversarial loss: 0.507445\n",
      "epoch 197; iter: 0; batch classifier loss: 0.300020; batch adversarial loss: 0.469726\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343943; batch adversarial loss: 0.582290\n",
      "epoch 199; iter: 0; batch classifier loss: 0.341040; batch adversarial loss: 0.544026\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706027; batch adversarial loss: 0.671778\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610391; batch adversarial loss: 0.654785\n",
      "epoch 2; iter: 0; batch classifier loss: 0.559615; batch adversarial loss: 0.628340\n",
      "epoch 3; iter: 0; batch classifier loss: 0.596730; batch adversarial loss: 0.624591\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521667; batch adversarial loss: 0.625589\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515413; batch adversarial loss: 0.616565\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592055; batch adversarial loss: 0.582922\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579756; batch adversarial loss: 0.616080\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490953; batch adversarial loss: 0.595586\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553409; batch adversarial loss: 0.638724\n",
      "epoch 10; iter: 0; batch classifier loss: 0.607192; batch adversarial loss: 0.629942\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565449; batch adversarial loss: 0.566016\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532714; batch adversarial loss: 0.542250\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506102; batch adversarial loss: 0.565177\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529301; batch adversarial loss: 0.579818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566974; batch adversarial loss: 0.583847\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503150; batch adversarial loss: 0.552359\n",
      "epoch 17; iter: 0; batch classifier loss: 0.551109; batch adversarial loss: 0.507976\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491531; batch adversarial loss: 0.555174\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459992; batch adversarial loss: 0.537820\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456186; batch adversarial loss: 0.562390\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456961; batch adversarial loss: 0.576766\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450192; batch adversarial loss: 0.516558\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479161; batch adversarial loss: 0.540354\n",
      "epoch 24; iter: 0; batch classifier loss: 0.627246; batch adversarial loss: 0.531857\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470612; batch adversarial loss: 0.553607\n",
      "epoch 26; iter: 0; batch classifier loss: 0.481318; batch adversarial loss: 0.515889\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481054; batch adversarial loss: 0.492922\n",
      "epoch 28; iter: 0; batch classifier loss: 0.505929; batch adversarial loss: 0.545996\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524041; batch adversarial loss: 0.572575\n",
      "epoch 30; iter: 0; batch classifier loss: 0.563878; batch adversarial loss: 0.481871\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453004; batch adversarial loss: 0.619076\n",
      "epoch 32; iter: 0; batch classifier loss: 0.542747; batch adversarial loss: 0.520290\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444890; batch adversarial loss: 0.526648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.500734; batch adversarial loss: 0.483474\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458092; batch adversarial loss: 0.518455\n",
      "epoch 36; iter: 0; batch classifier loss: 0.536144; batch adversarial loss: 0.507929\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425811; batch adversarial loss: 0.588918\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488040; batch adversarial loss: 0.517802\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437724; batch adversarial loss: 0.444758\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420579; batch adversarial loss: 0.554306\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476216; batch adversarial loss: 0.525646\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463422; batch adversarial loss: 0.544329\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458121; batch adversarial loss: 0.526522\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448088; batch adversarial loss: 0.489274\n",
      "epoch 45; iter: 0; batch classifier loss: 0.522734; batch adversarial loss: 0.544789\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495833; batch adversarial loss: 0.534799\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437633; batch adversarial loss: 0.479356\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491530; batch adversarial loss: 0.460821\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452079; batch adversarial loss: 0.498450\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433624; batch adversarial loss: 0.535232\n",
      "epoch 51; iter: 0; batch classifier loss: 0.326103; batch adversarial loss: 0.553897\n",
      "epoch 52; iter: 0; batch classifier loss: 0.370473; batch adversarial loss: 0.552956\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413241; batch adversarial loss: 0.553215\n",
      "epoch 54; iter: 0; batch classifier loss: 0.391531; batch adversarial loss: 0.516490\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393066; batch adversarial loss: 0.591134\n",
      "epoch 56; iter: 0; batch classifier loss: 0.461706; batch adversarial loss: 0.475538\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401326; batch adversarial loss: 0.516530\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440298; batch adversarial loss: 0.572118\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388191; batch adversarial loss: 0.495517\n",
      "epoch 60; iter: 0; batch classifier loss: 0.353519; batch adversarial loss: 0.534700\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432905; batch adversarial loss: 0.497167\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386209; batch adversarial loss: 0.590191\n",
      "epoch 63; iter: 0; batch classifier loss: 0.471954; batch adversarial loss: 0.535147\n",
      "epoch 64; iter: 0; batch classifier loss: 0.330825; batch adversarial loss: 0.572099\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397910; batch adversarial loss: 0.535331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.339338; batch adversarial loss: 0.589677\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460030; batch adversarial loss: 0.526304\n",
      "epoch 68; iter: 0; batch classifier loss: 0.471477; batch adversarial loss: 0.451605\n",
      "epoch 69; iter: 0; batch classifier loss: 0.441017; batch adversarial loss: 0.478587\n",
      "epoch 70; iter: 0; batch classifier loss: 0.376254; batch adversarial loss: 0.489967\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450768; batch adversarial loss: 0.572977\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422190; batch adversarial loss: 0.571670\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383717; batch adversarial loss: 0.526032\n",
      "epoch 74; iter: 0; batch classifier loss: 0.438681; batch adversarial loss: 0.562460\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413542; batch adversarial loss: 0.553877\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367023; batch adversarial loss: 0.544125\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395279; batch adversarial loss: 0.488939\n",
      "epoch 78; iter: 0; batch classifier loss: 0.474563; batch adversarial loss: 0.572006\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391189; batch adversarial loss: 0.507860\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399759; batch adversarial loss: 0.497707\n",
      "epoch 81; iter: 0; batch classifier loss: 0.362766; batch adversarial loss: 0.637068\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443363; batch adversarial loss: 0.599746\n",
      "epoch 83; iter: 0; batch classifier loss: 0.408886; batch adversarial loss: 0.488592\n",
      "epoch 84; iter: 0; batch classifier loss: 0.493952; batch adversarial loss: 0.460392\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424522; batch adversarial loss: 0.544789\n",
      "epoch 86; iter: 0; batch classifier loss: 0.536381; batch adversarial loss: 0.489284\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396709; batch adversarial loss: 0.554872\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354033; batch adversarial loss: 0.553103\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424849; batch adversarial loss: 0.534128\n",
      "epoch 90; iter: 0; batch classifier loss: 0.310673; batch adversarial loss: 0.589690\n",
      "epoch 91; iter: 0; batch classifier loss: 0.422642; batch adversarial loss: 0.526129\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398154; batch adversarial loss: 0.580716\n",
      "epoch 93; iter: 0; batch classifier loss: 0.453837; batch adversarial loss: 0.498641\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422416; batch adversarial loss: 0.461442\n",
      "epoch 95; iter: 0; batch classifier loss: 0.480978; batch adversarial loss: 0.562528\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402552; batch adversarial loss: 0.580654\n",
      "epoch 97; iter: 0; batch classifier loss: 0.453382; batch adversarial loss: 0.516412\n",
      "epoch 98; iter: 0; batch classifier loss: 0.304569; batch adversarial loss: 0.535793\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375686; batch adversarial loss: 0.489064\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404370; batch adversarial loss: 0.645592\n",
      "epoch 101; iter: 0; batch classifier loss: 0.369766; batch adversarial loss: 0.544412\n",
      "epoch 102; iter: 0; batch classifier loss: 0.418388; batch adversarial loss: 0.534933\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358751; batch adversarial loss: 0.637105\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409931; batch adversarial loss: 0.544971\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405917; batch adversarial loss: 0.525683\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443195; batch adversarial loss: 0.534521\n",
      "epoch 107; iter: 0; batch classifier loss: 0.395202; batch adversarial loss: 0.582102\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386037; batch adversarial loss: 0.554913\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356667; batch adversarial loss: 0.573082\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377900; batch adversarial loss: 0.544057\n",
      "epoch 111; iter: 0; batch classifier loss: 0.432245; batch adversarial loss: 0.536789\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363995; batch adversarial loss: 0.460334\n",
      "epoch 113; iter: 0; batch classifier loss: 0.444625; batch adversarial loss: 0.591941\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384842; batch adversarial loss: 0.544726\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356829; batch adversarial loss: 0.580867\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384493; batch adversarial loss: 0.544060\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405708; batch adversarial loss: 0.507103\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391332; batch adversarial loss: 0.534814\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423023; batch adversarial loss: 0.543455\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422698; batch adversarial loss: 0.516053\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400251; batch adversarial loss: 0.573301\n",
      "epoch 122; iter: 0; batch classifier loss: 0.354603; batch adversarial loss: 0.451823\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355551; batch adversarial loss: 0.516514\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376540; batch adversarial loss: 0.591120\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377606; batch adversarial loss: 0.619537\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353355; batch adversarial loss: 0.543861\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371921; batch adversarial loss: 0.581380\n",
      "epoch 128; iter: 0; batch classifier loss: 0.452891; batch adversarial loss: 0.554156\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377143; batch adversarial loss: 0.497258\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414521; batch adversarial loss: 0.553625\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407998; batch adversarial loss: 0.515133\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394854; batch adversarial loss: 0.608224\n",
      "epoch 133; iter: 0; batch classifier loss: 0.435527; batch adversarial loss: 0.507231\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384718; batch adversarial loss: 0.506334\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350441; batch adversarial loss: 0.499034\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354993; batch adversarial loss: 0.562210\n",
      "epoch 137; iter: 0; batch classifier loss: 0.448547; batch adversarial loss: 0.563321\n",
      "epoch 138; iter: 0; batch classifier loss: 0.430094; batch adversarial loss: 0.554720\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366840; batch adversarial loss: 0.552382\n",
      "epoch 140; iter: 0; batch classifier loss: 0.408772; batch adversarial loss: 0.534995\n",
      "epoch 141; iter: 0; batch classifier loss: 0.448508; batch adversarial loss: 0.525937\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387814; batch adversarial loss: 0.571946\n",
      "epoch 143; iter: 0; batch classifier loss: 0.424252; batch adversarial loss: 0.564150\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354937; batch adversarial loss: 0.545661\n",
      "epoch 145; iter: 0; batch classifier loss: 0.389986; batch adversarial loss: 0.536595\n",
      "epoch 146; iter: 0; batch classifier loss: 0.426544; batch adversarial loss: 0.571709\n",
      "epoch 147; iter: 0; batch classifier loss: 0.313730; batch adversarial loss: 0.489318\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365910; batch adversarial loss: 0.470686\n",
      "epoch 149; iter: 0; batch classifier loss: 0.444637; batch adversarial loss: 0.534999\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325726; batch adversarial loss: 0.562931\n",
      "epoch 151; iter: 0; batch classifier loss: 0.314708; batch adversarial loss: 0.507722\n",
      "epoch 152; iter: 0; batch classifier loss: 0.325272; batch adversarial loss: 0.535289\n",
      "epoch 153; iter: 0; batch classifier loss: 0.304487; batch adversarial loss: 0.599368\n",
      "epoch 154; iter: 0; batch classifier loss: 0.336717; batch adversarial loss: 0.571934\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356160; batch adversarial loss: 0.561692\n",
      "epoch 156; iter: 0; batch classifier loss: 0.369554; batch adversarial loss: 0.506989\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337392; batch adversarial loss: 0.526128\n",
      "epoch 158; iter: 0; batch classifier loss: 0.444926; batch adversarial loss: 0.516917\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354100; batch adversarial loss: 0.535314\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375542; batch adversarial loss: 0.516934\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414813; batch adversarial loss: 0.535518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.378699; batch adversarial loss: 0.563026\n",
      "epoch 163; iter: 0; batch classifier loss: 0.441854; batch adversarial loss: 0.637602\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410335; batch adversarial loss: 0.497698\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366952; batch adversarial loss: 0.572016\n",
      "epoch 166; iter: 0; batch classifier loss: 0.404664; batch adversarial loss: 0.553698\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348642; batch adversarial loss: 0.535185\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335891; batch adversarial loss: 0.535983\n",
      "epoch 169; iter: 0; batch classifier loss: 0.399783; batch adversarial loss: 0.470306\n",
      "epoch 170; iter: 0; batch classifier loss: 0.431718; batch adversarial loss: 0.563351\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372845; batch adversarial loss: 0.629697\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360018; batch adversarial loss: 0.534464\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392137; batch adversarial loss: 0.572489\n",
      "epoch 174; iter: 0; batch classifier loss: 0.461738; batch adversarial loss: 0.571678\n",
      "epoch 175; iter: 0; batch classifier loss: 0.354400; batch adversarial loss: 0.562559\n",
      "epoch 176; iter: 0; batch classifier loss: 0.375058; batch adversarial loss: 0.526390\n",
      "epoch 177; iter: 0; batch classifier loss: 0.420925; batch adversarial loss: 0.544902\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369362; batch adversarial loss: 0.562620\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380027; batch adversarial loss: 0.496435\n",
      "epoch 180; iter: 0; batch classifier loss: 0.357499; batch adversarial loss: 0.553311\n",
      "epoch 181; iter: 0; batch classifier loss: 0.296546; batch adversarial loss: 0.497372\n",
      "epoch 182; iter: 0; batch classifier loss: 0.393947; batch adversarial loss: 0.376814\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355274; batch adversarial loss: 0.479127\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350915; batch adversarial loss: 0.535344\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316766; batch adversarial loss: 0.664716\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377808; batch adversarial loss: 0.524337\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360361; batch adversarial loss: 0.514689\n",
      "epoch 188; iter: 0; batch classifier loss: 0.325464; batch adversarial loss: 0.620062\n",
      "epoch 189; iter: 0; batch classifier loss: 0.312529; batch adversarial loss: 0.562156\n",
      "epoch 190; iter: 0; batch classifier loss: 0.458374; batch adversarial loss: 0.462536\n",
      "epoch 191; iter: 0; batch classifier loss: 0.326993; batch adversarial loss: 0.554311\n",
      "epoch 192; iter: 0; batch classifier loss: 0.289208; batch adversarial loss: 0.534258\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362443; batch adversarial loss: 0.480743\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380700; batch adversarial loss: 0.508160\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336299; batch adversarial loss: 0.552248\n",
      "epoch 196; iter: 0; batch classifier loss: 0.389212; batch adversarial loss: 0.526375\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358216; batch adversarial loss: 0.441707\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354012; batch adversarial loss: 0.525962\n",
      "epoch 199; iter: 0; batch classifier loss: 0.393057; batch adversarial loss: 0.599023\n",
      "epoch 0; iter: 0; batch classifier loss: 0.768286; batch adversarial loss: 1.027603\n",
      "epoch 1; iter: 0; batch classifier loss: 0.844504; batch adversarial loss: 1.121797\n",
      "epoch 2; iter: 0; batch classifier loss: 1.011103; batch adversarial loss: 1.118077\n",
      "epoch 3; iter: 0; batch classifier loss: 1.071761; batch adversarial loss: 1.039672\n",
      "epoch 4; iter: 0; batch classifier loss: 1.058278; batch adversarial loss: 0.964245\n",
      "epoch 5; iter: 0; batch classifier loss: 0.921824; batch adversarial loss: 0.856475\n",
      "epoch 6; iter: 0; batch classifier loss: 0.981987; batch adversarial loss: 0.824174\n",
      "epoch 7; iter: 0; batch classifier loss: 0.874805; batch adversarial loss: 0.764623\n",
      "epoch 8; iter: 0; batch classifier loss: 0.759757; batch adversarial loss: 0.713581\n",
      "epoch 9; iter: 0; batch classifier loss: 0.611077; batch adversarial loss: 0.643672\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612379; batch adversarial loss: 0.635106\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544461; batch adversarial loss: 0.582510\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533953; batch adversarial loss: 0.620576\n",
      "epoch 13; iter: 0; batch classifier loss: 0.586273; batch adversarial loss: 0.599397\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529216; batch adversarial loss: 0.640849\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552433; batch adversarial loss: 0.559122\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561925; batch adversarial loss: 0.537179\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521649; batch adversarial loss: 0.568576\n",
      "epoch 18; iter: 0; batch classifier loss: 0.578512; batch adversarial loss: 0.589136\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497124; batch adversarial loss: 0.490599\n",
      "epoch 20; iter: 0; batch classifier loss: 0.549561; batch adversarial loss: 0.566550\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494505; batch adversarial loss: 0.559635\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490187; batch adversarial loss: 0.571325\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438644; batch adversarial loss: 0.569282\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508745; batch adversarial loss: 0.603722\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509838; batch adversarial loss: 0.568857\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520357; batch adversarial loss: 0.621137\n",
      "epoch 27; iter: 0; batch classifier loss: 0.528460; batch adversarial loss: 0.546623\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474548; batch adversarial loss: 0.553858\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477634; batch adversarial loss: 0.606978\n",
      "epoch 30; iter: 0; batch classifier loss: 0.393995; batch adversarial loss: 0.546060\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474963; batch adversarial loss: 0.579239\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444058; batch adversarial loss: 0.540214\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481626; batch adversarial loss: 0.575031\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416874; batch adversarial loss: 0.569955\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465756; batch adversarial loss: 0.626479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476931; batch adversarial loss: 0.515479\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440181; batch adversarial loss: 0.589083\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398193; batch adversarial loss: 0.439072\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457770; batch adversarial loss: 0.461118\n",
      "epoch 40; iter: 0; batch classifier loss: 0.550973; batch adversarial loss: 0.477216\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426615; batch adversarial loss: 0.579164\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448630; batch adversarial loss: 0.670917\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438414; batch adversarial loss: 0.509918\n",
      "epoch 44; iter: 0; batch classifier loss: 0.453115; batch adversarial loss: 0.599191\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459426; batch adversarial loss: 0.575865\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462849; batch adversarial loss: 0.506554\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399978; batch adversarial loss: 0.524763\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401435; batch adversarial loss: 0.643540\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475544; batch adversarial loss: 0.551516\n",
      "epoch 50; iter: 0; batch classifier loss: 0.377916; batch adversarial loss: 0.516733\n",
      "epoch 51; iter: 0; batch classifier loss: 0.342986; batch adversarial loss: 0.543747\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430701; batch adversarial loss: 0.514417\n",
      "epoch 53; iter: 0; batch classifier loss: 0.433188; batch adversarial loss: 0.506811\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406527; batch adversarial loss: 0.586981\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459187; batch adversarial loss: 0.599548\n",
      "epoch 56; iter: 0; batch classifier loss: 0.386679; batch adversarial loss: 0.554675\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445130; batch adversarial loss: 0.455858\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425330; batch adversarial loss: 0.613642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.517266; batch adversarial loss: 0.508803\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397663; batch adversarial loss: 0.545314\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402839; batch adversarial loss: 0.593918\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445163; batch adversarial loss: 0.569521\n",
      "epoch 63; iter: 0; batch classifier loss: 0.357802; batch adversarial loss: 0.581391\n",
      "epoch 64; iter: 0; batch classifier loss: 0.371839; batch adversarial loss: 0.480904\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376843; batch adversarial loss: 0.598094\n",
      "epoch 66; iter: 0; batch classifier loss: 0.376803; batch adversarial loss: 0.643158\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384748; batch adversarial loss: 0.572677\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437407; batch adversarial loss: 0.508117\n",
      "epoch 69; iter: 0; batch classifier loss: 0.352889; batch adversarial loss: 0.599861\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385674; batch adversarial loss: 0.526821\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451928; batch adversarial loss: 0.508142\n",
      "epoch 72; iter: 0; batch classifier loss: 0.363844; batch adversarial loss: 0.589925\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383214; batch adversarial loss: 0.589719\n",
      "epoch 74; iter: 0; batch classifier loss: 0.357064; batch adversarial loss: 0.490439\n",
      "epoch 75; iter: 0; batch classifier loss: 0.475733; batch adversarial loss: 0.526993\n",
      "epoch 76; iter: 0; batch classifier loss: 0.365896; batch adversarial loss: 0.553183\n",
      "epoch 77; iter: 0; batch classifier loss: 0.358662; batch adversarial loss: 0.525977\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380827; batch adversarial loss: 0.453830\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422657; batch adversarial loss: 0.599743\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393099; batch adversarial loss: 0.525351\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370095; batch adversarial loss: 0.562280\n",
      "epoch 82; iter: 0; batch classifier loss: 0.464485; batch adversarial loss: 0.579614\n",
      "epoch 83; iter: 0; batch classifier loss: 0.325433; batch adversarial loss: 0.516769\n",
      "epoch 84; iter: 0; batch classifier loss: 0.483513; batch adversarial loss: 0.515542\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408644; batch adversarial loss: 0.606650\n",
      "epoch 86; iter: 0; batch classifier loss: 0.323527; batch adversarial loss: 0.589888\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393145; batch adversarial loss: 0.561918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378430; batch adversarial loss: 0.497616\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376860; batch adversarial loss: 0.510051\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418750; batch adversarial loss: 0.526580\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413638; batch adversarial loss: 0.570781\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368579; batch adversarial loss: 0.564082\n",
      "epoch 93; iter: 0; batch classifier loss: 0.486590; batch adversarial loss: 0.553248\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402673; batch adversarial loss: 0.552495\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359602; batch adversarial loss: 0.499393\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349411; batch adversarial loss: 0.561640\n",
      "epoch 97; iter: 0; batch classifier loss: 0.426260; batch adversarial loss: 0.444047\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373944; batch adversarial loss: 0.472581\n",
      "epoch 99; iter: 0; batch classifier loss: 0.379333; batch adversarial loss: 0.509469\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396764; batch adversarial loss: 0.525674\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390173; batch adversarial loss: 0.570389\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363544; batch adversarial loss: 0.580374\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402566; batch adversarial loss: 0.526650\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390046; batch adversarial loss: 0.498520\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365840; batch adversarial loss: 0.561315\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398187; batch adversarial loss: 0.522360\n",
      "epoch 107; iter: 0; batch classifier loss: 0.376848; batch adversarial loss: 0.608228\n",
      "epoch 108; iter: 0; batch classifier loss: 0.418084; batch adversarial loss: 0.524907\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367011; batch adversarial loss: 0.517998\n",
      "epoch 110; iter: 0; batch classifier loss: 0.342681; batch adversarial loss: 0.506845\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394674; batch adversarial loss: 0.471267\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381073; batch adversarial loss: 0.534958\n",
      "epoch 113; iter: 0; batch classifier loss: 0.420107; batch adversarial loss: 0.652776\n",
      "epoch 114; iter: 0; batch classifier loss: 0.295836; batch adversarial loss: 0.561536\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418740; batch adversarial loss: 0.569695\n",
      "epoch 116; iter: 0; batch classifier loss: 0.320447; batch adversarial loss: 0.479450\n",
      "epoch 117; iter: 0; batch classifier loss: 0.394265; batch adversarial loss: 0.499204\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347324; batch adversarial loss: 0.510450\n",
      "epoch 119; iter: 0; batch classifier loss: 0.434807; batch adversarial loss: 0.563169\n",
      "epoch 120; iter: 0; batch classifier loss: 0.313714; batch adversarial loss: 0.464874\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373947; batch adversarial loss: 0.470586\n",
      "epoch 122; iter: 0; batch classifier loss: 0.354193; batch adversarial loss: 0.489882\n",
      "epoch 123; iter: 0; batch classifier loss: 0.418102; batch adversarial loss: 0.533994\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381361; batch adversarial loss: 0.498869\n",
      "epoch 125; iter: 0; batch classifier loss: 0.465868; batch adversarial loss: 0.545348\n",
      "epoch 126; iter: 0; batch classifier loss: 0.409168; batch adversarial loss: 0.516252\n",
      "epoch 127; iter: 0; batch classifier loss: 0.297610; batch adversarial loss: 0.507417\n",
      "epoch 128; iter: 0; batch classifier loss: 0.413674; batch adversarial loss: 0.524897\n",
      "epoch 129; iter: 0; batch classifier loss: 0.371306; batch adversarial loss: 0.571450\n",
      "epoch 130; iter: 0; batch classifier loss: 0.351932; batch adversarial loss: 0.557216\n",
      "epoch 131; iter: 0; batch classifier loss: 0.424183; batch adversarial loss: 0.473768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.426989; batch adversarial loss: 0.591145\n",
      "epoch 133; iter: 0; batch classifier loss: 0.368305; batch adversarial loss: 0.561557\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364321; batch adversarial loss: 0.533814\n",
      "epoch 135; iter: 0; batch classifier loss: 0.426787; batch adversarial loss: 0.531193\n",
      "epoch 136; iter: 0; batch classifier loss: 0.331001; batch adversarial loss: 0.569652\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385234; batch adversarial loss: 0.488084\n",
      "epoch 138; iter: 0; batch classifier loss: 0.321636; batch adversarial loss: 0.560075\n",
      "epoch 139; iter: 0; batch classifier loss: 0.365952; batch adversarial loss: 0.492334\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338406; batch adversarial loss: 0.537558\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375166; batch adversarial loss: 0.545153\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393226; batch adversarial loss: 0.539497\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396582; batch adversarial loss: 0.498599\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357164; batch adversarial loss: 0.481931\n",
      "epoch 145; iter: 0; batch classifier loss: 0.388305; batch adversarial loss: 0.597386\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371322; batch adversarial loss: 0.516136\n",
      "epoch 147; iter: 0; batch classifier loss: 0.421253; batch adversarial loss: 0.636594\n",
      "epoch 148; iter: 0; batch classifier loss: 0.461305; batch adversarial loss: 0.589432\n",
      "epoch 149; iter: 0; batch classifier loss: 0.308197; batch adversarial loss: 0.511125\n",
      "epoch 150; iter: 0; batch classifier loss: 0.318270; batch adversarial loss: 0.497099\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347105; batch adversarial loss: 0.560356\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384158; batch adversarial loss: 0.554447\n",
      "epoch 153; iter: 0; batch classifier loss: 0.288569; batch adversarial loss: 0.607262\n",
      "epoch 154; iter: 0; batch classifier loss: 0.391385; batch adversarial loss: 0.518046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.397212; batch adversarial loss: 0.561114\n",
      "epoch 156; iter: 0; batch classifier loss: 0.411580; batch adversarial loss: 0.517031\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375848; batch adversarial loss: 0.591130\n",
      "epoch 158; iter: 0; batch classifier loss: 0.400973; batch adversarial loss: 0.490012\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351494; batch adversarial loss: 0.599622\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353103; batch adversarial loss: 0.542009\n",
      "epoch 161; iter: 0; batch classifier loss: 0.313740; batch adversarial loss: 0.572073\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311015; batch adversarial loss: 0.607777\n",
      "epoch 163; iter: 0; batch classifier loss: 0.327028; batch adversarial loss: 0.526809\n",
      "epoch 164; iter: 0; batch classifier loss: 0.424009; batch adversarial loss: 0.536436\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315919; batch adversarial loss: 0.498744\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367789; batch adversarial loss: 0.548928\n",
      "epoch 167; iter: 0; batch classifier loss: 0.466431; batch adversarial loss: 0.581726\n",
      "epoch 168; iter: 0; batch classifier loss: 0.384050; batch adversarial loss: 0.563954\n",
      "epoch 169; iter: 0; batch classifier loss: 0.437346; batch adversarial loss: 0.498682\n",
      "epoch 170; iter: 0; batch classifier loss: 0.399192; batch adversarial loss: 0.571714\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330885; batch adversarial loss: 0.471563\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336140; batch adversarial loss: 0.506742\n",
      "epoch 173; iter: 0; batch classifier loss: 0.306377; batch adversarial loss: 0.525337\n",
      "epoch 174; iter: 0; batch classifier loss: 0.403770; batch adversarial loss: 0.497707\n",
      "epoch 175; iter: 0; batch classifier loss: 0.324265; batch adversarial loss: 0.561778\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365063; batch adversarial loss: 0.499272\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377243; batch adversarial loss: 0.534408\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371253; batch adversarial loss: 0.491101\n",
      "epoch 179; iter: 0; batch classifier loss: 0.321085; batch adversarial loss: 0.546795\n",
      "epoch 180; iter: 0; batch classifier loss: 0.408397; batch adversarial loss: 0.535170\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311067; batch adversarial loss: 0.571772\n",
      "epoch 182; iter: 0; batch classifier loss: 0.313986; batch adversarial loss: 0.516146\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366864; batch adversarial loss: 0.546380\n",
      "epoch 184; iter: 0; batch classifier loss: 0.395014; batch adversarial loss: 0.522897\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367151; batch adversarial loss: 0.555625\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348780; batch adversarial loss: 0.616132\n",
      "epoch 187; iter: 0; batch classifier loss: 0.349909; batch adversarial loss: 0.575889\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338068; batch adversarial loss: 0.493144\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414564; batch adversarial loss: 0.641814\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336098; batch adversarial loss: 0.544038\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337397; batch adversarial loss: 0.670059\n",
      "epoch 192; iter: 0; batch classifier loss: 0.306084; batch adversarial loss: 0.678393\n",
      "epoch 193; iter: 0; batch classifier loss: 0.466776; batch adversarial loss: 0.531211\n",
      "epoch 194; iter: 0; batch classifier loss: 0.266995; batch adversarial loss: 0.598188\n",
      "epoch 195; iter: 0; batch classifier loss: 0.284828; batch adversarial loss: 0.541449\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313581; batch adversarial loss: 0.588454\n",
      "epoch 197; iter: 0; batch classifier loss: 0.447078; batch adversarial loss: 0.599462\n",
      "epoch 198; iter: 0; batch classifier loss: 0.394978; batch adversarial loss: 0.500057\n",
      "epoch 199; iter: 0; batch classifier loss: 0.395314; batch adversarial loss: 0.498411\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684557; batch adversarial loss: 0.767725\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587892; batch adversarial loss: 0.742397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.504839; batch adversarial loss: 0.681610\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530842; batch adversarial loss: 0.679942\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567982; batch adversarial loss: 0.637706\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566307; batch adversarial loss: 0.639325\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545176; batch adversarial loss: 0.603907\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546563; batch adversarial loss: 0.572264\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528856; batch adversarial loss: 0.591681\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571455; batch adversarial loss: 0.573695\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504255; batch adversarial loss: 0.607970\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536937; batch adversarial loss: 0.547720\n",
      "epoch 12; iter: 0; batch classifier loss: 0.607468; batch adversarial loss: 0.530130\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520177; batch adversarial loss: 0.551103\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545979; batch adversarial loss: 0.572387\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506605; batch adversarial loss: 0.529569\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404025; batch adversarial loss: 0.573050\n",
      "epoch 17; iter: 0; batch classifier loss: 0.555675; batch adversarial loss: 0.607082\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523651; batch adversarial loss: 0.571347\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541725; batch adversarial loss: 0.631204\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487416; batch adversarial loss: 0.572034\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482296; batch adversarial loss: 0.523965\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475507; batch adversarial loss: 0.530687\n",
      "epoch 23; iter: 0; batch classifier loss: 0.549667; batch adversarial loss: 0.485783\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493191; batch adversarial loss: 0.559666\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516705; batch adversarial loss: 0.519105\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501976; batch adversarial loss: 0.523279\n",
      "epoch 27; iter: 0; batch classifier loss: 0.422177; batch adversarial loss: 0.543148\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491846; batch adversarial loss: 0.546962\n",
      "epoch 29; iter: 0; batch classifier loss: 0.540185; batch adversarial loss: 0.499133\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428327; batch adversarial loss: 0.576216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507334; batch adversarial loss: 0.532819\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469029; batch adversarial loss: 0.538600\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408903; batch adversarial loss: 0.563756\n",
      "epoch 34; iter: 0; batch classifier loss: 0.442909; batch adversarial loss: 0.563961\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447345; batch adversarial loss: 0.554764\n",
      "epoch 36; iter: 0; batch classifier loss: 0.486328; batch adversarial loss: 0.562163\n",
      "epoch 37; iter: 0; batch classifier loss: 0.468145; batch adversarial loss: 0.553264\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430710; batch adversarial loss: 0.553502\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470477; batch adversarial loss: 0.488212\n",
      "epoch 40; iter: 0; batch classifier loss: 0.410425; batch adversarial loss: 0.534942\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403554; batch adversarial loss: 0.572475\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477176; batch adversarial loss: 0.497309\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537683; batch adversarial loss: 0.640644\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445449; batch adversarial loss: 0.583306\n",
      "epoch 45; iter: 0; batch classifier loss: 0.493279; batch adversarial loss: 0.517594\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429146; batch adversarial loss: 0.544682\n",
      "epoch 47; iter: 0; batch classifier loss: 0.454212; batch adversarial loss: 0.526063\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412280; batch adversarial loss: 0.544115\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421868; batch adversarial loss: 0.562917\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430451; batch adversarial loss: 0.544061\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437473; batch adversarial loss: 0.507768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.415301; batch adversarial loss: 0.517232\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424174; batch adversarial loss: 0.573152\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385933; batch adversarial loss: 0.478140\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412086; batch adversarial loss: 0.487461\n",
      "epoch 56; iter: 0; batch classifier loss: 0.384034; batch adversarial loss: 0.516546\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402218; batch adversarial loss: 0.526758\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423065; batch adversarial loss: 0.525138\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421807; batch adversarial loss: 0.487249\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407720; batch adversarial loss: 0.496998\n",
      "epoch 61; iter: 0; batch classifier loss: 0.475273; batch adversarial loss: 0.553794\n",
      "epoch 62; iter: 0; batch classifier loss: 0.351490; batch adversarial loss: 0.516330\n",
      "epoch 63; iter: 0; batch classifier loss: 0.476564; batch adversarial loss: 0.506776\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404545; batch adversarial loss: 0.535027\n",
      "epoch 65; iter: 0; batch classifier loss: 0.493760; batch adversarial loss: 0.544818\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405113; batch adversarial loss: 0.525714\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414757; batch adversarial loss: 0.535989\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384770; batch adversarial loss: 0.506227\n",
      "epoch 69; iter: 0; batch classifier loss: 0.473365; batch adversarial loss: 0.486202\n",
      "epoch 70; iter: 0; batch classifier loss: 0.468597; batch adversarial loss: 0.562176\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437621; batch adversarial loss: 0.542397\n",
      "epoch 72; iter: 0; batch classifier loss: 0.337645; batch adversarial loss: 0.482811\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372315; batch adversarial loss: 0.504708\n",
      "epoch 74; iter: 0; batch classifier loss: 0.521929; batch adversarial loss: 0.506763\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424792; batch adversarial loss: 0.585938\n",
      "epoch 76; iter: 0; batch classifier loss: 0.507685; batch adversarial loss: 0.501561\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440764; batch adversarial loss: 0.595439\n",
      "epoch 78; iter: 0; batch classifier loss: 0.419036; batch adversarial loss: 0.576452\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373745; batch adversarial loss: 0.549460\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431561; batch adversarial loss: 0.556066\n",
      "epoch 81; iter: 0; batch classifier loss: 0.372683; batch adversarial loss: 0.526022\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390720; batch adversarial loss: 0.498935\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403392; batch adversarial loss: 0.507508\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437497; batch adversarial loss: 0.579492\n",
      "epoch 85; iter: 0; batch classifier loss: 0.478951; batch adversarial loss: 0.471424\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410323; batch adversarial loss: 0.500266\n",
      "epoch 87; iter: 0; batch classifier loss: 0.445742; batch adversarial loss: 0.609607\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368665; batch adversarial loss: 0.535559\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403511; batch adversarial loss: 0.554023\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450453; batch adversarial loss: 0.507252\n",
      "epoch 91; iter: 0; batch classifier loss: 0.462254; batch adversarial loss: 0.544200\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412131; batch adversarial loss: 0.516327\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439582; batch adversarial loss: 0.458624\n",
      "epoch 94; iter: 0; batch classifier loss: 0.338011; batch adversarial loss: 0.554941\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359087; batch adversarial loss: 0.601422\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389066; batch adversarial loss: 0.543992\n",
      "epoch 97; iter: 0; batch classifier loss: 0.417111; batch adversarial loss: 0.563011\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371066; batch adversarial loss: 0.610813\n",
      "epoch 99; iter: 0; batch classifier loss: 0.457086; batch adversarial loss: 0.554141\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374085; batch adversarial loss: 0.555413\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402304; batch adversarial loss: 0.630697\n",
      "epoch 102; iter: 0; batch classifier loss: 0.422340; batch adversarial loss: 0.554272\n",
      "epoch 103; iter: 0; batch classifier loss: 0.482984; batch adversarial loss: 0.496525\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371559; batch adversarial loss: 0.438518\n",
      "epoch 105; iter: 0; batch classifier loss: 0.346956; batch adversarial loss: 0.543597\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398794; batch adversarial loss: 0.545354\n",
      "epoch 107; iter: 0; batch classifier loss: 0.342703; batch adversarial loss: 0.525177\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388323; batch adversarial loss: 0.496151\n",
      "epoch 109; iter: 0; batch classifier loss: 0.404974; batch adversarial loss: 0.553943\n",
      "epoch 110; iter: 0; batch classifier loss: 0.331873; batch adversarial loss: 0.495894\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386985; batch adversarial loss: 0.494347\n",
      "epoch 112; iter: 0; batch classifier loss: 0.450061; batch adversarial loss: 0.551486\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377793; batch adversarial loss: 0.493969\n",
      "epoch 114; iter: 0; batch classifier loss: 0.348865; batch adversarial loss: 0.566595\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374466; batch adversarial loss: 0.535246\n",
      "epoch 116; iter: 0; batch classifier loss: 0.437495; batch adversarial loss: 0.478383\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339890; batch adversarial loss: 0.533993\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382127; batch adversarial loss: 0.591521\n",
      "epoch 119; iter: 0; batch classifier loss: 0.345550; batch adversarial loss: 0.584157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.348211; batch adversarial loss: 0.505077\n",
      "epoch 121; iter: 0; batch classifier loss: 0.438675; batch adversarial loss: 0.508863\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383907; batch adversarial loss: 0.507340\n",
      "epoch 123; iter: 0; batch classifier loss: 0.461430; batch adversarial loss: 0.451792\n",
      "epoch 124; iter: 0; batch classifier loss: 0.471929; batch adversarial loss: 0.565300\n",
      "epoch 125; iter: 0; batch classifier loss: 0.416279; batch adversarial loss: 0.516603\n",
      "epoch 126; iter: 0; batch classifier loss: 0.341239; batch adversarial loss: 0.507763\n",
      "epoch 127; iter: 0; batch classifier loss: 0.357297; batch adversarial loss: 0.516283\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368041; batch adversarial loss: 0.515585\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358035; batch adversarial loss: 0.487691\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385368; batch adversarial loss: 0.593017\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389957; batch adversarial loss: 0.583082\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390272; batch adversarial loss: 0.583342\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408989; batch adversarial loss: 0.506333\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383696; batch adversarial loss: 0.488295\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388234; batch adversarial loss: 0.449569\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377821; batch adversarial loss: 0.450501\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424782; batch adversarial loss: 0.506843\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369307; batch adversarial loss: 0.554318\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343840; batch adversarial loss: 0.543369\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347634; batch adversarial loss: 0.534340\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383664; batch adversarial loss: 0.477953\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345978; batch adversarial loss: 0.477692\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377175; batch adversarial loss: 0.582246\n",
      "epoch 144; iter: 0; batch classifier loss: 0.421433; batch adversarial loss: 0.526625\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349679; batch adversarial loss: 0.563226\n",
      "epoch 146; iter: 0; batch classifier loss: 0.452271; batch adversarial loss: 0.555745\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332492; batch adversarial loss: 0.544849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.443138; batch adversarial loss: 0.432236\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375736; batch adversarial loss: 0.544972\n",
      "epoch 150; iter: 0; batch classifier loss: 0.412809; batch adversarial loss: 0.487760\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374038; batch adversarial loss: 0.526286\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390934; batch adversarial loss: 0.497060\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327876; batch adversarial loss: 0.525531\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362903; batch adversarial loss: 0.572203\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358281; batch adversarial loss: 0.534754\n",
      "epoch 156; iter: 0; batch classifier loss: 0.420978; batch adversarial loss: 0.487203\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356285; batch adversarial loss: 0.564706\n",
      "epoch 158; iter: 0; batch classifier loss: 0.421164; batch adversarial loss: 0.465610\n",
      "epoch 159; iter: 0; batch classifier loss: 0.326671; batch adversarial loss: 0.525469\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351492; batch adversarial loss: 0.573670\n",
      "epoch 161; iter: 0; batch classifier loss: 0.470161; batch adversarial loss: 0.518971\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343911; batch adversarial loss: 0.516715\n",
      "epoch 163; iter: 0; batch classifier loss: 0.444501; batch adversarial loss: 0.486323\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386729; batch adversarial loss: 0.553685\n",
      "epoch 165; iter: 0; batch classifier loss: 0.317813; batch adversarial loss: 0.516544\n",
      "epoch 166; iter: 0; batch classifier loss: 0.290745; batch adversarial loss: 0.583449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360147; batch adversarial loss: 0.497251\n",
      "epoch 168; iter: 0; batch classifier loss: 0.421325; batch adversarial loss: 0.686884\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407357; batch adversarial loss: 0.526251\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397151; batch adversarial loss: 0.477250\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342590; batch adversarial loss: 0.572300\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372814; batch adversarial loss: 0.582837\n",
      "epoch 173; iter: 0; batch classifier loss: 0.432178; batch adversarial loss: 0.620040\n",
      "epoch 174; iter: 0; batch classifier loss: 0.367012; batch adversarial loss: 0.553953\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331645; batch adversarial loss: 0.515683\n",
      "epoch 176; iter: 0; batch classifier loss: 0.454316; batch adversarial loss: 0.556476\n",
      "epoch 177; iter: 0; batch classifier loss: 0.427637; batch adversarial loss: 0.487587\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350271; batch adversarial loss: 0.496302\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355392; batch adversarial loss: 0.583766\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366466; batch adversarial loss: 0.544633\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320416; batch adversarial loss: 0.506020\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399309; batch adversarial loss: 0.516289\n",
      "epoch 183; iter: 0; batch classifier loss: 0.433298; batch adversarial loss: 0.571982\n",
      "epoch 184; iter: 0; batch classifier loss: 0.410703; batch adversarial loss: 0.477597\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383514; batch adversarial loss: 0.526797\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373678; batch adversarial loss: 0.487343\n",
      "epoch 187; iter: 0; batch classifier loss: 0.428963; batch adversarial loss: 0.525828\n",
      "epoch 188; iter: 0; batch classifier loss: 0.350805; batch adversarial loss: 0.620788\n",
      "epoch 189; iter: 0; batch classifier loss: 0.386430; batch adversarial loss: 0.611424\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386603; batch adversarial loss: 0.516245\n",
      "epoch 191; iter: 0; batch classifier loss: 0.328757; batch adversarial loss: 0.534891\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326847; batch adversarial loss: 0.639737\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383836; batch adversarial loss: 0.554922\n",
      "epoch 194; iter: 0; batch classifier loss: 0.314849; batch adversarial loss: 0.524701\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336476; batch adversarial loss: 0.563489\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331699; batch adversarial loss: 0.572763\n",
      "epoch 197; iter: 0; batch classifier loss: 0.408731; batch adversarial loss: 0.572820\n",
      "epoch 198; iter: 0; batch classifier loss: 0.395886; batch adversarial loss: 0.517043\n",
      "epoch 199; iter: 0; batch classifier loss: 0.311650; batch adversarial loss: 0.525079\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725161; batch adversarial loss: 1.137722\n",
      "epoch 1; iter: 0; batch classifier loss: 0.889427; batch adversarial loss: 1.337726\n",
      "epoch 2; iter: 0; batch classifier loss: 0.988308; batch adversarial loss: 1.232775\n",
      "epoch 3; iter: 0; batch classifier loss: 1.290948; batch adversarial loss: 1.202919\n",
      "epoch 4; iter: 0; batch classifier loss: 1.124442; batch adversarial loss: 1.059118\n",
      "epoch 5; iter: 0; batch classifier loss: 1.073835; batch adversarial loss: 0.970456\n",
      "epoch 6; iter: 0; batch classifier loss: 1.207458; batch adversarial loss: 0.940861\n",
      "epoch 7; iter: 0; batch classifier loss: 1.112122; batch adversarial loss: 0.856771\n",
      "epoch 8; iter: 0; batch classifier loss: 1.091617; batch adversarial loss: 0.786831\n",
      "epoch 9; iter: 0; batch classifier loss: 0.962851; batch adversarial loss: 0.721321\n",
      "epoch 10; iter: 0; batch classifier loss: 0.747799; batch adversarial loss: 0.671539\n",
      "epoch 11; iter: 0; batch classifier loss: 0.758648; batch adversarial loss: 0.646809\n",
      "epoch 12; iter: 0; batch classifier loss: 0.625252; batch adversarial loss: 0.591307\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510222; batch adversarial loss: 0.565690\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559912; batch adversarial loss: 0.614671\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506782; batch adversarial loss: 0.559684\n",
      "epoch 16; iter: 0; batch classifier loss: 0.568444; batch adversarial loss: 0.579574\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531020; batch adversarial loss: 0.544781\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477307; batch adversarial loss: 0.541727\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487573; batch adversarial loss: 0.584459\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528880; batch adversarial loss: 0.555902\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497475; batch adversarial loss: 0.541378\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485284; batch adversarial loss: 0.569696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492735; batch adversarial loss: 0.520114\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507802; batch adversarial loss: 0.577310\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474837; batch adversarial loss: 0.591031\n",
      "epoch 26; iter: 0; batch classifier loss: 0.533649; batch adversarial loss: 0.621967\n",
      "epoch 27; iter: 0; batch classifier loss: 0.497482; batch adversarial loss: 0.504130\n",
      "epoch 28; iter: 0; batch classifier loss: 0.536289; batch adversarial loss: 0.533104\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452518; batch adversarial loss: 0.491097\n",
      "epoch 30; iter: 0; batch classifier loss: 0.427413; batch adversarial loss: 0.584556\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492181; batch adversarial loss: 0.533294\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469427; batch adversarial loss: 0.531366\n",
      "epoch 33; iter: 0; batch classifier loss: 0.555682; batch adversarial loss: 0.614018\n",
      "epoch 34; iter: 0; batch classifier loss: 0.440684; batch adversarial loss: 0.599997\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479479; batch adversarial loss: 0.585339\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415841; batch adversarial loss: 0.645458\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449907; batch adversarial loss: 0.604203\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498526; batch adversarial loss: 0.496959\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481080; batch adversarial loss: 0.548521\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463665; batch adversarial loss: 0.602283\n",
      "epoch 41; iter: 0; batch classifier loss: 0.526986; batch adversarial loss: 0.512844\n",
      "epoch 42; iter: 0; batch classifier loss: 0.515285; batch adversarial loss: 0.569615\n",
      "epoch 43; iter: 0; batch classifier loss: 0.485556; batch adversarial loss: 0.517992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.401024; batch adversarial loss: 0.557745\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434160; batch adversarial loss: 0.596948\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496402; batch adversarial loss: 0.468733\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484876; batch adversarial loss: 0.509130\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382173; batch adversarial loss: 0.598351\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404073; batch adversarial loss: 0.522852\n",
      "epoch 50; iter: 0; batch classifier loss: 0.364019; batch adversarial loss: 0.563983\n",
      "epoch 51; iter: 0; batch classifier loss: 0.396820; batch adversarial loss: 0.522642\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411587; batch adversarial loss: 0.583679\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417149; batch adversarial loss: 0.596372\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429562; batch adversarial loss: 0.629079\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422373; batch adversarial loss: 0.474349\n",
      "epoch 56; iter: 0; batch classifier loss: 0.369710; batch adversarial loss: 0.555254\n",
      "epoch 57; iter: 0; batch classifier loss: 0.434141; batch adversarial loss: 0.593907\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442123; batch adversarial loss: 0.547715\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391511; batch adversarial loss: 0.504885\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407004; batch adversarial loss: 0.514929\n",
      "epoch 61; iter: 0; batch classifier loss: 0.465218; batch adversarial loss: 0.564439\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397698; batch adversarial loss: 0.525004\n",
      "epoch 63; iter: 0; batch classifier loss: 0.351488; batch adversarial loss: 0.554995\n",
      "epoch 64; iter: 0; batch classifier loss: 0.462228; batch adversarial loss: 0.611579\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431745; batch adversarial loss: 0.488034\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459412; batch adversarial loss: 0.648718\n",
      "epoch 67; iter: 0; batch classifier loss: 0.433492; batch adversarial loss: 0.518272\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386787; batch adversarial loss: 0.561666\n",
      "epoch 69; iter: 0; batch classifier loss: 0.434665; batch adversarial loss: 0.535322\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415668; batch adversarial loss: 0.523865\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365965; batch adversarial loss: 0.505131\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432083; batch adversarial loss: 0.528034\n",
      "epoch 73; iter: 0; batch classifier loss: 0.488622; batch adversarial loss: 0.552712\n",
      "epoch 74; iter: 0; batch classifier loss: 0.421452; batch adversarial loss: 0.451513\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398879; batch adversarial loss: 0.564368\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395830; batch adversarial loss: 0.591702\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399692; batch adversarial loss: 0.543411\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444239; batch adversarial loss: 0.546365\n",
      "epoch 79; iter: 0; batch classifier loss: 0.414817; batch adversarial loss: 0.590586\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455970; batch adversarial loss: 0.590932\n",
      "epoch 81; iter: 0; batch classifier loss: 0.318183; batch adversarial loss: 0.523379\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400009; batch adversarial loss: 0.458827\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368927; batch adversarial loss: 0.546317\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372623; batch adversarial loss: 0.526434\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387651; batch adversarial loss: 0.581684\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430922; batch adversarial loss: 0.545349\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402905; batch adversarial loss: 0.571562\n",
      "epoch 88; iter: 0; batch classifier loss: 0.438027; batch adversarial loss: 0.516282\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375514; batch adversarial loss: 0.609163\n",
      "epoch 90; iter: 0; batch classifier loss: 0.441832; batch adversarial loss: 0.534899\n",
      "epoch 91; iter: 0; batch classifier loss: 0.446359; batch adversarial loss: 0.525035\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399738; batch adversarial loss: 0.516873\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410341; batch adversarial loss: 0.563381\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404287; batch adversarial loss: 0.611046\n",
      "epoch 95; iter: 0; batch classifier loss: 0.332911; batch adversarial loss: 0.497710\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368525; batch adversarial loss: 0.505549\n",
      "epoch 97; iter: 0; batch classifier loss: 0.408927; batch adversarial loss: 0.535272\n",
      "epoch 98; iter: 0; batch classifier loss: 0.350809; batch adversarial loss: 0.505391\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381258; batch adversarial loss: 0.542803\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368803; batch adversarial loss: 0.507401\n",
      "epoch 101; iter: 0; batch classifier loss: 0.429989; batch adversarial loss: 0.526787\n",
      "epoch 102; iter: 0; batch classifier loss: 0.449461; batch adversarial loss: 0.544756\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354901; batch adversarial loss: 0.488731\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375112; batch adversarial loss: 0.620234\n",
      "epoch 105; iter: 0; batch classifier loss: 0.300169; batch adversarial loss: 0.499278\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381548; batch adversarial loss: 0.525459\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378654; batch adversarial loss: 0.583035\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387577; batch adversarial loss: 0.608420\n",
      "epoch 109; iter: 0; batch classifier loss: 0.405195; batch adversarial loss: 0.525736\n",
      "epoch 110; iter: 0; batch classifier loss: 0.406761; batch adversarial loss: 0.599899\n",
      "epoch 111; iter: 0; batch classifier loss: 0.302441; batch adversarial loss: 0.507098\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355601; batch adversarial loss: 0.533553\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358393; batch adversarial loss: 0.589705\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389476; batch adversarial loss: 0.469342\n",
      "epoch 115; iter: 0; batch classifier loss: 0.406034; batch adversarial loss: 0.487646\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347008; batch adversarial loss: 0.554399\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362430; batch adversarial loss: 0.573839\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403825; batch adversarial loss: 0.478532\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388322; batch adversarial loss: 0.553293\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428476; batch adversarial loss: 0.552834\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403706; batch adversarial loss: 0.552780\n",
      "epoch 122; iter: 0; batch classifier loss: 0.305299; batch adversarial loss: 0.580731\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357131; batch adversarial loss: 0.544777\n",
      "epoch 124; iter: 0; batch classifier loss: 0.321836; batch adversarial loss: 0.523839\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384751; batch adversarial loss: 0.581854\n",
      "epoch 126; iter: 0; batch classifier loss: 0.294602; batch adversarial loss: 0.571914\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385661; batch adversarial loss: 0.526163\n",
      "epoch 128; iter: 0; batch classifier loss: 0.408667; batch adversarial loss: 0.535639\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388225; batch adversarial loss: 0.550573\n",
      "epoch 130; iter: 0; batch classifier loss: 0.292554; batch adversarial loss: 0.572251\n",
      "epoch 131; iter: 0; batch classifier loss: 0.342736; batch adversarial loss: 0.505348\n",
      "epoch 132; iter: 0; batch classifier loss: 0.345273; batch adversarial loss: 0.534752\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362663; batch adversarial loss: 0.563155\n",
      "epoch 134; iter: 0; batch classifier loss: 0.409729; batch adversarial loss: 0.542925\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362376; batch adversarial loss: 0.564617\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338970; batch adversarial loss: 0.544919\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334017; batch adversarial loss: 0.650840\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373089; batch adversarial loss: 0.573069\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347939; batch adversarial loss: 0.554552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.390405; batch adversarial loss: 0.507473\n",
      "epoch 141; iter: 0; batch classifier loss: 0.454648; batch adversarial loss: 0.599719\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361876; batch adversarial loss: 0.602269\n",
      "epoch 143; iter: 0; batch classifier loss: 0.326679; batch adversarial loss: 0.571204\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360491; batch adversarial loss: 0.478169\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334347; batch adversarial loss: 0.564500\n",
      "epoch 146; iter: 0; batch classifier loss: 0.338452; batch adversarial loss: 0.500054\n",
      "epoch 147; iter: 0; batch classifier loss: 0.408614; batch adversarial loss: 0.507586\n",
      "epoch 148; iter: 0; batch classifier loss: 0.454499; batch adversarial loss: 0.518141\n",
      "epoch 149; iter: 0; batch classifier loss: 0.333523; batch adversarial loss: 0.581029\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381485; batch adversarial loss: 0.562413\n",
      "epoch 151; iter: 0; batch classifier loss: 0.434725; batch adversarial loss: 0.564750\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340004; batch adversarial loss: 0.526701\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363513; batch adversarial loss: 0.535870\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375210; batch adversarial loss: 0.498722\n",
      "epoch 155; iter: 0; batch classifier loss: 0.315893; batch adversarial loss: 0.449832\n",
      "epoch 156; iter: 0; batch classifier loss: 0.438038; batch adversarial loss: 0.544425\n",
      "epoch 157; iter: 0; batch classifier loss: 0.431756; batch adversarial loss: 0.515684\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382356; batch adversarial loss: 0.495997\n",
      "epoch 159; iter: 0; batch classifier loss: 0.326064; batch adversarial loss: 0.572232\n",
      "epoch 160; iter: 0; batch classifier loss: 0.315892; batch adversarial loss: 0.516285\n",
      "epoch 161; iter: 0; batch classifier loss: 0.453236; batch adversarial loss: 0.506017\n",
      "epoch 162; iter: 0; batch classifier loss: 0.333518; batch adversarial loss: 0.580713\n",
      "epoch 163; iter: 0; batch classifier loss: 0.441367; batch adversarial loss: 0.554395\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400376; batch adversarial loss: 0.611237\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350479; batch adversarial loss: 0.526103\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340837; batch adversarial loss: 0.571216\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395457; batch adversarial loss: 0.581748\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356914; batch adversarial loss: 0.572360\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326594; batch adversarial loss: 0.543444\n",
      "epoch 170; iter: 0; batch classifier loss: 0.350296; batch adversarial loss: 0.563662\n",
      "epoch 171; iter: 0; batch classifier loss: 0.277894; batch adversarial loss: 0.497918\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365513; batch adversarial loss: 0.562744\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373873; batch adversarial loss: 0.563021\n",
      "epoch 174; iter: 0; batch classifier loss: 0.405534; batch adversarial loss: 0.563007\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311317; batch adversarial loss: 0.543831\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332929; batch adversarial loss: 0.561777\n",
      "epoch 177; iter: 0; batch classifier loss: 0.407929; batch adversarial loss: 0.506977\n",
      "epoch 178; iter: 0; batch classifier loss: 0.322201; batch adversarial loss: 0.497222\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334478; batch adversarial loss: 0.449963\n",
      "epoch 180; iter: 0; batch classifier loss: 0.345150; batch adversarial loss: 0.544053\n",
      "epoch 181; iter: 0; batch classifier loss: 0.313086; batch adversarial loss: 0.581908\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342214; batch adversarial loss: 0.479461\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386222; batch adversarial loss: 0.487354\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287830; batch adversarial loss: 0.553336\n",
      "epoch 185; iter: 0; batch classifier loss: 0.395105; batch adversarial loss: 0.554734\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368087; batch adversarial loss: 0.544510\n",
      "epoch 187; iter: 0; batch classifier loss: 0.366743; batch adversarial loss: 0.489078\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314314; batch adversarial loss: 0.562074\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365868; batch adversarial loss: 0.618818\n",
      "epoch 190; iter: 0; batch classifier loss: 0.389199; batch adversarial loss: 0.459552\n",
      "epoch 191; iter: 0; batch classifier loss: 0.348009; batch adversarial loss: 0.563586\n",
      "epoch 192; iter: 0; batch classifier loss: 0.302830; batch adversarial loss: 0.572474\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320482; batch adversarial loss: 0.534192\n",
      "epoch 194; iter: 0; batch classifier loss: 0.272198; batch adversarial loss: 0.517864\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357554; batch adversarial loss: 0.442166\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339544; batch adversarial loss: 0.573144\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342643; batch adversarial loss: 0.544132\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389296; batch adversarial loss: 0.582986\n",
      "epoch 199; iter: 0; batch classifier loss: 0.328971; batch adversarial loss: 0.560941\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718354; batch adversarial loss: 0.622388\n",
      "epoch 1; iter: 0; batch classifier loss: 0.558392; batch adversarial loss: 0.672563\n",
      "epoch 2; iter: 0; batch classifier loss: 0.643039; batch adversarial loss: 0.646656\n",
      "epoch 3; iter: 0; batch classifier loss: 0.592148; batch adversarial loss: 0.614422\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616063; batch adversarial loss: 0.646154\n",
      "epoch 5; iter: 0; batch classifier loss: 0.623724; batch adversarial loss: 0.659404\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593662; batch adversarial loss: 0.723384\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523027; batch adversarial loss: 0.519972\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566776; batch adversarial loss: 0.653471\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551214; batch adversarial loss: 0.608902\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512322; batch adversarial loss: 0.592909\n",
      "epoch 11; iter: 0; batch classifier loss: 0.612197; batch adversarial loss: 0.524811\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598440; batch adversarial loss: 0.598576\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555501; batch adversarial loss: 0.582147\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510684; batch adversarial loss: 0.532450\n",
      "epoch 15; iter: 0; batch classifier loss: 0.625780; batch adversarial loss: 0.561850\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502872; batch adversarial loss: 0.580679\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512257; batch adversarial loss: 0.549500\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524971; batch adversarial loss: 0.527688\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516842; batch adversarial loss: 0.572210\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534329; batch adversarial loss: 0.544946\n",
      "epoch 21; iter: 0; batch classifier loss: 0.438661; batch adversarial loss: 0.608705\n",
      "epoch 22; iter: 0; batch classifier loss: 0.528610; batch adversarial loss: 0.527376\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502809; batch adversarial loss: 0.498571\n",
      "epoch 24; iter: 0; batch classifier loss: 0.529799; batch adversarial loss: 0.469499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466317; batch adversarial loss: 0.526830\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502173; batch adversarial loss: 0.529269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478323; batch adversarial loss: 0.500269\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471754; batch adversarial loss: 0.474222\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510763; batch adversarial loss: 0.482193\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506218; batch adversarial loss: 0.482402\n",
      "epoch 31; iter: 0; batch classifier loss: 0.427297; batch adversarial loss: 0.516659\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520728; batch adversarial loss: 0.507566\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458293; batch adversarial loss: 0.607946\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497609; batch adversarial loss: 0.517506\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459353; batch adversarial loss: 0.534388\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405408; batch adversarial loss: 0.507040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418193; batch adversarial loss: 0.582938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.445298; batch adversarial loss: 0.544972\n",
      "epoch 39; iter: 0; batch classifier loss: 0.504928; batch adversarial loss: 0.543621\n",
      "epoch 40; iter: 0; batch classifier loss: 0.381247; batch adversarial loss: 0.564147\n",
      "epoch 41; iter: 0; batch classifier loss: 0.370496; batch adversarial loss: 0.431691\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467682; batch adversarial loss: 0.563424\n",
      "epoch 43; iter: 0; batch classifier loss: 0.388157; batch adversarial loss: 0.533131\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393816; batch adversarial loss: 0.516595\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455679; batch adversarial loss: 0.581541\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447500; batch adversarial loss: 0.621107\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395850; batch adversarial loss: 0.620780\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432606; batch adversarial loss: 0.486937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472749; batch adversarial loss: 0.505692\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388599; batch adversarial loss: 0.487807\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455203; batch adversarial loss: 0.583127\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415641; batch adversarial loss: 0.466871\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381599; batch adversarial loss: 0.505196\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417537; batch adversarial loss: 0.497113\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422186; batch adversarial loss: 0.574294\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429848; batch adversarial loss: 0.514161\n",
      "epoch 57; iter: 0; batch classifier loss: 0.377293; batch adversarial loss: 0.563844\n",
      "epoch 58; iter: 0; batch classifier loss: 0.481895; batch adversarial loss: 0.487851\n",
      "epoch 59; iter: 0; batch classifier loss: 0.405193; batch adversarial loss: 0.562266\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379521; batch adversarial loss: 0.487780\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395650; batch adversarial loss: 0.583425\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451429; batch adversarial loss: 0.515052\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392970; batch adversarial loss: 0.555367\n",
      "epoch 64; iter: 0; batch classifier loss: 0.383232; batch adversarial loss: 0.477840\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426892; batch adversarial loss: 0.515502\n",
      "epoch 66; iter: 0; batch classifier loss: 0.371949; batch adversarial loss: 0.630458\n",
      "epoch 67; iter: 0; batch classifier loss: 0.480617; batch adversarial loss: 0.590843\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415827; batch adversarial loss: 0.493686\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412992; batch adversarial loss: 0.592103\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382211; batch adversarial loss: 0.508195\n",
      "epoch 71; iter: 0; batch classifier loss: 0.485882; batch adversarial loss: 0.631275\n",
      "epoch 72; iter: 0; batch classifier loss: 0.483246; batch adversarial loss: 0.497279\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405128; batch adversarial loss: 0.529187\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401285; batch adversarial loss: 0.524561\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412651; batch adversarial loss: 0.499231\n",
      "epoch 76; iter: 0; batch classifier loss: 0.535257; batch adversarial loss: 0.485611\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385117; batch adversarial loss: 0.544509\n",
      "epoch 78; iter: 0; batch classifier loss: 0.462858; batch adversarial loss: 0.478411\n",
      "epoch 79; iter: 0; batch classifier loss: 0.355508; batch adversarial loss: 0.620889\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432075; batch adversarial loss: 0.565324\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381415; batch adversarial loss: 0.582815\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368425; batch adversarial loss: 0.608293\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434208; batch adversarial loss: 0.489120\n",
      "epoch 84; iter: 0; batch classifier loss: 0.323171; batch adversarial loss: 0.478305\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452553; batch adversarial loss: 0.598406\n",
      "epoch 86; iter: 0; batch classifier loss: 0.483075; batch adversarial loss: 0.533919\n",
      "epoch 87; iter: 0; batch classifier loss: 0.494850; batch adversarial loss: 0.589931\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420809; batch adversarial loss: 0.507747\n",
      "epoch 89; iter: 0; batch classifier loss: 0.440309; batch adversarial loss: 0.506587\n",
      "epoch 90; iter: 0; batch classifier loss: 0.329084; batch adversarial loss: 0.485879\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372475; batch adversarial loss: 0.546616\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388026; batch adversarial loss: 0.623349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412528; batch adversarial loss: 0.495915\n",
      "epoch 94; iter: 0; batch classifier loss: 0.445291; batch adversarial loss: 0.535363\n",
      "epoch 95; iter: 0; batch classifier loss: 0.340813; batch adversarial loss: 0.515394\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381690; batch adversarial loss: 0.583101\n",
      "epoch 97; iter: 0; batch classifier loss: 0.507227; batch adversarial loss: 0.622423\n",
      "epoch 98; iter: 0; batch classifier loss: 0.417789; batch adversarial loss: 0.456742\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408639; batch adversarial loss: 0.487076\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381517; batch adversarial loss: 0.524600\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367139; batch adversarial loss: 0.506289\n",
      "epoch 102; iter: 0; batch classifier loss: 0.439183; batch adversarial loss: 0.467410\n",
      "epoch 103; iter: 0; batch classifier loss: 0.473142; batch adversarial loss: 0.458506\n",
      "epoch 104; iter: 0; batch classifier loss: 0.343593; batch adversarial loss: 0.553855\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351332; batch adversarial loss: 0.545134\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334273; batch adversarial loss: 0.572468\n",
      "epoch 107; iter: 0; batch classifier loss: 0.321459; batch adversarial loss: 0.582359\n",
      "epoch 108; iter: 0; batch classifier loss: 0.302905; batch adversarial loss: 0.544731\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380521; batch adversarial loss: 0.535410\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348386; batch adversarial loss: 0.477959\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398471; batch adversarial loss: 0.555654\n",
      "epoch 112; iter: 0; batch classifier loss: 0.439631; batch adversarial loss: 0.468873\n",
      "epoch 113; iter: 0; batch classifier loss: 0.412842; batch adversarial loss: 0.610108\n",
      "epoch 114; iter: 0; batch classifier loss: 0.403474; batch adversarial loss: 0.516362\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401380; batch adversarial loss: 0.504191\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385271; batch adversarial loss: 0.581683\n",
      "epoch 117; iter: 0; batch classifier loss: 0.494656; batch adversarial loss: 0.516398\n",
      "epoch 118; iter: 0; batch classifier loss: 0.296335; batch adversarial loss: 0.496416\n",
      "epoch 119; iter: 0; batch classifier loss: 0.357016; batch adversarial loss: 0.449533\n",
      "epoch 120; iter: 0; batch classifier loss: 0.429000; batch adversarial loss: 0.545341\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347165; batch adversarial loss: 0.525561\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384040; batch adversarial loss: 0.640462\n",
      "epoch 123; iter: 0; batch classifier loss: 0.306714; batch adversarial loss: 0.553228\n",
      "epoch 124; iter: 0; batch classifier loss: 0.456932; batch adversarial loss: 0.515767\n",
      "epoch 125; iter: 0; batch classifier loss: 0.435763; batch adversarial loss: 0.516091\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354509; batch adversarial loss: 0.515078\n",
      "epoch 127; iter: 0; batch classifier loss: 0.448567; batch adversarial loss: 0.535032\n",
      "epoch 128; iter: 0; batch classifier loss: 0.429898; batch adversarial loss: 0.516233\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374434; batch adversarial loss: 0.506239\n",
      "epoch 130; iter: 0; batch classifier loss: 0.325541; batch adversarial loss: 0.563952\n",
      "epoch 131; iter: 0; batch classifier loss: 0.370538; batch adversarial loss: 0.514267\n",
      "epoch 132; iter: 0; batch classifier loss: 0.428930; batch adversarial loss: 0.564060\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336940; batch adversarial loss: 0.487331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.349649; batch adversarial loss: 0.487347\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334630; batch adversarial loss: 0.553919\n",
      "epoch 136; iter: 0; batch classifier loss: 0.367047; batch adversarial loss: 0.487677\n",
      "epoch 137; iter: 0; batch classifier loss: 0.454435; batch adversarial loss: 0.601900\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415346; batch adversarial loss: 0.488510\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357364; batch adversarial loss: 0.543869\n",
      "epoch 140; iter: 0; batch classifier loss: 0.372725; batch adversarial loss: 0.535661\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343372; batch adversarial loss: 0.582729\n",
      "epoch 142; iter: 0; batch classifier loss: 0.373997; batch adversarial loss: 0.458754\n",
      "epoch 143; iter: 0; batch classifier loss: 0.419218; batch adversarial loss: 0.544967\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359407; batch adversarial loss: 0.572012\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379281; batch adversarial loss: 0.600973\n",
      "epoch 146; iter: 0; batch classifier loss: 0.412061; batch adversarial loss: 0.488115\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374338; batch adversarial loss: 0.535496\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363551; batch adversarial loss: 0.563485\n",
      "epoch 149; iter: 0; batch classifier loss: 0.398852; batch adversarial loss: 0.582839\n",
      "epoch 150; iter: 0; batch classifier loss: 0.420006; batch adversarial loss: 0.516559\n",
      "epoch 151; iter: 0; batch classifier loss: 0.475529; batch adversarial loss: 0.524944\n",
      "epoch 152; iter: 0; batch classifier loss: 0.294497; batch adversarial loss: 0.525112\n",
      "epoch 153; iter: 0; batch classifier loss: 0.400420; batch adversarial loss: 0.506956\n",
      "epoch 154; iter: 0; batch classifier loss: 0.322916; batch adversarial loss: 0.497408\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377573; batch adversarial loss: 0.536036\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398095; batch adversarial loss: 0.516409\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359401; batch adversarial loss: 0.535269\n",
      "epoch 158; iter: 0; batch classifier loss: 0.299428; batch adversarial loss: 0.535503\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376289; batch adversarial loss: 0.496792\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374350; batch adversarial loss: 0.582563\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344776; batch adversarial loss: 0.534907\n",
      "epoch 162; iter: 0; batch classifier loss: 0.416651; batch adversarial loss: 0.515604\n",
      "epoch 163; iter: 0; batch classifier loss: 0.358089; batch adversarial loss: 0.506466\n",
      "epoch 164; iter: 0; batch classifier loss: 0.415679; batch adversarial loss: 0.439272\n",
      "epoch 165; iter: 0; batch classifier loss: 0.401145; batch adversarial loss: 0.526461\n",
      "epoch 166; iter: 0; batch classifier loss: 0.302223; batch adversarial loss: 0.505454\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399051; batch adversarial loss: 0.506110\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376802; batch adversarial loss: 0.564441\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330981; batch adversarial loss: 0.525189\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324171; batch adversarial loss: 0.457821\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355706; batch adversarial loss: 0.593438\n",
      "epoch 172; iter: 0; batch classifier loss: 0.430625; batch adversarial loss: 0.535079\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351280; batch adversarial loss: 0.582872\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361433; batch adversarial loss: 0.572918\n",
      "epoch 175; iter: 0; batch classifier loss: 0.401447; batch adversarial loss: 0.525329\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348069; batch adversarial loss: 0.544862\n",
      "epoch 177; iter: 0; batch classifier loss: 0.385146; batch adversarial loss: 0.534914\n",
      "epoch 178; iter: 0; batch classifier loss: 0.401678; batch adversarial loss: 0.534628\n",
      "epoch 179; iter: 0; batch classifier loss: 0.342387; batch adversarial loss: 0.620789\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318403; batch adversarial loss: 0.573329\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347907; batch adversarial loss: 0.563957\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389997; batch adversarial loss: 0.554126\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355614; batch adversarial loss: 0.602826\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378172; batch adversarial loss: 0.602646\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352975; batch adversarial loss: 0.553997\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379081; batch adversarial loss: 0.534704\n",
      "epoch 187; iter: 0; batch classifier loss: 0.416907; batch adversarial loss: 0.582893\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352452; batch adversarial loss: 0.534792\n",
      "epoch 189; iter: 0; batch classifier loss: 0.410676; batch adversarial loss: 0.516629\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328730; batch adversarial loss: 0.507111\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380212; batch adversarial loss: 0.488033\n",
      "epoch 192; iter: 0; batch classifier loss: 0.324553; batch adversarial loss: 0.554174\n",
      "epoch 193; iter: 0; batch classifier loss: 0.297200; batch adversarial loss: 0.525789\n",
      "epoch 194; iter: 0; batch classifier loss: 0.352616; batch adversarial loss: 0.515986\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337367; batch adversarial loss: 0.563668\n",
      "epoch 196; iter: 0; batch classifier loss: 0.428093; batch adversarial loss: 0.610649\n",
      "epoch 197; iter: 0; batch classifier loss: 0.411493; batch adversarial loss: 0.563230\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377807; batch adversarial loss: 0.581946\n",
      "epoch 199; iter: 0; batch classifier loss: 0.441174; batch adversarial loss: 0.496758\n",
      "epoch 0; iter: 0; batch classifier loss: 0.775175; batch adversarial loss: 0.989984\n",
      "epoch 1; iter: 0; batch classifier loss: 0.886525; batch adversarial loss: 1.129876\n",
      "epoch 2; iter: 0; batch classifier loss: 0.869850; batch adversarial loss: 1.046649\n",
      "epoch 3; iter: 0; batch classifier loss: 0.996351; batch adversarial loss: 0.975082\n",
      "epoch 4; iter: 0; batch classifier loss: 1.060409; batch adversarial loss: 0.887954\n",
      "epoch 5; iter: 0; batch classifier loss: 1.203740; batch adversarial loss: 0.847662\n",
      "epoch 6; iter: 0; batch classifier loss: 1.112100; batch adversarial loss: 0.793442\n",
      "epoch 7; iter: 0; batch classifier loss: 0.923049; batch adversarial loss: 0.698960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.709121; batch adversarial loss: 0.642847\n",
      "epoch 9; iter: 0; batch classifier loss: 0.630818; batch adversarial loss: 0.646831\n",
      "epoch 10; iter: 0; batch classifier loss: 0.577751; batch adversarial loss: 0.596910\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579308; batch adversarial loss: 0.563162\n",
      "epoch 12; iter: 0; batch classifier loss: 0.601178; batch adversarial loss: 0.584004\n",
      "epoch 13; iter: 0; batch classifier loss: 0.523503; batch adversarial loss: 0.609369\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532810; batch adversarial loss: 0.627980\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514416; batch adversarial loss: 0.544631\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492421; batch adversarial loss: 0.584568\n",
      "epoch 17; iter: 0; batch classifier loss: 0.564397; batch adversarial loss: 0.560459\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507331; batch adversarial loss: 0.570913\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495018; batch adversarial loss: 0.560299\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469973; batch adversarial loss: 0.548470\n",
      "epoch 21; iter: 0; batch classifier loss: 0.584265; batch adversarial loss: 0.557263\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467217; batch adversarial loss: 0.541632\n",
      "epoch 23; iter: 0; batch classifier loss: 0.541267; batch adversarial loss: 0.585623\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475716; batch adversarial loss: 0.511973\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456548; batch adversarial loss: 0.495489\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513506; batch adversarial loss: 0.527062\n",
      "epoch 27; iter: 0; batch classifier loss: 0.504824; batch adversarial loss: 0.531862\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452681; batch adversarial loss: 0.537591\n",
      "epoch 29; iter: 0; batch classifier loss: 0.515151; batch adversarial loss: 0.565227\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441863; batch adversarial loss: 0.504800\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505388; batch adversarial loss: 0.497911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.473134; batch adversarial loss: 0.550041\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460957; batch adversarial loss: 0.541184\n",
      "epoch 34; iter: 0; batch classifier loss: 0.389136; batch adversarial loss: 0.483248\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489091; batch adversarial loss: 0.514835\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407285; batch adversarial loss: 0.530301\n",
      "epoch 37; iter: 0; batch classifier loss: 0.553400; batch adversarial loss: 0.518559\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437590; batch adversarial loss: 0.540795\n",
      "epoch 39; iter: 0; batch classifier loss: 0.504944; batch adversarial loss: 0.554835\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351081; batch adversarial loss: 0.525425\n",
      "epoch 41; iter: 0; batch classifier loss: 0.578885; batch adversarial loss: 0.576764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416741; batch adversarial loss: 0.564217\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400436; batch adversarial loss: 0.512692\n",
      "epoch 44; iter: 0; batch classifier loss: 0.534904; batch adversarial loss: 0.450080\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421734; batch adversarial loss: 0.603568\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432861; batch adversarial loss: 0.546333\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403711; batch adversarial loss: 0.533638\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396528; batch adversarial loss: 0.481748\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470734; batch adversarial loss: 0.489052\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473346; batch adversarial loss: 0.489317\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482764; batch adversarial loss: 0.585073\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441916; batch adversarial loss: 0.565363\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397922; batch adversarial loss: 0.562787\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424265; batch adversarial loss: 0.511237\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401927; batch adversarial loss: 0.577380\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457761; batch adversarial loss: 0.524853\n",
      "epoch 57; iter: 0; batch classifier loss: 0.388322; batch adversarial loss: 0.506400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413878; batch adversarial loss: 0.564444\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432695; batch adversarial loss: 0.478708\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389978; batch adversarial loss: 0.580400\n",
      "epoch 61; iter: 0; batch classifier loss: 0.320371; batch adversarial loss: 0.582124\n",
      "epoch 62; iter: 0; batch classifier loss: 0.345989; batch adversarial loss: 0.489607\n",
      "epoch 63; iter: 0; batch classifier loss: 0.451599; batch adversarial loss: 0.574401\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401041; batch adversarial loss: 0.589507\n",
      "epoch 65; iter: 0; batch classifier loss: 0.360643; batch adversarial loss: 0.474143\n",
      "epoch 66; iter: 0; batch classifier loss: 0.451848; batch adversarial loss: 0.537702\n",
      "epoch 67; iter: 0; batch classifier loss: 0.344973; batch adversarial loss: 0.544625\n",
      "epoch 68; iter: 0; batch classifier loss: 0.433479; batch adversarial loss: 0.496359\n",
      "epoch 69; iter: 0; batch classifier loss: 0.317505; batch adversarial loss: 0.481407\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399606; batch adversarial loss: 0.478842\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349337; batch adversarial loss: 0.519951\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415505; batch adversarial loss: 0.514971\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409986; batch adversarial loss: 0.618874\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378669; batch adversarial loss: 0.527340\n",
      "epoch 75; iter: 0; batch classifier loss: 0.509371; batch adversarial loss: 0.598885\n",
      "epoch 76; iter: 0; batch classifier loss: 0.477311; batch adversarial loss: 0.467809\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427801; batch adversarial loss: 0.496530\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376761; batch adversarial loss: 0.488949\n",
      "epoch 79; iter: 0; batch classifier loss: 0.351870; batch adversarial loss: 0.554684\n",
      "epoch 80; iter: 0; batch classifier loss: 0.397862; batch adversarial loss: 0.533698\n",
      "epoch 81; iter: 0; batch classifier loss: 0.454447; batch adversarial loss: 0.598438\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380993; batch adversarial loss: 0.544890\n",
      "epoch 83; iter: 0; batch classifier loss: 0.455624; batch adversarial loss: 0.471461\n",
      "epoch 84; iter: 0; batch classifier loss: 0.428956; batch adversarial loss: 0.581594\n",
      "epoch 85; iter: 0; batch classifier loss: 0.379066; batch adversarial loss: 0.500203\n",
      "epoch 86; iter: 0; batch classifier loss: 0.351533; batch adversarial loss: 0.591731\n",
      "epoch 87; iter: 0; batch classifier loss: 0.327605; batch adversarial loss: 0.572839\n",
      "epoch 88; iter: 0; batch classifier loss: 0.307441; batch adversarial loss: 0.470820\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432715; batch adversarial loss: 0.499906\n",
      "epoch 90; iter: 0; batch classifier loss: 0.438554; batch adversarial loss: 0.564617\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416538; batch adversarial loss: 0.655928\n",
      "epoch 92; iter: 0; batch classifier loss: 0.438264; batch adversarial loss: 0.628075\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421851; batch adversarial loss: 0.534784\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372615; batch adversarial loss: 0.553042\n",
      "epoch 95; iter: 0; batch classifier loss: 0.445396; batch adversarial loss: 0.582160\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376472; batch adversarial loss: 0.516218\n",
      "epoch 97; iter: 0; batch classifier loss: 0.407922; batch adversarial loss: 0.505578\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371187; batch adversarial loss: 0.553896\n",
      "epoch 99; iter: 0; batch classifier loss: 0.301367; batch adversarial loss: 0.524263\n",
      "epoch 100; iter: 0; batch classifier loss: 0.339144; batch adversarial loss: 0.489328\n",
      "epoch 101; iter: 0; batch classifier loss: 0.340756; batch adversarial loss: 0.571268\n",
      "epoch 102; iter: 0; batch classifier loss: 0.429020; batch adversarial loss: 0.525174\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416743; batch adversarial loss: 0.515828\n",
      "epoch 104; iter: 0; batch classifier loss: 0.326462; batch adversarial loss: 0.554790\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337964; batch adversarial loss: 0.655118\n",
      "epoch 106; iter: 0; batch classifier loss: 0.356305; batch adversarial loss: 0.553871\n",
      "epoch 107; iter: 0; batch classifier loss: 0.327688; batch adversarial loss: 0.572842\n",
      "epoch 108; iter: 0; batch classifier loss: 0.317885; batch adversarial loss: 0.601709\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406191; batch adversarial loss: 0.508691\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368171; batch adversarial loss: 0.589827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378430; batch adversarial loss: 0.469264\n",
      "epoch 112; iter: 0; batch classifier loss: 0.313383; batch adversarial loss: 0.543515\n",
      "epoch 113; iter: 0; batch classifier loss: 0.339320; batch adversarial loss: 0.527723\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383281; batch adversarial loss: 0.506000\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371023; batch adversarial loss: 0.535298\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370123; batch adversarial loss: 0.525623\n",
      "epoch 117; iter: 0; batch classifier loss: 0.332004; batch adversarial loss: 0.545797\n",
      "epoch 118; iter: 0; batch classifier loss: 0.444375; batch adversarial loss: 0.553766\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363632; batch adversarial loss: 0.544177\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394933; batch adversarial loss: 0.591200\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356359; batch adversarial loss: 0.525974\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339278; batch adversarial loss: 0.545255\n",
      "epoch 123; iter: 0; batch classifier loss: 0.364920; batch adversarial loss: 0.497375\n",
      "epoch 124; iter: 0; batch classifier loss: 0.324527; batch adversarial loss: 0.534760\n",
      "epoch 125; iter: 0; batch classifier loss: 0.327949; batch adversarial loss: 0.534146\n",
      "epoch 126; iter: 0; batch classifier loss: 0.349919; batch adversarial loss: 0.572050\n",
      "epoch 127; iter: 0; batch classifier loss: 0.321767; batch adversarial loss: 0.563563\n",
      "epoch 128; iter: 0; batch classifier loss: 0.345746; batch adversarial loss: 0.468939\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377837; batch adversarial loss: 0.487765\n",
      "epoch 130; iter: 0; batch classifier loss: 0.344354; batch adversarial loss: 0.563511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.367515; batch adversarial loss: 0.553656\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421217; batch adversarial loss: 0.517221\n",
      "epoch 133; iter: 0; batch classifier loss: 0.313339; batch adversarial loss: 0.526364\n",
      "epoch 134; iter: 0; batch classifier loss: 0.324912; batch adversarial loss: 0.507017\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364408; batch adversarial loss: 0.627837\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322586; batch adversarial loss: 0.534856\n",
      "epoch 137; iter: 0; batch classifier loss: 0.337517; batch adversarial loss: 0.487497\n",
      "epoch 138; iter: 0; batch classifier loss: 0.331432; batch adversarial loss: 0.676678\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388726; batch adversarial loss: 0.486100\n",
      "epoch 140; iter: 0; batch classifier loss: 0.336984; batch adversarial loss: 0.573312\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368977; batch adversarial loss: 0.507146\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348298; batch adversarial loss: 0.544975\n",
      "epoch 143; iter: 0; batch classifier loss: 0.321089; batch adversarial loss: 0.563430\n",
      "epoch 144; iter: 0; batch classifier loss: 0.304795; batch adversarial loss: 0.599817\n",
      "epoch 145; iter: 0; batch classifier loss: 0.409905; batch adversarial loss: 0.544501\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381176; batch adversarial loss: 0.498370\n",
      "epoch 147; iter: 0; batch classifier loss: 0.305198; batch adversarial loss: 0.665143\n",
      "epoch 148; iter: 0; batch classifier loss: 0.307132; batch adversarial loss: 0.479526\n",
      "epoch 149; iter: 0; batch classifier loss: 0.312327; batch adversarial loss: 0.450577\n",
      "epoch 150; iter: 0; batch classifier loss: 0.315110; batch adversarial loss: 0.516185\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386461; batch adversarial loss: 0.535850\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382912; batch adversarial loss: 0.602265\n",
      "epoch 153; iter: 0; batch classifier loss: 0.290554; batch adversarial loss: 0.571729\n",
      "epoch 154; iter: 0; batch classifier loss: 0.338244; batch adversarial loss: 0.581455\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316547; batch adversarial loss: 0.526005\n",
      "epoch 156; iter: 0; batch classifier loss: 0.250057; batch adversarial loss: 0.535203\n",
      "epoch 157; iter: 0; batch classifier loss: 0.290529; batch adversarial loss: 0.581967\n",
      "epoch 158; iter: 0; batch classifier loss: 0.393427; batch adversarial loss: 0.591290\n",
      "epoch 159; iter: 0; batch classifier loss: 0.432085; batch adversarial loss: 0.544510\n",
      "epoch 160; iter: 0; batch classifier loss: 0.325362; batch adversarial loss: 0.469481\n",
      "epoch 161; iter: 0; batch classifier loss: 0.331388; batch adversarial loss: 0.525754\n",
      "epoch 162; iter: 0; batch classifier loss: 0.286870; batch adversarial loss: 0.609574\n",
      "epoch 163; iter: 0; batch classifier loss: 0.234363; batch adversarial loss: 0.563265\n",
      "epoch 164; iter: 0; batch classifier loss: 0.437829; batch adversarial loss: 0.553665\n",
      "epoch 165; iter: 0; batch classifier loss: 0.266853; batch adversarial loss: 0.582147\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382779; batch adversarial loss: 0.517130\n",
      "epoch 167; iter: 0; batch classifier loss: 0.278445; batch adversarial loss: 0.525513\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344210; batch adversarial loss: 0.563573\n",
      "epoch 169; iter: 0; batch classifier loss: 0.288961; batch adversarial loss: 0.572352\n",
      "epoch 170; iter: 0; batch classifier loss: 0.405672; batch adversarial loss: 0.525480\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409303; batch adversarial loss: 0.525958\n",
      "epoch 172; iter: 0; batch classifier loss: 0.433257; batch adversarial loss: 0.497463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.306388; batch adversarial loss: 0.533829\n",
      "epoch 174; iter: 0; batch classifier loss: 0.323572; batch adversarial loss: 0.526788\n",
      "epoch 175; iter: 0; batch classifier loss: 0.410336; batch adversarial loss: 0.572040\n",
      "epoch 176; iter: 0; batch classifier loss: 0.300452; batch adversarial loss: 0.581891\n",
      "epoch 177; iter: 0; batch classifier loss: 0.328772; batch adversarial loss: 0.552516\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340507; batch adversarial loss: 0.537851\n",
      "epoch 179; iter: 0; batch classifier loss: 0.314672; batch adversarial loss: 0.488077\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328608; batch adversarial loss: 0.515258\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384862; batch adversarial loss: 0.543563\n",
      "epoch 182; iter: 0; batch classifier loss: 0.388249; batch adversarial loss: 0.535611\n",
      "epoch 183; iter: 0; batch classifier loss: 0.294343; batch adversarial loss: 0.620949\n",
      "epoch 184; iter: 0; batch classifier loss: 0.305673; batch adversarial loss: 0.478886\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397580; batch adversarial loss: 0.563565\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382879; batch adversarial loss: 0.535840\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325525; batch adversarial loss: 0.572867\n",
      "epoch 188; iter: 0; batch classifier loss: 0.255082; batch adversarial loss: 0.562589\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381683; batch adversarial loss: 0.553970\n",
      "epoch 190; iter: 0; batch classifier loss: 0.378590; batch adversarial loss: 0.518075\n",
      "epoch 191; iter: 0; batch classifier loss: 0.332561; batch adversarial loss: 0.600270\n",
      "epoch 192; iter: 0; batch classifier loss: 0.379929; batch adversarial loss: 0.572680\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360948; batch adversarial loss: 0.507200\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419973; batch adversarial loss: 0.591522\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363167; batch adversarial loss: 0.544290\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370668; batch adversarial loss: 0.525413\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365592; batch adversarial loss: 0.544334\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404037; batch adversarial loss: 0.544146\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367008; batch adversarial loss: 0.516605\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676610; batch adversarial loss: 0.687390\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565583; batch adversarial loss: 0.640745\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630609; batch adversarial loss: 0.648481\n",
      "epoch 3; iter: 0; batch classifier loss: 0.546045; batch adversarial loss: 0.619240\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567637; batch adversarial loss: 0.635429\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564298; batch adversarial loss: 0.619148\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571136; batch adversarial loss: 0.613588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.613103; batch adversarial loss: 0.636069\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523660; batch adversarial loss: 0.605147\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520754; batch adversarial loss: 0.563867\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542140; batch adversarial loss: 0.572438\n",
      "epoch 11; iter: 0; batch classifier loss: 0.619437; batch adversarial loss: 0.580998\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534143; batch adversarial loss: 0.564787\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546199; batch adversarial loss: 0.607720\n",
      "epoch 14; iter: 0; batch classifier loss: 0.573799; batch adversarial loss: 0.621347\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527534; batch adversarial loss: 0.557865\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538327; batch adversarial loss: 0.548141\n",
      "epoch 17; iter: 0; batch classifier loss: 0.460513; batch adversarial loss: 0.576567\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556830; batch adversarial loss: 0.633067\n",
      "epoch 19; iter: 0; batch classifier loss: 0.556518; batch adversarial loss: 0.547730\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538396; batch adversarial loss: 0.619456\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495789; batch adversarial loss: 0.532174\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456094; batch adversarial loss: 0.529120\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443532; batch adversarial loss: 0.544448\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512913; batch adversarial loss: 0.510944\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440900; batch adversarial loss: 0.506883\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483535; batch adversarial loss: 0.572834\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529664; batch adversarial loss: 0.605903\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422426; batch adversarial loss: 0.563144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.442852; batch adversarial loss: 0.523504\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488897; batch adversarial loss: 0.510165\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477165; batch adversarial loss: 0.580521\n",
      "epoch 32; iter: 0; batch classifier loss: 0.561741; batch adversarial loss: 0.585157\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445816; batch adversarial loss: 0.557832\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448688; batch adversarial loss: 0.544717\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498103; batch adversarial loss: 0.468348\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461798; batch adversarial loss: 0.520625\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446142; batch adversarial loss: 0.564367\n",
      "epoch 38; iter: 0; batch classifier loss: 0.526056; batch adversarial loss: 0.491711\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451674; batch adversarial loss: 0.536550\n",
      "epoch 40; iter: 0; batch classifier loss: 0.519530; batch adversarial loss: 0.591675\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436003; batch adversarial loss: 0.528748\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438864; batch adversarial loss: 0.471403\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456816; batch adversarial loss: 0.621984\n",
      "epoch 44; iter: 0; batch classifier loss: 0.356579; batch adversarial loss: 0.525778\n",
      "epoch 45; iter: 0; batch classifier loss: 0.484387; batch adversarial loss: 0.608107\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439005; batch adversarial loss: 0.592245\n",
      "epoch 47; iter: 0; batch classifier loss: 0.349572; batch adversarial loss: 0.513755\n",
      "epoch 48; iter: 0; batch classifier loss: 0.398578; batch adversarial loss: 0.513702\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475786; batch adversarial loss: 0.571149\n",
      "epoch 50; iter: 0; batch classifier loss: 0.447080; batch adversarial loss: 0.562574\n",
      "epoch 51; iter: 0; batch classifier loss: 0.489052; batch adversarial loss: 0.474763\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423242; batch adversarial loss: 0.538322\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430829; batch adversarial loss: 0.528861\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446453; batch adversarial loss: 0.562003\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411349; batch adversarial loss: 0.547255\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395130; batch adversarial loss: 0.502781\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413630; batch adversarial loss: 0.605018\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438035; batch adversarial loss: 0.509456\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428142; batch adversarial loss: 0.515316\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402792; batch adversarial loss: 0.487965\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386436; batch adversarial loss: 0.613174\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394356; batch adversarial loss: 0.562982\n",
      "epoch 63; iter: 0; batch classifier loss: 0.524597; batch adversarial loss: 0.531214\n",
      "epoch 64; iter: 0; batch classifier loss: 0.526142; batch adversarial loss: 0.561948\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409781; batch adversarial loss: 0.432176\n",
      "epoch 66; iter: 0; batch classifier loss: 0.501191; batch adversarial loss: 0.570315\n",
      "epoch 67; iter: 0; batch classifier loss: 0.477321; batch adversarial loss: 0.542327\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438566; batch adversarial loss: 0.562623\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383393; batch adversarial loss: 0.622275\n",
      "epoch 70; iter: 0; batch classifier loss: 0.435048; batch adversarial loss: 0.582563\n",
      "epoch 71; iter: 0; batch classifier loss: 0.434963; batch adversarial loss: 0.526066\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386488; batch adversarial loss: 0.507053\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445232; batch adversarial loss: 0.560754\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396983; batch adversarial loss: 0.523472\n",
      "epoch 75; iter: 0; batch classifier loss: 0.383459; batch adversarial loss: 0.573303\n",
      "epoch 76; iter: 0; batch classifier loss: 0.458407; batch adversarial loss: 0.564105\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436326; batch adversarial loss: 0.517570\n",
      "epoch 78; iter: 0; batch classifier loss: 0.473095; batch adversarial loss: 0.535389\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371315; batch adversarial loss: 0.517478\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374497; batch adversarial loss: 0.525848\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394056; batch adversarial loss: 0.508748\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356936; batch adversarial loss: 0.580193\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428327; batch adversarial loss: 0.507582\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419372; batch adversarial loss: 0.563277\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434520; batch adversarial loss: 0.524764\n",
      "epoch 86; iter: 0; batch classifier loss: 0.449789; batch adversarial loss: 0.470379\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398486; batch adversarial loss: 0.544006\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416800; batch adversarial loss: 0.525122\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398086; batch adversarial loss: 0.534765\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418576; batch adversarial loss: 0.569900\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421767; batch adversarial loss: 0.664470\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407132; batch adversarial loss: 0.615439\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342082; batch adversarial loss: 0.588954\n",
      "epoch 94; iter: 0; batch classifier loss: 0.335447; batch adversarial loss: 0.478779\n",
      "epoch 95; iter: 0; batch classifier loss: 0.471082; batch adversarial loss: 0.544348\n",
      "epoch 96; iter: 0; batch classifier loss: 0.509028; batch adversarial loss: 0.573475\n",
      "epoch 97; iter: 0; batch classifier loss: 0.308762; batch adversarial loss: 0.554670\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387607; batch adversarial loss: 0.551726\n",
      "epoch 99; iter: 0; batch classifier loss: 0.352991; batch adversarial loss: 0.506145\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347153; batch adversarial loss: 0.568855\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368487; batch adversarial loss: 0.496577\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350654; batch adversarial loss: 0.530198\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366459; batch adversarial loss: 0.555260\n",
      "epoch 104; iter: 0; batch classifier loss: 0.470252; batch adversarial loss: 0.495684\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351491; batch adversarial loss: 0.555827\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413926; batch adversarial loss: 0.538819\n",
      "epoch 107; iter: 0; batch classifier loss: 0.414440; batch adversarial loss: 0.499513\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334294; batch adversarial loss: 0.601537\n",
      "epoch 109; iter: 0; batch classifier loss: 0.399896; batch adversarial loss: 0.573592\n",
      "epoch 110; iter: 0; batch classifier loss: 0.400830; batch adversarial loss: 0.536194\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409399; batch adversarial loss: 0.459154\n",
      "epoch 112; iter: 0; batch classifier loss: 0.407684; batch adversarial loss: 0.488659\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389735; batch adversarial loss: 0.599423\n",
      "epoch 114; iter: 0; batch classifier loss: 0.396749; batch adversarial loss: 0.599730\n",
      "epoch 115; iter: 0; batch classifier loss: 0.391261; batch adversarial loss: 0.478567\n",
      "epoch 116; iter: 0; batch classifier loss: 0.313493; batch adversarial loss: 0.602407\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388268; batch adversarial loss: 0.554063\n",
      "epoch 118; iter: 0; batch classifier loss: 0.421522; batch adversarial loss: 0.524363\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367950; batch adversarial loss: 0.525618\n",
      "epoch 120; iter: 0; batch classifier loss: 0.449150; batch adversarial loss: 0.608683\n",
      "epoch 121; iter: 0; batch classifier loss: 0.396322; batch adversarial loss: 0.525612\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353647; batch adversarial loss: 0.489497\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416015; batch adversarial loss: 0.516448\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402931; batch adversarial loss: 0.589532\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375671; batch adversarial loss: 0.508176\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377932; batch adversarial loss: 0.478129\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376127; batch adversarial loss: 0.516250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.369092; batch adversarial loss: 0.487982\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388461; batch adversarial loss: 0.583552\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366600; batch adversarial loss: 0.578737\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359306; batch adversarial loss: 0.536123\n",
      "epoch 132; iter: 0; batch classifier loss: 0.435319; batch adversarial loss: 0.515973\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357801; batch adversarial loss: 0.488801\n",
      "epoch 134; iter: 0; batch classifier loss: 0.451620; batch adversarial loss: 0.571754\n",
      "epoch 135; iter: 0; batch classifier loss: 0.476338; batch adversarial loss: 0.533202\n",
      "epoch 136; iter: 0; batch classifier loss: 0.342289; batch adversarial loss: 0.571457\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366089; batch adversarial loss: 0.516475\n",
      "epoch 138; iter: 0; batch classifier loss: 0.424633; batch adversarial loss: 0.507675\n",
      "epoch 139; iter: 0; batch classifier loss: 0.425000; batch adversarial loss: 0.572867\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364037; batch adversarial loss: 0.537379\n",
      "epoch 141; iter: 0; batch classifier loss: 0.413341; batch adversarial loss: 0.627698\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378935; batch adversarial loss: 0.543546\n",
      "epoch 143; iter: 0; batch classifier loss: 0.429505; batch adversarial loss: 0.601646\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389118; batch adversarial loss: 0.582961\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332605; batch adversarial loss: 0.545448\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425990; batch adversarial loss: 0.507677\n",
      "epoch 147; iter: 0; batch classifier loss: 0.419369; batch adversarial loss: 0.582852\n",
      "epoch 148; iter: 0; batch classifier loss: 0.431044; batch adversarial loss: 0.488454\n",
      "epoch 149; iter: 0; batch classifier loss: 0.397675; batch adversarial loss: 0.556090\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371100; batch adversarial loss: 0.562522\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379910; batch adversarial loss: 0.537006\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350211; batch adversarial loss: 0.569884\n",
      "epoch 153; iter: 0; batch classifier loss: 0.424472; batch adversarial loss: 0.507614\n",
      "epoch 154; iter: 0; batch classifier loss: 0.364151; batch adversarial loss: 0.636340\n",
      "epoch 155; iter: 0; batch classifier loss: 0.385898; batch adversarial loss: 0.536930\n",
      "epoch 156; iter: 0; batch classifier loss: 0.426383; batch adversarial loss: 0.543182\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411894; batch adversarial loss: 0.524820\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376194; batch adversarial loss: 0.582528\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346630; batch adversarial loss: 0.498516\n",
      "epoch 160; iter: 0; batch classifier loss: 0.371749; batch adversarial loss: 0.515242\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414192; batch adversarial loss: 0.610873\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379270; batch adversarial loss: 0.579299\n",
      "epoch 163; iter: 0; batch classifier loss: 0.305561; batch adversarial loss: 0.507856\n",
      "epoch 164; iter: 0; batch classifier loss: 0.449771; batch adversarial loss: 0.525963\n",
      "epoch 165; iter: 0; batch classifier loss: 0.376312; batch adversarial loss: 0.535061\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382040; batch adversarial loss: 0.480839\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337462; batch adversarial loss: 0.556384\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363828; batch adversarial loss: 0.478257\n",
      "epoch 169; iter: 0; batch classifier loss: 0.417149; batch adversarial loss: 0.609520\n",
      "epoch 170; iter: 0; batch classifier loss: 0.323271; batch adversarial loss: 0.488647\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388664; batch adversarial loss: 0.609814\n",
      "epoch 172; iter: 0; batch classifier loss: 0.409997; batch adversarial loss: 0.647978\n",
      "epoch 173; iter: 0; batch classifier loss: 0.407781; batch adversarial loss: 0.487457\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380215; batch adversarial loss: 0.532031\n",
      "epoch 175; iter: 0; batch classifier loss: 0.373571; batch adversarial loss: 0.517692\n",
      "epoch 176; iter: 0; batch classifier loss: 0.389475; batch adversarial loss: 0.515680\n",
      "epoch 177; iter: 0; batch classifier loss: 0.394232; batch adversarial loss: 0.618459\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361113; batch adversarial loss: 0.497418\n",
      "epoch 179; iter: 0; batch classifier loss: 0.404450; batch adversarial loss: 0.434135\n",
      "epoch 180; iter: 0; batch classifier loss: 0.292104; batch adversarial loss: 0.579392\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395663; batch adversarial loss: 0.468554\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408865; batch adversarial loss: 0.525348\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371737; batch adversarial loss: 0.432957\n",
      "epoch 184; iter: 0; batch classifier loss: 0.324916; batch adversarial loss: 0.593116\n",
      "epoch 185; iter: 0; batch classifier loss: 0.307647; batch adversarial loss: 0.525164\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390096; batch adversarial loss: 0.515890\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339042; batch adversarial loss: 0.563780\n",
      "epoch 188; iter: 0; batch classifier loss: 0.436132; batch adversarial loss: 0.517883\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375500; batch adversarial loss: 0.526653\n",
      "epoch 190; iter: 0; batch classifier loss: 0.318738; batch adversarial loss: 0.569322\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378249; batch adversarial loss: 0.562173\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364378; batch adversarial loss: 0.478698\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345285; batch adversarial loss: 0.608066\n",
      "epoch 194; iter: 0; batch classifier loss: 0.355012; batch adversarial loss: 0.564601\n",
      "epoch 195; iter: 0; batch classifier loss: 0.421474; batch adversarial loss: 0.545244\n",
      "epoch 196; iter: 0; batch classifier loss: 0.377179; batch adversarial loss: 0.527522\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372877; batch adversarial loss: 0.552695\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342930; batch adversarial loss: 0.523966\n",
      "epoch 199; iter: 0; batch classifier loss: 0.392736; batch adversarial loss: 0.554766\n",
      "epoch 0; iter: 0; batch classifier loss: 0.900738; batch adversarial loss: 1.067523\n",
      "epoch 1; iter: 0; batch classifier loss: 0.895230; batch adversarial loss: 1.099879\n",
      "epoch 2; iter: 0; batch classifier loss: 0.959742; batch adversarial loss: 1.013671\n",
      "epoch 3; iter: 0; batch classifier loss: 0.966378; batch adversarial loss: 0.936784\n",
      "epoch 4; iter: 0; batch classifier loss: 0.976853; batch adversarial loss: 0.896718\n",
      "epoch 5; iter: 0; batch classifier loss: 0.866608; batch adversarial loss: 0.811291\n",
      "epoch 6; iter: 0; batch classifier loss: 0.780450; batch adversarial loss: 0.750649\n",
      "epoch 7; iter: 0; batch classifier loss: 0.701619; batch adversarial loss: 0.700516\n",
      "epoch 8; iter: 0; batch classifier loss: 0.680197; batch adversarial loss: 0.670783\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612040; batch adversarial loss: 0.601778\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525113; batch adversarial loss: 0.579501\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560299; batch adversarial loss: 0.569625\n",
      "epoch 12; iter: 0; batch classifier loss: 0.617634; batch adversarial loss: 0.612727\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534588; batch adversarial loss: 0.547318\n",
      "epoch 14; iter: 0; batch classifier loss: 0.602716; batch adversarial loss: 0.540115\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510714; batch adversarial loss: 0.554592\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512370; batch adversarial loss: 0.558114\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489477; batch adversarial loss: 0.526321\n",
      "epoch 18; iter: 0; batch classifier loss: 0.481995; batch adversarial loss: 0.613261\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484122; batch adversarial loss: 0.562947\n",
      "epoch 20; iter: 0; batch classifier loss: 0.557570; batch adversarial loss: 0.570885\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492145; batch adversarial loss: 0.621859\n",
      "epoch 22; iter: 0; batch classifier loss: 0.542412; batch adversarial loss: 0.507827\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539517; batch adversarial loss: 0.551134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.438884; batch adversarial loss: 0.515324\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504217; batch adversarial loss: 0.545337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.479527; batch adversarial loss: 0.546547\n",
      "epoch 27; iter: 0; batch classifier loss: 0.508064; batch adversarial loss: 0.578316\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493133; batch adversarial loss: 0.636589\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472463; batch adversarial loss: 0.523175\n",
      "epoch 30; iter: 0; batch classifier loss: 0.494474; batch adversarial loss: 0.613815\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431302; batch adversarial loss: 0.519920\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469801; batch adversarial loss: 0.584210\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451620; batch adversarial loss: 0.538427\n",
      "epoch 34; iter: 0; batch classifier loss: 0.489235; batch adversarial loss: 0.478884\n",
      "epoch 35; iter: 0; batch classifier loss: 0.591743; batch adversarial loss: 0.572693\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432099; batch adversarial loss: 0.554630\n",
      "epoch 37; iter: 0; batch classifier loss: 0.426311; batch adversarial loss: 0.519140\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466970; batch adversarial loss: 0.496195\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471243; batch adversarial loss: 0.477992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395531; batch adversarial loss: 0.529259\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449569; batch adversarial loss: 0.501301\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410020; batch adversarial loss: 0.558554\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450397; batch adversarial loss: 0.526723\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411828; batch adversarial loss: 0.534022\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416793; batch adversarial loss: 0.607975\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403641; batch adversarial loss: 0.442182\n",
      "epoch 47; iter: 0; batch classifier loss: 0.414426; batch adversarial loss: 0.529051\n",
      "epoch 48; iter: 0; batch classifier loss: 0.374363; batch adversarial loss: 0.512939\n",
      "epoch 49; iter: 0; batch classifier loss: 0.489775; batch adversarial loss: 0.505221\n",
      "epoch 50; iter: 0; batch classifier loss: 0.511910; batch adversarial loss: 0.507694\n",
      "epoch 51; iter: 0; batch classifier loss: 0.439407; batch adversarial loss: 0.563983\n",
      "epoch 52; iter: 0; batch classifier loss: 0.482936; batch adversarial loss: 0.551646\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381920; batch adversarial loss: 0.499851\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446482; batch adversarial loss: 0.559084\n",
      "epoch 55; iter: 0; batch classifier loss: 0.367940; batch adversarial loss: 0.557460\n",
      "epoch 56; iter: 0; batch classifier loss: 0.488189; batch adversarial loss: 0.505473\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415592; batch adversarial loss: 0.568597\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447728; batch adversarial loss: 0.515000\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424230; batch adversarial loss: 0.507404\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384243; batch adversarial loss: 0.589548\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397034; batch adversarial loss: 0.480538\n",
      "epoch 62; iter: 0; batch classifier loss: 0.358433; batch adversarial loss: 0.567356\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403566; batch adversarial loss: 0.627436\n",
      "epoch 64; iter: 0; batch classifier loss: 0.490366; batch adversarial loss: 0.480762\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414684; batch adversarial loss: 0.515145\n",
      "epoch 66; iter: 0; batch classifier loss: 0.351586; batch adversarial loss: 0.532722\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423505; batch adversarial loss: 0.446434\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419701; batch adversarial loss: 0.542932\n",
      "epoch 69; iter: 0; batch classifier loss: 0.459814; batch adversarial loss: 0.507724\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423173; batch adversarial loss: 0.506164\n",
      "epoch 71; iter: 0; batch classifier loss: 0.368052; batch adversarial loss: 0.525802\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402030; batch adversarial loss: 0.533502\n",
      "epoch 73; iter: 0; batch classifier loss: 0.341036; batch adversarial loss: 0.574840\n",
      "epoch 74; iter: 0; batch classifier loss: 0.485385; batch adversarial loss: 0.529637\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384551; batch adversarial loss: 0.465103\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413235; batch adversarial loss: 0.548453\n",
      "epoch 77; iter: 0; batch classifier loss: 0.365278; batch adversarial loss: 0.555257\n",
      "epoch 78; iter: 0; batch classifier loss: 0.433114; batch adversarial loss: 0.468937\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422449; batch adversarial loss: 0.497618\n",
      "epoch 80; iter: 0; batch classifier loss: 0.302230; batch adversarial loss: 0.517707\n",
      "epoch 81; iter: 0; batch classifier loss: 0.372372; batch adversarial loss: 0.508608\n",
      "epoch 82; iter: 0; batch classifier loss: 0.431228; batch adversarial loss: 0.543980\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412255; batch adversarial loss: 0.479870\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371727; batch adversarial loss: 0.543987\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395935; batch adversarial loss: 0.497524\n",
      "epoch 86; iter: 0; batch classifier loss: 0.471511; batch adversarial loss: 0.553061\n",
      "epoch 87; iter: 0; batch classifier loss: 0.480531; batch adversarial loss: 0.497892\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401663; batch adversarial loss: 0.665513\n",
      "epoch 89; iter: 0; batch classifier loss: 0.482245; batch adversarial loss: 0.565007\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384549; batch adversarial loss: 0.525990\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356417; batch adversarial loss: 0.487670\n",
      "epoch 92; iter: 0; batch classifier loss: 0.330195; batch adversarial loss: 0.572128\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413695; batch adversarial loss: 0.552828\n",
      "epoch 94; iter: 0; batch classifier loss: 0.448840; batch adversarial loss: 0.545169\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400179; batch adversarial loss: 0.581176\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420220; batch adversarial loss: 0.534434\n",
      "epoch 97; iter: 0; batch classifier loss: 0.307752; batch adversarial loss: 0.534103\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387177; batch adversarial loss: 0.546993\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354699; batch adversarial loss: 0.506785\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367293; batch adversarial loss: 0.499661\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399750; batch adversarial loss: 0.551455\n",
      "epoch 102; iter: 0; batch classifier loss: 0.358741; batch adversarial loss: 0.441054\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346057; batch adversarial loss: 0.600013\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341871; batch adversarial loss: 0.514141\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401003; batch adversarial loss: 0.525515\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432180; batch adversarial loss: 0.543317\n",
      "epoch 107; iter: 0; batch classifier loss: 0.349836; batch adversarial loss: 0.482863\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355242; batch adversarial loss: 0.573786\n",
      "epoch 109; iter: 0; batch classifier loss: 0.466472; batch adversarial loss: 0.598874\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377463; batch adversarial loss: 0.590988\n",
      "epoch 111; iter: 0; batch classifier loss: 0.337369; batch adversarial loss: 0.553394\n",
      "epoch 112; iter: 0; batch classifier loss: 0.354539; batch adversarial loss: 0.553312\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406589; batch adversarial loss: 0.516436\n",
      "epoch 114; iter: 0; batch classifier loss: 0.404163; batch adversarial loss: 0.538720\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346543; batch adversarial loss: 0.468482\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377949; batch adversarial loss: 0.518010\n",
      "epoch 117; iter: 0; batch classifier loss: 0.462931; batch adversarial loss: 0.535831\n",
      "epoch 118; iter: 0; batch classifier loss: 0.341833; batch adversarial loss: 0.535813\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370861; batch adversarial loss: 0.489811\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354321; batch adversarial loss: 0.535924\n",
      "epoch 121; iter: 0; batch classifier loss: 0.336962; batch adversarial loss: 0.507676\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371783; batch adversarial loss: 0.572808\n",
      "epoch 123; iter: 0; batch classifier loss: 0.459212; batch adversarial loss: 0.506561\n",
      "epoch 124; iter: 0; batch classifier loss: 0.335959; batch adversarial loss: 0.507033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.389145; batch adversarial loss: 0.516773\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338064; batch adversarial loss: 0.554114\n",
      "epoch 127; iter: 0; batch classifier loss: 0.321693; batch adversarial loss: 0.477825\n",
      "epoch 128; iter: 0; batch classifier loss: 0.286041; batch adversarial loss: 0.582287\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406036; batch adversarial loss: 0.534584\n",
      "epoch 130; iter: 0; batch classifier loss: 0.336754; batch adversarial loss: 0.515961\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386196; batch adversarial loss: 0.524300\n",
      "epoch 132; iter: 0; batch classifier loss: 0.374722; batch adversarial loss: 0.581973\n",
      "epoch 133; iter: 0; batch classifier loss: 0.348025; batch adversarial loss: 0.571248\n",
      "epoch 134; iter: 0; batch classifier loss: 0.281098; batch adversarial loss: 0.579927\n",
      "epoch 135; iter: 0; batch classifier loss: 0.312052; batch adversarial loss: 0.600423\n",
      "epoch 136; iter: 0; batch classifier loss: 0.434445; batch adversarial loss: 0.507206\n",
      "epoch 137; iter: 0; batch classifier loss: 0.415497; batch adversarial loss: 0.556899\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375276; batch adversarial loss: 0.507198\n",
      "epoch 139; iter: 0; batch classifier loss: 0.322311; batch adversarial loss: 0.478352\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409555; batch adversarial loss: 0.461421\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387124; batch adversarial loss: 0.554696\n",
      "epoch 142; iter: 0; batch classifier loss: 0.279587; batch adversarial loss: 0.524570\n",
      "epoch 143; iter: 0; batch classifier loss: 0.349149; batch adversarial loss: 0.619416\n",
      "epoch 144; iter: 0; batch classifier loss: 0.303930; batch adversarial loss: 0.488213\n",
      "epoch 145; iter: 0; batch classifier loss: 0.417390; batch adversarial loss: 0.573472\n",
      "epoch 146; iter: 0; batch classifier loss: 0.364375; batch adversarial loss: 0.599273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.424225; batch adversarial loss: 0.496735\n",
      "epoch 148; iter: 0; batch classifier loss: 0.384943; batch adversarial loss: 0.563254\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354812; batch adversarial loss: 0.561762\n",
      "epoch 150; iter: 0; batch classifier loss: 0.397162; batch adversarial loss: 0.525503\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325276; batch adversarial loss: 0.630524\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332689; batch adversarial loss: 0.516062\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361647; batch adversarial loss: 0.516221\n",
      "epoch 154; iter: 0; batch classifier loss: 0.355673; batch adversarial loss: 0.554859\n",
      "epoch 155; iter: 0; batch classifier loss: 0.425072; batch adversarial loss: 0.487811\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398887; batch adversarial loss: 0.544695\n",
      "epoch 157; iter: 0; batch classifier loss: 0.380229; batch adversarial loss: 0.526200\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390416; batch adversarial loss: 0.497897\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362011; batch adversarial loss: 0.534844\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349956; batch adversarial loss: 0.535693\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408213; batch adversarial loss: 0.525875\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361890; batch adversarial loss: 0.543861\n",
      "epoch 163; iter: 0; batch classifier loss: 0.320634; batch adversarial loss: 0.553764\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371582; batch adversarial loss: 0.553566\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329053; batch adversarial loss: 0.572706\n",
      "epoch 166; iter: 0; batch classifier loss: 0.404048; batch adversarial loss: 0.525665\n",
      "epoch 167; iter: 0; batch classifier loss: 0.400349; batch adversarial loss: 0.562700\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345433; batch adversarial loss: 0.497575\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408100; batch adversarial loss: 0.581647\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371074; batch adversarial loss: 0.471054\n",
      "epoch 171; iter: 0; batch classifier loss: 0.316846; batch adversarial loss: 0.515996\n",
      "epoch 172; iter: 0; batch classifier loss: 0.325245; batch adversarial loss: 0.515474\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369798; batch adversarial loss: 0.515350\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393167; batch adversarial loss: 0.553105\n",
      "epoch 175; iter: 0; batch classifier loss: 0.287247; batch adversarial loss: 0.703156\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351859; batch adversarial loss: 0.514263\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396985; batch adversarial loss: 0.535857\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307612; batch adversarial loss: 0.507317\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322875; batch adversarial loss: 0.478987\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335924; batch adversarial loss: 0.479622\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374016; batch adversarial loss: 0.497973\n",
      "epoch 182; iter: 0; batch classifier loss: 0.295616; batch adversarial loss: 0.487982\n",
      "epoch 183; iter: 0; batch classifier loss: 0.404052; batch adversarial loss: 0.608479\n",
      "epoch 184; iter: 0; batch classifier loss: 0.283637; batch adversarial loss: 0.536011\n",
      "epoch 185; iter: 0; batch classifier loss: 0.382059; batch adversarial loss: 0.526017\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340397; batch adversarial loss: 0.552869\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353992; batch adversarial loss: 0.603889\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324700; batch adversarial loss: 0.450675\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356136; batch adversarial loss: 0.516410\n",
      "epoch 190; iter: 0; batch classifier loss: 0.400196; batch adversarial loss: 0.611666\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365230; batch adversarial loss: 0.572421\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326705; batch adversarial loss: 0.469349\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308475; batch adversarial loss: 0.563042\n",
      "epoch 194; iter: 0; batch classifier loss: 0.333437; batch adversarial loss: 0.423336\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354283; batch adversarial loss: 0.629478\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327757; batch adversarial loss: 0.562839\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353370; batch adversarial loss: 0.535467\n",
      "epoch 198; iter: 0; batch classifier loss: 0.386922; batch adversarial loss: 0.506489\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319287; batch adversarial loss: 0.562016\n",
      "epoch 0; iter: 0; batch classifier loss: 0.791148; batch adversarial loss: 0.571617\n",
      "epoch 1; iter: 0; batch classifier loss: 0.669196; batch adversarial loss: 0.618487\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563971; batch adversarial loss: 0.642991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548461; batch adversarial loss: 0.644047\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588027; batch adversarial loss: 0.630017\n",
      "epoch 5; iter: 0; batch classifier loss: 0.506523; batch adversarial loss: 0.602386\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525172; batch adversarial loss: 0.650499\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571506; batch adversarial loss: 0.614097\n",
      "epoch 8; iter: 0; batch classifier loss: 0.592381; batch adversarial loss: 0.601247\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538788; batch adversarial loss: 0.498804\n",
      "epoch 10; iter: 0; batch classifier loss: 0.615298; batch adversarial loss: 0.510627\n",
      "epoch 11; iter: 0; batch classifier loss: 0.595260; batch adversarial loss: 0.594803\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488007; batch adversarial loss: 0.579031\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496864; batch adversarial loss: 0.564291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538113; batch adversarial loss: 0.543406\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513049; batch adversarial loss: 0.561152\n",
      "epoch 16; iter: 0; batch classifier loss: 0.524718; batch adversarial loss: 0.503932\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477104; batch adversarial loss: 0.659991\n",
      "epoch 18; iter: 0; batch classifier loss: 0.537545; batch adversarial loss: 0.577073\n",
      "epoch 19; iter: 0; batch classifier loss: 0.555228; batch adversarial loss: 0.563282\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500765; batch adversarial loss: 0.529683\n",
      "epoch 21; iter: 0; batch classifier loss: 0.547045; batch adversarial loss: 0.513027\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507004; batch adversarial loss: 0.573379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.539790; batch adversarial loss: 0.498482\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465084; batch adversarial loss: 0.571314\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500288; batch adversarial loss: 0.507718\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500003; batch adversarial loss: 0.507159\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493842; batch adversarial loss: 0.499384\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486675; batch adversarial loss: 0.497902\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438579; batch adversarial loss: 0.596211\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513032; batch adversarial loss: 0.494489\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485277; batch adversarial loss: 0.521206\n",
      "epoch 32; iter: 0; batch classifier loss: 0.446753; batch adversarial loss: 0.489576\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437246; batch adversarial loss: 0.489248\n",
      "epoch 34; iter: 0; batch classifier loss: 0.518548; batch adversarial loss: 0.571354\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455474; batch adversarial loss: 0.464047\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477130; batch adversarial loss: 0.549269\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445793; batch adversarial loss: 0.521586\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471563; batch adversarial loss: 0.567531\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442012; batch adversarial loss: 0.534116\n",
      "epoch 40; iter: 0; batch classifier loss: 0.513042; batch adversarial loss: 0.496079\n",
      "epoch 41; iter: 0; batch classifier loss: 0.540833; batch adversarial loss: 0.500786\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448277; batch adversarial loss: 0.516814\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454592; batch adversarial loss: 0.578197\n",
      "epoch 44; iter: 0; batch classifier loss: 0.367211; batch adversarial loss: 0.584520\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479530; batch adversarial loss: 0.553796\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467475; batch adversarial loss: 0.583222\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430286; batch adversarial loss: 0.457001\n",
      "epoch 48; iter: 0; batch classifier loss: 0.522586; batch adversarial loss: 0.532993\n",
      "epoch 49; iter: 0; batch classifier loss: 0.484721; batch adversarial loss: 0.531855\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439039; batch adversarial loss: 0.545766\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438825; batch adversarial loss: 0.627007\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420856; batch adversarial loss: 0.499586\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413500; batch adversarial loss: 0.545348\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419832; batch adversarial loss: 0.586762\n",
      "epoch 55; iter: 0; batch classifier loss: 0.363351; batch adversarial loss: 0.540485\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411453; batch adversarial loss: 0.555115\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402344; batch adversarial loss: 0.573382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462788; batch adversarial loss: 0.487808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419274; batch adversarial loss: 0.458635\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450533; batch adversarial loss: 0.572052\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376217; batch adversarial loss: 0.440510\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416859; batch adversarial loss: 0.563400\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408911; batch adversarial loss: 0.493187\n",
      "epoch 64; iter: 0; batch classifier loss: 0.385870; batch adversarial loss: 0.573999\n",
      "epoch 65; iter: 0; batch classifier loss: 0.404848; batch adversarial loss: 0.605025\n",
      "epoch 66; iter: 0; batch classifier loss: 0.453232; batch adversarial loss: 0.541184\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444031; batch adversarial loss: 0.570896\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437705; batch adversarial loss: 0.565292\n",
      "epoch 69; iter: 0; batch classifier loss: 0.423093; batch adversarial loss: 0.581404\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461800; batch adversarial loss: 0.526017\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429697; batch adversarial loss: 0.634289\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400342; batch adversarial loss: 0.588069\n",
      "epoch 73; iter: 0; batch classifier loss: 0.500050; batch adversarial loss: 0.518479\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405223; batch adversarial loss: 0.599709\n",
      "epoch 75; iter: 0; batch classifier loss: 0.463214; batch adversarial loss: 0.539844\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377618; batch adversarial loss: 0.600493\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429471; batch adversarial loss: 0.580728\n",
      "epoch 78; iter: 0; batch classifier loss: 0.363405; batch adversarial loss: 0.554805\n",
      "epoch 79; iter: 0; batch classifier loss: 0.453767; batch adversarial loss: 0.648047\n",
      "epoch 80; iter: 0; batch classifier loss: 0.338624; batch adversarial loss: 0.585073\n",
      "epoch 81; iter: 0; batch classifier loss: 0.501865; batch adversarial loss: 0.532968\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372501; batch adversarial loss: 0.554356\n",
      "epoch 83; iter: 0; batch classifier loss: 0.443322; batch adversarial loss: 0.513438\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437200; batch adversarial loss: 0.503812\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419927; batch adversarial loss: 0.543798\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357867; batch adversarial loss: 0.629986\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392616; batch adversarial loss: 0.492580\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422499; batch adversarial loss: 0.542787\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398005; batch adversarial loss: 0.565724\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402506; batch adversarial loss: 0.633630\n",
      "epoch 91; iter: 0; batch classifier loss: 0.325836; batch adversarial loss: 0.486029\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408543; batch adversarial loss: 0.515249\n",
      "epoch 93; iter: 0; batch classifier loss: 0.470946; batch adversarial loss: 0.607415\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434894; batch adversarial loss: 0.529359\n",
      "epoch 95; iter: 0; batch classifier loss: 0.468099; batch adversarial loss: 0.471795\n",
      "epoch 96; iter: 0; batch classifier loss: 0.467750; batch adversarial loss: 0.510578\n",
      "epoch 97; iter: 0; batch classifier loss: 0.310871; batch adversarial loss: 0.592740\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393461; batch adversarial loss: 0.598867\n",
      "epoch 99; iter: 0; batch classifier loss: 0.454354; batch adversarial loss: 0.461142\n",
      "epoch 100; iter: 0; batch classifier loss: 0.430612; batch adversarial loss: 0.524535\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379716; batch adversarial loss: 0.558300\n",
      "epoch 102; iter: 0; batch classifier loss: 0.328051; batch adversarial loss: 0.554688\n",
      "epoch 103; iter: 0; batch classifier loss: 0.283336; batch adversarial loss: 0.497393\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389759; batch adversarial loss: 0.533635\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351488; batch adversarial loss: 0.604532\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409778; batch adversarial loss: 0.453245\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352490; batch adversarial loss: 0.558048\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364955; batch adversarial loss: 0.572964\n",
      "epoch 109; iter: 0; batch classifier loss: 0.420499; batch adversarial loss: 0.580877\n",
      "epoch 110; iter: 0; batch classifier loss: 0.435047; batch adversarial loss: 0.491596\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408288; batch adversarial loss: 0.531051\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397640; batch adversarial loss: 0.561342\n",
      "epoch 113; iter: 0; batch classifier loss: 0.408116; batch adversarial loss: 0.463876\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340192; batch adversarial loss: 0.600238\n",
      "epoch 115; iter: 0; batch classifier loss: 0.451357; batch adversarial loss: 0.608385\n",
      "epoch 116; iter: 0; batch classifier loss: 0.477377; batch adversarial loss: 0.545273\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399329; batch adversarial loss: 0.551273\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376385; batch adversarial loss: 0.539669\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344965; batch adversarial loss: 0.457068\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398836; batch adversarial loss: 0.567397\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397185; batch adversarial loss: 0.581760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.331774; batch adversarial loss: 0.525580\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366286; batch adversarial loss: 0.534477\n",
      "epoch 124; iter: 0; batch classifier loss: 0.324732; batch adversarial loss: 0.520542\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397138; batch adversarial loss: 0.548304\n",
      "epoch 126; iter: 0; batch classifier loss: 0.320344; batch adversarial loss: 0.495626\n",
      "epoch 127; iter: 0; batch classifier loss: 0.447816; batch adversarial loss: 0.534401\n",
      "epoch 128; iter: 0; batch classifier loss: 0.321174; batch adversarial loss: 0.574994\n",
      "epoch 129; iter: 0; batch classifier loss: 0.443316; batch adversarial loss: 0.428621\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377852; batch adversarial loss: 0.585757\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350539; batch adversarial loss: 0.537072\n",
      "epoch 132; iter: 0; batch classifier loss: 0.326016; batch adversarial loss: 0.512954\n",
      "epoch 133; iter: 0; batch classifier loss: 0.380882; batch adversarial loss: 0.595947\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385216; batch adversarial loss: 0.515689\n",
      "epoch 135; iter: 0; batch classifier loss: 0.469858; batch adversarial loss: 0.458586\n",
      "epoch 136; iter: 0; batch classifier loss: 0.453445; batch adversarial loss: 0.604308\n",
      "epoch 137; iter: 0; batch classifier loss: 0.360071; batch adversarial loss: 0.513112\n",
      "epoch 138; iter: 0; batch classifier loss: 0.385021; batch adversarial loss: 0.572594\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401427; batch adversarial loss: 0.514460\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348404; batch adversarial loss: 0.552709\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389356; batch adversarial loss: 0.536657\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358240; batch adversarial loss: 0.571398\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386464; batch adversarial loss: 0.471442\n",
      "epoch 144; iter: 0; batch classifier loss: 0.430320; batch adversarial loss: 0.557448\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380382; batch adversarial loss: 0.623757\n",
      "epoch 146; iter: 0; batch classifier loss: 0.450154; batch adversarial loss: 0.589333\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381722; batch adversarial loss: 0.554757\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381898; batch adversarial loss: 0.475917\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405687; batch adversarial loss: 0.514085\n",
      "epoch 150; iter: 0; batch classifier loss: 0.427197; batch adversarial loss: 0.535279\n",
      "epoch 151; iter: 0; batch classifier loss: 0.359283; batch adversarial loss: 0.509790\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378399; batch adversarial loss: 0.560131\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384349; batch adversarial loss: 0.567486\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372173; batch adversarial loss: 0.497923\n",
      "epoch 155; iter: 0; batch classifier loss: 0.353758; batch adversarial loss: 0.498696\n",
      "epoch 156; iter: 0; batch classifier loss: 0.365413; batch adversarial loss: 0.508119\n",
      "epoch 157; iter: 0; batch classifier loss: 0.345816; batch adversarial loss: 0.477941\n",
      "epoch 158; iter: 0; batch classifier loss: 0.289589; batch adversarial loss: 0.543065\n",
      "epoch 159; iter: 0; batch classifier loss: 0.328987; batch adversarial loss: 0.604136\n",
      "epoch 160; iter: 0; batch classifier loss: 0.301421; batch adversarial loss: 0.545366\n",
      "epoch 161; iter: 0; batch classifier loss: 0.353257; batch adversarial loss: 0.539392\n",
      "epoch 162; iter: 0; batch classifier loss: 0.450770; batch adversarial loss: 0.528745\n",
      "epoch 163; iter: 0; batch classifier loss: 0.427641; batch adversarial loss: 0.514222\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380152; batch adversarial loss: 0.526605\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344444; batch adversarial loss: 0.465814\n",
      "epoch 166; iter: 0; batch classifier loss: 0.434269; batch adversarial loss: 0.511665\n",
      "epoch 167; iter: 0; batch classifier loss: 0.460545; batch adversarial loss: 0.517879\n",
      "epoch 168; iter: 0; batch classifier loss: 0.310297; batch adversarial loss: 0.539073\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360556; batch adversarial loss: 0.572001\n",
      "epoch 170; iter: 0; batch classifier loss: 0.438104; batch adversarial loss: 0.580805\n",
      "epoch 171; iter: 0; batch classifier loss: 0.356530; batch adversarial loss: 0.483561\n",
      "epoch 172; iter: 0; batch classifier loss: 0.427853; batch adversarial loss: 0.587444\n",
      "epoch 173; iter: 0; batch classifier loss: 0.332438; batch adversarial loss: 0.544188\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371979; batch adversarial loss: 0.510841\n",
      "epoch 175; iter: 0; batch classifier loss: 0.350054; batch adversarial loss: 0.544452\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365098; batch adversarial loss: 0.434118\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376551; batch adversarial loss: 0.600130\n",
      "epoch 178; iter: 0; batch classifier loss: 0.472779; batch adversarial loss: 0.524814\n",
      "epoch 179; iter: 0; batch classifier loss: 0.264636; batch adversarial loss: 0.580399\n",
      "epoch 180; iter: 0; batch classifier loss: 0.409544; batch adversarial loss: 0.583491\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358450; batch adversarial loss: 0.522077\n",
      "epoch 182; iter: 0; batch classifier loss: 0.398483; batch adversarial loss: 0.634104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.459356; batch adversarial loss: 0.547638\n",
      "epoch 184; iter: 0; batch classifier loss: 0.388669; batch adversarial loss: 0.534012\n",
      "epoch 185; iter: 0; batch classifier loss: 0.343316; batch adversarial loss: 0.522128\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382910; batch adversarial loss: 0.579617\n",
      "epoch 187; iter: 0; batch classifier loss: 0.384566; batch adversarial loss: 0.583822\n",
      "epoch 188; iter: 0; batch classifier loss: 0.349369; batch adversarial loss: 0.552601\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414869; batch adversarial loss: 0.578104\n",
      "epoch 190; iter: 0; batch classifier loss: 0.389721; batch adversarial loss: 0.565410\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346509; batch adversarial loss: 0.560140\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344329; batch adversarial loss: 0.553469\n",
      "epoch 193; iter: 0; batch classifier loss: 0.271964; batch adversarial loss: 0.580915\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407444; batch adversarial loss: 0.534761\n",
      "epoch 195; iter: 0; batch classifier loss: 0.430474; batch adversarial loss: 0.547936\n",
      "epoch 196; iter: 0; batch classifier loss: 0.407573; batch adversarial loss: 0.512150\n",
      "epoch 197; iter: 0; batch classifier loss: 0.397640; batch adversarial loss: 0.489996\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350452; batch adversarial loss: 0.538877\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355167; batch adversarial loss: 0.546603\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7398471",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5528843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8ea9bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49869f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
